{"directory":{"bin":{"directory":{"openChrome.applescript":{"file":{"contents":"(*\nCopyright (c) 2015-present, Facebook, Inc.\n\nThis source code is licensed under the MIT license found in the\nLICENSE file at\nhttps://github.com/facebookincubator/create-react-app/blob/master/LICENSE\n*)\n\nproperty targetTab: null\nproperty targetTabIndex: -1\nproperty targetWindow: null\nproperty theProgram: \"Google Chrome\"\n\non run argv\n  set theURL to item 1 of argv\n\n  -- Allow requested program to be optional,\n  -- default to Google Chrome\n  if (count of argv) > 1 then\n    set theProgram to item 2 of argv\n  end if\n\n  using terms from application \"Google Chrome\"\n    tell application theProgram\n\n      if (count every window) = 0 then\n        make new window\n      end if\n\n      -- 1: Looking for tab running debugger\n      -- then, Reload debugging tab if found\n      -- then return\n      set found to my lookupTabWithUrl(theURL)\n      if found then\n        set targetWindow's active tab index to targetTabIndex\n        tell targetTab to reload\n        tell targetWindow to activate\n        set index of targetWindow to 1\n        return\n      end if\n\n      -- 2: Looking for Empty tab\n      -- In case debugging tab was not found\n      -- We try to find an empty tab instead\n      set found to my lookupTabWithUrl(\"chrome://newtab/\")\n      if found then\n        set targetWindow's active tab index to targetTabIndex\n        set URL of targetTab to theURL\n        tell targetWindow to activate\n        return\n      end if\n\n      -- 3: Create new tab\n      -- both debugging and empty tab were not found\n      -- make a new tab with url\n      tell window 1\n        activate\n        make new tab with properties {URL:theURL}\n      end tell\n    end tell\n  end using terms from\nend run\n\n-- Function:\n-- Lookup tab with given url\n-- if found, store tab, index, and window in properties\n-- (properties were declared on top of file)\non lookupTabWithUrl(lookupUrl)\n  using terms from application \"Google Chrome\"\n    tell application theProgram\n      -- Find a tab with the given url\n      set found to false\n      set theTabIndex to -1\n      repeat with theWindow in every window\n        set theTabIndex to 0\n        repeat with theTab in every tab of theWindow\n          set theTabIndex to theTabIndex + 1\n          if (theTab's URL as string) contains lookupUrl then\n            -- assign tab, tab index, and window to properties\n            set targetTab to theTab\n            set targetTabIndex to theTabIndex\n            set targetWindow to theWindow\n            set found to true\n            exit repeat\n          end if\n        end repeat\n\n        if found then\n          exit repeat\n        end if\n      end repeat\n    end tell\n  end using terms from\n  return found\nend lookupTabWithUrl\n"}},"vite.js":{"file":{"contents":"#!/usr/bin/env node\nimport { performance } from 'node:perf_hooks'\n\nif (!import.meta.url.includes('node_modules')) {\n  try {\n    // only available as dev dependency\n    await import('source-map-support').then((r) => r.default.install())\n  } catch (e) {}\n}\n\nglobal.__vite_start_time = performance.now()\n\n// check debug mode first before requiring the CLI.\nconst debugIndex = process.argv.findIndex((arg) => /^(?:-d|--debug)$/.test(arg))\nconst filterIndex = process.argv.findIndex((arg) =>\n  /^(?:-f|--filter)$/.test(arg),\n)\nconst profileIndex = process.argv.indexOf('--profile')\n\nif (debugIndex > 0) {\n  let value = process.argv[debugIndex + 1]\n  if (!value || value.startsWith('-')) {\n    value = 'vite:*'\n  } else {\n    // support debugging multiple flags with comma-separated list\n    value = value\n      .split(',')\n      .map((v) => `vite:${v}`)\n      .join(',')\n  }\n  process.env.DEBUG = `${\n    process.env.DEBUG ? process.env.DEBUG + ',' : ''\n  }${value}`\n\n  if (filterIndex > 0) {\n    const filter = process.argv[filterIndex + 1]\n    if (filter && !filter.startsWith('-')) {\n      process.env.VITE_DEBUG_FILTER = filter\n    }\n  }\n}\n\nfunction start() {\n  return import('../dist/node/cli.js')\n}\n\nif (profileIndex > 0) {\n  process.argv.splice(profileIndex, 1)\n  const next = process.argv[profileIndex]\n  if (next && !next.startsWith('-')) {\n    process.argv.splice(profileIndex, 1)\n  }\n  const inspector = await import('node:inspector').then((r) => r.default)\n  const session = (global.__vite_profile_session = new inspector.Session())\n  session.connect()\n  session.post('Profiler.enable', () => {\n    session.post('Profiler.start', start)\n  })\n} else {\n  start()\n}\n"}}}},"client.d.ts":{"file":{"contents":"/// <reference path=\"./types/importMeta.d.ts\" />\n\n// CSS modules\ntype CSSModuleClasses = { readonly [key: string]: string }\n\ndeclare module '*.module.css' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.scss' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.sass' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.less' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.styl' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.stylus' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.pcss' {\n  const classes: CSSModuleClasses\n  export default classes\n}\ndeclare module '*.module.sss' {\n  const classes: CSSModuleClasses\n  export default classes\n}\n\n// CSS\ndeclare module '*.css' {\n  /**\n   * @deprecated Use `import style from './style.css?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.scss' {\n  /**\n   * @deprecated Use `import style from './style.scss?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.sass' {\n  /**\n   * @deprecated Use `import style from './style.sass?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.less' {\n  /**\n   * @deprecated Use `import style from './style.less?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.styl' {\n  /**\n   * @deprecated Use `import style from './style.styl?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.stylus' {\n  /**\n   * @deprecated Use `import style from './style.stylus?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.pcss' {\n  /**\n   * @deprecated Use `import style from './style.pcss?inline'` instead.\n   */\n  const css: string\n  export default css\n}\ndeclare module '*.sss' {\n  /**\n   * @deprecated Use `import style from './style.sss?inline'` instead.\n   */\n  const css: string\n  export default css\n}\n\n// Built-in asset types\n// see `src/node/constants.ts`\n\n// images\ndeclare module '*.png' {\n  const src: string\n  export default src\n}\ndeclare module '*.jpg' {\n  const src: string\n  export default src\n}\ndeclare module '*.jpeg' {\n  const src: string\n  export default src\n}\ndeclare module '*.jfif' {\n  const src: string\n  export default src\n}\ndeclare module '*.pjpeg' {\n  const src: string\n  export default src\n}\ndeclare module '*.pjp' {\n  const src: string\n  export default src\n}\ndeclare module '*.gif' {\n  const src: string\n  export default src\n}\ndeclare module '*.svg' {\n  const src: string\n  export default src\n}\ndeclare module '*.ico' {\n  const src: string\n  export default src\n}\ndeclare module '*.webp' {\n  const src: string\n  export default src\n}\ndeclare module '*.avif' {\n  const src: string\n  export default src\n}\n\n// media\ndeclare module '*.mp4' {\n  const src: string\n  export default src\n}\ndeclare module '*.webm' {\n  const src: string\n  export default src\n}\ndeclare module '*.ogg' {\n  const src: string\n  export default src\n}\ndeclare module '*.mp3' {\n  const src: string\n  export default src\n}\ndeclare module '*.wav' {\n  const src: string\n  export default src\n}\ndeclare module '*.flac' {\n  const src: string\n  export default src\n}\ndeclare module '*.aac' {\n  const src: string\n  export default src\n}\n\n// fonts\ndeclare module '*.woff' {\n  const src: string\n  export default src\n}\ndeclare module '*.woff2' {\n  const src: string\n  export default src\n}\ndeclare module '*.eot' {\n  const src: string\n  export default src\n}\ndeclare module '*.ttf' {\n  const src: string\n  export default src\n}\ndeclare module '*.otf' {\n  const src: string\n  export default src\n}\n\n// other\ndeclare module '*.webmanifest' {\n  const src: string\n  export default src\n}\ndeclare module '*.pdf' {\n  const src: string\n  export default src\n}\ndeclare module '*.txt' {\n  const src: string\n  export default src\n}\n\n// wasm?init\ndeclare module '*.wasm?init' {\n  const initWasm: (\n    options: WebAssembly.Imports,\n  ) => Promise<WebAssembly.Instance>\n  export default initWasm\n}\n\n// web worker\ndeclare module '*?worker' {\n  const workerConstructor: {\n    new (): Worker\n  }\n  export default workerConstructor\n}\n\ndeclare module '*?worker&inline' {\n  const workerConstructor: {\n    new (): Worker\n  }\n  export default workerConstructor\n}\n\ndeclare module '*?worker&url' {\n  const src: string\n  export default src\n}\n\ndeclare module '*?sharedworker' {\n  const sharedWorkerConstructor: {\n    new (): SharedWorker\n  }\n  export default sharedWorkerConstructor\n}\n\ndeclare module '*?sharedworker&inline' {\n  const sharedWorkerConstructor: {\n    new (): SharedWorker\n  }\n  export default sharedWorkerConstructor\n}\n\ndeclare module '*?sharedworker&url' {\n  const src: string\n  export default src\n}\n\ndeclare module '*?raw' {\n  const src: string\n  export default src\n}\n\ndeclare module '*?url' {\n  const src: string\n  export default src\n}\n\ndeclare module '*?inline' {\n  const src: string\n  export default src\n}\n"}},"dist":{"directory":{"client":{"directory":{"client.mjs":{"file":{"contents":"import '@vite/env';\n\nconst base$1 = __BASE__ || '/';\n// set :host styles to make playwright detect the element as visible\nconst template = /*html*/ `\n<style>\n:host {\n  position: fixed;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  z-index: 99999;\n  --monospace: 'SFMono-Regular', Consolas,\n  'Liberation Mono', Menlo, Courier, monospace;\n  --red: #ff5555;\n  --yellow: #e2aa53;\n  --purple: #cfa4ff;\n  --cyan: #2dd9da;\n  --dim: #c9c9c9;\n\n  --window-background: #181818;\n  --window-color: #d8d8d8;\n}\n\n.backdrop {\n  position: fixed;\n  z-index: 99999;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  overflow-y: scroll;\n  margin: 0;\n  background: rgba(0, 0, 0, 0.66);\n}\n\n.window {\n  font-family: var(--monospace);\n  line-height: 1.5;\n  width: 800px;\n  color: var(--window-color);\n  margin: 30px auto;\n  padding: 25px 40px;\n  position: relative;\n  background: var(--window-background);\n  border-radius: 6px 6px 8px 8px;\n  box-shadow: 0 19px 38px rgba(0,0,0,0.30), 0 15px 12px rgba(0,0,0,0.22);\n  overflow: hidden;\n  border-top: 8px solid var(--red);\n  direction: ltr;\n  text-align: left;\n}\n\npre {\n  font-family: var(--monospace);\n  font-size: 16px;\n  margin-top: 0;\n  margin-bottom: 1em;\n  overflow-x: scroll;\n  scrollbar-width: none;\n}\n\npre::-webkit-scrollbar {\n  display: none;\n}\n\n.message {\n  line-height: 1.3;\n  font-weight: 600;\n  white-space: pre-wrap;\n}\n\n.message-body {\n  color: var(--red);\n}\n\n.plugin {\n  color: var(--purple);\n}\n\n.file {\n  color: var(--cyan);\n  margin-bottom: 0;\n  white-space: pre-wrap;\n  word-break: break-all;\n}\n\n.frame {\n  color: var(--yellow);\n}\n\n.stack {\n  font-size: 13px;\n  color: var(--dim);\n}\n\n.tip {\n  font-size: 13px;\n  color: #999;\n  border-top: 1px dotted #999;\n  padding-top: 13px;\n}\n\ncode {\n  font-size: 13px;\n  font-family: var(--monospace);\n  color: var(--yellow);\n}\n\n.file-link {\n  text-decoration: underline;\n  cursor: pointer;\n}\n</style>\n<div class=\"backdrop\" part=\"backdrop\">\n  <div class=\"window\" part=\"window\">\n    <pre class=\"message\" part=\"message\"><span class=\"plugin\"></span><span class=\"message-body\"></span></pre>\n    <pre class=\"file\" part=\"file\"></pre>\n    <pre class=\"frame\" part=\"frame\"></pre>\n    <pre class=\"stack\" part=\"stack\"></pre>\n    <div class=\"tip\" part=\"tip\">\n      Click outside or fix the code to dismiss.<br>\n      You can also disable this overlay by setting\n      <code>server.hmr.overlay</code> to <code>false</code> in <code>vite.config.js.</code>\n    </div>\n  </div>\n</div>\n`;\nconst fileRE = /(?:[a-zA-Z]:\\\\|\\/).*?:\\d+:\\d+/g;\nconst codeframeRE = /^(?:>?\\s+\\d+\\s+\\|.*|\\s+\\|\\s*\\^.*)\\r?\\n/gm;\n// Allow `ErrorOverlay` to extend `HTMLElement` even in environments where\n// `HTMLElement` was not originally defined.\nconst { HTMLElement = class {\n} } = globalThis;\nclass ErrorOverlay extends HTMLElement {\n    constructor(err, links = true) {\n        var _a;\n        super();\n        this.root = this.attachShadow({ mode: 'open' });\n        this.root.innerHTML = template;\n        codeframeRE.lastIndex = 0;\n        const hasFrame = err.frame && codeframeRE.test(err.frame);\n        const message = hasFrame\n            ? err.message.replace(codeframeRE, '')\n            : err.message;\n        if (err.plugin) {\n            this.text('.plugin', `[plugin:${err.plugin}] `);\n        }\n        this.text('.message-body', message.trim());\n        const [file] = (((_a = err.loc) === null || _a === void 0 ? void 0 : _a.file) || err.id || 'unknown file').split(`?`);\n        if (err.loc) {\n            this.text('.file', `${file}:${err.loc.line}:${err.loc.column}`, links);\n        }\n        else if (err.id) {\n            this.text('.file', file);\n        }\n        if (hasFrame) {\n            this.text('.frame', err.frame.trim());\n        }\n        this.text('.stack', err.stack, links);\n        this.root.querySelector('.window').addEventListener('click', (e) => {\n            e.stopPropagation();\n        });\n        this.addEventListener('click', () => {\n            this.close();\n        });\n    }\n    text(selector, text, linkFiles = false) {\n        const el = this.root.querySelector(selector);\n        if (!linkFiles) {\n            el.textContent = text;\n        }\n        else {\n            let curIndex = 0;\n            let match;\n            fileRE.lastIndex = 0;\n            while ((match = fileRE.exec(text))) {\n                const { 0: file, index } = match;\n                if (index != null) {\n                    const frag = text.slice(curIndex, index);\n                    el.appendChild(document.createTextNode(frag));\n                    const link = document.createElement('a');\n                    link.textContent = file;\n                    link.className = 'file-link';\n                    link.onclick = () => {\n                        fetch(`${base$1}__open-in-editor?file=` + encodeURIComponent(file));\n                    };\n                    el.appendChild(link);\n                    curIndex += frag.length + file.length;\n                }\n            }\n        }\n    }\n    close() {\n        var _a;\n        (_a = this.parentNode) === null || _a === void 0 ? void 0 : _a.removeChild(this);\n    }\n}\nconst overlayId = 'vite-error-overlay';\nconst { customElements } = globalThis; // Ensure `customElements` is defined before the next line.\nif (customElements && !customElements.get(overlayId)) {\n    customElements.define(overlayId, ErrorOverlay);\n}\n\nconsole.debug('[vite] connecting...');\nconst importMetaUrl = new URL(import.meta.url);\n// use server configuration, then fallback to inference\nconst serverHost = __SERVER_HOST__;\nconst socketProtocol = __HMR_PROTOCOL__ || (importMetaUrl.protocol === 'https:' ? 'wss' : 'ws');\nconst hmrPort = __HMR_PORT__;\nconst socketHost = `${__HMR_HOSTNAME__ || importMetaUrl.hostname}:${hmrPort || importMetaUrl.port}${__HMR_BASE__}`;\nconst directSocketHost = __HMR_DIRECT_TARGET__;\nconst base = __BASE__ || '/';\nconst messageBuffer = [];\nlet socket;\ntry {\n    let fallback;\n    // only use fallback when port is inferred to prevent confusion\n    if (!hmrPort) {\n        fallback = () => {\n            // fallback to connecting directly to the hmr server\n            // for servers which does not support proxying websocket\n            socket = setupWebSocket(socketProtocol, directSocketHost, () => {\n                const currentScriptHostURL = new URL(import.meta.url);\n                const currentScriptHost = currentScriptHostURL.host +\n                    currentScriptHostURL.pathname.replace(/@vite\\/client$/, '');\n                console.error('[vite] failed to connect to websocket.\\n' +\n                    'your current setup:\\n' +\n                    `  (browser) ${currentScriptHost} <--[HTTP]--> ${serverHost} (server)\\n` +\n                    `  (browser) ${socketHost} <--[WebSocket (failing)]--> ${directSocketHost} (server)\\n` +\n                    'Check out your Vite / network configuration and https://vitejs.dev/config/server-options.html#server-hmr .');\n            });\n            socket.addEventListener('open', () => {\n                console.info('[vite] Direct websocket connection fallback. Check out https://vitejs.dev/config/server-options.html#server-hmr to remove the previous connection error.');\n            }, { once: true });\n        };\n    }\n    socket = setupWebSocket(socketProtocol, socketHost, fallback);\n}\ncatch (error) {\n    console.error(`[vite] failed to connect to websocket (${error}). `);\n}\nfunction setupWebSocket(protocol, hostAndPath, onCloseWithoutOpen) {\n    const socket = new WebSocket(`${protocol}://${hostAndPath}`, 'vite-hmr');\n    let isOpened = false;\n    socket.addEventListener('open', () => {\n        isOpened = true;\n    }, { once: true });\n    // Listen for messages\n    socket.addEventListener('message', async ({ data }) => {\n        handleMessage(JSON.parse(data));\n    });\n    // ping server\n    socket.addEventListener('close', async ({ wasClean }) => {\n        if (wasClean)\n            return;\n        if (!isOpened && onCloseWithoutOpen) {\n            onCloseWithoutOpen();\n            return;\n        }\n        console.log(`[vite] server connection lost. polling for restart...`);\n        await waitForSuccessfulPing(protocol, hostAndPath);\n        location.reload();\n    });\n    return socket;\n}\nfunction warnFailedFetch(err, path) {\n    if (!err.message.match('fetch')) {\n        console.error(err);\n    }\n    console.error(`[hmr] Failed to reload ${path}. ` +\n        `This could be due to syntax errors or importing non-existent ` +\n        `modules. (see errors above)`);\n}\nfunction cleanUrl(pathname) {\n    const url = new URL(pathname, location.toString());\n    url.searchParams.delete('direct');\n    return url.pathname + url.search;\n}\nlet isFirstUpdate = true;\nconst outdatedLinkTags = new WeakSet();\nasync function handleMessage(payload) {\n    switch (payload.type) {\n        case 'connected':\n            console.debug(`[vite] connected.`);\n            sendMessageBuffer();\n            // proxy(nginx, docker) hmr ws maybe caused timeout,\n            // so send ping package let ws keep alive.\n            setInterval(() => {\n                if (socket.readyState === socket.OPEN) {\n                    socket.send('{\"type\":\"ping\"}');\n                }\n            }, __HMR_TIMEOUT__);\n            break;\n        case 'update':\n            notifyListeners('vite:beforeUpdate', payload);\n            // if this is the first update and there's already an error overlay, it\n            // means the page opened with existing server compile error and the whole\n            // module script failed to load (since one of the nested imports is 500).\n            // in this case a normal update won't work and a full reload is needed.\n            if (isFirstUpdate && hasErrorOverlay()) {\n                window.location.reload();\n                return;\n            }\n            else {\n                clearErrorOverlay();\n                isFirstUpdate = false;\n            }\n            await Promise.all(payload.updates.map(async (update) => {\n                if (update.type === 'js-update') {\n                    return queueUpdate(fetchUpdate(update));\n                }\n                // css-update\n                // this is only sent when a css file referenced with <link> is updated\n                const { path, timestamp } = update;\n                const searchUrl = cleanUrl(path);\n                // can't use querySelector with `[href*=]` here since the link may be\n                // using relative paths so we need to use link.href to grab the full\n                // URL for the include check.\n                const el = Array.from(document.querySelectorAll('link')).find((e) => !outdatedLinkTags.has(e) && cleanUrl(e.href).includes(searchUrl));\n                if (!el) {\n                    return;\n                }\n                const newPath = `${base}${searchUrl.slice(1)}${searchUrl.includes('?') ? '&' : '?'}t=${timestamp}`;\n                // rather than swapping the href on the existing tag, we will\n                // create a new link tag. Once the new stylesheet has loaded we\n                // will remove the existing link tag. This removes a Flash Of\n                // Unstyled Content that can occur when swapping out the tag href\n                // directly, as the new stylesheet has not yet been loaded.\n                return new Promise((resolve) => {\n                    const newLinkTag = el.cloneNode();\n                    newLinkTag.href = new URL(newPath, el.href).href;\n                    const removeOldEl = () => {\n                        el.remove();\n                        console.debug(`[vite] css hot updated: ${searchUrl}`);\n                        resolve();\n                    };\n                    newLinkTag.addEventListener('load', removeOldEl);\n                    newLinkTag.addEventListener('error', removeOldEl);\n                    outdatedLinkTags.add(el);\n                    el.after(newLinkTag);\n                });\n            }));\n            notifyListeners('vite:afterUpdate', payload);\n            break;\n        case 'custom': {\n            notifyListeners(payload.event, payload.data);\n            break;\n        }\n        case 'full-reload':\n            notifyListeners('vite:beforeFullReload', payload);\n            if (payload.path && payload.path.endsWith('.html')) {\n                // if html file is edited, only reload the page if the browser is\n                // currently on that page.\n                const pagePath = decodeURI(location.pathname);\n                const payloadPath = base + payload.path.slice(1);\n                if (pagePath === payloadPath ||\n                    payload.path === '/index.html' ||\n                    (pagePath.endsWith('/') && pagePath + 'index.html' === payloadPath)) {\n                    location.reload();\n                }\n                return;\n            }\n            else {\n                location.reload();\n            }\n            break;\n        case 'prune':\n            notifyListeners('vite:beforePrune', payload);\n            // After an HMR update, some modules are no longer imported on the page\n            // but they may have left behind side effects that need to be cleaned up\n            // (.e.g style injections)\n            // TODO Trigger their dispose callbacks.\n            payload.paths.forEach((path) => {\n                const fn = pruneMap.get(path);\n                if (fn) {\n                    fn(dataMap.get(path));\n                }\n            });\n            break;\n        case 'error': {\n            notifyListeners('vite:error', payload);\n            const err = payload.err;\n            if (enableOverlay) {\n                createErrorOverlay(err);\n            }\n            else {\n                console.error(`[vite] Internal Server Error\\n${err.message}\\n${err.stack}`);\n            }\n            break;\n        }\n        default: {\n            const check = payload;\n            return check;\n        }\n    }\n}\nfunction notifyListeners(event, data) {\n    const cbs = customListenersMap.get(event);\n    if (cbs) {\n        cbs.forEach((cb) => cb(data));\n    }\n}\nconst enableOverlay = __HMR_ENABLE_OVERLAY__;\nfunction createErrorOverlay(err) {\n    if (!enableOverlay)\n        return;\n    clearErrorOverlay();\n    document.body.appendChild(new ErrorOverlay(err));\n}\nfunction clearErrorOverlay() {\n    document\n        .querySelectorAll(overlayId)\n        .forEach((n) => n.close());\n}\nfunction hasErrorOverlay() {\n    return document.querySelectorAll(overlayId).length;\n}\nlet pending = false;\nlet queued = [];\n/**\n * buffer multiple hot updates triggered by the same src change\n * so that they are invoked in the same order they were sent.\n * (otherwise the order may be inconsistent because of the http request round trip)\n */\nasync function queueUpdate(p) {\n    queued.push(p);\n    if (!pending) {\n        pending = true;\n        await Promise.resolve();\n        pending = false;\n        const loading = [...queued];\n        queued = [];\n        (await Promise.all(loading)).forEach((fn) => fn && fn());\n    }\n}\nasync function waitForSuccessfulPing(socketProtocol, hostAndPath, ms = 1000) {\n    const pingHostProtocol = socketProtocol === 'wss' ? 'https' : 'http';\n    // eslint-disable-next-line no-constant-condition\n    while (true) {\n        try {\n            // A fetch on a websocket URL will return a successful promise with status 400,\n            // but will reject a networking error.\n            // When running on middleware mode, it returns status 426, and an cors error happens if mode is not no-cors\n            await fetch(`${pingHostProtocol}://${hostAndPath}`, {\n                mode: 'no-cors',\n            });\n            break;\n        }\n        catch (e) {\n            // wait ms before attempting to ping again\n            await new Promise((resolve) => setTimeout(resolve, ms));\n        }\n    }\n}\nconst sheetsMap = new Map();\n// all css imports should be inserted at the same position\n// because after build it will be a single css file\nlet lastInsertedStyle;\nfunction updateStyle(id, content) {\n    let style = sheetsMap.get(id);\n    {\n        if (style && !(style instanceof HTMLStyleElement)) {\n            removeStyle(id);\n            style = undefined;\n        }\n        if (!style) {\n            style = document.createElement('style');\n            style.setAttribute('type', 'text/css');\n            style.setAttribute('data-vite-dev-id', id);\n            style.textContent = content;\n            if (!lastInsertedStyle) {\n                document.head.appendChild(style);\n                // reset lastInsertedStyle after async\n                // because dynamically imported css will be splitted into a different file\n                setTimeout(() => {\n                    lastInsertedStyle = undefined;\n                }, 0);\n            }\n            else {\n                lastInsertedStyle.insertAdjacentElement('afterend', style);\n            }\n            lastInsertedStyle = style;\n        }\n        else {\n            style.textContent = content;\n        }\n    }\n    sheetsMap.set(id, style);\n}\nfunction removeStyle(id) {\n    const style = sheetsMap.get(id);\n    if (style) {\n        if (style instanceof CSSStyleSheet) {\n            document.adoptedStyleSheets = document.adoptedStyleSheets.filter((s) => s !== style);\n        }\n        else {\n            document.head.removeChild(style);\n        }\n        sheetsMap.delete(id);\n    }\n}\nasync function fetchUpdate({ path, acceptedPath, timestamp, explicitImportRequired, }) {\n    const mod = hotModulesMap.get(path);\n    if (!mod) {\n        // In a code-splitting project,\n        // it is common that the hot-updating module is not loaded yet.\n        // https://github.com/vitejs/vite/issues/721\n        return;\n    }\n    let fetchedModule;\n    const isSelfUpdate = path === acceptedPath;\n    // determine the qualified callbacks before we re-import the modules\n    const qualifiedCallbacks = mod.callbacks.filter(({ deps }) => deps.includes(acceptedPath));\n    if (isSelfUpdate || qualifiedCallbacks.length > 0) {\n        const disposer = disposeMap.get(acceptedPath);\n        if (disposer)\n            await disposer(dataMap.get(acceptedPath));\n        const [acceptedPathWithoutQuery, query] = acceptedPath.split(`?`);\n        try {\n            fetchedModule = await import(\n            /* @vite-ignore */\n            base +\n                acceptedPathWithoutQuery.slice(1) +\n                `?${explicitImportRequired ? 'import&' : ''}t=${timestamp}${query ? `&${query}` : ''}`);\n        }\n        catch (e) {\n            warnFailedFetch(e, acceptedPath);\n        }\n    }\n    return () => {\n        for (const { deps, fn } of qualifiedCallbacks) {\n            fn(deps.map((dep) => (dep === acceptedPath ? fetchedModule : undefined)));\n        }\n        const loggedPath = isSelfUpdate ? path : `${acceptedPath} via ${path}`;\n        console.debug(`[vite] hot updated: ${loggedPath}`);\n    };\n}\nfunction sendMessageBuffer() {\n    if (socket.readyState === 1) {\n        messageBuffer.forEach((msg) => socket.send(msg));\n        messageBuffer.length = 0;\n    }\n}\nconst hotModulesMap = new Map();\nconst disposeMap = new Map();\nconst pruneMap = new Map();\nconst dataMap = new Map();\nconst customListenersMap = new Map();\nconst ctxToListenersMap = new Map();\nfunction createHotContext(ownerPath) {\n    if (!dataMap.has(ownerPath)) {\n        dataMap.set(ownerPath, {});\n    }\n    // when a file is hot updated, a new context is created\n    // clear its stale callbacks\n    const mod = hotModulesMap.get(ownerPath);\n    if (mod) {\n        mod.callbacks = [];\n    }\n    // clear stale custom event listeners\n    const staleListeners = ctxToListenersMap.get(ownerPath);\n    if (staleListeners) {\n        for (const [event, staleFns] of staleListeners) {\n            const listeners = customListenersMap.get(event);\n            if (listeners) {\n                customListenersMap.set(event, listeners.filter((l) => !staleFns.includes(l)));\n            }\n        }\n    }\n    const newListeners = new Map();\n    ctxToListenersMap.set(ownerPath, newListeners);\n    function acceptDeps(deps, callback = () => { }) {\n        const mod = hotModulesMap.get(ownerPath) || {\n            id: ownerPath,\n            callbacks: [],\n        };\n        mod.callbacks.push({\n            deps,\n            fn: callback,\n        });\n        hotModulesMap.set(ownerPath, mod);\n    }\n    const hot = {\n        get data() {\n            return dataMap.get(ownerPath);\n        },\n        accept(deps, callback) {\n            if (typeof deps === 'function' || !deps) {\n                // self-accept: hot.accept(() => {})\n                acceptDeps([ownerPath], ([mod]) => deps === null || deps === void 0 ? void 0 : deps(mod));\n            }\n            else if (typeof deps === 'string') {\n                // explicit deps\n                acceptDeps([deps], ([mod]) => callback === null || callback === void 0 ? void 0 : callback(mod));\n            }\n            else if (Array.isArray(deps)) {\n                acceptDeps(deps, callback);\n            }\n            else {\n                throw new Error(`invalid hot.accept() usage.`);\n            }\n        },\n        // export names (first arg) are irrelevant on the client side, they're\n        // extracted in the server for propagation\n        acceptExports(_, callback) {\n            acceptDeps([ownerPath], ([mod]) => callback === null || callback === void 0 ? void 0 : callback(mod));\n        },\n        dispose(cb) {\n            disposeMap.set(ownerPath, cb);\n        },\n        prune(cb) {\n            pruneMap.set(ownerPath, cb);\n        },\n        // Kept for backward compatibility (#11036)\n        // @ts-expect-error untyped\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        decline() { },\n        // tell the server to re-perform hmr propagation from this module as root\n        invalidate(message) {\n            notifyListeners('vite:invalidate', { path: ownerPath, message });\n            this.send('vite:invalidate', { path: ownerPath, message });\n            console.debug(`[vite] invalidate ${ownerPath}${message ? `: ${message}` : ''}`);\n        },\n        // custom events\n        on(event, cb) {\n            const addToMap = (map) => {\n                const existing = map.get(event) || [];\n                existing.push(cb);\n                map.set(event, existing);\n            };\n            addToMap(customListenersMap);\n            addToMap(newListeners);\n        },\n        send(event, data) {\n            messageBuffer.push(JSON.stringify({ type: 'custom', event, data }));\n            sendMessageBuffer();\n        },\n    };\n    return hot;\n}\n/**\n * urls here are dynamic import() urls that couldn't be statically analyzed\n */\nfunction injectQuery(url, queryToInject) {\n    // skip urls that won't be handled by vite\n    if (!url.startsWith('.') && !url.startsWith('/')) {\n        return url;\n    }\n    // can't use pathname from URL since it may be relative like ../\n    const pathname = url.replace(/#.*$/, '').replace(/\\?.*$/, '');\n    const { search, hash } = new URL(url, 'http://vitejs.dev');\n    return `${pathname}?${queryToInject}${search ? `&` + search.slice(1) : ''}${hash || ''}`;\n}\n\nexport { ErrorOverlay, createHotContext, injectQuery, removeStyle, updateStyle };\n//# sourceMappingURL=client.mjs.map\n"}},"client.mjs.map":{"file":{"contents":"{\"version\":3,\"file\":\"client.mjs\",\"sources\":[\"overlay.ts\",\"client.ts\"],\"sourcesContent\":[\"import type { ErrorPayload } from 'types/hmrPayload'\\n\\n// injected by the hmr plugin when served\\ndeclare const __BASE__: string\\n\\nconst base = __BASE__ || '/'\\n\\n// set :host styles to make playwright detect the element as visible\\nconst template = /*html*/ `\\n<style>\\n:host {\\n  position: fixed;\\n  top: 0;\\n  left: 0;\\n  width: 100%;\\n  height: 100%;\\n  z-index: 99999;\\n  --monospace: 'SFMono-Regular', Consolas,\\n  'Liberation Mono', Menlo, Courier, monospace;\\n  --red: #ff5555;\\n  --yellow: #e2aa53;\\n  --purple: #cfa4ff;\\n  --cyan: #2dd9da;\\n  --dim: #c9c9c9;\\n\\n  --window-background: #181818;\\n  --window-color: #d8d8d8;\\n}\\n\\n.backdrop {\\n  position: fixed;\\n  z-index: 99999;\\n  top: 0;\\n  left: 0;\\n  width: 100%;\\n  height: 100%;\\n  overflow-y: scroll;\\n  margin: 0;\\n  background: rgba(0, 0, 0, 0.66);\\n}\\n\\n.window {\\n  font-family: var(--monospace);\\n  line-height: 1.5;\\n  width: 800px;\\n  color: var(--window-color);\\n  margin: 30px auto;\\n  padding: 25px 40px;\\n  position: relative;\\n  background: var(--window-background);\\n  border-radius: 6px 6px 8px 8px;\\n  box-shadow: 0 19px 38px rgba(0,0,0,0.30), 0 15px 12px rgba(0,0,0,0.22);\\n  overflow: hidden;\\n  border-top: 8px solid var(--red);\\n  direction: ltr;\\n  text-align: left;\\n}\\n\\npre {\\n  font-family: var(--monospace);\\n  font-size: 16px;\\n  margin-top: 0;\\n  margin-bottom: 1em;\\n  overflow-x: scroll;\\n  scrollbar-width: none;\\n}\\n\\npre::-webkit-scrollbar {\\n  display: none;\\n}\\n\\n.message {\\n  line-height: 1.3;\\n  font-weight: 600;\\n  white-space: pre-wrap;\\n}\\n\\n.message-body {\\n  color: var(--red);\\n}\\n\\n.plugin {\\n  color: var(--purple);\\n}\\n\\n.file {\\n  color: var(--cyan);\\n  margin-bottom: 0;\\n  white-space: pre-wrap;\\n  word-break: break-all;\\n}\\n\\n.frame {\\n  color: var(--yellow);\\n}\\n\\n.stack {\\n  font-size: 13px;\\n  color: var(--dim);\\n}\\n\\n.tip {\\n  font-size: 13px;\\n  color: #999;\\n  border-top: 1px dotted #999;\\n  padding-top: 13px;\\n}\\n\\ncode {\\n  font-size: 13px;\\n  font-family: var(--monospace);\\n  color: var(--yellow);\\n}\\n\\n.file-link {\\n  text-decoration: underline;\\n  cursor: pointer;\\n}\\n</style>\\n<div class=\\\"backdrop\\\" part=\\\"backdrop\\\">\\n  <div class=\\\"window\\\" part=\\\"window\\\">\\n    <pre class=\\\"message\\\" part=\\\"message\\\"><span class=\\\"plugin\\\"></span><span class=\\\"message-body\\\"></span></pre>\\n    <pre class=\\\"file\\\" part=\\\"file\\\"></pre>\\n    <pre class=\\\"frame\\\" part=\\\"frame\\\"></pre>\\n    <pre class=\\\"stack\\\" part=\\\"stack\\\"></pre>\\n    <div class=\\\"tip\\\" part=\\\"tip\\\">\\n      Click outside or fix the code to dismiss.<br>\\n      You can also disable this overlay by setting\\n      <code>server.hmr.overlay</code> to <code>false</code> in <code>vite.config.js.</code>\\n    </div>\\n  </div>\\n</div>\\n`\\n\\nconst fileRE = /(?:[a-zA-Z]:\\\\\\\\|\\\\/).*?:\\\\d+:\\\\d+/g\\nconst codeframeRE = /^(?:>?\\\\s+\\\\d+\\\\s+\\\\|.*|\\\\s+\\\\|\\\\s*\\\\^.*)\\\\r?\\\\n/gm\\n\\n// Allow `ErrorOverlay` to extend `HTMLElement` even in environments where\\n// `HTMLElement` was not originally defined.\\nconst { HTMLElement = class {} as typeof globalThis.HTMLElement } = globalThis\\nexport class ErrorOverlay extends HTMLElement {\\n  root: ShadowRoot\\n\\n  constructor(err: ErrorPayload['err'], links = true) {\\n    super()\\n    this.root = this.attachShadow({ mode: 'open' })\\n    this.root.innerHTML = template\\n\\n    codeframeRE.lastIndex = 0\\n    const hasFrame = err.frame && codeframeRE.test(err.frame)\\n    const message = hasFrame\\n      ? err.message.replace(codeframeRE, '')\\n      : err.message\\n    if (err.plugin) {\\n      this.text('.plugin', `[plugin:${err.plugin}] `)\\n    }\\n    this.text('.message-body', message.trim())\\n\\n    const [file] = (err.loc?.file || err.id || 'unknown file').split(`?`)\\n    if (err.loc) {\\n      this.text('.file', `${file}:${err.loc.line}:${err.loc.column}`, links)\\n    } else if (err.id) {\\n      this.text('.file', file)\\n    }\\n\\n    if (hasFrame) {\\n      this.text('.frame', err.frame!.trim())\\n    }\\n    this.text('.stack', err.stack, links)\\n\\n    this.root.querySelector('.window')!.addEventListener('click', (e) => {\\n      e.stopPropagation()\\n    })\\n    this.addEventListener('click', () => {\\n      this.close()\\n    })\\n  }\\n\\n  text(selector: string, text: string, linkFiles = false): void {\\n    const el = this.root.querySelector(selector)!\\n    if (!linkFiles) {\\n      el.textContent = text\\n    } else {\\n      let curIndex = 0\\n      let match: RegExpExecArray | null\\n      fileRE.lastIndex = 0\\n      while ((match = fileRE.exec(text))) {\\n        const { 0: file, index } = match\\n        if (index != null) {\\n          const frag = text.slice(curIndex, index)\\n          el.appendChild(document.createTextNode(frag))\\n          const link = document.createElement('a')\\n          link.textContent = file\\n          link.className = 'file-link'\\n          link.onclick = () => {\\n            fetch(`${base}__open-in-editor?file=` + encodeURIComponent(file))\\n          }\\n          el.appendChild(link)\\n          curIndex += frag.length + file.length\\n        }\\n      }\\n    }\\n  }\\n\\n  close(): void {\\n    this.parentNode?.removeChild(this)\\n  }\\n}\\n\\nexport const overlayId = 'vite-error-overlay'\\nconst { customElements } = globalThis // Ensure `customElements` is defined before the next line.\\nif (customElements && !customElements.get(overlayId)) {\\n  customElements.define(overlayId, ErrorOverlay)\\n}\\n\",\"import type { ErrorPayload, HMRPayload, Update } from 'types/hmrPayload'\\nimport type { ModuleNamespace, ViteHotContext } from 'types/hot'\\nimport type { InferCustomEventPayload } from 'types/customEvent'\\nimport { ErrorOverlay, overlayId } from './overlay'\\n// eslint-disable-next-line node/no-missing-import\\nimport '@vite/env'\\n\\n// injected by the hmr plugin when served\\ndeclare const __BASE__: string\\ndeclare const __SERVER_HOST__: string\\ndeclare const __HMR_PROTOCOL__: string | null\\ndeclare const __HMR_HOSTNAME__: string | null\\ndeclare const __HMR_PORT__: number | null\\ndeclare const __HMR_DIRECT_TARGET__: string\\ndeclare const __HMR_BASE__: string\\ndeclare const __HMR_TIMEOUT__: number\\ndeclare const __HMR_ENABLE_OVERLAY__: boolean\\n\\nconsole.debug('[vite] connecting...')\\n\\nconst importMetaUrl = new URL(import.meta.url)\\n\\n// use server configuration, then fallback to inference\\nconst serverHost = __SERVER_HOST__\\nconst socketProtocol =\\n  __HMR_PROTOCOL__ || (importMetaUrl.protocol === 'https:' ? 'wss' : 'ws')\\nconst hmrPort = __HMR_PORT__\\nconst socketHost = `${__HMR_HOSTNAME__ || importMetaUrl.hostname}:${\\n  hmrPort || importMetaUrl.port\\n}${__HMR_BASE__}`\\nconst directSocketHost = __HMR_DIRECT_TARGET__\\nconst base = __BASE__ || '/'\\nconst messageBuffer: string[] = []\\n\\nlet socket: WebSocket\\ntry {\\n  let fallback: (() => void) | undefined\\n  // only use fallback when port is inferred to prevent confusion\\n  if (!hmrPort) {\\n    fallback = () => {\\n      // fallback to connecting directly to the hmr server\\n      // for servers which does not support proxying websocket\\n      socket = setupWebSocket(socketProtocol, directSocketHost, () => {\\n        const currentScriptHostURL = new URL(import.meta.url)\\n        const currentScriptHost =\\n          currentScriptHostURL.host +\\n          currentScriptHostURL.pathname.replace(/@vite\\\\/client$/, '')\\n        console.error(\\n          '[vite] failed to connect to websocket.\\\\n' +\\n            'your current setup:\\\\n' +\\n            `  (browser) ${currentScriptHost} <--[HTTP]--> ${serverHost} (server)\\\\n` +\\n            `  (browser) ${socketHost} <--[WebSocket (failing)]--> ${directSocketHost} (server)\\\\n` +\\n            'Check out your Vite / network configuration and https://vitejs.dev/config/server-options.html#server-hmr .',\\n        )\\n      })\\n      socket.addEventListener(\\n        'open',\\n        () => {\\n          console.info(\\n            '[vite] Direct websocket connection fallback. Check out https://vitejs.dev/config/server-options.html#server-hmr to remove the previous connection error.',\\n          )\\n        },\\n        { once: true },\\n      )\\n    }\\n  }\\n\\n  socket = setupWebSocket(socketProtocol, socketHost, fallback)\\n} catch (error) {\\n  console.error(`[vite] failed to connect to websocket (${error}). `)\\n}\\n\\nfunction setupWebSocket(\\n  protocol: string,\\n  hostAndPath: string,\\n  onCloseWithoutOpen?: () => void,\\n) {\\n  const socket = new WebSocket(`${protocol}://${hostAndPath}`, 'vite-hmr')\\n  let isOpened = false\\n\\n  socket.addEventListener(\\n    'open',\\n    () => {\\n      isOpened = true\\n    },\\n    { once: true },\\n  )\\n\\n  // Listen for messages\\n  socket.addEventListener('message', async ({ data }) => {\\n    handleMessage(JSON.parse(data))\\n  })\\n\\n  // ping server\\n  socket.addEventListener('close', async ({ wasClean }) => {\\n    if (wasClean) return\\n\\n    if (!isOpened && onCloseWithoutOpen) {\\n      onCloseWithoutOpen()\\n      return\\n    }\\n\\n    console.log(`[vite] server connection lost. polling for restart...`)\\n    await waitForSuccessfulPing(protocol, hostAndPath)\\n    location.reload()\\n  })\\n\\n  return socket\\n}\\n\\nfunction warnFailedFetch(err: Error, path: string | string[]) {\\n  if (!err.message.match('fetch')) {\\n    console.error(err)\\n  }\\n  console.error(\\n    `[hmr] Failed to reload ${path}. ` +\\n      `This could be due to syntax errors or importing non-existent ` +\\n      `modules. (see errors above)`,\\n  )\\n}\\n\\nfunction cleanUrl(pathname: string): string {\\n  const url = new URL(pathname, location.toString())\\n  url.searchParams.delete('direct')\\n  return url.pathname + url.search\\n}\\n\\nlet isFirstUpdate = true\\nconst outdatedLinkTags = new WeakSet<HTMLLinkElement>()\\n\\nasync function handleMessage(payload: HMRPayload) {\\n  switch (payload.type) {\\n    case 'connected':\\n      console.debug(`[vite] connected.`)\\n      sendMessageBuffer()\\n      // proxy(nginx, docker) hmr ws maybe caused timeout,\\n      // so send ping package let ws keep alive.\\n      setInterval(() => {\\n        if (socket.readyState === socket.OPEN) {\\n          socket.send('{\\\"type\\\":\\\"ping\\\"}')\\n        }\\n      }, __HMR_TIMEOUT__)\\n      break\\n    case 'update':\\n      notifyListeners('vite:beforeUpdate', payload)\\n      // if this is the first update and there's already an error overlay, it\\n      // means the page opened with existing server compile error and the whole\\n      // module script failed to load (since one of the nested imports is 500).\\n      // in this case a normal update won't work and a full reload is needed.\\n      if (isFirstUpdate && hasErrorOverlay()) {\\n        window.location.reload()\\n        return\\n      } else {\\n        clearErrorOverlay()\\n        isFirstUpdate = false\\n      }\\n      await Promise.all(\\n        payload.updates.map(async (update): Promise<void> => {\\n          if (update.type === 'js-update') {\\n            return queueUpdate(fetchUpdate(update))\\n          }\\n\\n          // css-update\\n          // this is only sent when a css file referenced with <link> is updated\\n          const { path, timestamp } = update\\n          const searchUrl = cleanUrl(path)\\n          // can't use querySelector with `[href*=]` here since the link may be\\n          // using relative paths so we need to use link.href to grab the full\\n          // URL for the include check.\\n          const el = Array.from(\\n            document.querySelectorAll<HTMLLinkElement>('link'),\\n          ).find(\\n            (e) =>\\n              !outdatedLinkTags.has(e) && cleanUrl(e.href).includes(searchUrl),\\n          )\\n\\n          if (!el) {\\n            return\\n          }\\n\\n          const newPath = `${base}${searchUrl.slice(1)}${\\n            searchUrl.includes('?') ? '&' : '?'\\n          }t=${timestamp}`\\n\\n          // rather than swapping the href on the existing tag, we will\\n          // create a new link tag. Once the new stylesheet has loaded we\\n          // will remove the existing link tag. This removes a Flash Of\\n          // Unstyled Content that can occur when swapping out the tag href\\n          // directly, as the new stylesheet has not yet been loaded.\\n          return new Promise((resolve) => {\\n            const newLinkTag = el.cloneNode() as HTMLLinkElement\\n            newLinkTag.href = new URL(newPath, el.href).href\\n            const removeOldEl = () => {\\n              el.remove()\\n              console.debug(`[vite] css hot updated: ${searchUrl}`)\\n              resolve()\\n            }\\n            newLinkTag.addEventListener('load', removeOldEl)\\n            newLinkTag.addEventListener('error', removeOldEl)\\n            outdatedLinkTags.add(el)\\n            el.after(newLinkTag)\\n          })\\n        }),\\n      )\\n      notifyListeners('vite:afterUpdate', payload)\\n      break\\n    case 'custom': {\\n      notifyListeners(payload.event, payload.data)\\n      break\\n    }\\n    case 'full-reload':\\n      notifyListeners('vite:beforeFullReload', payload)\\n      if (payload.path && payload.path.endsWith('.html')) {\\n        // if html file is edited, only reload the page if the browser is\\n        // currently on that page.\\n        const pagePath = decodeURI(location.pathname)\\n        const payloadPath = base + payload.path.slice(1)\\n        if (\\n          pagePath === payloadPath ||\\n          payload.path === '/index.html' ||\\n          (pagePath.endsWith('/') && pagePath + 'index.html' === payloadPath)\\n        ) {\\n          location.reload()\\n        }\\n        return\\n      } else {\\n        location.reload()\\n      }\\n      break\\n    case 'prune':\\n      notifyListeners('vite:beforePrune', payload)\\n      // After an HMR update, some modules are no longer imported on the page\\n      // but they may have left behind side effects that need to be cleaned up\\n      // (.e.g style injections)\\n      // TODO Trigger their dispose callbacks.\\n      payload.paths.forEach((path) => {\\n        const fn = pruneMap.get(path)\\n        if (fn) {\\n          fn(dataMap.get(path))\\n        }\\n      })\\n      break\\n    case 'error': {\\n      notifyListeners('vite:error', payload)\\n      const err = payload.err\\n      if (enableOverlay) {\\n        createErrorOverlay(err)\\n      } else {\\n        console.error(\\n          `[vite] Internal Server Error\\\\n${err.message}\\\\n${err.stack}`,\\n        )\\n      }\\n      break\\n    }\\n    default: {\\n      const check: never = payload\\n      return check\\n    }\\n  }\\n}\\n\\nfunction notifyListeners<T extends string>(\\n  event: T,\\n  data: InferCustomEventPayload<T>,\\n): void\\nfunction notifyListeners(event: string, data: any): void {\\n  const cbs = customListenersMap.get(event)\\n  if (cbs) {\\n    cbs.forEach((cb) => cb(data))\\n  }\\n}\\n\\nconst enableOverlay = __HMR_ENABLE_OVERLAY__\\n\\nfunction createErrorOverlay(err: ErrorPayload['err']) {\\n  if (!enableOverlay) return\\n  clearErrorOverlay()\\n  document.body.appendChild(new ErrorOverlay(err))\\n}\\n\\nfunction clearErrorOverlay() {\\n  document\\n    .querySelectorAll(overlayId)\\n    .forEach((n) => (n as ErrorOverlay).close())\\n}\\n\\nfunction hasErrorOverlay() {\\n  return document.querySelectorAll(overlayId).length\\n}\\n\\nlet pending = false\\nlet queued: Promise<(() => void) | undefined>[] = []\\n\\n/**\\n * buffer multiple hot updates triggered by the same src change\\n * so that they are invoked in the same order they were sent.\\n * (otherwise the order may be inconsistent because of the http request round trip)\\n */\\nasync function queueUpdate(p: Promise<(() => void) | undefined>) {\\n  queued.push(p)\\n  if (!pending) {\\n    pending = true\\n    await Promise.resolve()\\n    pending = false\\n    const loading = [...queued]\\n    queued = []\\n    ;(await Promise.all(loading)).forEach((fn) => fn && fn())\\n  }\\n}\\n\\nasync function waitForSuccessfulPing(\\n  socketProtocol: string,\\n  hostAndPath: string,\\n  ms = 1000,\\n) {\\n  const pingHostProtocol = socketProtocol === 'wss' ? 'https' : 'http'\\n\\n  // eslint-disable-next-line no-constant-condition\\n  while (true) {\\n    try {\\n      // A fetch on a websocket URL will return a successful promise with status 400,\\n      // but will reject a networking error.\\n      // When running on middleware mode, it returns status 426, and an cors error happens if mode is not no-cors\\n      await fetch(`${pingHostProtocol}://${hostAndPath}`, {\\n        mode: 'no-cors',\\n      })\\n      break\\n    } catch (e) {\\n      // wait ms before attempting to ping again\\n      await new Promise((resolve) => setTimeout(resolve, ms))\\n    }\\n  }\\n}\\n\\n// https://wicg.github.io/construct-stylesheets\\nconst supportsConstructedSheet = (() => {\\n  // TODO: re-enable this try block once Chrome fixes the performance of\\n  // rule insertion in really big stylesheets\\n  // try {\\n  //   new CSSStyleSheet()\\n  //   return true\\n  // } catch (e) {}\\n  return false\\n})()\\n\\nconst sheetsMap = new Map<\\n  string,\\n  HTMLStyleElement | CSSStyleSheet | undefined\\n>()\\n// all css imports should be inserted at the same position\\n// because after build it will be a single css file\\nlet lastInsertedStyle: HTMLStyleElement | undefined\\n\\nexport function updateStyle(id: string, content: string): void {\\n  let style = sheetsMap.get(id)\\n  if (supportsConstructedSheet && !content.includes('@import')) {\\n    if (style && !(style instanceof CSSStyleSheet)) {\\n      removeStyle(id)\\n      style = undefined\\n    }\\n\\n    if (!style) {\\n      style = new CSSStyleSheet()\\n      style.replaceSync(content)\\n      document.adoptedStyleSheets = [...document.adoptedStyleSheets, style]\\n    } else {\\n      style.replaceSync(content)\\n    }\\n  } else {\\n    if (style && !(style instanceof HTMLStyleElement)) {\\n      removeStyle(id)\\n      style = undefined\\n    }\\n\\n    if (!style) {\\n      style = document.createElement('style')\\n      style.setAttribute('type', 'text/css')\\n      style.setAttribute('data-vite-dev-id', id)\\n      style.textContent = content\\n\\n      if (!lastInsertedStyle) {\\n        document.head.appendChild(style)\\n\\n        // reset lastInsertedStyle after async\\n        // because dynamically imported css will be splitted into a different file\\n        setTimeout(() => {\\n          lastInsertedStyle = undefined\\n        }, 0)\\n      } else {\\n        lastInsertedStyle.insertAdjacentElement('afterend', style)\\n      }\\n      lastInsertedStyle = style\\n    } else {\\n      style.textContent = content\\n    }\\n  }\\n  sheetsMap.set(id, style)\\n}\\n\\nexport function removeStyle(id: string): void {\\n  const style = sheetsMap.get(id)\\n  if (style) {\\n    if (style instanceof CSSStyleSheet) {\\n      document.adoptedStyleSheets = document.adoptedStyleSheets.filter(\\n        (s: CSSStyleSheet) => s !== style,\\n      )\\n    } else {\\n      document.head.removeChild(style)\\n    }\\n    sheetsMap.delete(id)\\n  }\\n}\\n\\nasync function fetchUpdate({\\n  path,\\n  acceptedPath,\\n  timestamp,\\n  explicitImportRequired,\\n}: Update) {\\n  const mod = hotModulesMap.get(path)\\n  if (!mod) {\\n    // In a code-splitting project,\\n    // it is common that the hot-updating module is not loaded yet.\\n    // https://github.com/vitejs/vite/issues/721\\n    return\\n  }\\n\\n  let fetchedModule: ModuleNamespace | undefined\\n  const isSelfUpdate = path === acceptedPath\\n\\n  // determine the qualified callbacks before we re-import the modules\\n  const qualifiedCallbacks = mod.callbacks.filter(({ deps }) =>\\n    deps.includes(acceptedPath),\\n  )\\n\\n  if (isSelfUpdate || qualifiedCallbacks.length > 0) {\\n    const disposer = disposeMap.get(acceptedPath)\\n    if (disposer) await disposer(dataMap.get(acceptedPath))\\n    const [acceptedPathWithoutQuery, query] = acceptedPath.split(`?`)\\n    try {\\n      fetchedModule = await import(\\n        /* @vite-ignore */\\n        base +\\n          acceptedPathWithoutQuery.slice(1) +\\n          `?${explicitImportRequired ? 'import&' : ''}t=${timestamp}${\\n            query ? `&${query}` : ''\\n          }`\\n      )\\n    } catch (e) {\\n      warnFailedFetch(e, acceptedPath)\\n    }\\n  }\\n\\n  return () => {\\n    for (const { deps, fn } of qualifiedCallbacks) {\\n      fn(deps.map((dep) => (dep === acceptedPath ? fetchedModule : undefined)))\\n    }\\n    const loggedPath = isSelfUpdate ? path : `${acceptedPath} via ${path}`\\n    console.debug(`[vite] hot updated: ${loggedPath}`)\\n  }\\n}\\n\\nfunction sendMessageBuffer() {\\n  if (socket.readyState === 1) {\\n    messageBuffer.forEach((msg) => socket.send(msg))\\n    messageBuffer.length = 0\\n  }\\n}\\n\\ninterface HotModule {\\n  id: string\\n  callbacks: HotCallback[]\\n}\\n\\ninterface HotCallback {\\n  // the dependencies must be fetchable paths\\n  deps: string[]\\n  fn: (modules: Array<ModuleNamespace | undefined>) => void\\n}\\n\\ntype CustomListenersMap = Map<string, ((data: any) => void)[]>\\n\\nconst hotModulesMap = new Map<string, HotModule>()\\nconst disposeMap = new Map<string, (data: any) => void | Promise<void>>()\\nconst pruneMap = new Map<string, (data: any) => void | Promise<void>>()\\nconst dataMap = new Map<string, any>()\\nconst customListenersMap: CustomListenersMap = new Map()\\nconst ctxToListenersMap = new Map<string, CustomListenersMap>()\\n\\nexport function createHotContext(ownerPath: string): ViteHotContext {\\n  if (!dataMap.has(ownerPath)) {\\n    dataMap.set(ownerPath, {})\\n  }\\n\\n  // when a file is hot updated, a new context is created\\n  // clear its stale callbacks\\n  const mod = hotModulesMap.get(ownerPath)\\n  if (mod) {\\n    mod.callbacks = []\\n  }\\n\\n  // clear stale custom event listeners\\n  const staleListeners = ctxToListenersMap.get(ownerPath)\\n  if (staleListeners) {\\n    for (const [event, staleFns] of staleListeners) {\\n      const listeners = customListenersMap.get(event)\\n      if (listeners) {\\n        customListenersMap.set(\\n          event,\\n          listeners.filter((l) => !staleFns.includes(l)),\\n        )\\n      }\\n    }\\n  }\\n\\n  const newListeners: CustomListenersMap = new Map()\\n  ctxToListenersMap.set(ownerPath, newListeners)\\n\\n  function acceptDeps(deps: string[], callback: HotCallback['fn'] = () => {}) {\\n    const mod: HotModule = hotModulesMap.get(ownerPath) || {\\n      id: ownerPath,\\n      callbacks: [],\\n    }\\n    mod.callbacks.push({\\n      deps,\\n      fn: callback,\\n    })\\n    hotModulesMap.set(ownerPath, mod)\\n  }\\n\\n  const hot: ViteHotContext = {\\n    get data() {\\n      return dataMap.get(ownerPath)\\n    },\\n\\n    accept(deps?: any, callback?: any) {\\n      if (typeof deps === 'function' || !deps) {\\n        // self-accept: hot.accept(() => {})\\n        acceptDeps([ownerPath], ([mod]) => deps?.(mod))\\n      } else if (typeof deps === 'string') {\\n        // explicit deps\\n        acceptDeps([deps], ([mod]) => callback?.(mod))\\n      } else if (Array.isArray(deps)) {\\n        acceptDeps(deps, callback)\\n      } else {\\n        throw new Error(`invalid hot.accept() usage.`)\\n      }\\n    },\\n\\n    // export names (first arg) are irrelevant on the client side, they're\\n    // extracted in the server for propagation\\n    acceptExports(_, callback) {\\n      acceptDeps([ownerPath], ([mod]) => callback?.(mod))\\n    },\\n\\n    dispose(cb) {\\n      disposeMap.set(ownerPath, cb)\\n    },\\n\\n    prune(cb) {\\n      pruneMap.set(ownerPath, cb)\\n    },\\n\\n    // Kept for backward compatibility (#11036)\\n    // @ts-expect-error untyped\\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\\n    decline() {},\\n\\n    // tell the server to re-perform hmr propagation from this module as root\\n    invalidate(message) {\\n      notifyListeners('vite:invalidate', { path: ownerPath, message })\\n      this.send('vite:invalidate', { path: ownerPath, message })\\n      console.debug(\\n        `[vite] invalidate ${ownerPath}${message ? `: ${message}` : ''}`,\\n      )\\n    },\\n\\n    // custom events\\n    on(event, cb) {\\n      const addToMap = (map: Map<string, any[]>) => {\\n        const existing = map.get(event) || []\\n        existing.push(cb)\\n        map.set(event, existing)\\n      }\\n      addToMap(customListenersMap)\\n      addToMap(newListeners)\\n    },\\n\\n    send(event, data) {\\n      messageBuffer.push(JSON.stringify({ type: 'custom', event, data }))\\n      sendMessageBuffer()\\n    },\\n  }\\n\\n  return hot\\n}\\n\\n/**\\n * urls here are dynamic import() urls that couldn't be statically analyzed\\n */\\nexport function injectQuery(url: string, queryToInject: string): string {\\n  // skip urls that won't be handled by vite\\n  if (!url.startsWith('.') && !url.startsWith('/')) {\\n    return url\\n  }\\n\\n  // can't use pathname from URL since it may be relative like ../\\n  const pathname = url.replace(/#.*$/, '').replace(/\\\\?.*$/, '')\\n  const { search, hash } = new URL(url, 'http://vitejs.dev')\\n\\n  return `${pathname}?${queryToInject}${search ? `&` + search.slice(1) : ''}${\\n    hash || ''\\n  }`\\n}\\n\\nexport { ErrorOverlay }\\n\"],\"names\":[\"base\"],\"mappings\":\";;AAKA,MAAMA,MAAI,GAAG,QAAQ,IAAI,GAAG,CAAA;AAE5B;AACA,MAAM,QAAQ,YAAY,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CA4HzB,CAAA;AAED,MAAM,MAAM,GAAG,gCAAgC,CAAA;AAC/C,MAAM,WAAW,GAAG,0CAA0C,CAAA;AAE9D;AACA;AACA,MAAM,EAAE,WAAW,GAAG,MAAA;CAAyC,EAAE,GAAG,UAAU,CAAA;AACxE,MAAO,YAAa,SAAQ,WAAW,CAAA;AAG3C,IAAA,WAAA,CAAY,GAAwB,EAAE,KAAK,GAAG,IAAI,EAAA;;AAChD,QAAA,KAAK,EAAE,CAAA;AACP,QAAA,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,YAAY,CAAC,EAAE,IAAI,EAAE,MAAM,EAAE,CAAC,CAAA;AAC/C,QAAA,IAAI,CAAC,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAA;AAE9B,QAAA,WAAW,CAAC,SAAS,GAAG,CAAC,CAAA;AACzB,QAAA,MAAM,QAAQ,GAAG,GAAG,CAAC,KAAK,IAAI,WAAW,CAAC,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAA;QACzD,MAAM,OAAO,GAAG,QAAQ;cACpB,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,WAAW,EAAE,EAAE,CAAC;AACtC,cAAE,GAAG,CAAC,OAAO,CAAA;QACf,IAAI,GAAG,CAAC,MAAM,EAAE;YACd,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAW,QAAA,EAAA,GAAG,CAAC,MAAM,CAAI,EAAA,CAAA,CAAC,CAAA;AAChD,SAAA;QACD,IAAI,CAAC,IAAI,CAAC,eAAe,EAAE,OAAO,CAAC,IAAI,EAAE,CAAC,CAAA;QAE1C,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,EAAA,GAAA,GAAG,CAAC,GAAG,MAAE,IAAA,IAAA,EAAA,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAA,EAAA,CAAA,IAAI,KAAI,GAAG,CAAC,EAAE,IAAI,cAAc,EAAE,KAAK,CAAC,CAAG,CAAA,CAAA,CAAC,CAAA;QACrE,IAAI,GAAG,CAAC,GAAG,EAAE;YACX,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CAAG,EAAA,IAAI,CAAI,CAAA,EAAA,GAAG,CAAC,GAAG,CAAC,IAAI,CAAA,CAAA,EAAI,GAAG,CAAC,GAAG,CAAC,MAAM,CAAE,CAAA,EAAE,KAAK,CAAC,CAAA;AACvE,SAAA;aAAM,IAAI,GAAG,CAAC,EAAE,EAAE;AACjB,YAAA,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,CAAA;AACzB,SAAA;AAED,QAAA,IAAI,QAAQ,EAAE;AACZ,YAAA,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,GAAG,CAAC,KAAM,CAAC,IAAI,EAAE,CAAC,CAAA;AACvC,SAAA;QACD,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,GAAG,CAAC,KAAK,EAAE,KAAK,CAAC,CAAA;AAErC,QAAA,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,SAAS,CAAE,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,KAAI;YAClE,CAAC,CAAC,eAAe,EAAE,CAAA;AACrB,SAAC,CAAC,CAAA;AACF,QAAA,IAAI,CAAC,gBAAgB,CAAC,OAAO,EAAE,MAAK;YAClC,IAAI,CAAC,KAAK,EAAE,CAAA;AACd,SAAC,CAAC,CAAA;KACH;AAED,IAAA,IAAI,CAAC,QAAgB,EAAE,IAAY,EAAE,SAAS,GAAG,KAAK,EAAA;QACpD,MAAM,EAAE,GAAG,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAE,CAAA;QAC7C,IAAI,CAAC,SAAS,EAAE;AACd,YAAA,EAAE,CAAC,WAAW,GAAG,IAAI,CAAA;AACtB,SAAA;AAAM,aAAA;YACL,IAAI,QAAQ,GAAG,CAAC,CAAA;AAChB,YAAA,IAAI,KAA6B,CAAA;AACjC,YAAA,MAAM,CAAC,SAAS,GAAG,CAAC,CAAA;YACpB,QAAQ,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG;gBAClC,MAAM,EAAE,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,KAAK,CAAA;gBAChC,IAAI,KAAK,IAAI,IAAI,EAAE;oBACjB,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ,EAAE,KAAK,CAAC,CAAA;oBACxC,EAAE,CAAC,WAAW,CAAC,QAAQ,CAAC,cAAc,CAAC,IAAI,CAAC,CAAC,CAAA;oBAC7C,MAAM,IAAI,GAAG,QAAQ,CAAC,aAAa,CAAC,GAAG,CAAC,CAAA;AACxC,oBAAA,IAAI,CAAC,WAAW,GAAG,IAAI,CAAA;AACvB,oBAAA,IAAI,CAAC,SAAS,GAAG,WAAW,CAAA;AAC5B,oBAAA,IAAI,CAAC,OAAO,GAAG,MAAK;wBAClB,KAAK,CAAC,CAAG,EAAAA,MAAI,CAAwB,sBAAA,CAAA,GAAG,kBAAkB,CAAC,IAAI,CAAC,CAAC,CAAA;AACnE,qBAAC,CAAA;AACD,oBAAA,EAAE,CAAC,WAAW,CAAC,IAAI,CAAC,CAAA;oBACpB,QAAQ,IAAI,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAA;AACtC,iBAAA;AACF,aAAA;AACF,SAAA;KACF;IAED,KAAK,GAAA;;QACH,CAAA,EAAA,GAAA,IAAI,CAAC,UAAU,MAAA,IAAA,IAAA,EAAA,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAA,EAAA,CAAE,WAAW,CAAC,IAAI,CAAC,CAAA;KACnC;AACF,CAAA;AAEM,MAAM,SAAS,GAAG,oBAAoB,CAAA;AAC7C,MAAM,EAAE,cAAc,EAAE,GAAG,UAAU,CAAA;AACrC,IAAI,cAAc,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,SAAS,CAAC,EAAE;AACpD,IAAA,cAAc,CAAC,MAAM,CAAC,SAAS,EAAE,YAAY,CAAC,CAAA;AAC/C;;ACnMD,OAAO,CAAC,KAAK,CAAC,sBAAsB,CAAC,CAAA;AAErC,MAAM,aAAa,GAAG,IAAI,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA;AAE9C;AACA,MAAM,UAAU,GAAG,eAAe,CAAA;AAClC,MAAM,cAAc,GAClB,gBAAgB,KAAK,aAAa,CAAC,QAAQ,KAAK,QAAQ,GAAG,KAAK,GAAG,IAAI,CAAC,CAAA;AAC1E,MAAM,OAAO,GAAG,YAAY,CAAA;AAC5B,MAAM,UAAU,GAAG,CAAA,EAAG,gBAAgB,IAAI,aAAa,CAAC,QAAQ,CAC9D,CAAA,EAAA,OAAO,IAAI,aAAa,CAAC,IAC3B,CAAG,EAAA,YAAY,EAAE,CAAA;AACjB,MAAM,gBAAgB,GAAG,qBAAqB,CAAA;AAC9C,MAAM,IAAI,GAAG,QAAQ,IAAI,GAAG,CAAA;AAC5B,MAAM,aAAa,GAAa,EAAE,CAAA;AAElC,IAAI,MAAiB,CAAA;AACrB,IAAI;AACF,IAAA,IAAI,QAAkC,CAAA;;IAEtC,IAAI,CAAC,OAAO,EAAE;QACZ,QAAQ,GAAG,MAAK;;;YAGd,MAAM,GAAG,cAAc,CAAC,cAAc,EAAE,gBAAgB,EAAE,MAAK;gBAC7D,MAAM,oBAAoB,GAAG,IAAI,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA;AACrD,gBAAA,MAAM,iBAAiB,GACrB,oBAAoB,CAAC,IAAI;oBACzB,oBAAoB,CAAC,QAAQ,CAAC,OAAO,CAAC,gBAAgB,EAAE,EAAE,CAAC,CAAA;gBAC7D,OAAO,CAAC,KAAK,CACX,0CAA0C;oBACxC,uBAAuB;oBACvB,CAAe,YAAA,EAAA,iBAAiB,CAAiB,cAAA,EAAA,UAAU,CAAa,WAAA,CAAA;oBACxE,CAAe,YAAA,EAAA,UAAU,CAAgC,6BAAA,EAAA,gBAAgB,CAAa,WAAA,CAAA;AACtF,oBAAA,4GAA4G,CAC/G,CAAA;AACH,aAAC,CAAC,CAAA;AACF,YAAA,MAAM,CAAC,gBAAgB,CACrB,MAAM,EACN,MAAK;AACH,gBAAA,OAAO,CAAC,IAAI,CACV,0JAA0J,CAC3J,CAAA;AACH,aAAC,EACD,EAAE,IAAI,EAAE,IAAI,EAAE,CACf,CAAA;AACH,SAAC,CAAA;AACF,KAAA;IAED,MAAM,GAAG,cAAc,CAAC,cAAc,EAAE,UAAU,EAAE,QAAQ,CAAC,CAAA;AAC9D,CAAA;AAAC,OAAO,KAAK,EAAE;AACd,IAAA,OAAO,CAAC,KAAK,CAAC,0CAA0C,KAAK,CAAA,GAAA,CAAK,CAAC,CAAA;AACpE,CAAA;AAED,SAAS,cAAc,CACrB,QAAgB,EAChB,WAAmB,EACnB,kBAA+B,EAAA;AAE/B,IAAA,MAAM,MAAM,GAAG,IAAI,SAAS,CAAC,CAAA,EAAG,QAAQ,CAAA,GAAA,EAAM,WAAW,CAAA,CAAE,EAAE,UAAU,CAAC,CAAA;IACxE,IAAI,QAAQ,GAAG,KAAK,CAAA;AAEpB,IAAA,MAAM,CAAC,gBAAgB,CACrB,MAAM,EACN,MAAK;QACH,QAAQ,GAAG,IAAI,CAAA;AACjB,KAAC,EACD,EAAE,IAAI,EAAE,IAAI,EAAE,CACf,CAAA;;IAGD,MAAM,CAAC,gBAAgB,CAAC,SAAS,EAAE,OAAO,EAAE,IAAI,EAAE,KAAI;QACpD,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAA;AACjC,KAAC,CAAC,CAAA;;IAGF,MAAM,CAAC,gBAAgB,CAAC,OAAO,EAAE,OAAO,EAAE,QAAQ,EAAE,KAAI;AACtD,QAAA,IAAI,QAAQ;YAAE,OAAM;AAEpB,QAAA,IAAI,CAAC,QAAQ,IAAI,kBAAkB,EAAE;AACnC,YAAA,kBAAkB,EAAE,CAAA;YACpB,OAAM;AACP,SAAA;AAED,QAAA,OAAO,CAAC,GAAG,CAAC,CAAA,qDAAA,CAAuD,CAAC,CAAA;AACpE,QAAA,MAAM,qBAAqB,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAA;QAClD,QAAQ,CAAC,MAAM,EAAE,CAAA;AACnB,KAAC,CAAC,CAAA;AAEF,IAAA,OAAO,MAAM,CAAA;AACf,CAAC;AAED,SAAS,eAAe,CAAC,GAAU,EAAE,IAAuB,EAAA;IAC1D,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE;AAC/B,QAAA,OAAO,CAAC,KAAK,CAAC,GAAG,CAAC,CAAA;AACnB,KAAA;AACD,IAAA,OAAO,CAAC,KAAK,CACX,CAAA,uBAAA,EAA0B,IAAI,CAAI,EAAA,CAAA;QAChC,CAA+D,6DAAA,CAAA;AAC/D,QAAA,CAAA,2BAAA,CAA6B,CAChC,CAAA;AACH,CAAC;AAED,SAAS,QAAQ,CAAC,QAAgB,EAAA;AAChC,IAAA,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,QAAQ,EAAE,QAAQ,CAAC,QAAQ,EAAE,CAAC,CAAA;AAClD,IAAA,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAA;AACjC,IAAA,OAAO,GAAG,CAAC,QAAQ,GAAG,GAAG,CAAC,MAAM,CAAA;AAClC,CAAC;AAED,IAAI,aAAa,GAAG,IAAI,CAAA;AACxB,MAAM,gBAAgB,GAAG,IAAI,OAAO,EAAmB,CAAA;AAEvD,eAAe,aAAa,CAAC,OAAmB,EAAA;IAC9C,QAAQ,OAAO,CAAC,IAAI;AAClB,QAAA,KAAK,WAAW;AACd,YAAA,OAAO,CAAC,KAAK,CAAC,CAAA,iBAAA,CAAmB,CAAC,CAAA;AAClC,YAAA,iBAAiB,EAAE,CAAA;;;YAGnB,WAAW,CAAC,MAAK;AACf,gBAAA,IAAI,MAAM,CAAC,UAAU,KAAK,MAAM,CAAC,IAAI,EAAE;AACrC,oBAAA,MAAM,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAA;AAC/B,iBAAA;aACF,EAAE,eAAe,CAAC,CAAA;YACnB,MAAK;AACP,QAAA,KAAK,QAAQ;AACX,YAAA,eAAe,CAAC,mBAAmB,EAAE,OAAO,CAAC,CAAA;;;;;AAK7C,YAAA,IAAI,aAAa,IAAI,eAAe,EAAE,EAAE;AACtC,gBAAA,MAAM,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAA;gBACxB,OAAM;AACP,aAAA;AAAM,iBAAA;AACL,gBAAA,iBAAiB,EAAE,CAAA;gBACnB,aAAa,GAAG,KAAK,CAAA;AACtB,aAAA;AACD,YAAA,MAAM,OAAO,CAAC,GAAG,CACf,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,OAAO,MAAM,KAAmB;AAClD,gBAAA,IAAI,MAAM,CAAC,IAAI,KAAK,WAAW,EAAE;AAC/B,oBAAA,OAAO,WAAW,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC,CAAA;AACxC,iBAAA;;;AAID,gBAAA,MAAM,EAAE,IAAI,EAAE,SAAS,EAAE,GAAG,MAAM,CAAA;AAClC,gBAAA,MAAM,SAAS,GAAG,QAAQ,CAAC,IAAI,CAAC,CAAA;;;;AAIhC,gBAAA,MAAM,EAAE,GAAG,KAAK,CAAC,IAAI,CACnB,QAAQ,CAAC,gBAAgB,CAAkB,MAAM,CAAC,CACnD,CAAC,IAAI,CACJ,CAAC,CAAC,KACA,CAAC,gBAAgB,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CACnE,CAAA;gBAED,IAAI,CAAC,EAAE,EAAE;oBACP,OAAM;AACP,iBAAA;AAED,gBAAA,MAAM,OAAO,GAAG,CAAG,EAAA,IAAI,CAAG,EAAA,SAAS,CAAC,KAAK,CAAC,CAAC,CAAC,CAAA,EAC1C,SAAS,CAAC,QAAQ,CAAC,GAAG,CAAC,GAAG,GAAG,GAAG,GAClC,CAAK,EAAA,EAAA,SAAS,EAAE,CAAA;;;;;;AAOhB,gBAAA,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,KAAI;AAC7B,oBAAA,MAAM,UAAU,GAAG,EAAE,CAAC,SAAS,EAAqB,CAAA;AACpD,oBAAA,UAAU,CAAC,IAAI,GAAG,IAAI,GAAG,CAAC,OAAO,EAAE,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAA;oBAChD,MAAM,WAAW,GAAG,MAAK;wBACvB,EAAE,CAAC,MAAM,EAAE,CAAA;AACX,wBAAA,OAAO,CAAC,KAAK,CAAC,2BAA2B,SAAS,CAAA,CAAE,CAAC,CAAA;AACrD,wBAAA,OAAO,EAAE,CAAA;AACX,qBAAC,CAAA;AACD,oBAAA,UAAU,CAAC,gBAAgB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAA;AAChD,oBAAA,UAAU,CAAC,gBAAgB,CAAC,OAAO,EAAE,WAAW,CAAC,CAAA;AACjD,oBAAA,gBAAgB,CAAC,GAAG,CAAC,EAAE,CAAC,CAAA;AACxB,oBAAA,EAAE,CAAC,KAAK,CAAC,UAAU,CAAC,CAAA;AACtB,iBAAC,CAAC,CAAA;aACH,CAAC,CACH,CAAA;AACD,YAAA,eAAe,CAAC,kBAAkB,EAAE,OAAO,CAAC,CAAA;YAC5C,MAAK;QACP,KAAK,QAAQ,EAAE;YACb,eAAe,CAAC,OAAO,CAAC,KAAK,EAAE,OAAO,CAAC,IAAI,CAAC,CAAA;YAC5C,MAAK;AACN,SAAA;AACD,QAAA,KAAK,aAAa;AAChB,YAAA,eAAe,CAAC,uBAAuB,EAAE,OAAO,CAAC,CAAA;AACjD,YAAA,IAAI,OAAO,CAAC,IAAI,IAAI,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,EAAE;;;gBAGlD,MAAM,QAAQ,GAAG,SAAS,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAA;AAC7C,gBAAA,MAAM,WAAW,GAAG,IAAI,GAAG,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAA;gBAChD,IACE,QAAQ,KAAK,WAAW;oBACxB,OAAO,CAAC,IAAI,KAAK,aAAa;AAC9B,qBAAC,QAAQ,CAAC,QAAQ,CAAC,GAAG,CAAC,IAAI,QAAQ,GAAG,YAAY,KAAK,WAAW,CAAC,EACnE;oBACA,QAAQ,CAAC,MAAM,EAAE,CAAA;AAClB,iBAAA;gBACD,OAAM;AACP,aAAA;AAAM,iBAAA;gBACL,QAAQ,CAAC,MAAM,EAAE,CAAA;AAClB,aAAA;YACD,MAAK;AACP,QAAA,KAAK,OAAO;AACV,YAAA,eAAe,CAAC,kBAAkB,EAAE,OAAO,CAAC,CAAA;;;;;YAK5C,OAAO,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,KAAI;gBAC7B,MAAM,EAAE,GAAG,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAA;AAC7B,gBAAA,IAAI,EAAE,EAAE;oBACN,EAAE,CAAC,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAA;AACtB,iBAAA;AACH,aAAC,CAAC,CAAA;YACF,MAAK;QACP,KAAK,OAAO,EAAE;AACZ,YAAA,eAAe,CAAC,YAAY,EAAE,OAAO,CAAC,CAAA;AACtC,YAAA,MAAM,GAAG,GAAG,OAAO,CAAC,GAAG,CAAA;AACvB,YAAA,IAAI,aAAa,EAAE;gBACjB,kBAAkB,CAAC,GAAG,CAAC,CAAA;AACxB,aAAA;AAAM,iBAAA;AACL,gBAAA,OAAO,CAAC,KAAK,CACX,CAAA,8BAAA,EAAiC,GAAG,CAAC,OAAO,CAAA,EAAA,EAAK,GAAG,CAAC,KAAK,CAAA,CAAE,CAC7D,CAAA;AACF,aAAA;YACD,MAAK;AACN,SAAA;AACD,QAAA,SAAS;YACP,MAAM,KAAK,GAAU,OAAO,CAAA;AAC5B,YAAA,OAAO,KAAK,CAAA;AACb,SAAA;AACF,KAAA;AACH,CAAC;AAMD,SAAS,eAAe,CAAC,KAAa,EAAE,IAAS,EAAA;IAC/C,MAAM,GAAG,GAAG,kBAAkB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAA;AACzC,IAAA,IAAI,GAAG,EAAE;AACP,QAAA,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,KAAK,EAAE,CAAC,IAAI,CAAC,CAAC,CAAA;AAC9B,KAAA;AACH,CAAC;AAED,MAAM,aAAa,GAAG,sBAAsB,CAAA;AAE5C,SAAS,kBAAkB,CAAC,GAAwB,EAAA;AAClD,IAAA,IAAI,CAAC,aAAa;QAAE,OAAM;AAC1B,IAAA,iBAAiB,EAAE,CAAA;IACnB,QAAQ,CAAC,IAAI,CAAC,WAAW,CAAC,IAAI,YAAY,CAAC,GAAG,CAAC,CAAC,CAAA;AAClD,CAAC;AAED,SAAS,iBAAiB,GAAA;IACxB,QAAQ;SACL,gBAAgB,CAAC,SAAS,CAAC;SAC3B,OAAO,CAAC,CAAC,CAAC,KAAM,CAAkB,CAAC,KAAK,EAAE,CAAC,CAAA;AAChD,CAAC;AAED,SAAS,eAAe,GAAA;IACtB,OAAO,QAAQ,CAAC,gBAAgB,CAAC,SAAS,CAAC,CAAC,MAAM,CAAA;AACpD,CAAC;AAED,IAAI,OAAO,GAAG,KAAK,CAAA;AACnB,IAAI,MAAM,GAAwC,EAAE,CAAA;AAEpD;;;;AAIG;AACH,eAAe,WAAW,CAAC,CAAoC,EAAA;AAC7D,IAAA,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAA;IACd,IAAI,CAAC,OAAO,EAAE;QACZ,OAAO,GAAG,IAAI,CAAA;AACd,QAAA,MAAM,OAAO,CAAC,OAAO,EAAE,CAAA;QACvB,OAAO,GAAG,KAAK,CAAA;AACf,QAAA,MAAM,OAAO,GAAG,CAAC,GAAG,MAAM,CAAC,CAAA;QAC3B,MAAM,GAAG,EAAE,CACV;QAAA,CAAC,MAAM,OAAO,CAAC,GAAG,CAAC,OAAO,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE,CAAC,CAAA;AAC1D,KAAA;AACH,CAAC;AAED,eAAe,qBAAqB,CAClC,cAAsB,EACtB,WAAmB,EACnB,EAAE,GAAG,IAAI,EAAA;AAET,IAAA,MAAM,gBAAgB,GAAG,cAAc,KAAK,KAAK,GAAG,OAAO,GAAG,MAAM,CAAA;;AAGpE,IAAA,OAAO,IAAI,EAAE;QACX,IAAI;;;;AAIF,YAAA,MAAM,KAAK,CAAC,CAAA,EAAG,gBAAgB,CAAM,GAAA,EAAA,WAAW,EAAE,EAAE;AAClD,gBAAA,IAAI,EAAE,SAAS;AAChB,aAAA,CAAC,CAAA;YACF,MAAK;AACN,SAAA;AAAC,QAAA,OAAO,CAAC,EAAE;;AAEV,YAAA,MAAM,IAAI,OAAO,CAAC,CAAC,OAAO,KAAK,UAAU,CAAC,OAAO,EAAE,EAAE,CAAC,CAAC,CAAA;AACxD,SAAA;AACF,KAAA;AACH,CAAC;AAaD,MAAM,SAAS,GAAG,IAAI,GAAG,EAGtB,CAAA;AACH;AACA;AACA,IAAI,iBAA+C,CAAA;AAEnC,SAAA,WAAW,CAAC,EAAU,EAAE,OAAe,EAAA;IACrD,IAAI,KAAK,GAAG,SAAS,CAAC,GAAG,CAAC,EAAE,CAAC,CAAA;IActB;QACL,IAAI,KAAK,IAAI,EAAE,KAAK,YAAY,gBAAgB,CAAC,EAAE;YACjD,WAAW,CAAC,EAAE,CAAC,CAAA;YACf,KAAK,GAAG,SAAS,CAAA;AAClB,SAAA;QAED,IAAI,CAAC,KAAK,EAAE;AACV,YAAA,KAAK,GAAG,QAAQ,CAAC,aAAa,CAAC,OAAO,CAAC,CAAA;AACvC,YAAA,KAAK,CAAC,YAAY,CAAC,MAAM,EAAE,UAAU,CAAC,CAAA;AACtC,YAAA,KAAK,CAAC,YAAY,CAAC,kBAAkB,EAAE,EAAE,CAAC,CAAA;AAC1C,YAAA,KAAK,CAAC,WAAW,GAAG,OAAO,CAAA;YAE3B,IAAI,CAAC,iBAAiB,EAAE;AACtB,gBAAA,QAAQ,CAAC,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,CAAA;;;gBAIhC,UAAU,CAAC,MAAK;oBACd,iBAAiB,GAAG,SAAS,CAAA;iBAC9B,EAAE,CAAC,CAAC,CAAA;AACN,aAAA;AAAM,iBAAA;AACL,gBAAA,iBAAiB,CAAC,qBAAqB,CAAC,UAAU,EAAE,KAAK,CAAC,CAAA;AAC3D,aAAA;YACD,iBAAiB,GAAG,KAAK,CAAA;AAC1B,SAAA;AAAM,aAAA;AACL,YAAA,KAAK,CAAC,WAAW,GAAG,OAAO,CAAA;AAC5B,SAAA;AACF,KAAA;AACD,IAAA,SAAS,CAAC,GAAG,CAAC,EAAE,EAAE,KAAK,CAAC,CAAA;AAC1B,CAAC;AAEK,SAAU,WAAW,CAAC,EAAU,EAAA;IACpC,MAAM,KAAK,GAAG,SAAS,CAAC,GAAG,CAAC,EAAE,CAAC,CAAA;AAC/B,IAAA,IAAI,KAAK,EAAE;QACT,IAAI,KAAK,YAAY,aAAa,EAAE;AAClC,YAAA,QAAQ,CAAC,kBAAkB,GAAG,QAAQ,CAAC,kBAAkB,CAAC,MAAM,CAC9D,CAAC,CAAgB,KAAK,CAAC,KAAK,KAAK,CAClC,CAAA;AACF,SAAA;AAAM,aAAA;AACL,YAAA,QAAQ,CAAC,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,CAAA;AACjC,SAAA;AACD,QAAA,SAAS,CAAC,MAAM,CAAC,EAAE,CAAC,CAAA;AACrB,KAAA;AACH,CAAC;AAED,eAAe,WAAW,CAAC,EACzB,IAAI,EACJ,YAAY,EACZ,SAAS,EACT,sBAAsB,GACf,EAAA;IACP,MAAM,GAAG,GAAG,aAAa,CAAC,GAAG,CAAC,IAAI,CAAC,CAAA;IACnC,IAAI,CAAC,GAAG,EAAE;;;;QAIR,OAAM;AACP,KAAA;AAED,IAAA,IAAI,aAA0C,CAAA;AAC9C,IAAA,MAAM,YAAY,GAAG,IAAI,KAAK,YAAY,CAAA;;IAG1C,MAAM,kBAAkB,GAAG,GAAG,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,EAAE,IAAI,EAAE,KACvD,IAAI,CAAC,QAAQ,CAAC,YAAY,CAAC,CAC5B,CAAA;AAED,IAAA,IAAI,YAAY,IAAI,kBAAkB,CAAC,MAAM,GAAG,CAAC,EAAE;QACjD,MAAM,QAAQ,GAAG,UAAU,CAAC,GAAG,CAAC,YAAY,CAAC,CAAA;AAC7C,QAAA,IAAI,QAAQ;YAAE,MAAM,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,CAAA;AACvD,QAAA,MAAM,CAAC,wBAAwB,EAAE,KAAK,CAAC,GAAG,YAAY,CAAC,KAAK,CAAC,CAAG,CAAA,CAAA,CAAC,CAAA;QACjE,IAAI;YACF,aAAa,GAAG,MAAM;;YAEpB,IAAI;AACF,gBAAA,wBAAwB,CAAC,KAAK,CAAC,CAAC,CAAC;gBACjC,CAAI,CAAA,EAAA,sBAAsB,GAAG,SAAS,GAAG,EAAE,CAAA,EAAA,EAAK,SAAS,CAAA,EACvD,KAAK,GAAG,CAAA,CAAA,EAAI,KAAK,CAAA,CAAE,GAAG,EACxB,CAAE,CAAA,CACL,CAAA;AACF,SAAA;AAAC,QAAA,OAAO,CAAC,EAAE;AACV,YAAA,eAAe,CAAC,CAAC,EAAE,YAAY,CAAC,CAAA;AACjC,SAAA;AACF,KAAA;AAED,IAAA,OAAO,MAAK;QACV,KAAK,MAAM,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,kBAAkB,EAAE;YAC7C,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,GAAG,KAAK,YAAY,GAAG,aAAa,GAAG,SAAS,CAAC,CAAC,CAAC,CAAA;AAC1E,SAAA;AACD,QAAA,MAAM,UAAU,GAAG,YAAY,GAAG,IAAI,GAAG,CAAG,EAAA,YAAY,CAAQ,KAAA,EAAA,IAAI,EAAE,CAAA;AACtE,QAAA,OAAO,CAAC,KAAK,CAAC,uBAAuB,UAAU,CAAA,CAAE,CAAC,CAAA;AACpD,KAAC,CAAA;AACH,CAAC;AAED,SAAS,iBAAiB,GAAA;AACxB,IAAA,IAAI,MAAM,CAAC,UAAU,KAAK,CAAC,EAAE;AAC3B,QAAA,aAAa,CAAC,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAA;AAChD,QAAA,aAAa,CAAC,MAAM,GAAG,CAAC,CAAA;AACzB,KAAA;AACH,CAAC;AAeD,MAAM,aAAa,GAAG,IAAI,GAAG,EAAqB,CAAA;AAClD,MAAM,UAAU,GAAG,IAAI,GAAG,EAA+C,CAAA;AACzE,MAAM,QAAQ,GAAG,IAAI,GAAG,EAA+C,CAAA;AACvE,MAAM,OAAO,GAAG,IAAI,GAAG,EAAe,CAAA;AACtC,MAAM,kBAAkB,GAAuB,IAAI,GAAG,EAAE,CAAA;AACxD,MAAM,iBAAiB,GAAG,IAAI,GAAG,EAA8B,CAAA;AAEzD,SAAU,gBAAgB,CAAC,SAAiB,EAAA;AAChD,IAAA,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,SAAS,CAAC,EAAE;AAC3B,QAAA,OAAO,CAAC,GAAG,CAAC,SAAS,EAAE,EAAE,CAAC,CAAA;AAC3B,KAAA;;;IAID,MAAM,GAAG,GAAG,aAAa,CAAC,GAAG,CAAC,SAAS,CAAC,CAAA;AACxC,IAAA,IAAI,GAAG,EAAE;AACP,QAAA,GAAG,CAAC,SAAS,GAAG,EAAE,CAAA;AACnB,KAAA;;IAGD,MAAM,cAAc,GAAG,iBAAiB,CAAC,GAAG,CAAC,SAAS,CAAC,CAAA;AACvD,IAAA,IAAI,cAAc,EAAE;QAClB,KAAK,MAAM,CAAC,KAAK,EAAE,QAAQ,CAAC,IAAI,cAAc,EAAE;YAC9C,MAAM,SAAS,GAAG,kBAAkB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAA;AAC/C,YAAA,IAAI,SAAS,EAAE;gBACb,kBAAkB,CAAC,GAAG,CACpB,KAAK,EACL,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAC/C,CAAA;AACF,aAAA;AACF,SAAA;AACF,KAAA;AAED,IAAA,MAAM,YAAY,GAAuB,IAAI,GAAG,EAAE,CAAA;AAClD,IAAA,iBAAiB,CAAC,GAAG,CAAC,SAAS,EAAE,YAAY,CAAC,CAAA;IAE9C,SAAS,UAAU,CAAC,IAAc,EAAE,WAA8B,SAAQ,EAAA;QACxE,MAAM,GAAG,GAAc,aAAa,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI;AACrD,YAAA,EAAE,EAAE,SAAS;AACb,YAAA,SAAS,EAAE,EAAE;SACd,CAAA;AACD,QAAA,GAAG,CAAC,SAAS,CAAC,IAAI,CAAC;YACjB,IAAI;AACJ,YAAA,EAAE,EAAE,QAAQ;AACb,SAAA,CAAC,CAAA;AACF,QAAA,aAAa,CAAC,GAAG,CAAC,SAAS,EAAE,GAAG,CAAC,CAAA;KAClC;AAED,IAAA,MAAM,GAAG,GAAmB;AAC1B,QAAA,IAAI,IAAI,GAAA;AACN,YAAA,OAAO,OAAO,CAAC,GAAG,CAAC,SAAS,CAAC,CAAA;SAC9B;QAED,MAAM,CAAC,IAAU,EAAE,QAAc,EAAA;AAC/B,YAAA,IAAI,OAAO,IAAI,KAAK,UAAU,IAAI,CAAC,IAAI,EAAE;;gBAEvC,UAAU,CAAC,CAAC,SAAS,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,KAAK,IAAI,aAAJ,IAAI,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAJ,IAAI,CAAG,GAAG,CAAC,CAAC,CAAA;AAChD,aAAA;AAAM,iBAAA,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;;gBAEnC,UAAU,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,KAAK,QAAQ,aAAR,QAAQ,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAR,QAAQ,CAAG,GAAG,CAAC,CAAC,CAAA;AAC/C,aAAA;AAAM,iBAAA,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;AAC9B,gBAAA,UAAU,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAA;AAC3B,aAAA;AAAM,iBAAA;AACL,gBAAA,MAAM,IAAI,KAAK,CAAC,CAAA,2BAAA,CAA6B,CAAC,CAAA;AAC/C,aAAA;SACF;;;QAID,aAAa,CAAC,CAAC,EAAE,QAAQ,EAAA;YACvB,UAAU,CAAC,CAAC,SAAS,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,KAAK,QAAQ,aAAR,QAAQ,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAR,QAAQ,CAAG,GAAG,CAAC,CAAC,CAAA;SACpD;AAED,QAAA,OAAO,CAAC,EAAE,EAAA;AACR,YAAA,UAAU,CAAC,GAAG,CAAC,SAAS,EAAE,EAAE,CAAC,CAAA;SAC9B;AAED,QAAA,KAAK,CAAC,EAAE,EAAA;AACN,YAAA,QAAQ,CAAC,GAAG,CAAC,SAAS,EAAE,EAAE,CAAC,CAAA;SAC5B;;;;AAKD,QAAA,OAAO,MAAK;;AAGZ,QAAA,UAAU,CAAC,OAAO,EAAA;YAChB,eAAe,CAAC,iBAAiB,EAAE,EAAE,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,CAAC,CAAA;AAChE,YAAA,IAAI,CAAC,IAAI,CAAC,iBAAiB,EAAE,EAAE,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,CAAC,CAAA;AAC1D,YAAA,OAAO,CAAC,KAAK,CACX,qBAAqB,SAAS,CAAA,EAAG,OAAO,GAAG,CAAK,EAAA,EAAA,OAAO,EAAE,GAAG,EAAE,CAAA,CAAE,CACjE,CAAA;SACF;;QAGD,EAAE,CAAC,KAAK,EAAE,EAAE,EAAA;AACV,YAAA,MAAM,QAAQ,GAAG,CAAC,GAAuB,KAAI;gBAC3C,MAAM,QAAQ,GAAG,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,EAAE,CAAA;AACrC,gBAAA,QAAQ,CAAC,IAAI,CAAC,EAAE,CAAC,CAAA;AACjB,gBAAA,GAAG,CAAC,GAAG,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAA;AAC1B,aAAC,CAAA;YACD,QAAQ,CAAC,kBAAkB,CAAC,CAAA;YAC5B,QAAQ,CAAC,YAAY,CAAC,CAAA;SACvB;QAED,IAAI,CAAC,KAAK,EAAE,IAAI,EAAA;AACd,YAAA,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,IAAI,EAAE,CAAC,CAAC,CAAA;AACnE,YAAA,iBAAiB,EAAE,CAAA;SACpB;KACF,CAAA;AAED,IAAA,OAAO,GAAG,CAAA;AACZ,CAAC;AAED;;AAEG;AACa,SAAA,WAAW,CAAC,GAAW,EAAE,aAAqB,EAAA;;AAE5D,IAAA,IAAI,CAAC,GAAG,CAAC,UAAU,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,UAAU,CAAC,GAAG,CAAC,EAAE;AAChD,QAAA,OAAO,GAAG,CAAA;AACX,KAAA;;AAGD,IAAA,MAAM,QAAQ,GAAG,GAAG,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC,OAAO,CAAC,OAAO,EAAE,EAAE,CAAC,CAAA;AAC7D,IAAA,MAAM,EAAE,MAAM,EAAE,IAAI,EAAE,GAAG,IAAI,GAAG,CAAC,GAAG,EAAE,mBAAmB,CAAC,CAAA;IAE1D,OAAO,CAAA,EAAG,QAAQ,CAAA,CAAA,EAAI,aAAa,CAAA,EAAG,MAAM,GAAG,CAAG,CAAA,CAAA,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,EAAE,CAAA,EACvE,IAAI,IAAI,EACV,CAAA,CAAE,CAAA;AACJ;;;;\"}"}},"env.mjs":{"file":{"contents":"const context = (() => {\n    if (typeof globalThis !== 'undefined') {\n        return globalThis;\n    }\n    else if (typeof self !== 'undefined') {\n        return self;\n    }\n    else if (typeof window !== 'undefined') {\n        return window;\n    }\n    else {\n        return Function('return this')();\n    }\n})();\n// assign defines\nconst defines = __DEFINES__;\nObject.keys(defines).forEach((key) => {\n    const segments = key.split('.');\n    let target = context;\n    for (let i = 0; i < segments.length; i++) {\n        const segment = segments[i];\n        if (i === segments.length - 1) {\n            target[segment] = defines[key];\n        }\n        else {\n            target = target[segment] || (target[segment] = {});\n        }\n    }\n});\n//# sourceMappingURL=env.mjs.map\n"}},"env.mjs.map":{"file":{"contents":"{\"version\":3,\"file\":\"env.mjs\",\"sources\":[\"env.ts\"],\"sourcesContent\":[\"declare const __MODE__: string\\ndeclare const __DEFINES__: Record<string, any>\\n\\nconst context = (() => {\\n  if (typeof globalThis !== 'undefined') {\\n    return globalThis\\n  } else if (typeof self !== 'undefined') {\\n    return self\\n  } else if (typeof window !== 'undefined') {\\n    return window\\n  } else {\\n    return Function('return this')()\\n  }\\n})()\\n\\n// assign defines\\nconst defines = __DEFINES__\\nObject.keys(defines).forEach((key) => {\\n  const segments = key.split('.')\\n  let target = context\\n  for (let i = 0; i < segments.length; i++) {\\n    const segment = segments[i]\\n    if (i === segments.length - 1) {\\n      target[segment] = defines[key]\\n    } else {\\n      target = target[segment] || (target[segment] = {})\\n    }\\n  }\\n})\\n\"],\"names\":[],\"mappings\":\"AAGA,MAAM,OAAO,GAAG,CAAC,MAAK;AACpB,IAAA,IAAI,OAAO,UAAU,KAAK,WAAW,EAAE;AACrC,QAAA,OAAO,UAAU,CAAA;AAClB,KAAA;AAAM,SAAA,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;AACtC,QAAA,OAAO,IAAI,CAAA;AACZ,KAAA;AAAM,SAAA,IAAI,OAAO,MAAM,KAAK,WAAW,EAAE;AACxC,QAAA,OAAO,MAAM,CAAA;AACd,KAAA;AAAM,SAAA;AACL,QAAA,OAAO,QAAQ,CAAC,aAAa,CAAC,EAAE,CAAA;AACjC,KAAA;AACH,CAAC,GAAG,CAAA;AAEJ;AACA,MAAM,OAAO,GAAG,WAAW,CAAA;AAC3B,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,OAAO,CAAC,CAAC,GAAG,KAAI;IACnC,MAAM,QAAQ,GAAG,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAA;IAC/B,IAAI,MAAM,GAAG,OAAO,CAAA;AACpB,IAAA,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;AACxC,QAAA,MAAM,OAAO,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAA;AAC3B,QAAA,IAAI,CAAC,KAAK,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE;YAC7B,MAAM,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,GAAG,CAAC,CAAA;AAC/B,SAAA;AAAM,aAAA;AACL,YAAA,MAAM,GAAG,MAAM,CAAC,OAAO,CAAC,KAAK,MAAM,CAAC,OAAO,CAAC,GAAG,EAAE,CAAC,CAAA;AACnD,SAAA;AACF,KAAA;AACH,CAAC,CAAC\"}"}}}},"node":{"directory":{"chunks":{"directory":{"dep-53dc1ef4.js":{"file":{"contents":"import require$$0 from 'path';\nimport resolve$2 from 'resolve';\nimport require$$0__default from 'fs';\nimport { l as lib } from './dep-c423598f.js';\n\nimport { fileURLToPath as __cjs_fileURLToPath } from 'node:url';\nimport { dirname as __cjs_dirname } from 'node:path';\nimport { createRequire as __cjs_createRequire } from 'node:module';\n\nconst __filename = __cjs_fileURLToPath(import.meta.url);\nconst __dirname = __cjs_dirname(__filename);\nconst require = __cjs_createRequire(import.meta.url);\nconst __require = require;\nfunction _mergeNamespaces(n, m) {\n  for (var i = 0; i < m.length; i++) {\n    var e = m[i];\n    if (typeof e !== 'string' && !Array.isArray(e)) { for (var k in e) {\n      if (k !== 'default' && !(k in n)) {\n        n[k] = e[k];\n      }\n    } }\n  }\n  return n;\n}\n\nconst startsWithKeywordRegexp = /^(all|not|only|print|screen)/i;\n\nvar joinMedia$1 = function (parentMedia, childMedia) {\n  if (!parentMedia.length && childMedia.length) return childMedia\n  if (parentMedia.length && !childMedia.length) return parentMedia\n  if (!parentMedia.length && !childMedia.length) return []\n\n  const media = [];\n\n  parentMedia.forEach(parentItem => {\n    const parentItemStartsWithKeyword = startsWithKeywordRegexp.test(parentItem);\n\n    childMedia.forEach(childItem => {\n      const childItemStartsWithKeyword = startsWithKeywordRegexp.test(childItem);\n      if (parentItem !== childItem) {\n        if (childItemStartsWithKeyword && !parentItemStartsWithKeyword) {\n          media.push(`${childItem} and ${parentItem}`);\n        } else {\n          media.push(`${parentItem} and ${childItem}`);\n        }\n      }\n    });\n  });\n\n  return media\n};\n\nvar joinLayer$1 = function (parentLayer, childLayer) {\n  if (!parentLayer.length && childLayer.length) return childLayer\n  if (parentLayer.length && !childLayer.length) return parentLayer\n  if (!parentLayer.length && !childLayer.length) return []\n\n  return parentLayer.concat(childLayer)\n};\n\n// external tooling\nconst resolve$1 = resolve$2;\n\nconst moduleDirectories = [\"web_modules\", \"node_modules\"];\n\nfunction resolveModule(id, opts) {\n  return new Promise((res, rej) => {\n    resolve$1(id, opts, (err, path) => (err ? rej(err) : res(path)));\n  })\n}\n\nvar resolveId$1 = function (id, base, options) {\n  const paths = options.path;\n\n  const resolveOpts = {\n    basedir: base,\n    moduleDirectory: moduleDirectories.concat(options.addModulesDirectories),\n    paths,\n    extensions: [\".css\"],\n    packageFilter: function processPackage(pkg) {\n      if (pkg.style) pkg.main = pkg.style;\n      else if (!pkg.main || !/\\.css$/.test(pkg.main)) pkg.main = \"index.css\";\n      return pkg\n    },\n    preserveSymlinks: false,\n  };\n\n  return resolveModule(`./${id}`, resolveOpts)\n    .catch(() => resolveModule(id, resolveOpts))\n    .catch(() => {\n      if (paths.indexOf(base) === -1) paths.unshift(base);\n\n      throw new Error(\n        `Failed to find '${id}'\n  in [\n    ${paths.join(\",\\n        \")}\n  ]`\n      )\n    })\n};\n\nvar readCacheExports = {};\nvar readCache$1 = {\n  get exports(){ return readCacheExports; },\n  set exports(v){ readCacheExports = v; },\n};\n\nvar pifyExports = {};\nvar pify$2 = {\n  get exports(){ return pifyExports; },\n  set exports(v){ pifyExports = v; },\n};\n\nvar processFn = function (fn, P, opts) {\n\treturn function () {\n\t\tvar that = this;\n\t\tvar args = new Array(arguments.length);\n\n\t\tfor (var i = 0; i < arguments.length; i++) {\n\t\t\targs[i] = arguments[i];\n\t\t}\n\n\t\treturn new P(function (resolve, reject) {\n\t\t\targs.push(function (err, result) {\n\t\t\t\tif (err) {\n\t\t\t\t\treject(err);\n\t\t\t\t} else if (opts.multiArgs) {\n\t\t\t\t\tvar results = new Array(arguments.length - 1);\n\n\t\t\t\t\tfor (var i = 1; i < arguments.length; i++) {\n\t\t\t\t\t\tresults[i - 1] = arguments[i];\n\t\t\t\t\t}\n\n\t\t\t\t\tresolve(results);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(result);\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tfn.apply(that, args);\n\t\t});\n\t};\n};\n\nvar pify$1 = pify$2.exports = function (obj, P, opts) {\n\tif (typeof P !== 'function') {\n\t\topts = P;\n\t\tP = Promise;\n\t}\n\n\topts = opts || {};\n\topts.exclude = opts.exclude || [/.+Sync$/];\n\n\tvar filter = function (key) {\n\t\tvar match = function (pattern) {\n\t\t\treturn typeof pattern === 'string' ? key === pattern : pattern.test(key);\n\t\t};\n\n\t\treturn opts.include ? opts.include.some(match) : !opts.exclude.some(match);\n\t};\n\n\tvar ret = typeof obj === 'function' ? function () {\n\t\tif (opts.excludeMain) {\n\t\t\treturn obj.apply(this, arguments);\n\t\t}\n\n\t\treturn processFn(obj, P, opts).apply(this, arguments);\n\t} : {};\n\n\treturn Object.keys(obj).reduce(function (ret, key) {\n\t\tvar x = obj[key];\n\n\t\tret[key] = typeof x === 'function' && filter(key) ? processFn(x, P, opts) : x;\n\n\t\treturn ret;\n\t}, ret);\n};\n\npify$1.all = pify$1;\n\nvar fs = require$$0__default;\r\nvar path$2 = require$$0;\r\nvar pify = pifyExports;\r\n\r\nvar stat = pify(fs.stat);\r\nvar readFile = pify(fs.readFile);\r\nvar resolve = path$2.resolve;\r\n\r\nvar cache = Object.create(null);\r\n\r\nfunction convert(content, encoding) {\r\n\tif (Buffer.isEncoding(encoding)) {\r\n\t\treturn content.toString(encoding);\r\n\t}\r\n\treturn content;\r\n}\r\n\r\nreadCache$1.exports = function (path, encoding) {\r\n\tpath = resolve(path);\r\n\r\n\treturn stat(path).then(function (stats) {\r\n\t\tvar item = cache[path];\r\n\r\n\t\tif (item && item.mtime.getTime() === stats.mtime.getTime()) {\r\n\t\t\treturn convert(item.content, encoding);\r\n\t\t}\r\n\r\n\t\treturn readFile(path).then(function (data) {\r\n\t\t\tcache[path] = {\r\n\t\t\t\tmtime: stats.mtime,\r\n\t\t\t\tcontent: data\r\n\t\t\t};\r\n\r\n\t\t\treturn convert(data, encoding);\r\n\t\t});\r\n\t}).catch(function (err) {\r\n\t\tcache[path] = null;\r\n\t\treturn Promise.reject(err);\r\n\t});\r\n};\r\n\r\nreadCacheExports.sync = function (path, encoding) {\r\n\tpath = resolve(path);\r\n\r\n\ttry {\r\n\t\tvar stats = fs.statSync(path);\r\n\t\tvar item = cache[path];\r\n\r\n\t\tif (item && item.mtime.getTime() === stats.mtime.getTime()) {\r\n\t\t\treturn convert(item.content, encoding);\r\n\t\t}\r\n\r\n\t\tvar data = fs.readFileSync(path);\r\n\r\n\t\tcache[path] = {\r\n\t\t\tmtime: stats.mtime,\r\n\t\t\tcontent: data\r\n\t\t};\r\n\r\n\t\treturn convert(data, encoding);\r\n\t} catch (err) {\r\n\t\tcache[path] = null;\r\n\t\tthrow err;\r\n\t}\r\n\r\n};\r\n\r\nreadCacheExports.get = function (path, encoding) {\r\n\tpath = resolve(path);\r\n\tif (cache[path]) {\r\n\t\treturn convert(cache[path].content, encoding);\r\n\t}\r\n\treturn null;\r\n};\r\n\r\nreadCacheExports.clear = function () {\r\n\tcache = Object.create(null);\r\n};\n\nconst dataURLRegexp = /^data:text\\/css;base64,/i;\n\nfunction isValid(url) {\n  return dataURLRegexp.test(url)\n}\n\nfunction contents(url) {\n  // \"data:text/css;base64,\".length === 21\n  return Buffer.from(url.slice(21), \"base64\").toString()\n}\n\nvar dataUrl = {\n  isValid,\n  contents,\n};\n\nconst readCache = readCacheExports;\nconst dataURL$1 = dataUrl;\n\nvar loadContent$1 = filename => {\n  if (dataURL$1.isValid(filename)) {\n    return dataURL$1.contents(filename)\n  }\n\n  return readCache(filename, \"utf-8\")\n};\n\n// builtin tooling\nconst path$1 = require$$0;\n\n// placeholder tooling\nlet sugarss;\n\nvar processContent$1 = function processContent(\n  result,\n  content,\n  filename,\n  options,\n  postcss\n) {\n  const { plugins } = options;\n  const ext = path$1.extname(filename);\n\n  const parserList = [];\n\n  // SugarSS support:\n  if (ext === \".sss\") {\n    if (!sugarss) {\n      try {\n        sugarss = __require('sugarss');\n      } catch {} // Ignore\n    }\n    if (sugarss)\n      return runPostcss(postcss, content, filename, plugins, [sugarss])\n  }\n\n  // Syntax support:\n  if (result.opts.syntax?.parse) {\n    parserList.push(result.opts.syntax.parse);\n  }\n\n  // Parser support:\n  if (result.opts.parser) parserList.push(result.opts.parser);\n  // Try the default as a last resort:\n  parserList.push(null);\n\n  return runPostcss(postcss, content, filename, plugins, parserList)\n};\n\nfunction runPostcss(postcss, content, filename, plugins, parsers, index) {\n  if (!index) index = 0;\n  return postcss(plugins)\n    .process(content, {\n      from: filename,\n      parser: parsers[index],\n    })\n    .catch(err => {\n      // If there's an error, try the next parser\n      index++;\n      // If there are no parsers left, throw it\n      if (index === parsers.length) throw err\n      return runPostcss(postcss, content, filename, plugins, parsers, index)\n    })\n}\n\n// external tooling\nconst valueParser = lib;\n\n// extended tooling\nconst { stringify } = valueParser;\n\nfunction split(params, start) {\n  const list = [];\n  const last = params.reduce((item, node, index) => {\n    if (index < start) return \"\"\n    if (node.type === \"div\" && node.value === \",\") {\n      list.push(item);\n      return \"\"\n    }\n    return item + stringify(node)\n  }, \"\");\n  list.push(last);\n  return list\n}\n\nvar parseStatements$1 = function (result, styles) {\n  const statements = [];\n  let nodes = [];\n\n  styles.each(node => {\n    let stmt;\n    if (node.type === \"atrule\") {\n      if (node.name === \"import\") stmt = parseImport(result, node);\n      else if (node.name === \"media\") stmt = parseMedia(result, node);\n      else if (node.name === \"charset\") stmt = parseCharset(result, node);\n    }\n\n    if (stmt) {\n      if (nodes.length) {\n        statements.push({\n          type: \"nodes\",\n          nodes,\n          media: [],\n          layer: [],\n        });\n        nodes = [];\n      }\n      statements.push(stmt);\n    } else nodes.push(node);\n  });\n\n  if (nodes.length) {\n    statements.push({\n      type: \"nodes\",\n      nodes,\n      media: [],\n      layer: [],\n    });\n  }\n\n  return statements\n};\n\nfunction parseMedia(result, atRule) {\n  const params = valueParser(atRule.params).nodes;\n  return {\n    type: \"media\",\n    node: atRule,\n    media: split(params, 0),\n    layer: [],\n  }\n}\n\nfunction parseCharset(result, atRule) {\n  if (atRule.prev()) {\n    return result.warn(\"@charset must precede all other statements\", {\n      node: atRule,\n    })\n  }\n  return {\n    type: \"charset\",\n    node: atRule,\n    media: [],\n    layer: [],\n  }\n}\n\nfunction parseImport(result, atRule) {\n  let prev = atRule.prev();\n  if (prev) {\n    do {\n      if (\n        prev.type !== \"comment\" &&\n        (prev.type !== \"atrule\" ||\n          (prev.name !== \"import\" &&\n            prev.name !== \"charset\" &&\n            !(prev.name === \"layer\" && !prev.nodes)))\n      ) {\n        return result.warn(\n          \"@import must precede all other statements (besides @charset or empty @layer)\",\n          { node: atRule }\n        )\n      }\n      prev = prev.prev();\n    } while (prev)\n  }\n\n  if (atRule.nodes) {\n    return result.warn(\n      \"It looks like you didn't end your @import statement correctly. \" +\n        \"Child nodes are attached to it.\",\n      { node: atRule }\n    )\n  }\n\n  const params = valueParser(atRule.params).nodes;\n  const stmt = {\n    type: \"import\",\n    node: atRule,\n    media: [],\n    layer: [],\n  };\n\n  // prettier-ignore\n  if (\n    !params.length ||\n    (\n      params[0].type !== \"string\" ||\n      !params[0].value\n    ) &&\n    (\n      params[0].type !== \"function\" ||\n      params[0].value !== \"url\" ||\n      !params[0].nodes.length ||\n      !params[0].nodes[0].value\n    )\n  ) {\n    return result.warn(`Unable to find uri in '${  atRule.toString()  }'`, {\n      node: atRule,\n    })\n  }\n\n  if (params[0].type === \"string\") stmt.uri = params[0].value;\n  else stmt.uri = params[0].nodes[0].value;\n  stmt.fullUri = stringify(params[0]);\n\n  let remainder = params;\n  if (remainder.length > 2) {\n    if (\n      (remainder[2].type === \"word\" || remainder[2].type === \"function\") &&\n      remainder[2].value === \"layer\"\n    ) {\n      if (remainder[1].type !== \"space\") {\n        return result.warn(\"Invalid import layer statement\", { node: atRule })\n      }\n\n      if (remainder[2].nodes) {\n        stmt.layer = [stringify(remainder[2].nodes)];\n      } else {\n        stmt.layer = [\"\"];\n      }\n      remainder = remainder.slice(2);\n    }\n  }\n\n  if (remainder.length > 2) {\n    if (remainder[1].type !== \"space\") {\n      return result.warn(\"Invalid import media statement\", { node: atRule })\n    }\n\n    stmt.media = split(remainder, 2);\n  }\n\n  return stmt\n}\n\nvar assignLayerNames$1 = function (layer, node, state, options) {\n  layer.forEach((layerPart, i) => {\n    if (layerPart.trim() === \"\") {\n      if (options.nameLayer) {\n        layer[i] = options\n          .nameLayer(state.anonymousLayerCounter++, state.rootFilename)\n          .toString();\n      } else {\n        throw node.error(\n          `When using anonymous layers in @import you must also set the \"nameLayer\" plugin option`\n        )\n      }\n    }\n  });\n};\n\n// builtin tooling\nconst path = require$$0;\n\n// internal tooling\nconst joinMedia = joinMedia$1;\nconst joinLayer = joinLayer$1;\nconst resolveId = resolveId$1;\nconst loadContent = loadContent$1;\nconst processContent = processContent$1;\nconst parseStatements = parseStatements$1;\nconst assignLayerNames = assignLayerNames$1;\nconst dataURL = dataUrl;\n\nfunction AtImport(options) {\n  options = {\n    root: process.cwd(),\n    path: [],\n    skipDuplicates: true,\n    resolve: resolveId,\n    load: loadContent,\n    plugins: [],\n    addModulesDirectories: [],\n    nameLayer: null,\n    ...options,\n  };\n\n  options.root = path.resolve(options.root);\n\n  // convert string to an array of a single element\n  if (typeof options.path === \"string\") options.path = [options.path];\n\n  if (!Array.isArray(options.path)) options.path = [];\n\n  options.path = options.path.map(p => path.resolve(options.root, p));\n\n  return {\n    postcssPlugin: \"postcss-import\",\n    Once(styles, { result, atRule, postcss }) {\n      const state = {\n        importedFiles: {},\n        hashFiles: {},\n        rootFilename: null,\n        anonymousLayerCounter: 0,\n      };\n\n      if (styles.source?.input?.file) {\n        state.rootFilename = styles.source.input.file;\n        state.importedFiles[styles.source.input.file] = {};\n      }\n\n      if (options.plugins && !Array.isArray(options.plugins)) {\n        throw new Error(\"plugins option must be an array\")\n      }\n\n      if (options.nameLayer && typeof options.nameLayer !== \"function\") {\n        throw new Error(\"nameLayer option must be a function\")\n      }\n\n      return parseStyles(result, styles, options, state, [], []).then(\n        bundle => {\n          applyRaws(bundle);\n          applyMedia(bundle);\n          applyStyles(bundle, styles);\n        }\n      )\n\n      function applyRaws(bundle) {\n        bundle.forEach((stmt, index) => {\n          if (index === 0) return\n\n          if (stmt.parent) {\n            const { before } = stmt.parent.node.raws;\n            if (stmt.type === \"nodes\") stmt.nodes[0].raws.before = before;\n            else stmt.node.raws.before = before;\n          } else if (stmt.type === \"nodes\") {\n            stmt.nodes[0].raws.before = stmt.nodes[0].raws.before || \"\\n\";\n          }\n        });\n      }\n\n      function applyMedia(bundle) {\n        bundle.forEach(stmt => {\n          if (\n            (!stmt.media.length && !stmt.layer.length) ||\n            stmt.type === \"charset\"\n          ) {\n            return\n          }\n\n          if (stmt.layer.length > 1) {\n            assignLayerNames(stmt.layer, stmt.node, state, options);\n          }\n\n          if (stmt.type === \"import\") {\n            const parts = [stmt.fullUri];\n\n            const media = stmt.media.join(\", \");\n\n            if (stmt.layer.length) {\n              const layerName = stmt.layer.join(\".\");\n\n              let layerParams = \"layer\";\n              if (layerName) {\n                layerParams = `layer(${layerName})`;\n              }\n\n              parts.push(layerParams);\n            }\n\n            if (media) {\n              parts.push(media);\n            }\n\n            stmt.node.params = parts.join(\" \");\n          } else if (stmt.type === \"media\") {\n            if (stmt.layer.length) {\n              const layerNode = atRule({\n                name: \"layer\",\n                params: stmt.layer.join(\".\"),\n                source: stmt.node.source,\n              });\n\n              if (stmt.parentMedia?.length) {\n                const mediaNode = atRule({\n                  name: \"media\",\n                  params: stmt.parentMedia.join(\", \"),\n                  source: stmt.node.source,\n                });\n\n                mediaNode.append(layerNode);\n                layerNode.append(stmt.node);\n                stmt.node = mediaNode;\n              } else {\n                layerNode.append(stmt.node);\n                stmt.node = layerNode;\n              }\n            } else {\n              stmt.node.params = stmt.media.join(\", \");\n            }\n          } else {\n            const { nodes } = stmt;\n            const { parent } = nodes[0];\n\n            let outerAtRule;\n            let innerAtRule;\n            if (stmt.media.length && stmt.layer.length) {\n              const mediaNode = atRule({\n                name: \"media\",\n                params: stmt.media.join(\", \"),\n                source: parent.source,\n              });\n\n              const layerNode = atRule({\n                name: \"layer\",\n                params: stmt.layer.join(\".\"),\n                source: parent.source,\n              });\n\n              mediaNode.append(layerNode);\n              innerAtRule = layerNode;\n              outerAtRule = mediaNode;\n            } else if (stmt.media.length) {\n              const mediaNode = atRule({\n                name: \"media\",\n                params: stmt.media.join(\", \"),\n                source: parent.source,\n              });\n\n              innerAtRule = mediaNode;\n              outerAtRule = mediaNode;\n            } else if (stmt.layer.length) {\n              const layerNode = atRule({\n                name: \"layer\",\n                params: stmt.layer.join(\".\"),\n                source: parent.source,\n              });\n\n              innerAtRule = layerNode;\n              outerAtRule = layerNode;\n            }\n\n            parent.insertBefore(nodes[0], outerAtRule);\n\n            // remove nodes\n            nodes.forEach(node => {\n              node.parent = undefined;\n            });\n\n            // better output\n            nodes[0].raws.before = nodes[0].raws.before || \"\\n\";\n\n            // wrap new rules with media query and/or layer at rule\n            innerAtRule.append(nodes);\n\n            stmt.type = \"media\";\n            stmt.node = outerAtRule;\n            delete stmt.nodes;\n          }\n        });\n      }\n\n      function applyStyles(bundle, styles) {\n        styles.nodes = [];\n\n        // Strip additional statements.\n        bundle.forEach(stmt => {\n          if ([\"charset\", \"import\", \"media\"].includes(stmt.type)) {\n            stmt.node.parent = undefined;\n            styles.append(stmt.node);\n          } else if (stmt.type === \"nodes\") {\n            stmt.nodes.forEach(node => {\n              node.parent = undefined;\n              styles.append(node);\n            });\n          }\n        });\n      }\n\n      function parseStyles(result, styles, options, state, media, layer) {\n        const statements = parseStatements(result, styles);\n\n        return Promise.resolve(statements)\n          .then(stmts => {\n            // process each statement in series\n            return stmts.reduce((promise, stmt) => {\n              return promise.then(() => {\n                stmt.media = joinMedia(media, stmt.media || []);\n                stmt.parentMedia = media;\n                stmt.layer = joinLayer(layer, stmt.layer || []);\n\n                // skip protocol base uri (protocol://url) or protocol-relative\n                if (\n                  stmt.type !== \"import\" ||\n                  /^(?:[a-z]+:)?\\/\\//i.test(stmt.uri)\n                ) {\n                  return\n                }\n\n                if (options.filter && !options.filter(stmt.uri)) {\n                  // rejected by filter\n                  return\n                }\n\n                return resolveImportId(result, stmt, options, state)\n              })\n            }, Promise.resolve())\n          })\n          .then(() => {\n            let charset;\n            const imports = [];\n            const bundle = [];\n\n            function handleCharset(stmt) {\n              if (!charset) charset = stmt;\n              // charsets aren't case-sensitive, so convert to lower case to compare\n              else if (\n                stmt.node.params.toLowerCase() !==\n                charset.node.params.toLowerCase()\n              ) {\n                throw new Error(\n                  `Incompatable @charset statements:\n  ${stmt.node.params} specified in ${stmt.node.source.input.file}\n  ${charset.node.params} specified in ${charset.node.source.input.file}`\n                )\n              }\n            }\n\n            // squash statements and their children\n            statements.forEach(stmt => {\n              if (stmt.type === \"charset\") handleCharset(stmt);\n              else if (stmt.type === \"import\") {\n                if (stmt.children) {\n                  stmt.children.forEach((child, index) => {\n                    if (child.type === \"import\") imports.push(child);\n                    else if (child.type === \"charset\") handleCharset(child);\n                    else bundle.push(child);\n                    // For better output\n                    if (index === 0) child.parent = stmt;\n                  });\n                } else imports.push(stmt);\n              } else if (stmt.type === \"media\" || stmt.type === \"nodes\") {\n                bundle.push(stmt);\n              }\n            });\n\n            return charset\n              ? [charset, ...imports.concat(bundle)]\n              : imports.concat(bundle)\n          })\n      }\n\n      function resolveImportId(result, stmt, options, state) {\n        if (dataURL.isValid(stmt.uri)) {\n          return loadImportContent(result, stmt, stmt.uri, options, state).then(\n            result => {\n              stmt.children = result;\n            }\n          )\n        }\n\n        const atRule = stmt.node;\n        let sourceFile;\n        if (atRule.source?.input?.file) {\n          sourceFile = atRule.source.input.file;\n        }\n        const base = sourceFile\n          ? path.dirname(atRule.source.input.file)\n          : options.root;\n\n        return Promise.resolve(options.resolve(stmt.uri, base, options))\n          .then(paths => {\n            if (!Array.isArray(paths)) paths = [paths];\n            // Ensure that each path is absolute:\n            return Promise.all(\n              paths.map(file => {\n                return !path.isAbsolute(file)\n                  ? resolveId(file, base, options)\n                  : file\n              })\n            )\n          })\n          .then(resolved => {\n            // Add dependency messages:\n            resolved.forEach(file => {\n              result.messages.push({\n                type: \"dependency\",\n                plugin: \"postcss-import\",\n                file,\n                parent: sourceFile,\n              });\n            });\n\n            return Promise.all(\n              resolved.map(file => {\n                return loadImportContent(result, stmt, file, options, state)\n              })\n            )\n          })\n          .then(result => {\n            // Merge loaded statements\n            stmt.children = result.reduce((result, statements) => {\n              return statements ? result.concat(statements) : result\n            }, []);\n          })\n      }\n\n      function loadImportContent(result, stmt, filename, options, state) {\n        const atRule = stmt.node;\n        const { media, layer } = stmt;\n\n        assignLayerNames(layer, atRule, state, options);\n\n        if (options.skipDuplicates) {\n          // skip files already imported at the same scope\n          if (state.importedFiles[filename]?.[media]?.[layer]) {\n            return\n          }\n\n          // save imported files to skip them next time\n          if (!state.importedFiles[filename]) {\n            state.importedFiles[filename] = {};\n          }\n          if (!state.importedFiles[filename][media]) {\n            state.importedFiles[filename][media] = {};\n          }\n          state.importedFiles[filename][media][layer] = true;\n        }\n\n        return Promise.resolve(options.load(filename, options)).then(\n          content => {\n            if (content.trim() === \"\") {\n              result.warn(`${filename} is empty`, { node: atRule });\n              return\n            }\n\n            // skip previous imported files not containing @import rules\n            if (state.hashFiles[content]?.[media]?.[layer]) {\n              return\n            }\n\n            return processContent(\n              result,\n              content,\n              filename,\n              options,\n              postcss\n            ).then(importedResult => {\n              const styles = importedResult.root;\n              result.messages = result.messages.concat(importedResult.messages);\n\n              if (options.skipDuplicates) {\n                const hasImport = styles.some(child => {\n                  return child.type === \"atrule\" && child.name === \"import\"\n                });\n                if (!hasImport) {\n                  // save hash files to skip them next time\n                  if (!state.hashFiles[content]) {\n                    state.hashFiles[content] = {};\n                  }\n                  if (!state.hashFiles[content][media]) {\n                    state.hashFiles[content][media] = {};\n                  }\n                  state.hashFiles[content][media][layer] = true;\n                }\n              }\n\n              // recursion: import @import from imported file\n              return parseStyles(result, styles, options, state, media, layer)\n            })\n          }\n        )\n      }\n    },\n  }\n}\n\nAtImport.postcss = true;\n\nvar postcssImport = AtImport;\n\nvar index = /*#__PURE__*/_mergeNamespaces({\n  __proto__: null,\n  default: postcssImport\n}, [postcssImport]);\n\nexport { index as i };\n"}},"dep-98d07f71.js":{"file":{"contents":"import { fileURLToPath as __cjs_fileURLToPath } from 'node:url';\nimport { dirname as __cjs_dirname } from 'node:path';\nimport { createRequire as __cjs_createRequire } from 'node:module';\n\nconst __filename = __cjs_fileURLToPath(import.meta.url);\nconst __dirname = __cjs_dirname(__filename);\nconst require = __cjs_createRequire(import.meta.url);\nconst __require = require;\nconst UNDEFINED_CODE_POINTS = new Set([\n    65534, 65535, 131070, 131071, 196606, 196607, 262142, 262143, 327678, 327679, 393214,\n    393215, 458750, 458751, 524286, 524287, 589822, 589823, 655358, 655359, 720894,\n    720895, 786430, 786431, 851966, 851967, 917502, 917503, 983038, 983039, 1048574,\n    1048575, 1114110, 1114111,\n]);\nconst REPLACEMENT_CHARACTER = '\\uFFFD';\nvar CODE_POINTS;\n(function (CODE_POINTS) {\n    CODE_POINTS[CODE_POINTS[\"EOF\"] = -1] = \"EOF\";\n    CODE_POINTS[CODE_POINTS[\"NULL\"] = 0] = \"NULL\";\n    CODE_POINTS[CODE_POINTS[\"TABULATION\"] = 9] = \"TABULATION\";\n    CODE_POINTS[CODE_POINTS[\"CARRIAGE_RETURN\"] = 13] = \"CARRIAGE_RETURN\";\n    CODE_POINTS[CODE_POINTS[\"LINE_FEED\"] = 10] = \"LINE_FEED\";\n    CODE_POINTS[CODE_POINTS[\"FORM_FEED\"] = 12] = \"FORM_FEED\";\n    CODE_POINTS[CODE_POINTS[\"SPACE\"] = 32] = \"SPACE\";\n    CODE_POINTS[CODE_POINTS[\"EXCLAMATION_MARK\"] = 33] = \"EXCLAMATION_MARK\";\n    CODE_POINTS[CODE_POINTS[\"QUOTATION_MARK\"] = 34] = \"QUOTATION_MARK\";\n    CODE_POINTS[CODE_POINTS[\"NUMBER_SIGN\"] = 35] = \"NUMBER_SIGN\";\n    CODE_POINTS[CODE_POINTS[\"AMPERSAND\"] = 38] = \"AMPERSAND\";\n    CODE_POINTS[CODE_POINTS[\"APOSTROPHE\"] = 39] = \"APOSTROPHE\";\n    CODE_POINTS[CODE_POINTS[\"HYPHEN_MINUS\"] = 45] = \"HYPHEN_MINUS\";\n    CODE_POINTS[CODE_POINTS[\"SOLIDUS\"] = 47] = \"SOLIDUS\";\n    CODE_POINTS[CODE_POINTS[\"DIGIT_0\"] = 48] = \"DIGIT_0\";\n    CODE_POINTS[CODE_POINTS[\"DIGIT_9\"] = 57] = \"DIGIT_9\";\n    CODE_POINTS[CODE_POINTS[\"SEMICOLON\"] = 59] = \"SEMICOLON\";\n    CODE_POINTS[CODE_POINTS[\"LESS_THAN_SIGN\"] = 60] = \"LESS_THAN_SIGN\";\n    CODE_POINTS[CODE_POINTS[\"EQUALS_SIGN\"] = 61] = \"EQUALS_SIGN\";\n    CODE_POINTS[CODE_POINTS[\"GREATER_THAN_SIGN\"] = 62] = \"GREATER_THAN_SIGN\";\n    CODE_POINTS[CODE_POINTS[\"QUESTION_MARK\"] = 63] = \"QUESTION_MARK\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_CAPITAL_A\"] = 65] = \"LATIN_CAPITAL_A\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_CAPITAL_F\"] = 70] = \"LATIN_CAPITAL_F\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_CAPITAL_X\"] = 88] = \"LATIN_CAPITAL_X\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_CAPITAL_Z\"] = 90] = \"LATIN_CAPITAL_Z\";\n    CODE_POINTS[CODE_POINTS[\"RIGHT_SQUARE_BRACKET\"] = 93] = \"RIGHT_SQUARE_BRACKET\";\n    CODE_POINTS[CODE_POINTS[\"GRAVE_ACCENT\"] = 96] = \"GRAVE_ACCENT\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_SMALL_A\"] = 97] = \"LATIN_SMALL_A\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_SMALL_F\"] = 102] = \"LATIN_SMALL_F\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_SMALL_X\"] = 120] = \"LATIN_SMALL_X\";\n    CODE_POINTS[CODE_POINTS[\"LATIN_SMALL_Z\"] = 122] = \"LATIN_SMALL_Z\";\n    CODE_POINTS[CODE_POINTS[\"REPLACEMENT_CHARACTER\"] = 65533] = \"REPLACEMENT_CHARACTER\";\n})(CODE_POINTS = CODE_POINTS || (CODE_POINTS = {}));\nconst SEQUENCES = {\n    DASH_DASH: '--',\n    CDATA_START: '[CDATA[',\n    DOCTYPE: 'doctype',\n    SCRIPT: 'script',\n    PUBLIC: 'public',\n    SYSTEM: 'system',\n};\n//Surrogates\nfunction isSurrogate(cp) {\n    return cp >= 55296 && cp <= 57343;\n}\nfunction isSurrogatePair(cp) {\n    return cp >= 56320 && cp <= 57343;\n}\nfunction getSurrogatePairCodePoint(cp1, cp2) {\n    return (cp1 - 55296) * 1024 + 9216 + cp2;\n}\n//NOTE: excluding NULL and ASCII whitespace\nfunction isControlCodePoint(cp) {\n    return ((cp !== 0x20 && cp !== 0x0a && cp !== 0x0d && cp !== 0x09 && cp !== 0x0c && cp >= 0x01 && cp <= 0x1f) ||\n        (cp >= 0x7f && cp <= 0x9f));\n}\nfunction isUndefinedCodePoint(cp) {\n    return (cp >= 64976 && cp <= 65007) || UNDEFINED_CODE_POINTS.has(cp);\n}\n\nvar ERR;\n(function (ERR) {\n    ERR[\"controlCharacterInInputStream\"] = \"control-character-in-input-stream\";\n    ERR[\"noncharacterInInputStream\"] = \"noncharacter-in-input-stream\";\n    ERR[\"surrogateInInputStream\"] = \"surrogate-in-input-stream\";\n    ERR[\"nonVoidHtmlElementStartTagWithTrailingSolidus\"] = \"non-void-html-element-start-tag-with-trailing-solidus\";\n    ERR[\"endTagWithAttributes\"] = \"end-tag-with-attributes\";\n    ERR[\"endTagWithTrailingSolidus\"] = \"end-tag-with-trailing-solidus\";\n    ERR[\"unexpectedSolidusInTag\"] = \"unexpected-solidus-in-tag\";\n    ERR[\"unexpectedNullCharacter\"] = \"unexpected-null-character\";\n    ERR[\"unexpectedQuestionMarkInsteadOfTagName\"] = \"unexpected-question-mark-instead-of-tag-name\";\n    ERR[\"invalidFirstCharacterOfTagName\"] = \"invalid-first-character-of-tag-name\";\n    ERR[\"unexpectedEqualsSignBeforeAttributeName\"] = \"unexpected-equals-sign-before-attribute-name\";\n    ERR[\"missingEndTagName\"] = \"missing-end-tag-name\";\n    ERR[\"unexpectedCharacterInAttributeName\"] = \"unexpected-character-in-attribute-name\";\n    ERR[\"unknownNamedCharacterReference\"] = \"unknown-named-character-reference\";\n    ERR[\"missingSemicolonAfterCharacterReference\"] = \"missing-semicolon-after-character-reference\";\n    ERR[\"unexpectedCharacterAfterDoctypeSystemIdentifier\"] = \"unexpected-character-after-doctype-system-identifier\";\n    ERR[\"unexpectedCharacterInUnquotedAttributeValue\"] = \"unexpected-character-in-unquoted-attribute-value\";\n    ERR[\"eofBeforeTagName\"] = \"eof-before-tag-name\";\n    ERR[\"eofInTag\"] = \"eof-in-tag\";\n    ERR[\"missingAttributeValue\"] = \"missing-attribute-value\";\n    ERR[\"missingWhitespaceBetweenAttributes\"] = \"missing-whitespace-between-attributes\";\n    ERR[\"missingWhitespaceAfterDoctypePublicKeyword\"] = \"missing-whitespace-after-doctype-public-keyword\";\n    ERR[\"missingWhitespaceBetweenDoctypePublicAndSystemIdentifiers\"] = \"missing-whitespace-between-doctype-public-and-system-identifiers\";\n    ERR[\"missingWhitespaceAfterDoctypeSystemKeyword\"] = \"missing-whitespace-after-doctype-system-keyword\";\n    ERR[\"missingQuoteBeforeDoctypePublicIdentifier\"] = \"missing-quote-before-doctype-public-identifier\";\n    ERR[\"missingQuoteBeforeDoctypeSystemIdentifier\"] = \"missing-quote-before-doctype-system-identifier\";\n    ERR[\"missingDoctypePublicIdentifier\"] = \"missing-doctype-public-identifier\";\n    ERR[\"missingDoctypeSystemIdentifier\"] = \"missing-doctype-system-identifier\";\n    ERR[\"abruptDoctypePublicIdentifier\"] = \"abrupt-doctype-public-identifier\";\n    ERR[\"abruptDoctypeSystemIdentifier\"] = \"abrupt-doctype-system-identifier\";\n    ERR[\"cdataInHtmlContent\"] = \"cdata-in-html-content\";\n    ERR[\"incorrectlyOpenedComment\"] = \"incorrectly-opened-comment\";\n    ERR[\"eofInScriptHtmlCommentLikeText\"] = \"eof-in-script-html-comment-like-text\";\n    ERR[\"eofInDoctype\"] = \"eof-in-doctype\";\n    ERR[\"nestedComment\"] = \"nested-comment\";\n    ERR[\"abruptClosingOfEmptyComment\"] = \"abrupt-closing-of-empty-comment\";\n    ERR[\"eofInComment\"] = \"eof-in-comment\";\n    ERR[\"incorrectlyClosedComment\"] = \"incorrectly-closed-comment\";\n    ERR[\"eofInCdata\"] = \"eof-in-cdata\";\n    ERR[\"absenceOfDigitsInNumericCharacterReference\"] = \"absence-of-digits-in-numeric-character-reference\";\n    ERR[\"nullCharacterReference\"] = \"null-character-reference\";\n    ERR[\"surrogateCharacterReference\"] = \"surrogate-character-reference\";\n    ERR[\"characterReferenceOutsideUnicodeRange\"] = \"character-reference-outside-unicode-range\";\n    ERR[\"controlCharacterReference\"] = \"control-character-reference\";\n    ERR[\"noncharacterCharacterReference\"] = \"noncharacter-character-reference\";\n    ERR[\"missingWhitespaceBeforeDoctypeName\"] = \"missing-whitespace-before-doctype-name\";\n    ERR[\"missingDoctypeName\"] = \"missing-doctype-name\";\n    ERR[\"invalidCharacterSequenceAfterDoctypeName\"] = \"invalid-character-sequence-after-doctype-name\";\n    ERR[\"duplicateAttribute\"] = \"duplicate-attribute\";\n    ERR[\"nonConformingDoctype\"] = \"non-conforming-doctype\";\n    ERR[\"missingDoctype\"] = \"missing-doctype\";\n    ERR[\"misplacedDoctype\"] = \"misplaced-doctype\";\n    ERR[\"endTagWithoutMatchingOpenElement\"] = \"end-tag-without-matching-open-element\";\n    ERR[\"closingOfElementWithOpenChildElements\"] = \"closing-of-element-with-open-child-elements\";\n    ERR[\"disallowedContentInNoscriptInHead\"] = \"disallowed-content-in-noscript-in-head\";\n    ERR[\"openElementsLeftAfterEof\"] = \"open-elements-left-after-eof\";\n    ERR[\"abandonedHeadElementChild\"] = \"abandoned-head-element-child\";\n    ERR[\"misplacedStartTagForHeadElement\"] = \"misplaced-start-tag-for-head-element\";\n    ERR[\"nestedNoscriptInHead\"] = \"nested-noscript-in-head\";\n    ERR[\"eofInElementThatCanContainOnlyText\"] = \"eof-in-element-that-can-contain-only-text\";\n})(ERR = ERR || (ERR = {}));\n\n//Const\nconst DEFAULT_BUFFER_WATERLINE = 1 << 16;\n//Preprocessor\n//NOTE: HTML input preprocessing\n//(see: http://www.whatwg.org/specs/web-apps/current-work/multipage/parsing.html#preprocessing-the-input-stream)\nclass Preprocessor {\n    constructor(handler) {\n        this.handler = handler;\n        this.html = '';\n        this.pos = -1;\n        // NOTE: Initial `lastGapPos` is -2, to ensure `col` on initialisation is 0\n        this.lastGapPos = -2;\n        this.gapStack = [];\n        this.skipNextNewLine = false;\n        this.lastChunkWritten = false;\n        this.endOfChunkHit = false;\n        this.bufferWaterline = DEFAULT_BUFFER_WATERLINE;\n        this.isEol = false;\n        this.lineStartPos = 0;\n        this.droppedBufferSize = 0;\n        this.line = 1;\n        //NOTE: avoid reporting errors twice on advance/retreat\n        this.lastErrOffset = -1;\n    }\n    /** The column on the current line. If we just saw a gap (eg. a surrogate pair), return the index before. */\n    get col() {\n        return this.pos - this.lineStartPos + Number(this.lastGapPos !== this.pos);\n    }\n    get offset() {\n        return this.droppedBufferSize + this.pos;\n    }\n    getError(code) {\n        const { line, col, offset } = this;\n        return {\n            code,\n            startLine: line,\n            endLine: line,\n            startCol: col,\n            endCol: col,\n            startOffset: offset,\n            endOffset: offset,\n        };\n    }\n    _err(code) {\n        if (this.handler.onParseError && this.lastErrOffset !== this.offset) {\n            this.lastErrOffset = this.offset;\n            this.handler.onParseError(this.getError(code));\n        }\n    }\n    _addGap() {\n        this.gapStack.push(this.lastGapPos);\n        this.lastGapPos = this.pos;\n    }\n    _processSurrogate(cp) {\n        //NOTE: try to peek a surrogate pair\n        if (this.pos !== this.html.length - 1) {\n            const nextCp = this.html.charCodeAt(this.pos + 1);\n            if (isSurrogatePair(nextCp)) {\n                //NOTE: we have a surrogate pair. Peek pair character and recalculate code point.\n                this.pos++;\n                //NOTE: add a gap that should be avoided during retreat\n                this._addGap();\n                return getSurrogatePairCodePoint(cp, nextCp);\n            }\n        }\n        //NOTE: we are at the end of a chunk, therefore we can't infer the surrogate pair yet.\n        else if (!this.lastChunkWritten) {\n            this.endOfChunkHit = true;\n            return CODE_POINTS.EOF;\n        }\n        //NOTE: isolated surrogate\n        this._err(ERR.surrogateInInputStream);\n        return cp;\n    }\n    willDropParsedChunk() {\n        return this.pos > this.bufferWaterline;\n    }\n    dropParsedChunk() {\n        if (this.willDropParsedChunk()) {\n            this.html = this.html.substring(this.pos);\n            this.lineStartPos -= this.pos;\n            this.droppedBufferSize += this.pos;\n            this.pos = 0;\n            this.lastGapPos = -2;\n            this.gapStack.length = 0;\n        }\n    }\n    write(chunk, isLastChunk) {\n        if (this.html.length > 0) {\n            this.html += chunk;\n        }\n        else {\n            this.html = chunk;\n        }\n        this.endOfChunkHit = false;\n        this.lastChunkWritten = isLastChunk;\n    }\n    insertHtmlAtCurrentPos(chunk) {\n        this.html = this.html.substring(0, this.pos + 1) + chunk + this.html.substring(this.pos + 1);\n        this.endOfChunkHit = false;\n    }\n    startsWith(pattern, caseSensitive) {\n        // Check if our buffer has enough characters\n        if (this.pos + pattern.length > this.html.length) {\n            this.endOfChunkHit = !this.lastChunkWritten;\n            return false;\n        }\n        if (caseSensitive) {\n            return this.html.startsWith(pattern, this.pos);\n        }\n        for (let i = 0; i < pattern.length; i++) {\n            const cp = this.html.charCodeAt(this.pos + i) | 0x20;\n            if (cp !== pattern.charCodeAt(i)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    peek(offset) {\n        const pos = this.pos + offset;\n        if (pos >= this.html.length) {\n            this.endOfChunkHit = !this.lastChunkWritten;\n            return CODE_POINTS.EOF;\n        }\n        const code = this.html.charCodeAt(pos);\n        return code === CODE_POINTS.CARRIAGE_RETURN ? CODE_POINTS.LINE_FEED : code;\n    }\n    advance() {\n        this.pos++;\n        //NOTE: LF should be in the last column of the line\n        if (this.isEol) {\n            this.isEol = false;\n            this.line++;\n            this.lineStartPos = this.pos;\n        }\n        if (this.pos >= this.html.length) {\n            this.endOfChunkHit = !this.lastChunkWritten;\n            return CODE_POINTS.EOF;\n        }\n        let cp = this.html.charCodeAt(this.pos);\n        //NOTE: all U+000D CARRIAGE RETURN (CR) characters must be converted to U+000A LINE FEED (LF) characters\n        if (cp === CODE_POINTS.CARRIAGE_RETURN) {\n            this.isEol = true;\n            this.skipNextNewLine = true;\n            return CODE_POINTS.LINE_FEED;\n        }\n        //NOTE: any U+000A LINE FEED (LF) characters that immediately follow a U+000D CARRIAGE RETURN (CR) character\n        //must be ignored.\n        if (cp === CODE_POINTS.LINE_FEED) {\n            this.isEol = true;\n            if (this.skipNextNewLine) {\n                // `line` will be bumped again in the recursive call.\n                this.line--;\n                this.skipNextNewLine = false;\n                this._addGap();\n                return this.advance();\n            }\n        }\n        this.skipNextNewLine = false;\n        if (isSurrogate(cp)) {\n            cp = this._processSurrogate(cp);\n        }\n        //OPTIMIZATION: first check if code point is in the common allowed\n        //range (ASCII alphanumeric, whitespaces, big chunk of BMP)\n        //before going into detailed performance cost validation.\n        const isCommonValidRange = this.handler.onParseError === null ||\n            (cp > 0x1f && cp < 0x7f) ||\n            cp === CODE_POINTS.LINE_FEED ||\n            cp === CODE_POINTS.CARRIAGE_RETURN ||\n            (cp > 0x9f && cp < 64976);\n        if (!isCommonValidRange) {\n            this._checkForProblematicCharacters(cp);\n        }\n        return cp;\n    }\n    _checkForProblematicCharacters(cp) {\n        if (isControlCodePoint(cp)) {\n            this._err(ERR.controlCharacterInInputStream);\n        }\n        else if (isUndefinedCodePoint(cp)) {\n            this._err(ERR.noncharacterInInputStream);\n        }\n    }\n    retreat(count) {\n        this.pos -= count;\n        while (this.pos < this.lastGapPos) {\n            this.lastGapPos = this.gapStack.pop();\n            this.pos--;\n        }\n        this.isEol = false;\n    }\n}\n\nvar TokenType;\n(function (TokenType) {\n    TokenType[TokenType[\"CHARACTER\"] = 0] = \"CHARACTER\";\n    TokenType[TokenType[\"NULL_CHARACTER\"] = 1] = \"NULL_CHARACTER\";\n    TokenType[TokenType[\"WHITESPACE_CHARACTER\"] = 2] = \"WHITESPACE_CHARACTER\";\n    TokenType[TokenType[\"START_TAG\"] = 3] = \"START_TAG\";\n    TokenType[TokenType[\"END_TAG\"] = 4] = \"END_TAG\";\n    TokenType[TokenType[\"COMMENT\"] = 5] = \"COMMENT\";\n    TokenType[TokenType[\"DOCTYPE\"] = 6] = \"DOCTYPE\";\n    TokenType[TokenType[\"EOF\"] = 7] = \"EOF\";\n    TokenType[TokenType[\"HIBERNATION\"] = 8] = \"HIBERNATION\";\n})(TokenType = TokenType || (TokenType = {}));\nfunction getTokenAttr(token, attrName) {\n    for (let i = token.attrs.length - 1; i >= 0; i--) {\n        if (token.attrs[i].name === attrName) {\n            return token.attrs[i].value;\n        }\n    }\n    return null;\n}\n\nvar token = {\n    __proto__: null,\n    get TokenType () { return TokenType; },\n    getTokenAttr: getTokenAttr\n};\n\n// Generated using scripts/write-decode-map.ts\nvar htmlDecodeTree = new Uint16Array(\n// prettier-ignore\n\"\\u1d41<\\xd5\\u0131\\u028a\\u049d\\u057b\\u05d0\\u0675\\u06de\\u07a2\\u07d6\\u080f\\u0a4a\\u0a91\\u0da1\\u0e6d\\u0f09\\u0f26\\u10ca\\u1228\\u12e1\\u1415\\u149d\\u14c3\\u14df\\u1525\\0\\0\\0\\0\\0\\0\\u156b\\u16cd\\u198d\\u1c12\\u1ddd\\u1f7e\\u2060\\u21b0\\u228d\\u23c0\\u23fb\\u2442\\u2824\\u2912\\u2d08\\u2e48\\u2fce\\u3016\\u32ba\\u3639\\u37ac\\u38fe\\u3a28\\u3a71\\u3ae0\\u3b2e\\u0800EMabcfglmnoprstu\\\\bfms\\x7f\\x84\\x8b\\x90\\x95\\x98\\xa6\\xb3\\xb9\\xc8\\xcflig\\u803b\\xc6\\u40c6P\\u803b&\\u4026cute\\u803b\\xc1\\u40c1reve;\\u4102\\u0100iyx}rc\\u803b\\xc2\\u40c2;\\u4410r;\\uc000\\ud835\\udd04rave\\u803b\\xc0\\u40c0pha;\\u4391acr;\\u4100d;\\u6a53\\u0100gp\\x9d\\xa1on;\\u4104f;\\uc000\\ud835\\udd38plyFunction;\\u6061ing\\u803b\\xc5\\u40c5\\u0100cs\\xbe\\xc3r;\\uc000\\ud835\\udc9cign;\\u6254ilde\\u803b\\xc3\\u40c3ml\\u803b\\xc4\\u40c4\\u0400aceforsu\\xe5\\xfb\\xfe\\u0117\\u011c\\u0122\\u0127\\u012a\\u0100cr\\xea\\xf2kslash;\\u6216\\u0176\\xf6\\xf8;\\u6ae7ed;\\u6306y;\\u4411\\u0180crt\\u0105\\u010b\\u0114ause;\\u6235noullis;\\u612ca;\\u4392r;\\uc000\\ud835\\udd05pf;\\uc000\\ud835\\udd39eve;\\u42d8c\\xf2\\u0113mpeq;\\u624e\\u0700HOacdefhilorsu\\u014d\\u0151\\u0156\\u0180\\u019e\\u01a2\\u01b5\\u01b7\\u01ba\\u01dc\\u0215\\u0273\\u0278\\u027ecy;\\u4427PY\\u803b\\xa9\\u40a9\\u0180cpy\\u015d\\u0162\\u017aute;\\u4106\\u0100;i\\u0167\\u0168\\u62d2talDifferentialD;\\u6145leys;\\u612d\\u0200aeio\\u0189\\u018e\\u0194\\u0198ron;\\u410cdil\\u803b\\xc7\\u40c7rc;\\u4108nint;\\u6230ot;\\u410a\\u0100dn\\u01a7\\u01adilla;\\u40b8terDot;\\u40b7\\xf2\\u017fi;\\u43a7rcle\\u0200DMPT\\u01c7\\u01cb\\u01d1\\u01d6ot;\\u6299inus;\\u6296lus;\\u6295imes;\\u6297o\\u0100cs\\u01e2\\u01f8kwiseContourIntegral;\\u6232eCurly\\u0100DQ\\u0203\\u020foubleQuote;\\u601duote;\\u6019\\u0200lnpu\\u021e\\u0228\\u0247\\u0255on\\u0100;e\\u0225\\u0226\\u6237;\\u6a74\\u0180git\\u022f\\u0236\\u023aruent;\\u6261nt;\\u622fourIntegral;\\u622e\\u0100fr\\u024c\\u024e;\\u6102oduct;\\u6210nterClockwiseContourIntegral;\\u6233oss;\\u6a2fcr;\\uc000\\ud835\\udc9ep\\u0100;C\\u0284\\u0285\\u62d3ap;\\u624d\\u0580DJSZacefios\\u02a0\\u02ac\\u02b0\\u02b4\\u02b8\\u02cb\\u02d7\\u02e1\\u02e6\\u0333\\u048d\\u0100;o\\u0179\\u02a5trahd;\\u6911cy;\\u4402cy;\\u4405cy;\\u440f\\u0180grs\\u02bf\\u02c4\\u02c7ger;\\u6021r;\\u61a1hv;\\u6ae4\\u0100ay\\u02d0\\u02d5ron;\\u410e;\\u4414l\\u0100;t\\u02dd\\u02de\\u6207a;\\u4394r;\\uc000\\ud835\\udd07\\u0100af\\u02eb\\u0327\\u0100cm\\u02f0\\u0322ritical\\u0200ADGT\\u0300\\u0306\\u0316\\u031ccute;\\u40b4o\\u0174\\u030b\\u030d;\\u42d9bleAcute;\\u42ddrave;\\u4060ilde;\\u42dcond;\\u62c4ferentialD;\\u6146\\u0470\\u033d\\0\\0\\0\\u0342\\u0354\\0\\u0405f;\\uc000\\ud835\\udd3b\\u0180;DE\\u0348\\u0349\\u034d\\u40a8ot;\\u60dcqual;\\u6250ble\\u0300CDLRUV\\u0363\\u0372\\u0382\\u03cf\\u03e2\\u03f8ontourIntegra\\xec\\u0239o\\u0274\\u0379\\0\\0\\u037b\\xbb\\u0349nArrow;\\u61d3\\u0100eo\\u0387\\u03a4ft\\u0180ART\\u0390\\u0396\\u03a1rrow;\\u61d0ightArrow;\\u61d4e\\xe5\\u02cang\\u0100LR\\u03ab\\u03c4eft\\u0100AR\\u03b3\\u03b9rrow;\\u67f8ightArrow;\\u67faightArrow;\\u67f9ight\\u0100AT\\u03d8\\u03derrow;\\u61d2ee;\\u62a8p\\u0241\\u03e9\\0\\0\\u03efrrow;\\u61d1ownArrow;\\u61d5erticalBar;\\u6225n\\u0300ABLRTa\\u0412\\u042a\\u0430\\u045e\\u047f\\u037crrow\\u0180;BU\\u041d\\u041e\\u0422\\u6193ar;\\u6913pArrow;\\u61f5reve;\\u4311eft\\u02d2\\u043a\\0\\u0446\\0\\u0450ightVector;\\u6950eeVector;\\u695eector\\u0100;B\\u0459\\u045a\\u61bdar;\\u6956ight\\u01d4\\u0467\\0\\u0471eeVector;\\u695fector\\u0100;B\\u047a\\u047b\\u61c1ar;\\u6957ee\\u0100;A\\u0486\\u0487\\u62a4rrow;\\u61a7\\u0100ct\\u0492\\u0497r;\\uc000\\ud835\\udc9frok;\\u4110\\u0800NTacdfglmopqstux\\u04bd\\u04c0\\u04c4\\u04cb\\u04de\\u04e2\\u04e7\\u04ee\\u04f5\\u0521\\u052f\\u0536\\u0552\\u055d\\u0560\\u0565G;\\u414aH\\u803b\\xd0\\u40d0cute\\u803b\\xc9\\u40c9\\u0180aiy\\u04d2\\u04d7\\u04dcron;\\u411arc\\u803b\\xca\\u40ca;\\u442dot;\\u4116r;\\uc000\\ud835\\udd08rave\\u803b\\xc8\\u40c8ement;\\u6208\\u0100ap\\u04fa\\u04fecr;\\u4112ty\\u0253\\u0506\\0\\0\\u0512mallSquare;\\u65fberySmallSquare;\\u65ab\\u0100gp\\u0526\\u052aon;\\u4118f;\\uc000\\ud835\\udd3csilon;\\u4395u\\u0100ai\\u053c\\u0549l\\u0100;T\\u0542\\u0543\\u6a75ilde;\\u6242librium;\\u61cc\\u0100ci\\u0557\\u055ar;\\u6130m;\\u6a73a;\\u4397ml\\u803b\\xcb\\u40cb\\u0100ip\\u056a\\u056fsts;\\u6203onentialE;\\u6147\\u0280cfios\\u0585\\u0588\\u058d\\u05b2\\u05ccy;\\u4424r;\\uc000\\ud835\\udd09lled\\u0253\\u0597\\0\\0\\u05a3mallSquare;\\u65fcerySmallSquare;\\u65aa\\u0370\\u05ba\\0\\u05bf\\0\\0\\u05c4f;\\uc000\\ud835\\udd3dAll;\\u6200riertrf;\\u6131c\\xf2\\u05cb\\u0600JTabcdfgorst\\u05e8\\u05ec\\u05ef\\u05fa\\u0600\\u0612\\u0616\\u061b\\u061d\\u0623\\u066c\\u0672cy;\\u4403\\u803b>\\u403emma\\u0100;d\\u05f7\\u05f8\\u4393;\\u43dcreve;\\u411e\\u0180eiy\\u0607\\u060c\\u0610dil;\\u4122rc;\\u411c;\\u4413ot;\\u4120r;\\uc000\\ud835\\udd0a;\\u62d9pf;\\uc000\\ud835\\udd3eeater\\u0300EFGLST\\u0635\\u0644\\u064e\\u0656\\u065b\\u0666qual\\u0100;L\\u063e\\u063f\\u6265ess;\\u62dbullEqual;\\u6267reater;\\u6aa2ess;\\u6277lantEqual;\\u6a7eilde;\\u6273cr;\\uc000\\ud835\\udca2;\\u626b\\u0400Aacfiosu\\u0685\\u068b\\u0696\\u069b\\u069e\\u06aa\\u06be\\u06caRDcy;\\u442a\\u0100ct\\u0690\\u0694ek;\\u42c7;\\u405eirc;\\u4124r;\\u610clbertSpace;\\u610b\\u01f0\\u06af\\0\\u06b2f;\\u610dizontalLine;\\u6500\\u0100ct\\u06c3\\u06c5\\xf2\\u06a9rok;\\u4126mp\\u0144\\u06d0\\u06d8ownHum\\xf0\\u012fqual;\\u624f\\u0700EJOacdfgmnostu\\u06fa\\u06fe\\u0703\\u0707\\u070e\\u071a\\u071e\\u0721\\u0728\\u0744\\u0778\\u078b\\u078f\\u0795cy;\\u4415lig;\\u4132cy;\\u4401cute\\u803b\\xcd\\u40cd\\u0100iy\\u0713\\u0718rc\\u803b\\xce\\u40ce;\\u4418ot;\\u4130r;\\u6111rave\\u803b\\xcc\\u40cc\\u0180;ap\\u0720\\u072f\\u073f\\u0100cg\\u0734\\u0737r;\\u412ainaryI;\\u6148lie\\xf3\\u03dd\\u01f4\\u0749\\0\\u0762\\u0100;e\\u074d\\u074e\\u622c\\u0100gr\\u0753\\u0758ral;\\u622bsection;\\u62c2isible\\u0100CT\\u076c\\u0772omma;\\u6063imes;\\u6062\\u0180gpt\\u077f\\u0783\\u0788on;\\u412ef;\\uc000\\ud835\\udd40a;\\u4399cr;\\u6110ilde;\\u4128\\u01eb\\u079a\\0\\u079ecy;\\u4406l\\u803b\\xcf\\u40cf\\u0280cfosu\\u07ac\\u07b7\\u07bc\\u07c2\\u07d0\\u0100iy\\u07b1\\u07b5rc;\\u4134;\\u4419r;\\uc000\\ud835\\udd0dpf;\\uc000\\ud835\\udd41\\u01e3\\u07c7\\0\\u07ccr;\\uc000\\ud835\\udca5rcy;\\u4408kcy;\\u4404\\u0380HJacfos\\u07e4\\u07e8\\u07ec\\u07f1\\u07fd\\u0802\\u0808cy;\\u4425cy;\\u440cppa;\\u439a\\u0100ey\\u07f6\\u07fbdil;\\u4136;\\u441ar;\\uc000\\ud835\\udd0epf;\\uc000\\ud835\\udd42cr;\\uc000\\ud835\\udca6\\u0580JTaceflmost\\u0825\\u0829\\u082c\\u0850\\u0863\\u09b3\\u09b8\\u09c7\\u09cd\\u0a37\\u0a47cy;\\u4409\\u803b<\\u403c\\u0280cmnpr\\u0837\\u083c\\u0841\\u0844\\u084dute;\\u4139bda;\\u439bg;\\u67ealacetrf;\\u6112r;\\u619e\\u0180aey\\u0857\\u085c\\u0861ron;\\u413ddil;\\u413b;\\u441b\\u0100fs\\u0868\\u0970t\\u0500ACDFRTUVar\\u087e\\u08a9\\u08b1\\u08e0\\u08e6\\u08fc\\u092f\\u095b\\u0390\\u096a\\u0100nr\\u0883\\u088fgleBracket;\\u67e8row\\u0180;BR\\u0899\\u089a\\u089e\\u6190ar;\\u61e4ightArrow;\\u61c6eiling;\\u6308o\\u01f5\\u08b7\\0\\u08c3bleBracket;\\u67e6n\\u01d4\\u08c8\\0\\u08d2eeVector;\\u6961ector\\u0100;B\\u08db\\u08dc\\u61c3ar;\\u6959loor;\\u630aight\\u0100AV\\u08ef\\u08f5rrow;\\u6194ector;\\u694e\\u0100er\\u0901\\u0917e\\u0180;AV\\u0909\\u090a\\u0910\\u62a3rrow;\\u61a4ector;\\u695aiangle\\u0180;BE\\u0924\\u0925\\u0929\\u62b2ar;\\u69cfqual;\\u62b4p\\u0180DTV\\u0937\\u0942\\u094cownVector;\\u6951eeVector;\\u6960ector\\u0100;B\\u0956\\u0957\\u61bfar;\\u6958ector\\u0100;B\\u0965\\u0966\\u61bcar;\\u6952ight\\xe1\\u039cs\\u0300EFGLST\\u097e\\u098b\\u0995\\u099d\\u09a2\\u09adqualGreater;\\u62daullEqual;\\u6266reater;\\u6276ess;\\u6aa1lantEqual;\\u6a7dilde;\\u6272r;\\uc000\\ud835\\udd0f\\u0100;e\\u09bd\\u09be\\u62d8ftarrow;\\u61daidot;\\u413f\\u0180npw\\u09d4\\u0a16\\u0a1bg\\u0200LRlr\\u09de\\u09f7\\u0a02\\u0a10eft\\u0100AR\\u09e6\\u09ecrrow;\\u67f5ightArrow;\\u67f7ightArrow;\\u67f6eft\\u0100ar\\u03b3\\u0a0aight\\xe1\\u03bfight\\xe1\\u03caf;\\uc000\\ud835\\udd43er\\u0100LR\\u0a22\\u0a2ceftArrow;\\u6199ightArrow;\\u6198\\u0180cht\\u0a3e\\u0a40\\u0a42\\xf2\\u084c;\\u61b0rok;\\u4141;\\u626a\\u0400acefiosu\\u0a5a\\u0a5d\\u0a60\\u0a77\\u0a7c\\u0a85\\u0a8b\\u0a8ep;\\u6905y;\\u441c\\u0100dl\\u0a65\\u0a6fiumSpace;\\u605flintrf;\\u6133r;\\uc000\\ud835\\udd10nusPlus;\\u6213pf;\\uc000\\ud835\\udd44c\\xf2\\u0a76;\\u439c\\u0480Jacefostu\\u0aa3\\u0aa7\\u0aad\\u0ac0\\u0b14\\u0b19\\u0d91\\u0d97\\u0d9ecy;\\u440acute;\\u4143\\u0180aey\\u0ab4\\u0ab9\\u0aberon;\\u4147dil;\\u4145;\\u441d\\u0180gsw\\u0ac7\\u0af0\\u0b0eative\\u0180MTV\\u0ad3\\u0adf\\u0ae8ediumSpace;\\u600bhi\\u0100cn\\u0ae6\\u0ad8\\xeb\\u0ad9eryThi\\xee\\u0ad9ted\\u0100GL\\u0af8\\u0b06reaterGreate\\xf2\\u0673essLes\\xf3\\u0a48Line;\\u400ar;\\uc000\\ud835\\udd11\\u0200Bnpt\\u0b22\\u0b28\\u0b37\\u0b3areak;\\u6060BreakingSpace;\\u40a0f;\\u6115\\u0680;CDEGHLNPRSTV\\u0b55\\u0b56\\u0b6a\\u0b7c\\u0ba1\\u0beb\\u0c04\\u0c5e\\u0c84\\u0ca6\\u0cd8\\u0d61\\u0d85\\u6aec\\u0100ou\\u0b5b\\u0b64ngruent;\\u6262pCap;\\u626doubleVerticalBar;\\u6226\\u0180lqx\\u0b83\\u0b8a\\u0b9bement;\\u6209ual\\u0100;T\\u0b92\\u0b93\\u6260ilde;\\uc000\\u2242\\u0338ists;\\u6204reater\\u0380;EFGLST\\u0bb6\\u0bb7\\u0bbd\\u0bc9\\u0bd3\\u0bd8\\u0be5\\u626fqual;\\u6271ullEqual;\\uc000\\u2267\\u0338reater;\\uc000\\u226b\\u0338ess;\\u6279lantEqual;\\uc000\\u2a7e\\u0338ilde;\\u6275ump\\u0144\\u0bf2\\u0bfdownHump;\\uc000\\u224e\\u0338qual;\\uc000\\u224f\\u0338e\\u0100fs\\u0c0a\\u0c27tTriangle\\u0180;BE\\u0c1a\\u0c1b\\u0c21\\u62eaar;\\uc000\\u29cf\\u0338qual;\\u62ecs\\u0300;EGLST\\u0c35\\u0c36\\u0c3c\\u0c44\\u0c4b\\u0c58\\u626equal;\\u6270reater;\\u6278ess;\\uc000\\u226a\\u0338lantEqual;\\uc000\\u2a7d\\u0338ilde;\\u6274ested\\u0100GL\\u0c68\\u0c79reaterGreater;\\uc000\\u2aa2\\u0338essLess;\\uc000\\u2aa1\\u0338recedes\\u0180;ES\\u0c92\\u0c93\\u0c9b\\u6280qual;\\uc000\\u2aaf\\u0338lantEqual;\\u62e0\\u0100ei\\u0cab\\u0cb9verseElement;\\u620cghtTriangle\\u0180;BE\\u0ccb\\u0ccc\\u0cd2\\u62ebar;\\uc000\\u29d0\\u0338qual;\\u62ed\\u0100qu\\u0cdd\\u0d0cuareSu\\u0100bp\\u0ce8\\u0cf9set\\u0100;E\\u0cf0\\u0cf3\\uc000\\u228f\\u0338qual;\\u62e2erset\\u0100;E\\u0d03\\u0d06\\uc000\\u2290\\u0338qual;\\u62e3\\u0180bcp\\u0d13\\u0d24\\u0d4eset\\u0100;E\\u0d1b\\u0d1e\\uc000\\u2282\\u20d2qual;\\u6288ceeds\\u0200;EST\\u0d32\\u0d33\\u0d3b\\u0d46\\u6281qual;\\uc000\\u2ab0\\u0338lantEqual;\\u62e1ilde;\\uc000\\u227f\\u0338erset\\u0100;E\\u0d58\\u0d5b\\uc000\\u2283\\u20d2qual;\\u6289ilde\\u0200;EFT\\u0d6e\\u0d6f\\u0d75\\u0d7f\\u6241qual;\\u6244ullEqual;\\u6247ilde;\\u6249erticalBar;\\u6224cr;\\uc000\\ud835\\udca9ilde\\u803b\\xd1\\u40d1;\\u439d\\u0700Eacdfgmoprstuv\\u0dbd\\u0dc2\\u0dc9\\u0dd5\\u0ddb\\u0de0\\u0de7\\u0dfc\\u0e02\\u0e20\\u0e22\\u0e32\\u0e3f\\u0e44lig;\\u4152cute\\u803b\\xd3\\u40d3\\u0100iy\\u0dce\\u0dd3rc\\u803b\\xd4\\u40d4;\\u441eblac;\\u4150r;\\uc000\\ud835\\udd12rave\\u803b\\xd2\\u40d2\\u0180aei\\u0dee\\u0df2\\u0df6cr;\\u414cga;\\u43a9cron;\\u439fpf;\\uc000\\ud835\\udd46enCurly\\u0100DQ\\u0e0e\\u0e1aoubleQuote;\\u601cuote;\\u6018;\\u6a54\\u0100cl\\u0e27\\u0e2cr;\\uc000\\ud835\\udcaaash\\u803b\\xd8\\u40d8i\\u016c\\u0e37\\u0e3cde\\u803b\\xd5\\u40d5es;\\u6a37ml\\u803b\\xd6\\u40d6er\\u0100BP\\u0e4b\\u0e60\\u0100ar\\u0e50\\u0e53r;\\u603eac\\u0100ek\\u0e5a\\u0e5c;\\u63deet;\\u63b4arenthesis;\\u63dc\\u0480acfhilors\\u0e7f\\u0e87\\u0e8a\\u0e8f\\u0e92\\u0e94\\u0e9d\\u0eb0\\u0efcrtialD;\\u6202y;\\u441fr;\\uc000\\ud835\\udd13i;\\u43a6;\\u43a0usMinus;\\u40b1\\u0100ip\\u0ea2\\u0eadncareplan\\xe5\\u069df;\\u6119\\u0200;eio\\u0eb9\\u0eba\\u0ee0\\u0ee4\\u6abbcedes\\u0200;EST\\u0ec8\\u0ec9\\u0ecf\\u0eda\\u627aqual;\\u6aaflantEqual;\\u627cilde;\\u627eme;\\u6033\\u0100dp\\u0ee9\\u0eeeuct;\\u620fortion\\u0100;a\\u0225\\u0ef9l;\\u621d\\u0100ci\\u0f01\\u0f06r;\\uc000\\ud835\\udcab;\\u43a8\\u0200Ufos\\u0f11\\u0f16\\u0f1b\\u0f1fOT\\u803b\\\"\\u4022r;\\uc000\\ud835\\udd14pf;\\u611acr;\\uc000\\ud835\\udcac\\u0600BEacefhiorsu\\u0f3e\\u0f43\\u0f47\\u0f60\\u0f73\\u0fa7\\u0faa\\u0fad\\u1096\\u10a9\\u10b4\\u10bearr;\\u6910G\\u803b\\xae\\u40ae\\u0180cnr\\u0f4e\\u0f53\\u0f56ute;\\u4154g;\\u67ebr\\u0100;t\\u0f5c\\u0f5d\\u61a0l;\\u6916\\u0180aey\\u0f67\\u0f6c\\u0f71ron;\\u4158dil;\\u4156;\\u4420\\u0100;v\\u0f78\\u0f79\\u611cerse\\u0100EU\\u0f82\\u0f99\\u0100lq\\u0f87\\u0f8eement;\\u620builibrium;\\u61cbpEquilibrium;\\u696fr\\xbb\\u0f79o;\\u43a1ght\\u0400ACDFTUVa\\u0fc1\\u0feb\\u0ff3\\u1022\\u1028\\u105b\\u1087\\u03d8\\u0100nr\\u0fc6\\u0fd2gleBracket;\\u67e9row\\u0180;BL\\u0fdc\\u0fdd\\u0fe1\\u6192ar;\\u61e5eftArrow;\\u61c4eiling;\\u6309o\\u01f5\\u0ff9\\0\\u1005bleBracket;\\u67e7n\\u01d4\\u100a\\0\\u1014eeVector;\\u695dector\\u0100;B\\u101d\\u101e\\u61c2ar;\\u6955loor;\\u630b\\u0100er\\u102d\\u1043e\\u0180;AV\\u1035\\u1036\\u103c\\u62a2rrow;\\u61a6ector;\\u695biangle\\u0180;BE\\u1050\\u1051\\u1055\\u62b3ar;\\u69d0qual;\\u62b5p\\u0180DTV\\u1063\\u106e\\u1078ownVector;\\u694feeVector;\\u695cector\\u0100;B\\u1082\\u1083\\u61bear;\\u6954ector\\u0100;B\\u1091\\u1092\\u61c0ar;\\u6953\\u0100pu\\u109b\\u109ef;\\u611dndImplies;\\u6970ightarrow;\\u61db\\u0100ch\\u10b9\\u10bcr;\\u611b;\\u61b1leDelayed;\\u69f4\\u0680HOacfhimoqstu\\u10e4\\u10f1\\u10f7\\u10fd\\u1119\\u111e\\u1151\\u1156\\u1161\\u1167\\u11b5\\u11bb\\u11bf\\u0100Cc\\u10e9\\u10eeHcy;\\u4429y;\\u4428FTcy;\\u442ccute;\\u415a\\u0280;aeiy\\u1108\\u1109\\u110e\\u1113\\u1117\\u6abcron;\\u4160dil;\\u415erc;\\u415c;\\u4421r;\\uc000\\ud835\\udd16ort\\u0200DLRU\\u112a\\u1134\\u113e\\u1149ownArrow\\xbb\\u041eeftArrow\\xbb\\u089aightArrow\\xbb\\u0fddpArrow;\\u6191gma;\\u43a3allCircle;\\u6218pf;\\uc000\\ud835\\udd4a\\u0272\\u116d\\0\\0\\u1170t;\\u621aare\\u0200;ISU\\u117b\\u117c\\u1189\\u11af\\u65a1ntersection;\\u6293u\\u0100bp\\u118f\\u119eset\\u0100;E\\u1197\\u1198\\u628fqual;\\u6291erset\\u0100;E\\u11a8\\u11a9\\u6290qual;\\u6292nion;\\u6294cr;\\uc000\\ud835\\udcaear;\\u62c6\\u0200bcmp\\u11c8\\u11db\\u1209\\u120b\\u0100;s\\u11cd\\u11ce\\u62d0et\\u0100;E\\u11cd\\u11d5qual;\\u6286\\u0100ch\\u11e0\\u1205eeds\\u0200;EST\\u11ed\\u11ee\\u11f4\\u11ff\\u627bqual;\\u6ab0lantEqual;\\u627dilde;\\u627fTh\\xe1\\u0f8c;\\u6211\\u0180;es\\u1212\\u1213\\u1223\\u62d1rset\\u0100;E\\u121c\\u121d\\u6283qual;\\u6287et\\xbb\\u1213\\u0580HRSacfhiors\\u123e\\u1244\\u1249\\u1255\\u125e\\u1271\\u1276\\u129f\\u12c2\\u12c8\\u12d1ORN\\u803b\\xde\\u40deADE;\\u6122\\u0100Hc\\u124e\\u1252cy;\\u440by;\\u4426\\u0100bu\\u125a\\u125c;\\u4009;\\u43a4\\u0180aey\\u1265\\u126a\\u126fron;\\u4164dil;\\u4162;\\u4422r;\\uc000\\ud835\\udd17\\u0100ei\\u127b\\u1289\\u01f2\\u1280\\0\\u1287efore;\\u6234a;\\u4398\\u0100cn\\u128e\\u1298kSpace;\\uc000\\u205f\\u200aSpace;\\u6009lde\\u0200;EFT\\u12ab\\u12ac\\u12b2\\u12bc\\u623cqual;\\u6243ullEqual;\\u6245ilde;\\u6248pf;\\uc000\\ud835\\udd4bipleDot;\\u60db\\u0100ct\\u12d6\\u12dbr;\\uc000\\ud835\\udcafrok;\\u4166\\u0ae1\\u12f7\\u130e\\u131a\\u1326\\0\\u132c\\u1331\\0\\0\\0\\0\\0\\u1338\\u133d\\u1377\\u1385\\0\\u13ff\\u1404\\u140a\\u1410\\u0100cr\\u12fb\\u1301ute\\u803b\\xda\\u40dar\\u0100;o\\u1307\\u1308\\u619fcir;\\u6949r\\u01e3\\u1313\\0\\u1316y;\\u440eve;\\u416c\\u0100iy\\u131e\\u1323rc\\u803b\\xdb\\u40db;\\u4423blac;\\u4170r;\\uc000\\ud835\\udd18rave\\u803b\\xd9\\u40d9acr;\\u416a\\u0100di\\u1341\\u1369er\\u0100BP\\u1348\\u135d\\u0100ar\\u134d\\u1350r;\\u405fac\\u0100ek\\u1357\\u1359;\\u63dfet;\\u63b5arenthesis;\\u63ddon\\u0100;P\\u1370\\u1371\\u62c3lus;\\u628e\\u0100gp\\u137b\\u137fon;\\u4172f;\\uc000\\ud835\\udd4c\\u0400ADETadps\\u1395\\u13ae\\u13b8\\u13c4\\u03e8\\u13d2\\u13d7\\u13f3rrow\\u0180;BD\\u1150\\u13a0\\u13a4ar;\\u6912ownArrow;\\u61c5ownArrow;\\u6195quilibrium;\\u696eee\\u0100;A\\u13cb\\u13cc\\u62a5rrow;\\u61a5own\\xe1\\u03f3er\\u0100LR\\u13de\\u13e8eftArrow;\\u6196ightArrow;\\u6197i\\u0100;l\\u13f9\\u13fa\\u43d2on;\\u43a5ing;\\u416ecr;\\uc000\\ud835\\udcb0ilde;\\u4168ml\\u803b\\xdc\\u40dc\\u0480Dbcdefosv\\u1427\\u142c\\u1430\\u1433\\u143e\\u1485\\u148a\\u1490\\u1496ash;\\u62abar;\\u6aeby;\\u4412ash\\u0100;l\\u143b\\u143c\\u62a9;\\u6ae6\\u0100er\\u1443\\u1445;\\u62c1\\u0180bty\\u144c\\u1450\\u147aar;\\u6016\\u0100;i\\u144f\\u1455cal\\u0200BLST\\u1461\\u1465\\u146a\\u1474ar;\\u6223ine;\\u407ceparator;\\u6758ilde;\\u6240ThinSpace;\\u600ar;\\uc000\\ud835\\udd19pf;\\uc000\\ud835\\udd4dcr;\\uc000\\ud835\\udcb1dash;\\u62aa\\u0280cefos\\u14a7\\u14ac\\u14b1\\u14b6\\u14bcirc;\\u4174dge;\\u62c0r;\\uc000\\ud835\\udd1apf;\\uc000\\ud835\\udd4ecr;\\uc000\\ud835\\udcb2\\u0200fios\\u14cb\\u14d0\\u14d2\\u14d8r;\\uc000\\ud835\\udd1b;\\u439epf;\\uc000\\ud835\\udd4fcr;\\uc000\\ud835\\udcb3\\u0480AIUacfosu\\u14f1\\u14f5\\u14f9\\u14fd\\u1504\\u150f\\u1514\\u151a\\u1520cy;\\u442fcy;\\u4407cy;\\u442ecute\\u803b\\xdd\\u40dd\\u0100iy\\u1509\\u150drc;\\u4176;\\u442br;\\uc000\\ud835\\udd1cpf;\\uc000\\ud835\\udd50cr;\\uc000\\ud835\\udcb4ml;\\u4178\\u0400Hacdefos\\u1535\\u1539\\u153f\\u154b\\u154f\\u155d\\u1560\\u1564cy;\\u4416cute;\\u4179\\u0100ay\\u1544\\u1549ron;\\u417d;\\u4417ot;\\u417b\\u01f2\\u1554\\0\\u155boWidt\\xe8\\u0ad9a;\\u4396r;\\u6128pf;\\u6124cr;\\uc000\\ud835\\udcb5\\u0be1\\u1583\\u158a\\u1590\\0\\u15b0\\u15b6\\u15bf\\0\\0\\0\\0\\u15c6\\u15db\\u15eb\\u165f\\u166d\\0\\u1695\\u169b\\u16b2\\u16b9\\0\\u16becute\\u803b\\xe1\\u40e1reve;\\u4103\\u0300;Ediuy\\u159c\\u159d\\u15a1\\u15a3\\u15a8\\u15ad\\u623e;\\uc000\\u223e\\u0333;\\u623frc\\u803b\\xe2\\u40e2te\\u80bb\\xb4\\u0306;\\u4430lig\\u803b\\xe6\\u40e6\\u0100;r\\xb2\\u15ba;\\uc000\\ud835\\udd1erave\\u803b\\xe0\\u40e0\\u0100ep\\u15ca\\u15d6\\u0100fp\\u15cf\\u15d4sym;\\u6135\\xe8\\u15d3ha;\\u43b1\\u0100ap\\u15dfc\\u0100cl\\u15e4\\u15e7r;\\u4101g;\\u6a3f\\u0264\\u15f0\\0\\0\\u160a\\u0280;adsv\\u15fa\\u15fb\\u15ff\\u1601\\u1607\\u6227nd;\\u6a55;\\u6a5clope;\\u6a58;\\u6a5a\\u0380;elmrsz\\u1618\\u1619\\u161b\\u161e\\u163f\\u164f\\u1659\\u6220;\\u69a4e\\xbb\\u1619sd\\u0100;a\\u1625\\u1626\\u6221\\u0461\\u1630\\u1632\\u1634\\u1636\\u1638\\u163a\\u163c\\u163e;\\u69a8;\\u69a9;\\u69aa;\\u69ab;\\u69ac;\\u69ad;\\u69ae;\\u69aft\\u0100;v\\u1645\\u1646\\u621fb\\u0100;d\\u164c\\u164d\\u62be;\\u699d\\u0100pt\\u1654\\u1657h;\\u6222\\xbb\\xb9arr;\\u637c\\u0100gp\\u1663\\u1667on;\\u4105f;\\uc000\\ud835\\udd52\\u0380;Eaeiop\\u12c1\\u167b\\u167d\\u1682\\u1684\\u1687\\u168a;\\u6a70cir;\\u6a6f;\\u624ad;\\u624bs;\\u4027rox\\u0100;e\\u12c1\\u1692\\xf1\\u1683ing\\u803b\\xe5\\u40e5\\u0180cty\\u16a1\\u16a6\\u16a8r;\\uc000\\ud835\\udcb6;\\u402amp\\u0100;e\\u12c1\\u16af\\xf1\\u0288ilde\\u803b\\xe3\\u40e3ml\\u803b\\xe4\\u40e4\\u0100ci\\u16c2\\u16c8onin\\xf4\\u0272nt;\\u6a11\\u0800Nabcdefiklnoprsu\\u16ed\\u16f1\\u1730\\u173c\\u1743\\u1748\\u1778\\u177d\\u17e0\\u17e6\\u1839\\u1850\\u170d\\u193d\\u1948\\u1970ot;\\u6aed\\u0100cr\\u16f6\\u171ek\\u0200ceps\\u1700\\u1705\\u170d\\u1713ong;\\u624cpsilon;\\u43f6rime;\\u6035im\\u0100;e\\u171a\\u171b\\u623dq;\\u62cd\\u0176\\u1722\\u1726ee;\\u62bded\\u0100;g\\u172c\\u172d\\u6305e\\xbb\\u172drk\\u0100;t\\u135c\\u1737brk;\\u63b6\\u0100oy\\u1701\\u1741;\\u4431quo;\\u601e\\u0280cmprt\\u1753\\u175b\\u1761\\u1764\\u1768aus\\u0100;e\\u010a\\u0109ptyv;\\u69b0s\\xe9\\u170cno\\xf5\\u0113\\u0180ahw\\u176f\\u1771\\u1773;\\u43b2;\\u6136een;\\u626cr;\\uc000\\ud835\\udd1fg\\u0380costuvw\\u178d\\u179d\\u17b3\\u17c1\\u17d5\\u17db\\u17de\\u0180aiu\\u1794\\u1796\\u179a\\xf0\\u0760rc;\\u65efp\\xbb\\u1371\\u0180dpt\\u17a4\\u17a8\\u17adot;\\u6a00lus;\\u6a01imes;\\u6a02\\u0271\\u17b9\\0\\0\\u17becup;\\u6a06ar;\\u6605riangle\\u0100du\\u17cd\\u17d2own;\\u65bdp;\\u65b3plus;\\u6a04e\\xe5\\u1444\\xe5\\u14adarow;\\u690d\\u0180ako\\u17ed\\u1826\\u1835\\u0100cn\\u17f2\\u1823k\\u0180lst\\u17fa\\u05ab\\u1802ozenge;\\u69ebriangle\\u0200;dlr\\u1812\\u1813\\u1818\\u181d\\u65b4own;\\u65beeft;\\u65c2ight;\\u65b8k;\\u6423\\u01b1\\u182b\\0\\u1833\\u01b2\\u182f\\0\\u1831;\\u6592;\\u65914;\\u6593ck;\\u6588\\u0100eo\\u183e\\u184d\\u0100;q\\u1843\\u1846\\uc000=\\u20e5uiv;\\uc000\\u2261\\u20e5t;\\u6310\\u0200ptwx\\u1859\\u185e\\u1867\\u186cf;\\uc000\\ud835\\udd53\\u0100;t\\u13cb\\u1863om\\xbb\\u13cctie;\\u62c8\\u0600DHUVbdhmptuv\\u1885\\u1896\\u18aa\\u18bb\\u18d7\\u18db\\u18ec\\u18ff\\u1905\\u190a\\u1910\\u1921\\u0200LRlr\\u188e\\u1890\\u1892\\u1894;\\u6557;\\u6554;\\u6556;\\u6553\\u0280;DUdu\\u18a1\\u18a2\\u18a4\\u18a6\\u18a8\\u6550;\\u6566;\\u6569;\\u6564;\\u6567\\u0200LRlr\\u18b3\\u18b5\\u18b7\\u18b9;\\u655d;\\u655a;\\u655c;\\u6559\\u0380;HLRhlr\\u18ca\\u18cb\\u18cd\\u18cf\\u18d1\\u18d3\\u18d5\\u6551;\\u656c;\\u6563;\\u6560;\\u656b;\\u6562;\\u655fox;\\u69c9\\u0200LRlr\\u18e4\\u18e6\\u18e8\\u18ea;\\u6555;\\u6552;\\u6510;\\u650c\\u0280;DUdu\\u06bd\\u18f7\\u18f9\\u18fb\\u18fd;\\u6565;\\u6568;\\u652c;\\u6534inus;\\u629flus;\\u629eimes;\\u62a0\\u0200LRlr\\u1919\\u191b\\u191d\\u191f;\\u655b;\\u6558;\\u6518;\\u6514\\u0380;HLRhlr\\u1930\\u1931\\u1933\\u1935\\u1937\\u1939\\u193b\\u6502;\\u656a;\\u6561;\\u655e;\\u653c;\\u6524;\\u651c\\u0100ev\\u0123\\u1942bar\\u803b\\xa6\\u40a6\\u0200ceio\\u1951\\u1956\\u195a\\u1960r;\\uc000\\ud835\\udcb7mi;\\u604fm\\u0100;e\\u171a\\u171cl\\u0180;bh\\u1968\\u1969\\u196b\\u405c;\\u69c5sub;\\u67c8\\u016c\\u1974\\u197el\\u0100;e\\u1979\\u197a\\u6022t\\xbb\\u197ap\\u0180;Ee\\u012f\\u1985\\u1987;\\u6aae\\u0100;q\\u06dc\\u06db\\u0ce1\\u19a7\\0\\u19e8\\u1a11\\u1a15\\u1a32\\0\\u1a37\\u1a50\\0\\0\\u1ab4\\0\\0\\u1ac1\\0\\0\\u1b21\\u1b2e\\u1b4d\\u1b52\\0\\u1bfd\\0\\u1c0c\\u0180cpr\\u19ad\\u19b2\\u19ddute;\\u4107\\u0300;abcds\\u19bf\\u19c0\\u19c4\\u19ca\\u19d5\\u19d9\\u6229nd;\\u6a44rcup;\\u6a49\\u0100au\\u19cf\\u19d2p;\\u6a4bp;\\u6a47ot;\\u6a40;\\uc000\\u2229\\ufe00\\u0100eo\\u19e2\\u19e5t;\\u6041\\xee\\u0693\\u0200aeiu\\u19f0\\u19fb\\u1a01\\u1a05\\u01f0\\u19f5\\0\\u19f8s;\\u6a4don;\\u410ddil\\u803b\\xe7\\u40e7rc;\\u4109ps\\u0100;s\\u1a0c\\u1a0d\\u6a4cm;\\u6a50ot;\\u410b\\u0180dmn\\u1a1b\\u1a20\\u1a26il\\u80bb\\xb8\\u01adptyv;\\u69b2t\\u8100\\xa2;e\\u1a2d\\u1a2e\\u40a2r\\xe4\\u01b2r;\\uc000\\ud835\\udd20\\u0180cei\\u1a3d\\u1a40\\u1a4dy;\\u4447ck\\u0100;m\\u1a47\\u1a48\\u6713ark\\xbb\\u1a48;\\u43c7r\\u0380;Ecefms\\u1a5f\\u1a60\\u1a62\\u1a6b\\u1aa4\\u1aaa\\u1aae\\u65cb;\\u69c3\\u0180;el\\u1a69\\u1a6a\\u1a6d\\u42c6q;\\u6257e\\u0261\\u1a74\\0\\0\\u1a88rrow\\u0100lr\\u1a7c\\u1a81eft;\\u61baight;\\u61bb\\u0280RSacd\\u1a92\\u1a94\\u1a96\\u1a9a\\u1a9f\\xbb\\u0f47;\\u64c8st;\\u629birc;\\u629aash;\\u629dnint;\\u6a10id;\\u6aefcir;\\u69c2ubs\\u0100;u\\u1abb\\u1abc\\u6663it\\xbb\\u1abc\\u02ec\\u1ac7\\u1ad4\\u1afa\\0\\u1b0aon\\u0100;e\\u1acd\\u1ace\\u403a\\u0100;q\\xc7\\xc6\\u026d\\u1ad9\\0\\0\\u1ae2a\\u0100;t\\u1ade\\u1adf\\u402c;\\u4040\\u0180;fl\\u1ae8\\u1ae9\\u1aeb\\u6201\\xee\\u1160e\\u0100mx\\u1af1\\u1af6ent\\xbb\\u1ae9e\\xf3\\u024d\\u01e7\\u1afe\\0\\u1b07\\u0100;d\\u12bb\\u1b02ot;\\u6a6dn\\xf4\\u0246\\u0180fry\\u1b10\\u1b14\\u1b17;\\uc000\\ud835\\udd54o\\xe4\\u0254\\u8100\\xa9;s\\u0155\\u1b1dr;\\u6117\\u0100ao\\u1b25\\u1b29rr;\\u61b5ss;\\u6717\\u0100cu\\u1b32\\u1b37r;\\uc000\\ud835\\udcb8\\u0100bp\\u1b3c\\u1b44\\u0100;e\\u1b41\\u1b42\\u6acf;\\u6ad1\\u0100;e\\u1b49\\u1b4a\\u6ad0;\\u6ad2dot;\\u62ef\\u0380delprvw\\u1b60\\u1b6c\\u1b77\\u1b82\\u1bac\\u1bd4\\u1bf9arr\\u0100lr\\u1b68\\u1b6a;\\u6938;\\u6935\\u0270\\u1b72\\0\\0\\u1b75r;\\u62dec;\\u62dfarr\\u0100;p\\u1b7f\\u1b80\\u61b6;\\u693d\\u0300;bcdos\\u1b8f\\u1b90\\u1b96\\u1ba1\\u1ba5\\u1ba8\\u622arcap;\\u6a48\\u0100au\\u1b9b\\u1b9ep;\\u6a46p;\\u6a4aot;\\u628dr;\\u6a45;\\uc000\\u222a\\ufe00\\u0200alrv\\u1bb5\\u1bbf\\u1bde\\u1be3rr\\u0100;m\\u1bbc\\u1bbd\\u61b7;\\u693cy\\u0180evw\\u1bc7\\u1bd4\\u1bd8q\\u0270\\u1bce\\0\\0\\u1bd2re\\xe3\\u1b73u\\xe3\\u1b75ee;\\u62ceedge;\\u62cfen\\u803b\\xa4\\u40a4earrow\\u0100lr\\u1bee\\u1bf3eft\\xbb\\u1b80ight\\xbb\\u1bbde\\xe4\\u1bdd\\u0100ci\\u1c01\\u1c07onin\\xf4\\u01f7nt;\\u6231lcty;\\u632d\\u0980AHabcdefhijlorstuwz\\u1c38\\u1c3b\\u1c3f\\u1c5d\\u1c69\\u1c75\\u1c8a\\u1c9e\\u1cac\\u1cb7\\u1cfb\\u1cff\\u1d0d\\u1d7b\\u1d91\\u1dab\\u1dbb\\u1dc6\\u1dcdr\\xf2\\u0381ar;\\u6965\\u0200glrs\\u1c48\\u1c4d\\u1c52\\u1c54ger;\\u6020eth;\\u6138\\xf2\\u1133h\\u0100;v\\u1c5a\\u1c5b\\u6010\\xbb\\u090a\\u016b\\u1c61\\u1c67arow;\\u690fa\\xe3\\u0315\\u0100ay\\u1c6e\\u1c73ron;\\u410f;\\u4434\\u0180;ao\\u0332\\u1c7c\\u1c84\\u0100gr\\u02bf\\u1c81r;\\u61catseq;\\u6a77\\u0180glm\\u1c91\\u1c94\\u1c98\\u803b\\xb0\\u40b0ta;\\u43b4ptyv;\\u69b1\\u0100ir\\u1ca3\\u1ca8sht;\\u697f;\\uc000\\ud835\\udd21ar\\u0100lr\\u1cb3\\u1cb5\\xbb\\u08dc\\xbb\\u101e\\u0280aegsv\\u1cc2\\u0378\\u1cd6\\u1cdc\\u1ce0m\\u0180;os\\u0326\\u1cca\\u1cd4nd\\u0100;s\\u0326\\u1cd1uit;\\u6666amma;\\u43ddin;\\u62f2\\u0180;io\\u1ce7\\u1ce8\\u1cf8\\u40f7de\\u8100\\xf7;o\\u1ce7\\u1cf0ntimes;\\u62c7n\\xf8\\u1cf7cy;\\u4452c\\u026f\\u1d06\\0\\0\\u1d0arn;\\u631eop;\\u630d\\u0280lptuw\\u1d18\\u1d1d\\u1d22\\u1d49\\u1d55lar;\\u4024f;\\uc000\\ud835\\udd55\\u0280;emps\\u030b\\u1d2d\\u1d37\\u1d3d\\u1d42q\\u0100;d\\u0352\\u1d33ot;\\u6251inus;\\u6238lus;\\u6214quare;\\u62a1blebarwedg\\xe5\\xfan\\u0180adh\\u112e\\u1d5d\\u1d67ownarrow\\xf3\\u1c83arpoon\\u0100lr\\u1d72\\u1d76ef\\xf4\\u1cb4igh\\xf4\\u1cb6\\u0162\\u1d7f\\u1d85karo\\xf7\\u0f42\\u026f\\u1d8a\\0\\0\\u1d8ern;\\u631fop;\\u630c\\u0180cot\\u1d98\\u1da3\\u1da6\\u0100ry\\u1d9d\\u1da1;\\uc000\\ud835\\udcb9;\\u4455l;\\u69f6rok;\\u4111\\u0100dr\\u1db0\\u1db4ot;\\u62f1i\\u0100;f\\u1dba\\u1816\\u65bf\\u0100ah\\u1dc0\\u1dc3r\\xf2\\u0429a\\xf2\\u0fa6angle;\\u69a6\\u0100ci\\u1dd2\\u1dd5y;\\u445fgrarr;\\u67ff\\u0900Dacdefglmnopqrstux\\u1e01\\u1e09\\u1e19\\u1e38\\u0578\\u1e3c\\u1e49\\u1e61\\u1e7e\\u1ea5\\u1eaf\\u1ebd\\u1ee1\\u1f2a\\u1f37\\u1f44\\u1f4e\\u1f5a\\u0100Do\\u1e06\\u1d34o\\xf4\\u1c89\\u0100cs\\u1e0e\\u1e14ute\\u803b\\xe9\\u40e9ter;\\u6a6e\\u0200aioy\\u1e22\\u1e27\\u1e31\\u1e36ron;\\u411br\\u0100;c\\u1e2d\\u1e2e\\u6256\\u803b\\xea\\u40ealon;\\u6255;\\u444dot;\\u4117\\u0100Dr\\u1e41\\u1e45ot;\\u6252;\\uc000\\ud835\\udd22\\u0180;rs\\u1e50\\u1e51\\u1e57\\u6a9aave\\u803b\\xe8\\u40e8\\u0100;d\\u1e5c\\u1e5d\\u6a96ot;\\u6a98\\u0200;ils\\u1e6a\\u1e6b\\u1e72\\u1e74\\u6a99nters;\\u63e7;\\u6113\\u0100;d\\u1e79\\u1e7a\\u6a95ot;\\u6a97\\u0180aps\\u1e85\\u1e89\\u1e97cr;\\u4113ty\\u0180;sv\\u1e92\\u1e93\\u1e95\\u6205et\\xbb\\u1e93p\\u01001;\\u1e9d\\u1ea4\\u0133\\u1ea1\\u1ea3;\\u6004;\\u6005\\u6003\\u0100gs\\u1eaa\\u1eac;\\u414bp;\\u6002\\u0100gp\\u1eb4\\u1eb8on;\\u4119f;\\uc000\\ud835\\udd56\\u0180als\\u1ec4\\u1ece\\u1ed2r\\u0100;s\\u1eca\\u1ecb\\u62d5l;\\u69e3us;\\u6a71i\\u0180;lv\\u1eda\\u1edb\\u1edf\\u43b5on\\xbb\\u1edb;\\u43f5\\u0200csuv\\u1eea\\u1ef3\\u1f0b\\u1f23\\u0100io\\u1eef\\u1e31rc\\xbb\\u1e2e\\u0269\\u1ef9\\0\\0\\u1efb\\xed\\u0548ant\\u0100gl\\u1f02\\u1f06tr\\xbb\\u1e5dess\\xbb\\u1e7a\\u0180aei\\u1f12\\u1f16\\u1f1als;\\u403dst;\\u625fv\\u0100;D\\u0235\\u1f20D;\\u6a78parsl;\\u69e5\\u0100Da\\u1f2f\\u1f33ot;\\u6253rr;\\u6971\\u0180cdi\\u1f3e\\u1f41\\u1ef8r;\\u612fo\\xf4\\u0352\\u0100ah\\u1f49\\u1f4b;\\u43b7\\u803b\\xf0\\u40f0\\u0100mr\\u1f53\\u1f57l\\u803b\\xeb\\u40ebo;\\u60ac\\u0180cip\\u1f61\\u1f64\\u1f67l;\\u4021s\\xf4\\u056e\\u0100eo\\u1f6c\\u1f74ctatio\\xee\\u0559nential\\xe5\\u0579\\u09e1\\u1f92\\0\\u1f9e\\0\\u1fa1\\u1fa7\\0\\0\\u1fc6\\u1fcc\\0\\u1fd3\\0\\u1fe6\\u1fea\\u2000\\0\\u2008\\u205allingdotse\\xf1\\u1e44y;\\u4444male;\\u6640\\u0180ilr\\u1fad\\u1fb3\\u1fc1lig;\\u8000\\ufb03\\u0269\\u1fb9\\0\\0\\u1fbdg;\\u8000\\ufb00ig;\\u8000\\ufb04;\\uc000\\ud835\\udd23lig;\\u8000\\ufb01lig;\\uc000fj\\u0180alt\\u1fd9\\u1fdc\\u1fe1t;\\u666dig;\\u8000\\ufb02ns;\\u65b1of;\\u4192\\u01f0\\u1fee\\0\\u1ff3f;\\uc000\\ud835\\udd57\\u0100ak\\u05bf\\u1ff7\\u0100;v\\u1ffc\\u1ffd\\u62d4;\\u6ad9artint;\\u6a0d\\u0100ao\\u200c\\u2055\\u0100cs\\u2011\\u2052\\u03b1\\u201a\\u2030\\u2038\\u2045\\u2048\\0\\u2050\\u03b2\\u2022\\u2025\\u2027\\u202a\\u202c\\0\\u202e\\u803b\\xbd\\u40bd;\\u6153\\u803b\\xbc\\u40bc;\\u6155;\\u6159;\\u615b\\u01b3\\u2034\\0\\u2036;\\u6154;\\u6156\\u02b4\\u203e\\u2041\\0\\0\\u2043\\u803b\\xbe\\u40be;\\u6157;\\u615c5;\\u6158\\u01b6\\u204c\\0\\u204e;\\u615a;\\u615d8;\\u615el;\\u6044wn;\\u6322cr;\\uc000\\ud835\\udcbb\\u0880Eabcdefgijlnorstv\\u2082\\u2089\\u209f\\u20a5\\u20b0\\u20b4\\u20f0\\u20f5\\u20fa\\u20ff\\u2103\\u2112\\u2138\\u0317\\u213e\\u2152\\u219e\\u0100;l\\u064d\\u2087;\\u6a8c\\u0180cmp\\u2090\\u2095\\u209dute;\\u41f5ma\\u0100;d\\u209c\\u1cda\\u43b3;\\u6a86reve;\\u411f\\u0100iy\\u20aa\\u20aerc;\\u411d;\\u4433ot;\\u4121\\u0200;lqs\\u063e\\u0642\\u20bd\\u20c9\\u0180;qs\\u063e\\u064c\\u20c4lan\\xf4\\u0665\\u0200;cdl\\u0665\\u20d2\\u20d5\\u20e5c;\\u6aa9ot\\u0100;o\\u20dc\\u20dd\\u6a80\\u0100;l\\u20e2\\u20e3\\u6a82;\\u6a84\\u0100;e\\u20ea\\u20ed\\uc000\\u22db\\ufe00s;\\u6a94r;\\uc000\\ud835\\udd24\\u0100;g\\u0673\\u061bmel;\\u6137cy;\\u4453\\u0200;Eaj\\u065a\\u210c\\u210e\\u2110;\\u6a92;\\u6aa5;\\u6aa4\\u0200Eaes\\u211b\\u211d\\u2129\\u2134;\\u6269p\\u0100;p\\u2123\\u2124\\u6a8arox\\xbb\\u2124\\u0100;q\\u212e\\u212f\\u6a88\\u0100;q\\u212e\\u211bim;\\u62e7pf;\\uc000\\ud835\\udd58\\u0100ci\\u2143\\u2146r;\\u610am\\u0180;el\\u066b\\u214e\\u2150;\\u6a8e;\\u6a90\\u8300>;cdlqr\\u05ee\\u2160\\u216a\\u216e\\u2173\\u2179\\u0100ci\\u2165\\u2167;\\u6aa7r;\\u6a7aot;\\u62d7Par;\\u6995uest;\\u6a7c\\u0280adels\\u2184\\u216a\\u2190\\u0656\\u219b\\u01f0\\u2189\\0\\u218epro\\xf8\\u209er;\\u6978q\\u0100lq\\u063f\\u2196les\\xf3\\u2088i\\xed\\u066b\\u0100en\\u21a3\\u21adrtneqq;\\uc000\\u2269\\ufe00\\xc5\\u21aa\\u0500Aabcefkosy\\u21c4\\u21c7\\u21f1\\u21f5\\u21fa\\u2218\\u221d\\u222f\\u2268\\u227dr\\xf2\\u03a0\\u0200ilmr\\u21d0\\u21d4\\u21d7\\u21dbrs\\xf0\\u1484f\\xbb\\u2024il\\xf4\\u06a9\\u0100dr\\u21e0\\u21e4cy;\\u444a\\u0180;cw\\u08f4\\u21eb\\u21efir;\\u6948;\\u61adar;\\u610firc;\\u4125\\u0180alr\\u2201\\u220e\\u2213rts\\u0100;u\\u2209\\u220a\\u6665it\\xbb\\u220alip;\\u6026con;\\u62b9r;\\uc000\\ud835\\udd25s\\u0100ew\\u2223\\u2229arow;\\u6925arow;\\u6926\\u0280amopr\\u223a\\u223e\\u2243\\u225e\\u2263rr;\\u61fftht;\\u623bk\\u0100lr\\u2249\\u2253eftarrow;\\u61a9ightarrow;\\u61aaf;\\uc000\\ud835\\udd59bar;\\u6015\\u0180clt\\u226f\\u2274\\u2278r;\\uc000\\ud835\\udcbdas\\xe8\\u21f4rok;\\u4127\\u0100bp\\u2282\\u2287ull;\\u6043hen\\xbb\\u1c5b\\u0ae1\\u22a3\\0\\u22aa\\0\\u22b8\\u22c5\\u22ce\\0\\u22d5\\u22f3\\0\\0\\u22f8\\u2322\\u2367\\u2362\\u237f\\0\\u2386\\u23aa\\u23b4cute\\u803b\\xed\\u40ed\\u0180;iy\\u0771\\u22b0\\u22b5rc\\u803b\\xee\\u40ee;\\u4438\\u0100cx\\u22bc\\u22bfy;\\u4435cl\\u803b\\xa1\\u40a1\\u0100fr\\u039f\\u22c9;\\uc000\\ud835\\udd26rave\\u803b\\xec\\u40ec\\u0200;ino\\u073e\\u22dd\\u22e9\\u22ee\\u0100in\\u22e2\\u22e6nt;\\u6a0ct;\\u622dfin;\\u69dcta;\\u6129lig;\\u4133\\u0180aop\\u22fe\\u231a\\u231d\\u0180cgt\\u2305\\u2308\\u2317r;\\u412b\\u0180elp\\u071f\\u230f\\u2313in\\xe5\\u078ear\\xf4\\u0720h;\\u4131f;\\u62b7ed;\\u41b5\\u0280;cfot\\u04f4\\u232c\\u2331\\u233d\\u2341are;\\u6105in\\u0100;t\\u2338\\u2339\\u621eie;\\u69dddo\\xf4\\u2319\\u0280;celp\\u0757\\u234c\\u2350\\u235b\\u2361al;\\u62ba\\u0100gr\\u2355\\u2359er\\xf3\\u1563\\xe3\\u234darhk;\\u6a17rod;\\u6a3c\\u0200cgpt\\u236f\\u2372\\u2376\\u237by;\\u4451on;\\u412ff;\\uc000\\ud835\\udd5aa;\\u43b9uest\\u803b\\xbf\\u40bf\\u0100ci\\u238a\\u238fr;\\uc000\\ud835\\udcben\\u0280;Edsv\\u04f4\\u239b\\u239d\\u23a1\\u04f3;\\u62f9ot;\\u62f5\\u0100;v\\u23a6\\u23a7\\u62f4;\\u62f3\\u0100;i\\u0777\\u23aelde;\\u4129\\u01eb\\u23b8\\0\\u23bccy;\\u4456l\\u803b\\xef\\u40ef\\u0300cfmosu\\u23cc\\u23d7\\u23dc\\u23e1\\u23e7\\u23f5\\u0100iy\\u23d1\\u23d5rc;\\u4135;\\u4439r;\\uc000\\ud835\\udd27ath;\\u4237pf;\\uc000\\ud835\\udd5b\\u01e3\\u23ec\\0\\u23f1r;\\uc000\\ud835\\udcbfrcy;\\u4458kcy;\\u4454\\u0400acfghjos\\u240b\\u2416\\u2422\\u2427\\u242d\\u2431\\u2435\\u243bppa\\u0100;v\\u2413\\u2414\\u43ba;\\u43f0\\u0100ey\\u241b\\u2420dil;\\u4137;\\u443ar;\\uc000\\ud835\\udd28reen;\\u4138cy;\\u4445cy;\\u445cpf;\\uc000\\ud835\\udd5ccr;\\uc000\\ud835\\udcc0\\u0b80ABEHabcdefghjlmnoprstuv\\u2470\\u2481\\u2486\\u248d\\u2491\\u250e\\u253d\\u255a\\u2580\\u264e\\u265e\\u2665\\u2679\\u267d\\u269a\\u26b2\\u26d8\\u275d\\u2768\\u278b\\u27c0\\u2801\\u2812\\u0180art\\u2477\\u247a\\u247cr\\xf2\\u09c6\\xf2\\u0395ail;\\u691barr;\\u690e\\u0100;g\\u0994\\u248b;\\u6a8bar;\\u6962\\u0963\\u24a5\\0\\u24aa\\0\\u24b1\\0\\0\\0\\0\\0\\u24b5\\u24ba\\0\\u24c6\\u24c8\\u24cd\\0\\u24f9ute;\\u413amptyv;\\u69b4ra\\xee\\u084cbda;\\u43bbg\\u0180;dl\\u088e\\u24c1\\u24c3;\\u6991\\xe5\\u088e;\\u6a85uo\\u803b\\xab\\u40abr\\u0400;bfhlpst\\u0899\\u24de\\u24e6\\u24e9\\u24eb\\u24ee\\u24f1\\u24f5\\u0100;f\\u089d\\u24e3s;\\u691fs;\\u691d\\xeb\\u2252p;\\u61abl;\\u6939im;\\u6973l;\\u61a2\\u0180;ae\\u24ff\\u2500\\u2504\\u6aabil;\\u6919\\u0100;s\\u2509\\u250a\\u6aad;\\uc000\\u2aad\\ufe00\\u0180abr\\u2515\\u2519\\u251drr;\\u690crk;\\u6772\\u0100ak\\u2522\\u252cc\\u0100ek\\u2528\\u252a;\\u407b;\\u405b\\u0100es\\u2531\\u2533;\\u698bl\\u0100du\\u2539\\u253b;\\u698f;\\u698d\\u0200aeuy\\u2546\\u254b\\u2556\\u2558ron;\\u413e\\u0100di\\u2550\\u2554il;\\u413c\\xec\\u08b0\\xe2\\u2529;\\u443b\\u0200cqrs\\u2563\\u2566\\u256d\\u257da;\\u6936uo\\u0100;r\\u0e19\\u1746\\u0100du\\u2572\\u2577har;\\u6967shar;\\u694bh;\\u61b2\\u0280;fgqs\\u258b\\u258c\\u0989\\u25f3\\u25ff\\u6264t\\u0280ahlrt\\u2598\\u25a4\\u25b7\\u25c2\\u25e8rrow\\u0100;t\\u0899\\u25a1a\\xe9\\u24f6arpoon\\u0100du\\u25af\\u25b4own\\xbb\\u045ap\\xbb\\u0966eftarrows;\\u61c7ight\\u0180ahs\\u25cd\\u25d6\\u25derrow\\u0100;s\\u08f4\\u08a7arpoon\\xf3\\u0f98quigarro\\xf7\\u21f0hreetimes;\\u62cb\\u0180;qs\\u258b\\u0993\\u25falan\\xf4\\u09ac\\u0280;cdgs\\u09ac\\u260a\\u260d\\u261d\\u2628c;\\u6aa8ot\\u0100;o\\u2614\\u2615\\u6a7f\\u0100;r\\u261a\\u261b\\u6a81;\\u6a83\\u0100;e\\u2622\\u2625\\uc000\\u22da\\ufe00s;\\u6a93\\u0280adegs\\u2633\\u2639\\u263d\\u2649\\u264bppro\\xf8\\u24c6ot;\\u62d6q\\u0100gq\\u2643\\u2645\\xf4\\u0989gt\\xf2\\u248c\\xf4\\u099bi\\xed\\u09b2\\u0180ilr\\u2655\\u08e1\\u265asht;\\u697c;\\uc000\\ud835\\udd29\\u0100;E\\u099c\\u2663;\\u6a91\\u0161\\u2669\\u2676r\\u0100du\\u25b2\\u266e\\u0100;l\\u0965\\u2673;\\u696alk;\\u6584cy;\\u4459\\u0280;acht\\u0a48\\u2688\\u268b\\u2691\\u2696r\\xf2\\u25c1orne\\xf2\\u1d08ard;\\u696bri;\\u65fa\\u0100io\\u269f\\u26a4dot;\\u4140ust\\u0100;a\\u26ac\\u26ad\\u63b0che\\xbb\\u26ad\\u0200Eaes\\u26bb\\u26bd\\u26c9\\u26d4;\\u6268p\\u0100;p\\u26c3\\u26c4\\u6a89rox\\xbb\\u26c4\\u0100;q\\u26ce\\u26cf\\u6a87\\u0100;q\\u26ce\\u26bbim;\\u62e6\\u0400abnoptwz\\u26e9\\u26f4\\u26f7\\u271a\\u272f\\u2741\\u2747\\u2750\\u0100nr\\u26ee\\u26f1g;\\u67ecr;\\u61fdr\\xeb\\u08c1g\\u0180lmr\\u26ff\\u270d\\u2714eft\\u0100ar\\u09e6\\u2707ight\\xe1\\u09f2apsto;\\u67fcight\\xe1\\u09fdparrow\\u0100lr\\u2725\\u2729ef\\xf4\\u24edight;\\u61ac\\u0180afl\\u2736\\u2739\\u273dr;\\u6985;\\uc000\\ud835\\udd5dus;\\u6a2dimes;\\u6a34\\u0161\\u274b\\u274fst;\\u6217\\xe1\\u134e\\u0180;ef\\u2757\\u2758\\u1800\\u65cange\\xbb\\u2758ar\\u0100;l\\u2764\\u2765\\u4028t;\\u6993\\u0280achmt\\u2773\\u2776\\u277c\\u2785\\u2787r\\xf2\\u08a8orne\\xf2\\u1d8car\\u0100;d\\u0f98\\u2783;\\u696d;\\u600eri;\\u62bf\\u0300achiqt\\u2798\\u279d\\u0a40\\u27a2\\u27ae\\u27bbquo;\\u6039r;\\uc000\\ud835\\udcc1m\\u0180;eg\\u09b2\\u27aa\\u27ac;\\u6a8d;\\u6a8f\\u0100bu\\u252a\\u27b3o\\u0100;r\\u0e1f\\u27b9;\\u601arok;\\u4142\\u8400<;cdhilqr\\u082b\\u27d2\\u2639\\u27dc\\u27e0\\u27e5\\u27ea\\u27f0\\u0100ci\\u27d7\\u27d9;\\u6aa6r;\\u6a79re\\xe5\\u25f2mes;\\u62c9arr;\\u6976uest;\\u6a7b\\u0100Pi\\u27f5\\u27f9ar;\\u6996\\u0180;ef\\u2800\\u092d\\u181b\\u65c3r\\u0100du\\u2807\\u280dshar;\\u694ahar;\\u6966\\u0100en\\u2817\\u2821rtneqq;\\uc000\\u2268\\ufe00\\xc5\\u281e\\u0700Dacdefhilnopsu\\u2840\\u2845\\u2882\\u288e\\u2893\\u28a0\\u28a5\\u28a8\\u28da\\u28e2\\u28e4\\u0a83\\u28f3\\u2902Dot;\\u623a\\u0200clpr\\u284e\\u2852\\u2863\\u287dr\\u803b\\xaf\\u40af\\u0100et\\u2857\\u2859;\\u6642\\u0100;e\\u285e\\u285f\\u6720se\\xbb\\u285f\\u0100;s\\u103b\\u2868to\\u0200;dlu\\u103b\\u2873\\u2877\\u287bow\\xee\\u048cef\\xf4\\u090f\\xf0\\u13d1ker;\\u65ae\\u0100oy\\u2887\\u288cmma;\\u6a29;\\u443cash;\\u6014asuredangle\\xbb\\u1626r;\\uc000\\ud835\\udd2ao;\\u6127\\u0180cdn\\u28af\\u28b4\\u28c9ro\\u803b\\xb5\\u40b5\\u0200;acd\\u1464\\u28bd\\u28c0\\u28c4s\\xf4\\u16a7ir;\\u6af0ot\\u80bb\\xb7\\u01b5us\\u0180;bd\\u28d2\\u1903\\u28d3\\u6212\\u0100;u\\u1d3c\\u28d8;\\u6a2a\\u0163\\u28de\\u28e1p;\\u6adb\\xf2\\u2212\\xf0\\u0a81\\u0100dp\\u28e9\\u28eeels;\\u62a7f;\\uc000\\ud835\\udd5e\\u0100ct\\u28f8\\u28fdr;\\uc000\\ud835\\udcc2pos\\xbb\\u159d\\u0180;lm\\u2909\\u290a\\u290d\\u43bctimap;\\u62b8\\u0c00GLRVabcdefghijlmoprstuvw\\u2942\\u2953\\u297e\\u2989\\u2998\\u29da\\u29e9\\u2a15\\u2a1a\\u2a58\\u2a5d\\u2a83\\u2a95\\u2aa4\\u2aa8\\u2b04\\u2b07\\u2b44\\u2b7f\\u2bae\\u2c34\\u2c67\\u2c7c\\u2ce9\\u0100gt\\u2947\\u294b;\\uc000\\u22d9\\u0338\\u0100;v\\u2950\\u0bcf\\uc000\\u226b\\u20d2\\u0180elt\\u295a\\u2972\\u2976ft\\u0100ar\\u2961\\u2967rrow;\\u61cdightarrow;\\u61ce;\\uc000\\u22d8\\u0338\\u0100;v\\u297b\\u0c47\\uc000\\u226a\\u20d2ightarrow;\\u61cf\\u0100Dd\\u298e\\u2993ash;\\u62afash;\\u62ae\\u0280bcnpt\\u29a3\\u29a7\\u29ac\\u29b1\\u29ccla\\xbb\\u02deute;\\u4144g;\\uc000\\u2220\\u20d2\\u0280;Eiop\\u0d84\\u29bc\\u29c0\\u29c5\\u29c8;\\uc000\\u2a70\\u0338d;\\uc000\\u224b\\u0338s;\\u4149ro\\xf8\\u0d84ur\\u0100;a\\u29d3\\u29d4\\u666el\\u0100;s\\u29d3\\u0b38\\u01f3\\u29df\\0\\u29e3p\\u80bb\\xa0\\u0b37mp\\u0100;e\\u0bf9\\u0c00\\u0280aeouy\\u29f4\\u29fe\\u2a03\\u2a10\\u2a13\\u01f0\\u29f9\\0\\u29fb;\\u6a43on;\\u4148dil;\\u4146ng\\u0100;d\\u0d7e\\u2a0aot;\\uc000\\u2a6d\\u0338p;\\u6a42;\\u443dash;\\u6013\\u0380;Aadqsx\\u0b92\\u2a29\\u2a2d\\u2a3b\\u2a41\\u2a45\\u2a50rr;\\u61d7r\\u0100hr\\u2a33\\u2a36k;\\u6924\\u0100;o\\u13f2\\u13f0ot;\\uc000\\u2250\\u0338ui\\xf6\\u0b63\\u0100ei\\u2a4a\\u2a4ear;\\u6928\\xed\\u0b98ist\\u0100;s\\u0ba0\\u0b9fr;\\uc000\\ud835\\udd2b\\u0200Eest\\u0bc5\\u2a66\\u2a79\\u2a7c\\u0180;qs\\u0bbc\\u2a6d\\u0be1\\u0180;qs\\u0bbc\\u0bc5\\u2a74lan\\xf4\\u0be2i\\xed\\u0bea\\u0100;r\\u0bb6\\u2a81\\xbb\\u0bb7\\u0180Aap\\u2a8a\\u2a8d\\u2a91r\\xf2\\u2971rr;\\u61aear;\\u6af2\\u0180;sv\\u0f8d\\u2a9c\\u0f8c\\u0100;d\\u2aa1\\u2aa2\\u62fc;\\u62facy;\\u445a\\u0380AEadest\\u2ab7\\u2aba\\u2abe\\u2ac2\\u2ac5\\u2af6\\u2af9r\\xf2\\u2966;\\uc000\\u2266\\u0338rr;\\u619ar;\\u6025\\u0200;fqs\\u0c3b\\u2ace\\u2ae3\\u2aeft\\u0100ar\\u2ad4\\u2ad9rro\\xf7\\u2ac1ightarro\\xf7\\u2a90\\u0180;qs\\u0c3b\\u2aba\\u2aealan\\xf4\\u0c55\\u0100;s\\u0c55\\u2af4\\xbb\\u0c36i\\xed\\u0c5d\\u0100;r\\u0c35\\u2afei\\u0100;e\\u0c1a\\u0c25i\\xe4\\u0d90\\u0100pt\\u2b0c\\u2b11f;\\uc000\\ud835\\udd5f\\u8180\\xac;in\\u2b19\\u2b1a\\u2b36\\u40acn\\u0200;Edv\\u0b89\\u2b24\\u2b28\\u2b2e;\\uc000\\u22f9\\u0338ot;\\uc000\\u22f5\\u0338\\u01e1\\u0b89\\u2b33\\u2b35;\\u62f7;\\u62f6i\\u0100;v\\u0cb8\\u2b3c\\u01e1\\u0cb8\\u2b41\\u2b43;\\u62fe;\\u62fd\\u0180aor\\u2b4b\\u2b63\\u2b69r\\u0200;ast\\u0b7b\\u2b55\\u2b5a\\u2b5flle\\xec\\u0b7bl;\\uc000\\u2afd\\u20e5;\\uc000\\u2202\\u0338lint;\\u6a14\\u0180;ce\\u0c92\\u2b70\\u2b73u\\xe5\\u0ca5\\u0100;c\\u0c98\\u2b78\\u0100;e\\u0c92\\u2b7d\\xf1\\u0c98\\u0200Aait\\u2b88\\u2b8b\\u2b9d\\u2ba7r\\xf2\\u2988rr\\u0180;cw\\u2b94\\u2b95\\u2b99\\u619b;\\uc000\\u2933\\u0338;\\uc000\\u219d\\u0338ghtarrow\\xbb\\u2b95ri\\u0100;e\\u0ccb\\u0cd6\\u0380chimpqu\\u2bbd\\u2bcd\\u2bd9\\u2b04\\u0b78\\u2be4\\u2bef\\u0200;cer\\u0d32\\u2bc6\\u0d37\\u2bc9u\\xe5\\u0d45;\\uc000\\ud835\\udcc3ort\\u026d\\u2b05\\0\\0\\u2bd6ar\\xe1\\u2b56m\\u0100;e\\u0d6e\\u2bdf\\u0100;q\\u0d74\\u0d73su\\u0100bp\\u2beb\\u2bed\\xe5\\u0cf8\\xe5\\u0d0b\\u0180bcp\\u2bf6\\u2c11\\u2c19\\u0200;Ees\\u2bff\\u2c00\\u0d22\\u2c04\\u6284;\\uc000\\u2ac5\\u0338et\\u0100;e\\u0d1b\\u2c0bq\\u0100;q\\u0d23\\u2c00c\\u0100;e\\u0d32\\u2c17\\xf1\\u0d38\\u0200;Ees\\u2c22\\u2c23\\u0d5f\\u2c27\\u6285;\\uc000\\u2ac6\\u0338et\\u0100;e\\u0d58\\u2c2eq\\u0100;q\\u0d60\\u2c23\\u0200gilr\\u2c3d\\u2c3f\\u2c45\\u2c47\\xec\\u0bd7lde\\u803b\\xf1\\u40f1\\xe7\\u0c43iangle\\u0100lr\\u2c52\\u2c5ceft\\u0100;e\\u0c1a\\u2c5a\\xf1\\u0c26ight\\u0100;e\\u0ccb\\u2c65\\xf1\\u0cd7\\u0100;m\\u2c6c\\u2c6d\\u43bd\\u0180;es\\u2c74\\u2c75\\u2c79\\u4023ro;\\u6116p;\\u6007\\u0480DHadgilrs\\u2c8f\\u2c94\\u2c99\\u2c9e\\u2ca3\\u2cb0\\u2cb6\\u2cd3\\u2ce3ash;\\u62adarr;\\u6904p;\\uc000\\u224d\\u20d2ash;\\u62ac\\u0100et\\u2ca8\\u2cac;\\uc000\\u2265\\u20d2;\\uc000>\\u20d2nfin;\\u69de\\u0180Aet\\u2cbd\\u2cc1\\u2cc5rr;\\u6902;\\uc000\\u2264\\u20d2\\u0100;r\\u2cca\\u2ccd\\uc000<\\u20d2ie;\\uc000\\u22b4\\u20d2\\u0100At\\u2cd8\\u2cdcrr;\\u6903rie;\\uc000\\u22b5\\u20d2im;\\uc000\\u223c\\u20d2\\u0180Aan\\u2cf0\\u2cf4\\u2d02rr;\\u61d6r\\u0100hr\\u2cfa\\u2cfdk;\\u6923\\u0100;o\\u13e7\\u13e5ear;\\u6927\\u1253\\u1a95\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\u2d2d\\0\\u2d38\\u2d48\\u2d60\\u2d65\\u2d72\\u2d84\\u1b07\\0\\0\\u2d8d\\u2dab\\0\\u2dc8\\u2dce\\0\\u2ddc\\u2e19\\u2e2b\\u2e3e\\u2e43\\u0100cs\\u2d31\\u1a97ute\\u803b\\xf3\\u40f3\\u0100iy\\u2d3c\\u2d45r\\u0100;c\\u1a9e\\u2d42\\u803b\\xf4\\u40f4;\\u443e\\u0280abios\\u1aa0\\u2d52\\u2d57\\u01c8\\u2d5alac;\\u4151v;\\u6a38old;\\u69bclig;\\u4153\\u0100cr\\u2d69\\u2d6dir;\\u69bf;\\uc000\\ud835\\udd2c\\u036f\\u2d79\\0\\0\\u2d7c\\0\\u2d82n;\\u42dbave\\u803b\\xf2\\u40f2;\\u69c1\\u0100bm\\u2d88\\u0df4ar;\\u69b5\\u0200acit\\u2d95\\u2d98\\u2da5\\u2da8r\\xf2\\u1a80\\u0100ir\\u2d9d\\u2da0r;\\u69beoss;\\u69bbn\\xe5\\u0e52;\\u69c0\\u0180aei\\u2db1\\u2db5\\u2db9cr;\\u414dga;\\u43c9\\u0180cdn\\u2dc0\\u2dc5\\u01cdron;\\u43bf;\\u69b6pf;\\uc000\\ud835\\udd60\\u0180ael\\u2dd4\\u2dd7\\u01d2r;\\u69b7rp;\\u69b9\\u0380;adiosv\\u2dea\\u2deb\\u2dee\\u2e08\\u2e0d\\u2e10\\u2e16\\u6228r\\xf2\\u1a86\\u0200;efm\\u2df7\\u2df8\\u2e02\\u2e05\\u6a5dr\\u0100;o\\u2dfe\\u2dff\\u6134f\\xbb\\u2dff\\u803b\\xaa\\u40aa\\u803b\\xba\\u40bagof;\\u62b6r;\\u6a56lope;\\u6a57;\\u6a5b\\u0180clo\\u2e1f\\u2e21\\u2e27\\xf2\\u2e01ash\\u803b\\xf8\\u40f8l;\\u6298i\\u016c\\u2e2f\\u2e34de\\u803b\\xf5\\u40f5es\\u0100;a\\u01db\\u2e3as;\\u6a36ml\\u803b\\xf6\\u40f6bar;\\u633d\\u0ae1\\u2e5e\\0\\u2e7d\\0\\u2e80\\u2e9d\\0\\u2ea2\\u2eb9\\0\\0\\u2ecb\\u0e9c\\0\\u2f13\\0\\0\\u2f2b\\u2fbc\\0\\u2fc8r\\u0200;ast\\u0403\\u2e67\\u2e72\\u0e85\\u8100\\xb6;l\\u2e6d\\u2e6e\\u40b6le\\xec\\u0403\\u0269\\u2e78\\0\\0\\u2e7bm;\\u6af3;\\u6afdy;\\u443fr\\u0280cimpt\\u2e8b\\u2e8f\\u2e93\\u1865\\u2e97nt;\\u4025od;\\u402eil;\\u6030enk;\\u6031r;\\uc000\\ud835\\udd2d\\u0180imo\\u2ea8\\u2eb0\\u2eb4\\u0100;v\\u2ead\\u2eae\\u43c6;\\u43d5ma\\xf4\\u0a76ne;\\u660e\\u0180;tv\\u2ebf\\u2ec0\\u2ec8\\u43c0chfork\\xbb\\u1ffd;\\u43d6\\u0100au\\u2ecf\\u2edfn\\u0100ck\\u2ed5\\u2eddk\\u0100;h\\u21f4\\u2edb;\\u610e\\xf6\\u21f4s\\u0480;abcdemst\\u2ef3\\u2ef4\\u1908\\u2ef9\\u2efd\\u2f04\\u2f06\\u2f0a\\u2f0e\\u402bcir;\\u6a23ir;\\u6a22\\u0100ou\\u1d40\\u2f02;\\u6a25;\\u6a72n\\u80bb\\xb1\\u0e9dim;\\u6a26wo;\\u6a27\\u0180ipu\\u2f19\\u2f20\\u2f25ntint;\\u6a15f;\\uc000\\ud835\\udd61nd\\u803b\\xa3\\u40a3\\u0500;Eaceinosu\\u0ec8\\u2f3f\\u2f41\\u2f44\\u2f47\\u2f81\\u2f89\\u2f92\\u2f7e\\u2fb6;\\u6ab3p;\\u6ab7u\\xe5\\u0ed9\\u0100;c\\u0ece\\u2f4c\\u0300;acens\\u0ec8\\u2f59\\u2f5f\\u2f66\\u2f68\\u2f7eppro\\xf8\\u2f43urlye\\xf1\\u0ed9\\xf1\\u0ece\\u0180aes\\u2f6f\\u2f76\\u2f7approx;\\u6ab9qq;\\u6ab5im;\\u62e8i\\xed\\u0edfme\\u0100;s\\u2f88\\u0eae\\u6032\\u0180Eas\\u2f78\\u2f90\\u2f7a\\xf0\\u2f75\\u0180dfp\\u0eec\\u2f99\\u2faf\\u0180als\\u2fa0\\u2fa5\\u2faalar;\\u632eine;\\u6312urf;\\u6313\\u0100;t\\u0efb\\u2fb4\\xef\\u0efbrel;\\u62b0\\u0100ci\\u2fc0\\u2fc5r;\\uc000\\ud835\\udcc5;\\u43c8ncsp;\\u6008\\u0300fiopsu\\u2fda\\u22e2\\u2fdf\\u2fe5\\u2feb\\u2ff1r;\\uc000\\ud835\\udd2epf;\\uc000\\ud835\\udd62rime;\\u6057cr;\\uc000\\ud835\\udcc6\\u0180aeo\\u2ff8\\u3009\\u3013t\\u0100ei\\u2ffe\\u3005rnion\\xf3\\u06b0nt;\\u6a16st\\u0100;e\\u3010\\u3011\\u403f\\xf1\\u1f19\\xf4\\u0f14\\u0a80ABHabcdefhilmnoprstux\\u3040\\u3051\\u3055\\u3059\\u30e0\\u310e\\u312b\\u3147\\u3162\\u3172\\u318e\\u3206\\u3215\\u3224\\u3229\\u3258\\u326e\\u3272\\u3290\\u32b0\\u32b7\\u0180art\\u3047\\u304a\\u304cr\\xf2\\u10b3\\xf2\\u03ddail;\\u691car\\xf2\\u1c65ar;\\u6964\\u0380cdenqrt\\u3068\\u3075\\u3078\\u307f\\u308f\\u3094\\u30cc\\u0100eu\\u306d\\u3071;\\uc000\\u223d\\u0331te;\\u4155i\\xe3\\u116emptyv;\\u69b3g\\u0200;del\\u0fd1\\u3089\\u308b\\u308d;\\u6992;\\u69a5\\xe5\\u0fd1uo\\u803b\\xbb\\u40bbr\\u0580;abcfhlpstw\\u0fdc\\u30ac\\u30af\\u30b7\\u30b9\\u30bc\\u30be\\u30c0\\u30c3\\u30c7\\u30cap;\\u6975\\u0100;f\\u0fe0\\u30b4s;\\u6920;\\u6933s;\\u691e\\xeb\\u225d\\xf0\\u272el;\\u6945im;\\u6974l;\\u61a3;\\u619d\\u0100ai\\u30d1\\u30d5il;\\u691ao\\u0100;n\\u30db\\u30dc\\u6236al\\xf3\\u0f1e\\u0180abr\\u30e7\\u30ea\\u30eer\\xf2\\u17e5rk;\\u6773\\u0100ak\\u30f3\\u30fdc\\u0100ek\\u30f9\\u30fb;\\u407d;\\u405d\\u0100es\\u3102\\u3104;\\u698cl\\u0100du\\u310a\\u310c;\\u698e;\\u6990\\u0200aeuy\\u3117\\u311c\\u3127\\u3129ron;\\u4159\\u0100di\\u3121\\u3125il;\\u4157\\xec\\u0ff2\\xe2\\u30fa;\\u4440\\u0200clqs\\u3134\\u3137\\u313d\\u3144a;\\u6937dhar;\\u6969uo\\u0100;r\\u020e\\u020dh;\\u61b3\\u0180acg\\u314e\\u315f\\u0f44l\\u0200;ips\\u0f78\\u3158\\u315b\\u109cn\\xe5\\u10bbar\\xf4\\u0fa9t;\\u65ad\\u0180ilr\\u3169\\u1023\\u316esht;\\u697d;\\uc000\\ud835\\udd2f\\u0100ao\\u3177\\u3186r\\u0100du\\u317d\\u317f\\xbb\\u047b\\u0100;l\\u1091\\u3184;\\u696c\\u0100;v\\u318b\\u318c\\u43c1;\\u43f1\\u0180gns\\u3195\\u31f9\\u31fcht\\u0300ahlrst\\u31a4\\u31b0\\u31c2\\u31d8\\u31e4\\u31eerrow\\u0100;t\\u0fdc\\u31ada\\xe9\\u30c8arpoon\\u0100du\\u31bb\\u31bfow\\xee\\u317ep\\xbb\\u1092eft\\u0100ah\\u31ca\\u31d0rrow\\xf3\\u0feaarpoon\\xf3\\u0551ightarrows;\\u61c9quigarro\\xf7\\u30cbhreetimes;\\u62ccg;\\u42daingdotse\\xf1\\u1f32\\u0180ahm\\u320d\\u3210\\u3213r\\xf2\\u0feaa\\xf2\\u0551;\\u600foust\\u0100;a\\u321e\\u321f\\u63b1che\\xbb\\u321fmid;\\u6aee\\u0200abpt\\u3232\\u323d\\u3240\\u3252\\u0100nr\\u3237\\u323ag;\\u67edr;\\u61fer\\xeb\\u1003\\u0180afl\\u3247\\u324a\\u324er;\\u6986;\\uc000\\ud835\\udd63us;\\u6a2eimes;\\u6a35\\u0100ap\\u325d\\u3267r\\u0100;g\\u3263\\u3264\\u4029t;\\u6994olint;\\u6a12ar\\xf2\\u31e3\\u0200achq\\u327b\\u3280\\u10bc\\u3285quo;\\u603ar;\\uc000\\ud835\\udcc7\\u0100bu\\u30fb\\u328ao\\u0100;r\\u0214\\u0213\\u0180hir\\u3297\\u329b\\u32a0re\\xe5\\u31f8mes;\\u62cai\\u0200;efl\\u32aa\\u1059\\u1821\\u32ab\\u65b9tri;\\u69celuhar;\\u6968;\\u611e\\u0d61\\u32d5\\u32db\\u32df\\u332c\\u3338\\u3371\\0\\u337a\\u33a4\\0\\0\\u33ec\\u33f0\\0\\u3428\\u3448\\u345a\\u34ad\\u34b1\\u34ca\\u34f1\\0\\u3616\\0\\0\\u3633cute;\\u415bqu\\xef\\u27ba\\u0500;Eaceinpsy\\u11ed\\u32f3\\u32f5\\u32ff\\u3302\\u330b\\u330f\\u331f\\u3326\\u3329;\\u6ab4\\u01f0\\u32fa\\0\\u32fc;\\u6ab8on;\\u4161u\\xe5\\u11fe\\u0100;d\\u11f3\\u3307il;\\u415frc;\\u415d\\u0180Eas\\u3316\\u3318\\u331b;\\u6ab6p;\\u6abaim;\\u62e9olint;\\u6a13i\\xed\\u1204;\\u4441ot\\u0180;be\\u3334\\u1d47\\u3335\\u62c5;\\u6a66\\u0380Aacmstx\\u3346\\u334a\\u3357\\u335b\\u335e\\u3363\\u336drr;\\u61d8r\\u0100hr\\u3350\\u3352\\xeb\\u2228\\u0100;o\\u0a36\\u0a34t\\u803b\\xa7\\u40a7i;\\u403bwar;\\u6929m\\u0100in\\u3369\\xf0nu\\xf3\\xf1t;\\u6736r\\u0100;o\\u3376\\u2055\\uc000\\ud835\\udd30\\u0200acoy\\u3382\\u3386\\u3391\\u33a0rp;\\u666f\\u0100hy\\u338b\\u338fcy;\\u4449;\\u4448rt\\u026d\\u3399\\0\\0\\u339ci\\xe4\\u1464ara\\xec\\u2e6f\\u803b\\xad\\u40ad\\u0100gm\\u33a8\\u33b4ma\\u0180;fv\\u33b1\\u33b2\\u33b2\\u43c3;\\u43c2\\u0400;deglnpr\\u12ab\\u33c5\\u33c9\\u33ce\\u33d6\\u33de\\u33e1\\u33e6ot;\\u6a6a\\u0100;q\\u12b1\\u12b0\\u0100;E\\u33d3\\u33d4\\u6a9e;\\u6aa0\\u0100;E\\u33db\\u33dc\\u6a9d;\\u6a9fe;\\u6246lus;\\u6a24arr;\\u6972ar\\xf2\\u113d\\u0200aeit\\u33f8\\u3408\\u340f\\u3417\\u0100ls\\u33fd\\u3404lsetm\\xe9\\u336ahp;\\u6a33parsl;\\u69e4\\u0100dl\\u1463\\u3414e;\\u6323\\u0100;e\\u341c\\u341d\\u6aaa\\u0100;s\\u3422\\u3423\\u6aac;\\uc000\\u2aac\\ufe00\\u0180flp\\u342e\\u3433\\u3442tcy;\\u444c\\u0100;b\\u3438\\u3439\\u402f\\u0100;a\\u343e\\u343f\\u69c4r;\\u633ff;\\uc000\\ud835\\udd64a\\u0100dr\\u344d\\u0402es\\u0100;u\\u3454\\u3455\\u6660it\\xbb\\u3455\\u0180csu\\u3460\\u3479\\u349f\\u0100au\\u3465\\u346fp\\u0100;s\\u1188\\u346b;\\uc000\\u2293\\ufe00p\\u0100;s\\u11b4\\u3475;\\uc000\\u2294\\ufe00u\\u0100bp\\u347f\\u348f\\u0180;es\\u1197\\u119c\\u3486et\\u0100;e\\u1197\\u348d\\xf1\\u119d\\u0180;es\\u11a8\\u11ad\\u3496et\\u0100;e\\u11a8\\u349d\\xf1\\u11ae\\u0180;af\\u117b\\u34a6\\u05b0r\\u0165\\u34ab\\u05b1\\xbb\\u117car\\xf2\\u1148\\u0200cemt\\u34b9\\u34be\\u34c2\\u34c5r;\\uc000\\ud835\\udcc8tm\\xee\\xf1i\\xec\\u3415ar\\xe6\\u11be\\u0100ar\\u34ce\\u34d5r\\u0100;f\\u34d4\\u17bf\\u6606\\u0100an\\u34da\\u34edight\\u0100ep\\u34e3\\u34eapsilo\\xee\\u1ee0h\\xe9\\u2eafs\\xbb\\u2852\\u0280bcmnp\\u34fb\\u355e\\u1209\\u358b\\u358e\\u0480;Edemnprs\\u350e\\u350f\\u3511\\u3515\\u351e\\u3523\\u352c\\u3531\\u3536\\u6282;\\u6ac5ot;\\u6abd\\u0100;d\\u11da\\u351aot;\\u6ac3ult;\\u6ac1\\u0100Ee\\u3528\\u352a;\\u6acb;\\u628alus;\\u6abfarr;\\u6979\\u0180eiu\\u353d\\u3552\\u3555t\\u0180;en\\u350e\\u3545\\u354bq\\u0100;q\\u11da\\u350feq\\u0100;q\\u352b\\u3528m;\\u6ac7\\u0100bp\\u355a\\u355c;\\u6ad5;\\u6ad3c\\u0300;acens\\u11ed\\u356c\\u3572\\u3579\\u357b\\u3326ppro\\xf8\\u32faurlye\\xf1\\u11fe\\xf1\\u11f3\\u0180aes\\u3582\\u3588\\u331bppro\\xf8\\u331aq\\xf1\\u3317g;\\u666a\\u0680123;Edehlmnps\\u35a9\\u35ac\\u35af\\u121c\\u35b2\\u35b4\\u35c0\\u35c9\\u35d5\\u35da\\u35df\\u35e8\\u35ed\\u803b\\xb9\\u40b9\\u803b\\xb2\\u40b2\\u803b\\xb3\\u40b3;\\u6ac6\\u0100os\\u35b9\\u35bct;\\u6abeub;\\u6ad8\\u0100;d\\u1222\\u35c5ot;\\u6ac4s\\u0100ou\\u35cf\\u35d2l;\\u67c9b;\\u6ad7arr;\\u697bult;\\u6ac2\\u0100Ee\\u35e4\\u35e6;\\u6acc;\\u628blus;\\u6ac0\\u0180eiu\\u35f4\\u3609\\u360ct\\u0180;en\\u121c\\u35fc\\u3602q\\u0100;q\\u1222\\u35b2eq\\u0100;q\\u35e7\\u35e4m;\\u6ac8\\u0100bp\\u3611\\u3613;\\u6ad4;\\u6ad6\\u0180Aan\\u361c\\u3620\\u362drr;\\u61d9r\\u0100hr\\u3626\\u3628\\xeb\\u222e\\u0100;o\\u0a2b\\u0a29war;\\u692alig\\u803b\\xdf\\u40df\\u0be1\\u3651\\u365d\\u3660\\u12ce\\u3673\\u3679\\0\\u367e\\u36c2\\0\\0\\0\\0\\0\\u36db\\u3703\\0\\u3709\\u376c\\0\\0\\0\\u3787\\u0272\\u3656\\0\\0\\u365bget;\\u6316;\\u43c4r\\xeb\\u0e5f\\u0180aey\\u3666\\u366b\\u3670ron;\\u4165dil;\\u4163;\\u4442lrec;\\u6315r;\\uc000\\ud835\\udd31\\u0200eiko\\u3686\\u369d\\u36b5\\u36bc\\u01f2\\u368b\\0\\u3691e\\u01004f\\u1284\\u1281a\\u0180;sv\\u3698\\u3699\\u369b\\u43b8ym;\\u43d1\\u0100cn\\u36a2\\u36b2k\\u0100as\\u36a8\\u36aeppro\\xf8\\u12c1im\\xbb\\u12acs\\xf0\\u129e\\u0100as\\u36ba\\u36ae\\xf0\\u12c1rn\\u803b\\xfe\\u40fe\\u01ec\\u031f\\u36c6\\u22e7es\\u8180\\xd7;bd\\u36cf\\u36d0\\u36d8\\u40d7\\u0100;a\\u190f\\u36d5r;\\u6a31;\\u6a30\\u0180eps\\u36e1\\u36e3\\u3700\\xe1\\u2a4d\\u0200;bcf\\u0486\\u36ec\\u36f0\\u36f4ot;\\u6336ir;\\u6af1\\u0100;o\\u36f9\\u36fc\\uc000\\ud835\\udd65rk;\\u6ada\\xe1\\u3362rime;\\u6034\\u0180aip\\u370f\\u3712\\u3764d\\xe5\\u1248\\u0380adempst\\u3721\\u374d\\u3740\\u3751\\u3757\\u375c\\u375fngle\\u0280;dlqr\\u3730\\u3731\\u3736\\u3740\\u3742\\u65b5own\\xbb\\u1dbbeft\\u0100;e\\u2800\\u373e\\xf1\\u092e;\\u625cight\\u0100;e\\u32aa\\u374b\\xf1\\u105aot;\\u65ecinus;\\u6a3alus;\\u6a39b;\\u69cdime;\\u6a3bezium;\\u63e2\\u0180cht\\u3772\\u377d\\u3781\\u0100ry\\u3777\\u377b;\\uc000\\ud835\\udcc9;\\u4446cy;\\u445brok;\\u4167\\u0100io\\u378b\\u378ex\\xf4\\u1777head\\u0100lr\\u3797\\u37a0eftarro\\xf7\\u084fightarrow\\xbb\\u0f5d\\u0900AHabcdfghlmoprstuw\\u37d0\\u37d3\\u37d7\\u37e4\\u37f0\\u37fc\\u380e\\u381c\\u3823\\u3834\\u3851\\u385d\\u386b\\u38a9\\u38cc\\u38d2\\u38ea\\u38f6r\\xf2\\u03edar;\\u6963\\u0100cr\\u37dc\\u37e2ute\\u803b\\xfa\\u40fa\\xf2\\u1150r\\u01e3\\u37ea\\0\\u37edy;\\u445eve;\\u416d\\u0100iy\\u37f5\\u37farc\\u803b\\xfb\\u40fb;\\u4443\\u0180abh\\u3803\\u3806\\u380br\\xf2\\u13adlac;\\u4171a\\xf2\\u13c3\\u0100ir\\u3813\\u3818sht;\\u697e;\\uc000\\ud835\\udd32rave\\u803b\\xf9\\u40f9\\u0161\\u3827\\u3831r\\u0100lr\\u382c\\u382e\\xbb\\u0957\\xbb\\u1083lk;\\u6580\\u0100ct\\u3839\\u384d\\u026f\\u383f\\0\\0\\u384arn\\u0100;e\\u3845\\u3846\\u631cr\\xbb\\u3846op;\\u630fri;\\u65f8\\u0100al\\u3856\\u385acr;\\u416b\\u80bb\\xa8\\u0349\\u0100gp\\u3862\\u3866on;\\u4173f;\\uc000\\ud835\\udd66\\u0300adhlsu\\u114b\\u3878\\u387d\\u1372\\u3891\\u38a0own\\xe1\\u13b3arpoon\\u0100lr\\u3888\\u388cef\\xf4\\u382digh\\xf4\\u382fi\\u0180;hl\\u3899\\u389a\\u389c\\u43c5\\xbb\\u13faon\\xbb\\u389aparrows;\\u61c8\\u0180cit\\u38b0\\u38c4\\u38c8\\u026f\\u38b6\\0\\0\\u38c1rn\\u0100;e\\u38bc\\u38bd\\u631dr\\xbb\\u38bdop;\\u630eng;\\u416fri;\\u65f9cr;\\uc000\\ud835\\udcca\\u0180dir\\u38d9\\u38dd\\u38e2ot;\\u62f0lde;\\u4169i\\u0100;f\\u3730\\u38e8\\xbb\\u1813\\u0100am\\u38ef\\u38f2r\\xf2\\u38a8l\\u803b\\xfc\\u40fcangle;\\u69a7\\u0780ABDacdeflnoprsz\\u391c\\u391f\\u3929\\u392d\\u39b5\\u39b8\\u39bd\\u39df\\u39e4\\u39e8\\u39f3\\u39f9\\u39fd\\u3a01\\u3a20r\\xf2\\u03f7ar\\u0100;v\\u3926\\u3927\\u6ae8;\\u6ae9as\\xe8\\u03e1\\u0100nr\\u3932\\u3937grt;\\u699c\\u0380eknprst\\u34e3\\u3946\\u394b\\u3952\\u395d\\u3964\\u3996app\\xe1\\u2415othin\\xe7\\u1e96\\u0180hir\\u34eb\\u2ec8\\u3959op\\xf4\\u2fb5\\u0100;h\\u13b7\\u3962\\xef\\u318d\\u0100iu\\u3969\\u396dgm\\xe1\\u33b3\\u0100bp\\u3972\\u3984setneq\\u0100;q\\u397d\\u3980\\uc000\\u228a\\ufe00;\\uc000\\u2acb\\ufe00setneq\\u0100;q\\u398f\\u3992\\uc000\\u228b\\ufe00;\\uc000\\u2acc\\ufe00\\u0100hr\\u399b\\u399fet\\xe1\\u369ciangle\\u0100lr\\u39aa\\u39afeft\\xbb\\u0925ight\\xbb\\u1051y;\\u4432ash\\xbb\\u1036\\u0180elr\\u39c4\\u39d2\\u39d7\\u0180;be\\u2dea\\u39cb\\u39cfar;\\u62bbq;\\u625alip;\\u62ee\\u0100bt\\u39dc\\u1468a\\xf2\\u1469r;\\uc000\\ud835\\udd33tr\\xe9\\u39aesu\\u0100bp\\u39ef\\u39f1\\xbb\\u0d1c\\xbb\\u0d59pf;\\uc000\\ud835\\udd67ro\\xf0\\u0efbtr\\xe9\\u39b4\\u0100cu\\u3a06\\u3a0br;\\uc000\\ud835\\udccb\\u0100bp\\u3a10\\u3a18n\\u0100Ee\\u3980\\u3a16\\xbb\\u397en\\u0100Ee\\u3992\\u3a1e\\xbb\\u3990igzag;\\u699a\\u0380cefoprs\\u3a36\\u3a3b\\u3a56\\u3a5b\\u3a54\\u3a61\\u3a6airc;\\u4175\\u0100di\\u3a40\\u3a51\\u0100bg\\u3a45\\u3a49ar;\\u6a5fe\\u0100;q\\u15fa\\u3a4f;\\u6259erp;\\u6118r;\\uc000\\ud835\\udd34pf;\\uc000\\ud835\\udd68\\u0100;e\\u1479\\u3a66at\\xe8\\u1479cr;\\uc000\\ud835\\udccc\\u0ae3\\u178e\\u3a87\\0\\u3a8b\\0\\u3a90\\u3a9b\\0\\0\\u3a9d\\u3aa8\\u3aab\\u3aaf\\0\\0\\u3ac3\\u3ace\\0\\u3ad8\\u17dc\\u17dftr\\xe9\\u17d1r;\\uc000\\ud835\\udd35\\u0100Aa\\u3a94\\u3a97r\\xf2\\u03c3r\\xf2\\u09f6;\\u43be\\u0100Aa\\u3aa1\\u3aa4r\\xf2\\u03b8r\\xf2\\u09eba\\xf0\\u2713is;\\u62fb\\u0180dpt\\u17a4\\u3ab5\\u3abe\\u0100fl\\u3aba\\u17a9;\\uc000\\ud835\\udd69im\\xe5\\u17b2\\u0100Aa\\u3ac7\\u3acar\\xf2\\u03cer\\xf2\\u0a01\\u0100cq\\u3ad2\\u17b8r;\\uc000\\ud835\\udccd\\u0100pt\\u17d6\\u3adcr\\xe9\\u17d4\\u0400acefiosu\\u3af0\\u3afd\\u3b08\\u3b0c\\u3b11\\u3b15\\u3b1b\\u3b21c\\u0100uy\\u3af6\\u3afbte\\u803b\\xfd\\u40fd;\\u444f\\u0100iy\\u3b02\\u3b06rc;\\u4177;\\u444bn\\u803b\\xa5\\u40a5r;\\uc000\\ud835\\udd36cy;\\u4457pf;\\uc000\\ud835\\udd6acr;\\uc000\\ud835\\udcce\\u0100cm\\u3b26\\u3b29y;\\u444el\\u803b\\xff\\u40ff\\u0500acdefhiosw\\u3b42\\u3b48\\u3b54\\u3b58\\u3b64\\u3b69\\u3b6d\\u3b74\\u3b7a\\u3b80cute;\\u417a\\u0100ay\\u3b4d\\u3b52ron;\\u417e;\\u4437ot;\\u417c\\u0100et\\u3b5d\\u3b61tr\\xe6\\u155fa;\\u43b6r;\\uc000\\ud835\\udd37cy;\\u4436grarr;\\u61ddpf;\\uc000\\ud835\\udd6bcr;\\uc000\\ud835\\udccf\\u0100jn\\u3b85\\u3b87;\\u600dj;\\u600c\"\n    .split(\"\")\n    .map((c) => c.charCodeAt(0)));\n\n// Generated using scripts/write-decode-map.ts\nnew Uint16Array(\n// prettier-ignore\n\"\\u0200aglq\\t\\x15\\x18\\x1b\\u026d\\x0f\\0\\0\\x12p;\\u4026os;\\u4027t;\\u403et;\\u403cuot;\\u4022\"\n    .split(\"\")\n    .map((c) => c.charCodeAt(0)));\n\nvar CharCodes;\n(function (CharCodes) {\n    CharCodes[CharCodes[\"NUM\"] = 35] = \"NUM\";\n    CharCodes[CharCodes[\"SEMI\"] = 59] = \"SEMI\";\n    CharCodes[CharCodes[\"ZERO\"] = 48] = \"ZERO\";\n    CharCodes[CharCodes[\"NINE\"] = 57] = \"NINE\";\n    CharCodes[CharCodes[\"LOWER_A\"] = 97] = \"LOWER_A\";\n    CharCodes[CharCodes[\"LOWER_F\"] = 102] = \"LOWER_F\";\n    CharCodes[CharCodes[\"LOWER_X\"] = 120] = \"LOWER_X\";\n    /** Bit that needs to be set to convert an upper case ASCII character to lower case */\n    CharCodes[CharCodes[\"To_LOWER_BIT\"] = 32] = \"To_LOWER_BIT\";\n})(CharCodes || (CharCodes = {}));\nvar BinTrieFlags;\n(function (BinTrieFlags) {\n    BinTrieFlags[BinTrieFlags[\"VALUE_LENGTH\"] = 49152] = \"VALUE_LENGTH\";\n    BinTrieFlags[BinTrieFlags[\"BRANCH_LENGTH\"] = 16256] = \"BRANCH_LENGTH\";\n    BinTrieFlags[BinTrieFlags[\"JUMP_TABLE\"] = 127] = \"JUMP_TABLE\";\n})(BinTrieFlags || (BinTrieFlags = {}));\nfunction determineBranch(decodeTree, current, nodeIdx, char) {\n    const branchCount = (current & BinTrieFlags.BRANCH_LENGTH) >> 7;\n    const jumpOffset = current & BinTrieFlags.JUMP_TABLE;\n    // Case 1: Single branch encoded in jump offset\n    if (branchCount === 0) {\n        return jumpOffset !== 0 && char === jumpOffset ? nodeIdx : -1;\n    }\n    // Case 2: Multiple branches encoded in jump table\n    if (jumpOffset) {\n        const value = char - jumpOffset;\n        return value < 0 || value >= branchCount\n            ? -1\n            : decodeTree[nodeIdx + value] - 1;\n    }\n    // Case 3: Multiple branches encoded in dictionary\n    // Binary search for the character.\n    let lo = nodeIdx;\n    let hi = lo + branchCount - 1;\n    while (lo <= hi) {\n        const mid = (lo + hi) >>> 1;\n        const midVal = decodeTree[mid];\n        if (midVal < char) {\n            lo = mid + 1;\n        }\n        else if (midVal > char) {\n            hi = mid - 1;\n        }\n        else {\n            return decodeTree[mid + branchCount];\n        }\n    }\n    return -1;\n}\n\n/** All valid namespaces in HTML. */\nvar NS;\n(function (NS) {\n    NS[\"HTML\"] = \"http://www.w3.org/1999/xhtml\";\n    NS[\"MATHML\"] = \"http://www.w3.org/1998/Math/MathML\";\n    NS[\"SVG\"] = \"http://www.w3.org/2000/svg\";\n    NS[\"XLINK\"] = \"http://www.w3.org/1999/xlink\";\n    NS[\"XML\"] = \"http://www.w3.org/XML/1998/namespace\";\n    NS[\"XMLNS\"] = \"http://www.w3.org/2000/xmlns/\";\n})(NS = NS || (NS = {}));\nvar ATTRS;\n(function (ATTRS) {\n    ATTRS[\"TYPE\"] = \"type\";\n    ATTRS[\"ACTION\"] = \"action\";\n    ATTRS[\"ENCODING\"] = \"encoding\";\n    ATTRS[\"PROMPT\"] = \"prompt\";\n    ATTRS[\"NAME\"] = \"name\";\n    ATTRS[\"COLOR\"] = \"color\";\n    ATTRS[\"FACE\"] = \"face\";\n    ATTRS[\"SIZE\"] = \"size\";\n})(ATTRS = ATTRS || (ATTRS = {}));\n/**\n * The mode of the document.\n *\n * @see {@link https://dom.spec.whatwg.org/#concept-document-limited-quirks}\n */\nvar DOCUMENT_MODE;\n(function (DOCUMENT_MODE) {\n    DOCUMENT_MODE[\"NO_QUIRKS\"] = \"no-quirks\";\n    DOCUMENT_MODE[\"QUIRKS\"] = \"quirks\";\n    DOCUMENT_MODE[\"LIMITED_QUIRKS\"] = \"limited-quirks\";\n})(DOCUMENT_MODE = DOCUMENT_MODE || (DOCUMENT_MODE = {}));\nvar TAG_NAMES;\n(function (TAG_NAMES) {\n    TAG_NAMES[\"A\"] = \"a\";\n    TAG_NAMES[\"ADDRESS\"] = \"address\";\n    TAG_NAMES[\"ANNOTATION_XML\"] = \"annotation-xml\";\n    TAG_NAMES[\"APPLET\"] = \"applet\";\n    TAG_NAMES[\"AREA\"] = \"area\";\n    TAG_NAMES[\"ARTICLE\"] = \"article\";\n    TAG_NAMES[\"ASIDE\"] = \"aside\";\n    TAG_NAMES[\"B\"] = \"b\";\n    TAG_NAMES[\"BASE\"] = \"base\";\n    TAG_NAMES[\"BASEFONT\"] = \"basefont\";\n    TAG_NAMES[\"BGSOUND\"] = \"bgsound\";\n    TAG_NAMES[\"BIG\"] = \"big\";\n    TAG_NAMES[\"BLOCKQUOTE\"] = \"blockquote\";\n    TAG_NAMES[\"BODY\"] = \"body\";\n    TAG_NAMES[\"BR\"] = \"br\";\n    TAG_NAMES[\"BUTTON\"] = \"button\";\n    TAG_NAMES[\"CAPTION\"] = \"caption\";\n    TAG_NAMES[\"CENTER\"] = \"center\";\n    TAG_NAMES[\"CODE\"] = \"code\";\n    TAG_NAMES[\"COL\"] = \"col\";\n    TAG_NAMES[\"COLGROUP\"] = \"colgroup\";\n    TAG_NAMES[\"DD\"] = \"dd\";\n    TAG_NAMES[\"DESC\"] = \"desc\";\n    TAG_NAMES[\"DETAILS\"] = \"details\";\n    TAG_NAMES[\"DIALOG\"] = \"dialog\";\n    TAG_NAMES[\"DIR\"] = \"dir\";\n    TAG_NAMES[\"DIV\"] = \"div\";\n    TAG_NAMES[\"DL\"] = \"dl\";\n    TAG_NAMES[\"DT\"] = \"dt\";\n    TAG_NAMES[\"EM\"] = \"em\";\n    TAG_NAMES[\"EMBED\"] = \"embed\";\n    TAG_NAMES[\"FIELDSET\"] = \"fieldset\";\n    TAG_NAMES[\"FIGCAPTION\"] = \"figcaption\";\n    TAG_NAMES[\"FIGURE\"] = \"figure\";\n    TAG_NAMES[\"FONT\"] = \"font\";\n    TAG_NAMES[\"FOOTER\"] = \"footer\";\n    TAG_NAMES[\"FOREIGN_OBJECT\"] = \"foreignObject\";\n    TAG_NAMES[\"FORM\"] = \"form\";\n    TAG_NAMES[\"FRAME\"] = \"frame\";\n    TAG_NAMES[\"FRAMESET\"] = \"frameset\";\n    TAG_NAMES[\"H1\"] = \"h1\";\n    TAG_NAMES[\"H2\"] = \"h2\";\n    TAG_NAMES[\"H3\"] = \"h3\";\n    TAG_NAMES[\"H4\"] = \"h4\";\n    TAG_NAMES[\"H5\"] = \"h5\";\n    TAG_NAMES[\"H6\"] = \"h6\";\n    TAG_NAMES[\"HEAD\"] = \"head\";\n    TAG_NAMES[\"HEADER\"] = \"header\";\n    TAG_NAMES[\"HGROUP\"] = \"hgroup\";\n    TAG_NAMES[\"HR\"] = \"hr\";\n    TAG_NAMES[\"HTML\"] = \"html\";\n    TAG_NAMES[\"I\"] = \"i\";\n    TAG_NAMES[\"IMG\"] = \"img\";\n    TAG_NAMES[\"IMAGE\"] = \"image\";\n    TAG_NAMES[\"INPUT\"] = \"input\";\n    TAG_NAMES[\"IFRAME\"] = \"iframe\";\n    TAG_NAMES[\"KEYGEN\"] = \"keygen\";\n    TAG_NAMES[\"LABEL\"] = \"label\";\n    TAG_NAMES[\"LI\"] = \"li\";\n    TAG_NAMES[\"LINK\"] = \"link\";\n    TAG_NAMES[\"LISTING\"] = \"listing\";\n    TAG_NAMES[\"MAIN\"] = \"main\";\n    TAG_NAMES[\"MALIGNMARK\"] = \"malignmark\";\n    TAG_NAMES[\"MARQUEE\"] = \"marquee\";\n    TAG_NAMES[\"MATH\"] = \"math\";\n    TAG_NAMES[\"MENU\"] = \"menu\";\n    TAG_NAMES[\"META\"] = \"meta\";\n    TAG_NAMES[\"MGLYPH\"] = \"mglyph\";\n    TAG_NAMES[\"MI\"] = \"mi\";\n    TAG_NAMES[\"MO\"] = \"mo\";\n    TAG_NAMES[\"MN\"] = \"mn\";\n    TAG_NAMES[\"MS\"] = \"ms\";\n    TAG_NAMES[\"MTEXT\"] = \"mtext\";\n    TAG_NAMES[\"NAV\"] = \"nav\";\n    TAG_NAMES[\"NOBR\"] = \"nobr\";\n    TAG_NAMES[\"NOFRAMES\"] = \"noframes\";\n    TAG_NAMES[\"NOEMBED\"] = \"noembed\";\n    TAG_NAMES[\"NOSCRIPT\"] = \"noscript\";\n    TAG_NAMES[\"OBJECT\"] = \"object\";\n    TAG_NAMES[\"OL\"] = \"ol\";\n    TAG_NAMES[\"OPTGROUP\"] = \"optgroup\";\n    TAG_NAMES[\"OPTION\"] = \"option\";\n    TAG_NAMES[\"P\"] = \"p\";\n    TAG_NAMES[\"PARAM\"] = \"param\";\n    TAG_NAMES[\"PLAINTEXT\"] = \"plaintext\";\n    TAG_NAMES[\"PRE\"] = \"pre\";\n    TAG_NAMES[\"RB\"] = \"rb\";\n    TAG_NAMES[\"RP\"] = \"rp\";\n    TAG_NAMES[\"RT\"] = \"rt\";\n    TAG_NAMES[\"RTC\"] = \"rtc\";\n    TAG_NAMES[\"RUBY\"] = \"ruby\";\n    TAG_NAMES[\"S\"] = \"s\";\n    TAG_NAMES[\"SCRIPT\"] = \"script\";\n    TAG_NAMES[\"SECTION\"] = \"section\";\n    TAG_NAMES[\"SELECT\"] = \"select\";\n    TAG_NAMES[\"SOURCE\"] = \"source\";\n    TAG_NAMES[\"SMALL\"] = \"small\";\n    TAG_NAMES[\"SPAN\"] = \"span\";\n    TAG_NAMES[\"STRIKE\"] = \"strike\";\n    TAG_NAMES[\"STRONG\"] = \"strong\";\n    TAG_NAMES[\"STYLE\"] = \"style\";\n    TAG_NAMES[\"SUB\"] = \"sub\";\n    TAG_NAMES[\"SUMMARY\"] = \"summary\";\n    TAG_NAMES[\"SUP\"] = \"sup\";\n    TAG_NAMES[\"TABLE\"] = \"table\";\n    TAG_NAMES[\"TBODY\"] = \"tbody\";\n    TAG_NAMES[\"TEMPLATE\"] = \"template\";\n    TAG_NAMES[\"TEXTAREA\"] = \"textarea\";\n    TAG_NAMES[\"TFOOT\"] = \"tfoot\";\n    TAG_NAMES[\"TD\"] = \"td\";\n    TAG_NAMES[\"TH\"] = \"th\";\n    TAG_NAMES[\"THEAD\"] = \"thead\";\n    TAG_NAMES[\"TITLE\"] = \"title\";\n    TAG_NAMES[\"TR\"] = \"tr\";\n    TAG_NAMES[\"TRACK\"] = \"track\";\n    TAG_NAMES[\"TT\"] = \"tt\";\n    TAG_NAMES[\"U\"] = \"u\";\n    TAG_NAMES[\"UL\"] = \"ul\";\n    TAG_NAMES[\"SVG\"] = \"svg\";\n    TAG_NAMES[\"VAR\"] = \"var\";\n    TAG_NAMES[\"WBR\"] = \"wbr\";\n    TAG_NAMES[\"XMP\"] = \"xmp\";\n})(TAG_NAMES = TAG_NAMES || (TAG_NAMES = {}));\n/**\n * Tag IDs are numeric IDs for known tag names.\n *\n * We use tag IDs to improve the performance of tag name comparisons.\n */\nvar TAG_ID;\n(function (TAG_ID) {\n    TAG_ID[TAG_ID[\"UNKNOWN\"] = 0] = \"UNKNOWN\";\n    TAG_ID[TAG_ID[\"A\"] = 1] = \"A\";\n    TAG_ID[TAG_ID[\"ADDRESS\"] = 2] = \"ADDRESS\";\n    TAG_ID[TAG_ID[\"ANNOTATION_XML\"] = 3] = \"ANNOTATION_XML\";\n    TAG_ID[TAG_ID[\"APPLET\"] = 4] = \"APPLET\";\n    TAG_ID[TAG_ID[\"AREA\"] = 5] = \"AREA\";\n    TAG_ID[TAG_ID[\"ARTICLE\"] = 6] = \"ARTICLE\";\n    TAG_ID[TAG_ID[\"ASIDE\"] = 7] = \"ASIDE\";\n    TAG_ID[TAG_ID[\"B\"] = 8] = \"B\";\n    TAG_ID[TAG_ID[\"BASE\"] = 9] = \"BASE\";\n    TAG_ID[TAG_ID[\"BASEFONT\"] = 10] = \"BASEFONT\";\n    TAG_ID[TAG_ID[\"BGSOUND\"] = 11] = \"BGSOUND\";\n    TAG_ID[TAG_ID[\"BIG\"] = 12] = \"BIG\";\n    TAG_ID[TAG_ID[\"BLOCKQUOTE\"] = 13] = \"BLOCKQUOTE\";\n    TAG_ID[TAG_ID[\"BODY\"] = 14] = \"BODY\";\n    TAG_ID[TAG_ID[\"BR\"] = 15] = \"BR\";\n    TAG_ID[TAG_ID[\"BUTTON\"] = 16] = \"BUTTON\";\n    TAG_ID[TAG_ID[\"CAPTION\"] = 17] = \"CAPTION\";\n    TAG_ID[TAG_ID[\"CENTER\"] = 18] = \"CENTER\";\n    TAG_ID[TAG_ID[\"CODE\"] = 19] = \"CODE\";\n    TAG_ID[TAG_ID[\"COL\"] = 20] = \"COL\";\n    TAG_ID[TAG_ID[\"COLGROUP\"] = 21] = \"COLGROUP\";\n    TAG_ID[TAG_ID[\"DD\"] = 22] = \"DD\";\n    TAG_ID[TAG_ID[\"DESC\"] = 23] = \"DESC\";\n    TAG_ID[TAG_ID[\"DETAILS\"] = 24] = \"DETAILS\";\n    TAG_ID[TAG_ID[\"DIALOG\"] = 25] = \"DIALOG\";\n    TAG_ID[TAG_ID[\"DIR\"] = 26] = \"DIR\";\n    TAG_ID[TAG_ID[\"DIV\"] = 27] = \"DIV\";\n    TAG_ID[TAG_ID[\"DL\"] = 28] = \"DL\";\n    TAG_ID[TAG_ID[\"DT\"] = 29] = \"DT\";\n    TAG_ID[TAG_ID[\"EM\"] = 30] = \"EM\";\n    TAG_ID[TAG_ID[\"EMBED\"] = 31] = \"EMBED\";\n    TAG_ID[TAG_ID[\"FIELDSET\"] = 32] = \"FIELDSET\";\n    TAG_ID[TAG_ID[\"FIGCAPTION\"] = 33] = \"FIGCAPTION\";\n    TAG_ID[TAG_ID[\"FIGURE\"] = 34] = \"FIGURE\";\n    TAG_ID[TAG_ID[\"FONT\"] = 35] = \"FONT\";\n    TAG_ID[TAG_ID[\"FOOTER\"] = 36] = \"FOOTER\";\n    TAG_ID[TAG_ID[\"FOREIGN_OBJECT\"] = 37] = \"FOREIGN_OBJECT\";\n    TAG_ID[TAG_ID[\"FORM\"] = 38] = \"FORM\";\n    TAG_ID[TAG_ID[\"FRAME\"] = 39] = \"FRAME\";\n    TAG_ID[TAG_ID[\"FRAMESET\"] = 40] = \"FRAMESET\";\n    TAG_ID[TAG_ID[\"H1\"] = 41] = \"H1\";\n    TAG_ID[TAG_ID[\"H2\"] = 42] = \"H2\";\n    TAG_ID[TAG_ID[\"H3\"] = 43] = \"H3\";\n    TAG_ID[TAG_ID[\"H4\"] = 44] = \"H4\";\n    TAG_ID[TAG_ID[\"H5\"] = 45] = \"H5\";\n    TAG_ID[TAG_ID[\"H6\"] = 46] = \"H6\";\n    TAG_ID[TAG_ID[\"HEAD\"] = 47] = \"HEAD\";\n    TAG_ID[TAG_ID[\"HEADER\"] = 48] = \"HEADER\";\n    TAG_ID[TAG_ID[\"HGROUP\"] = 49] = \"HGROUP\";\n    TAG_ID[TAG_ID[\"HR\"] = 50] = \"HR\";\n    TAG_ID[TAG_ID[\"HTML\"] = 51] = \"HTML\";\n    TAG_ID[TAG_ID[\"I\"] = 52] = \"I\";\n    TAG_ID[TAG_ID[\"IMG\"] = 53] = \"IMG\";\n    TAG_ID[TAG_ID[\"IMAGE\"] = 54] = \"IMAGE\";\n    TAG_ID[TAG_ID[\"INPUT\"] = 55] = \"INPUT\";\n    TAG_ID[TAG_ID[\"IFRAME\"] = 56] = \"IFRAME\";\n    TAG_ID[TAG_ID[\"KEYGEN\"] = 57] = \"KEYGEN\";\n    TAG_ID[TAG_ID[\"LABEL\"] = 58] = \"LABEL\";\n    TAG_ID[TAG_ID[\"LI\"] = 59] = \"LI\";\n    TAG_ID[TAG_ID[\"LINK\"] = 60] = \"LINK\";\n    TAG_ID[TAG_ID[\"LISTING\"] = 61] = \"LISTING\";\n    TAG_ID[TAG_ID[\"MAIN\"] = 62] = \"MAIN\";\n    TAG_ID[TAG_ID[\"MALIGNMARK\"] = 63] = \"MALIGNMARK\";\n    TAG_ID[TAG_ID[\"MARQUEE\"] = 64] = \"MARQUEE\";\n    TAG_ID[TAG_ID[\"MATH\"] = 65] = \"MATH\";\n    TAG_ID[TAG_ID[\"MENU\"] = 66] = \"MENU\";\n    TAG_ID[TAG_ID[\"META\"] = 67] = \"META\";\n    TAG_ID[TAG_ID[\"MGLYPH\"] = 68] = \"MGLYPH\";\n    TAG_ID[TAG_ID[\"MI\"] = 69] = \"MI\";\n    TAG_ID[TAG_ID[\"MO\"] = 70] = \"MO\";\n    TAG_ID[TAG_ID[\"MN\"] = 71] = \"MN\";\n    TAG_ID[TAG_ID[\"MS\"] = 72] = \"MS\";\n    TAG_ID[TAG_ID[\"MTEXT\"] = 73] = \"MTEXT\";\n    TAG_ID[TAG_ID[\"NAV\"] = 74] = \"NAV\";\n    TAG_ID[TAG_ID[\"NOBR\"] = 75] = \"NOBR\";\n    TAG_ID[TAG_ID[\"NOFRAMES\"] = 76] = \"NOFRAMES\";\n    TAG_ID[TAG_ID[\"NOEMBED\"] = 77] = \"NOEMBED\";\n    TAG_ID[TAG_ID[\"NOSCRIPT\"] = 78] = \"NOSCRIPT\";\n    TAG_ID[TAG_ID[\"OBJECT\"] = 79] = \"OBJECT\";\n    TAG_ID[TAG_ID[\"OL\"] = 80] = \"OL\";\n    TAG_ID[TAG_ID[\"OPTGROUP\"] = 81] = \"OPTGROUP\";\n    TAG_ID[TAG_ID[\"OPTION\"] = 82] = \"OPTION\";\n    TAG_ID[TAG_ID[\"P\"] = 83] = \"P\";\n    TAG_ID[TAG_ID[\"PARAM\"] = 84] = \"PARAM\";\n    TAG_ID[TAG_ID[\"PLAINTEXT\"] = 85] = \"PLAINTEXT\";\n    TAG_ID[TAG_ID[\"PRE\"] = 86] = \"PRE\";\n    TAG_ID[TAG_ID[\"RB\"] = 87] = \"RB\";\n    TAG_ID[TAG_ID[\"RP\"] = 88] = \"RP\";\n    TAG_ID[TAG_ID[\"RT\"] = 89] = \"RT\";\n    TAG_ID[TAG_ID[\"RTC\"] = 90] = \"RTC\";\n    TAG_ID[TAG_ID[\"RUBY\"] = 91] = \"RUBY\";\n    TAG_ID[TAG_ID[\"S\"] = 92] = \"S\";\n    TAG_ID[TAG_ID[\"SCRIPT\"] = 93] = \"SCRIPT\";\n    TAG_ID[TAG_ID[\"SECTION\"] = 94] = \"SECTION\";\n    TAG_ID[TAG_ID[\"SELECT\"] = 95] = \"SELECT\";\n    TAG_ID[TAG_ID[\"SOURCE\"] = 96] = \"SOURCE\";\n    TAG_ID[TAG_ID[\"SMALL\"] = 97] = \"SMALL\";\n    TAG_ID[TAG_ID[\"SPAN\"] = 98] = \"SPAN\";\n    TAG_ID[TAG_ID[\"STRIKE\"] = 99] = \"STRIKE\";\n    TAG_ID[TAG_ID[\"STRONG\"] = 100] = \"STRONG\";\n    TAG_ID[TAG_ID[\"STYLE\"] = 101] = \"STYLE\";\n    TAG_ID[TAG_ID[\"SUB\"] = 102] = \"SUB\";\n    TAG_ID[TAG_ID[\"SUMMARY\"] = 103] = \"SUMMARY\";\n    TAG_ID[TAG_ID[\"SUP\"] = 104] = \"SUP\";\n    TAG_ID[TAG_ID[\"TABLE\"] = 105] = \"TABLE\";\n    TAG_ID[TAG_ID[\"TBODY\"] = 106] = \"TBODY\";\n    TAG_ID[TAG_ID[\"TEMPLATE\"] = 107] = \"TEMPLATE\";\n    TAG_ID[TAG_ID[\"TEXTAREA\"] = 108] = \"TEXTAREA\";\n    TAG_ID[TAG_ID[\"TFOOT\"] = 109] = \"TFOOT\";\n    TAG_ID[TAG_ID[\"TD\"] = 110] = \"TD\";\n    TAG_ID[TAG_ID[\"TH\"] = 111] = \"TH\";\n    TAG_ID[TAG_ID[\"THEAD\"] = 112] = \"THEAD\";\n    TAG_ID[TAG_ID[\"TITLE\"] = 113] = \"TITLE\";\n    TAG_ID[TAG_ID[\"TR\"] = 114] = \"TR\";\n    TAG_ID[TAG_ID[\"TRACK\"] = 115] = \"TRACK\";\n    TAG_ID[TAG_ID[\"TT\"] = 116] = \"TT\";\n    TAG_ID[TAG_ID[\"U\"] = 117] = \"U\";\n    TAG_ID[TAG_ID[\"UL\"] = 118] = \"UL\";\n    TAG_ID[TAG_ID[\"SVG\"] = 119] = \"SVG\";\n    TAG_ID[TAG_ID[\"VAR\"] = 120] = \"VAR\";\n    TAG_ID[TAG_ID[\"WBR\"] = 121] = \"WBR\";\n    TAG_ID[TAG_ID[\"XMP\"] = 122] = \"XMP\";\n})(TAG_ID = TAG_ID || (TAG_ID = {}));\nconst TAG_NAME_TO_ID = new Map([\n    [TAG_NAMES.A, TAG_ID.A],\n    [TAG_NAMES.ADDRESS, TAG_ID.ADDRESS],\n    [TAG_NAMES.ANNOTATION_XML, TAG_ID.ANNOTATION_XML],\n    [TAG_NAMES.APPLET, TAG_ID.APPLET],\n    [TAG_NAMES.AREA, TAG_ID.AREA],\n    [TAG_NAMES.ARTICLE, TAG_ID.ARTICLE],\n    [TAG_NAMES.ASIDE, TAG_ID.ASIDE],\n    [TAG_NAMES.B, TAG_ID.B],\n    [TAG_NAMES.BASE, TAG_ID.BASE],\n    [TAG_NAMES.BASEFONT, TAG_ID.BASEFONT],\n    [TAG_NAMES.BGSOUND, TAG_ID.BGSOUND],\n    [TAG_NAMES.BIG, TAG_ID.BIG],\n    [TAG_NAMES.BLOCKQUOTE, TAG_ID.BLOCKQUOTE],\n    [TAG_NAMES.BODY, TAG_ID.BODY],\n    [TAG_NAMES.BR, TAG_ID.BR],\n    [TAG_NAMES.BUTTON, TAG_ID.BUTTON],\n    [TAG_NAMES.CAPTION, TAG_ID.CAPTION],\n    [TAG_NAMES.CENTER, TAG_ID.CENTER],\n    [TAG_NAMES.CODE, TAG_ID.CODE],\n    [TAG_NAMES.COL, TAG_ID.COL],\n    [TAG_NAMES.COLGROUP, TAG_ID.COLGROUP],\n    [TAG_NAMES.DD, TAG_ID.DD],\n    [TAG_NAMES.DESC, TAG_ID.DESC],\n    [TAG_NAMES.DETAILS, TAG_ID.DETAILS],\n    [TAG_NAMES.DIALOG, TAG_ID.DIALOG],\n    [TAG_NAMES.DIR, TAG_ID.DIR],\n    [TAG_NAMES.DIV, TAG_ID.DIV],\n    [TAG_NAMES.DL, TAG_ID.DL],\n    [TAG_NAMES.DT, TAG_ID.DT],\n    [TAG_NAMES.EM, TAG_ID.EM],\n    [TAG_NAMES.EMBED, TAG_ID.EMBED],\n    [TAG_NAMES.FIELDSET, TAG_ID.FIELDSET],\n    [TAG_NAMES.FIGCAPTION, TAG_ID.FIGCAPTION],\n    [TAG_NAMES.FIGURE, TAG_ID.FIGURE],\n    [TAG_NAMES.FONT, TAG_ID.FONT],\n    [TAG_NAMES.FOOTER, TAG_ID.FOOTER],\n    [TAG_NAMES.FOREIGN_OBJECT, TAG_ID.FOREIGN_OBJECT],\n    [TAG_NAMES.FORM, TAG_ID.FORM],\n    [TAG_NAMES.FRAME, TAG_ID.FRAME],\n    [TAG_NAMES.FRAMESET, TAG_ID.FRAMESET],\n    [TAG_NAMES.H1, TAG_ID.H1],\n    [TAG_NAMES.H2, TAG_ID.H2],\n    [TAG_NAMES.H3, TAG_ID.H3],\n    [TAG_NAMES.H4, TAG_ID.H4],\n    [TAG_NAMES.H5, TAG_ID.H5],\n    [TAG_NAMES.H6, TAG_ID.H6],\n    [TAG_NAMES.HEAD, TAG_ID.HEAD],\n    [TAG_NAMES.HEADER, TAG_ID.HEADER],\n    [TAG_NAMES.HGROUP, TAG_ID.HGROUP],\n    [TAG_NAMES.HR, TAG_ID.HR],\n    [TAG_NAMES.HTML, TAG_ID.HTML],\n    [TAG_NAMES.I, TAG_ID.I],\n    [TAG_NAMES.IMG, TAG_ID.IMG],\n    [TAG_NAMES.IMAGE, TAG_ID.IMAGE],\n    [TAG_NAMES.INPUT, TAG_ID.INPUT],\n    [TAG_NAMES.IFRAME, TAG_ID.IFRAME],\n    [TAG_NAMES.KEYGEN, TAG_ID.KEYGEN],\n    [TAG_NAMES.LABEL, TAG_ID.LABEL],\n    [TAG_NAMES.LI, TAG_ID.LI],\n    [TAG_NAMES.LINK, TAG_ID.LINK],\n    [TAG_NAMES.LISTING, TAG_ID.LISTING],\n    [TAG_NAMES.MAIN, TAG_ID.MAIN],\n    [TAG_NAMES.MALIGNMARK, TAG_ID.MALIGNMARK],\n    [TAG_NAMES.MARQUEE, TAG_ID.MARQUEE],\n    [TAG_NAMES.MATH, TAG_ID.MATH],\n    [TAG_NAMES.MENU, TAG_ID.MENU],\n    [TAG_NAMES.META, TAG_ID.META],\n    [TAG_NAMES.MGLYPH, TAG_ID.MGLYPH],\n    [TAG_NAMES.MI, TAG_ID.MI],\n    [TAG_NAMES.MO, TAG_ID.MO],\n    [TAG_NAMES.MN, TAG_ID.MN],\n    [TAG_NAMES.MS, TAG_ID.MS],\n    [TAG_NAMES.MTEXT, TAG_ID.MTEXT],\n    [TAG_NAMES.NAV, TAG_ID.NAV],\n    [TAG_NAMES.NOBR, TAG_ID.NOBR],\n    [TAG_NAMES.NOFRAMES, TAG_ID.NOFRAMES],\n    [TAG_NAMES.NOEMBED, TAG_ID.NOEMBED],\n    [TAG_NAMES.NOSCRIPT, TAG_ID.NOSCRIPT],\n    [TAG_NAMES.OBJECT, TAG_ID.OBJECT],\n    [TAG_NAMES.OL, TAG_ID.OL],\n    [TAG_NAMES.OPTGROUP, TAG_ID.OPTGROUP],\n    [TAG_NAMES.OPTION, TAG_ID.OPTION],\n    [TAG_NAMES.P, TAG_ID.P],\n    [TAG_NAMES.PARAM, TAG_ID.PARAM],\n    [TAG_NAMES.PLAINTEXT, TAG_ID.PLAINTEXT],\n    [TAG_NAMES.PRE, TAG_ID.PRE],\n    [TAG_NAMES.RB, TAG_ID.RB],\n    [TAG_NAMES.RP, TAG_ID.RP],\n    [TAG_NAMES.RT, TAG_ID.RT],\n    [TAG_NAMES.RTC, TAG_ID.RTC],\n    [TAG_NAMES.RUBY, TAG_ID.RUBY],\n    [TAG_NAMES.S, TAG_ID.S],\n    [TAG_NAMES.SCRIPT, TAG_ID.SCRIPT],\n    [TAG_NAMES.SECTION, TAG_ID.SECTION],\n    [TAG_NAMES.SELECT, TAG_ID.SELECT],\n    [TAG_NAMES.SOURCE, TAG_ID.SOURCE],\n    [TAG_NAMES.SMALL, TAG_ID.SMALL],\n    [TAG_NAMES.SPAN, TAG_ID.SPAN],\n    [TAG_NAMES.STRIKE, TAG_ID.STRIKE],\n    [TAG_NAMES.STRONG, TAG_ID.STRONG],\n    [TAG_NAMES.STYLE, TAG_ID.STYLE],\n    [TAG_NAMES.SUB, TAG_ID.SUB],\n    [TAG_NAMES.SUMMARY, TAG_ID.SUMMARY],\n    [TAG_NAMES.SUP, TAG_ID.SUP],\n    [TAG_NAMES.TABLE, TAG_ID.TABLE],\n    [TAG_NAMES.TBODY, TAG_ID.TBODY],\n    [TAG_NAMES.TEMPLATE, TAG_ID.TEMPLATE],\n    [TAG_NAMES.TEXTAREA, TAG_ID.TEXTAREA],\n    [TAG_NAMES.TFOOT, TAG_ID.TFOOT],\n    [TAG_NAMES.TD, TAG_ID.TD],\n    [TAG_NAMES.TH, TAG_ID.TH],\n    [TAG_NAMES.THEAD, TAG_ID.THEAD],\n    [TAG_NAMES.TITLE, TAG_ID.TITLE],\n    [TAG_NAMES.TR, TAG_ID.TR],\n    [TAG_NAMES.TRACK, TAG_ID.TRACK],\n    [TAG_NAMES.TT, TAG_ID.TT],\n    [TAG_NAMES.U, TAG_ID.U],\n    [TAG_NAMES.UL, TAG_ID.UL],\n    [TAG_NAMES.SVG, TAG_ID.SVG],\n    [TAG_NAMES.VAR, TAG_ID.VAR],\n    [TAG_NAMES.WBR, TAG_ID.WBR],\n    [TAG_NAMES.XMP, TAG_ID.XMP],\n]);\nfunction getTagID(tagName) {\n    var _a;\n    return (_a = TAG_NAME_TO_ID.get(tagName)) !== null && _a !== void 0 ? _a : TAG_ID.UNKNOWN;\n}\nconst $ = TAG_ID;\nconst SPECIAL_ELEMENTS = {\n    [NS.HTML]: new Set([\n        $.ADDRESS,\n        $.APPLET,\n        $.AREA,\n        $.ARTICLE,\n        $.ASIDE,\n        $.BASE,\n        $.BASEFONT,\n        $.BGSOUND,\n        $.BLOCKQUOTE,\n        $.BODY,\n        $.BR,\n        $.BUTTON,\n        $.CAPTION,\n        $.CENTER,\n        $.COL,\n        $.COLGROUP,\n        $.DD,\n        $.DETAILS,\n        $.DIR,\n        $.DIV,\n        $.DL,\n        $.DT,\n        $.EMBED,\n        $.FIELDSET,\n        $.FIGCAPTION,\n        $.FIGURE,\n        $.FOOTER,\n        $.FORM,\n        $.FRAME,\n        $.FRAMESET,\n        $.H1,\n        $.H2,\n        $.H3,\n        $.H4,\n        $.H5,\n        $.H6,\n        $.HEAD,\n        $.HEADER,\n        $.HGROUP,\n        $.HR,\n        $.HTML,\n        $.IFRAME,\n        $.IMG,\n        $.INPUT,\n        $.LI,\n        $.LINK,\n        $.LISTING,\n        $.MAIN,\n        $.MARQUEE,\n        $.MENU,\n        $.META,\n        $.NAV,\n        $.NOEMBED,\n        $.NOFRAMES,\n        $.NOSCRIPT,\n        $.OBJECT,\n        $.OL,\n        $.P,\n        $.PARAM,\n        $.PLAINTEXT,\n        $.PRE,\n        $.SCRIPT,\n        $.SECTION,\n        $.SELECT,\n        $.SOURCE,\n        $.STYLE,\n        $.SUMMARY,\n        $.TABLE,\n        $.TBODY,\n        $.TD,\n        $.TEMPLATE,\n        $.TEXTAREA,\n        $.TFOOT,\n        $.TH,\n        $.THEAD,\n        $.TITLE,\n        $.TR,\n        $.TRACK,\n        $.UL,\n        $.WBR,\n        $.XMP,\n    ]),\n    [NS.MATHML]: new Set([$.MI, $.MO, $.MN, $.MS, $.MTEXT, $.ANNOTATION_XML]),\n    [NS.SVG]: new Set([$.TITLE, $.FOREIGN_OBJECT, $.DESC]),\n    [NS.XLINK]: new Set(),\n    [NS.XML]: new Set(),\n    [NS.XMLNS]: new Set(),\n};\nfunction isNumberedHeader(tn) {\n    return tn === $.H1 || tn === $.H2 || tn === $.H3 || tn === $.H4 || tn === $.H5 || tn === $.H6;\n}\nconst UNESCAPED_TEXT = new Set([\n    TAG_NAMES.STYLE,\n    TAG_NAMES.SCRIPT,\n    TAG_NAMES.XMP,\n    TAG_NAMES.IFRAME,\n    TAG_NAMES.NOEMBED,\n    TAG_NAMES.NOFRAMES,\n    TAG_NAMES.PLAINTEXT,\n]);\nfunction hasUnescapedText(tn, scriptingEnabled) {\n    return UNESCAPED_TEXT.has(tn) || (scriptingEnabled && tn === TAG_NAMES.NOSCRIPT);\n}\n\nvar html = {\n    __proto__: null,\n    get ATTRS () { return ATTRS; },\n    get DOCUMENT_MODE () { return DOCUMENT_MODE; },\n    get NS () { return NS; },\n    SPECIAL_ELEMENTS: SPECIAL_ELEMENTS,\n    get TAG_ID () { return TAG_ID; },\n    get TAG_NAMES () { return TAG_NAMES; },\n    getTagID: getTagID,\n    hasUnescapedText: hasUnescapedText,\n    isNumberedHeader: isNumberedHeader\n};\n\n//C1 Unicode control character reference replacements\nconst C1_CONTROLS_REFERENCE_REPLACEMENTS = new Map([\n    [0x80, 8364],\n    [0x82, 8218],\n    [0x83, 402],\n    [0x84, 8222],\n    [0x85, 8230],\n    [0x86, 8224],\n    [0x87, 8225],\n    [0x88, 710],\n    [0x89, 8240],\n    [0x8a, 352],\n    [0x8b, 8249],\n    [0x8c, 338],\n    [0x8e, 381],\n    [0x91, 8216],\n    [0x92, 8217],\n    [0x93, 8220],\n    [0x94, 8221],\n    [0x95, 8226],\n    [0x96, 8211],\n    [0x97, 8212],\n    [0x98, 732],\n    [0x99, 8482],\n    [0x9a, 353],\n    [0x9b, 8250],\n    [0x9c, 339],\n    [0x9e, 382],\n    [0x9f, 376],\n]);\n//States\nvar State;\n(function (State) {\n    State[State[\"DATA\"] = 0] = \"DATA\";\n    State[State[\"RCDATA\"] = 1] = \"RCDATA\";\n    State[State[\"RAWTEXT\"] = 2] = \"RAWTEXT\";\n    State[State[\"SCRIPT_DATA\"] = 3] = \"SCRIPT_DATA\";\n    State[State[\"PLAINTEXT\"] = 4] = \"PLAINTEXT\";\n    State[State[\"TAG_OPEN\"] = 5] = \"TAG_OPEN\";\n    State[State[\"END_TAG_OPEN\"] = 6] = \"END_TAG_OPEN\";\n    State[State[\"TAG_NAME\"] = 7] = \"TAG_NAME\";\n    State[State[\"RCDATA_LESS_THAN_SIGN\"] = 8] = \"RCDATA_LESS_THAN_SIGN\";\n    State[State[\"RCDATA_END_TAG_OPEN\"] = 9] = \"RCDATA_END_TAG_OPEN\";\n    State[State[\"RCDATA_END_TAG_NAME\"] = 10] = \"RCDATA_END_TAG_NAME\";\n    State[State[\"RAWTEXT_LESS_THAN_SIGN\"] = 11] = \"RAWTEXT_LESS_THAN_SIGN\";\n    State[State[\"RAWTEXT_END_TAG_OPEN\"] = 12] = \"RAWTEXT_END_TAG_OPEN\";\n    State[State[\"RAWTEXT_END_TAG_NAME\"] = 13] = \"RAWTEXT_END_TAG_NAME\";\n    State[State[\"SCRIPT_DATA_LESS_THAN_SIGN\"] = 14] = \"SCRIPT_DATA_LESS_THAN_SIGN\";\n    State[State[\"SCRIPT_DATA_END_TAG_OPEN\"] = 15] = \"SCRIPT_DATA_END_TAG_OPEN\";\n    State[State[\"SCRIPT_DATA_END_TAG_NAME\"] = 16] = \"SCRIPT_DATA_END_TAG_NAME\";\n    State[State[\"SCRIPT_DATA_ESCAPE_START\"] = 17] = \"SCRIPT_DATA_ESCAPE_START\";\n    State[State[\"SCRIPT_DATA_ESCAPE_START_DASH\"] = 18] = \"SCRIPT_DATA_ESCAPE_START_DASH\";\n    State[State[\"SCRIPT_DATA_ESCAPED\"] = 19] = \"SCRIPT_DATA_ESCAPED\";\n    State[State[\"SCRIPT_DATA_ESCAPED_DASH\"] = 20] = \"SCRIPT_DATA_ESCAPED_DASH\";\n    State[State[\"SCRIPT_DATA_ESCAPED_DASH_DASH\"] = 21] = \"SCRIPT_DATA_ESCAPED_DASH_DASH\";\n    State[State[\"SCRIPT_DATA_ESCAPED_LESS_THAN_SIGN\"] = 22] = \"SCRIPT_DATA_ESCAPED_LESS_THAN_SIGN\";\n    State[State[\"SCRIPT_DATA_ESCAPED_END_TAG_OPEN\"] = 23] = \"SCRIPT_DATA_ESCAPED_END_TAG_OPEN\";\n    State[State[\"SCRIPT_DATA_ESCAPED_END_TAG_NAME\"] = 24] = \"SCRIPT_DATA_ESCAPED_END_TAG_NAME\";\n    State[State[\"SCRIPT_DATA_DOUBLE_ESCAPE_START\"] = 25] = \"SCRIPT_DATA_DOUBLE_ESCAPE_START\";\n    State[State[\"SCRIPT_DATA_DOUBLE_ESCAPED\"] = 26] = \"SCRIPT_DATA_DOUBLE_ESCAPED\";\n    State[State[\"SCRIPT_DATA_DOUBLE_ESCAPED_DASH\"] = 27] = \"SCRIPT_DATA_DOUBLE_ESCAPED_DASH\";\n    State[State[\"SCRIPT_DATA_DOUBLE_ESCAPED_DASH_DASH\"] = 28] = \"SCRIPT_DATA_DOUBLE_ESCAPED_DASH_DASH\";\n    State[State[\"SCRIPT_DATA_DOUBLE_ESCAPED_LESS_THAN_SIGN\"] = 29] = \"SCRIPT_DATA_DOUBLE_ESCAPED_LESS_THAN_SIGN\";\n    State[State[\"SCRIPT_DATA_DOUBLE_ESCAPE_END\"] = 30] = \"SCRIPT_DATA_DOUBLE_ESCAPE_END\";\n    State[State[\"BEFORE_ATTRIBUTE_NAME\"] = 31] = \"BEFORE_ATTRIBUTE_NAME\";\n    State[State[\"ATTRIBUTE_NAME\"] = 32] = \"ATTRIBUTE_NAME\";\n    State[State[\"AFTER_ATTRIBUTE_NAME\"] = 33] = \"AFTER_ATTRIBUTE_NAME\";\n    State[State[\"BEFORE_ATTRIBUTE_VALUE\"] = 34] = \"BEFORE_ATTRIBUTE_VALUE\";\n    State[State[\"ATTRIBUTE_VALUE_DOUBLE_QUOTED\"] = 35] = \"ATTRIBUTE_VALUE_DOUBLE_QUOTED\";\n    State[State[\"ATTRIBUTE_VALUE_SINGLE_QUOTED\"] = 36] = \"ATTRIBUTE_VALUE_SINGLE_QUOTED\";\n    State[State[\"ATTRIBUTE_VALUE_UNQUOTED\"] = 37] = \"ATTRIBUTE_VALUE_UNQUOTED\";\n    State[State[\"AFTER_ATTRIBUTE_VALUE_QUOTED\"] = 38] = \"AFTER_ATTRIBUTE_VALUE_QUOTED\";\n    State[State[\"SELF_CLOSING_START_TAG\"] = 39] = \"SELF_CLOSING_START_TAG\";\n    State[State[\"BOGUS_COMMENT\"] = 40] = \"BOGUS_COMMENT\";\n    State[State[\"MARKUP_DECLARATION_OPEN\"] = 41] = \"MARKUP_DECLARATION_OPEN\";\n    State[State[\"COMMENT_START\"] = 42] = \"COMMENT_START\";\n    State[State[\"COMMENT_START_DASH\"] = 43] = \"COMMENT_START_DASH\";\n    State[State[\"COMMENT\"] = 44] = \"COMMENT\";\n    State[State[\"COMMENT_LESS_THAN_SIGN\"] = 45] = \"COMMENT_LESS_THAN_SIGN\";\n    State[State[\"COMMENT_LESS_THAN_SIGN_BANG\"] = 46] = \"COMMENT_LESS_THAN_SIGN_BANG\";\n    State[State[\"COMMENT_LESS_THAN_SIGN_BANG_DASH\"] = 47] = \"COMMENT_LESS_THAN_SIGN_BANG_DASH\";\n    State[State[\"COMMENT_LESS_THAN_SIGN_BANG_DASH_DASH\"] = 48] = \"COMMENT_LESS_THAN_SIGN_BANG_DASH_DASH\";\n    State[State[\"COMMENT_END_DASH\"] = 49] = \"COMMENT_END_DASH\";\n    State[State[\"COMMENT_END\"] = 50] = \"COMMENT_END\";\n    State[State[\"COMMENT_END_BANG\"] = 51] = \"COMMENT_END_BANG\";\n    State[State[\"DOCTYPE\"] = 52] = \"DOCTYPE\";\n    State[State[\"BEFORE_DOCTYPE_NAME\"] = 53] = \"BEFORE_DOCTYPE_NAME\";\n    State[State[\"DOCTYPE_NAME\"] = 54] = \"DOCTYPE_NAME\";\n    State[State[\"AFTER_DOCTYPE_NAME\"] = 55] = \"AFTER_DOCTYPE_NAME\";\n    State[State[\"AFTER_DOCTYPE_PUBLIC_KEYWORD\"] = 56] = \"AFTER_DOCTYPE_PUBLIC_KEYWORD\";\n    State[State[\"BEFORE_DOCTYPE_PUBLIC_IDENTIFIER\"] = 57] = \"BEFORE_DOCTYPE_PUBLIC_IDENTIFIER\";\n    State[State[\"DOCTYPE_PUBLIC_IDENTIFIER_DOUBLE_QUOTED\"] = 58] = \"DOCTYPE_PUBLIC_IDENTIFIER_DOUBLE_QUOTED\";\n    State[State[\"DOCTYPE_PUBLIC_IDENTIFIER_SINGLE_QUOTED\"] = 59] = \"DOCTYPE_PUBLIC_IDENTIFIER_SINGLE_QUOTED\";\n    State[State[\"AFTER_DOCTYPE_PUBLIC_IDENTIFIER\"] = 60] = \"AFTER_DOCTYPE_PUBLIC_IDENTIFIER\";\n    State[State[\"BETWEEN_DOCTYPE_PUBLIC_AND_SYSTEM_IDENTIFIERS\"] = 61] = \"BETWEEN_DOCTYPE_PUBLIC_AND_SYSTEM_IDENTIFIERS\";\n    State[State[\"AFTER_DOCTYPE_SYSTEM_KEYWORD\"] = 62] = \"AFTER_DOCTYPE_SYSTEM_KEYWORD\";\n    State[State[\"BEFORE_DOCTYPE_SYSTEM_IDENTIFIER\"] = 63] = \"BEFORE_DOCTYPE_SYSTEM_IDENTIFIER\";\n    State[State[\"DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED\"] = 64] = \"DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED\";\n    State[State[\"DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED\"] = 65] = \"DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED\";\n    State[State[\"AFTER_DOCTYPE_SYSTEM_IDENTIFIER\"] = 66] = \"AFTER_DOCTYPE_SYSTEM_IDENTIFIER\";\n    State[State[\"BOGUS_DOCTYPE\"] = 67] = \"BOGUS_DOCTYPE\";\n    State[State[\"CDATA_SECTION\"] = 68] = \"CDATA_SECTION\";\n    State[State[\"CDATA_SECTION_BRACKET\"] = 69] = \"CDATA_SECTION_BRACKET\";\n    State[State[\"CDATA_SECTION_END\"] = 70] = \"CDATA_SECTION_END\";\n    State[State[\"CHARACTER_REFERENCE\"] = 71] = \"CHARACTER_REFERENCE\";\n    State[State[\"NAMED_CHARACTER_REFERENCE\"] = 72] = \"NAMED_CHARACTER_REFERENCE\";\n    State[State[\"AMBIGUOUS_AMPERSAND\"] = 73] = \"AMBIGUOUS_AMPERSAND\";\n    State[State[\"NUMERIC_CHARACTER_REFERENCE\"] = 74] = \"NUMERIC_CHARACTER_REFERENCE\";\n    State[State[\"HEXADEMICAL_CHARACTER_REFERENCE_START\"] = 75] = \"HEXADEMICAL_CHARACTER_REFERENCE_START\";\n    State[State[\"HEXADEMICAL_CHARACTER_REFERENCE\"] = 76] = \"HEXADEMICAL_CHARACTER_REFERENCE\";\n    State[State[\"DECIMAL_CHARACTER_REFERENCE\"] = 77] = \"DECIMAL_CHARACTER_REFERENCE\";\n    State[State[\"NUMERIC_CHARACTER_REFERENCE_END\"] = 78] = \"NUMERIC_CHARACTER_REFERENCE_END\";\n})(State || (State = {}));\n//Tokenizer initial states for different modes\nconst TokenizerMode = {\n    DATA: State.DATA,\n    RCDATA: State.RCDATA,\n    RAWTEXT: State.RAWTEXT,\n    SCRIPT_DATA: State.SCRIPT_DATA,\n    PLAINTEXT: State.PLAINTEXT,\n    CDATA_SECTION: State.CDATA_SECTION,\n};\n//Utils\n//OPTIMIZATION: these utility functions should not be moved out of this module. V8 Crankshaft will not inline\n//this functions if they will be situated in another module due to context switch.\n//Always perform inlining check before modifying this functions ('node --trace-inlining').\nfunction isAsciiDigit(cp) {\n    return cp >= CODE_POINTS.DIGIT_0 && cp <= CODE_POINTS.DIGIT_9;\n}\nfunction isAsciiUpper(cp) {\n    return cp >= CODE_POINTS.LATIN_CAPITAL_A && cp <= CODE_POINTS.LATIN_CAPITAL_Z;\n}\nfunction isAsciiLower(cp) {\n    return cp >= CODE_POINTS.LATIN_SMALL_A && cp <= CODE_POINTS.LATIN_SMALL_Z;\n}\nfunction isAsciiLetter(cp) {\n    return isAsciiLower(cp) || isAsciiUpper(cp);\n}\nfunction isAsciiAlphaNumeric(cp) {\n    return isAsciiLetter(cp) || isAsciiDigit(cp);\n}\nfunction isAsciiUpperHexDigit(cp) {\n    return cp >= CODE_POINTS.LATIN_CAPITAL_A && cp <= CODE_POINTS.LATIN_CAPITAL_F;\n}\nfunction isAsciiLowerHexDigit(cp) {\n    return cp >= CODE_POINTS.LATIN_SMALL_A && cp <= CODE_POINTS.LATIN_SMALL_F;\n}\nfunction isAsciiHexDigit(cp) {\n    return isAsciiDigit(cp) || isAsciiUpperHexDigit(cp) || isAsciiLowerHexDigit(cp);\n}\nfunction toAsciiLower(cp) {\n    return cp + 32;\n}\nfunction isWhitespace(cp) {\n    return cp === CODE_POINTS.SPACE || cp === CODE_POINTS.LINE_FEED || cp === CODE_POINTS.TABULATION || cp === CODE_POINTS.FORM_FEED;\n}\nfunction isEntityInAttributeInvalidEnd(nextCp) {\n    return nextCp === CODE_POINTS.EQUALS_SIGN || isAsciiAlphaNumeric(nextCp);\n}\nfunction isScriptDataDoubleEscapeSequenceEnd(cp) {\n    return isWhitespace(cp) || cp === CODE_POINTS.SOLIDUS || cp === CODE_POINTS.GREATER_THAN_SIGN;\n}\n//Tokenizer\nclass Tokenizer {\n    constructor(options, handler) {\n        this.options = options;\n        this.handler = handler;\n        this.paused = false;\n        /** Ensures that the parsing loop isn't run multiple times at once. */\n        this.inLoop = false;\n        /**\n         * Indicates that the current adjusted node exists, is not an element in the HTML namespace,\n         * and that it is not an integration point for either MathML or HTML.\n         *\n         * @see {@link https://html.spec.whatwg.org/multipage/parsing.html#tree-construction}\n         */\n        this.inForeignNode = false;\n        this.lastStartTagName = '';\n        this.active = false;\n        this.state = State.DATA;\n        this.returnState = State.DATA;\n        this.charRefCode = -1;\n        this.consumedAfterSnapshot = -1;\n        this.currentCharacterToken = null;\n        this.currentToken = null;\n        this.currentAttr = { name: '', value: '' };\n        this.preprocessor = new Preprocessor(handler);\n        this.currentLocation = this.getCurrentLocation(-1);\n    }\n    //Errors\n    _err(code) {\n        var _a, _b;\n        (_b = (_a = this.handler).onParseError) === null || _b === void 0 ? void 0 : _b.call(_a, this.preprocessor.getError(code));\n    }\n    // NOTE: `offset` may never run across line boundaries.\n    getCurrentLocation(offset) {\n        if (!this.options.sourceCodeLocationInfo) {\n            return null;\n        }\n        return {\n            startLine: this.preprocessor.line,\n            startCol: this.preprocessor.col - offset,\n            startOffset: this.preprocessor.offset - offset,\n            endLine: -1,\n            endCol: -1,\n            endOffset: -1,\n        };\n    }\n    _runParsingLoop() {\n        if (this.inLoop)\n            return;\n        this.inLoop = true;\n        while (this.active && !this.paused) {\n            this.consumedAfterSnapshot = 0;\n            const cp = this._consume();\n            if (!this._ensureHibernation()) {\n                this._callState(cp);\n            }\n        }\n        this.inLoop = false;\n    }\n    //API\n    pause() {\n        this.paused = true;\n    }\n    resume(writeCallback) {\n        if (!this.paused) {\n            throw new Error('Parser was already resumed');\n        }\n        this.paused = false;\n        // Necessary for synchronous resume.\n        if (this.inLoop)\n            return;\n        this._runParsingLoop();\n        if (!this.paused) {\n            writeCallback === null || writeCallback === void 0 ? void 0 : writeCallback();\n        }\n    }\n    write(chunk, isLastChunk, writeCallback) {\n        this.active = true;\n        this.preprocessor.write(chunk, isLastChunk);\n        this._runParsingLoop();\n        if (!this.paused) {\n            writeCallback === null || writeCallback === void 0 ? void 0 : writeCallback();\n        }\n    }\n    insertHtmlAtCurrentPos(chunk) {\n        this.active = true;\n        this.preprocessor.insertHtmlAtCurrentPos(chunk);\n        this._runParsingLoop();\n    }\n    //Hibernation\n    _ensureHibernation() {\n        if (this.preprocessor.endOfChunkHit) {\n            this._unconsume(this.consumedAfterSnapshot);\n            this.active = false;\n            return true;\n        }\n        return false;\n    }\n    //Consumption\n    _consume() {\n        this.consumedAfterSnapshot++;\n        return this.preprocessor.advance();\n    }\n    _unconsume(count) {\n        this.consumedAfterSnapshot -= count;\n        this.preprocessor.retreat(count);\n    }\n    _reconsumeInState(state, cp) {\n        this.state = state;\n        this._callState(cp);\n    }\n    _advanceBy(count) {\n        this.consumedAfterSnapshot += count;\n        for (let i = 0; i < count; i++) {\n            this.preprocessor.advance();\n        }\n    }\n    _consumeSequenceIfMatch(pattern, caseSensitive) {\n        if (this.preprocessor.startsWith(pattern, caseSensitive)) {\n            // We will already have consumed one character before calling this method.\n            this._advanceBy(pattern.length - 1);\n            return true;\n        }\n        return false;\n    }\n    //Token creation\n    _createStartTagToken() {\n        this.currentToken = {\n            type: TokenType.START_TAG,\n            tagName: '',\n            tagID: TAG_ID.UNKNOWN,\n            selfClosing: false,\n            ackSelfClosing: false,\n            attrs: [],\n            location: this.getCurrentLocation(1),\n        };\n    }\n    _createEndTagToken() {\n        this.currentToken = {\n            type: TokenType.END_TAG,\n            tagName: '',\n            tagID: TAG_ID.UNKNOWN,\n            selfClosing: false,\n            ackSelfClosing: false,\n            attrs: [],\n            location: this.getCurrentLocation(2),\n        };\n    }\n    _createCommentToken(offset) {\n        this.currentToken = {\n            type: TokenType.COMMENT,\n            data: '',\n            location: this.getCurrentLocation(offset),\n        };\n    }\n    _createDoctypeToken(initialName) {\n        this.currentToken = {\n            type: TokenType.DOCTYPE,\n            name: initialName,\n            forceQuirks: false,\n            publicId: null,\n            systemId: null,\n            location: this.currentLocation,\n        };\n    }\n    _createCharacterToken(type, chars) {\n        this.currentCharacterToken = {\n            type,\n            chars,\n            location: this.currentLocation,\n        };\n    }\n    //Tag attributes\n    _createAttr(attrNameFirstCh) {\n        this.currentAttr = {\n            name: attrNameFirstCh,\n            value: '',\n        };\n        this.currentLocation = this.getCurrentLocation(0);\n    }\n    _leaveAttrName() {\n        var _a;\n        var _b;\n        const token = this.currentToken;\n        if (getTokenAttr(token, this.currentAttr.name) === null) {\n            token.attrs.push(this.currentAttr);\n            if (token.location && this.currentLocation) {\n                const attrLocations = ((_a = (_b = token.location).attrs) !== null && _a !== void 0 ? _a : (_b.attrs = Object.create(null)));\n                attrLocations[this.currentAttr.name] = this.currentLocation;\n                // Set end location\n                this._leaveAttrValue();\n            }\n        }\n        else {\n            this._err(ERR.duplicateAttribute);\n        }\n    }\n    _leaveAttrValue() {\n        if (this.currentLocation) {\n            this.currentLocation.endLine = this.preprocessor.line;\n            this.currentLocation.endCol = this.preprocessor.col;\n            this.currentLocation.endOffset = this.preprocessor.offset;\n        }\n    }\n    //Token emission\n    prepareToken(ct) {\n        this._emitCurrentCharacterToken(ct.location);\n        this.currentToken = null;\n        if (ct.location) {\n            ct.location.endLine = this.preprocessor.line;\n            ct.location.endCol = this.preprocessor.col + 1;\n            ct.location.endOffset = this.preprocessor.offset + 1;\n        }\n        this.currentLocation = this.getCurrentLocation(-1);\n    }\n    emitCurrentTagToken() {\n        const ct = this.currentToken;\n        this.prepareToken(ct);\n        ct.tagID = getTagID(ct.tagName);\n        if (ct.type === TokenType.START_TAG) {\n            this.lastStartTagName = ct.tagName;\n            this.handler.onStartTag(ct);\n        }\n        else {\n            if (ct.attrs.length > 0) {\n                this._err(ERR.endTagWithAttributes);\n            }\n            if (ct.selfClosing) {\n                this._err(ERR.endTagWithTrailingSolidus);\n            }\n            this.handler.onEndTag(ct);\n        }\n        this.preprocessor.dropParsedChunk();\n    }\n    emitCurrentComment(ct) {\n        this.prepareToken(ct);\n        this.handler.onComment(ct);\n        this.preprocessor.dropParsedChunk();\n    }\n    emitCurrentDoctype(ct) {\n        this.prepareToken(ct);\n        this.handler.onDoctype(ct);\n        this.preprocessor.dropParsedChunk();\n    }\n    _emitCurrentCharacterToken(nextLocation) {\n        if (this.currentCharacterToken) {\n            //NOTE: if we have a pending character token, make it's end location equal to the\n            //current token's start location.\n            if (nextLocation && this.currentCharacterToken.location) {\n                this.currentCharacterToken.location.endLine = nextLocation.startLine;\n                this.currentCharacterToken.location.endCol = nextLocation.startCol;\n                this.currentCharacterToken.location.endOffset = nextLocation.startOffset;\n            }\n            switch (this.currentCharacterToken.type) {\n                case TokenType.CHARACTER: {\n                    this.handler.onCharacter(this.currentCharacterToken);\n                    break;\n                }\n                case TokenType.NULL_CHARACTER: {\n                    this.handler.onNullCharacter(this.currentCharacterToken);\n                    break;\n                }\n                case TokenType.WHITESPACE_CHARACTER: {\n                    this.handler.onWhitespaceCharacter(this.currentCharacterToken);\n                    break;\n                }\n            }\n            this.currentCharacterToken = null;\n        }\n    }\n    _emitEOFToken() {\n        const location = this.getCurrentLocation(0);\n        if (location) {\n            location.endLine = location.startLine;\n            location.endCol = location.startCol;\n            location.endOffset = location.startOffset;\n        }\n        this._emitCurrentCharacterToken(location);\n        this.handler.onEof({ type: TokenType.EOF, location });\n        this.active = false;\n    }\n    //Characters emission\n    //OPTIMIZATION: specification uses only one type of character tokens (one token per character).\n    //This causes a huge memory overhead and a lot of unnecessary parser loops. parse5 uses 3 groups of characters.\n    //If we have a sequence of characters that belong to the same group, the parser can process it\n    //as a single solid character token.\n    //So, there are 3 types of character tokens in parse5:\n    //1)TokenType.NULL_CHARACTER - \\u0000-character sequences (e.g. '\\u0000\\u0000\\u0000')\n    //2)TokenType.WHITESPACE_CHARACTER - any whitespace/new-line character sequences (e.g. '\\n  \\r\\t   \\f')\n    //3)TokenType.CHARACTER - any character sequence which don't belong to groups 1 and 2 (e.g. 'abcdef1234@@#$%^')\n    _appendCharToCurrentCharacterToken(type, ch) {\n        if (this.currentCharacterToken) {\n            if (this.currentCharacterToken.type !== type) {\n                this.currentLocation = this.getCurrentLocation(0);\n                this._emitCurrentCharacterToken(this.currentLocation);\n                this.preprocessor.dropParsedChunk();\n            }\n            else {\n                this.currentCharacterToken.chars += ch;\n                return;\n            }\n        }\n        this._createCharacterToken(type, ch);\n    }\n    _emitCodePoint(cp) {\n        const type = isWhitespace(cp)\n            ? TokenType.WHITESPACE_CHARACTER\n            : cp === CODE_POINTS.NULL\n                ? TokenType.NULL_CHARACTER\n                : TokenType.CHARACTER;\n        this._appendCharToCurrentCharacterToken(type, String.fromCodePoint(cp));\n    }\n    //NOTE: used when we emit characters explicitly.\n    //This is always for non-whitespace and non-null characters, which allows us to avoid additional checks.\n    _emitChars(ch) {\n        this._appendCharToCurrentCharacterToken(TokenType.CHARACTER, ch);\n    }\n    // Character reference helpers\n    _matchNamedCharacterReference(cp) {\n        let result = null;\n        let excess = 0;\n        let withoutSemicolon = false;\n        for (let i = 0, current = htmlDecodeTree[0]; i >= 0; cp = this._consume()) {\n            i = determineBranch(htmlDecodeTree, current, i + 1, cp);\n            if (i < 0)\n                break;\n            excess += 1;\n            current = htmlDecodeTree[i];\n            const masked = current & BinTrieFlags.VALUE_LENGTH;\n            // If the branch is a value, store it and continue\n            if (masked) {\n                // The mask is the number of bytes of the value, including the current byte.\n                const valueLength = (masked >> 14) - 1;\n                // Attribute values that aren't terminated properly aren't parsed, and shouldn't lead to a parser error.\n                // See the example in https://html.spec.whatwg.org/multipage/parsing.html#named-character-reference-state\n                if (cp !== CODE_POINTS.SEMICOLON &&\n                    this._isCharacterReferenceInAttribute() &&\n                    isEntityInAttributeInvalidEnd(this.preprocessor.peek(1))) {\n                    //NOTE: we don't flush all consumed code points here, and instead switch back to the original state after\n                    //emitting an ampersand. This is fine, as alphanumeric characters won't be parsed differently in attributes.\n                    result = [CODE_POINTS.AMPERSAND];\n                    // Skip over the value.\n                    i += valueLength;\n                }\n                else {\n                    // If this is a surrogate pair, consume the next two bytes.\n                    result =\n                        valueLength === 0\n                            ? [htmlDecodeTree[i] & ~BinTrieFlags.VALUE_LENGTH]\n                            : valueLength === 1\n                                ? [htmlDecodeTree[++i]]\n                                : [htmlDecodeTree[++i], htmlDecodeTree[++i]];\n                    excess = 0;\n                    withoutSemicolon = cp !== CODE_POINTS.SEMICOLON;\n                }\n                if (valueLength === 0) {\n                    // If the value is zero-length, we're done.\n                    this._consume();\n                    break;\n                }\n            }\n        }\n        this._unconsume(excess);\n        if (withoutSemicolon && !this.preprocessor.endOfChunkHit) {\n            this._err(ERR.missingSemicolonAfterCharacterReference);\n        }\n        // We want to emit the error above on the code point after the entity.\n        // We always consume one code point too many in the loop, and we wait to\n        // unconsume it until after the error is emitted.\n        this._unconsume(1);\n        return result;\n    }\n    _isCharacterReferenceInAttribute() {\n        return (this.returnState === State.ATTRIBUTE_VALUE_DOUBLE_QUOTED ||\n            this.returnState === State.ATTRIBUTE_VALUE_SINGLE_QUOTED ||\n            this.returnState === State.ATTRIBUTE_VALUE_UNQUOTED);\n    }\n    _flushCodePointConsumedAsCharacterReference(cp) {\n        if (this._isCharacterReferenceInAttribute()) {\n            this.currentAttr.value += String.fromCodePoint(cp);\n        }\n        else {\n            this._emitCodePoint(cp);\n        }\n    }\n    // Calling states this way turns out to be much faster than any other approach.\n    _callState(cp) {\n        switch (this.state) {\n            case State.DATA: {\n                this._stateData(cp);\n                break;\n            }\n            case State.RCDATA: {\n                this._stateRcdata(cp);\n                break;\n            }\n            case State.RAWTEXT: {\n                this._stateRawtext(cp);\n                break;\n            }\n            case State.SCRIPT_DATA: {\n                this._stateScriptData(cp);\n                break;\n            }\n            case State.PLAINTEXT: {\n                this._statePlaintext(cp);\n                break;\n            }\n            case State.TAG_OPEN: {\n                this._stateTagOpen(cp);\n                break;\n            }\n            case State.END_TAG_OPEN: {\n                this._stateEndTagOpen(cp);\n                break;\n            }\n            case State.TAG_NAME: {\n                this._stateTagName(cp);\n                break;\n            }\n            case State.RCDATA_LESS_THAN_SIGN: {\n                this._stateRcdataLessThanSign(cp);\n                break;\n            }\n            case State.RCDATA_END_TAG_OPEN: {\n                this._stateRcdataEndTagOpen(cp);\n                break;\n            }\n            case State.RCDATA_END_TAG_NAME: {\n                this._stateRcdataEndTagName(cp);\n                break;\n            }\n            case State.RAWTEXT_LESS_THAN_SIGN: {\n                this._stateRawtextLessThanSign(cp);\n                break;\n            }\n            case State.RAWTEXT_END_TAG_OPEN: {\n                this._stateRawtextEndTagOpen(cp);\n                break;\n            }\n            case State.RAWTEXT_END_TAG_NAME: {\n                this._stateRawtextEndTagName(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_LESS_THAN_SIGN: {\n                this._stateScriptDataLessThanSign(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_END_TAG_OPEN: {\n                this._stateScriptDataEndTagOpen(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_END_TAG_NAME: {\n                this._stateScriptDataEndTagName(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPE_START: {\n                this._stateScriptDataEscapeStart(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPE_START_DASH: {\n                this._stateScriptDataEscapeStartDash(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPED: {\n                this._stateScriptDataEscaped(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPED_DASH: {\n                this._stateScriptDataEscapedDash(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPED_DASH_DASH: {\n                this._stateScriptDataEscapedDashDash(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPED_LESS_THAN_SIGN: {\n                this._stateScriptDataEscapedLessThanSign(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPED_END_TAG_OPEN: {\n                this._stateScriptDataEscapedEndTagOpen(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_ESCAPED_END_TAG_NAME: {\n                this._stateScriptDataEscapedEndTagName(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_DOUBLE_ESCAPE_START: {\n                this._stateScriptDataDoubleEscapeStart(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_DOUBLE_ESCAPED: {\n                this._stateScriptDataDoubleEscaped(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_DOUBLE_ESCAPED_DASH: {\n                this._stateScriptDataDoubleEscapedDash(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_DOUBLE_ESCAPED_DASH_DASH: {\n                this._stateScriptDataDoubleEscapedDashDash(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_DOUBLE_ESCAPED_LESS_THAN_SIGN: {\n                this._stateScriptDataDoubleEscapedLessThanSign(cp);\n                break;\n            }\n            case State.SCRIPT_DATA_DOUBLE_ESCAPE_END: {\n                this._stateScriptDataDoubleEscapeEnd(cp);\n                break;\n            }\n            case State.BEFORE_ATTRIBUTE_NAME: {\n                this._stateBeforeAttributeName(cp);\n                break;\n            }\n            case State.ATTRIBUTE_NAME: {\n                this._stateAttributeName(cp);\n                break;\n            }\n            case State.AFTER_ATTRIBUTE_NAME: {\n                this._stateAfterAttributeName(cp);\n                break;\n            }\n            case State.BEFORE_ATTRIBUTE_VALUE: {\n                this._stateBeforeAttributeValue(cp);\n                break;\n            }\n            case State.ATTRIBUTE_VALUE_DOUBLE_QUOTED: {\n                this._stateAttributeValueDoubleQuoted(cp);\n                break;\n            }\n            case State.ATTRIBUTE_VALUE_SINGLE_QUOTED: {\n                this._stateAttributeValueSingleQuoted(cp);\n                break;\n            }\n            case State.ATTRIBUTE_VALUE_UNQUOTED: {\n                this._stateAttributeValueUnquoted(cp);\n                break;\n            }\n            case State.AFTER_ATTRIBUTE_VALUE_QUOTED: {\n                this._stateAfterAttributeValueQuoted(cp);\n                break;\n            }\n            case State.SELF_CLOSING_START_TAG: {\n                this._stateSelfClosingStartTag(cp);\n                break;\n            }\n            case State.BOGUS_COMMENT: {\n                this._stateBogusComment(cp);\n                break;\n            }\n            case State.MARKUP_DECLARATION_OPEN: {\n                this._stateMarkupDeclarationOpen(cp);\n                break;\n            }\n            case State.COMMENT_START: {\n                this._stateCommentStart(cp);\n                break;\n            }\n            case State.COMMENT_START_DASH: {\n                this._stateCommentStartDash(cp);\n                break;\n            }\n            case State.COMMENT: {\n                this._stateComment(cp);\n                break;\n            }\n            case State.COMMENT_LESS_THAN_SIGN: {\n                this._stateCommentLessThanSign(cp);\n                break;\n            }\n            case State.COMMENT_LESS_THAN_SIGN_BANG: {\n                this._stateCommentLessThanSignBang(cp);\n                break;\n            }\n            case State.COMMENT_LESS_THAN_SIGN_BANG_DASH: {\n                this._stateCommentLessThanSignBangDash(cp);\n                break;\n            }\n            case State.COMMENT_LESS_THAN_SIGN_BANG_DASH_DASH: {\n                this._stateCommentLessThanSignBangDashDash(cp);\n                break;\n            }\n            case State.COMMENT_END_DASH: {\n                this._stateCommentEndDash(cp);\n                break;\n            }\n            case State.COMMENT_END: {\n                this._stateCommentEnd(cp);\n                break;\n            }\n            case State.COMMENT_END_BANG: {\n                this._stateCommentEndBang(cp);\n                break;\n            }\n            case State.DOCTYPE: {\n                this._stateDoctype(cp);\n                break;\n            }\n            case State.BEFORE_DOCTYPE_NAME: {\n                this._stateBeforeDoctypeName(cp);\n                break;\n            }\n            case State.DOCTYPE_NAME: {\n                this._stateDoctypeName(cp);\n                break;\n            }\n            case State.AFTER_DOCTYPE_NAME: {\n                this._stateAfterDoctypeName(cp);\n                break;\n            }\n            case State.AFTER_DOCTYPE_PUBLIC_KEYWORD: {\n                this._stateAfterDoctypePublicKeyword(cp);\n                break;\n            }\n            case State.BEFORE_DOCTYPE_PUBLIC_IDENTIFIER: {\n                this._stateBeforeDoctypePublicIdentifier(cp);\n                break;\n            }\n            case State.DOCTYPE_PUBLIC_IDENTIFIER_DOUBLE_QUOTED: {\n                this._stateDoctypePublicIdentifierDoubleQuoted(cp);\n                break;\n            }\n            case State.DOCTYPE_PUBLIC_IDENTIFIER_SINGLE_QUOTED: {\n                this._stateDoctypePublicIdentifierSingleQuoted(cp);\n                break;\n            }\n            case State.AFTER_DOCTYPE_PUBLIC_IDENTIFIER: {\n                this._stateAfterDoctypePublicIdentifier(cp);\n                break;\n            }\n            case State.BETWEEN_DOCTYPE_PUBLIC_AND_SYSTEM_IDENTIFIERS: {\n                this._stateBetweenDoctypePublicAndSystemIdentifiers(cp);\n                break;\n            }\n            case State.AFTER_DOCTYPE_SYSTEM_KEYWORD: {\n                this._stateAfterDoctypeSystemKeyword(cp);\n                break;\n            }\n            case State.BEFORE_DOCTYPE_SYSTEM_IDENTIFIER: {\n                this._stateBeforeDoctypeSystemIdentifier(cp);\n                break;\n            }\n            case State.DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED: {\n                this._stateDoctypeSystemIdentifierDoubleQuoted(cp);\n                break;\n            }\n            case State.DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED: {\n                this._stateDoctypeSystemIdentifierSingleQuoted(cp);\n                break;\n            }\n            case State.AFTER_DOCTYPE_SYSTEM_IDENTIFIER: {\n                this._stateAfterDoctypeSystemIdentifier(cp);\n                break;\n            }\n            case State.BOGUS_DOCTYPE: {\n                this._stateBogusDoctype(cp);\n                break;\n            }\n            case State.CDATA_SECTION: {\n                this._stateCdataSection(cp);\n                break;\n            }\n            case State.CDATA_SECTION_BRACKET: {\n                this._stateCdataSectionBracket(cp);\n                break;\n            }\n            case State.CDATA_SECTION_END: {\n                this._stateCdataSectionEnd(cp);\n                break;\n            }\n            case State.CHARACTER_REFERENCE: {\n                this._stateCharacterReference(cp);\n                break;\n            }\n            case State.NAMED_CHARACTER_REFERENCE: {\n                this._stateNamedCharacterReference(cp);\n                break;\n            }\n            case State.AMBIGUOUS_AMPERSAND: {\n                this._stateAmbiguousAmpersand(cp);\n                break;\n            }\n            case State.NUMERIC_CHARACTER_REFERENCE: {\n                this._stateNumericCharacterReference(cp);\n                break;\n            }\n            case State.HEXADEMICAL_CHARACTER_REFERENCE_START: {\n                this._stateHexademicalCharacterReferenceStart(cp);\n                break;\n            }\n            case State.HEXADEMICAL_CHARACTER_REFERENCE: {\n                this._stateHexademicalCharacterReference(cp);\n                break;\n            }\n            case State.DECIMAL_CHARACTER_REFERENCE: {\n                this._stateDecimalCharacterReference(cp);\n                break;\n            }\n            case State.NUMERIC_CHARACTER_REFERENCE_END: {\n                this._stateNumericCharacterReferenceEnd(cp);\n                break;\n            }\n            default: {\n                throw new Error('Unknown state');\n            }\n        }\n    }\n    // State machine\n    // Data state\n    //------------------------------------------------------------------\n    _stateData(cp) {\n        switch (cp) {\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.TAG_OPEN;\n                break;\n            }\n            case CODE_POINTS.AMPERSAND: {\n                this.returnState = State.DATA;\n                this.state = State.CHARACTER_REFERENCE;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitCodePoint(cp);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    //  RCDATA state\n    //------------------------------------------------------------------\n    _stateRcdata(cp) {\n        switch (cp) {\n            case CODE_POINTS.AMPERSAND: {\n                this.returnState = State.RCDATA;\n                this.state = State.CHARACTER_REFERENCE;\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.RCDATA_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // RAWTEXT state\n    //------------------------------------------------------------------\n    _stateRawtext(cp) {\n        switch (cp) {\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.RAWTEXT_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data state\n    //------------------------------------------------------------------\n    _stateScriptData(cp) {\n        switch (cp) {\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // PLAINTEXT state\n    //------------------------------------------------------------------\n    _statePlaintext(cp) {\n        switch (cp) {\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Tag open state\n    //------------------------------------------------------------------\n    _stateTagOpen(cp) {\n        if (isAsciiLetter(cp)) {\n            this._createStartTagToken();\n            this.state = State.TAG_NAME;\n            this._stateTagName(cp);\n        }\n        else\n            switch (cp) {\n                case CODE_POINTS.EXCLAMATION_MARK: {\n                    this.state = State.MARKUP_DECLARATION_OPEN;\n                    break;\n                }\n                case CODE_POINTS.SOLIDUS: {\n                    this.state = State.END_TAG_OPEN;\n                    break;\n                }\n                case CODE_POINTS.QUESTION_MARK: {\n                    this._err(ERR.unexpectedQuestionMarkInsteadOfTagName);\n                    this._createCommentToken(1);\n                    this.state = State.BOGUS_COMMENT;\n                    this._stateBogusComment(cp);\n                    break;\n                }\n                case CODE_POINTS.EOF: {\n                    this._err(ERR.eofBeforeTagName);\n                    this._emitChars('<');\n                    this._emitEOFToken();\n                    break;\n                }\n                default: {\n                    this._err(ERR.invalidFirstCharacterOfTagName);\n                    this._emitChars('<');\n                    this.state = State.DATA;\n                    this._stateData(cp);\n                }\n            }\n    }\n    // End tag open state\n    //------------------------------------------------------------------\n    _stateEndTagOpen(cp) {\n        if (isAsciiLetter(cp)) {\n            this._createEndTagToken();\n            this.state = State.TAG_NAME;\n            this._stateTagName(cp);\n        }\n        else\n            switch (cp) {\n                case CODE_POINTS.GREATER_THAN_SIGN: {\n                    this._err(ERR.missingEndTagName);\n                    this.state = State.DATA;\n                    break;\n                }\n                case CODE_POINTS.EOF: {\n                    this._err(ERR.eofBeforeTagName);\n                    this._emitChars('</');\n                    this._emitEOFToken();\n                    break;\n                }\n                default: {\n                    this._err(ERR.invalidFirstCharacterOfTagName);\n                    this._createCommentToken(2);\n                    this.state = State.BOGUS_COMMENT;\n                    this._stateBogusComment(cp);\n                }\n            }\n    }\n    // Tag name state\n    //------------------------------------------------------------------\n    _stateTagName(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this.state = State.BEFORE_ATTRIBUTE_NAME;\n                break;\n            }\n            case CODE_POINTS.SOLIDUS: {\n                this.state = State.SELF_CLOSING_START_TAG;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentTagToken();\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.tagName += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.tagName += String.fromCodePoint(isAsciiUpper(cp) ? toAsciiLower(cp) : cp);\n            }\n        }\n    }\n    // RCDATA less-than sign state\n    //------------------------------------------------------------------\n    _stateRcdataLessThanSign(cp) {\n        if (cp === CODE_POINTS.SOLIDUS) {\n            this.state = State.RCDATA_END_TAG_OPEN;\n        }\n        else {\n            this._emitChars('<');\n            this.state = State.RCDATA;\n            this._stateRcdata(cp);\n        }\n    }\n    // RCDATA end tag open state\n    //------------------------------------------------------------------\n    _stateRcdataEndTagOpen(cp) {\n        if (isAsciiLetter(cp)) {\n            this.state = State.RCDATA_END_TAG_NAME;\n            this._stateRcdataEndTagName(cp);\n        }\n        else {\n            this._emitChars('</');\n            this.state = State.RCDATA;\n            this._stateRcdata(cp);\n        }\n    }\n    handleSpecialEndTag(_cp) {\n        if (!this.preprocessor.startsWith(this.lastStartTagName, false)) {\n            return !this._ensureHibernation();\n        }\n        this._createEndTagToken();\n        const token = this.currentToken;\n        token.tagName = this.lastStartTagName;\n        const cp = this.preprocessor.peek(this.lastStartTagName.length);\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this._advanceBy(this.lastStartTagName.length);\n                this.state = State.BEFORE_ATTRIBUTE_NAME;\n                return false;\n            }\n            case CODE_POINTS.SOLIDUS: {\n                this._advanceBy(this.lastStartTagName.length);\n                this.state = State.SELF_CLOSING_START_TAG;\n                return false;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._advanceBy(this.lastStartTagName.length);\n                this.emitCurrentTagToken();\n                this.state = State.DATA;\n                return false;\n            }\n            default: {\n                return !this._ensureHibernation();\n            }\n        }\n    }\n    // RCDATA end tag name state\n    //------------------------------------------------------------------\n    _stateRcdataEndTagName(cp) {\n        if (this.handleSpecialEndTag(cp)) {\n            this._emitChars('</');\n            this.state = State.RCDATA;\n            this._stateRcdata(cp);\n        }\n    }\n    // RAWTEXT less-than sign state\n    //------------------------------------------------------------------\n    _stateRawtextLessThanSign(cp) {\n        if (cp === CODE_POINTS.SOLIDUS) {\n            this.state = State.RAWTEXT_END_TAG_OPEN;\n        }\n        else {\n            this._emitChars('<');\n            this.state = State.RAWTEXT;\n            this._stateRawtext(cp);\n        }\n    }\n    // RAWTEXT end tag open state\n    //------------------------------------------------------------------\n    _stateRawtextEndTagOpen(cp) {\n        if (isAsciiLetter(cp)) {\n            this.state = State.RAWTEXT_END_TAG_NAME;\n            this._stateRawtextEndTagName(cp);\n        }\n        else {\n            this._emitChars('</');\n            this.state = State.RAWTEXT;\n            this._stateRawtext(cp);\n        }\n    }\n    // RAWTEXT end tag name state\n    //------------------------------------------------------------------\n    _stateRawtextEndTagName(cp) {\n        if (this.handleSpecialEndTag(cp)) {\n            this._emitChars('</');\n            this.state = State.RAWTEXT;\n            this._stateRawtext(cp);\n        }\n    }\n    // Script data less-than sign state\n    //------------------------------------------------------------------\n    _stateScriptDataLessThanSign(cp) {\n        switch (cp) {\n            case CODE_POINTS.SOLIDUS: {\n                this.state = State.SCRIPT_DATA_END_TAG_OPEN;\n                break;\n            }\n            case CODE_POINTS.EXCLAMATION_MARK: {\n                this.state = State.SCRIPT_DATA_ESCAPE_START;\n                this._emitChars('<!');\n                break;\n            }\n            default: {\n                this._emitChars('<');\n                this.state = State.SCRIPT_DATA;\n                this._stateScriptData(cp);\n            }\n        }\n    }\n    // Script data end tag open state\n    //------------------------------------------------------------------\n    _stateScriptDataEndTagOpen(cp) {\n        if (isAsciiLetter(cp)) {\n            this.state = State.SCRIPT_DATA_END_TAG_NAME;\n            this._stateScriptDataEndTagName(cp);\n        }\n        else {\n            this._emitChars('</');\n            this.state = State.SCRIPT_DATA;\n            this._stateScriptData(cp);\n        }\n    }\n    // Script data end tag name state\n    //------------------------------------------------------------------\n    _stateScriptDataEndTagName(cp) {\n        if (this.handleSpecialEndTag(cp)) {\n            this._emitChars('</');\n            this.state = State.SCRIPT_DATA;\n            this._stateScriptData(cp);\n        }\n    }\n    // Script data escape start state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapeStart(cp) {\n        if (cp === CODE_POINTS.HYPHEN_MINUS) {\n            this.state = State.SCRIPT_DATA_ESCAPE_START_DASH;\n            this._emitChars('-');\n        }\n        else {\n            this.state = State.SCRIPT_DATA;\n            this._stateScriptData(cp);\n        }\n    }\n    // Script data escape start dash state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapeStartDash(cp) {\n        if (cp === CODE_POINTS.HYPHEN_MINUS) {\n            this.state = State.SCRIPT_DATA_ESCAPED_DASH_DASH;\n            this._emitChars('-');\n        }\n        else {\n            this.state = State.SCRIPT_DATA;\n            this._stateScriptData(cp);\n        }\n    }\n    // Script data escaped state\n    //------------------------------------------------------------------\n    _stateScriptDataEscaped(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.SCRIPT_DATA_ESCAPED_DASH;\n                this._emitChars('-');\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_ESCAPED_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInScriptHtmlCommentLikeText);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data escaped dash state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapedDash(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.SCRIPT_DATA_ESCAPED_DASH_DASH;\n                this._emitChars('-');\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_ESCAPED_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.state = State.SCRIPT_DATA_ESCAPED;\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInScriptHtmlCommentLikeText);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.state = State.SCRIPT_DATA_ESCAPED;\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data escaped dash dash state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapedDashDash(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this._emitChars('-');\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_ESCAPED_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA;\n                this._emitChars('>');\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.state = State.SCRIPT_DATA_ESCAPED;\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInScriptHtmlCommentLikeText);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.state = State.SCRIPT_DATA_ESCAPED;\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data escaped less-than sign state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapedLessThanSign(cp) {\n        if (cp === CODE_POINTS.SOLIDUS) {\n            this.state = State.SCRIPT_DATA_ESCAPED_END_TAG_OPEN;\n        }\n        else if (isAsciiLetter(cp)) {\n            this._emitChars('<');\n            this.state = State.SCRIPT_DATA_DOUBLE_ESCAPE_START;\n            this._stateScriptDataDoubleEscapeStart(cp);\n        }\n        else {\n            this._emitChars('<');\n            this.state = State.SCRIPT_DATA_ESCAPED;\n            this._stateScriptDataEscaped(cp);\n        }\n    }\n    // Script data escaped end tag open state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapedEndTagOpen(cp) {\n        if (isAsciiLetter(cp)) {\n            this.state = State.SCRIPT_DATA_ESCAPED_END_TAG_NAME;\n            this._stateScriptDataEscapedEndTagName(cp);\n        }\n        else {\n            this._emitChars('</');\n            this.state = State.SCRIPT_DATA_ESCAPED;\n            this._stateScriptDataEscaped(cp);\n        }\n    }\n    // Script data escaped end tag name state\n    //------------------------------------------------------------------\n    _stateScriptDataEscapedEndTagName(cp) {\n        if (this.handleSpecialEndTag(cp)) {\n            this._emitChars('</');\n            this.state = State.SCRIPT_DATA_ESCAPED;\n            this._stateScriptDataEscaped(cp);\n        }\n    }\n    // Script data double escape start state\n    //------------------------------------------------------------------\n    _stateScriptDataDoubleEscapeStart(cp) {\n        if (this.preprocessor.startsWith(SEQUENCES.SCRIPT, false) &&\n            isScriptDataDoubleEscapeSequenceEnd(this.preprocessor.peek(SEQUENCES.SCRIPT.length))) {\n            this._emitCodePoint(cp);\n            for (let i = 0; i < SEQUENCES.SCRIPT.length; i++) {\n                this._emitCodePoint(this._consume());\n            }\n            this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n        }\n        else if (!this._ensureHibernation()) {\n            this.state = State.SCRIPT_DATA_ESCAPED;\n            this._stateScriptDataEscaped(cp);\n        }\n    }\n    // Script data double escaped state\n    //------------------------------------------------------------------\n    _stateScriptDataDoubleEscaped(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED_DASH;\n                this._emitChars('-');\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED_LESS_THAN_SIGN;\n                this._emitChars('<');\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInScriptHtmlCommentLikeText);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data double escaped dash state\n    //------------------------------------------------------------------\n    _stateScriptDataDoubleEscapedDash(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED_DASH_DASH;\n                this._emitChars('-');\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED_LESS_THAN_SIGN;\n                this._emitChars('<');\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInScriptHtmlCommentLikeText);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data double escaped dash dash state\n    //------------------------------------------------------------------\n    _stateScriptDataDoubleEscapedDashDash(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this._emitChars('-');\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED_LESS_THAN_SIGN;\n                this._emitChars('<');\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.SCRIPT_DATA;\n                this._emitChars('>');\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n                this._emitChars(REPLACEMENT_CHARACTER);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInScriptHtmlCommentLikeText);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // Script data double escaped less-than sign state\n    //------------------------------------------------------------------\n    _stateScriptDataDoubleEscapedLessThanSign(cp) {\n        if (cp === CODE_POINTS.SOLIDUS) {\n            this.state = State.SCRIPT_DATA_DOUBLE_ESCAPE_END;\n            this._emitChars('/');\n        }\n        else {\n            this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n            this._stateScriptDataDoubleEscaped(cp);\n        }\n    }\n    // Script data double escape end state\n    //------------------------------------------------------------------\n    _stateScriptDataDoubleEscapeEnd(cp) {\n        if (this.preprocessor.startsWith(SEQUENCES.SCRIPT, false) &&\n            isScriptDataDoubleEscapeSequenceEnd(this.preprocessor.peek(SEQUENCES.SCRIPT.length))) {\n            this._emitCodePoint(cp);\n            for (let i = 0; i < SEQUENCES.SCRIPT.length; i++) {\n                this._emitCodePoint(this._consume());\n            }\n            this.state = State.SCRIPT_DATA_ESCAPED;\n        }\n        else if (!this._ensureHibernation()) {\n            this.state = State.SCRIPT_DATA_DOUBLE_ESCAPED;\n            this._stateScriptDataDoubleEscaped(cp);\n        }\n    }\n    // Before attribute name state\n    //------------------------------------------------------------------\n    _stateBeforeAttributeName(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.SOLIDUS:\n            case CODE_POINTS.GREATER_THAN_SIGN:\n            case CODE_POINTS.EOF: {\n                this.state = State.AFTER_ATTRIBUTE_NAME;\n                this._stateAfterAttributeName(cp);\n                break;\n            }\n            case CODE_POINTS.EQUALS_SIGN: {\n                this._err(ERR.unexpectedEqualsSignBeforeAttributeName);\n                this._createAttr('=');\n                this.state = State.ATTRIBUTE_NAME;\n                break;\n            }\n            default: {\n                this._createAttr('');\n                this.state = State.ATTRIBUTE_NAME;\n                this._stateAttributeName(cp);\n            }\n        }\n    }\n    // Attribute name state\n    //------------------------------------------------------------------\n    _stateAttributeName(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED:\n            case CODE_POINTS.SOLIDUS:\n            case CODE_POINTS.GREATER_THAN_SIGN:\n            case CODE_POINTS.EOF: {\n                this._leaveAttrName();\n                this.state = State.AFTER_ATTRIBUTE_NAME;\n                this._stateAfterAttributeName(cp);\n                break;\n            }\n            case CODE_POINTS.EQUALS_SIGN: {\n                this._leaveAttrName();\n                this.state = State.BEFORE_ATTRIBUTE_VALUE;\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK:\n            case CODE_POINTS.APOSTROPHE:\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                this._err(ERR.unexpectedCharacterInAttributeName);\n                this.currentAttr.name += String.fromCodePoint(cp);\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.currentAttr.name += REPLACEMENT_CHARACTER;\n                break;\n            }\n            default: {\n                this.currentAttr.name += String.fromCodePoint(isAsciiUpper(cp) ? toAsciiLower(cp) : cp);\n            }\n        }\n    }\n    // After attribute name state\n    //------------------------------------------------------------------\n    _stateAfterAttributeName(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.SOLIDUS: {\n                this.state = State.SELF_CLOSING_START_TAG;\n                break;\n            }\n            case CODE_POINTS.EQUALS_SIGN: {\n                this.state = State.BEFORE_ATTRIBUTE_VALUE;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentTagToken();\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._createAttr('');\n                this.state = State.ATTRIBUTE_NAME;\n                this._stateAttributeName(cp);\n            }\n        }\n    }\n    // Before attribute value state\n    //------------------------------------------------------------------\n    _stateBeforeAttributeValue(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                this.state = State.ATTRIBUTE_VALUE_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                this.state = State.ATTRIBUTE_VALUE_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.missingAttributeValue);\n                this.state = State.DATA;\n                this.emitCurrentTagToken();\n                break;\n            }\n            default: {\n                this.state = State.ATTRIBUTE_VALUE_UNQUOTED;\n                this._stateAttributeValueUnquoted(cp);\n            }\n        }\n    }\n    // Attribute value (double-quoted) state\n    //------------------------------------------------------------------\n    _stateAttributeValueDoubleQuoted(cp) {\n        switch (cp) {\n            case CODE_POINTS.QUOTATION_MARK: {\n                this.state = State.AFTER_ATTRIBUTE_VALUE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.AMPERSAND: {\n                this.returnState = State.ATTRIBUTE_VALUE_DOUBLE_QUOTED;\n                this.state = State.CHARACTER_REFERENCE;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.currentAttr.value += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.currentAttr.value += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // Attribute value (single-quoted) state\n    //------------------------------------------------------------------\n    _stateAttributeValueSingleQuoted(cp) {\n        switch (cp) {\n            case CODE_POINTS.APOSTROPHE: {\n                this.state = State.AFTER_ATTRIBUTE_VALUE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.AMPERSAND: {\n                this.returnState = State.ATTRIBUTE_VALUE_SINGLE_QUOTED;\n                this.state = State.CHARACTER_REFERENCE;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.currentAttr.value += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.currentAttr.value += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // Attribute value (unquoted) state\n    //------------------------------------------------------------------\n    _stateAttributeValueUnquoted(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this._leaveAttrValue();\n                this.state = State.BEFORE_ATTRIBUTE_NAME;\n                break;\n            }\n            case CODE_POINTS.AMPERSAND: {\n                this.returnState = State.ATTRIBUTE_VALUE_UNQUOTED;\n                this.state = State.CHARACTER_REFERENCE;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._leaveAttrValue();\n                this.state = State.DATA;\n                this.emitCurrentTagToken();\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                this.currentAttr.value += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK:\n            case CODE_POINTS.APOSTROPHE:\n            case CODE_POINTS.LESS_THAN_SIGN:\n            case CODE_POINTS.EQUALS_SIGN:\n            case CODE_POINTS.GRAVE_ACCENT: {\n                this._err(ERR.unexpectedCharacterInUnquotedAttributeValue);\n                this.currentAttr.value += String.fromCodePoint(cp);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this.currentAttr.value += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // After attribute value (quoted) state\n    //------------------------------------------------------------------\n    _stateAfterAttributeValueQuoted(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this._leaveAttrValue();\n                this.state = State.BEFORE_ATTRIBUTE_NAME;\n                break;\n            }\n            case CODE_POINTS.SOLIDUS: {\n                this._leaveAttrValue();\n                this.state = State.SELF_CLOSING_START_TAG;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._leaveAttrValue();\n                this.state = State.DATA;\n                this.emitCurrentTagToken();\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingWhitespaceBetweenAttributes);\n                this.state = State.BEFORE_ATTRIBUTE_NAME;\n                this._stateBeforeAttributeName(cp);\n            }\n        }\n    }\n    // Self-closing start tag state\n    //------------------------------------------------------------------\n    _stateSelfClosingStartTag(cp) {\n        switch (cp) {\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                const token = this.currentToken;\n                token.selfClosing = true;\n                this.state = State.DATA;\n                this.emitCurrentTagToken();\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInTag);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.unexpectedSolidusInTag);\n                this.state = State.BEFORE_ATTRIBUTE_NAME;\n                this._stateBeforeAttributeName(cp);\n            }\n        }\n    }\n    // Bogus comment state\n    //------------------------------------------------------------------\n    _stateBogusComment(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentComment(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this.emitCurrentComment(token);\n                this._emitEOFToken();\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.data += REPLACEMENT_CHARACTER;\n                break;\n            }\n            default: {\n                token.data += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // Markup declaration open state\n    //------------------------------------------------------------------\n    _stateMarkupDeclarationOpen(cp) {\n        if (this._consumeSequenceIfMatch(SEQUENCES.DASH_DASH, true)) {\n            this._createCommentToken(SEQUENCES.DASH_DASH.length + 1);\n            this.state = State.COMMENT_START;\n        }\n        else if (this._consumeSequenceIfMatch(SEQUENCES.DOCTYPE, false)) {\n            // NOTE: Doctypes tokens are created without fixed offsets. We keep track of the moment a doctype *might* start here.\n            this.currentLocation = this.getCurrentLocation(SEQUENCES.DOCTYPE.length + 1);\n            this.state = State.DOCTYPE;\n        }\n        else if (this._consumeSequenceIfMatch(SEQUENCES.CDATA_START, true)) {\n            if (this.inForeignNode) {\n                this.state = State.CDATA_SECTION;\n            }\n            else {\n                this._err(ERR.cdataInHtmlContent);\n                this._createCommentToken(SEQUENCES.CDATA_START.length + 1);\n                this.currentToken.data = '[CDATA[';\n                this.state = State.BOGUS_COMMENT;\n            }\n        }\n        //NOTE: Sequence lookups can be abrupted by hibernation. In that case, lookup\n        //results are no longer valid and we will need to start over.\n        else if (!this._ensureHibernation()) {\n            this._err(ERR.incorrectlyOpenedComment);\n            this._createCommentToken(2);\n            this.state = State.BOGUS_COMMENT;\n            this._stateBogusComment(cp);\n        }\n    }\n    // Comment start state\n    //------------------------------------------------------------------\n    _stateCommentStart(cp) {\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.COMMENT_START_DASH;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.abruptClosingOfEmptyComment);\n                this.state = State.DATA;\n                const token = this.currentToken;\n                this.emitCurrentComment(token);\n                break;\n            }\n            default: {\n                this.state = State.COMMENT;\n                this._stateComment(cp);\n            }\n        }\n    }\n    // Comment start dash state\n    //------------------------------------------------------------------\n    _stateCommentStartDash(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.COMMENT_END;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.abruptClosingOfEmptyComment);\n                this.state = State.DATA;\n                this.emitCurrentComment(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInComment);\n                this.emitCurrentComment(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.data += '-';\n                this.state = State.COMMENT;\n                this._stateComment(cp);\n            }\n        }\n    }\n    // Comment state\n    //------------------------------------------------------------------\n    _stateComment(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.COMMENT_END_DASH;\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                token.data += '<';\n                this.state = State.COMMENT_LESS_THAN_SIGN;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.data += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInComment);\n                this.emitCurrentComment(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.data += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // Comment less-than sign state\n    //------------------------------------------------------------------\n    _stateCommentLessThanSign(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.EXCLAMATION_MARK: {\n                token.data += '!';\n                this.state = State.COMMENT_LESS_THAN_SIGN_BANG;\n                break;\n            }\n            case CODE_POINTS.LESS_THAN_SIGN: {\n                token.data += '<';\n                break;\n            }\n            default: {\n                this.state = State.COMMENT;\n                this._stateComment(cp);\n            }\n        }\n    }\n    // Comment less-than sign bang state\n    //------------------------------------------------------------------\n    _stateCommentLessThanSignBang(cp) {\n        if (cp === CODE_POINTS.HYPHEN_MINUS) {\n            this.state = State.COMMENT_LESS_THAN_SIGN_BANG_DASH;\n        }\n        else {\n            this.state = State.COMMENT;\n            this._stateComment(cp);\n        }\n    }\n    // Comment less-than sign bang dash state\n    //------------------------------------------------------------------\n    _stateCommentLessThanSignBangDash(cp) {\n        if (cp === CODE_POINTS.HYPHEN_MINUS) {\n            this.state = State.COMMENT_LESS_THAN_SIGN_BANG_DASH_DASH;\n        }\n        else {\n            this.state = State.COMMENT_END_DASH;\n            this._stateCommentEndDash(cp);\n        }\n    }\n    // Comment less-than sign bang dash dash state\n    //------------------------------------------------------------------\n    _stateCommentLessThanSignBangDashDash(cp) {\n        if (cp !== CODE_POINTS.GREATER_THAN_SIGN && cp !== CODE_POINTS.EOF) {\n            this._err(ERR.nestedComment);\n        }\n        this.state = State.COMMENT_END;\n        this._stateCommentEnd(cp);\n    }\n    // Comment end dash state\n    //------------------------------------------------------------------\n    _stateCommentEndDash(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                this.state = State.COMMENT_END;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInComment);\n                this.emitCurrentComment(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.data += '-';\n                this.state = State.COMMENT;\n                this._stateComment(cp);\n            }\n        }\n    }\n    // Comment end state\n    //------------------------------------------------------------------\n    _stateCommentEnd(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentComment(token);\n                break;\n            }\n            case CODE_POINTS.EXCLAMATION_MARK: {\n                this.state = State.COMMENT_END_BANG;\n                break;\n            }\n            case CODE_POINTS.HYPHEN_MINUS: {\n                token.data += '-';\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInComment);\n                this.emitCurrentComment(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.data += '--';\n                this.state = State.COMMENT;\n                this._stateComment(cp);\n            }\n        }\n    }\n    // Comment end bang state\n    //------------------------------------------------------------------\n    _stateCommentEndBang(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.HYPHEN_MINUS: {\n                token.data += '--!';\n                this.state = State.COMMENT_END_DASH;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.incorrectlyClosedComment);\n                this.state = State.DATA;\n                this.emitCurrentComment(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInComment);\n                this.emitCurrentComment(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.data += '--!';\n                this.state = State.COMMENT;\n                this._stateComment(cp);\n            }\n        }\n    }\n    // DOCTYPE state\n    //------------------------------------------------------------------\n    _stateDoctype(cp) {\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this.state = State.BEFORE_DOCTYPE_NAME;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.BEFORE_DOCTYPE_NAME;\n                this._stateBeforeDoctypeName(cp);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                this._createDoctypeToken(null);\n                const token = this.currentToken;\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingWhitespaceBeforeDoctypeName);\n                this.state = State.BEFORE_DOCTYPE_NAME;\n                this._stateBeforeDoctypeName(cp);\n            }\n        }\n    }\n    // Before DOCTYPE name state\n    //------------------------------------------------------------------\n    _stateBeforeDoctypeName(cp) {\n        if (isAsciiUpper(cp)) {\n            this._createDoctypeToken(String.fromCharCode(toAsciiLower(cp)));\n            this.state = State.DOCTYPE_NAME;\n        }\n        else\n            switch (cp) {\n                case CODE_POINTS.SPACE:\n                case CODE_POINTS.LINE_FEED:\n                case CODE_POINTS.TABULATION:\n                case CODE_POINTS.FORM_FEED: {\n                    // Ignore whitespace\n                    break;\n                }\n                case CODE_POINTS.NULL: {\n                    this._err(ERR.unexpectedNullCharacter);\n                    this._createDoctypeToken(REPLACEMENT_CHARACTER);\n                    this.state = State.DOCTYPE_NAME;\n                    break;\n                }\n                case CODE_POINTS.GREATER_THAN_SIGN: {\n                    this._err(ERR.missingDoctypeName);\n                    this._createDoctypeToken(null);\n                    const token = this.currentToken;\n                    token.forceQuirks = true;\n                    this.emitCurrentDoctype(token);\n                    this.state = State.DATA;\n                    break;\n                }\n                case CODE_POINTS.EOF: {\n                    this._err(ERR.eofInDoctype);\n                    this._createDoctypeToken(null);\n                    const token = this.currentToken;\n                    token.forceQuirks = true;\n                    this.emitCurrentDoctype(token);\n                    this._emitEOFToken();\n                    break;\n                }\n                default: {\n                    this._createDoctypeToken(String.fromCodePoint(cp));\n                    this.state = State.DOCTYPE_NAME;\n                }\n            }\n    }\n    // DOCTYPE name state\n    //------------------------------------------------------------------\n    _stateDoctypeName(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this.state = State.AFTER_DOCTYPE_NAME;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.name += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.name += String.fromCodePoint(isAsciiUpper(cp) ? toAsciiLower(cp) : cp);\n            }\n        }\n    }\n    // After DOCTYPE name state\n    //------------------------------------------------------------------\n    _stateAfterDoctypeName(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                if (this._consumeSequenceIfMatch(SEQUENCES.PUBLIC, false)) {\n                    this.state = State.AFTER_DOCTYPE_PUBLIC_KEYWORD;\n                }\n                else if (this._consumeSequenceIfMatch(SEQUENCES.SYSTEM, false)) {\n                    this.state = State.AFTER_DOCTYPE_SYSTEM_KEYWORD;\n                }\n                //NOTE: sequence lookup can be abrupted by hibernation. In that case lookup\n                //results are no longer valid and we will need to start over.\n                else if (!this._ensureHibernation()) {\n                    this._err(ERR.invalidCharacterSequenceAfterDoctypeName);\n                    token.forceQuirks = true;\n                    this.state = State.BOGUS_DOCTYPE;\n                    this._stateBogusDoctype(cp);\n                }\n            }\n        }\n    }\n    // After DOCTYPE public keyword state\n    //------------------------------------------------------------------\n    _stateAfterDoctypePublicKeyword(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this.state = State.BEFORE_DOCTYPE_PUBLIC_IDENTIFIER;\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                this._err(ERR.missingWhitespaceAfterDoctypePublicKeyword);\n                token.publicId = '';\n                this.state = State.DOCTYPE_PUBLIC_IDENTIFIER_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                this._err(ERR.missingWhitespaceAfterDoctypePublicKeyword);\n                token.publicId = '';\n                this.state = State.DOCTYPE_PUBLIC_IDENTIFIER_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.missingDoctypePublicIdentifier);\n                token.forceQuirks = true;\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingQuoteBeforeDoctypePublicIdentifier);\n                token.forceQuirks = true;\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // Before DOCTYPE public identifier state\n    //------------------------------------------------------------------\n    _stateBeforeDoctypePublicIdentifier(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                token.publicId = '';\n                this.state = State.DOCTYPE_PUBLIC_IDENTIFIER_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                token.publicId = '';\n                this.state = State.DOCTYPE_PUBLIC_IDENTIFIER_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.missingDoctypePublicIdentifier);\n                token.forceQuirks = true;\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingQuoteBeforeDoctypePublicIdentifier);\n                token.forceQuirks = true;\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // DOCTYPE public identifier (double-quoted) state\n    //------------------------------------------------------------------\n    _stateDoctypePublicIdentifierDoubleQuoted(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.QUOTATION_MARK: {\n                this.state = State.AFTER_DOCTYPE_PUBLIC_IDENTIFIER;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.publicId += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.abruptDoctypePublicIdentifier);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.publicId += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // DOCTYPE public identifier (single-quoted) state\n    //------------------------------------------------------------------\n    _stateDoctypePublicIdentifierSingleQuoted(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.APOSTROPHE: {\n                this.state = State.AFTER_DOCTYPE_PUBLIC_IDENTIFIER;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.publicId += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.abruptDoctypePublicIdentifier);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.publicId += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // After DOCTYPE public identifier state\n    //------------------------------------------------------------------\n    _stateAfterDoctypePublicIdentifier(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this.state = State.BETWEEN_DOCTYPE_PUBLIC_AND_SYSTEM_IDENTIFIERS;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                this._err(ERR.missingWhitespaceBetweenDoctypePublicAndSystemIdentifiers);\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                this._err(ERR.missingWhitespaceBetweenDoctypePublicAndSystemIdentifiers);\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingQuoteBeforeDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // Between DOCTYPE public and system identifiers state\n    //------------------------------------------------------------------\n    _stateBetweenDoctypePublicAndSystemIdentifiers(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingQuoteBeforeDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // After DOCTYPE system keyword state\n    //------------------------------------------------------------------\n    _stateAfterDoctypeSystemKeyword(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                this.state = State.BEFORE_DOCTYPE_SYSTEM_IDENTIFIER;\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                this._err(ERR.missingWhitespaceAfterDoctypeSystemKeyword);\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                this._err(ERR.missingWhitespaceAfterDoctypeSystemKeyword);\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.missingDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingQuoteBeforeDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // Before DOCTYPE system identifier state\n    //------------------------------------------------------------------\n    _stateBeforeDoctypeSystemIdentifier(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.QUOTATION_MARK: {\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_DOUBLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.APOSTROPHE: {\n                token.systemId = '';\n                this.state = State.DOCTYPE_SYSTEM_IDENTIFIER_SINGLE_QUOTED;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.missingDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.state = State.DATA;\n                this.emitCurrentDoctype(token);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.missingQuoteBeforeDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // DOCTYPE system identifier (double-quoted) state\n    //------------------------------------------------------------------\n    _stateDoctypeSystemIdentifierDoubleQuoted(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.QUOTATION_MARK: {\n                this.state = State.AFTER_DOCTYPE_SYSTEM_IDENTIFIER;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.systemId += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.abruptDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.systemId += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // DOCTYPE system identifier (single-quoted) state\n    //------------------------------------------------------------------\n    _stateDoctypeSystemIdentifierSingleQuoted(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.APOSTROPHE: {\n                this.state = State.AFTER_DOCTYPE_SYSTEM_IDENTIFIER;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                token.systemId += REPLACEMENT_CHARACTER;\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this._err(ERR.abruptDoctypeSystemIdentifier);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                token.systemId += String.fromCodePoint(cp);\n            }\n        }\n    }\n    // After DOCTYPE system identifier state\n    //------------------------------------------------------------------\n    _stateAfterDoctypeSystemIdentifier(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.SPACE:\n            case CODE_POINTS.LINE_FEED:\n            case CODE_POINTS.TABULATION:\n            case CODE_POINTS.FORM_FEED: {\n                // Ignore whitespace\n                break;\n            }\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInDoctype);\n                token.forceQuirks = true;\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._err(ERR.unexpectedCharacterAfterDoctypeSystemIdentifier);\n                this.state = State.BOGUS_DOCTYPE;\n                this._stateBogusDoctype(cp);\n            }\n        }\n    }\n    // Bogus DOCTYPE state\n    //------------------------------------------------------------------\n    _stateBogusDoctype(cp) {\n        const token = this.currentToken;\n        switch (cp) {\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.emitCurrentDoctype(token);\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.NULL: {\n                this._err(ERR.unexpectedNullCharacter);\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this.emitCurrentDoctype(token);\n                this._emitEOFToken();\n                break;\n            }\n            // Do nothing\n        }\n    }\n    // CDATA section state\n    //------------------------------------------------------------------\n    _stateCdataSection(cp) {\n        switch (cp) {\n            case CODE_POINTS.RIGHT_SQUARE_BRACKET: {\n                this.state = State.CDATA_SECTION_BRACKET;\n                break;\n            }\n            case CODE_POINTS.EOF: {\n                this._err(ERR.eofInCdata);\n                this._emitEOFToken();\n                break;\n            }\n            default: {\n                this._emitCodePoint(cp);\n            }\n        }\n    }\n    // CDATA section bracket state\n    //------------------------------------------------------------------\n    _stateCdataSectionBracket(cp) {\n        if (cp === CODE_POINTS.RIGHT_SQUARE_BRACKET) {\n            this.state = State.CDATA_SECTION_END;\n        }\n        else {\n            this._emitChars(']');\n            this.state = State.CDATA_SECTION;\n            this._stateCdataSection(cp);\n        }\n    }\n    // CDATA section end state\n    //------------------------------------------------------------------\n    _stateCdataSectionEnd(cp) {\n        switch (cp) {\n            case CODE_POINTS.GREATER_THAN_SIGN: {\n                this.state = State.DATA;\n                break;\n            }\n            case CODE_POINTS.RIGHT_SQUARE_BRACKET: {\n                this._emitChars(']');\n                break;\n            }\n            default: {\n                this._emitChars(']]');\n                this.state = State.CDATA_SECTION;\n                this._stateCdataSection(cp);\n            }\n        }\n    }\n    // Character reference state\n    //------------------------------------------------------------------\n    _stateCharacterReference(cp) {\n        if (cp === CODE_POINTS.NUMBER_SIGN) {\n            this.state = State.NUMERIC_CHARACTER_REFERENCE;\n        }\n        else if (isAsciiAlphaNumeric(cp)) {\n            this.state = State.NAMED_CHARACTER_REFERENCE;\n            this._stateNamedCharacterReference(cp);\n        }\n        else {\n            this._flushCodePointConsumedAsCharacterReference(CODE_POINTS.AMPERSAND);\n            this._reconsumeInState(this.returnState, cp);\n        }\n    }\n    // Named character reference state\n    //------------------------------------------------------------------\n    _stateNamedCharacterReference(cp) {\n        const matchResult = this._matchNamedCharacterReference(cp);\n        //NOTE: Matching can be abrupted by hibernation. In that case, match\n        //results are no longer valid and we will need to start over.\n        if (this._ensureHibernation()) ;\n        else if (matchResult) {\n            for (let i = 0; i < matchResult.length; i++) {\n                this._flushCodePointConsumedAsCharacterReference(matchResult[i]);\n            }\n            this.state = this.returnState;\n        }\n        else {\n            this._flushCodePointConsumedAsCharacterReference(CODE_POINTS.AMPERSAND);\n            this.state = State.AMBIGUOUS_AMPERSAND;\n        }\n    }\n    // Ambiguos ampersand state\n    //------------------------------------------------------------------\n    _stateAmbiguousAmpersand(cp) {\n        if (isAsciiAlphaNumeric(cp)) {\n            this._flushCodePointConsumedAsCharacterReference(cp);\n        }\n        else {\n            if (cp === CODE_POINTS.SEMICOLON) {\n                this._err(ERR.unknownNamedCharacterReference);\n            }\n            this._reconsumeInState(this.returnState, cp);\n        }\n    }\n    // Numeric character reference state\n    //------------------------------------------------------------------\n    _stateNumericCharacterReference(cp) {\n        this.charRefCode = 0;\n        if (cp === CODE_POINTS.LATIN_SMALL_X || cp === CODE_POINTS.LATIN_CAPITAL_X) {\n            this.state = State.HEXADEMICAL_CHARACTER_REFERENCE_START;\n        }\n        // Inlined decimal character reference start state\n        else if (isAsciiDigit(cp)) {\n            this.state = State.DECIMAL_CHARACTER_REFERENCE;\n            this._stateDecimalCharacterReference(cp);\n        }\n        else {\n            this._err(ERR.absenceOfDigitsInNumericCharacterReference);\n            this._flushCodePointConsumedAsCharacterReference(CODE_POINTS.AMPERSAND);\n            this._flushCodePointConsumedAsCharacterReference(CODE_POINTS.NUMBER_SIGN);\n            this._reconsumeInState(this.returnState, cp);\n        }\n    }\n    // Hexademical character reference start state\n    //------------------------------------------------------------------\n    _stateHexademicalCharacterReferenceStart(cp) {\n        if (isAsciiHexDigit(cp)) {\n            this.state = State.HEXADEMICAL_CHARACTER_REFERENCE;\n            this._stateHexademicalCharacterReference(cp);\n        }\n        else {\n            this._err(ERR.absenceOfDigitsInNumericCharacterReference);\n            this._flushCodePointConsumedAsCharacterReference(CODE_POINTS.AMPERSAND);\n            this._flushCodePointConsumedAsCharacterReference(CODE_POINTS.NUMBER_SIGN);\n            this._unconsume(2);\n            this.state = this.returnState;\n        }\n    }\n    // Hexademical character reference state\n    //------------------------------------------------------------------\n    _stateHexademicalCharacterReference(cp) {\n        if (isAsciiUpperHexDigit(cp)) {\n            this.charRefCode = this.charRefCode * 16 + cp - 0x37;\n        }\n        else if (isAsciiLowerHexDigit(cp)) {\n            this.charRefCode = this.charRefCode * 16 + cp - 0x57;\n        }\n        else if (isAsciiDigit(cp)) {\n            this.charRefCode = this.charRefCode * 16 + cp - 0x30;\n        }\n        else if (cp === CODE_POINTS.SEMICOLON) {\n            this.state = State.NUMERIC_CHARACTER_REFERENCE_END;\n        }\n        else {\n            this._err(ERR.missingSemicolonAfterCharacterReference);\n            this.state = State.NUMERIC_CHARACTER_REFERENCE_END;\n            this._stateNumericCharacterReferenceEnd(cp);\n        }\n    }\n    // Decimal character reference state\n    //------------------------------------------------------------------\n    _stateDecimalCharacterReference(cp) {\n        if (isAsciiDigit(cp)) {\n            this.charRefCode = this.charRefCode * 10 + cp - 0x30;\n        }\n        else if (cp === CODE_POINTS.SEMICOLON) {\n            this.state = State.NUMERIC_CHARACTER_REFERENCE_END;\n        }\n        else {\n            this._err(ERR.missingSemicolonAfterCharacterReference);\n            this.state = State.NUMERIC_CHARACTER_REFERENCE_END;\n            this._stateNumericCharacterReferenceEnd(cp);\n        }\n    }\n    // Numeric character reference end state\n    //------------------------------------------------------------------\n    _stateNumericCharacterReferenceEnd(cp) {\n        if (this.charRefCode === CODE_POINTS.NULL) {\n            this._err(ERR.nullCharacterReference);\n            this.charRefCode = CODE_POINTS.REPLACEMENT_CHARACTER;\n        }\n        else if (this.charRefCode > 1114111) {\n            this._err(ERR.characterReferenceOutsideUnicodeRange);\n            this.charRefCode = CODE_POINTS.REPLACEMENT_CHARACTER;\n        }\n        else if (isSurrogate(this.charRefCode)) {\n            this._err(ERR.surrogateCharacterReference);\n            this.charRefCode = CODE_POINTS.REPLACEMENT_CHARACTER;\n        }\n        else if (isUndefinedCodePoint(this.charRefCode)) {\n            this._err(ERR.noncharacterCharacterReference);\n        }\n        else if (isControlCodePoint(this.charRefCode) || this.charRefCode === CODE_POINTS.CARRIAGE_RETURN) {\n            this._err(ERR.controlCharacterReference);\n            const replacement = C1_CONTROLS_REFERENCE_REPLACEMENTS.get(this.charRefCode);\n            if (replacement !== undefined) {\n                this.charRefCode = replacement;\n            }\n        }\n        this._flushCodePointConsumedAsCharacterReference(this.charRefCode);\n        this._reconsumeInState(this.returnState, cp);\n    }\n}\n\n//Element utils\nconst IMPLICIT_END_TAG_REQUIRED = new Set([TAG_ID.DD, TAG_ID.DT, TAG_ID.LI, TAG_ID.OPTGROUP, TAG_ID.OPTION, TAG_ID.P, TAG_ID.RB, TAG_ID.RP, TAG_ID.RT, TAG_ID.RTC]);\nconst IMPLICIT_END_TAG_REQUIRED_THOROUGHLY = new Set([\n    ...IMPLICIT_END_TAG_REQUIRED,\n    TAG_ID.CAPTION,\n    TAG_ID.COLGROUP,\n    TAG_ID.TBODY,\n    TAG_ID.TD,\n    TAG_ID.TFOOT,\n    TAG_ID.TH,\n    TAG_ID.THEAD,\n    TAG_ID.TR,\n]);\nconst SCOPING_ELEMENT_NS = new Map([\n    [TAG_ID.APPLET, NS.HTML],\n    [TAG_ID.CAPTION, NS.HTML],\n    [TAG_ID.HTML, NS.HTML],\n    [TAG_ID.MARQUEE, NS.HTML],\n    [TAG_ID.OBJECT, NS.HTML],\n    [TAG_ID.TABLE, NS.HTML],\n    [TAG_ID.TD, NS.HTML],\n    [TAG_ID.TEMPLATE, NS.HTML],\n    [TAG_ID.TH, NS.HTML],\n    [TAG_ID.ANNOTATION_XML, NS.MATHML],\n    [TAG_ID.MI, NS.MATHML],\n    [TAG_ID.MN, NS.MATHML],\n    [TAG_ID.MO, NS.MATHML],\n    [TAG_ID.MS, NS.MATHML],\n    [TAG_ID.MTEXT, NS.MATHML],\n    [TAG_ID.DESC, NS.SVG],\n    [TAG_ID.FOREIGN_OBJECT, NS.SVG],\n    [TAG_ID.TITLE, NS.SVG],\n]);\nconst NAMED_HEADERS = [TAG_ID.H1, TAG_ID.H2, TAG_ID.H3, TAG_ID.H4, TAG_ID.H5, TAG_ID.H6];\nconst TABLE_ROW_CONTEXT = [TAG_ID.TR, TAG_ID.TEMPLATE, TAG_ID.HTML];\nconst TABLE_BODY_CONTEXT = [TAG_ID.TBODY, TAG_ID.TFOOT, TAG_ID.THEAD, TAG_ID.TEMPLATE, TAG_ID.HTML];\nconst TABLE_CONTEXT = [TAG_ID.TABLE, TAG_ID.TEMPLATE, TAG_ID.HTML];\nconst TABLE_CELLS = [TAG_ID.TD, TAG_ID.TH];\n//Stack of open elements\nclass OpenElementStack {\n    get currentTmplContentOrNode() {\n        return this._isInTemplate() ? this.treeAdapter.getTemplateContent(this.current) : this.current;\n    }\n    constructor(document, treeAdapter, handler) {\n        this.treeAdapter = treeAdapter;\n        this.handler = handler;\n        this.items = [];\n        this.tagIDs = [];\n        this.stackTop = -1;\n        this.tmplCount = 0;\n        this.currentTagId = TAG_ID.UNKNOWN;\n        this.current = document;\n    }\n    //Index of element\n    _indexOf(element) {\n        return this.items.lastIndexOf(element, this.stackTop);\n    }\n    //Update current element\n    _isInTemplate() {\n        return this.currentTagId === TAG_ID.TEMPLATE && this.treeAdapter.getNamespaceURI(this.current) === NS.HTML;\n    }\n    _updateCurrentElement() {\n        this.current = this.items[this.stackTop];\n        this.currentTagId = this.tagIDs[this.stackTop];\n    }\n    //Mutations\n    push(element, tagID) {\n        this.stackTop++;\n        this.items[this.stackTop] = element;\n        this.current = element;\n        this.tagIDs[this.stackTop] = tagID;\n        this.currentTagId = tagID;\n        if (this._isInTemplate()) {\n            this.tmplCount++;\n        }\n        this.handler.onItemPush(element, tagID, true);\n    }\n    pop() {\n        const popped = this.current;\n        if (this.tmplCount > 0 && this._isInTemplate()) {\n            this.tmplCount--;\n        }\n        this.stackTop--;\n        this._updateCurrentElement();\n        this.handler.onItemPop(popped, true);\n    }\n    replace(oldElement, newElement) {\n        const idx = this._indexOf(oldElement);\n        this.items[idx] = newElement;\n        if (idx === this.stackTop) {\n            this.current = newElement;\n        }\n    }\n    insertAfter(referenceElement, newElement, newElementID) {\n        const insertionIdx = this._indexOf(referenceElement) + 1;\n        this.items.splice(insertionIdx, 0, newElement);\n        this.tagIDs.splice(insertionIdx, 0, newElementID);\n        this.stackTop++;\n        if (insertionIdx === this.stackTop) {\n            this._updateCurrentElement();\n        }\n        this.handler.onItemPush(this.current, this.currentTagId, insertionIdx === this.stackTop);\n    }\n    popUntilTagNamePopped(tagName) {\n        let targetIdx = this.stackTop + 1;\n        do {\n            targetIdx = this.tagIDs.lastIndexOf(tagName, targetIdx - 1);\n        } while (targetIdx > 0 && this.treeAdapter.getNamespaceURI(this.items[targetIdx]) !== NS.HTML);\n        this.shortenToLength(targetIdx < 0 ? 0 : targetIdx);\n    }\n    shortenToLength(idx) {\n        while (this.stackTop >= idx) {\n            const popped = this.current;\n            if (this.tmplCount > 0 && this._isInTemplate()) {\n                this.tmplCount -= 1;\n            }\n            this.stackTop--;\n            this._updateCurrentElement();\n            this.handler.onItemPop(popped, this.stackTop < idx);\n        }\n    }\n    popUntilElementPopped(element) {\n        const idx = this._indexOf(element);\n        this.shortenToLength(idx < 0 ? 0 : idx);\n    }\n    popUntilPopped(tagNames, targetNS) {\n        const idx = this._indexOfTagNames(tagNames, targetNS);\n        this.shortenToLength(idx < 0 ? 0 : idx);\n    }\n    popUntilNumberedHeaderPopped() {\n        this.popUntilPopped(NAMED_HEADERS, NS.HTML);\n    }\n    popUntilTableCellPopped() {\n        this.popUntilPopped(TABLE_CELLS, NS.HTML);\n    }\n    popAllUpToHtmlElement() {\n        //NOTE: here we assume that the root <html> element is always first in the open element stack, so\n        //we perform this fast stack clean up.\n        this.tmplCount = 0;\n        this.shortenToLength(1);\n    }\n    _indexOfTagNames(tagNames, namespace) {\n        for (let i = this.stackTop; i >= 0; i--) {\n            if (tagNames.includes(this.tagIDs[i]) && this.treeAdapter.getNamespaceURI(this.items[i]) === namespace) {\n                return i;\n            }\n        }\n        return -1;\n    }\n    clearBackTo(tagNames, targetNS) {\n        const idx = this._indexOfTagNames(tagNames, targetNS);\n        this.shortenToLength(idx + 1);\n    }\n    clearBackToTableContext() {\n        this.clearBackTo(TABLE_CONTEXT, NS.HTML);\n    }\n    clearBackToTableBodyContext() {\n        this.clearBackTo(TABLE_BODY_CONTEXT, NS.HTML);\n    }\n    clearBackToTableRowContext() {\n        this.clearBackTo(TABLE_ROW_CONTEXT, NS.HTML);\n    }\n    remove(element) {\n        const idx = this._indexOf(element);\n        if (idx >= 0) {\n            if (idx === this.stackTop) {\n                this.pop();\n            }\n            else {\n                this.items.splice(idx, 1);\n                this.tagIDs.splice(idx, 1);\n                this.stackTop--;\n                this._updateCurrentElement();\n                this.handler.onItemPop(element, false);\n            }\n        }\n    }\n    //Search\n    tryPeekProperlyNestedBodyElement() {\n        //Properly nested <body> element (should be second element in stack).\n        return this.stackTop >= 1 && this.tagIDs[1] === TAG_ID.BODY ? this.items[1] : null;\n    }\n    contains(element) {\n        return this._indexOf(element) > -1;\n    }\n    getCommonAncestor(element) {\n        const elementIdx = this._indexOf(element) - 1;\n        return elementIdx >= 0 ? this.items[elementIdx] : null;\n    }\n    isRootHtmlElementCurrent() {\n        return this.stackTop === 0 && this.tagIDs[0] === TAG_ID.HTML;\n    }\n    //Element in scope\n    hasInScope(tagName) {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (tn === tagName && ns === NS.HTML) {\n                return true;\n            }\n            if (SCOPING_ELEMENT_NS.get(tn) === ns) {\n                return false;\n            }\n        }\n        return true;\n    }\n    hasNumberedHeaderInScope() {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (isNumberedHeader(tn) && ns === NS.HTML) {\n                return true;\n            }\n            if (SCOPING_ELEMENT_NS.get(tn) === ns) {\n                return false;\n            }\n        }\n        return true;\n    }\n    hasInListItemScope(tagName) {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (tn === tagName && ns === NS.HTML) {\n                return true;\n            }\n            if (((tn === TAG_ID.UL || tn === TAG_ID.OL) && ns === NS.HTML) || SCOPING_ELEMENT_NS.get(tn) === ns) {\n                return false;\n            }\n        }\n        return true;\n    }\n    hasInButtonScope(tagName) {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (tn === tagName && ns === NS.HTML) {\n                return true;\n            }\n            if ((tn === TAG_ID.BUTTON && ns === NS.HTML) || SCOPING_ELEMENT_NS.get(tn) === ns) {\n                return false;\n            }\n        }\n        return true;\n    }\n    hasInTableScope(tagName) {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (ns !== NS.HTML) {\n                continue;\n            }\n            if (tn === tagName) {\n                return true;\n            }\n            if (tn === TAG_ID.TABLE || tn === TAG_ID.TEMPLATE || tn === TAG_ID.HTML) {\n                return false;\n            }\n        }\n        return true;\n    }\n    hasTableBodyContextInTableScope() {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (ns !== NS.HTML) {\n                continue;\n            }\n            if (tn === TAG_ID.TBODY || tn === TAG_ID.THEAD || tn === TAG_ID.TFOOT) {\n                return true;\n            }\n            if (tn === TAG_ID.TABLE || tn === TAG_ID.HTML) {\n                return false;\n            }\n        }\n        return true;\n    }\n    hasInSelectScope(tagName) {\n        for (let i = this.stackTop; i >= 0; i--) {\n            const tn = this.tagIDs[i];\n            const ns = this.treeAdapter.getNamespaceURI(this.items[i]);\n            if (ns !== NS.HTML) {\n                continue;\n            }\n            if (tn === tagName) {\n                return true;\n            }\n            if (tn !== TAG_ID.OPTION && tn !== TAG_ID.OPTGROUP) {\n                return false;\n            }\n        }\n        return true;\n    }\n    //Implied end tags\n    generateImpliedEndTags() {\n        while (IMPLICIT_END_TAG_REQUIRED.has(this.currentTagId)) {\n            this.pop();\n        }\n    }\n    generateImpliedEndTagsThoroughly() {\n        while (IMPLICIT_END_TAG_REQUIRED_THOROUGHLY.has(this.currentTagId)) {\n            this.pop();\n        }\n    }\n    generateImpliedEndTagsWithExclusion(exclusionId) {\n        while (this.currentTagId !== exclusionId && IMPLICIT_END_TAG_REQUIRED_THOROUGHLY.has(this.currentTagId)) {\n            this.pop();\n        }\n    }\n}\n\n//Const\nconst NOAH_ARK_CAPACITY = 3;\nvar EntryType;\n(function (EntryType) {\n    EntryType[EntryType[\"Marker\"] = 0] = \"Marker\";\n    EntryType[EntryType[\"Element\"] = 1] = \"Element\";\n})(EntryType = EntryType || (EntryType = {}));\nconst MARKER = { type: EntryType.Marker };\n//List of formatting elements\nclass FormattingElementList {\n    constructor(treeAdapter) {\n        this.treeAdapter = treeAdapter;\n        this.entries = [];\n        this.bookmark = null;\n    }\n    //Noah Ark's condition\n    //OPTIMIZATION: at first we try to find possible candidates for exclusion using\n    //lightweight heuristics without thorough attributes check.\n    _getNoahArkConditionCandidates(newElement, neAttrs) {\n        const candidates = [];\n        const neAttrsLength = neAttrs.length;\n        const neTagName = this.treeAdapter.getTagName(newElement);\n        const neNamespaceURI = this.treeAdapter.getNamespaceURI(newElement);\n        for (let i = 0; i < this.entries.length; i++) {\n            const entry = this.entries[i];\n            if (entry.type === EntryType.Marker) {\n                break;\n            }\n            const { element } = entry;\n            if (this.treeAdapter.getTagName(element) === neTagName &&\n                this.treeAdapter.getNamespaceURI(element) === neNamespaceURI) {\n                const elementAttrs = this.treeAdapter.getAttrList(element);\n                if (elementAttrs.length === neAttrsLength) {\n                    candidates.push({ idx: i, attrs: elementAttrs });\n                }\n            }\n        }\n        return candidates;\n    }\n    _ensureNoahArkCondition(newElement) {\n        if (this.entries.length < NOAH_ARK_CAPACITY)\n            return;\n        const neAttrs = this.treeAdapter.getAttrList(newElement);\n        const candidates = this._getNoahArkConditionCandidates(newElement, neAttrs);\n        if (candidates.length < NOAH_ARK_CAPACITY)\n            return;\n        //NOTE: build attrs map for the new element, so we can perform fast lookups\n        const neAttrsMap = new Map(neAttrs.map((neAttr) => [neAttr.name, neAttr.value]));\n        let validCandidates = 0;\n        //NOTE: remove bottommost candidates, until Noah's Ark condition will not be met\n        for (let i = 0; i < candidates.length; i++) {\n            const candidate = candidates[i];\n            // We know that `candidate.attrs.length === neAttrs.length`\n            if (candidate.attrs.every((cAttr) => neAttrsMap.get(cAttr.name) === cAttr.value)) {\n                validCandidates += 1;\n                if (validCandidates >= NOAH_ARK_CAPACITY) {\n                    this.entries.splice(candidate.idx, 1);\n                }\n            }\n        }\n    }\n    //Mutations\n    insertMarker() {\n        this.entries.unshift(MARKER);\n    }\n    pushElement(element, token) {\n        this._ensureNoahArkCondition(element);\n        this.entries.unshift({\n            type: EntryType.Element,\n            element,\n            token,\n        });\n    }\n    insertElementAfterBookmark(element, token) {\n        const bookmarkIdx = this.entries.indexOf(this.bookmark);\n        this.entries.splice(bookmarkIdx, 0, {\n            type: EntryType.Element,\n            element,\n            token,\n        });\n    }\n    removeEntry(entry) {\n        const entryIndex = this.entries.indexOf(entry);\n        if (entryIndex >= 0) {\n            this.entries.splice(entryIndex, 1);\n        }\n    }\n    /**\n     * Clears the list of formatting elements up to the last marker.\n     *\n     * @see https://html.spec.whatwg.org/multipage/parsing.html#clear-the-list-of-active-formatting-elements-up-to-the-last-marker\n     */\n    clearToLastMarker() {\n        const markerIdx = this.entries.indexOf(MARKER);\n        if (markerIdx >= 0) {\n            this.entries.splice(0, markerIdx + 1);\n        }\n        else {\n            this.entries.length = 0;\n        }\n    }\n    //Search\n    getElementEntryInScopeWithTagName(tagName) {\n        const entry = this.entries.find((entry) => entry.type === EntryType.Marker || this.treeAdapter.getTagName(entry.element) === tagName);\n        return entry && entry.type === EntryType.Element ? entry : null;\n    }\n    getElementEntry(element) {\n        return this.entries.find((entry) => entry.type === EntryType.Element && entry.element === element);\n    }\n}\n\nfunction createTextNode(value) {\n    return {\n        nodeName: '#text',\n        value,\n        parentNode: null,\n    };\n}\nconst defaultTreeAdapter = {\n    //Node construction\n    createDocument() {\n        return {\n            nodeName: '#document',\n            mode: DOCUMENT_MODE.NO_QUIRKS,\n            childNodes: [],\n        };\n    },\n    createDocumentFragment() {\n        return {\n            nodeName: '#document-fragment',\n            childNodes: [],\n        };\n    },\n    createElement(tagName, namespaceURI, attrs) {\n        return {\n            nodeName: tagName,\n            tagName,\n            attrs,\n            namespaceURI,\n            childNodes: [],\n            parentNode: null,\n        };\n    },\n    createCommentNode(data) {\n        return {\n            nodeName: '#comment',\n            data,\n            parentNode: null,\n        };\n    },\n    //Tree mutation\n    appendChild(parentNode, newNode) {\n        parentNode.childNodes.push(newNode);\n        newNode.parentNode = parentNode;\n    },\n    insertBefore(parentNode, newNode, referenceNode) {\n        const insertionIdx = parentNode.childNodes.indexOf(referenceNode);\n        parentNode.childNodes.splice(insertionIdx, 0, newNode);\n        newNode.parentNode = parentNode;\n    },\n    setTemplateContent(templateElement, contentElement) {\n        templateElement.content = contentElement;\n    },\n    getTemplateContent(templateElement) {\n        return templateElement.content;\n    },\n    setDocumentType(document, name, publicId, systemId) {\n        const doctypeNode = document.childNodes.find((node) => node.nodeName === '#documentType');\n        if (doctypeNode) {\n            doctypeNode.name = name;\n            doctypeNode.publicId = publicId;\n            doctypeNode.systemId = systemId;\n        }\n        else {\n            const node = {\n                nodeName: '#documentType',\n                name,\n                publicId,\n                systemId,\n                parentNode: null,\n            };\n            defaultTreeAdapter.appendChild(document, node);\n        }\n    },\n    setDocumentMode(document, mode) {\n        document.mode = mode;\n    },\n    getDocumentMode(document) {\n        return document.mode;\n    },\n    detachNode(node) {\n        if (node.parentNode) {\n            const idx = node.parentNode.childNodes.indexOf(node);\n            node.parentNode.childNodes.splice(idx, 1);\n            node.parentNode = null;\n        }\n    },\n    insertText(parentNode, text) {\n        if (parentNode.childNodes.length > 0) {\n            const prevNode = parentNode.childNodes[parentNode.childNodes.length - 1];\n            if (defaultTreeAdapter.isTextNode(prevNode)) {\n                prevNode.value += text;\n                return;\n            }\n        }\n        defaultTreeAdapter.appendChild(parentNode, createTextNode(text));\n    },\n    insertTextBefore(parentNode, text, referenceNode) {\n        const prevNode = parentNode.childNodes[parentNode.childNodes.indexOf(referenceNode) - 1];\n        if (prevNode && defaultTreeAdapter.isTextNode(prevNode)) {\n            prevNode.value += text;\n        }\n        else {\n            defaultTreeAdapter.insertBefore(parentNode, createTextNode(text), referenceNode);\n        }\n    },\n    adoptAttributes(recipient, attrs) {\n        const recipientAttrsMap = new Set(recipient.attrs.map((attr) => attr.name));\n        for (let j = 0; j < attrs.length; j++) {\n            if (!recipientAttrsMap.has(attrs[j].name)) {\n                recipient.attrs.push(attrs[j]);\n            }\n        }\n    },\n    //Tree traversing\n    getFirstChild(node) {\n        return node.childNodes[0];\n    },\n    getChildNodes(node) {\n        return node.childNodes;\n    },\n    getParentNode(node) {\n        return node.parentNode;\n    },\n    getAttrList(element) {\n        return element.attrs;\n    },\n    //Node data\n    getTagName(element) {\n        return element.tagName;\n    },\n    getNamespaceURI(element) {\n        return element.namespaceURI;\n    },\n    getTextNodeContent(textNode) {\n        return textNode.value;\n    },\n    getCommentNodeContent(commentNode) {\n        return commentNode.data;\n    },\n    getDocumentTypeNodeName(doctypeNode) {\n        return doctypeNode.name;\n    },\n    getDocumentTypeNodePublicId(doctypeNode) {\n        return doctypeNode.publicId;\n    },\n    getDocumentTypeNodeSystemId(doctypeNode) {\n        return doctypeNode.systemId;\n    },\n    //Node types\n    isTextNode(node) {\n        return node.nodeName === '#text';\n    },\n    isCommentNode(node) {\n        return node.nodeName === '#comment';\n    },\n    isDocumentTypeNode(node) {\n        return node.nodeName === '#documentType';\n    },\n    isElementNode(node) {\n        return Object.prototype.hasOwnProperty.call(node, 'tagName');\n    },\n    // Source code location\n    setNodeSourceCodeLocation(node, location) {\n        node.sourceCodeLocation = location;\n    },\n    getNodeSourceCodeLocation(node) {\n        return node.sourceCodeLocation;\n    },\n    updateNodeSourceCodeLocation(node, endLocation) {\n        node.sourceCodeLocation = { ...node.sourceCodeLocation, ...endLocation };\n    },\n};\n\n//Const\nconst VALID_DOCTYPE_NAME = 'html';\nconst VALID_SYSTEM_ID = 'about:legacy-compat';\nconst QUIRKS_MODE_SYSTEM_ID = 'http://www.ibm.com/data/dtd/v11/ibmxhtml1-transitional.dtd';\nconst QUIRKS_MODE_PUBLIC_ID_PREFIXES = [\n    '+//silmaril//dtd html pro v0r11 19970101//',\n    '-//as//dtd html 3.0 aswedit + extensions//',\n    '-//advasoft ltd//dtd html 3.0 aswedit + extensions//',\n    '-//ietf//dtd html 2.0 level 1//',\n    '-//ietf//dtd html 2.0 level 2//',\n    '-//ietf//dtd html 2.0 strict level 1//',\n    '-//ietf//dtd html 2.0 strict level 2//',\n    '-//ietf//dtd html 2.0 strict//',\n    '-//ietf//dtd html 2.0//',\n    '-//ietf//dtd html 2.1e//',\n    '-//ietf//dtd html 3.0//',\n    '-//ietf//dtd html 3.2 final//',\n    '-//ietf//dtd html 3.2//',\n    '-//ietf//dtd html 3//',\n    '-//ietf//dtd html level 0//',\n    '-//ietf//dtd html level 1//',\n    '-//ietf//dtd html level 2//',\n    '-//ietf//dtd html level 3//',\n    '-//ietf//dtd html strict level 0//',\n    '-//ietf//dtd html strict level 1//',\n    '-//ietf//dtd html strict level 2//',\n    '-//ietf//dtd html strict level 3//',\n    '-//ietf//dtd html strict//',\n    '-//ietf//dtd html//',\n    '-//metrius//dtd metrius presentational//',\n    '-//microsoft//dtd internet explorer 2.0 html strict//',\n    '-//microsoft//dtd internet explorer 2.0 html//',\n    '-//microsoft//dtd internet explorer 2.0 tables//',\n    '-//microsoft//dtd internet explorer 3.0 html strict//',\n    '-//microsoft//dtd internet explorer 3.0 html//',\n    '-//microsoft//dtd internet explorer 3.0 tables//',\n    '-//netscape comm. corp.//dtd html//',\n    '-//netscape comm. corp.//dtd strict html//',\n    \"-//o'reilly and associates//dtd html 2.0//\",\n    \"-//o'reilly and associates//dtd html extended 1.0//\",\n    \"-//o'reilly and associates//dtd html extended relaxed 1.0//\",\n    '-//sq//dtd html 2.0 hotmetal + extensions//',\n    '-//softquad software//dtd hotmetal pro 6.0::19990601::extensions to html 4.0//',\n    '-//softquad//dtd hotmetal pro 4.0::19971010::extensions to html 4.0//',\n    '-//spyglass//dtd html 2.0 extended//',\n    '-//sun microsystems corp.//dtd hotjava html//',\n    '-//sun microsystems corp.//dtd hotjava strict html//',\n    '-//w3c//dtd html 3 1995-03-24//',\n    '-//w3c//dtd html 3.2 draft//',\n    '-//w3c//dtd html 3.2 final//',\n    '-//w3c//dtd html 3.2//',\n    '-//w3c//dtd html 3.2s draft//',\n    '-//w3c//dtd html 4.0 frameset//',\n    '-//w3c//dtd html 4.0 transitional//',\n    '-//w3c//dtd html experimental 19960712//',\n    '-//w3c//dtd html experimental 970421//',\n    '-//w3c//dtd w3 html//',\n    '-//w3o//dtd w3 html 3.0//',\n    '-//webtechs//dtd mozilla html 2.0//',\n    '-//webtechs//dtd mozilla html//',\n];\nconst QUIRKS_MODE_NO_SYSTEM_ID_PUBLIC_ID_PREFIXES = [\n    ...QUIRKS_MODE_PUBLIC_ID_PREFIXES,\n    '-//w3c//dtd html 4.01 frameset//',\n    '-//w3c//dtd html 4.01 transitional//',\n];\nconst QUIRKS_MODE_PUBLIC_IDS = new Set([\n    '-//w3o//dtd w3 html strict 3.0//en//',\n    '-/w3c/dtd html 4.0 transitional/en',\n    'html',\n]);\nconst LIMITED_QUIRKS_PUBLIC_ID_PREFIXES = ['-//w3c//dtd xhtml 1.0 frameset//', '-//w3c//dtd xhtml 1.0 transitional//'];\nconst LIMITED_QUIRKS_WITH_SYSTEM_ID_PUBLIC_ID_PREFIXES = [\n    ...LIMITED_QUIRKS_PUBLIC_ID_PREFIXES,\n    '-//w3c//dtd html 4.01 frameset//',\n    '-//w3c//dtd html 4.01 transitional//',\n];\n//Utils\nfunction hasPrefix(publicId, prefixes) {\n    return prefixes.some((prefix) => publicId.startsWith(prefix));\n}\n//API\nfunction isConforming(token) {\n    return (token.name === VALID_DOCTYPE_NAME &&\n        token.publicId === null &&\n        (token.systemId === null || token.systemId === VALID_SYSTEM_ID));\n}\nfunction getDocumentMode(token) {\n    if (token.name !== VALID_DOCTYPE_NAME) {\n        return DOCUMENT_MODE.QUIRKS;\n    }\n    const { systemId } = token;\n    if (systemId && systemId.toLowerCase() === QUIRKS_MODE_SYSTEM_ID) {\n        return DOCUMENT_MODE.QUIRKS;\n    }\n    let { publicId } = token;\n    if (publicId !== null) {\n        publicId = publicId.toLowerCase();\n        if (QUIRKS_MODE_PUBLIC_IDS.has(publicId)) {\n            return DOCUMENT_MODE.QUIRKS;\n        }\n        let prefixes = systemId === null ? QUIRKS_MODE_NO_SYSTEM_ID_PUBLIC_ID_PREFIXES : QUIRKS_MODE_PUBLIC_ID_PREFIXES;\n        if (hasPrefix(publicId, prefixes)) {\n            return DOCUMENT_MODE.QUIRKS;\n        }\n        prefixes =\n            systemId === null ? LIMITED_QUIRKS_PUBLIC_ID_PREFIXES : LIMITED_QUIRKS_WITH_SYSTEM_ID_PUBLIC_ID_PREFIXES;\n        if (hasPrefix(publicId, prefixes)) {\n            return DOCUMENT_MODE.LIMITED_QUIRKS;\n        }\n    }\n    return DOCUMENT_MODE.NO_QUIRKS;\n}\n\n//MIME types\nconst MIME_TYPES = {\n    TEXT_HTML: 'text/html',\n    APPLICATION_XML: 'application/xhtml+xml',\n};\n//Attributes\nconst DEFINITION_URL_ATTR = 'definitionurl';\nconst ADJUSTED_DEFINITION_URL_ATTR = 'definitionURL';\nconst SVG_ATTRS_ADJUSTMENT_MAP = new Map([\n    'attributeName',\n    'attributeType',\n    'baseFrequency',\n    'baseProfile',\n    'calcMode',\n    'clipPathUnits',\n    'diffuseConstant',\n    'edgeMode',\n    'filterUnits',\n    'glyphRef',\n    'gradientTransform',\n    'gradientUnits',\n    'kernelMatrix',\n    'kernelUnitLength',\n    'keyPoints',\n    'keySplines',\n    'keyTimes',\n    'lengthAdjust',\n    'limitingConeAngle',\n    'markerHeight',\n    'markerUnits',\n    'markerWidth',\n    'maskContentUnits',\n    'maskUnits',\n    'numOctaves',\n    'pathLength',\n    'patternContentUnits',\n    'patternTransform',\n    'patternUnits',\n    'pointsAtX',\n    'pointsAtY',\n    'pointsAtZ',\n    'preserveAlpha',\n    'preserveAspectRatio',\n    'primitiveUnits',\n    'refX',\n    'refY',\n    'repeatCount',\n    'repeatDur',\n    'requiredExtensions',\n    'requiredFeatures',\n    'specularConstant',\n    'specularExponent',\n    'spreadMethod',\n    'startOffset',\n    'stdDeviation',\n    'stitchTiles',\n    'surfaceScale',\n    'systemLanguage',\n    'tableValues',\n    'targetX',\n    'targetY',\n    'textLength',\n    'viewBox',\n    'viewTarget',\n    'xChannelSelector',\n    'yChannelSelector',\n    'zoomAndPan',\n].map((attr) => [attr.toLowerCase(), attr]));\nconst XML_ATTRS_ADJUSTMENT_MAP = new Map([\n    ['xlink:actuate', { prefix: 'xlink', name: 'actuate', namespace: NS.XLINK }],\n    ['xlink:arcrole', { prefix: 'xlink', name: 'arcrole', namespace: NS.XLINK }],\n    ['xlink:href', { prefix: 'xlink', name: 'href', namespace: NS.XLINK }],\n    ['xlink:role', { prefix: 'xlink', name: 'role', namespace: NS.XLINK }],\n    ['xlink:show', { prefix: 'xlink', name: 'show', namespace: NS.XLINK }],\n    ['xlink:title', { prefix: 'xlink', name: 'title', namespace: NS.XLINK }],\n    ['xlink:type', { prefix: 'xlink', name: 'type', namespace: NS.XLINK }],\n    ['xml:base', { prefix: 'xml', name: 'base', namespace: NS.XML }],\n    ['xml:lang', { prefix: 'xml', name: 'lang', namespace: NS.XML }],\n    ['xml:space', { prefix: 'xml', name: 'space', namespace: NS.XML }],\n    ['xmlns', { prefix: '', name: 'xmlns', namespace: NS.XMLNS }],\n    ['xmlns:xlink', { prefix: 'xmlns', name: 'xlink', namespace: NS.XMLNS }],\n]);\n//SVG tag names adjustment map\nconst SVG_TAG_NAMES_ADJUSTMENT_MAP = new Map([\n    'altGlyph',\n    'altGlyphDef',\n    'altGlyphItem',\n    'animateColor',\n    'animateMotion',\n    'animateTransform',\n    'clipPath',\n    'feBlend',\n    'feColorMatrix',\n    'feComponentTransfer',\n    'feComposite',\n    'feConvolveMatrix',\n    'feDiffuseLighting',\n    'feDisplacementMap',\n    'feDistantLight',\n    'feFlood',\n    'feFuncA',\n    'feFuncB',\n    'feFuncG',\n    'feFuncR',\n    'feGaussianBlur',\n    'feImage',\n    'feMerge',\n    'feMergeNode',\n    'feMorphology',\n    'feOffset',\n    'fePointLight',\n    'feSpecularLighting',\n    'feSpotLight',\n    'feTile',\n    'feTurbulence',\n    'foreignObject',\n    'glyphRef',\n    'linearGradient',\n    'radialGradient',\n    'textPath',\n].map((tn) => [tn.toLowerCase(), tn]));\n//Tags that causes exit from foreign content\nconst EXITS_FOREIGN_CONTENT = new Set([\n    TAG_ID.B,\n    TAG_ID.BIG,\n    TAG_ID.BLOCKQUOTE,\n    TAG_ID.BODY,\n    TAG_ID.BR,\n    TAG_ID.CENTER,\n    TAG_ID.CODE,\n    TAG_ID.DD,\n    TAG_ID.DIV,\n    TAG_ID.DL,\n    TAG_ID.DT,\n    TAG_ID.EM,\n    TAG_ID.EMBED,\n    TAG_ID.H1,\n    TAG_ID.H2,\n    TAG_ID.H3,\n    TAG_ID.H4,\n    TAG_ID.H5,\n    TAG_ID.H6,\n    TAG_ID.HEAD,\n    TAG_ID.HR,\n    TAG_ID.I,\n    TAG_ID.IMG,\n    TAG_ID.LI,\n    TAG_ID.LISTING,\n    TAG_ID.MENU,\n    TAG_ID.META,\n    TAG_ID.NOBR,\n    TAG_ID.OL,\n    TAG_ID.P,\n    TAG_ID.PRE,\n    TAG_ID.RUBY,\n    TAG_ID.S,\n    TAG_ID.SMALL,\n    TAG_ID.SPAN,\n    TAG_ID.STRONG,\n    TAG_ID.STRIKE,\n    TAG_ID.SUB,\n    TAG_ID.SUP,\n    TAG_ID.TABLE,\n    TAG_ID.TT,\n    TAG_ID.U,\n    TAG_ID.UL,\n    TAG_ID.VAR,\n]);\n//Check exit from foreign content\nfunction causesExit(startTagToken) {\n    const tn = startTagToken.tagID;\n    const isFontWithAttrs = tn === TAG_ID.FONT &&\n        startTagToken.attrs.some(({ name }) => name === ATTRS.COLOR || name === ATTRS.SIZE || name === ATTRS.FACE);\n    return isFontWithAttrs || EXITS_FOREIGN_CONTENT.has(tn);\n}\n//Token adjustments\nfunction adjustTokenMathMLAttrs(token) {\n    for (let i = 0; i < token.attrs.length; i++) {\n        if (token.attrs[i].name === DEFINITION_URL_ATTR) {\n            token.attrs[i].name = ADJUSTED_DEFINITION_URL_ATTR;\n            break;\n        }\n    }\n}\nfunction adjustTokenSVGAttrs(token) {\n    for (let i = 0; i < token.attrs.length; i++) {\n        const adjustedAttrName = SVG_ATTRS_ADJUSTMENT_MAP.get(token.attrs[i].name);\n        if (adjustedAttrName != null) {\n            token.attrs[i].name = adjustedAttrName;\n        }\n    }\n}\nfunction adjustTokenXMLAttrs(token) {\n    for (let i = 0; i < token.attrs.length; i++) {\n        const adjustedAttrEntry = XML_ATTRS_ADJUSTMENT_MAP.get(token.attrs[i].name);\n        if (adjustedAttrEntry) {\n            token.attrs[i].prefix = adjustedAttrEntry.prefix;\n            token.attrs[i].name = adjustedAttrEntry.name;\n            token.attrs[i].namespace = adjustedAttrEntry.namespace;\n        }\n    }\n}\nfunction adjustTokenSVGTagName(token) {\n    const adjustedTagName = SVG_TAG_NAMES_ADJUSTMENT_MAP.get(token.tagName);\n    if (adjustedTagName != null) {\n        token.tagName = adjustedTagName;\n        token.tagID = getTagID(token.tagName);\n    }\n}\n//Integration points\nfunction isMathMLTextIntegrationPoint(tn, ns) {\n    return ns === NS.MATHML && (tn === TAG_ID.MI || tn === TAG_ID.MO || tn === TAG_ID.MN || tn === TAG_ID.MS || tn === TAG_ID.MTEXT);\n}\nfunction isHtmlIntegrationPoint(tn, ns, attrs) {\n    if (ns === NS.MATHML && tn === TAG_ID.ANNOTATION_XML) {\n        for (let i = 0; i < attrs.length; i++) {\n            if (attrs[i].name === ATTRS.ENCODING) {\n                const value = attrs[i].value.toLowerCase();\n                return value === MIME_TYPES.TEXT_HTML || value === MIME_TYPES.APPLICATION_XML;\n            }\n        }\n    }\n    return ns === NS.SVG && (tn === TAG_ID.FOREIGN_OBJECT || tn === TAG_ID.DESC || tn === TAG_ID.TITLE);\n}\nfunction isIntegrationPoint(tn, ns, attrs, foreignNS) {\n    return (((!foreignNS || foreignNS === NS.HTML) && isHtmlIntegrationPoint(tn, ns, attrs)) ||\n        ((!foreignNS || foreignNS === NS.MATHML) && isMathMLTextIntegrationPoint(tn, ns)));\n}\n\nvar foreignContent = {\n    __proto__: null,\n    SVG_TAG_NAMES_ADJUSTMENT_MAP: SVG_TAG_NAMES_ADJUSTMENT_MAP,\n    adjustTokenMathMLAttrs: adjustTokenMathMLAttrs,\n    adjustTokenSVGAttrs: adjustTokenSVGAttrs,\n    adjustTokenSVGTagName: adjustTokenSVGTagName,\n    adjustTokenXMLAttrs: adjustTokenXMLAttrs,\n    causesExit: causesExit,\n    isIntegrationPoint: isIntegrationPoint\n};\n\n//Misc constants\nconst HIDDEN_INPUT_TYPE = 'hidden';\n//Adoption agency loops iteration count\nconst AA_OUTER_LOOP_ITER = 8;\nconst AA_INNER_LOOP_ITER = 3;\n//Insertion modes\nvar InsertionMode;\n(function (InsertionMode) {\n    InsertionMode[InsertionMode[\"INITIAL\"] = 0] = \"INITIAL\";\n    InsertionMode[InsertionMode[\"BEFORE_HTML\"] = 1] = \"BEFORE_HTML\";\n    InsertionMode[InsertionMode[\"BEFORE_HEAD\"] = 2] = \"BEFORE_HEAD\";\n    InsertionMode[InsertionMode[\"IN_HEAD\"] = 3] = \"IN_HEAD\";\n    InsertionMode[InsertionMode[\"IN_HEAD_NO_SCRIPT\"] = 4] = \"IN_HEAD_NO_SCRIPT\";\n    InsertionMode[InsertionMode[\"AFTER_HEAD\"] = 5] = \"AFTER_HEAD\";\n    InsertionMode[InsertionMode[\"IN_BODY\"] = 6] = \"IN_BODY\";\n    InsertionMode[InsertionMode[\"TEXT\"] = 7] = \"TEXT\";\n    InsertionMode[InsertionMode[\"IN_TABLE\"] = 8] = \"IN_TABLE\";\n    InsertionMode[InsertionMode[\"IN_TABLE_TEXT\"] = 9] = \"IN_TABLE_TEXT\";\n    InsertionMode[InsertionMode[\"IN_CAPTION\"] = 10] = \"IN_CAPTION\";\n    InsertionMode[InsertionMode[\"IN_COLUMN_GROUP\"] = 11] = \"IN_COLUMN_GROUP\";\n    InsertionMode[InsertionMode[\"IN_TABLE_BODY\"] = 12] = \"IN_TABLE_BODY\";\n    InsertionMode[InsertionMode[\"IN_ROW\"] = 13] = \"IN_ROW\";\n    InsertionMode[InsertionMode[\"IN_CELL\"] = 14] = \"IN_CELL\";\n    InsertionMode[InsertionMode[\"IN_SELECT\"] = 15] = \"IN_SELECT\";\n    InsertionMode[InsertionMode[\"IN_SELECT_IN_TABLE\"] = 16] = \"IN_SELECT_IN_TABLE\";\n    InsertionMode[InsertionMode[\"IN_TEMPLATE\"] = 17] = \"IN_TEMPLATE\";\n    InsertionMode[InsertionMode[\"AFTER_BODY\"] = 18] = \"AFTER_BODY\";\n    InsertionMode[InsertionMode[\"IN_FRAMESET\"] = 19] = \"IN_FRAMESET\";\n    InsertionMode[InsertionMode[\"AFTER_FRAMESET\"] = 20] = \"AFTER_FRAMESET\";\n    InsertionMode[InsertionMode[\"AFTER_AFTER_BODY\"] = 21] = \"AFTER_AFTER_BODY\";\n    InsertionMode[InsertionMode[\"AFTER_AFTER_FRAMESET\"] = 22] = \"AFTER_AFTER_FRAMESET\";\n})(InsertionMode || (InsertionMode = {}));\nconst BASE_LOC = {\n    startLine: -1,\n    startCol: -1,\n    startOffset: -1,\n    endLine: -1,\n    endCol: -1,\n    endOffset: -1,\n};\nconst TABLE_STRUCTURE_TAGS = new Set([TAG_ID.TABLE, TAG_ID.TBODY, TAG_ID.TFOOT, TAG_ID.THEAD, TAG_ID.TR]);\nconst defaultParserOptions = {\n    scriptingEnabled: true,\n    sourceCodeLocationInfo: false,\n    treeAdapter: defaultTreeAdapter,\n    onParseError: null,\n};\n//Parser\nclass Parser {\n    constructor(options, document, fragmentContext = null, scriptHandler = null) {\n        this.fragmentContext = fragmentContext;\n        this.scriptHandler = scriptHandler;\n        this.currentToken = null;\n        this.stopped = false;\n        this.insertionMode = InsertionMode.INITIAL;\n        this.originalInsertionMode = InsertionMode.INITIAL;\n        this.headElement = null;\n        this.formElement = null;\n        /** Indicates that the current node is not an element in the HTML namespace */\n        this.currentNotInHTML = false;\n        /**\n         * The template insertion mode stack is maintained from the left.\n         * Ie. the topmost element will always have index 0.\n         */\n        this.tmplInsertionModeStack = [];\n        this.pendingCharacterTokens = [];\n        this.hasNonWhitespacePendingCharacterToken = false;\n        this.framesetOk = true;\n        this.skipNextNewLine = false;\n        this.fosterParentingEnabled = false;\n        this.options = {\n            ...defaultParserOptions,\n            ...options,\n        };\n        this.treeAdapter = this.options.treeAdapter;\n        this.onParseError = this.options.onParseError;\n        // Always enable location info if we report parse errors.\n        if (this.onParseError) {\n            this.options.sourceCodeLocationInfo = true;\n        }\n        this.document = document !== null && document !== void 0 ? document : this.treeAdapter.createDocument();\n        this.tokenizer = new Tokenizer(this.options, this);\n        this.activeFormattingElements = new FormattingElementList(this.treeAdapter);\n        this.fragmentContextID = fragmentContext ? getTagID(this.treeAdapter.getTagName(fragmentContext)) : TAG_ID.UNKNOWN;\n        this._setContextModes(fragmentContext !== null && fragmentContext !== void 0 ? fragmentContext : this.document, this.fragmentContextID);\n        this.openElements = new OpenElementStack(this.document, this.treeAdapter, this);\n    }\n    // API\n    static parse(html, options) {\n        const parser = new this(options);\n        parser.tokenizer.write(html, true);\n        return parser.document;\n    }\n    static getFragmentParser(fragmentContext, options) {\n        const opts = {\n            ...defaultParserOptions,\n            ...options,\n        };\n        //NOTE: use a <template> element as the fragment context if no context element was provided,\n        //so we will parse in a \"forgiving\" manner\n        fragmentContext !== null && fragmentContext !== void 0 ? fragmentContext : (fragmentContext = opts.treeAdapter.createElement(TAG_NAMES.TEMPLATE, NS.HTML, []));\n        //NOTE: create a fake element which will be used as the `document` for fragment parsing.\n        //This is important for jsdom, where a new `document` cannot be created. This led to\n        //fragment parsing messing with the main `document`.\n        const documentMock = opts.treeAdapter.createElement('documentmock', NS.HTML, []);\n        const parser = new this(opts, documentMock, fragmentContext);\n        if (parser.fragmentContextID === TAG_ID.TEMPLATE) {\n            parser.tmplInsertionModeStack.unshift(InsertionMode.IN_TEMPLATE);\n        }\n        parser._initTokenizerForFragmentParsing();\n        parser._insertFakeRootElement();\n        parser._resetInsertionMode();\n        parser._findFormInFragmentContext();\n        return parser;\n    }\n    getFragment() {\n        const rootElement = this.treeAdapter.getFirstChild(this.document);\n        const fragment = this.treeAdapter.createDocumentFragment();\n        this._adoptNodes(rootElement, fragment);\n        return fragment;\n    }\n    //Errors\n    _err(token, code, beforeToken) {\n        var _a;\n        if (!this.onParseError)\n            return;\n        const loc = (_a = token.location) !== null && _a !== void 0 ? _a : BASE_LOC;\n        const err = {\n            code,\n            startLine: loc.startLine,\n            startCol: loc.startCol,\n            startOffset: loc.startOffset,\n            endLine: beforeToken ? loc.startLine : loc.endLine,\n            endCol: beforeToken ? loc.startCol : loc.endCol,\n            endOffset: beforeToken ? loc.startOffset : loc.endOffset,\n        };\n        this.onParseError(err);\n    }\n    //Stack events\n    onItemPush(node, tid, isTop) {\n        var _a, _b;\n        (_b = (_a = this.treeAdapter).onItemPush) === null || _b === void 0 ? void 0 : _b.call(_a, node);\n        if (isTop && this.openElements.stackTop > 0)\n            this._setContextModes(node, tid);\n    }\n    onItemPop(node, isTop) {\n        var _a, _b;\n        if (this.options.sourceCodeLocationInfo) {\n            this._setEndLocation(node, this.currentToken);\n        }\n        (_b = (_a = this.treeAdapter).onItemPop) === null || _b === void 0 ? void 0 : _b.call(_a, node, this.openElements.current);\n        if (isTop) {\n            let current;\n            let currentTagId;\n            if (this.openElements.stackTop === 0 && this.fragmentContext) {\n                current = this.fragmentContext;\n                currentTagId = this.fragmentContextID;\n            }\n            else {\n                ({ current, currentTagId } = this.openElements);\n            }\n            this._setContextModes(current, currentTagId);\n        }\n    }\n    _setContextModes(current, tid) {\n        const isHTML = current === this.document || this.treeAdapter.getNamespaceURI(current) === NS.HTML;\n        this.currentNotInHTML = !isHTML;\n        this.tokenizer.inForeignNode = !isHTML && !this._isIntegrationPoint(tid, current);\n    }\n    _switchToTextParsing(currentToken, nextTokenizerState) {\n        this._insertElement(currentToken, NS.HTML);\n        this.tokenizer.state = nextTokenizerState;\n        this.originalInsertionMode = this.insertionMode;\n        this.insertionMode = InsertionMode.TEXT;\n    }\n    switchToPlaintextParsing() {\n        this.insertionMode = InsertionMode.TEXT;\n        this.originalInsertionMode = InsertionMode.IN_BODY;\n        this.tokenizer.state = TokenizerMode.PLAINTEXT;\n    }\n    //Fragment parsing\n    _getAdjustedCurrentElement() {\n        return this.openElements.stackTop === 0 && this.fragmentContext\n            ? this.fragmentContext\n            : this.openElements.current;\n    }\n    _findFormInFragmentContext() {\n        let node = this.fragmentContext;\n        while (node) {\n            if (this.treeAdapter.getTagName(node) === TAG_NAMES.FORM) {\n                this.formElement = node;\n                break;\n            }\n            node = this.treeAdapter.getParentNode(node);\n        }\n    }\n    _initTokenizerForFragmentParsing() {\n        if (!this.fragmentContext || this.treeAdapter.getNamespaceURI(this.fragmentContext) !== NS.HTML) {\n            return;\n        }\n        switch (this.fragmentContextID) {\n            case TAG_ID.TITLE:\n            case TAG_ID.TEXTAREA: {\n                this.tokenizer.state = TokenizerMode.RCDATA;\n                break;\n            }\n            case TAG_ID.STYLE:\n            case TAG_ID.XMP:\n            case TAG_ID.IFRAME:\n            case TAG_ID.NOEMBED:\n            case TAG_ID.NOFRAMES:\n            case TAG_ID.NOSCRIPT: {\n                this.tokenizer.state = TokenizerMode.RAWTEXT;\n                break;\n            }\n            case TAG_ID.SCRIPT: {\n                this.tokenizer.state = TokenizerMode.SCRIPT_DATA;\n                break;\n            }\n            case TAG_ID.PLAINTEXT: {\n                this.tokenizer.state = TokenizerMode.PLAINTEXT;\n                break;\n            }\n            // Do nothing\n        }\n    }\n    //Tree mutation\n    _setDocumentType(token) {\n        const name = token.name || '';\n        const publicId = token.publicId || '';\n        const systemId = token.systemId || '';\n        this.treeAdapter.setDocumentType(this.document, name, publicId, systemId);\n        if (token.location) {\n            const documentChildren = this.treeAdapter.getChildNodes(this.document);\n            const docTypeNode = documentChildren.find((node) => this.treeAdapter.isDocumentTypeNode(node));\n            if (docTypeNode) {\n                this.treeAdapter.setNodeSourceCodeLocation(docTypeNode, token.location);\n            }\n        }\n    }\n    _attachElementToTree(element, location) {\n        if (this.options.sourceCodeLocationInfo) {\n            const loc = location && {\n                ...location,\n                startTag: location,\n            };\n            this.treeAdapter.setNodeSourceCodeLocation(element, loc);\n        }\n        if (this._shouldFosterParentOnInsertion()) {\n            this._fosterParentElement(element);\n        }\n        else {\n            const parent = this.openElements.currentTmplContentOrNode;\n            this.treeAdapter.appendChild(parent, element);\n        }\n    }\n    _appendElement(token, namespaceURI) {\n        const element = this.treeAdapter.createElement(token.tagName, namespaceURI, token.attrs);\n        this._attachElementToTree(element, token.location);\n    }\n    _insertElement(token, namespaceURI) {\n        const element = this.treeAdapter.createElement(token.tagName, namespaceURI, token.attrs);\n        this._attachElementToTree(element, token.location);\n        this.openElements.push(element, token.tagID);\n    }\n    _insertFakeElement(tagName, tagID) {\n        const element = this.treeAdapter.createElement(tagName, NS.HTML, []);\n        this._attachElementToTree(element, null);\n        this.openElements.push(element, tagID);\n    }\n    _insertTemplate(token) {\n        const tmpl = this.treeAdapter.createElement(token.tagName, NS.HTML, token.attrs);\n        const content = this.treeAdapter.createDocumentFragment();\n        this.treeAdapter.setTemplateContent(tmpl, content);\n        this._attachElementToTree(tmpl, token.location);\n        this.openElements.push(tmpl, token.tagID);\n        if (this.options.sourceCodeLocationInfo)\n            this.treeAdapter.setNodeSourceCodeLocation(content, null);\n    }\n    _insertFakeRootElement() {\n        const element = this.treeAdapter.createElement(TAG_NAMES.HTML, NS.HTML, []);\n        if (this.options.sourceCodeLocationInfo)\n            this.treeAdapter.setNodeSourceCodeLocation(element, null);\n        this.treeAdapter.appendChild(this.openElements.current, element);\n        this.openElements.push(element, TAG_ID.HTML);\n    }\n    _appendCommentNode(token, parent) {\n        const commentNode = this.treeAdapter.createCommentNode(token.data);\n        this.treeAdapter.appendChild(parent, commentNode);\n        if (this.options.sourceCodeLocationInfo) {\n            this.treeAdapter.setNodeSourceCodeLocation(commentNode, token.location);\n        }\n    }\n    _insertCharacters(token) {\n        let parent;\n        let beforeElement;\n        if (this._shouldFosterParentOnInsertion()) {\n            ({ parent, beforeElement } = this._findFosterParentingLocation());\n            if (beforeElement) {\n                this.treeAdapter.insertTextBefore(parent, token.chars, beforeElement);\n            }\n            else {\n                this.treeAdapter.insertText(parent, token.chars);\n            }\n        }\n        else {\n            parent = this.openElements.currentTmplContentOrNode;\n            this.treeAdapter.insertText(parent, token.chars);\n        }\n        if (!token.location)\n            return;\n        const siblings = this.treeAdapter.getChildNodes(parent);\n        const textNodeIdx = beforeElement ? siblings.lastIndexOf(beforeElement) : siblings.length;\n        const textNode = siblings[textNodeIdx - 1];\n        //NOTE: if we have a location assigned by another token, then just update the end position\n        const tnLoc = this.treeAdapter.getNodeSourceCodeLocation(textNode);\n        if (tnLoc) {\n            const { endLine, endCol, endOffset } = token.location;\n            this.treeAdapter.updateNodeSourceCodeLocation(textNode, { endLine, endCol, endOffset });\n        }\n        else if (this.options.sourceCodeLocationInfo) {\n            this.treeAdapter.setNodeSourceCodeLocation(textNode, token.location);\n        }\n    }\n    _adoptNodes(donor, recipient) {\n        for (let child = this.treeAdapter.getFirstChild(donor); child; child = this.treeAdapter.getFirstChild(donor)) {\n            this.treeAdapter.detachNode(child);\n            this.treeAdapter.appendChild(recipient, child);\n        }\n    }\n    _setEndLocation(element, closingToken) {\n        if (this.treeAdapter.getNodeSourceCodeLocation(element) && closingToken.location) {\n            const ctLoc = closingToken.location;\n            const tn = this.treeAdapter.getTagName(element);\n            const endLoc = \n            // NOTE: For cases like <p> <p> </p> - First 'p' closes without a closing\n            // tag and for cases like <td> <p> </td> - 'p' closes without a closing tag.\n            closingToken.type === TokenType.END_TAG && tn === closingToken.tagName\n                ? {\n                    endTag: { ...ctLoc },\n                    endLine: ctLoc.endLine,\n                    endCol: ctLoc.endCol,\n                    endOffset: ctLoc.endOffset,\n                }\n                : {\n                    endLine: ctLoc.startLine,\n                    endCol: ctLoc.startCol,\n                    endOffset: ctLoc.startOffset,\n                };\n            this.treeAdapter.updateNodeSourceCodeLocation(element, endLoc);\n        }\n    }\n    //Token processing\n    shouldProcessStartTagTokenInForeignContent(token) {\n        // Check that neither current === document, or ns === NS.HTML\n        if (!this.currentNotInHTML)\n            return false;\n        let current;\n        let currentTagId;\n        if (this.openElements.stackTop === 0 && this.fragmentContext) {\n            current = this.fragmentContext;\n            currentTagId = this.fragmentContextID;\n        }\n        else {\n            ({ current, currentTagId } = this.openElements);\n        }\n        if (token.tagID === TAG_ID.SVG &&\n            this.treeAdapter.getTagName(current) === TAG_NAMES.ANNOTATION_XML &&\n            this.treeAdapter.getNamespaceURI(current) === NS.MATHML) {\n            return false;\n        }\n        return (\n        // Check that `current` is not an integration point for HTML or MathML elements.\n        this.tokenizer.inForeignNode ||\n            // If it _is_ an integration point, then we might have to check that it is not an HTML\n            // integration point.\n            ((token.tagID === TAG_ID.MGLYPH || token.tagID === TAG_ID.MALIGNMARK) &&\n                !this._isIntegrationPoint(currentTagId, current, NS.HTML)));\n    }\n    _processToken(token) {\n        switch (token.type) {\n            case TokenType.CHARACTER: {\n                this.onCharacter(token);\n                break;\n            }\n            case TokenType.NULL_CHARACTER: {\n                this.onNullCharacter(token);\n                break;\n            }\n            case TokenType.COMMENT: {\n                this.onComment(token);\n                break;\n            }\n            case TokenType.DOCTYPE: {\n                this.onDoctype(token);\n                break;\n            }\n            case TokenType.START_TAG: {\n                this._processStartTag(token);\n                break;\n            }\n            case TokenType.END_TAG: {\n                this.onEndTag(token);\n                break;\n            }\n            case TokenType.EOF: {\n                this.onEof(token);\n                break;\n            }\n            case TokenType.WHITESPACE_CHARACTER: {\n                this.onWhitespaceCharacter(token);\n                break;\n            }\n        }\n    }\n    //Integration points\n    _isIntegrationPoint(tid, element, foreignNS) {\n        const ns = this.treeAdapter.getNamespaceURI(element);\n        const attrs = this.treeAdapter.getAttrList(element);\n        return isIntegrationPoint(tid, ns, attrs, foreignNS);\n    }\n    //Active formatting elements reconstruction\n    _reconstructActiveFormattingElements() {\n        const listLength = this.activeFormattingElements.entries.length;\n        if (listLength) {\n            const endIndex = this.activeFormattingElements.entries.findIndex((entry) => entry.type === EntryType.Marker || this.openElements.contains(entry.element));\n            const unopenIdx = endIndex < 0 ? listLength - 1 : endIndex - 1;\n            for (let i = unopenIdx; i >= 0; i--) {\n                const entry = this.activeFormattingElements.entries[i];\n                this._insertElement(entry.token, this.treeAdapter.getNamespaceURI(entry.element));\n                entry.element = this.openElements.current;\n            }\n        }\n    }\n    //Close elements\n    _closeTableCell() {\n        this.openElements.generateImpliedEndTags();\n        this.openElements.popUntilTableCellPopped();\n        this.activeFormattingElements.clearToLastMarker();\n        this.insertionMode = InsertionMode.IN_ROW;\n    }\n    _closePElement() {\n        this.openElements.generateImpliedEndTagsWithExclusion(TAG_ID.P);\n        this.openElements.popUntilTagNamePopped(TAG_ID.P);\n    }\n    //Insertion modes\n    _resetInsertionMode() {\n        for (let i = this.openElements.stackTop; i >= 0; i--) {\n            //Insertion mode reset map\n            switch (i === 0 && this.fragmentContext ? this.fragmentContextID : this.openElements.tagIDs[i]) {\n                case TAG_ID.TR: {\n                    this.insertionMode = InsertionMode.IN_ROW;\n                    return;\n                }\n                case TAG_ID.TBODY:\n                case TAG_ID.THEAD:\n                case TAG_ID.TFOOT: {\n                    this.insertionMode = InsertionMode.IN_TABLE_BODY;\n                    return;\n                }\n                case TAG_ID.CAPTION: {\n                    this.insertionMode = InsertionMode.IN_CAPTION;\n                    return;\n                }\n                case TAG_ID.COLGROUP: {\n                    this.insertionMode = InsertionMode.IN_COLUMN_GROUP;\n                    return;\n                }\n                case TAG_ID.TABLE: {\n                    this.insertionMode = InsertionMode.IN_TABLE;\n                    return;\n                }\n                case TAG_ID.BODY: {\n                    this.insertionMode = InsertionMode.IN_BODY;\n                    return;\n                }\n                case TAG_ID.FRAMESET: {\n                    this.insertionMode = InsertionMode.IN_FRAMESET;\n                    return;\n                }\n                case TAG_ID.SELECT: {\n                    this._resetInsertionModeForSelect(i);\n                    return;\n                }\n                case TAG_ID.TEMPLATE: {\n                    this.insertionMode = this.tmplInsertionModeStack[0];\n                    return;\n                }\n                case TAG_ID.HTML: {\n                    this.insertionMode = this.headElement ? InsertionMode.AFTER_HEAD : InsertionMode.BEFORE_HEAD;\n                    return;\n                }\n                case TAG_ID.TD:\n                case TAG_ID.TH: {\n                    if (i > 0) {\n                        this.insertionMode = InsertionMode.IN_CELL;\n                        return;\n                    }\n                    break;\n                }\n                case TAG_ID.HEAD: {\n                    if (i > 0) {\n                        this.insertionMode = InsertionMode.IN_HEAD;\n                        return;\n                    }\n                    break;\n                }\n            }\n        }\n        this.insertionMode = InsertionMode.IN_BODY;\n    }\n    _resetInsertionModeForSelect(selectIdx) {\n        if (selectIdx > 0) {\n            for (let i = selectIdx - 1; i > 0; i--) {\n                const tn = this.openElements.tagIDs[i];\n                if (tn === TAG_ID.TEMPLATE) {\n                    break;\n                }\n                else if (tn === TAG_ID.TABLE) {\n                    this.insertionMode = InsertionMode.IN_SELECT_IN_TABLE;\n                    return;\n                }\n            }\n        }\n        this.insertionMode = InsertionMode.IN_SELECT;\n    }\n    //Foster parenting\n    _isElementCausesFosterParenting(tn) {\n        return TABLE_STRUCTURE_TAGS.has(tn);\n    }\n    _shouldFosterParentOnInsertion() {\n        return this.fosterParentingEnabled && this._isElementCausesFosterParenting(this.openElements.currentTagId);\n    }\n    _findFosterParentingLocation() {\n        for (let i = this.openElements.stackTop; i >= 0; i--) {\n            const openElement = this.openElements.items[i];\n            switch (this.openElements.tagIDs[i]) {\n                case TAG_ID.TEMPLATE: {\n                    if (this.treeAdapter.getNamespaceURI(openElement) === NS.HTML) {\n                        return { parent: this.treeAdapter.getTemplateContent(openElement), beforeElement: null };\n                    }\n                    break;\n                }\n                case TAG_ID.TABLE: {\n                    const parent = this.treeAdapter.getParentNode(openElement);\n                    if (parent) {\n                        return { parent, beforeElement: openElement };\n                    }\n                    return { parent: this.openElements.items[i - 1], beforeElement: null };\n                }\n                // Do nothing\n            }\n        }\n        return { parent: this.openElements.items[0], beforeElement: null };\n    }\n    _fosterParentElement(element) {\n        const location = this._findFosterParentingLocation();\n        if (location.beforeElement) {\n            this.treeAdapter.insertBefore(location.parent, element, location.beforeElement);\n        }\n        else {\n            this.treeAdapter.appendChild(location.parent, element);\n        }\n    }\n    //Special elements\n    _isSpecialElement(element, id) {\n        const ns = this.treeAdapter.getNamespaceURI(element);\n        return SPECIAL_ELEMENTS[ns].has(id);\n    }\n    onCharacter(token) {\n        this.skipNextNewLine = false;\n        if (this.tokenizer.inForeignNode) {\n            characterInForeignContent(this, token);\n            return;\n        }\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL: {\n                tokenInInitialMode(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HTML: {\n                tokenBeforeHtml(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HEAD: {\n                tokenBeforeHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD: {\n                tokenInHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD_NO_SCRIPT: {\n                tokenInHeadNoScript(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_HEAD: {\n                tokenAfterHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_BODY:\n            case InsertionMode.IN_CAPTION:\n            case InsertionMode.IN_CELL:\n            case InsertionMode.IN_TEMPLATE: {\n                characterInBody(this, token);\n                break;\n            }\n            case InsertionMode.TEXT:\n            case InsertionMode.IN_SELECT:\n            case InsertionMode.IN_SELECT_IN_TABLE: {\n                this._insertCharacters(token);\n                break;\n            }\n            case InsertionMode.IN_TABLE:\n            case InsertionMode.IN_TABLE_BODY:\n            case InsertionMode.IN_ROW: {\n                characterInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                characterInTableText(this, token);\n                break;\n            }\n            case InsertionMode.IN_COLUMN_GROUP: {\n                tokenInColumnGroup(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_BODY: {\n                tokenAfterBody(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_AFTER_BODY: {\n                tokenAfterAfterBody(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onNullCharacter(token) {\n        this.skipNextNewLine = false;\n        if (this.tokenizer.inForeignNode) {\n            nullCharacterInForeignContent(this, token);\n            return;\n        }\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL: {\n                tokenInInitialMode(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HTML: {\n                tokenBeforeHtml(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HEAD: {\n                tokenBeforeHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD: {\n                tokenInHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD_NO_SCRIPT: {\n                tokenInHeadNoScript(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_HEAD: {\n                tokenAfterHead(this, token);\n                break;\n            }\n            case InsertionMode.TEXT: {\n                this._insertCharacters(token);\n                break;\n            }\n            case InsertionMode.IN_TABLE:\n            case InsertionMode.IN_TABLE_BODY:\n            case InsertionMode.IN_ROW: {\n                characterInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_COLUMN_GROUP: {\n                tokenInColumnGroup(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_BODY: {\n                tokenAfterBody(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_AFTER_BODY: {\n                tokenAfterAfterBody(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onComment(token) {\n        this.skipNextNewLine = false;\n        if (this.currentNotInHTML) {\n            appendComment(this, token);\n            return;\n        }\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL:\n            case InsertionMode.BEFORE_HTML:\n            case InsertionMode.BEFORE_HEAD:\n            case InsertionMode.IN_HEAD:\n            case InsertionMode.IN_HEAD_NO_SCRIPT:\n            case InsertionMode.AFTER_HEAD:\n            case InsertionMode.IN_BODY:\n            case InsertionMode.IN_TABLE:\n            case InsertionMode.IN_CAPTION:\n            case InsertionMode.IN_COLUMN_GROUP:\n            case InsertionMode.IN_TABLE_BODY:\n            case InsertionMode.IN_ROW:\n            case InsertionMode.IN_CELL:\n            case InsertionMode.IN_SELECT:\n            case InsertionMode.IN_SELECT_IN_TABLE:\n            case InsertionMode.IN_TEMPLATE:\n            case InsertionMode.IN_FRAMESET:\n            case InsertionMode.AFTER_FRAMESET: {\n                appendComment(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                tokenInTableText(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_BODY: {\n                appendCommentToRootHtmlElement(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_AFTER_BODY:\n            case InsertionMode.AFTER_AFTER_FRAMESET: {\n                appendCommentToDocument(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onDoctype(token) {\n        this.skipNextNewLine = false;\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL: {\n                doctypeInInitialMode(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HEAD:\n            case InsertionMode.IN_HEAD:\n            case InsertionMode.IN_HEAD_NO_SCRIPT:\n            case InsertionMode.AFTER_HEAD: {\n                this._err(token, ERR.misplacedDoctype);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                tokenInTableText(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onStartTag(token) {\n        this.skipNextNewLine = false;\n        this.currentToken = token;\n        this._processStartTag(token);\n        if (token.selfClosing && !token.ackSelfClosing) {\n            this._err(token, ERR.nonVoidHtmlElementStartTagWithTrailingSolidus);\n        }\n    }\n    /**\n     * Processes a given start tag.\n     *\n     * `onStartTag` checks if a self-closing tag was recognized. When a token\n     * is moved inbetween multiple insertion modes, this check for self-closing\n     * could lead to false positives. To avoid this, `_processStartTag` is used\n     * for nested calls.\n     *\n     * @param token The token to process.\n     */\n    _processStartTag(token) {\n        if (this.shouldProcessStartTagTokenInForeignContent(token)) {\n            startTagInForeignContent(this, token);\n        }\n        else {\n            this._startTagOutsideForeignContent(token);\n        }\n    }\n    _startTagOutsideForeignContent(token) {\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL: {\n                tokenInInitialMode(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HTML: {\n                startTagBeforeHtml(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HEAD: {\n                startTagBeforeHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD: {\n                startTagInHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD_NO_SCRIPT: {\n                startTagInHeadNoScript(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_HEAD: {\n                startTagAfterHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_BODY: {\n                startTagInBody(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE: {\n                startTagInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                tokenInTableText(this, token);\n                break;\n            }\n            case InsertionMode.IN_CAPTION: {\n                startTagInCaption(this, token);\n                break;\n            }\n            case InsertionMode.IN_COLUMN_GROUP: {\n                startTagInColumnGroup(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_BODY: {\n                startTagInTableBody(this, token);\n                break;\n            }\n            case InsertionMode.IN_ROW: {\n                startTagInRow(this, token);\n                break;\n            }\n            case InsertionMode.IN_CELL: {\n                startTagInCell(this, token);\n                break;\n            }\n            case InsertionMode.IN_SELECT: {\n                startTagInSelect(this, token);\n                break;\n            }\n            case InsertionMode.IN_SELECT_IN_TABLE: {\n                startTagInSelectInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_TEMPLATE: {\n                startTagInTemplate(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_BODY: {\n                startTagAfterBody(this, token);\n                break;\n            }\n            case InsertionMode.IN_FRAMESET: {\n                startTagInFrameset(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_FRAMESET: {\n                startTagAfterFrameset(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_AFTER_BODY: {\n                startTagAfterAfterBody(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_AFTER_FRAMESET: {\n                startTagAfterAfterFrameset(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onEndTag(token) {\n        this.skipNextNewLine = false;\n        this.currentToken = token;\n        if (this.currentNotInHTML) {\n            endTagInForeignContent(this, token);\n        }\n        else {\n            this._endTagOutsideForeignContent(token);\n        }\n    }\n    _endTagOutsideForeignContent(token) {\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL: {\n                tokenInInitialMode(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HTML: {\n                endTagBeforeHtml(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HEAD: {\n                endTagBeforeHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD: {\n                endTagInHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD_NO_SCRIPT: {\n                endTagInHeadNoScript(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_HEAD: {\n                endTagAfterHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_BODY: {\n                endTagInBody(this, token);\n                break;\n            }\n            case InsertionMode.TEXT: {\n                endTagInText(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE: {\n                endTagInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                tokenInTableText(this, token);\n                break;\n            }\n            case InsertionMode.IN_CAPTION: {\n                endTagInCaption(this, token);\n                break;\n            }\n            case InsertionMode.IN_COLUMN_GROUP: {\n                endTagInColumnGroup(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_BODY: {\n                endTagInTableBody(this, token);\n                break;\n            }\n            case InsertionMode.IN_ROW: {\n                endTagInRow(this, token);\n                break;\n            }\n            case InsertionMode.IN_CELL: {\n                endTagInCell(this, token);\n                break;\n            }\n            case InsertionMode.IN_SELECT: {\n                endTagInSelect(this, token);\n                break;\n            }\n            case InsertionMode.IN_SELECT_IN_TABLE: {\n                endTagInSelectInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_TEMPLATE: {\n                endTagInTemplate(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_BODY: {\n                endTagAfterBody(this, token);\n                break;\n            }\n            case InsertionMode.IN_FRAMESET: {\n                endTagInFrameset(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_FRAMESET: {\n                endTagAfterFrameset(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_AFTER_BODY: {\n                tokenAfterAfterBody(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onEof(token) {\n        switch (this.insertionMode) {\n            case InsertionMode.INITIAL: {\n                tokenInInitialMode(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HTML: {\n                tokenBeforeHtml(this, token);\n                break;\n            }\n            case InsertionMode.BEFORE_HEAD: {\n                tokenBeforeHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD: {\n                tokenInHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_HEAD_NO_SCRIPT: {\n                tokenInHeadNoScript(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_HEAD: {\n                tokenAfterHead(this, token);\n                break;\n            }\n            case InsertionMode.IN_BODY:\n            case InsertionMode.IN_TABLE:\n            case InsertionMode.IN_CAPTION:\n            case InsertionMode.IN_COLUMN_GROUP:\n            case InsertionMode.IN_TABLE_BODY:\n            case InsertionMode.IN_ROW:\n            case InsertionMode.IN_CELL:\n            case InsertionMode.IN_SELECT:\n            case InsertionMode.IN_SELECT_IN_TABLE: {\n                eofInBody(this, token);\n                break;\n            }\n            case InsertionMode.TEXT: {\n                eofInText(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                tokenInTableText(this, token);\n                break;\n            }\n            case InsertionMode.IN_TEMPLATE: {\n                eofInTemplate(this, token);\n                break;\n            }\n            case InsertionMode.AFTER_BODY:\n            case InsertionMode.IN_FRAMESET:\n            case InsertionMode.AFTER_FRAMESET:\n            case InsertionMode.AFTER_AFTER_BODY:\n            case InsertionMode.AFTER_AFTER_FRAMESET: {\n                stopParsing(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n    onWhitespaceCharacter(token) {\n        if (this.skipNextNewLine) {\n            this.skipNextNewLine = false;\n            if (token.chars.charCodeAt(0) === CODE_POINTS.LINE_FEED) {\n                if (token.chars.length === 1) {\n                    return;\n                }\n                token.chars = token.chars.substr(1);\n            }\n        }\n        if (this.tokenizer.inForeignNode) {\n            this._insertCharacters(token);\n            return;\n        }\n        switch (this.insertionMode) {\n            case InsertionMode.IN_HEAD:\n            case InsertionMode.IN_HEAD_NO_SCRIPT:\n            case InsertionMode.AFTER_HEAD:\n            case InsertionMode.TEXT:\n            case InsertionMode.IN_COLUMN_GROUP:\n            case InsertionMode.IN_SELECT:\n            case InsertionMode.IN_SELECT_IN_TABLE:\n            case InsertionMode.IN_FRAMESET:\n            case InsertionMode.AFTER_FRAMESET: {\n                this._insertCharacters(token);\n                break;\n            }\n            case InsertionMode.IN_BODY:\n            case InsertionMode.IN_CAPTION:\n            case InsertionMode.IN_CELL:\n            case InsertionMode.IN_TEMPLATE:\n            case InsertionMode.AFTER_BODY:\n            case InsertionMode.AFTER_AFTER_BODY:\n            case InsertionMode.AFTER_AFTER_FRAMESET: {\n                whitespaceCharacterInBody(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE:\n            case InsertionMode.IN_TABLE_BODY:\n            case InsertionMode.IN_ROW: {\n                characterInTable(this, token);\n                break;\n            }\n            case InsertionMode.IN_TABLE_TEXT: {\n                whitespaceCharacterInTableText(this, token);\n                break;\n            }\n            // Do nothing\n        }\n    }\n}\n//Adoption agency algorithm\n//(see: http://www.whatwg.org/specs/web-apps/current-work/multipage/tree-construction.html#adoptionAgency)\n//------------------------------------------------------------------\n//Steps 5-8 of the algorithm\nfunction aaObtainFormattingElementEntry(p, token) {\n    let formattingElementEntry = p.activeFormattingElements.getElementEntryInScopeWithTagName(token.tagName);\n    if (formattingElementEntry) {\n        if (!p.openElements.contains(formattingElementEntry.element)) {\n            p.activeFormattingElements.removeEntry(formattingElementEntry);\n            formattingElementEntry = null;\n        }\n        else if (!p.openElements.hasInScope(token.tagID)) {\n            formattingElementEntry = null;\n        }\n    }\n    else {\n        genericEndTagInBody(p, token);\n    }\n    return formattingElementEntry;\n}\n//Steps 9 and 10 of the algorithm\nfunction aaObtainFurthestBlock(p, formattingElementEntry) {\n    let furthestBlock = null;\n    let idx = p.openElements.stackTop;\n    for (; idx >= 0; idx--) {\n        const element = p.openElements.items[idx];\n        if (element === formattingElementEntry.element) {\n            break;\n        }\n        if (p._isSpecialElement(element, p.openElements.tagIDs[idx])) {\n            furthestBlock = element;\n        }\n    }\n    if (!furthestBlock) {\n        p.openElements.shortenToLength(idx < 0 ? 0 : idx);\n        p.activeFormattingElements.removeEntry(formattingElementEntry);\n    }\n    return furthestBlock;\n}\n//Step 13 of the algorithm\nfunction aaInnerLoop(p, furthestBlock, formattingElement) {\n    let lastElement = furthestBlock;\n    let nextElement = p.openElements.getCommonAncestor(furthestBlock);\n    for (let i = 0, element = nextElement; element !== formattingElement; i++, element = nextElement) {\n        //NOTE: store the next element for the next loop iteration (it may be deleted from the stack by step 9.5)\n        nextElement = p.openElements.getCommonAncestor(element);\n        const elementEntry = p.activeFormattingElements.getElementEntry(element);\n        const counterOverflow = elementEntry && i >= AA_INNER_LOOP_ITER;\n        const shouldRemoveFromOpenElements = !elementEntry || counterOverflow;\n        if (shouldRemoveFromOpenElements) {\n            if (counterOverflow) {\n                p.activeFormattingElements.removeEntry(elementEntry);\n            }\n            p.openElements.remove(element);\n        }\n        else {\n            element = aaRecreateElementFromEntry(p, elementEntry);\n            if (lastElement === furthestBlock) {\n                p.activeFormattingElements.bookmark = elementEntry;\n            }\n            p.treeAdapter.detachNode(lastElement);\n            p.treeAdapter.appendChild(element, lastElement);\n            lastElement = element;\n        }\n    }\n    return lastElement;\n}\n//Step 13.7 of the algorithm\nfunction aaRecreateElementFromEntry(p, elementEntry) {\n    const ns = p.treeAdapter.getNamespaceURI(elementEntry.element);\n    const newElement = p.treeAdapter.createElement(elementEntry.token.tagName, ns, elementEntry.token.attrs);\n    p.openElements.replace(elementEntry.element, newElement);\n    elementEntry.element = newElement;\n    return newElement;\n}\n//Step 14 of the algorithm\nfunction aaInsertLastNodeInCommonAncestor(p, commonAncestor, lastElement) {\n    const tn = p.treeAdapter.getTagName(commonAncestor);\n    const tid = getTagID(tn);\n    if (p._isElementCausesFosterParenting(tid)) {\n        p._fosterParentElement(lastElement);\n    }\n    else {\n        const ns = p.treeAdapter.getNamespaceURI(commonAncestor);\n        if (tid === TAG_ID.TEMPLATE && ns === NS.HTML) {\n            commonAncestor = p.treeAdapter.getTemplateContent(commonAncestor);\n        }\n        p.treeAdapter.appendChild(commonAncestor, lastElement);\n    }\n}\n//Steps 15-19 of the algorithm\nfunction aaReplaceFormattingElement(p, furthestBlock, formattingElementEntry) {\n    const ns = p.treeAdapter.getNamespaceURI(formattingElementEntry.element);\n    const { token } = formattingElementEntry;\n    const newElement = p.treeAdapter.createElement(token.tagName, ns, token.attrs);\n    p._adoptNodes(furthestBlock, newElement);\n    p.treeAdapter.appendChild(furthestBlock, newElement);\n    p.activeFormattingElements.insertElementAfterBookmark(newElement, token);\n    p.activeFormattingElements.removeEntry(formattingElementEntry);\n    p.openElements.remove(formattingElementEntry.element);\n    p.openElements.insertAfter(furthestBlock, newElement, token.tagID);\n}\n//Algorithm entry point\nfunction callAdoptionAgency(p, token) {\n    for (let i = 0; i < AA_OUTER_LOOP_ITER; i++) {\n        const formattingElementEntry = aaObtainFormattingElementEntry(p, token);\n        if (!formattingElementEntry) {\n            break;\n        }\n        const furthestBlock = aaObtainFurthestBlock(p, formattingElementEntry);\n        if (!furthestBlock) {\n            break;\n        }\n        p.activeFormattingElements.bookmark = formattingElementEntry;\n        const lastElement = aaInnerLoop(p, furthestBlock, formattingElementEntry.element);\n        const commonAncestor = p.openElements.getCommonAncestor(formattingElementEntry.element);\n        p.treeAdapter.detachNode(lastElement);\n        if (commonAncestor)\n            aaInsertLastNodeInCommonAncestor(p, commonAncestor, lastElement);\n        aaReplaceFormattingElement(p, furthestBlock, formattingElementEntry);\n    }\n}\n//Generic token handlers\n//------------------------------------------------------------------\nfunction appendComment(p, token) {\n    p._appendCommentNode(token, p.openElements.currentTmplContentOrNode);\n}\nfunction appendCommentToRootHtmlElement(p, token) {\n    p._appendCommentNode(token, p.openElements.items[0]);\n}\nfunction appendCommentToDocument(p, token) {\n    p._appendCommentNode(token, p.document);\n}\nfunction stopParsing(p, token) {\n    p.stopped = true;\n    // NOTE: Set end locations for elements that remain on the open element stack.\n    if (token.location) {\n        // NOTE: If we are not in a fragment, `html` and `body` will stay on the stack.\n        // This is a problem, as we might overwrite their end position here.\n        const target = p.fragmentContext ? 0 : 2;\n        for (let i = p.openElements.stackTop; i >= target; i--) {\n            p._setEndLocation(p.openElements.items[i], token);\n        }\n        // Handle `html` and `body`\n        if (!p.fragmentContext && p.openElements.stackTop >= 0) {\n            const htmlElement = p.openElements.items[0];\n            const htmlLocation = p.treeAdapter.getNodeSourceCodeLocation(htmlElement);\n            if (htmlLocation && !htmlLocation.endTag) {\n                p._setEndLocation(htmlElement, token);\n                if (p.openElements.stackTop >= 1) {\n                    const bodyElement = p.openElements.items[1];\n                    const bodyLocation = p.treeAdapter.getNodeSourceCodeLocation(bodyElement);\n                    if (bodyLocation && !bodyLocation.endTag) {\n                        p._setEndLocation(bodyElement, token);\n                    }\n                }\n            }\n        }\n    }\n}\n// The \"initial\" insertion mode\n//------------------------------------------------------------------\nfunction doctypeInInitialMode(p, token) {\n    p._setDocumentType(token);\n    const mode = token.forceQuirks ? DOCUMENT_MODE.QUIRKS : getDocumentMode(token);\n    if (!isConforming(token)) {\n        p._err(token, ERR.nonConformingDoctype);\n    }\n    p.treeAdapter.setDocumentMode(p.document, mode);\n    p.insertionMode = InsertionMode.BEFORE_HTML;\n}\nfunction tokenInInitialMode(p, token) {\n    p._err(token, ERR.missingDoctype, true);\n    p.treeAdapter.setDocumentMode(p.document, DOCUMENT_MODE.QUIRKS);\n    p.insertionMode = InsertionMode.BEFORE_HTML;\n    p._processToken(token);\n}\n// The \"before html\" insertion mode\n//------------------------------------------------------------------\nfunction startTagBeforeHtml(p, token) {\n    if (token.tagID === TAG_ID.HTML) {\n        p._insertElement(token, NS.HTML);\n        p.insertionMode = InsertionMode.BEFORE_HEAD;\n    }\n    else {\n        tokenBeforeHtml(p, token);\n    }\n}\nfunction endTagBeforeHtml(p, token) {\n    const tn = token.tagID;\n    if (tn === TAG_ID.HTML || tn === TAG_ID.HEAD || tn === TAG_ID.BODY || tn === TAG_ID.BR) {\n        tokenBeforeHtml(p, token);\n    }\n}\nfunction tokenBeforeHtml(p, token) {\n    p._insertFakeRootElement();\n    p.insertionMode = InsertionMode.BEFORE_HEAD;\n    p._processToken(token);\n}\n// The \"before head\" insertion mode\n//------------------------------------------------------------------\nfunction startTagBeforeHead(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.HEAD: {\n            p._insertElement(token, NS.HTML);\n            p.headElement = p.openElements.current;\n            p.insertionMode = InsertionMode.IN_HEAD;\n            break;\n        }\n        default: {\n            tokenBeforeHead(p, token);\n        }\n    }\n}\nfunction endTagBeforeHead(p, token) {\n    const tn = token.tagID;\n    if (tn === TAG_ID.HEAD || tn === TAG_ID.BODY || tn === TAG_ID.HTML || tn === TAG_ID.BR) {\n        tokenBeforeHead(p, token);\n    }\n    else {\n        p._err(token, ERR.endTagWithoutMatchingOpenElement);\n    }\n}\nfunction tokenBeforeHead(p, token) {\n    p._insertFakeElement(TAG_NAMES.HEAD, TAG_ID.HEAD);\n    p.headElement = p.openElements.current;\n    p.insertionMode = InsertionMode.IN_HEAD;\n    p._processToken(token);\n}\n// The \"in head\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInHead(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.BASE:\n        case TAG_ID.BASEFONT:\n        case TAG_ID.BGSOUND:\n        case TAG_ID.LINK:\n        case TAG_ID.META: {\n            p._appendElement(token, NS.HTML);\n            token.ackSelfClosing = true;\n            break;\n        }\n        case TAG_ID.TITLE: {\n            p._switchToTextParsing(token, TokenizerMode.RCDATA);\n            break;\n        }\n        case TAG_ID.NOSCRIPT: {\n            if (p.options.scriptingEnabled) {\n                p._switchToTextParsing(token, TokenizerMode.RAWTEXT);\n            }\n            else {\n                p._insertElement(token, NS.HTML);\n                p.insertionMode = InsertionMode.IN_HEAD_NO_SCRIPT;\n            }\n            break;\n        }\n        case TAG_ID.NOFRAMES:\n        case TAG_ID.STYLE: {\n            p._switchToTextParsing(token, TokenizerMode.RAWTEXT);\n            break;\n        }\n        case TAG_ID.SCRIPT: {\n            p._switchToTextParsing(token, TokenizerMode.SCRIPT_DATA);\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            p._insertTemplate(token);\n            p.activeFormattingElements.insertMarker();\n            p.framesetOk = false;\n            p.insertionMode = InsertionMode.IN_TEMPLATE;\n            p.tmplInsertionModeStack.unshift(InsertionMode.IN_TEMPLATE);\n            break;\n        }\n        case TAG_ID.HEAD: {\n            p._err(token, ERR.misplacedStartTagForHeadElement);\n            break;\n        }\n        default: {\n            tokenInHead(p, token);\n        }\n    }\n}\nfunction endTagInHead(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HEAD: {\n            p.openElements.pop();\n            p.insertionMode = InsertionMode.AFTER_HEAD;\n            break;\n        }\n        case TAG_ID.BODY:\n        case TAG_ID.BR:\n        case TAG_ID.HTML: {\n            tokenInHead(p, token);\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            templateEndTagInHead(p, token);\n            break;\n        }\n        default: {\n            p._err(token, ERR.endTagWithoutMatchingOpenElement);\n        }\n    }\n}\nfunction templateEndTagInHead(p, token) {\n    if (p.openElements.tmplCount > 0) {\n        p.openElements.generateImpliedEndTagsThoroughly();\n        if (p.openElements.currentTagId !== TAG_ID.TEMPLATE) {\n            p._err(token, ERR.closingOfElementWithOpenChildElements);\n        }\n        p.openElements.popUntilTagNamePopped(TAG_ID.TEMPLATE);\n        p.activeFormattingElements.clearToLastMarker();\n        p.tmplInsertionModeStack.shift();\n        p._resetInsertionMode();\n    }\n    else {\n        p._err(token, ERR.endTagWithoutMatchingOpenElement);\n    }\n}\nfunction tokenInHead(p, token) {\n    p.openElements.pop();\n    p.insertionMode = InsertionMode.AFTER_HEAD;\n    p._processToken(token);\n}\n// The \"in head no script\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInHeadNoScript(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.BASEFONT:\n        case TAG_ID.BGSOUND:\n        case TAG_ID.HEAD:\n        case TAG_ID.LINK:\n        case TAG_ID.META:\n        case TAG_ID.NOFRAMES:\n        case TAG_ID.STYLE: {\n            startTagInHead(p, token);\n            break;\n        }\n        case TAG_ID.NOSCRIPT: {\n            p._err(token, ERR.nestedNoscriptInHead);\n            break;\n        }\n        default: {\n            tokenInHeadNoScript(p, token);\n        }\n    }\n}\nfunction endTagInHeadNoScript(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.NOSCRIPT: {\n            p.openElements.pop();\n            p.insertionMode = InsertionMode.IN_HEAD;\n            break;\n        }\n        case TAG_ID.BR: {\n            tokenInHeadNoScript(p, token);\n            break;\n        }\n        default: {\n            p._err(token, ERR.endTagWithoutMatchingOpenElement);\n        }\n    }\n}\nfunction tokenInHeadNoScript(p, token) {\n    const errCode = token.type === TokenType.EOF ? ERR.openElementsLeftAfterEof : ERR.disallowedContentInNoscriptInHead;\n    p._err(token, errCode);\n    p.openElements.pop();\n    p.insertionMode = InsertionMode.IN_HEAD;\n    p._processToken(token);\n}\n// The \"after head\" insertion mode\n//------------------------------------------------------------------\nfunction startTagAfterHead(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.BODY: {\n            p._insertElement(token, NS.HTML);\n            p.framesetOk = false;\n            p.insertionMode = InsertionMode.IN_BODY;\n            break;\n        }\n        case TAG_ID.FRAMESET: {\n            p._insertElement(token, NS.HTML);\n            p.insertionMode = InsertionMode.IN_FRAMESET;\n            break;\n        }\n        case TAG_ID.BASE:\n        case TAG_ID.BASEFONT:\n        case TAG_ID.BGSOUND:\n        case TAG_ID.LINK:\n        case TAG_ID.META:\n        case TAG_ID.NOFRAMES:\n        case TAG_ID.SCRIPT:\n        case TAG_ID.STYLE:\n        case TAG_ID.TEMPLATE:\n        case TAG_ID.TITLE: {\n            p._err(token, ERR.abandonedHeadElementChild);\n            p.openElements.push(p.headElement, TAG_ID.HEAD);\n            startTagInHead(p, token);\n            p.openElements.remove(p.headElement);\n            break;\n        }\n        case TAG_ID.HEAD: {\n            p._err(token, ERR.misplacedStartTagForHeadElement);\n            break;\n        }\n        default: {\n            tokenAfterHead(p, token);\n        }\n    }\n}\nfunction endTagAfterHead(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.BODY:\n        case TAG_ID.HTML:\n        case TAG_ID.BR: {\n            tokenAfterHead(p, token);\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            templateEndTagInHead(p, token);\n            break;\n        }\n        default: {\n            p._err(token, ERR.endTagWithoutMatchingOpenElement);\n        }\n    }\n}\nfunction tokenAfterHead(p, token) {\n    p._insertFakeElement(TAG_NAMES.BODY, TAG_ID.BODY);\n    p.insertionMode = InsertionMode.IN_BODY;\n    modeInBody(p, token);\n}\n// The \"in body\" insertion mode\n//------------------------------------------------------------------\nfunction modeInBody(p, token) {\n    switch (token.type) {\n        case TokenType.CHARACTER: {\n            characterInBody(p, token);\n            break;\n        }\n        case TokenType.WHITESPACE_CHARACTER: {\n            whitespaceCharacterInBody(p, token);\n            break;\n        }\n        case TokenType.COMMENT: {\n            appendComment(p, token);\n            break;\n        }\n        case TokenType.START_TAG: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TokenType.END_TAG: {\n            endTagInBody(p, token);\n            break;\n        }\n        case TokenType.EOF: {\n            eofInBody(p, token);\n            break;\n        }\n        // Do nothing\n    }\n}\nfunction whitespaceCharacterInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._insertCharacters(token);\n}\nfunction characterInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._insertCharacters(token);\n    p.framesetOk = false;\n}\nfunction htmlStartTagInBody(p, token) {\n    if (p.openElements.tmplCount === 0) {\n        p.treeAdapter.adoptAttributes(p.openElements.items[0], token.attrs);\n    }\n}\nfunction bodyStartTagInBody(p, token) {\n    const bodyElement = p.openElements.tryPeekProperlyNestedBodyElement();\n    if (bodyElement && p.openElements.tmplCount === 0) {\n        p.framesetOk = false;\n        p.treeAdapter.adoptAttributes(bodyElement, token.attrs);\n    }\n}\nfunction framesetStartTagInBody(p, token) {\n    const bodyElement = p.openElements.tryPeekProperlyNestedBodyElement();\n    if (p.framesetOk && bodyElement) {\n        p.treeAdapter.detachNode(bodyElement);\n        p.openElements.popAllUpToHtmlElement();\n        p._insertElement(token, NS.HTML);\n        p.insertionMode = InsertionMode.IN_FRAMESET;\n    }\n}\nfunction addressStartTagInBody(p, token) {\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._insertElement(token, NS.HTML);\n}\nfunction numberedHeaderStartTagInBody(p, token) {\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    if (isNumberedHeader(p.openElements.currentTagId)) {\n        p.openElements.pop();\n    }\n    p._insertElement(token, NS.HTML);\n}\nfunction preStartTagInBody(p, token) {\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._insertElement(token, NS.HTML);\n    //NOTE: If the next token is a U+000A LINE FEED (LF) character token, then ignore that token and move\n    //on to the next one. (Newlines at the start of pre blocks are ignored as an authoring convenience.)\n    p.skipNextNewLine = true;\n    p.framesetOk = false;\n}\nfunction formStartTagInBody(p, token) {\n    const inTemplate = p.openElements.tmplCount > 0;\n    if (!p.formElement || inTemplate) {\n        if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n            p._closePElement();\n        }\n        p._insertElement(token, NS.HTML);\n        if (!inTemplate) {\n            p.formElement = p.openElements.current;\n        }\n    }\n}\nfunction listItemStartTagInBody(p, token) {\n    p.framesetOk = false;\n    const tn = token.tagID;\n    for (let i = p.openElements.stackTop; i >= 0; i--) {\n        const elementId = p.openElements.tagIDs[i];\n        if ((tn === TAG_ID.LI && elementId === TAG_ID.LI) ||\n            ((tn === TAG_ID.DD || tn === TAG_ID.DT) && (elementId === TAG_ID.DD || elementId === TAG_ID.DT))) {\n            p.openElements.generateImpliedEndTagsWithExclusion(elementId);\n            p.openElements.popUntilTagNamePopped(elementId);\n            break;\n        }\n        if (elementId !== TAG_ID.ADDRESS &&\n            elementId !== TAG_ID.DIV &&\n            elementId !== TAG_ID.P &&\n            p._isSpecialElement(p.openElements.items[i], elementId)) {\n            break;\n        }\n    }\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._insertElement(token, NS.HTML);\n}\nfunction plaintextStartTagInBody(p, token) {\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._insertElement(token, NS.HTML);\n    p.tokenizer.state = TokenizerMode.PLAINTEXT;\n}\nfunction buttonStartTagInBody(p, token) {\n    if (p.openElements.hasInScope(TAG_ID.BUTTON)) {\n        p.openElements.generateImpliedEndTags();\n        p.openElements.popUntilTagNamePopped(TAG_ID.BUTTON);\n    }\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n    p.framesetOk = false;\n}\nfunction aStartTagInBody(p, token) {\n    const activeElementEntry = p.activeFormattingElements.getElementEntryInScopeWithTagName(TAG_NAMES.A);\n    if (activeElementEntry) {\n        callAdoptionAgency(p, token);\n        p.openElements.remove(activeElementEntry.element);\n        p.activeFormattingElements.removeEntry(activeElementEntry);\n    }\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n    p.activeFormattingElements.pushElement(p.openElements.current, token);\n}\nfunction bStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n    p.activeFormattingElements.pushElement(p.openElements.current, token);\n}\nfunction nobrStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    if (p.openElements.hasInScope(TAG_ID.NOBR)) {\n        callAdoptionAgency(p, token);\n        p._reconstructActiveFormattingElements();\n    }\n    p._insertElement(token, NS.HTML);\n    p.activeFormattingElements.pushElement(p.openElements.current, token);\n}\nfunction appletStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n    p.activeFormattingElements.insertMarker();\n    p.framesetOk = false;\n}\nfunction tableStartTagInBody(p, token) {\n    if (p.treeAdapter.getDocumentMode(p.document) !== DOCUMENT_MODE.QUIRKS && p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._insertElement(token, NS.HTML);\n    p.framesetOk = false;\n    p.insertionMode = InsertionMode.IN_TABLE;\n}\nfunction areaStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._appendElement(token, NS.HTML);\n    p.framesetOk = false;\n    token.ackSelfClosing = true;\n}\nfunction isHiddenInput(token) {\n    const inputType = getTokenAttr(token, ATTRS.TYPE);\n    return inputType != null && inputType.toLowerCase() === HIDDEN_INPUT_TYPE;\n}\nfunction inputStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._appendElement(token, NS.HTML);\n    if (!isHiddenInput(token)) {\n        p.framesetOk = false;\n    }\n    token.ackSelfClosing = true;\n}\nfunction paramStartTagInBody(p, token) {\n    p._appendElement(token, NS.HTML);\n    token.ackSelfClosing = true;\n}\nfunction hrStartTagInBody(p, token) {\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._appendElement(token, NS.HTML);\n    p.framesetOk = false;\n    token.ackSelfClosing = true;\n}\nfunction imageStartTagInBody(p, token) {\n    token.tagName = TAG_NAMES.IMG;\n    token.tagID = TAG_ID.IMG;\n    areaStartTagInBody(p, token);\n}\nfunction textareaStartTagInBody(p, token) {\n    p._insertElement(token, NS.HTML);\n    //NOTE: If the next token is a U+000A LINE FEED (LF) character token, then ignore that token and move\n    //on to the next one. (Newlines at the start of textarea elements are ignored as an authoring convenience.)\n    p.skipNextNewLine = true;\n    p.tokenizer.state = TokenizerMode.RCDATA;\n    p.originalInsertionMode = p.insertionMode;\n    p.framesetOk = false;\n    p.insertionMode = InsertionMode.TEXT;\n}\nfunction xmpStartTagInBody(p, token) {\n    if (p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._closePElement();\n    }\n    p._reconstructActiveFormattingElements();\n    p.framesetOk = false;\n    p._switchToTextParsing(token, TokenizerMode.RAWTEXT);\n}\nfunction iframeStartTagInBody(p, token) {\n    p.framesetOk = false;\n    p._switchToTextParsing(token, TokenizerMode.RAWTEXT);\n}\n//NOTE: here we assume that we always act as an user agent with enabled plugins, so we parse\n//<noembed> as rawtext.\nfunction noembedStartTagInBody(p, token) {\n    p._switchToTextParsing(token, TokenizerMode.RAWTEXT);\n}\nfunction selectStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n    p.framesetOk = false;\n    p.insertionMode =\n        p.insertionMode === InsertionMode.IN_TABLE ||\n            p.insertionMode === InsertionMode.IN_CAPTION ||\n            p.insertionMode === InsertionMode.IN_TABLE_BODY ||\n            p.insertionMode === InsertionMode.IN_ROW ||\n            p.insertionMode === InsertionMode.IN_CELL\n            ? InsertionMode.IN_SELECT_IN_TABLE\n            : InsertionMode.IN_SELECT;\n}\nfunction optgroupStartTagInBody(p, token) {\n    if (p.openElements.currentTagId === TAG_ID.OPTION) {\n        p.openElements.pop();\n    }\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n}\nfunction rbStartTagInBody(p, token) {\n    if (p.openElements.hasInScope(TAG_ID.RUBY)) {\n        p.openElements.generateImpliedEndTags();\n    }\n    p._insertElement(token, NS.HTML);\n}\nfunction rtStartTagInBody(p, token) {\n    if (p.openElements.hasInScope(TAG_ID.RUBY)) {\n        p.openElements.generateImpliedEndTagsWithExclusion(TAG_ID.RTC);\n    }\n    p._insertElement(token, NS.HTML);\n}\nfunction mathStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    adjustTokenMathMLAttrs(token);\n    adjustTokenXMLAttrs(token);\n    if (token.selfClosing) {\n        p._appendElement(token, NS.MATHML);\n    }\n    else {\n        p._insertElement(token, NS.MATHML);\n    }\n    token.ackSelfClosing = true;\n}\nfunction svgStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    adjustTokenSVGAttrs(token);\n    adjustTokenXMLAttrs(token);\n    if (token.selfClosing) {\n        p._appendElement(token, NS.SVG);\n    }\n    else {\n        p._insertElement(token, NS.SVG);\n    }\n    token.ackSelfClosing = true;\n}\nfunction genericStartTagInBody(p, token) {\n    p._reconstructActiveFormattingElements();\n    p._insertElement(token, NS.HTML);\n}\nfunction startTagInBody(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.I:\n        case TAG_ID.S:\n        case TAG_ID.B:\n        case TAG_ID.U:\n        case TAG_ID.EM:\n        case TAG_ID.TT:\n        case TAG_ID.BIG:\n        case TAG_ID.CODE:\n        case TAG_ID.FONT:\n        case TAG_ID.SMALL:\n        case TAG_ID.STRIKE:\n        case TAG_ID.STRONG: {\n            bStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.A: {\n            aStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.H1:\n        case TAG_ID.H2:\n        case TAG_ID.H3:\n        case TAG_ID.H4:\n        case TAG_ID.H5:\n        case TAG_ID.H6: {\n            numberedHeaderStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.P:\n        case TAG_ID.DL:\n        case TAG_ID.OL:\n        case TAG_ID.UL:\n        case TAG_ID.DIV:\n        case TAG_ID.DIR:\n        case TAG_ID.NAV:\n        case TAG_ID.MAIN:\n        case TAG_ID.MENU:\n        case TAG_ID.ASIDE:\n        case TAG_ID.CENTER:\n        case TAG_ID.FIGURE:\n        case TAG_ID.FOOTER:\n        case TAG_ID.HEADER:\n        case TAG_ID.HGROUP:\n        case TAG_ID.DIALOG:\n        case TAG_ID.DETAILS:\n        case TAG_ID.ADDRESS:\n        case TAG_ID.ARTICLE:\n        case TAG_ID.SECTION:\n        case TAG_ID.SUMMARY:\n        case TAG_ID.FIELDSET:\n        case TAG_ID.BLOCKQUOTE:\n        case TAG_ID.FIGCAPTION: {\n            addressStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.LI:\n        case TAG_ID.DD:\n        case TAG_ID.DT: {\n            listItemStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.BR:\n        case TAG_ID.IMG:\n        case TAG_ID.WBR:\n        case TAG_ID.AREA:\n        case TAG_ID.EMBED:\n        case TAG_ID.KEYGEN: {\n            areaStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.HR: {\n            hrStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.RB:\n        case TAG_ID.RTC: {\n            rbStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.RT:\n        case TAG_ID.RP: {\n            rtStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.PRE:\n        case TAG_ID.LISTING: {\n            preStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.XMP: {\n            xmpStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.SVG: {\n            svgStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.HTML: {\n            htmlStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.BASE:\n        case TAG_ID.LINK:\n        case TAG_ID.META:\n        case TAG_ID.STYLE:\n        case TAG_ID.TITLE:\n        case TAG_ID.SCRIPT:\n        case TAG_ID.BGSOUND:\n        case TAG_ID.BASEFONT:\n        case TAG_ID.TEMPLATE: {\n            startTagInHead(p, token);\n            break;\n        }\n        case TAG_ID.BODY: {\n            bodyStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.FORM: {\n            formStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.NOBR: {\n            nobrStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.MATH: {\n            mathStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.TABLE: {\n            tableStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.INPUT: {\n            inputStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.PARAM:\n        case TAG_ID.TRACK:\n        case TAG_ID.SOURCE: {\n            paramStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.IMAGE: {\n            imageStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.BUTTON: {\n            buttonStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.APPLET:\n        case TAG_ID.OBJECT:\n        case TAG_ID.MARQUEE: {\n            appletStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.IFRAME: {\n            iframeStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.SELECT: {\n            selectStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.OPTION:\n        case TAG_ID.OPTGROUP: {\n            optgroupStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.NOEMBED: {\n            noembedStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.FRAMESET: {\n            framesetStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.TEXTAREA: {\n            textareaStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.NOSCRIPT: {\n            if (p.options.scriptingEnabled) {\n                noembedStartTagInBody(p, token);\n            }\n            else {\n                genericStartTagInBody(p, token);\n            }\n            break;\n        }\n        case TAG_ID.PLAINTEXT: {\n            plaintextStartTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.COL:\n        case TAG_ID.TH:\n        case TAG_ID.TD:\n        case TAG_ID.TR:\n        case TAG_ID.HEAD:\n        case TAG_ID.FRAME:\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD:\n        case TAG_ID.CAPTION:\n        case TAG_ID.COLGROUP: {\n            // Ignore token\n            break;\n        }\n        default: {\n            genericStartTagInBody(p, token);\n        }\n    }\n}\nfunction bodyEndTagInBody(p, token) {\n    if (p.openElements.hasInScope(TAG_ID.BODY)) {\n        p.insertionMode = InsertionMode.AFTER_BODY;\n        //NOTE: <body> is never popped from the stack, so we need to updated\n        //the end location explicitly.\n        if (p.options.sourceCodeLocationInfo) {\n            const bodyElement = p.openElements.tryPeekProperlyNestedBodyElement();\n            if (bodyElement) {\n                p._setEndLocation(bodyElement, token);\n            }\n        }\n    }\n}\nfunction htmlEndTagInBody(p, token) {\n    if (p.openElements.hasInScope(TAG_ID.BODY)) {\n        p.insertionMode = InsertionMode.AFTER_BODY;\n        endTagAfterBody(p, token);\n    }\n}\nfunction addressEndTagInBody(p, token) {\n    const tn = token.tagID;\n    if (p.openElements.hasInScope(tn)) {\n        p.openElements.generateImpliedEndTags();\n        p.openElements.popUntilTagNamePopped(tn);\n    }\n}\nfunction formEndTagInBody(p) {\n    const inTemplate = p.openElements.tmplCount > 0;\n    const { formElement } = p;\n    if (!inTemplate) {\n        p.formElement = null;\n    }\n    if ((formElement || inTemplate) && p.openElements.hasInScope(TAG_ID.FORM)) {\n        p.openElements.generateImpliedEndTags();\n        if (inTemplate) {\n            p.openElements.popUntilTagNamePopped(TAG_ID.FORM);\n        }\n        else if (formElement) {\n            p.openElements.remove(formElement);\n        }\n    }\n}\nfunction pEndTagInBody(p) {\n    if (!p.openElements.hasInButtonScope(TAG_ID.P)) {\n        p._insertFakeElement(TAG_NAMES.P, TAG_ID.P);\n    }\n    p._closePElement();\n}\nfunction liEndTagInBody(p) {\n    if (p.openElements.hasInListItemScope(TAG_ID.LI)) {\n        p.openElements.generateImpliedEndTagsWithExclusion(TAG_ID.LI);\n        p.openElements.popUntilTagNamePopped(TAG_ID.LI);\n    }\n}\nfunction ddEndTagInBody(p, token) {\n    const tn = token.tagID;\n    if (p.openElements.hasInScope(tn)) {\n        p.openElements.generateImpliedEndTagsWithExclusion(tn);\n        p.openElements.popUntilTagNamePopped(tn);\n    }\n}\nfunction numberedHeaderEndTagInBody(p) {\n    if (p.openElements.hasNumberedHeaderInScope()) {\n        p.openElements.generateImpliedEndTags();\n        p.openElements.popUntilNumberedHeaderPopped();\n    }\n}\nfunction appletEndTagInBody(p, token) {\n    const tn = token.tagID;\n    if (p.openElements.hasInScope(tn)) {\n        p.openElements.generateImpliedEndTags();\n        p.openElements.popUntilTagNamePopped(tn);\n        p.activeFormattingElements.clearToLastMarker();\n    }\n}\nfunction brEndTagInBody(p) {\n    p._reconstructActiveFormattingElements();\n    p._insertFakeElement(TAG_NAMES.BR, TAG_ID.BR);\n    p.openElements.pop();\n    p.framesetOk = false;\n}\nfunction genericEndTagInBody(p, token) {\n    const tn = token.tagName;\n    const tid = token.tagID;\n    for (let i = p.openElements.stackTop; i > 0; i--) {\n        const element = p.openElements.items[i];\n        const elementId = p.openElements.tagIDs[i];\n        // Compare the tag name here, as the tag might not be a known tag with an ID.\n        if (tid === elementId && (tid !== TAG_ID.UNKNOWN || p.treeAdapter.getTagName(element) === tn)) {\n            p.openElements.generateImpliedEndTagsWithExclusion(tid);\n            if (p.openElements.stackTop >= i)\n                p.openElements.shortenToLength(i);\n            break;\n        }\n        if (p._isSpecialElement(element, elementId)) {\n            break;\n        }\n    }\n}\nfunction endTagInBody(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.A:\n        case TAG_ID.B:\n        case TAG_ID.I:\n        case TAG_ID.S:\n        case TAG_ID.U:\n        case TAG_ID.EM:\n        case TAG_ID.TT:\n        case TAG_ID.BIG:\n        case TAG_ID.CODE:\n        case TAG_ID.FONT:\n        case TAG_ID.NOBR:\n        case TAG_ID.SMALL:\n        case TAG_ID.STRIKE:\n        case TAG_ID.STRONG: {\n            callAdoptionAgency(p, token);\n            break;\n        }\n        case TAG_ID.P: {\n            pEndTagInBody(p);\n            break;\n        }\n        case TAG_ID.DL:\n        case TAG_ID.UL:\n        case TAG_ID.OL:\n        case TAG_ID.DIR:\n        case TAG_ID.DIV:\n        case TAG_ID.NAV:\n        case TAG_ID.PRE:\n        case TAG_ID.MAIN:\n        case TAG_ID.MENU:\n        case TAG_ID.ASIDE:\n        case TAG_ID.BUTTON:\n        case TAG_ID.CENTER:\n        case TAG_ID.FIGURE:\n        case TAG_ID.FOOTER:\n        case TAG_ID.HEADER:\n        case TAG_ID.HGROUP:\n        case TAG_ID.DIALOG:\n        case TAG_ID.ADDRESS:\n        case TAG_ID.ARTICLE:\n        case TAG_ID.DETAILS:\n        case TAG_ID.SECTION:\n        case TAG_ID.SUMMARY:\n        case TAG_ID.LISTING:\n        case TAG_ID.FIELDSET:\n        case TAG_ID.BLOCKQUOTE:\n        case TAG_ID.FIGCAPTION: {\n            addressEndTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.LI: {\n            liEndTagInBody(p);\n            break;\n        }\n        case TAG_ID.DD:\n        case TAG_ID.DT: {\n            ddEndTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.H1:\n        case TAG_ID.H2:\n        case TAG_ID.H3:\n        case TAG_ID.H4:\n        case TAG_ID.H5:\n        case TAG_ID.H6: {\n            numberedHeaderEndTagInBody(p);\n            break;\n        }\n        case TAG_ID.BR: {\n            brEndTagInBody(p);\n            break;\n        }\n        case TAG_ID.BODY: {\n            bodyEndTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.HTML: {\n            htmlEndTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.FORM: {\n            formEndTagInBody(p);\n            break;\n        }\n        case TAG_ID.APPLET:\n        case TAG_ID.OBJECT:\n        case TAG_ID.MARQUEE: {\n            appletEndTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            templateEndTagInHead(p, token);\n            break;\n        }\n        default: {\n            genericEndTagInBody(p, token);\n        }\n    }\n}\nfunction eofInBody(p, token) {\n    if (p.tmplInsertionModeStack.length > 0) {\n        eofInTemplate(p, token);\n    }\n    else {\n        stopParsing(p, token);\n    }\n}\n// The \"text\" insertion mode\n//------------------------------------------------------------------\nfunction endTagInText(p, token) {\n    var _a;\n    if (token.tagID === TAG_ID.SCRIPT) {\n        (_a = p.scriptHandler) === null || _a === void 0 ? void 0 : _a.call(p, p.openElements.current);\n    }\n    p.openElements.pop();\n    p.insertionMode = p.originalInsertionMode;\n}\nfunction eofInText(p, token) {\n    p._err(token, ERR.eofInElementThatCanContainOnlyText);\n    p.openElements.pop();\n    p.insertionMode = p.originalInsertionMode;\n    p.onEof(token);\n}\n// The \"in table\" insertion mode\n//------------------------------------------------------------------\nfunction characterInTable(p, token) {\n    if (TABLE_STRUCTURE_TAGS.has(p.openElements.currentTagId)) {\n        p.pendingCharacterTokens.length = 0;\n        p.hasNonWhitespacePendingCharacterToken = false;\n        p.originalInsertionMode = p.insertionMode;\n        p.insertionMode = InsertionMode.IN_TABLE_TEXT;\n        switch (token.type) {\n            case TokenType.CHARACTER: {\n                characterInTableText(p, token);\n                break;\n            }\n            case TokenType.WHITESPACE_CHARACTER: {\n                whitespaceCharacterInTableText(p, token);\n                break;\n            }\n            // Ignore null\n        }\n    }\n    else {\n        tokenInTable(p, token);\n    }\n}\nfunction captionStartTagInTable(p, token) {\n    p.openElements.clearBackToTableContext();\n    p.activeFormattingElements.insertMarker();\n    p._insertElement(token, NS.HTML);\n    p.insertionMode = InsertionMode.IN_CAPTION;\n}\nfunction colgroupStartTagInTable(p, token) {\n    p.openElements.clearBackToTableContext();\n    p._insertElement(token, NS.HTML);\n    p.insertionMode = InsertionMode.IN_COLUMN_GROUP;\n}\nfunction colStartTagInTable(p, token) {\n    p.openElements.clearBackToTableContext();\n    p._insertFakeElement(TAG_NAMES.COLGROUP, TAG_ID.COLGROUP);\n    p.insertionMode = InsertionMode.IN_COLUMN_GROUP;\n    startTagInColumnGroup(p, token);\n}\nfunction tbodyStartTagInTable(p, token) {\n    p.openElements.clearBackToTableContext();\n    p._insertElement(token, NS.HTML);\n    p.insertionMode = InsertionMode.IN_TABLE_BODY;\n}\nfunction tdStartTagInTable(p, token) {\n    p.openElements.clearBackToTableContext();\n    p._insertFakeElement(TAG_NAMES.TBODY, TAG_ID.TBODY);\n    p.insertionMode = InsertionMode.IN_TABLE_BODY;\n    startTagInTableBody(p, token);\n}\nfunction tableStartTagInTable(p, token) {\n    if (p.openElements.hasInTableScope(TAG_ID.TABLE)) {\n        p.openElements.popUntilTagNamePopped(TAG_ID.TABLE);\n        p._resetInsertionMode();\n        p._processStartTag(token);\n    }\n}\nfunction inputStartTagInTable(p, token) {\n    if (isHiddenInput(token)) {\n        p._appendElement(token, NS.HTML);\n    }\n    else {\n        tokenInTable(p, token);\n    }\n    token.ackSelfClosing = true;\n}\nfunction formStartTagInTable(p, token) {\n    if (!p.formElement && p.openElements.tmplCount === 0) {\n        p._insertElement(token, NS.HTML);\n        p.formElement = p.openElements.current;\n        p.openElements.pop();\n    }\n}\nfunction startTagInTable(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.TD:\n        case TAG_ID.TH:\n        case TAG_ID.TR: {\n            tdStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.STYLE:\n        case TAG_ID.SCRIPT:\n        case TAG_ID.TEMPLATE: {\n            startTagInHead(p, token);\n            break;\n        }\n        case TAG_ID.COL: {\n            colStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.FORM: {\n            formStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.TABLE: {\n            tableStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD: {\n            tbodyStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.INPUT: {\n            inputStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.CAPTION: {\n            captionStartTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.COLGROUP: {\n            colgroupStartTagInTable(p, token);\n            break;\n        }\n        default: {\n            tokenInTable(p, token);\n        }\n    }\n}\nfunction endTagInTable(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.TABLE: {\n            if (p.openElements.hasInTableScope(TAG_ID.TABLE)) {\n                p.openElements.popUntilTagNamePopped(TAG_ID.TABLE);\n                p._resetInsertionMode();\n            }\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            templateEndTagInHead(p, token);\n            break;\n        }\n        case TAG_ID.BODY:\n        case TAG_ID.CAPTION:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.HTML:\n        case TAG_ID.TBODY:\n        case TAG_ID.TD:\n        case TAG_ID.TFOOT:\n        case TAG_ID.TH:\n        case TAG_ID.THEAD:\n        case TAG_ID.TR: {\n            // Ignore token\n            break;\n        }\n        default: {\n            tokenInTable(p, token);\n        }\n    }\n}\nfunction tokenInTable(p, token) {\n    const savedFosterParentingState = p.fosterParentingEnabled;\n    p.fosterParentingEnabled = true;\n    // Process token in `In Body` mode\n    modeInBody(p, token);\n    p.fosterParentingEnabled = savedFosterParentingState;\n}\n// The \"in table text\" insertion mode\n//------------------------------------------------------------------\nfunction whitespaceCharacterInTableText(p, token) {\n    p.pendingCharacterTokens.push(token);\n}\nfunction characterInTableText(p, token) {\n    p.pendingCharacterTokens.push(token);\n    p.hasNonWhitespacePendingCharacterToken = true;\n}\nfunction tokenInTableText(p, token) {\n    let i = 0;\n    if (p.hasNonWhitespacePendingCharacterToken) {\n        for (; i < p.pendingCharacterTokens.length; i++) {\n            tokenInTable(p, p.pendingCharacterTokens[i]);\n        }\n    }\n    else {\n        for (; i < p.pendingCharacterTokens.length; i++) {\n            p._insertCharacters(p.pendingCharacterTokens[i]);\n        }\n    }\n    p.insertionMode = p.originalInsertionMode;\n    p._processToken(token);\n}\n// The \"in caption\" insertion mode\n//------------------------------------------------------------------\nconst TABLE_VOID_ELEMENTS = new Set([TAG_ID.CAPTION, TAG_ID.COL, TAG_ID.COLGROUP, TAG_ID.TBODY, TAG_ID.TD, TAG_ID.TFOOT, TAG_ID.TH, TAG_ID.THEAD, TAG_ID.TR]);\nfunction startTagInCaption(p, token) {\n    const tn = token.tagID;\n    if (TABLE_VOID_ELEMENTS.has(tn)) {\n        if (p.openElements.hasInTableScope(TAG_ID.CAPTION)) {\n            p.openElements.generateImpliedEndTags();\n            p.openElements.popUntilTagNamePopped(TAG_ID.CAPTION);\n            p.activeFormattingElements.clearToLastMarker();\n            p.insertionMode = InsertionMode.IN_TABLE;\n            startTagInTable(p, token);\n        }\n    }\n    else {\n        startTagInBody(p, token);\n    }\n}\nfunction endTagInCaption(p, token) {\n    const tn = token.tagID;\n    switch (tn) {\n        case TAG_ID.CAPTION:\n        case TAG_ID.TABLE: {\n            if (p.openElements.hasInTableScope(TAG_ID.CAPTION)) {\n                p.openElements.generateImpliedEndTags();\n                p.openElements.popUntilTagNamePopped(TAG_ID.CAPTION);\n                p.activeFormattingElements.clearToLastMarker();\n                p.insertionMode = InsertionMode.IN_TABLE;\n                if (tn === TAG_ID.TABLE) {\n                    endTagInTable(p, token);\n                }\n            }\n            break;\n        }\n        case TAG_ID.BODY:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.HTML:\n        case TAG_ID.TBODY:\n        case TAG_ID.TD:\n        case TAG_ID.TFOOT:\n        case TAG_ID.TH:\n        case TAG_ID.THEAD:\n        case TAG_ID.TR: {\n            // Ignore token\n            break;\n        }\n        default: {\n            endTagInBody(p, token);\n        }\n    }\n}\n// The \"in column group\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInColumnGroup(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.COL: {\n            p._appendElement(token, NS.HTML);\n            token.ackSelfClosing = true;\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            startTagInHead(p, token);\n            break;\n        }\n        default: {\n            tokenInColumnGroup(p, token);\n        }\n    }\n}\nfunction endTagInColumnGroup(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.COLGROUP: {\n            if (p.openElements.currentTagId === TAG_ID.COLGROUP) {\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE;\n            }\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            templateEndTagInHead(p, token);\n            break;\n        }\n        case TAG_ID.COL: {\n            // Ignore token\n            break;\n        }\n        default: {\n            tokenInColumnGroup(p, token);\n        }\n    }\n}\nfunction tokenInColumnGroup(p, token) {\n    if (p.openElements.currentTagId === TAG_ID.COLGROUP) {\n        p.openElements.pop();\n        p.insertionMode = InsertionMode.IN_TABLE;\n        p._processToken(token);\n    }\n}\n// The \"in table body\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInTableBody(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.TR: {\n            p.openElements.clearBackToTableBodyContext();\n            p._insertElement(token, NS.HTML);\n            p.insertionMode = InsertionMode.IN_ROW;\n            break;\n        }\n        case TAG_ID.TH:\n        case TAG_ID.TD: {\n            p.openElements.clearBackToTableBodyContext();\n            p._insertFakeElement(TAG_NAMES.TR, TAG_ID.TR);\n            p.insertionMode = InsertionMode.IN_ROW;\n            startTagInRow(p, token);\n            break;\n        }\n        case TAG_ID.CAPTION:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD: {\n            if (p.openElements.hasTableBodyContextInTableScope()) {\n                p.openElements.clearBackToTableBodyContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE;\n                startTagInTable(p, token);\n            }\n            break;\n        }\n        default: {\n            startTagInTable(p, token);\n        }\n    }\n}\nfunction endTagInTableBody(p, token) {\n    const tn = token.tagID;\n    switch (token.tagID) {\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD: {\n            if (p.openElements.hasInTableScope(tn)) {\n                p.openElements.clearBackToTableBodyContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE;\n            }\n            break;\n        }\n        case TAG_ID.TABLE: {\n            if (p.openElements.hasTableBodyContextInTableScope()) {\n                p.openElements.clearBackToTableBodyContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE;\n                endTagInTable(p, token);\n            }\n            break;\n        }\n        case TAG_ID.BODY:\n        case TAG_ID.CAPTION:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.HTML:\n        case TAG_ID.TD:\n        case TAG_ID.TH:\n        case TAG_ID.TR: {\n            // Ignore token\n            break;\n        }\n        default: {\n            endTagInTable(p, token);\n        }\n    }\n}\n// The \"in row\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInRow(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.TH:\n        case TAG_ID.TD: {\n            p.openElements.clearBackToTableRowContext();\n            p._insertElement(token, NS.HTML);\n            p.insertionMode = InsertionMode.IN_CELL;\n            p.activeFormattingElements.insertMarker();\n            break;\n        }\n        case TAG_ID.CAPTION:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD:\n        case TAG_ID.TR: {\n            if (p.openElements.hasInTableScope(TAG_ID.TR)) {\n                p.openElements.clearBackToTableRowContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE_BODY;\n                startTagInTableBody(p, token);\n            }\n            break;\n        }\n        default: {\n            startTagInTable(p, token);\n        }\n    }\n}\nfunction endTagInRow(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.TR: {\n            if (p.openElements.hasInTableScope(TAG_ID.TR)) {\n                p.openElements.clearBackToTableRowContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE_BODY;\n            }\n            break;\n        }\n        case TAG_ID.TABLE: {\n            if (p.openElements.hasInTableScope(TAG_ID.TR)) {\n                p.openElements.clearBackToTableRowContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE_BODY;\n                endTagInTableBody(p, token);\n            }\n            break;\n        }\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD: {\n            if (p.openElements.hasInTableScope(token.tagID) || p.openElements.hasInTableScope(TAG_ID.TR)) {\n                p.openElements.clearBackToTableRowContext();\n                p.openElements.pop();\n                p.insertionMode = InsertionMode.IN_TABLE_BODY;\n                endTagInTableBody(p, token);\n            }\n            break;\n        }\n        case TAG_ID.BODY:\n        case TAG_ID.CAPTION:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.HTML:\n        case TAG_ID.TD:\n        case TAG_ID.TH: {\n            // Ignore end tag\n            break;\n        }\n        default: {\n            endTagInTable(p, token);\n        }\n    }\n}\n// The \"in cell\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInCell(p, token) {\n    const tn = token.tagID;\n    if (TABLE_VOID_ELEMENTS.has(tn)) {\n        if (p.openElements.hasInTableScope(TAG_ID.TD) || p.openElements.hasInTableScope(TAG_ID.TH)) {\n            p._closeTableCell();\n            startTagInRow(p, token);\n        }\n    }\n    else {\n        startTagInBody(p, token);\n    }\n}\nfunction endTagInCell(p, token) {\n    const tn = token.tagID;\n    switch (tn) {\n        case TAG_ID.TD:\n        case TAG_ID.TH: {\n            if (p.openElements.hasInTableScope(tn)) {\n                p.openElements.generateImpliedEndTags();\n                p.openElements.popUntilTagNamePopped(tn);\n                p.activeFormattingElements.clearToLastMarker();\n                p.insertionMode = InsertionMode.IN_ROW;\n            }\n            break;\n        }\n        case TAG_ID.TABLE:\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD:\n        case TAG_ID.TR: {\n            if (p.openElements.hasInTableScope(tn)) {\n                p._closeTableCell();\n                endTagInRow(p, token);\n            }\n            break;\n        }\n        case TAG_ID.BODY:\n        case TAG_ID.CAPTION:\n        case TAG_ID.COL:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.HTML: {\n            // Ignore token\n            break;\n        }\n        default: {\n            endTagInBody(p, token);\n        }\n    }\n}\n// The \"in select\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInSelect(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.OPTION: {\n            if (p.openElements.currentTagId === TAG_ID.OPTION) {\n                p.openElements.pop();\n            }\n            p._insertElement(token, NS.HTML);\n            break;\n        }\n        case TAG_ID.OPTGROUP: {\n            if (p.openElements.currentTagId === TAG_ID.OPTION) {\n                p.openElements.pop();\n            }\n            if (p.openElements.currentTagId === TAG_ID.OPTGROUP) {\n                p.openElements.pop();\n            }\n            p._insertElement(token, NS.HTML);\n            break;\n        }\n        case TAG_ID.INPUT:\n        case TAG_ID.KEYGEN:\n        case TAG_ID.TEXTAREA:\n        case TAG_ID.SELECT: {\n            if (p.openElements.hasInSelectScope(TAG_ID.SELECT)) {\n                p.openElements.popUntilTagNamePopped(TAG_ID.SELECT);\n                p._resetInsertionMode();\n                if (token.tagID !== TAG_ID.SELECT) {\n                    p._processStartTag(token);\n                }\n            }\n            break;\n        }\n        case TAG_ID.SCRIPT:\n        case TAG_ID.TEMPLATE: {\n            startTagInHead(p, token);\n            break;\n        }\n        // Do nothing\n    }\n}\nfunction endTagInSelect(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.OPTGROUP: {\n            if (p.openElements.stackTop > 0 &&\n                p.openElements.currentTagId === TAG_ID.OPTION &&\n                p.openElements.tagIDs[p.openElements.stackTop - 1] === TAG_ID.OPTGROUP) {\n                p.openElements.pop();\n            }\n            if (p.openElements.currentTagId === TAG_ID.OPTGROUP) {\n                p.openElements.pop();\n            }\n            break;\n        }\n        case TAG_ID.OPTION: {\n            if (p.openElements.currentTagId === TAG_ID.OPTION) {\n                p.openElements.pop();\n            }\n            break;\n        }\n        case TAG_ID.SELECT: {\n            if (p.openElements.hasInSelectScope(TAG_ID.SELECT)) {\n                p.openElements.popUntilTagNamePopped(TAG_ID.SELECT);\n                p._resetInsertionMode();\n            }\n            break;\n        }\n        case TAG_ID.TEMPLATE: {\n            templateEndTagInHead(p, token);\n            break;\n        }\n        // Do nothing\n    }\n}\n// The \"in select in table\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInSelectInTable(p, token) {\n    const tn = token.tagID;\n    if (tn === TAG_ID.CAPTION ||\n        tn === TAG_ID.TABLE ||\n        tn === TAG_ID.TBODY ||\n        tn === TAG_ID.TFOOT ||\n        tn === TAG_ID.THEAD ||\n        tn === TAG_ID.TR ||\n        tn === TAG_ID.TD ||\n        tn === TAG_ID.TH) {\n        p.openElements.popUntilTagNamePopped(TAG_ID.SELECT);\n        p._resetInsertionMode();\n        p._processStartTag(token);\n    }\n    else {\n        startTagInSelect(p, token);\n    }\n}\nfunction endTagInSelectInTable(p, token) {\n    const tn = token.tagID;\n    if (tn === TAG_ID.CAPTION ||\n        tn === TAG_ID.TABLE ||\n        tn === TAG_ID.TBODY ||\n        tn === TAG_ID.TFOOT ||\n        tn === TAG_ID.THEAD ||\n        tn === TAG_ID.TR ||\n        tn === TAG_ID.TD ||\n        tn === TAG_ID.TH) {\n        if (p.openElements.hasInTableScope(tn)) {\n            p.openElements.popUntilTagNamePopped(TAG_ID.SELECT);\n            p._resetInsertionMode();\n            p.onEndTag(token);\n        }\n    }\n    else {\n        endTagInSelect(p, token);\n    }\n}\n// The \"in template\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInTemplate(p, token) {\n    switch (token.tagID) {\n        // First, handle tags that can start without a mode change\n        case TAG_ID.BASE:\n        case TAG_ID.BASEFONT:\n        case TAG_ID.BGSOUND:\n        case TAG_ID.LINK:\n        case TAG_ID.META:\n        case TAG_ID.NOFRAMES:\n        case TAG_ID.SCRIPT:\n        case TAG_ID.STYLE:\n        case TAG_ID.TEMPLATE:\n        case TAG_ID.TITLE: {\n            startTagInHead(p, token);\n            break;\n        }\n        // Re-process the token in the appropriate mode\n        case TAG_ID.CAPTION:\n        case TAG_ID.COLGROUP:\n        case TAG_ID.TBODY:\n        case TAG_ID.TFOOT:\n        case TAG_ID.THEAD: {\n            p.tmplInsertionModeStack[0] = InsertionMode.IN_TABLE;\n            p.insertionMode = InsertionMode.IN_TABLE;\n            startTagInTable(p, token);\n            break;\n        }\n        case TAG_ID.COL: {\n            p.tmplInsertionModeStack[0] = InsertionMode.IN_COLUMN_GROUP;\n            p.insertionMode = InsertionMode.IN_COLUMN_GROUP;\n            startTagInColumnGroup(p, token);\n            break;\n        }\n        case TAG_ID.TR: {\n            p.tmplInsertionModeStack[0] = InsertionMode.IN_TABLE_BODY;\n            p.insertionMode = InsertionMode.IN_TABLE_BODY;\n            startTagInTableBody(p, token);\n            break;\n        }\n        case TAG_ID.TD:\n        case TAG_ID.TH: {\n            p.tmplInsertionModeStack[0] = InsertionMode.IN_ROW;\n            p.insertionMode = InsertionMode.IN_ROW;\n            startTagInRow(p, token);\n            break;\n        }\n        default: {\n            p.tmplInsertionModeStack[0] = InsertionMode.IN_BODY;\n            p.insertionMode = InsertionMode.IN_BODY;\n            startTagInBody(p, token);\n        }\n    }\n}\nfunction endTagInTemplate(p, token) {\n    if (token.tagID === TAG_ID.TEMPLATE) {\n        templateEndTagInHead(p, token);\n    }\n}\nfunction eofInTemplate(p, token) {\n    if (p.openElements.tmplCount > 0) {\n        p.openElements.popUntilTagNamePopped(TAG_ID.TEMPLATE);\n        p.activeFormattingElements.clearToLastMarker();\n        p.tmplInsertionModeStack.shift();\n        p._resetInsertionMode();\n        p.onEof(token);\n    }\n    else {\n        stopParsing(p, token);\n    }\n}\n// The \"after body\" insertion mode\n//------------------------------------------------------------------\nfunction startTagAfterBody(p, token) {\n    if (token.tagID === TAG_ID.HTML) {\n        startTagInBody(p, token);\n    }\n    else {\n        tokenAfterBody(p, token);\n    }\n}\nfunction endTagAfterBody(p, token) {\n    var _a;\n    if (token.tagID === TAG_ID.HTML) {\n        if (!p.fragmentContext) {\n            p.insertionMode = InsertionMode.AFTER_AFTER_BODY;\n        }\n        //NOTE: <html> is never popped from the stack, so we need to updated\n        //the end location explicitly.\n        if (p.options.sourceCodeLocationInfo && p.openElements.tagIDs[0] === TAG_ID.HTML) {\n            p._setEndLocation(p.openElements.items[0], token);\n            // Update the body element, if it doesn't have an end tag\n            const bodyElement = p.openElements.items[1];\n            if (bodyElement && !((_a = p.treeAdapter.getNodeSourceCodeLocation(bodyElement)) === null || _a === void 0 ? void 0 : _a.endTag)) {\n                p._setEndLocation(bodyElement, token);\n            }\n        }\n    }\n    else {\n        tokenAfterBody(p, token);\n    }\n}\nfunction tokenAfterBody(p, token) {\n    p.insertionMode = InsertionMode.IN_BODY;\n    modeInBody(p, token);\n}\n// The \"in frameset\" insertion mode\n//------------------------------------------------------------------\nfunction startTagInFrameset(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.FRAMESET: {\n            p._insertElement(token, NS.HTML);\n            break;\n        }\n        case TAG_ID.FRAME: {\n            p._appendElement(token, NS.HTML);\n            token.ackSelfClosing = true;\n            break;\n        }\n        case TAG_ID.NOFRAMES: {\n            startTagInHead(p, token);\n            break;\n        }\n        // Do nothing\n    }\n}\nfunction endTagInFrameset(p, token) {\n    if (token.tagID === TAG_ID.FRAMESET && !p.openElements.isRootHtmlElementCurrent()) {\n        p.openElements.pop();\n        if (!p.fragmentContext && p.openElements.currentTagId !== TAG_ID.FRAMESET) {\n            p.insertionMode = InsertionMode.AFTER_FRAMESET;\n        }\n    }\n}\n// The \"after frameset\" insertion mode\n//------------------------------------------------------------------\nfunction startTagAfterFrameset(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.NOFRAMES: {\n            startTagInHead(p, token);\n            break;\n        }\n        // Do nothing\n    }\n}\nfunction endTagAfterFrameset(p, token) {\n    if (token.tagID === TAG_ID.HTML) {\n        p.insertionMode = InsertionMode.AFTER_AFTER_FRAMESET;\n    }\n}\n// The \"after after body\" insertion mode\n//------------------------------------------------------------------\nfunction startTagAfterAfterBody(p, token) {\n    if (token.tagID === TAG_ID.HTML) {\n        startTagInBody(p, token);\n    }\n    else {\n        tokenAfterAfterBody(p, token);\n    }\n}\nfunction tokenAfterAfterBody(p, token) {\n    p.insertionMode = InsertionMode.IN_BODY;\n    modeInBody(p, token);\n}\n// The \"after after frameset\" insertion mode\n//------------------------------------------------------------------\nfunction startTagAfterAfterFrameset(p, token) {\n    switch (token.tagID) {\n        case TAG_ID.HTML: {\n            startTagInBody(p, token);\n            break;\n        }\n        case TAG_ID.NOFRAMES: {\n            startTagInHead(p, token);\n            break;\n        }\n        // Do nothing\n    }\n}\n// The rules for parsing tokens in foreign content\n//------------------------------------------------------------------\nfunction nullCharacterInForeignContent(p, token) {\n    token.chars = REPLACEMENT_CHARACTER;\n    p._insertCharacters(token);\n}\nfunction characterInForeignContent(p, token) {\n    p._insertCharacters(token);\n    p.framesetOk = false;\n}\nfunction popUntilHtmlOrIntegrationPoint(p) {\n    while (p.treeAdapter.getNamespaceURI(p.openElements.current) !== NS.HTML &&\n        !p._isIntegrationPoint(p.openElements.currentTagId, p.openElements.current)) {\n        p.openElements.pop();\n    }\n}\nfunction startTagInForeignContent(p, token) {\n    if (causesExit(token)) {\n        popUntilHtmlOrIntegrationPoint(p);\n        p._startTagOutsideForeignContent(token);\n    }\n    else {\n        const current = p._getAdjustedCurrentElement();\n        const currentNs = p.treeAdapter.getNamespaceURI(current);\n        if (currentNs === NS.MATHML) {\n            adjustTokenMathMLAttrs(token);\n        }\n        else if (currentNs === NS.SVG) {\n            adjustTokenSVGTagName(token);\n            adjustTokenSVGAttrs(token);\n        }\n        adjustTokenXMLAttrs(token);\n        if (token.selfClosing) {\n            p._appendElement(token, currentNs);\n        }\n        else {\n            p._insertElement(token, currentNs);\n        }\n        token.ackSelfClosing = true;\n    }\n}\nfunction endTagInForeignContent(p, token) {\n    if (token.tagID === TAG_ID.P || token.tagID === TAG_ID.BR) {\n        popUntilHtmlOrIntegrationPoint(p);\n        p._endTagOutsideForeignContent(token);\n        return;\n    }\n    for (let i = p.openElements.stackTop; i > 0; i--) {\n        const element = p.openElements.items[i];\n        if (p.treeAdapter.getNamespaceURI(element) === NS.HTML) {\n            p._endTagOutsideForeignContent(token);\n            break;\n        }\n        const tagName = p.treeAdapter.getTagName(element);\n        if (tagName.toLowerCase() === token.tagName) {\n            //NOTE: update the token tag name for `_setEndLocation`.\n            token.tagName = tagName;\n            p.openElements.shortenToLength(i);\n            break;\n        }\n    }\n}\n\nfunction getEscaper(regex, map) {\n    return function escape(data) {\n        let match;\n        let lastIdx = 0;\n        let result = \"\";\n        while ((match = regex.exec(data))) {\n            if (lastIdx !== match.index) {\n                result += data.substring(lastIdx, match.index);\n            }\n            // We know that this chararcter will be in the map.\n            result += map.get(match[0].charCodeAt(0));\n            // Every match will be of length 1\n            lastIdx = match.index + 1;\n        }\n        return result + data.substring(lastIdx);\n    };\n}\n/**\n * Encodes all characters that have to be escaped in HTML attributes,\n * following {@link https://html.spec.whatwg.org/multipage/parsing.html#escapingString}.\n *\n * @param data String to escape.\n */\nconst escapeAttribute = getEscaper(/[\"&\\u00A0]/g, new Map([\n    [34, \"&quot;\"],\n    [38, \"&amp;\"],\n    [160, \"&nbsp;\"],\n]));\n/**\n * Encodes all characters that have to be escaped in HTML text,\n * following {@link https://html.spec.whatwg.org/multipage/parsing.html#escapingString}.\n *\n * @param data String to escape.\n */\nconst escapeText = getEscaper(/[&<>\\u00A0]/g, new Map([\n    [38, \"&amp;\"],\n    [60, \"&lt;\"],\n    [62, \"&gt;\"],\n    [160, \"&nbsp;\"],\n]));\n\n// Sets\nconst VOID_ELEMENTS = new Set([\n    TAG_NAMES.AREA,\n    TAG_NAMES.BASE,\n    TAG_NAMES.BASEFONT,\n    TAG_NAMES.BGSOUND,\n    TAG_NAMES.BR,\n    TAG_NAMES.COL,\n    TAG_NAMES.EMBED,\n    TAG_NAMES.FRAME,\n    TAG_NAMES.HR,\n    TAG_NAMES.IMG,\n    TAG_NAMES.INPUT,\n    TAG_NAMES.KEYGEN,\n    TAG_NAMES.LINK,\n    TAG_NAMES.META,\n    TAG_NAMES.PARAM,\n    TAG_NAMES.SOURCE,\n    TAG_NAMES.TRACK,\n    TAG_NAMES.WBR,\n]);\nfunction isVoidElement(node, options) {\n    return (options.treeAdapter.isElementNode(node) &&\n        options.treeAdapter.getNamespaceURI(node) === NS.HTML &&\n        VOID_ELEMENTS.has(options.treeAdapter.getTagName(node)));\n}\nconst defaultOpts = { treeAdapter: defaultTreeAdapter, scriptingEnabled: true };\n/**\n * Serializes an AST node to an HTML string.\n *\n * @example\n *\n * ```js\n * const parse5 = require('parse5');\n *\n * const document = parse5.parse('<!DOCTYPE html><html><head></head><body>Hi there!</body></html>');\n *\n * // Serializes a document.\n * const html = parse5.serialize(document);\n *\n * // Serializes the <html> element content.\n * const str = parse5.serialize(document.childNodes[1]);\n *\n * console.log(str); //> '<head></head><body>Hi there!</body>'\n * ```\n *\n * @param node Node to serialize.\n * @param options Serialization options.\n */\nfunction serialize(node, options) {\n    const opts = { ...defaultOpts, ...options };\n    if (isVoidElement(node, opts)) {\n        return '';\n    }\n    return serializeChildNodes(node, opts);\n}\n/**\n * Serializes an AST element node to an HTML string, including the element node.\n *\n * @example\n *\n * ```js\n * const parse5 = require('parse5');\n *\n * const document = parse5.parseFragment('<div>Hello, <b>world</b>!</div>');\n *\n * // Serializes the <div> element.\n * const html = parse5.serializeOuter(document.childNodes[0]);\n *\n * console.log(str); //> '<div>Hello, <b>world</b>!</div>'\n * ```\n *\n * @param node Node to serialize.\n * @param options Serialization options.\n */\nfunction serializeOuter(node, options) {\n    const opts = { ...defaultOpts, ...options };\n    return serializeNode(node, opts);\n}\nfunction serializeChildNodes(parentNode, options) {\n    let html = '';\n    // Get container of the child nodes\n    const container = options.treeAdapter.isElementNode(parentNode) &&\n        options.treeAdapter.getTagName(parentNode) === TAG_NAMES.TEMPLATE &&\n        options.treeAdapter.getNamespaceURI(parentNode) === NS.HTML\n        ? options.treeAdapter.getTemplateContent(parentNode)\n        : parentNode;\n    const childNodes = options.treeAdapter.getChildNodes(container);\n    if (childNodes) {\n        for (const currentNode of childNodes) {\n            html += serializeNode(currentNode, options);\n        }\n    }\n    return html;\n}\nfunction serializeNode(node, options) {\n    if (options.treeAdapter.isElementNode(node)) {\n        return serializeElement(node, options);\n    }\n    if (options.treeAdapter.isTextNode(node)) {\n        return serializeTextNode(node, options);\n    }\n    if (options.treeAdapter.isCommentNode(node)) {\n        return serializeCommentNode(node, options);\n    }\n    if (options.treeAdapter.isDocumentTypeNode(node)) {\n        return serializeDocumentTypeNode(node, options);\n    }\n    // Return an empty string for unknown nodes\n    return '';\n}\nfunction serializeElement(node, options) {\n    const tn = options.treeAdapter.getTagName(node);\n    return `<${tn}${serializeAttributes(node, options)}>${isVoidElement(node, options) ? '' : `${serializeChildNodes(node, options)}</${tn}>`}`;\n}\nfunction serializeAttributes(node, { treeAdapter }) {\n    let html = '';\n    for (const attr of treeAdapter.getAttrList(node)) {\n        html += ' ';\n        if (!attr.namespace) {\n            html += attr.name;\n        }\n        else\n            switch (attr.namespace) {\n                case NS.XML: {\n                    html += `xml:${attr.name}`;\n                    break;\n                }\n                case NS.XMLNS: {\n                    if (attr.name !== 'xmlns') {\n                        html += 'xmlns:';\n                    }\n                    html += attr.name;\n                    break;\n                }\n                case NS.XLINK: {\n                    html += `xlink:${attr.name}`;\n                    break;\n                }\n                default: {\n                    html += `${attr.prefix}:${attr.name}`;\n                }\n            }\n        html += `=\"${escapeAttribute(attr.value)}\"`;\n    }\n    return html;\n}\nfunction serializeTextNode(node, options) {\n    const { treeAdapter } = options;\n    const content = treeAdapter.getTextNodeContent(node);\n    const parent = treeAdapter.getParentNode(node);\n    const parentTn = parent && treeAdapter.isElementNode(parent) && treeAdapter.getTagName(parent);\n    return parentTn &&\n        treeAdapter.getNamespaceURI(parent) === NS.HTML &&\n        hasUnescapedText(parentTn, options.scriptingEnabled)\n        ? content\n        : escapeText(content);\n}\nfunction serializeCommentNode(node, { treeAdapter }) {\n    return `<!--${treeAdapter.getCommentNodeContent(node)}-->`;\n}\nfunction serializeDocumentTypeNode(node, { treeAdapter }) {\n    return `<!DOCTYPE ${treeAdapter.getDocumentTypeNodeName(node)}>`;\n}\n\n// Shorthands\n/**\n * Parses an HTML string.\n *\n * @param html Input HTML string.\n * @param options Parsing options.\n * @returns Document\n *\n * @example\n *\n * ```js\n * const parse5 = require('parse5');\n *\n * const document = parse5.parse('<!DOCTYPE html><html><head></head><body>Hi there!</body></html>');\n *\n * console.log(document.childNodes[1].tagName); //> 'html'\n *```\n */\nfunction parse(html, options) {\n    return Parser.parse(html, options);\n}\nfunction parseFragment(fragmentContext, html, options) {\n    if (typeof fragmentContext === 'string') {\n        options = html;\n        html = fragmentContext;\n        fragmentContext = null;\n    }\n    const parser = Parser.getFragmentParser(fragmentContext, options);\n    parser.tokenizer.write(html, true);\n    return parser.getFragment();\n}\n\nexport { ERR as ErrorCodes, Parser, token as Token, Tokenizer, TokenizerMode, defaultTreeAdapter, foreignContent, html, parse, parseFragment, serialize, serializeOuter };\n"}},"dep-ace95160.js":{"file":{"contents":"import { fileURLToPath as __cjs_fileURLToPath } from 'node:url';\nimport { dirname as __cjs_dirname } from 'node:path';\nimport { createRequire as __cjs_createRequire } from 'node:module';\n\nconst __filename = __cjs_fileURLToPath(import.meta.url);\nconst __dirname = __cjs_dirname(__filename);\nconst require = __cjs_createRequire(import.meta.url);\nconst __require = require;\nvar commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};\n\nfunction getDefaultExportFromCjs (x) {\n\treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n}\n\nfunction getAugmentedNamespace(n) {\n  if (n.__esModule) return n;\n  var f = n.default;\n\tif (typeof f == \"function\") {\n\t\tvar a = function a () {\n\t\t\tif (this instanceof a) {\n\t\t\t\tvar args = [null];\n\t\t\t\targs.push.apply(args, arguments);\n\t\t\t\tvar Ctor = Function.bind.apply(f, args);\n\t\t\t\treturn new Ctor();\n\t\t\t}\n\t\t\treturn f.apply(this, arguments);\n\t\t};\n\t\ta.prototype = f.prototype;\n  } else a = {};\n  Object.defineProperty(a, '__esModule', {value: true});\n\tObject.keys(n).forEach(function (k) {\n\t\tvar d = Object.getOwnPropertyDescriptor(n, k);\n\t\tObject.defineProperty(a, k, d.get ? d : {\n\t\t\tenumerable: true,\n\t\t\tget: function () {\n\t\t\t\treturn n[k];\n\t\t\t}\n\t\t});\n\t});\n\treturn a;\n}\n\nexport { getAugmentedNamespace as a, commonjsGlobal as c, getDefaultExportFromCjs as g };\n"}},"dep-c423598f.js":{"file":{"contents":"import { fileURLToPath as __cjs_fileURLToPath } from 'node:url';\nimport { dirname as __cjs_dirname } from 'node:path';\nimport { createRequire as __cjs_createRequire } from 'node:module';\n\nconst __filename = __cjs_fileURLToPath(import.meta.url);\nconst __dirname = __cjs_dirname(__filename);\nconst require = __cjs_createRequire(import.meta.url);\nconst __require = require;\nvar openParentheses = \"(\".charCodeAt(0);\nvar closeParentheses = \")\".charCodeAt(0);\nvar singleQuote = \"'\".charCodeAt(0);\nvar doubleQuote = '\"'.charCodeAt(0);\nvar backslash = \"\\\\\".charCodeAt(0);\nvar slash = \"/\".charCodeAt(0);\nvar comma = \",\".charCodeAt(0);\nvar colon = \":\".charCodeAt(0);\nvar star = \"*\".charCodeAt(0);\nvar uLower = \"u\".charCodeAt(0);\nvar uUpper = \"U\".charCodeAt(0);\nvar plus = \"+\".charCodeAt(0);\nvar isUnicodeRange = /^[a-f0-9?-]+$/i;\n\nvar parse$1 = function(input) {\n  var tokens = [];\n  var value = input;\n\n  var next,\n    quote,\n    prev,\n    token,\n    escape,\n    escapePos,\n    whitespacePos,\n    parenthesesOpenPos;\n  var pos = 0;\n  var code = value.charCodeAt(pos);\n  var max = value.length;\n  var stack = [{ nodes: tokens }];\n  var balanced = 0;\n  var parent;\n\n  var name = \"\";\n  var before = \"\";\n  var after = \"\";\n\n  while (pos < max) {\n    // Whitespaces\n    if (code <= 32) {\n      next = pos;\n      do {\n        next += 1;\n        code = value.charCodeAt(next);\n      } while (code <= 32);\n      token = value.slice(pos, next);\n\n      prev = tokens[tokens.length - 1];\n      if (code === closeParentheses && balanced) {\n        after = token;\n      } else if (prev && prev.type === \"div\") {\n        prev.after = token;\n        prev.sourceEndIndex += token.length;\n      } else if (\n        code === comma ||\n        code === colon ||\n        (code === slash &&\n          value.charCodeAt(next + 1) !== star &&\n          (!parent ||\n            (parent && parent.type === \"function\" && parent.value !== \"calc\")))\n      ) {\n        before = token;\n      } else {\n        tokens.push({\n          type: \"space\",\n          sourceIndex: pos,\n          sourceEndIndex: next,\n          value: token\n        });\n      }\n\n      pos = next;\n\n      // Quotes\n    } else if (code === singleQuote || code === doubleQuote) {\n      next = pos;\n      quote = code === singleQuote ? \"'\" : '\"';\n      token = {\n        type: \"string\",\n        sourceIndex: pos,\n        quote: quote\n      };\n      do {\n        escape = false;\n        next = value.indexOf(quote, next + 1);\n        if (~next) {\n          escapePos = next;\n          while (value.charCodeAt(escapePos - 1) === backslash) {\n            escapePos -= 1;\n            escape = !escape;\n          }\n        } else {\n          value += quote;\n          next = value.length - 1;\n          token.unclosed = true;\n        }\n      } while (escape);\n      token.value = value.slice(pos + 1, next);\n      token.sourceEndIndex = token.unclosed ? next : next + 1;\n      tokens.push(token);\n      pos = next + 1;\n      code = value.charCodeAt(pos);\n\n      // Comments\n    } else if (code === slash && value.charCodeAt(pos + 1) === star) {\n      next = value.indexOf(\"*/\", pos);\n\n      token = {\n        type: \"comment\",\n        sourceIndex: pos,\n        sourceEndIndex: next + 2\n      };\n\n      if (next === -1) {\n        token.unclosed = true;\n        next = value.length;\n        token.sourceEndIndex = next;\n      }\n\n      token.value = value.slice(pos + 2, next);\n      tokens.push(token);\n\n      pos = next + 2;\n      code = value.charCodeAt(pos);\n\n      // Operation within calc\n    } else if (\n      (code === slash || code === star) &&\n      parent &&\n      parent.type === \"function\" &&\n      parent.value === \"calc\"\n    ) {\n      token = value[pos];\n      tokens.push({\n        type: \"word\",\n        sourceIndex: pos - before.length,\n        sourceEndIndex: pos + token.length,\n        value: token\n      });\n      pos += 1;\n      code = value.charCodeAt(pos);\n\n      // Dividers\n    } else if (code === slash || code === comma || code === colon) {\n      token = value[pos];\n\n      tokens.push({\n        type: \"div\",\n        sourceIndex: pos - before.length,\n        sourceEndIndex: pos + token.length,\n        value: token,\n        before: before,\n        after: \"\"\n      });\n      before = \"\";\n\n      pos += 1;\n      code = value.charCodeAt(pos);\n\n      // Open parentheses\n    } else if (openParentheses === code) {\n      // Whitespaces after open parentheses\n      next = pos;\n      do {\n        next += 1;\n        code = value.charCodeAt(next);\n      } while (code <= 32);\n      parenthesesOpenPos = pos;\n      token = {\n        type: \"function\",\n        sourceIndex: pos - name.length,\n        value: name,\n        before: value.slice(parenthesesOpenPos + 1, next)\n      };\n      pos = next;\n\n      if (name === \"url\" && code !== singleQuote && code !== doubleQuote) {\n        next -= 1;\n        do {\n          escape = false;\n          next = value.indexOf(\")\", next + 1);\n          if (~next) {\n            escapePos = next;\n            while (value.charCodeAt(escapePos - 1) === backslash) {\n              escapePos -= 1;\n              escape = !escape;\n            }\n          } else {\n            value += \")\";\n            next = value.length - 1;\n            token.unclosed = true;\n          }\n        } while (escape);\n        // Whitespaces before closed\n        whitespacePos = next;\n        do {\n          whitespacePos -= 1;\n          code = value.charCodeAt(whitespacePos);\n        } while (code <= 32);\n        if (parenthesesOpenPos < whitespacePos) {\n          if (pos !== whitespacePos + 1) {\n            token.nodes = [\n              {\n                type: \"word\",\n                sourceIndex: pos,\n                sourceEndIndex: whitespacePos + 1,\n                value: value.slice(pos, whitespacePos + 1)\n              }\n            ];\n          } else {\n            token.nodes = [];\n          }\n          if (token.unclosed && whitespacePos + 1 !== next) {\n            token.after = \"\";\n            token.nodes.push({\n              type: \"space\",\n              sourceIndex: whitespacePos + 1,\n              sourceEndIndex: next,\n              value: value.slice(whitespacePos + 1, next)\n            });\n          } else {\n            token.after = value.slice(whitespacePos + 1, next);\n            token.sourceEndIndex = next;\n          }\n        } else {\n          token.after = \"\";\n          token.nodes = [];\n        }\n        pos = next + 1;\n        token.sourceEndIndex = token.unclosed ? next : pos;\n        code = value.charCodeAt(pos);\n        tokens.push(token);\n      } else {\n        balanced += 1;\n        token.after = \"\";\n        token.sourceEndIndex = pos + 1;\n        tokens.push(token);\n        stack.push(token);\n        tokens = token.nodes = [];\n        parent = token;\n      }\n      name = \"\";\n\n      // Close parentheses\n    } else if (closeParentheses === code && balanced) {\n      pos += 1;\n      code = value.charCodeAt(pos);\n\n      parent.after = after;\n      parent.sourceEndIndex += after.length;\n      after = \"\";\n      balanced -= 1;\n      stack[stack.length - 1].sourceEndIndex = pos;\n      stack.pop();\n      parent = stack[balanced];\n      tokens = parent.nodes;\n\n      // Words\n    } else {\n      next = pos;\n      do {\n        if (code === backslash) {\n          next += 1;\n        }\n        next += 1;\n        code = value.charCodeAt(next);\n      } while (\n        next < max &&\n        !(\n          code <= 32 ||\n          code === singleQuote ||\n          code === doubleQuote ||\n          code === comma ||\n          code === colon ||\n          code === slash ||\n          code === openParentheses ||\n          (code === star &&\n            parent &&\n            parent.type === \"function\" &&\n            parent.value === \"calc\") ||\n          (code === slash &&\n            parent.type === \"function\" &&\n            parent.value === \"calc\") ||\n          (code === closeParentheses && balanced)\n        )\n      );\n      token = value.slice(pos, next);\n\n      if (openParentheses === code) {\n        name = token;\n      } else if (\n        (uLower === token.charCodeAt(0) || uUpper === token.charCodeAt(0)) &&\n        plus === token.charCodeAt(1) &&\n        isUnicodeRange.test(token.slice(2))\n      ) {\n        tokens.push({\n          type: \"unicode-range\",\n          sourceIndex: pos,\n          sourceEndIndex: next,\n          value: token\n        });\n      } else {\n        tokens.push({\n          type: \"word\",\n          sourceIndex: pos,\n          sourceEndIndex: next,\n          value: token\n        });\n      }\n\n      pos = next;\n    }\n  }\n\n  for (pos = stack.length - 1; pos; pos -= 1) {\n    stack[pos].unclosed = true;\n    stack[pos].sourceEndIndex = value.length;\n  }\n\n  return stack[0].nodes;\n};\n\nvar walk$1 = function walk(nodes, cb, bubble) {\n  var i, max, node, result;\n\n  for (i = 0, max = nodes.length; i < max; i += 1) {\n    node = nodes[i];\n    if (!bubble) {\n      result = cb(node, i, nodes);\n    }\n\n    if (\n      result !== false &&\n      node.type === \"function\" &&\n      Array.isArray(node.nodes)\n    ) {\n      walk(node.nodes, cb, bubble);\n    }\n\n    if (bubble) {\n      cb(node, i, nodes);\n    }\n  }\n};\n\nfunction stringifyNode(node, custom) {\n  var type = node.type;\n  var value = node.value;\n  var buf;\n  var customResult;\n\n  if (custom && (customResult = custom(node)) !== undefined) {\n    return customResult;\n  } else if (type === \"word\" || type === \"space\") {\n    return value;\n  } else if (type === \"string\") {\n    buf = node.quote || \"\";\n    return buf + value + (node.unclosed ? \"\" : buf);\n  } else if (type === \"comment\") {\n    return \"/*\" + value + (node.unclosed ? \"\" : \"*/\");\n  } else if (type === \"div\") {\n    return (node.before || \"\") + value + (node.after || \"\");\n  } else if (Array.isArray(node.nodes)) {\n    buf = stringify$1(node.nodes, custom);\n    if (type !== \"function\") {\n      return buf;\n    }\n    return (\n      value +\n      \"(\" +\n      (node.before || \"\") +\n      buf +\n      (node.after || \"\") +\n      (node.unclosed ? \"\" : \")\")\n    );\n  }\n  return value;\n}\n\nfunction stringify$1(nodes, custom) {\n  var result, i;\n\n  if (Array.isArray(nodes)) {\n    result = \"\";\n    for (i = nodes.length - 1; ~i; i -= 1) {\n      result = stringifyNode(nodes[i], custom) + result;\n    }\n    return result;\n  }\n  return stringifyNode(nodes, custom);\n}\n\nvar stringify_1 = stringify$1;\n\nvar unit;\nvar hasRequiredUnit;\n\nfunction requireUnit () {\n\tif (hasRequiredUnit) return unit;\n\thasRequiredUnit = 1;\n\tvar minus = \"-\".charCodeAt(0);\n\tvar plus = \"+\".charCodeAt(0);\n\tvar dot = \".\".charCodeAt(0);\n\tvar exp = \"e\".charCodeAt(0);\n\tvar EXP = \"E\".charCodeAt(0);\n\n\t// Check if three code points would start a number\n\t// https://www.w3.org/TR/css-syntax-3/#starts-with-a-number\n\tfunction likeNumber(value) {\n\t  var code = value.charCodeAt(0);\n\t  var nextCode;\n\n\t  if (code === plus || code === minus) {\n\t    nextCode = value.charCodeAt(1);\n\n\t    if (nextCode >= 48 && nextCode <= 57) {\n\t      return true;\n\t    }\n\n\t    var nextNextCode = value.charCodeAt(2);\n\n\t    if (nextCode === dot && nextNextCode >= 48 && nextNextCode <= 57) {\n\t      return true;\n\t    }\n\n\t    return false;\n\t  }\n\n\t  if (code === dot) {\n\t    nextCode = value.charCodeAt(1);\n\n\t    if (nextCode >= 48 && nextCode <= 57) {\n\t      return true;\n\t    }\n\n\t    return false;\n\t  }\n\n\t  if (code >= 48 && code <= 57) {\n\t    return true;\n\t  }\n\n\t  return false;\n\t}\n\n\t// Consume a number\n\t// https://www.w3.org/TR/css-syntax-3/#consume-number\n\tunit = function(value) {\n\t  var pos = 0;\n\t  var length = value.length;\n\t  var code;\n\t  var nextCode;\n\t  var nextNextCode;\n\n\t  if (length === 0 || !likeNumber(value)) {\n\t    return false;\n\t  }\n\n\t  code = value.charCodeAt(pos);\n\n\t  if (code === plus || code === minus) {\n\t    pos++;\n\t  }\n\n\t  while (pos < length) {\n\t    code = value.charCodeAt(pos);\n\n\t    if (code < 48 || code > 57) {\n\t      break;\n\t    }\n\n\t    pos += 1;\n\t  }\n\n\t  code = value.charCodeAt(pos);\n\t  nextCode = value.charCodeAt(pos + 1);\n\n\t  if (code === dot && nextCode >= 48 && nextCode <= 57) {\n\t    pos += 2;\n\n\t    while (pos < length) {\n\t      code = value.charCodeAt(pos);\n\n\t      if (code < 48 || code > 57) {\n\t        break;\n\t      }\n\n\t      pos += 1;\n\t    }\n\t  }\n\n\t  code = value.charCodeAt(pos);\n\t  nextCode = value.charCodeAt(pos + 1);\n\t  nextNextCode = value.charCodeAt(pos + 2);\n\n\t  if (\n\t    (code === exp || code === EXP) &&\n\t    ((nextCode >= 48 && nextCode <= 57) ||\n\t      ((nextCode === plus || nextCode === minus) &&\n\t        nextNextCode >= 48 &&\n\t        nextNextCode <= 57))\n\t  ) {\n\t    pos += nextCode === plus || nextCode === minus ? 3 : 2;\n\n\t    while (pos < length) {\n\t      code = value.charCodeAt(pos);\n\n\t      if (code < 48 || code > 57) {\n\t        break;\n\t      }\n\n\t      pos += 1;\n\t    }\n\t  }\n\n\t  return {\n\t    number: value.slice(0, pos),\n\t    unit: value.slice(pos)\n\t  };\n\t};\n\treturn unit;\n}\n\nvar parse = parse$1;\nvar walk = walk$1;\nvar stringify = stringify_1;\n\nfunction ValueParser(value) {\n  if (this instanceof ValueParser) {\n    this.nodes = parse(value);\n    return this;\n  }\n  return new ValueParser(value);\n}\n\nValueParser.prototype.toString = function() {\n  return Array.isArray(this.nodes) ? stringify(this.nodes) : \"\";\n};\n\nValueParser.prototype.walk = function(cb, bubble) {\n  walk(this.nodes, cb, bubble);\n  return this;\n};\n\nValueParser.unit = requireUnit();\n\nValueParser.walk = walk;\n\nValueParser.stringify = stringify;\n\nvar lib = ValueParser;\n\nexport { lib as l };\n"}},"dep-ca21228b.js":{"file":{"contents":"import fs$l, { promises as promises$2 } from 'node:fs';\nimport path$o, { posix as posix$1, isAbsolute as isAbsolute$2, join as join$2, relative as relative$2, dirname as dirname$2, basename as basename$2, extname as extname$1 } from 'node:path';\nimport { URL as URL$3, URLSearchParams, parse as parse$i, pathToFileURL } from 'node:url';\nimport { performance } from 'node:perf_hooks';\nimport { createRequire as createRequire$1, builtinModules } from 'node:module';\nimport require$$0$3 from 'tty';\nimport { transform as transform$2, formatMessages, build as build$3 } from 'esbuild';\nimport require$$0$4, { win32, posix, isAbsolute as isAbsolute$1, resolve as resolve$3, relative as relative$1, basename as basename$1, extname, dirname as dirname$1, join as join$1, sep, normalize } from 'path';\nimport { g as getDefaultExportFromCjs, c as commonjsGlobal, a as getAugmentedNamespace } from './dep-ace95160.js';\nimport * as require$$0$2 from 'fs';\nimport require$$0__default, { existsSync, readFileSync, statSync as statSync$1, promises as promises$1, readdirSync } from 'fs';\nimport require$$0$5 from 'events';\nimport require$$5 from 'assert';\nimport require$$0$6 from 'util';\nimport require$$3$2 from 'net';\nimport require$$0$9 from 'url';\nimport require$$1$1 from 'http';\nimport require$$0$7 from 'stream';\nimport require$$2 from 'os';\nimport require$$2$1 from 'child_process';\nimport os$3 from 'node:os';\nimport { createHash as createHash$2 } from 'node:crypto';\nimport { promisify as promisify$4, format as format$2, inspect } from 'node:util';\nimport { promises } from 'node:dns';\nimport resolve$4 from 'resolve';\nimport { CLIENT_ENTRY, OPTIMIZABLE_ENTRY_RE, DEFAULT_EXTENSIONS as DEFAULT_EXTENSIONS$1, wildcardHosts, loopbackHosts, VALID_ID_PREFIX, NULL_BYTE_PLACEHOLDER, FS_PREFIX, CLIENT_PUBLIC_PATH, ENV_PUBLIC_PATH, ENV_ENTRY, DEFAULT_MAIN_FIELDS, SPECIAL_QUERY_RE, DEP_VERSION_RE, KNOWN_ASSET_TYPES, CSS_LANGS_RE, CLIENT_DIR, JS_TYPES_RE, ESBUILD_MODULES_TARGET, VERSION as VERSION$1, VITE_PACKAGE_DIR, DEFAULT_DEV_PORT, DEFAULT_PREVIEW_PORT, DEFAULT_ASSETS_RE, DEFAULT_CONFIG_FILES } from '../constants.js';\nimport require$$5$1 from 'crypto';\nimport { Buffer as Buffer$1 } from 'node:buffer';\nimport require$$0$8, { createRequire as createRequire$2 } from 'module';\nimport assert$1 from 'node:assert';\nimport process$1 from 'node:process';\nimport v8 from 'node:v8';\nimport require$$1 from 'worker_threads';\nimport require$$0$a from 'zlib';\nimport require$$0$b from 'buffer';\nimport require$$1$2 from 'https';\nimport require$$4 from 'tls';\nimport { STATUS_CODES } from 'node:http';\nimport { createServer as createServer$2 } from 'node:https';\nimport { VERSION } from 'rollup';\nimport * as qs from 'querystring';\nimport { execSync } from 'node:child_process';\nimport readline from 'node:readline';\nimport zlib$1, { gzip } from 'node:zlib';\n\nimport { fileURLToPath as __cjs_fileURLToPath } from 'node:url';\nimport { dirname as __cjs_dirname } from 'node:path';\nimport { createRequire as __cjs_createRequire } from 'node:module';\n\nconst __filename = __cjs_fileURLToPath(import.meta.url);\nconst __dirname = __cjs_dirname(__filename);\nconst require = __cjs_createRequire(import.meta.url);\nconst __require = require;\nvar picocolorsExports = {};\nvar picocolors = {\n  get exports(){ return picocolorsExports; },\n  set exports(v){ picocolorsExports = v; },\n};\n\nlet tty = require$$0$3;\n\nlet isColorSupported =\n\t!(\"NO_COLOR\" in process.env || process.argv.includes(\"--no-color\")) &&\n\t(\"FORCE_COLOR\" in process.env ||\n\t\tprocess.argv.includes(\"--color\") ||\n\t\tprocess.platform === \"win32\" ||\n\t\t(tty.isatty(1) && process.env.TERM !== \"dumb\") ||\n\t\t\"CI\" in process.env);\n\nlet formatter =\n\t(open, close, replace = open) =>\n\tinput => {\n\t\tlet string = \"\" + input;\n\t\tlet index = string.indexOf(close, open.length);\n\t\treturn ~index\n\t\t\t? open + replaceClose(string, close, replace, index) + close\n\t\t\t: open + string + close\n\t};\n\nlet replaceClose = (string, close, replace, index) => {\n\tlet start = string.substring(0, index) + replace;\n\tlet end = string.substring(index + close.length);\n\tlet nextIndex = end.indexOf(close);\n\treturn ~nextIndex ? start + replaceClose(end, close, replace, nextIndex) : start + end\n};\n\nlet createColors = (enabled = isColorSupported) => ({\n\tisColorSupported: enabled,\n\treset: enabled ? s => `\\x1b[0m${s}\\x1b[0m` : String,\n\tbold: enabled ? formatter(\"\\x1b[1m\", \"\\x1b[22m\", \"\\x1b[22m\\x1b[1m\") : String,\n\tdim: enabled ? formatter(\"\\x1b[2m\", \"\\x1b[22m\", \"\\x1b[22m\\x1b[2m\") : String,\n\titalic: enabled ? formatter(\"\\x1b[3m\", \"\\x1b[23m\") : String,\n\tunderline: enabled ? formatter(\"\\x1b[4m\", \"\\x1b[24m\") : String,\n\tinverse: enabled ? formatter(\"\\x1b[7m\", \"\\x1b[27m\") : String,\n\thidden: enabled ? formatter(\"\\x1b[8m\", \"\\x1b[28m\") : String,\n\tstrikethrough: enabled ? formatter(\"\\x1b[9m\", \"\\x1b[29m\") : String,\n\tblack: enabled ? formatter(\"\\x1b[30m\", \"\\x1b[39m\") : String,\n\tred: enabled ? formatter(\"\\x1b[31m\", \"\\x1b[39m\") : String,\n\tgreen: enabled ? formatter(\"\\x1b[32m\", \"\\x1b[39m\") : String,\n\tyellow: enabled ? formatter(\"\\x1b[33m\", \"\\x1b[39m\") : String,\n\tblue: enabled ? formatter(\"\\x1b[34m\", \"\\x1b[39m\") : String,\n\tmagenta: enabled ? formatter(\"\\x1b[35m\", \"\\x1b[39m\") : String,\n\tcyan: enabled ? formatter(\"\\x1b[36m\", \"\\x1b[39m\") : String,\n\twhite: enabled ? formatter(\"\\x1b[37m\", \"\\x1b[39m\") : String,\n\tgray: enabled ? formatter(\"\\x1b[90m\", \"\\x1b[39m\") : String,\n\tbgBlack: enabled ? formatter(\"\\x1b[40m\", \"\\x1b[49m\") : String,\n\tbgRed: enabled ? formatter(\"\\x1b[41m\", \"\\x1b[49m\") : String,\n\tbgGreen: enabled ? formatter(\"\\x1b[42m\", \"\\x1b[49m\") : String,\n\tbgYellow: enabled ? formatter(\"\\x1b[43m\", \"\\x1b[49m\") : String,\n\tbgBlue: enabled ? formatter(\"\\x1b[44m\", \"\\x1b[49m\") : String,\n\tbgMagenta: enabled ? formatter(\"\\x1b[45m\", \"\\x1b[49m\") : String,\n\tbgCyan: enabled ? formatter(\"\\x1b[46m\", \"\\x1b[49m\") : String,\n\tbgWhite: enabled ? formatter(\"\\x1b[47m\", \"\\x1b[49m\") : String,\n});\n\npicocolors.exports = createColors();\npicocolorsExports.createColors = createColors;\n\nfunction matches$1(pattern, importee) {\n    if (pattern instanceof RegExp) {\n        return pattern.test(importee);\n    }\n    if (importee.length < pattern.length) {\n        return false;\n    }\n    if (importee === pattern) {\n        return true;\n    }\n    // eslint-disable-next-line prefer-template\n    return importee.startsWith(pattern + '/');\n}\nfunction getEntries({ entries, customResolver }) {\n    if (!entries) {\n        return [];\n    }\n    const resolverFunctionFromOptions = resolveCustomResolver(customResolver);\n    if (Array.isArray(entries)) {\n        return entries.map((entry) => {\n            return {\n                find: entry.find,\n                replacement: entry.replacement,\n                resolverFunction: resolveCustomResolver(entry.customResolver) || resolverFunctionFromOptions\n            };\n        });\n    }\n    return Object.entries(entries).map(([key, value]) => {\n        return { find: key, replacement: value, resolverFunction: resolverFunctionFromOptions };\n    });\n}\nfunction getHookFunction(hook) {\n    if (typeof hook === 'function') {\n        return hook;\n    }\n    if (hook && 'handler' in hook && typeof hook.handler === 'function') {\n        return hook.handler;\n    }\n    return null;\n}\nfunction resolveCustomResolver(customResolver) {\n    if (typeof customResolver === 'function') {\n        return customResolver;\n    }\n    if (customResolver) {\n        return getHookFunction(customResolver.resolveId);\n    }\n    return null;\n}\nfunction alias$1(options = {}) {\n    const entries = getEntries(options);\n    if (entries.length === 0) {\n        return {\n            name: 'alias',\n            resolveId: () => null\n        };\n    }\n    return {\n        name: 'alias',\n        async buildStart(inputOptions) {\n            await Promise.all([...(Array.isArray(options.entries) ? options.entries : []), options].map(({ customResolver }) => { var _a; return customResolver && ((_a = getHookFunction(customResolver.buildStart)) === null || _a === void 0 ? void 0 : _a.call(this, inputOptions)); }));\n        },\n        resolveId(importee, importer, resolveOptions) {\n            if (!importer) {\n                return null;\n            }\n            // First match is supposed to be the correct one\n            const matchedEntry = entries.find((entry) => matches$1(entry.find, importee));\n            if (!matchedEntry) {\n                return null;\n            }\n            const updatedId = importee.replace(matchedEntry.find, matchedEntry.replacement);\n            if (matchedEntry.resolverFunction) {\n                return matchedEntry.resolverFunction.call(this, updatedId, importer, resolveOptions);\n            }\n            return this.resolve(updatedId, importer, Object.assign({ skipSelf: true }, resolveOptions)).then((resolved) => resolved || { id: updatedId });\n        }\n    };\n}\n\n// @ts-check\n/** @typedef { import('estree').BaseNode} BaseNode */\n\n/** @typedef {{\n\tskip: () => void;\n\tremove: () => void;\n\treplace: (node: BaseNode) => void;\n}} WalkerContext */\n\nlet WalkerBase$1 = class WalkerBase {\n\tconstructor() {\n\t\t/** @type {boolean} */\n\t\tthis.should_skip = false;\n\n\t\t/** @type {boolean} */\n\t\tthis.should_remove = false;\n\n\t\t/** @type {BaseNode | null} */\n\t\tthis.replacement = null;\n\n\t\t/** @type {WalkerContext} */\n\t\tthis.context = {\n\t\t\tskip: () => (this.should_skip = true),\n\t\t\tremove: () => (this.should_remove = true),\n\t\t\treplace: (node) => (this.replacement = node)\n\t\t};\n\t}\n\n\t/**\n\t *\n\t * @param {any} parent\n\t * @param {string} prop\n\t * @param {number} index\n\t * @param {BaseNode} node\n\t */\n\treplace(parent, prop, index, node) {\n\t\tif (parent) {\n\t\t\tif (index !== null) {\n\t\t\t\tparent[prop][index] = node;\n\t\t\t} else {\n\t\t\t\tparent[prop] = node;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t *\n\t * @param {any} parent\n\t * @param {string} prop\n\t * @param {number} index\n\t */\n\tremove(parent, prop, index) {\n\t\tif (parent) {\n\t\t\tif (index !== null) {\n\t\t\t\tparent[prop].splice(index, 1);\n\t\t\t} else {\n\t\t\t\tdelete parent[prop];\n\t\t\t}\n\t\t}\n\t}\n};\n\n// @ts-check\n\n/** @typedef { import('estree').BaseNode} BaseNode */\n/** @typedef { import('./walker.js').WalkerContext} WalkerContext */\n\n/** @typedef {(\n *    this: WalkerContext,\n *    node: BaseNode,\n *    parent: BaseNode,\n *    key: string,\n *    index: number\n * ) => void} SyncHandler */\n\nlet SyncWalker$1 = class SyncWalker extends WalkerBase$1 {\n\t/**\n\t *\n\t * @param {SyncHandler} enter\n\t * @param {SyncHandler} leave\n\t */\n\tconstructor(enter, leave) {\n\t\tsuper();\n\n\t\t/** @type {SyncHandler} */\n\t\tthis.enter = enter;\n\n\t\t/** @type {SyncHandler} */\n\t\tthis.leave = leave;\n\t}\n\n\t/**\n\t *\n\t * @param {BaseNode} node\n\t * @param {BaseNode} parent\n\t * @param {string} [prop]\n\t * @param {number} [index]\n\t * @returns {BaseNode}\n\t */\n\tvisit(node, parent, prop, index) {\n\t\tif (node) {\n\t\t\tif (this.enter) {\n\t\t\t\tconst _should_skip = this.should_skip;\n\t\t\t\tconst _should_remove = this.should_remove;\n\t\t\t\tconst _replacement = this.replacement;\n\t\t\t\tthis.should_skip = false;\n\t\t\t\tthis.should_remove = false;\n\t\t\t\tthis.replacement = null;\n\n\t\t\t\tthis.enter.call(this.context, node, parent, prop, index);\n\n\t\t\t\tif (this.replacement) {\n\t\t\t\t\tnode = this.replacement;\n\t\t\t\t\tthis.replace(parent, prop, index, node);\n\t\t\t\t}\n\n\t\t\t\tif (this.should_remove) {\n\t\t\t\t\tthis.remove(parent, prop, index);\n\t\t\t\t}\n\n\t\t\t\tconst skipped = this.should_skip;\n\t\t\t\tconst removed = this.should_remove;\n\n\t\t\t\tthis.should_skip = _should_skip;\n\t\t\t\tthis.should_remove = _should_remove;\n\t\t\t\tthis.replacement = _replacement;\n\n\t\t\t\tif (skipped) return node;\n\t\t\t\tif (removed) return null;\n\t\t\t}\n\n\t\t\tfor (const key in node) {\n\t\t\t\tconst value = node[key];\n\n\t\t\t\tif (typeof value !== \"object\") {\n\t\t\t\t\tcontinue;\n\t\t\t\t} else if (Array.isArray(value)) {\n\t\t\t\t\tfor (let i = 0; i < value.length; i += 1) {\n\t\t\t\t\t\tif (value[i] !== null && typeof value[i].type === 'string') {\n\t\t\t\t\t\t\tif (!this.visit(value[i], node, key, i)) {\n\t\t\t\t\t\t\t\t// removed\n\t\t\t\t\t\t\t\ti--;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if (value !== null && typeof value.type === \"string\") {\n\t\t\t\t\tthis.visit(value, node, key, null);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (this.leave) {\n\t\t\t\tconst _replacement = this.replacement;\n\t\t\t\tconst _should_remove = this.should_remove;\n\t\t\t\tthis.replacement = null;\n\t\t\t\tthis.should_remove = false;\n\n\t\t\t\tthis.leave.call(this.context, node, parent, prop, index);\n\n\t\t\t\tif (this.replacement) {\n\t\t\t\t\tnode = this.replacement;\n\t\t\t\t\tthis.replace(parent, prop, index, node);\n\t\t\t\t}\n\n\t\t\t\tif (this.should_remove) {\n\t\t\t\t\tthis.remove(parent, prop, index);\n\t\t\t\t}\n\n\t\t\t\tconst removed = this.should_remove;\n\n\t\t\t\tthis.replacement = _replacement;\n\t\t\t\tthis.should_remove = _should_remove;\n\n\t\t\t\tif (removed) return null;\n\t\t\t}\n\t\t}\n\n\t\treturn node;\n\t}\n};\n\n// @ts-check\n\n/** @typedef { import('estree').BaseNode} BaseNode */\n/** @typedef { import('./sync.js').SyncHandler} SyncHandler */\n/** @typedef { import('./async.js').AsyncHandler} AsyncHandler */\n\n/**\n *\n * @param {BaseNode} ast\n * @param {{\n *   enter?: SyncHandler\n *   leave?: SyncHandler\n * }} walker\n * @returns {BaseNode}\n */\nfunction walk$3(ast, { enter, leave }) {\n\tconst instance = new SyncWalker$1(enter, leave);\n\treturn instance.visit(ast, null);\n}\n\nvar picomatchExports = {};\nvar picomatch$5 = {\n  get exports(){ return picomatchExports; },\n  set exports(v){ picomatchExports = v; },\n};\n\nvar utils$k = {};\n\nconst path$n = require$$0$4;\nconst WIN_SLASH = '\\\\\\\\/';\nconst WIN_NO_SLASH = `[^${WIN_SLASH}]`;\n\n/**\n * Posix glob regex\n */\n\nconst DOT_LITERAL = '\\\\.';\nconst PLUS_LITERAL = '\\\\+';\nconst QMARK_LITERAL = '\\\\?';\nconst SLASH_LITERAL = '\\\\/';\nconst ONE_CHAR = '(?=.)';\nconst QMARK = '[^/]';\nconst END_ANCHOR = `(?:${SLASH_LITERAL}|$)`;\nconst START_ANCHOR = `(?:^|${SLASH_LITERAL})`;\nconst DOTS_SLASH = `${DOT_LITERAL}{1,2}${END_ANCHOR}`;\nconst NO_DOT = `(?!${DOT_LITERAL})`;\nconst NO_DOTS = `(?!${START_ANCHOR}${DOTS_SLASH})`;\nconst NO_DOT_SLASH = `(?!${DOT_LITERAL}{0,1}${END_ANCHOR})`;\nconst NO_DOTS_SLASH = `(?!${DOTS_SLASH})`;\nconst QMARK_NO_DOT = `[^.${SLASH_LITERAL}]`;\nconst STAR$1 = `${QMARK}*?`;\n\nconst POSIX_CHARS = {\n  DOT_LITERAL,\n  PLUS_LITERAL,\n  QMARK_LITERAL,\n  SLASH_LITERAL,\n  ONE_CHAR,\n  QMARK,\n  END_ANCHOR,\n  DOTS_SLASH,\n  NO_DOT,\n  NO_DOTS,\n  NO_DOT_SLASH,\n  NO_DOTS_SLASH,\n  QMARK_NO_DOT,\n  STAR: STAR$1,\n  START_ANCHOR\n};\n\n/**\n * Windows glob regex\n */\n\nconst WINDOWS_CHARS = {\n  ...POSIX_CHARS,\n\n  SLASH_LITERAL: `[${WIN_SLASH}]`,\n  QMARK: WIN_NO_SLASH,\n  STAR: `${WIN_NO_SLASH}*?`,\n  DOTS_SLASH: `${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$)`,\n  NO_DOT: `(?!${DOT_LITERAL})`,\n  NO_DOTS: `(?!(?:^|[${WIN_SLASH}])${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,\n  NO_DOT_SLASH: `(?!${DOT_LITERAL}{0,1}(?:[${WIN_SLASH}]|$))`,\n  NO_DOTS_SLASH: `(?!${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,\n  QMARK_NO_DOT: `[^.${WIN_SLASH}]`,\n  START_ANCHOR: `(?:^|[${WIN_SLASH}])`,\n  END_ANCHOR: `(?:[${WIN_SLASH}]|$)`\n};\n\n/**\n * POSIX Bracket Regex\n */\n\nconst POSIX_REGEX_SOURCE$1 = {\n  alnum: 'a-zA-Z0-9',\n  alpha: 'a-zA-Z',\n  ascii: '\\\\x00-\\\\x7F',\n  blank: ' \\\\t',\n  cntrl: '\\\\x00-\\\\x1F\\\\x7F',\n  digit: '0-9',\n  graph: '\\\\x21-\\\\x7E',\n  lower: 'a-z',\n  print: '\\\\x20-\\\\x7E ',\n  punct: '\\\\-!\"#$%&\\'()\\\\*+,./:;<=>?@[\\\\]^_`{|}~',\n  space: ' \\\\t\\\\r\\\\n\\\\v\\\\f',\n  upper: 'A-Z',\n  word: 'A-Za-z0-9_',\n  xdigit: 'A-Fa-f0-9'\n};\n\nvar constants$6 = {\n  MAX_LENGTH: 1024 * 64,\n  POSIX_REGEX_SOURCE: POSIX_REGEX_SOURCE$1,\n\n  // regular expressions\n  REGEX_BACKSLASH: /\\\\(?![*+?^${}(|)[\\]])/g,\n  REGEX_NON_SPECIAL_CHARS: /^[^@![\\].,$*+?^{}()|\\\\/]+/,\n  REGEX_SPECIAL_CHARS: /[-*+?.^${}(|)[\\]]/,\n  REGEX_SPECIAL_CHARS_BACKREF: /(\\\\?)((\\W)(\\3*))/g,\n  REGEX_SPECIAL_CHARS_GLOBAL: /([-*+?.^${}(|)[\\]])/g,\n  REGEX_REMOVE_BACKSLASH: /(?:\\[.*?[^\\\\]\\]|\\\\(?=.))/g,\n\n  // Replace globs with equivalent patterns to reduce parsing time.\n  REPLACEMENTS: {\n    '***': '*',\n    '**/**': '**',\n    '**/**/**': '**'\n  },\n\n  // Digits\n  CHAR_0: 48, /* 0 */\n  CHAR_9: 57, /* 9 */\n\n  // Alphabet chars.\n  CHAR_UPPERCASE_A: 65, /* A */\n  CHAR_LOWERCASE_A: 97, /* a */\n  CHAR_UPPERCASE_Z: 90, /* Z */\n  CHAR_LOWERCASE_Z: 122, /* z */\n\n  CHAR_LEFT_PARENTHESES: 40, /* ( */\n  CHAR_RIGHT_PARENTHESES: 41, /* ) */\n\n  CHAR_ASTERISK: 42, /* * */\n\n  // Non-alphabetic chars.\n  CHAR_AMPERSAND: 38, /* & */\n  CHAR_AT: 64, /* @ */\n  CHAR_BACKWARD_SLASH: 92, /* \\ */\n  CHAR_CARRIAGE_RETURN: 13, /* \\r */\n  CHAR_CIRCUMFLEX_ACCENT: 94, /* ^ */\n  CHAR_COLON: 58, /* : */\n  CHAR_COMMA: 44, /* , */\n  CHAR_DOT: 46, /* . */\n  CHAR_DOUBLE_QUOTE: 34, /* \" */\n  CHAR_EQUAL: 61, /* = */\n  CHAR_EXCLAMATION_MARK: 33, /* ! */\n  CHAR_FORM_FEED: 12, /* \\f */\n  CHAR_FORWARD_SLASH: 47, /* / */\n  CHAR_GRAVE_ACCENT: 96, /* ` */\n  CHAR_HASH: 35, /* # */\n  CHAR_HYPHEN_MINUS: 45, /* - */\n  CHAR_LEFT_ANGLE_BRACKET: 60, /* < */\n  CHAR_LEFT_CURLY_BRACE: 123, /* { */\n  CHAR_LEFT_SQUARE_BRACKET: 91, /* [ */\n  CHAR_LINE_FEED: 10, /* \\n */\n  CHAR_NO_BREAK_SPACE: 160, /* \\u00A0 */\n  CHAR_PERCENT: 37, /* % */\n  CHAR_PLUS: 43, /* + */\n  CHAR_QUESTION_MARK: 63, /* ? */\n  CHAR_RIGHT_ANGLE_BRACKET: 62, /* > */\n  CHAR_RIGHT_CURLY_BRACE: 125, /* } */\n  CHAR_RIGHT_SQUARE_BRACKET: 93, /* ] */\n  CHAR_SEMICOLON: 59, /* ; */\n  CHAR_SINGLE_QUOTE: 39, /* ' */\n  CHAR_SPACE: 32, /*   */\n  CHAR_TAB: 9, /* \\t */\n  CHAR_UNDERSCORE: 95, /* _ */\n  CHAR_VERTICAL_LINE: 124, /* | */\n  CHAR_ZERO_WIDTH_NOBREAK_SPACE: 65279, /* \\uFEFF */\n\n  SEP: path$n.sep,\n\n  /**\n   * Create EXTGLOB_CHARS\n   */\n\n  extglobChars(chars) {\n    return {\n      '!': { type: 'negate', open: '(?:(?!(?:', close: `))${chars.STAR})` },\n      '?': { type: 'qmark', open: '(?:', close: ')?' },\n      '+': { type: 'plus', open: '(?:', close: ')+' },\n      '*': { type: 'star', open: '(?:', close: ')*' },\n      '@': { type: 'at', open: '(?:', close: ')' }\n    };\n  },\n\n  /**\n   * Create GLOB_CHARS\n   */\n\n  globChars(win32) {\n    return win32 === true ? WINDOWS_CHARS : POSIX_CHARS;\n  }\n};\n\n(function (exports) {\n\n\tconst path = require$$0$4;\n\tconst win32 = process.platform === 'win32';\n\tconst {\n\t  REGEX_BACKSLASH,\n\t  REGEX_REMOVE_BACKSLASH,\n\t  REGEX_SPECIAL_CHARS,\n\t  REGEX_SPECIAL_CHARS_GLOBAL\n\t} = constants$6;\n\n\texports.isObject = val => val !== null && typeof val === 'object' && !Array.isArray(val);\n\texports.hasRegexChars = str => REGEX_SPECIAL_CHARS.test(str);\n\texports.isRegexChar = str => str.length === 1 && exports.hasRegexChars(str);\n\texports.escapeRegex = str => str.replace(REGEX_SPECIAL_CHARS_GLOBAL, '\\\\$1');\n\texports.toPosixSlashes = str => str.replace(REGEX_BACKSLASH, '/');\n\n\texports.removeBackslashes = str => {\n\t  return str.replace(REGEX_REMOVE_BACKSLASH, match => {\n\t    return match === '\\\\' ? '' : match;\n\t  });\n\t};\n\n\texports.supportsLookbehinds = () => {\n\t  const segs = process.version.slice(1).split('.').map(Number);\n\t  if (segs.length === 3 && segs[0] >= 9 || (segs[0] === 8 && segs[1] >= 10)) {\n\t    return true;\n\t  }\n\t  return false;\n\t};\n\n\texports.isWindows = options => {\n\t  if (options && typeof options.windows === 'boolean') {\n\t    return options.windows;\n\t  }\n\t  return win32 === true || path.sep === '\\\\';\n\t};\n\n\texports.escapeLast = (input, char, lastIdx) => {\n\t  const idx = input.lastIndexOf(char, lastIdx);\n\t  if (idx === -1) return input;\n\t  if (input[idx - 1] === '\\\\') return exports.escapeLast(input, char, idx - 1);\n\t  return `${input.slice(0, idx)}\\\\${input.slice(idx)}`;\n\t};\n\n\texports.removePrefix = (input, state = {}) => {\n\t  let output = input;\n\t  if (output.startsWith('./')) {\n\t    output = output.slice(2);\n\t    state.prefix = './';\n\t  }\n\t  return output;\n\t};\n\n\texports.wrapOutput = (input, state = {}, options = {}) => {\n\t  const prepend = options.contains ? '' : '^';\n\t  const append = options.contains ? '' : '$';\n\n\t  let output = `${prepend}(?:${input})${append}`;\n\t  if (state.negated === true) {\n\t    output = `(?:^(?!${output}).*$)`;\n\t  }\n\t  return output;\n\t};\n} (utils$k));\n\nconst utils$j = utils$k;\nconst {\n  CHAR_ASTERISK,             /* * */\n  CHAR_AT,                   /* @ */\n  CHAR_BACKWARD_SLASH,       /* \\ */\n  CHAR_COMMA: CHAR_COMMA$1,                /* , */\n  CHAR_DOT: CHAR_DOT$1,                  /* . */\n  CHAR_EXCLAMATION_MARK,     /* ! */\n  CHAR_FORWARD_SLASH,        /* / */\n  CHAR_LEFT_CURLY_BRACE: CHAR_LEFT_CURLY_BRACE$1,     /* { */\n  CHAR_LEFT_PARENTHESES: CHAR_LEFT_PARENTHESES$1,     /* ( */\n  CHAR_LEFT_SQUARE_BRACKET: CHAR_LEFT_SQUARE_BRACKET$1,  /* [ */\n  CHAR_PLUS,                 /* + */\n  CHAR_QUESTION_MARK,        /* ? */\n  CHAR_RIGHT_CURLY_BRACE: CHAR_RIGHT_CURLY_BRACE$1,    /* } */\n  CHAR_RIGHT_PARENTHESES: CHAR_RIGHT_PARENTHESES$1,    /* ) */\n  CHAR_RIGHT_SQUARE_BRACKET: CHAR_RIGHT_SQUARE_BRACKET$1  /* ] */\n} = constants$6;\n\nconst isPathSeparator = code => {\n  return code === CHAR_FORWARD_SLASH || code === CHAR_BACKWARD_SLASH;\n};\n\nconst depth = token => {\n  if (token.isPrefix !== true) {\n    token.depth = token.isGlobstar ? Infinity : 1;\n  }\n};\n\n/**\n * Quickly scans a glob pattern and returns an object with a handful of\n * useful properties, like `isGlob`, `path` (the leading non-glob, if it exists),\n * `glob` (the actual pattern), `negated` (true if the path starts with `!` but not\n * with `!(`) and `negatedExtglob` (true if the path starts with `!(`).\n *\n * ```js\n * const pm = require('picomatch');\n * console.log(pm.scan('foo/bar/*.js'));\n * { isGlob: true, input: 'foo/bar/*.js', base: 'foo/bar', glob: '*.js' }\n * ```\n * @param {String} `str`\n * @param {Object} `options`\n * @return {Object} Returns an object with tokens and regex source string.\n * @api public\n */\n\nconst scan$2 = (input, options) => {\n  const opts = options || {};\n\n  const length = input.length - 1;\n  const scanToEnd = opts.parts === true || opts.scanToEnd === true;\n  const slashes = [];\n  const tokens = [];\n  const parts = [];\n\n  let str = input;\n  let index = -1;\n  let start = 0;\n  let lastIndex = 0;\n  let isBrace = false;\n  let isBracket = false;\n  let isGlob = false;\n  let isExtglob = false;\n  let isGlobstar = false;\n  let braceEscaped = false;\n  let backslashes = false;\n  let negated = false;\n  let negatedExtglob = false;\n  let finished = false;\n  let braces = 0;\n  let prev;\n  let code;\n  let token = { value: '', depth: 0, isGlob: false };\n\n  const eos = () => index >= length;\n  const peek = () => str.charCodeAt(index + 1);\n  const advance = () => {\n    prev = code;\n    return str.charCodeAt(++index);\n  };\n\n  while (index < length) {\n    code = advance();\n    let next;\n\n    if (code === CHAR_BACKWARD_SLASH) {\n      backslashes = token.backslashes = true;\n      code = advance();\n\n      if (code === CHAR_LEFT_CURLY_BRACE$1) {\n        braceEscaped = true;\n      }\n      continue;\n    }\n\n    if (braceEscaped === true || code === CHAR_LEFT_CURLY_BRACE$1) {\n      braces++;\n\n      while (eos() !== true && (code = advance())) {\n        if (code === CHAR_BACKWARD_SLASH) {\n          backslashes = token.backslashes = true;\n          advance();\n          continue;\n        }\n\n        if (code === CHAR_LEFT_CURLY_BRACE$1) {\n          braces++;\n          continue;\n        }\n\n        if (braceEscaped !== true && code === CHAR_DOT$1 && (code = advance()) === CHAR_DOT$1) {\n          isBrace = token.isBrace = true;\n          isGlob = token.isGlob = true;\n          finished = true;\n\n          if (scanToEnd === true) {\n            continue;\n          }\n\n          break;\n        }\n\n        if (braceEscaped !== true && code === CHAR_COMMA$1) {\n          isBrace = token.isBrace = true;\n          isGlob = token.isGlob = true;\n          finished = true;\n\n          if (scanToEnd === true) {\n            continue;\n          }\n\n          break;\n        }\n\n        if (code === CHAR_RIGHT_CURLY_BRACE$1) {\n          braces--;\n\n          if (braces === 0) {\n            braceEscaped = false;\n            isBrace = token.isBrace = true;\n            finished = true;\n            break;\n          }\n        }\n      }\n\n      if (scanToEnd === true) {\n        continue;\n      }\n\n      break;\n    }\n\n    if (code === CHAR_FORWARD_SLASH) {\n      slashes.push(index);\n      tokens.push(token);\n      token = { value: '', depth: 0, isGlob: false };\n\n      if (finished === true) continue;\n      if (prev === CHAR_DOT$1 && index === (start + 1)) {\n        start += 2;\n        continue;\n      }\n\n      lastIndex = index + 1;\n      continue;\n    }\n\n    if (opts.noext !== true) {\n      const isExtglobChar = code === CHAR_PLUS\n        || code === CHAR_AT\n        || code === CHAR_ASTERISK\n        || code === CHAR_QUESTION_MARK\n        || code === CHAR_EXCLAMATION_MARK;\n\n      if (isExtglobChar === true && peek() === CHAR_LEFT_PARENTHESES$1) {\n        isGlob = token.isGlob = true;\n        isExtglob = token.isExtglob = true;\n        finished = true;\n        if (code === CHAR_EXCLAMATION_MARK && index === start) {\n          negatedExtglob = true;\n        }\n\n        if (scanToEnd === true) {\n          while (eos() !== true && (code = advance())) {\n            if (code === CHAR_BACKWARD_SLASH) {\n              backslashes = token.backslashes = true;\n              code = advance();\n              continue;\n            }\n\n            if (code === CHAR_RIGHT_PARENTHESES$1) {\n              isGlob = token.isGlob = true;\n              finished = true;\n              break;\n            }\n          }\n          continue;\n        }\n        break;\n      }\n    }\n\n    if (code === CHAR_ASTERISK) {\n      if (prev === CHAR_ASTERISK) isGlobstar = token.isGlobstar = true;\n      isGlob = token.isGlob = true;\n      finished = true;\n\n      if (scanToEnd === true) {\n        continue;\n      }\n      break;\n    }\n\n    if (code === CHAR_QUESTION_MARK) {\n      isGlob = token.isGlob = true;\n      finished = true;\n\n      if (scanToEnd === true) {\n        continue;\n      }\n      break;\n    }\n\n    if (code === CHAR_LEFT_SQUARE_BRACKET$1) {\n      while (eos() !== true && (next = advance())) {\n        if (next === CHAR_BACKWARD_SLASH) {\n          backslashes = token.backslashes = true;\n          advance();\n          continue;\n        }\n\n        if (next === CHAR_RIGHT_SQUARE_BRACKET$1) {\n          isBracket = token.isBracket = true;\n          isGlob = token.isGlob = true;\n          finished = true;\n          break;\n        }\n      }\n\n      if (scanToEnd === true) {\n        continue;\n      }\n\n      break;\n    }\n\n    if (opts.nonegate !== true && code === CHAR_EXCLAMATION_MARK && index === start) {\n      negated = token.negated = true;\n      start++;\n      continue;\n    }\n\n    if (opts.noparen !== true && code === CHAR_LEFT_PARENTHESES$1) {\n      isGlob = token.isGlob = true;\n\n      if (scanToEnd === true) {\n        while (eos() !== true && (code = advance())) {\n          if (code === CHAR_LEFT_PARENTHESES$1) {\n            backslashes = token.backslashes = true;\n            code = advance();\n            continue;\n          }\n\n          if (code === CHAR_RIGHT_PARENTHESES$1) {\n            finished = true;\n            break;\n          }\n        }\n        continue;\n      }\n      break;\n    }\n\n    if (isGlob === true) {\n      finished = true;\n\n      if (scanToEnd === true) {\n        continue;\n      }\n\n      break;\n    }\n  }\n\n  if (opts.noext === true) {\n    isExtglob = false;\n    isGlob = false;\n  }\n\n  let base = str;\n  let prefix = '';\n  let glob = '';\n\n  if (start > 0) {\n    prefix = str.slice(0, start);\n    str = str.slice(start);\n    lastIndex -= start;\n  }\n\n  if (base && isGlob === true && lastIndex > 0) {\n    base = str.slice(0, lastIndex);\n    glob = str.slice(lastIndex);\n  } else if (isGlob === true) {\n    base = '';\n    glob = str;\n  } else {\n    base = str;\n  }\n\n  if (base && base !== '' && base !== '/' && base !== str) {\n    if (isPathSeparator(base.charCodeAt(base.length - 1))) {\n      base = base.slice(0, -1);\n    }\n  }\n\n  if (opts.unescape === true) {\n    if (glob) glob = utils$j.removeBackslashes(glob);\n\n    if (base && backslashes === true) {\n      base = utils$j.removeBackslashes(base);\n    }\n  }\n\n  const state = {\n    prefix,\n    input,\n    start,\n    base,\n    glob,\n    isBrace,\n    isBracket,\n    isGlob,\n    isExtglob,\n    isGlobstar,\n    negated,\n    negatedExtglob\n  };\n\n  if (opts.tokens === true) {\n    state.maxDepth = 0;\n    if (!isPathSeparator(code)) {\n      tokens.push(token);\n    }\n    state.tokens = tokens;\n  }\n\n  if (opts.parts === true || opts.tokens === true) {\n    let prevIndex;\n\n    for (let idx = 0; idx < slashes.length; idx++) {\n      const n = prevIndex ? prevIndex + 1 : start;\n      const i = slashes[idx];\n      const value = input.slice(n, i);\n      if (opts.tokens) {\n        if (idx === 0 && start !== 0) {\n          tokens[idx].isPrefix = true;\n          tokens[idx].value = prefix;\n        } else {\n          tokens[idx].value = value;\n        }\n        depth(tokens[idx]);\n        state.maxDepth += tokens[idx].depth;\n      }\n      if (idx !== 0 || value !== '') {\n        parts.push(value);\n      }\n      prevIndex = i;\n    }\n\n    if (prevIndex && prevIndex + 1 < input.length) {\n      const value = input.slice(prevIndex + 1);\n      parts.push(value);\n\n      if (opts.tokens) {\n        tokens[tokens.length - 1].value = value;\n        depth(tokens[tokens.length - 1]);\n        state.maxDepth += tokens[tokens.length - 1].depth;\n      }\n    }\n\n    state.slashes = slashes;\n    state.parts = parts;\n  }\n\n  return state;\n};\n\nvar scan_1 = scan$2;\n\nconst constants$5 = constants$6;\nconst utils$i = utils$k;\n\n/**\n * Constants\n */\n\nconst {\n  MAX_LENGTH: MAX_LENGTH$1,\n  POSIX_REGEX_SOURCE,\n  REGEX_NON_SPECIAL_CHARS,\n  REGEX_SPECIAL_CHARS_BACKREF,\n  REPLACEMENTS\n} = constants$5;\n\n/**\n * Helpers\n */\n\nconst expandRange = (args, options) => {\n  if (typeof options.expandRange === 'function') {\n    return options.expandRange(...args, options);\n  }\n\n  args.sort();\n  const value = `[${args.join('-')}]`;\n\n  return value;\n};\n\n/**\n * Create the message for a syntax error\n */\n\nconst syntaxError = (type, char) => {\n  return `Missing ${type}: \"${char}\" - use \"\\\\\\\\${char}\" to match literal characters`;\n};\n\n/**\n * Parse the given input string.\n * @param {String} input\n * @param {Object} options\n * @return {Object}\n */\n\nconst parse$h = (input, options) => {\n  if (typeof input !== 'string') {\n    throw new TypeError('Expected a string');\n  }\n\n  input = REPLACEMENTS[input] || input;\n\n  const opts = { ...options };\n  const max = typeof opts.maxLength === 'number' ? Math.min(MAX_LENGTH$1, opts.maxLength) : MAX_LENGTH$1;\n\n  let len = input.length;\n  if (len > max) {\n    throw new SyntaxError(`Input length: ${len}, exceeds maximum allowed length: ${max}`);\n  }\n\n  const bos = { type: 'bos', value: '', output: opts.prepend || '' };\n  const tokens = [bos];\n\n  const capture = opts.capture ? '' : '?:';\n  const win32 = utils$i.isWindows(options);\n\n  // create constants based on platform, for windows or posix\n  const PLATFORM_CHARS = constants$5.globChars(win32);\n  const EXTGLOB_CHARS = constants$5.extglobChars(PLATFORM_CHARS);\n\n  const {\n    DOT_LITERAL,\n    PLUS_LITERAL,\n    SLASH_LITERAL,\n    ONE_CHAR,\n    DOTS_SLASH,\n    NO_DOT,\n    NO_DOT_SLASH,\n    NO_DOTS_SLASH,\n    QMARK,\n    QMARK_NO_DOT,\n    STAR,\n    START_ANCHOR\n  } = PLATFORM_CHARS;\n\n  const globstar = opts => {\n    return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`;\n  };\n\n  const nodot = opts.dot ? '' : NO_DOT;\n  const qmarkNoDot = opts.dot ? QMARK : QMARK_NO_DOT;\n  let star = opts.bash === true ? globstar(opts) : STAR;\n\n  if (opts.capture) {\n    star = `(${star})`;\n  }\n\n  // minimatch options support\n  if (typeof opts.noext === 'boolean') {\n    opts.noextglob = opts.noext;\n  }\n\n  const state = {\n    input,\n    index: -1,\n    start: 0,\n    dot: opts.dot === true,\n    consumed: '',\n    output: '',\n    prefix: '',\n    backtrack: false,\n    negated: false,\n    brackets: 0,\n    braces: 0,\n    parens: 0,\n    quotes: 0,\n    globstar: false,\n    tokens\n  };\n\n  input = utils$i.removePrefix(input, state);\n  len = input.length;\n\n  const extglobs = [];\n  const braces = [];\n  const stack = [];\n  let prev = bos;\n  let value;\n\n  /**\n   * Tokenizing helpers\n   */\n\n  const eos = () => state.index === len - 1;\n  const peek = state.peek = (n = 1) => input[state.index + n];\n  const advance = state.advance = () => input[++state.index] || '';\n  const remaining = () => input.slice(state.index + 1);\n  const consume = (value = '', num = 0) => {\n    state.consumed += value;\n    state.index += num;\n  };\n\n  const append = token => {\n    state.output += token.output != null ? token.output : token.value;\n    consume(token.value);\n  };\n\n  const negate = () => {\n    let count = 1;\n\n    while (peek() === '!' && (peek(2) !== '(' || peek(3) === '?')) {\n      advance();\n      state.start++;\n      count++;\n    }\n\n    if (count % 2 === 0) {\n      return false;\n    }\n\n    state.negated = true;\n    state.start++;\n    return true;\n  };\n\n  const increment = type => {\n    state[type]++;\n    stack.push(type);\n  };\n\n  const decrement = type => {\n    state[type]--;\n    stack.pop();\n  };\n\n  /**\n   * Push tokens onto the tokens array. This helper speeds up\n   * tokenizing by 1) helping us avoid backtracking as much as possible,\n   * and 2) helping us avoid creating extra tokens when consecutive\n   * characters are plain text. This improves performance and simplifies\n   * lookbehinds.\n   */\n\n  const push = tok => {\n    if (prev.type === 'globstar') {\n      const isBrace = state.braces > 0 && (tok.type === 'comma' || tok.type === 'brace');\n      const isExtglob = tok.extglob === true || (extglobs.length && (tok.type === 'pipe' || tok.type === 'paren'));\n\n      if (tok.type !== 'slash' && tok.type !== 'paren' && !isBrace && !isExtglob) {\n        state.output = state.output.slice(0, -prev.output.length);\n        prev.type = 'star';\n        prev.value = '*';\n        prev.output = star;\n        state.output += prev.output;\n      }\n    }\n\n    if (extglobs.length && tok.type !== 'paren') {\n      extglobs[extglobs.length - 1].inner += tok.value;\n    }\n\n    if (tok.value || tok.output) append(tok);\n    if (prev && prev.type === 'text' && tok.type === 'text') {\n      prev.value += tok.value;\n      prev.output = (prev.output || '') + tok.value;\n      return;\n    }\n\n    tok.prev = prev;\n    tokens.push(tok);\n    prev = tok;\n  };\n\n  const extglobOpen = (type, value) => {\n    const token = { ...EXTGLOB_CHARS[value], conditions: 1, inner: '' };\n\n    token.prev = prev;\n    token.parens = state.parens;\n    token.output = state.output;\n    const output = (opts.capture ? '(' : '') + token.open;\n\n    increment('parens');\n    push({ type, value, output: state.output ? '' : ONE_CHAR });\n    push({ type: 'paren', extglob: true, value: advance(), output });\n    extglobs.push(token);\n  };\n\n  const extglobClose = token => {\n    let output = token.close + (opts.capture ? ')' : '');\n    let rest;\n\n    if (token.type === 'negate') {\n      let extglobStar = star;\n\n      if (token.inner && token.inner.length > 1 && token.inner.includes('/')) {\n        extglobStar = globstar(opts);\n      }\n\n      if (extglobStar !== star || eos() || /^\\)+$/.test(remaining())) {\n        output = token.close = `)$))${extglobStar}`;\n      }\n\n      if (token.inner.includes('*') && (rest = remaining()) && /^\\.[^\\\\/.]+$/.test(rest)) {\n        // Any non-magical string (`.ts`) or even nested expression (`.{ts,tsx}`) can follow after the closing parenthesis.\n        // In this case, we need to parse the string and use it in the output of the original pattern.\n        // Suitable patterns: `/!(*.d).ts`, `/!(*.d).{ts,tsx}`, `**/!(*-dbg).@(js)`.\n        //\n        // Disabling the `fastpaths` option due to a problem with parsing strings as `.ts` in the pattern like `**/!(*.d).ts`.\n        const expression = parse$h(rest, { ...options, fastpaths: false }).output;\n\n        output = token.close = `)${expression})${extglobStar})`;\n      }\n\n      if (token.prev.type === 'bos') {\n        state.negatedExtglob = true;\n      }\n    }\n\n    push({ type: 'paren', extglob: true, value, output });\n    decrement('parens');\n  };\n\n  /**\n   * Fast paths\n   */\n\n  if (opts.fastpaths !== false && !/(^[*!]|[/()[\\]{}\"])/.test(input)) {\n    let backslashes = false;\n\n    let output = input.replace(REGEX_SPECIAL_CHARS_BACKREF, (m, esc, chars, first, rest, index) => {\n      if (first === '\\\\') {\n        backslashes = true;\n        return m;\n      }\n\n      if (first === '?') {\n        if (esc) {\n          return esc + first + (rest ? QMARK.repeat(rest.length) : '');\n        }\n        if (index === 0) {\n          return qmarkNoDot + (rest ? QMARK.repeat(rest.length) : '');\n        }\n        return QMARK.repeat(chars.length);\n      }\n\n      if (first === '.') {\n        return DOT_LITERAL.repeat(chars.length);\n      }\n\n      if (first === '*') {\n        if (esc) {\n          return esc + first + (rest ? star : '');\n        }\n        return star;\n      }\n      return esc ? m : `\\\\${m}`;\n    });\n\n    if (backslashes === true) {\n      if (opts.unescape === true) {\n        output = output.replace(/\\\\/g, '');\n      } else {\n        output = output.replace(/\\\\+/g, m => {\n          return m.length % 2 === 0 ? '\\\\\\\\' : (m ? '\\\\' : '');\n        });\n      }\n    }\n\n    if (output === input && opts.contains === true) {\n      state.output = input;\n      return state;\n    }\n\n    state.output = utils$i.wrapOutput(output, state, options);\n    return state;\n  }\n\n  /**\n   * Tokenize input until we reach end-of-string\n   */\n\n  while (!eos()) {\n    value = advance();\n\n    if (value === '\\u0000') {\n      continue;\n    }\n\n    /**\n     * Escaped characters\n     */\n\n    if (value === '\\\\') {\n      const next = peek();\n\n      if (next === '/' && opts.bash !== true) {\n        continue;\n      }\n\n      if (next === '.' || next === ';') {\n        continue;\n      }\n\n      if (!next) {\n        value += '\\\\';\n        push({ type: 'text', value });\n        continue;\n      }\n\n      // collapse slashes to reduce potential for exploits\n      const match = /^\\\\+/.exec(remaining());\n      let slashes = 0;\n\n      if (match && match[0].length > 2) {\n        slashes = match[0].length;\n        state.index += slashes;\n        if (slashes % 2 !== 0) {\n          value += '\\\\';\n        }\n      }\n\n      if (opts.unescape === true) {\n        value = advance();\n      } else {\n        value += advance();\n      }\n\n      if (state.brackets === 0) {\n        push({ type: 'text', value });\n        continue;\n      }\n    }\n\n    /**\n     * If we're inside a regex character class, continue\n     * until we reach the closing bracket.\n     */\n\n    if (state.brackets > 0 && (value !== ']' || prev.value === '[' || prev.value === '[^')) {\n      if (opts.posix !== false && value === ':') {\n        const inner = prev.value.slice(1);\n        if (inner.includes('[')) {\n          prev.posix = true;\n\n          if (inner.includes(':')) {\n            const idx = prev.value.lastIndexOf('[');\n            const pre = prev.value.slice(0, idx);\n            const rest = prev.value.slice(idx + 2);\n            const posix = POSIX_REGEX_SOURCE[rest];\n            if (posix) {\n              prev.value = pre + posix;\n              state.backtrack = true;\n              advance();\n\n              if (!bos.output && tokens.indexOf(prev) === 1) {\n                bos.output = ONE_CHAR;\n              }\n              continue;\n            }\n          }\n        }\n      }\n\n      if ((value === '[' && peek() !== ':') || (value === '-' && peek() === ']')) {\n        value = `\\\\${value}`;\n      }\n\n      if (value === ']' && (prev.value === '[' || prev.value === '[^')) {\n        value = `\\\\${value}`;\n      }\n\n      if (opts.posix === true && value === '!' && prev.value === '[') {\n        value = '^';\n      }\n\n      prev.value += value;\n      append({ value });\n      continue;\n    }\n\n    /**\n     * If we're inside a quoted string, continue\n     * until we reach the closing double quote.\n     */\n\n    if (state.quotes === 1 && value !== '\"') {\n      value = utils$i.escapeRegex(value);\n      prev.value += value;\n      append({ value });\n      continue;\n    }\n\n    /**\n     * Double quotes\n     */\n\n    if (value === '\"') {\n      state.quotes = state.quotes === 1 ? 0 : 1;\n      if (opts.keepQuotes === true) {\n        push({ type: 'text', value });\n      }\n      continue;\n    }\n\n    /**\n     * Parentheses\n     */\n\n    if (value === '(') {\n      increment('parens');\n      push({ type: 'paren', value });\n      continue;\n    }\n\n    if (value === ')') {\n      if (state.parens === 0 && opts.strictBrackets === true) {\n        throw new SyntaxError(syntaxError('opening', '('));\n      }\n\n      const extglob = extglobs[extglobs.length - 1];\n      if (extglob && state.parens === extglob.parens + 1) {\n        extglobClose(extglobs.pop());\n        continue;\n      }\n\n      push({ type: 'paren', value, output: state.parens ? ')' : '\\\\)' });\n      decrement('parens');\n      continue;\n    }\n\n    /**\n     * Square brackets\n     */\n\n    if (value === '[') {\n      if (opts.nobracket === true || !remaining().includes(']')) {\n        if (opts.nobracket !== true && opts.strictBrackets === true) {\n          throw new SyntaxError(syntaxError('closing', ']'));\n        }\n\n        value = `\\\\${value}`;\n      } else {\n        increment('brackets');\n      }\n\n      push({ type: 'bracket', value });\n      continue;\n    }\n\n    if (value === ']') {\n      if (opts.nobracket === true || (prev && prev.type === 'bracket' && prev.value.length === 1)) {\n        push({ type: 'text', value, output: `\\\\${value}` });\n        continue;\n      }\n\n      if (state.brackets === 0) {\n        if (opts.strictBrackets === true) {\n          throw new SyntaxError(syntaxError('opening', '['));\n        }\n\n        push({ type: 'text', value, output: `\\\\${value}` });\n        continue;\n      }\n\n      decrement('brackets');\n\n      const prevValue = prev.value.slice(1);\n      if (prev.posix !== true && prevValue[0] === '^' && !prevValue.includes('/')) {\n        value = `/${value}`;\n      }\n\n      prev.value += value;\n      append({ value });\n\n      // when literal brackets are explicitly disabled\n      // assume we should match with a regex character class\n      if (opts.literalBrackets === false || utils$i.hasRegexChars(prevValue)) {\n        continue;\n      }\n\n      const escaped = utils$i.escapeRegex(prev.value);\n      state.output = state.output.slice(0, -prev.value.length);\n\n      // when literal brackets are explicitly enabled\n      // assume we should escape the brackets to match literal characters\n      if (opts.literalBrackets === true) {\n        state.output += escaped;\n        prev.value = escaped;\n        continue;\n      }\n\n      // when the user specifies nothing, try to match both\n      prev.value = `(${capture}${escaped}|${prev.value})`;\n      state.output += prev.value;\n      continue;\n    }\n\n    /**\n     * Braces\n     */\n\n    if (value === '{' && opts.nobrace !== true) {\n      increment('braces');\n\n      const open = {\n        type: 'brace',\n        value,\n        output: '(',\n        outputIndex: state.output.length,\n        tokensIndex: state.tokens.length\n      };\n\n      braces.push(open);\n      push(open);\n      continue;\n    }\n\n    if (value === '}') {\n      const brace = braces[braces.length - 1];\n\n      if (opts.nobrace === true || !brace) {\n        push({ type: 'text', value, output: value });\n        continue;\n      }\n\n      let output = ')';\n\n      if (brace.dots === true) {\n        const arr = tokens.slice();\n        const range = [];\n\n        for (let i = arr.length - 1; i >= 0; i--) {\n          tokens.pop();\n          if (arr[i].type === 'brace') {\n            break;\n          }\n          if (arr[i].type !== 'dots') {\n            range.unshift(arr[i].value);\n          }\n        }\n\n        output = expandRange(range, opts);\n        state.backtrack = true;\n      }\n\n      if (brace.comma !== true && brace.dots !== true) {\n        const out = state.output.slice(0, brace.outputIndex);\n        const toks = state.tokens.slice(brace.tokensIndex);\n        brace.value = brace.output = '\\\\{';\n        value = output = '\\\\}';\n        state.output = out;\n        for (const t of toks) {\n          state.output += (t.output || t.value);\n        }\n      }\n\n      push({ type: 'brace', value, output });\n      decrement('braces');\n      braces.pop();\n      continue;\n    }\n\n    /**\n     * Pipes\n     */\n\n    if (value === '|') {\n      if (extglobs.length > 0) {\n        extglobs[extglobs.length - 1].conditions++;\n      }\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Commas\n     */\n\n    if (value === ',') {\n      let output = value;\n\n      const brace = braces[braces.length - 1];\n      if (brace && stack[stack.length - 1] === 'braces') {\n        brace.comma = true;\n        output = '|';\n      }\n\n      push({ type: 'comma', value, output });\n      continue;\n    }\n\n    /**\n     * Slashes\n     */\n\n    if (value === '/') {\n      // if the beginning of the glob is \"./\", advance the start\n      // to the current index, and don't add the \"./\" characters\n      // to the state. This greatly simplifies lookbehinds when\n      // checking for BOS characters like \"!\" and \".\" (not \"./\")\n      if (prev.type === 'dot' && state.index === state.start + 1) {\n        state.start = state.index + 1;\n        state.consumed = '';\n        state.output = '';\n        tokens.pop();\n        prev = bos; // reset \"prev\" to the first token\n        continue;\n      }\n\n      push({ type: 'slash', value, output: SLASH_LITERAL });\n      continue;\n    }\n\n    /**\n     * Dots\n     */\n\n    if (value === '.') {\n      if (state.braces > 0 && prev.type === 'dot') {\n        if (prev.value === '.') prev.output = DOT_LITERAL;\n        const brace = braces[braces.length - 1];\n        prev.type = 'dots';\n        prev.output += value;\n        prev.value += value;\n        brace.dots = true;\n        continue;\n      }\n\n      if ((state.braces + state.parens) === 0 && prev.type !== 'bos' && prev.type !== 'slash') {\n        push({ type: 'text', value, output: DOT_LITERAL });\n        continue;\n      }\n\n      push({ type: 'dot', value, output: DOT_LITERAL });\n      continue;\n    }\n\n    /**\n     * Question marks\n     */\n\n    if (value === '?') {\n      const isGroup = prev && prev.value === '(';\n      if (!isGroup && opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {\n        extglobOpen('qmark', value);\n        continue;\n      }\n\n      if (prev && prev.type === 'paren') {\n        const next = peek();\n        let output = value;\n\n        if (next === '<' && !utils$i.supportsLookbehinds()) {\n          throw new Error('Node.js v10 or higher is required for regex lookbehinds');\n        }\n\n        if ((prev.value === '(' && !/[!=<:]/.test(next)) || (next === '<' && !/<([!=]|\\w+>)/.test(remaining()))) {\n          output = `\\\\${value}`;\n        }\n\n        push({ type: 'text', value, output });\n        continue;\n      }\n\n      if (opts.dot !== true && (prev.type === 'slash' || prev.type === 'bos')) {\n        push({ type: 'qmark', value, output: QMARK_NO_DOT });\n        continue;\n      }\n\n      push({ type: 'qmark', value, output: QMARK });\n      continue;\n    }\n\n    /**\n     * Exclamation\n     */\n\n    if (value === '!') {\n      if (opts.noextglob !== true && peek() === '(') {\n        if (peek(2) !== '?' || !/[!=<:]/.test(peek(3))) {\n          extglobOpen('negate', value);\n          continue;\n        }\n      }\n\n      if (opts.nonegate !== true && state.index === 0) {\n        negate();\n        continue;\n      }\n    }\n\n    /**\n     * Plus\n     */\n\n    if (value === '+') {\n      if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {\n        extglobOpen('plus', value);\n        continue;\n      }\n\n      if ((prev && prev.value === '(') || opts.regex === false) {\n        push({ type: 'plus', value, output: PLUS_LITERAL });\n        continue;\n      }\n\n      if ((prev && (prev.type === 'bracket' || prev.type === 'paren' || prev.type === 'brace')) || state.parens > 0) {\n        push({ type: 'plus', value });\n        continue;\n      }\n\n      push({ type: 'plus', value: PLUS_LITERAL });\n      continue;\n    }\n\n    /**\n     * Plain text\n     */\n\n    if (value === '@') {\n      if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {\n        push({ type: 'at', extglob: true, value, output: '' });\n        continue;\n      }\n\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Plain text\n     */\n\n    if (value !== '*') {\n      if (value === '$' || value === '^') {\n        value = `\\\\${value}`;\n      }\n\n      const match = REGEX_NON_SPECIAL_CHARS.exec(remaining());\n      if (match) {\n        value += match[0];\n        state.index += match[0].length;\n      }\n\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Stars\n     */\n\n    if (prev && (prev.type === 'globstar' || prev.star === true)) {\n      prev.type = 'star';\n      prev.star = true;\n      prev.value += value;\n      prev.output = star;\n      state.backtrack = true;\n      state.globstar = true;\n      consume(value);\n      continue;\n    }\n\n    let rest = remaining();\n    if (opts.noextglob !== true && /^\\([^?]/.test(rest)) {\n      extglobOpen('star', value);\n      continue;\n    }\n\n    if (prev.type === 'star') {\n      if (opts.noglobstar === true) {\n        consume(value);\n        continue;\n      }\n\n      const prior = prev.prev;\n      const before = prior.prev;\n      const isStart = prior.type === 'slash' || prior.type === 'bos';\n      const afterStar = before && (before.type === 'star' || before.type === 'globstar');\n\n      if (opts.bash === true && (!isStart || (rest[0] && rest[0] !== '/'))) {\n        push({ type: 'star', value, output: '' });\n        continue;\n      }\n\n      const isBrace = state.braces > 0 && (prior.type === 'comma' || prior.type === 'brace');\n      const isExtglob = extglobs.length && (prior.type === 'pipe' || prior.type === 'paren');\n      if (!isStart && prior.type !== 'paren' && !isBrace && !isExtglob) {\n        push({ type: 'star', value, output: '' });\n        continue;\n      }\n\n      // strip consecutive `/**/`\n      while (rest.slice(0, 3) === '/**') {\n        const after = input[state.index + 4];\n        if (after && after !== '/') {\n          break;\n        }\n        rest = rest.slice(3);\n        consume('/**', 3);\n      }\n\n      if (prior.type === 'bos' && eos()) {\n        prev.type = 'globstar';\n        prev.value += value;\n        prev.output = globstar(opts);\n        state.output = prev.output;\n        state.globstar = true;\n        consume(value);\n        continue;\n      }\n\n      if (prior.type === 'slash' && prior.prev.type !== 'bos' && !afterStar && eos()) {\n        state.output = state.output.slice(0, -(prior.output + prev.output).length);\n        prior.output = `(?:${prior.output}`;\n\n        prev.type = 'globstar';\n        prev.output = globstar(opts) + (opts.strictSlashes ? ')' : '|$)');\n        prev.value += value;\n        state.globstar = true;\n        state.output += prior.output + prev.output;\n        consume(value);\n        continue;\n      }\n\n      if (prior.type === 'slash' && prior.prev.type !== 'bos' && rest[0] === '/') {\n        const end = rest[1] !== void 0 ? '|$' : '';\n\n        state.output = state.output.slice(0, -(prior.output + prev.output).length);\n        prior.output = `(?:${prior.output}`;\n\n        prev.type = 'globstar';\n        prev.output = `${globstar(opts)}${SLASH_LITERAL}|${SLASH_LITERAL}${end})`;\n        prev.value += value;\n\n        state.output += prior.output + prev.output;\n        state.globstar = true;\n\n        consume(value + advance());\n\n        push({ type: 'slash', value: '/', output: '' });\n        continue;\n      }\n\n      if (prior.type === 'bos' && rest[0] === '/') {\n        prev.type = 'globstar';\n        prev.value += value;\n        prev.output = `(?:^|${SLASH_LITERAL}|${globstar(opts)}${SLASH_LITERAL})`;\n        state.output = prev.output;\n        state.globstar = true;\n        consume(value + advance());\n        push({ type: 'slash', value: '/', output: '' });\n        continue;\n      }\n\n      // remove single star from output\n      state.output = state.output.slice(0, -prev.output.length);\n\n      // reset previous token to globstar\n      prev.type = 'globstar';\n      prev.output = globstar(opts);\n      prev.value += value;\n\n      // reset output with globstar\n      state.output += prev.output;\n      state.globstar = true;\n      consume(value);\n      continue;\n    }\n\n    const token = { type: 'star', value, output: star };\n\n    if (opts.bash === true) {\n      token.output = '.*?';\n      if (prev.type === 'bos' || prev.type === 'slash') {\n        token.output = nodot + token.output;\n      }\n      push(token);\n      continue;\n    }\n\n    if (prev && (prev.type === 'bracket' || prev.type === 'paren') && opts.regex === true) {\n      token.output = value;\n      push(token);\n      continue;\n    }\n\n    if (state.index === state.start || prev.type === 'slash' || prev.type === 'dot') {\n      if (prev.type === 'dot') {\n        state.output += NO_DOT_SLASH;\n        prev.output += NO_DOT_SLASH;\n\n      } else if (opts.dot === true) {\n        state.output += NO_DOTS_SLASH;\n        prev.output += NO_DOTS_SLASH;\n\n      } else {\n        state.output += nodot;\n        prev.output += nodot;\n      }\n\n      if (peek() !== '*') {\n        state.output += ONE_CHAR;\n        prev.output += ONE_CHAR;\n      }\n    }\n\n    push(token);\n  }\n\n  while (state.brackets > 0) {\n    if (opts.strictBrackets === true) throw new SyntaxError(syntaxError('closing', ']'));\n    state.output = utils$i.escapeLast(state.output, '[');\n    decrement('brackets');\n  }\n\n  while (state.parens > 0) {\n    if (opts.strictBrackets === true) throw new SyntaxError(syntaxError('closing', ')'));\n    state.output = utils$i.escapeLast(state.output, '(');\n    decrement('parens');\n  }\n\n  while (state.braces > 0) {\n    if (opts.strictBrackets === true) throw new SyntaxError(syntaxError('closing', '}'));\n    state.output = utils$i.escapeLast(state.output, '{');\n    decrement('braces');\n  }\n\n  if (opts.strictSlashes !== true && (prev.type === 'star' || prev.type === 'bracket')) {\n    push({ type: 'maybe_slash', value: '', output: `${SLASH_LITERAL}?` });\n  }\n\n  // rebuild the output if we had to backtrack at any point\n  if (state.backtrack === true) {\n    state.output = '';\n\n    for (const token of state.tokens) {\n      state.output += token.output != null ? token.output : token.value;\n\n      if (token.suffix) {\n        state.output += token.suffix;\n      }\n    }\n  }\n\n  return state;\n};\n\n/**\n * Fast paths for creating regular expressions for common glob patterns.\n * This can significantly speed up processing and has very little downside\n * impact when none of the fast paths match.\n */\n\nparse$h.fastpaths = (input, options) => {\n  const opts = { ...options };\n  const max = typeof opts.maxLength === 'number' ? Math.min(MAX_LENGTH$1, opts.maxLength) : MAX_LENGTH$1;\n  const len = input.length;\n  if (len > max) {\n    throw new SyntaxError(`Input length: ${len}, exceeds maximum allowed length: ${max}`);\n  }\n\n  input = REPLACEMENTS[input] || input;\n  const win32 = utils$i.isWindows(options);\n\n  // create constants based on platform, for windows or posix\n  const {\n    DOT_LITERAL,\n    SLASH_LITERAL,\n    ONE_CHAR,\n    DOTS_SLASH,\n    NO_DOT,\n    NO_DOTS,\n    NO_DOTS_SLASH,\n    STAR,\n    START_ANCHOR\n  } = constants$5.globChars(win32);\n\n  const nodot = opts.dot ? NO_DOTS : NO_DOT;\n  const slashDot = opts.dot ? NO_DOTS_SLASH : NO_DOT;\n  const capture = opts.capture ? '' : '?:';\n  const state = { negated: false, prefix: '' };\n  let star = opts.bash === true ? '.*?' : STAR;\n\n  if (opts.capture) {\n    star = `(${star})`;\n  }\n\n  const globstar = opts => {\n    if (opts.noglobstar === true) return star;\n    return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`;\n  };\n\n  const create = str => {\n    switch (str) {\n      case '*':\n        return `${nodot}${ONE_CHAR}${star}`;\n\n      case '.*':\n        return `${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      case '*.*':\n        return `${nodot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      case '*/*':\n        return `${nodot}${star}${SLASH_LITERAL}${ONE_CHAR}${slashDot}${star}`;\n\n      case '**':\n        return nodot + globstar(opts);\n\n      case '**/*':\n        return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${ONE_CHAR}${star}`;\n\n      case '**/*.*':\n        return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      case '**/.*':\n        return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      default: {\n        const match = /^(.*?)\\.(\\w+)$/.exec(str);\n        if (!match) return;\n\n        const source = create(match[1]);\n        if (!source) return;\n\n        return source + DOT_LITERAL + match[2];\n      }\n    }\n  };\n\n  const output = utils$i.removePrefix(input, state);\n  let source = create(output);\n\n  if (source && opts.strictSlashes !== true) {\n    source += `${SLASH_LITERAL}?`;\n  }\n\n  return source;\n};\n\nvar parse_1$3 = parse$h;\n\nconst path$m = require$$0$4;\nconst scan$1 = scan_1;\nconst parse$g = parse_1$3;\nconst utils$h = utils$k;\nconst constants$4 = constants$6;\nconst isObject$3 = val => val && typeof val === 'object' && !Array.isArray(val);\n\n/**\n * Creates a matcher function from one or more glob patterns. The\n * returned function takes a string to match as its first argument,\n * and returns true if the string is a match. The returned matcher\n * function also takes a boolean as the second argument that, when true,\n * returns an object with additional information.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch(glob[, options]);\n *\n * const isMatch = picomatch('*.!(*a)');\n * console.log(isMatch('a.a')); //=> false\n * console.log(isMatch('a.b')); //=> true\n * ```\n * @name picomatch\n * @param {String|Array} `globs` One or more glob patterns.\n * @param {Object=} `options`\n * @return {Function=} Returns a matcher function.\n * @api public\n */\n\nconst picomatch$4 = (glob, options, returnState = false) => {\n  if (Array.isArray(glob)) {\n    const fns = glob.map(input => picomatch$4(input, options, returnState));\n    const arrayMatcher = str => {\n      for (const isMatch of fns) {\n        const state = isMatch(str);\n        if (state) return state;\n      }\n      return false;\n    };\n    return arrayMatcher;\n  }\n\n  const isState = isObject$3(glob) && glob.tokens && glob.input;\n\n  if (glob === '' || (typeof glob !== 'string' && !isState)) {\n    throw new TypeError('Expected pattern to be a non-empty string');\n  }\n\n  const opts = options || {};\n  const posix = utils$h.isWindows(options);\n  const regex = isState\n    ? picomatch$4.compileRe(glob, options)\n    : picomatch$4.makeRe(glob, options, false, true);\n\n  const state = regex.state;\n  delete regex.state;\n\n  let isIgnored = () => false;\n  if (opts.ignore) {\n    const ignoreOpts = { ...options, ignore: null, onMatch: null, onResult: null };\n    isIgnored = picomatch$4(opts.ignore, ignoreOpts, returnState);\n  }\n\n  const matcher = (input, returnObject = false) => {\n    const { isMatch, match, output } = picomatch$4.test(input, regex, options, { glob, posix });\n    const result = { glob, state, regex, posix, input, output, match, isMatch };\n\n    if (typeof opts.onResult === 'function') {\n      opts.onResult(result);\n    }\n\n    if (isMatch === false) {\n      result.isMatch = false;\n      return returnObject ? result : false;\n    }\n\n    if (isIgnored(input)) {\n      if (typeof opts.onIgnore === 'function') {\n        opts.onIgnore(result);\n      }\n      result.isMatch = false;\n      return returnObject ? result : false;\n    }\n\n    if (typeof opts.onMatch === 'function') {\n      opts.onMatch(result);\n    }\n    return returnObject ? result : true;\n  };\n\n  if (returnState) {\n    matcher.state = state;\n  }\n\n  return matcher;\n};\n\n/**\n * Test `input` with the given `regex`. This is used by the main\n * `picomatch()` function to test the input string.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.test(input, regex[, options]);\n *\n * console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\\/([^/]*?))$/));\n * // { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' }\n * ```\n * @param {String} `input` String to test.\n * @param {RegExp} `regex`\n * @return {Object} Returns an object with matching info.\n * @api public\n */\n\npicomatch$4.test = (input, regex, options, { glob, posix } = {}) => {\n  if (typeof input !== 'string') {\n    throw new TypeError('Expected input to be a string');\n  }\n\n  if (input === '') {\n    return { isMatch: false, output: '' };\n  }\n\n  const opts = options || {};\n  const format = opts.format || (posix ? utils$h.toPosixSlashes : null);\n  let match = input === glob;\n  let output = (match && format) ? format(input) : input;\n\n  if (match === false) {\n    output = format ? format(input) : input;\n    match = output === glob;\n  }\n\n  if (match === false || opts.capture === true) {\n    if (opts.matchBase === true || opts.basename === true) {\n      match = picomatch$4.matchBase(input, regex, options, posix);\n    } else {\n      match = regex.exec(output);\n    }\n  }\n\n  return { isMatch: Boolean(match), match, output };\n};\n\n/**\n * Match the basename of a filepath.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.matchBase(input, glob[, options]);\n * console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true\n * ```\n * @param {String} `input` String to test.\n * @param {RegExp|String} `glob` Glob pattern or regex created by [.makeRe](#makeRe).\n * @return {Boolean}\n * @api public\n */\n\npicomatch$4.matchBase = (input, glob, options, posix = utils$h.isWindows(options)) => {\n  const regex = glob instanceof RegExp ? glob : picomatch$4.makeRe(glob, options);\n  return regex.test(path$m.basename(input));\n};\n\n/**\n * Returns true if **any** of the given glob `patterns` match the specified `string`.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.isMatch(string, patterns[, options]);\n *\n * console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true\n * console.log(picomatch.isMatch('a.a', 'b.*')); //=> false\n * ```\n * @param {String|Array} str The string to test.\n * @param {String|Array} patterns One or more glob patterns to use for matching.\n * @param {Object} [options] See available [options](#options).\n * @return {Boolean} Returns true if any patterns match `str`\n * @api public\n */\n\npicomatch$4.isMatch = (str, patterns, options) => picomatch$4(patterns, options)(str);\n\n/**\n * Parse a glob pattern to create the source string for a regular\n * expression.\n *\n * ```js\n * const picomatch = require('picomatch');\n * const result = picomatch.parse(pattern[, options]);\n * ```\n * @param {String} `pattern`\n * @param {Object} `options`\n * @return {Object} Returns an object with useful properties and output to be used as a regex source string.\n * @api public\n */\n\npicomatch$4.parse = (pattern, options) => {\n  if (Array.isArray(pattern)) return pattern.map(p => picomatch$4.parse(p, options));\n  return parse$g(pattern, { ...options, fastpaths: false });\n};\n\n/**\n * Scan a glob pattern to separate the pattern into segments.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.scan(input[, options]);\n *\n * const result = picomatch.scan('!./foo/*.js');\n * console.log(result);\n * { prefix: '!./',\n *   input: '!./foo/*.js',\n *   start: 3,\n *   base: 'foo',\n *   glob: '*.js',\n *   isBrace: false,\n *   isBracket: false,\n *   isGlob: true,\n *   isExtglob: false,\n *   isGlobstar: false,\n *   negated: true }\n * ```\n * @param {String} `input` Glob pattern to scan.\n * @param {Object} `options`\n * @return {Object} Returns an object with\n * @api public\n */\n\npicomatch$4.scan = (input, options) => scan$1(input, options);\n\n/**\n * Compile a regular expression from the `state` object returned by the\n * [parse()](#parse) method.\n *\n * @param {Object} `state`\n * @param {Object} `options`\n * @param {Boolean} `returnOutput` Intended for implementors, this argument allows you to return the raw output from the parser.\n * @param {Boolean} `returnState` Adds the state to a `state` property on the returned regex. Useful for implementors and debugging.\n * @return {RegExp}\n * @api public\n */\n\npicomatch$4.compileRe = (state, options, returnOutput = false, returnState = false) => {\n  if (returnOutput === true) {\n    return state.output;\n  }\n\n  const opts = options || {};\n  const prepend = opts.contains ? '' : '^';\n  const append = opts.contains ? '' : '$';\n\n  let source = `${prepend}(?:${state.output})${append}`;\n  if (state && state.negated === true) {\n    source = `^(?!${source}).*$`;\n  }\n\n  const regex = picomatch$4.toRegex(source, options);\n  if (returnState === true) {\n    regex.state = state;\n  }\n\n  return regex;\n};\n\n/**\n * Create a regular expression from a parsed glob pattern.\n *\n * ```js\n * const picomatch = require('picomatch');\n * const state = picomatch.parse('*.js');\n * // picomatch.compileRe(state[, options]);\n *\n * console.log(picomatch.compileRe(state));\n * //=> /^(?:(?!\\.)(?=.)[^/]*?\\.js)$/\n * ```\n * @param {String} `state` The object returned from the `.parse` method.\n * @param {Object} `options`\n * @param {Boolean} `returnOutput` Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result.\n * @param {Boolean} `returnState` Implementors may use this argument to return the state from the parsed glob with the returned regular expression.\n * @return {RegExp} Returns a regex created from the given pattern.\n * @api public\n */\n\npicomatch$4.makeRe = (input, options = {}, returnOutput = false, returnState = false) => {\n  if (!input || typeof input !== 'string') {\n    throw new TypeError('Expected a non-empty string');\n  }\n\n  let parsed = { negated: false, fastpaths: true };\n\n  if (options.fastpaths !== false && (input[0] === '.' || input[0] === '*')) {\n    parsed.output = parse$g.fastpaths(input, options);\n  }\n\n  if (!parsed.output) {\n    parsed = parse$g(input, options);\n  }\n\n  return picomatch$4.compileRe(parsed, options, returnOutput, returnState);\n};\n\n/**\n * Create a regular expression from the given regex source string.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.toRegex(source[, options]);\n *\n * const { output } = picomatch.parse('*.js');\n * console.log(picomatch.toRegex(output));\n * //=> /^(?:(?!\\.)(?=.)[^/]*?\\.js)$/\n * ```\n * @param {String} `source` Regular expression source string.\n * @param {Object} `options`\n * @return {RegExp}\n * @api public\n */\n\npicomatch$4.toRegex = (source, options) => {\n  try {\n    const opts = options || {};\n    return new RegExp(source, opts.flags || (opts.nocase ? 'i' : ''));\n  } catch (err) {\n    if (options && options.debug === true) throw err;\n    return /$^/;\n  }\n};\n\n/**\n * Picomatch constants.\n * @return {Object}\n */\n\npicomatch$4.constants = constants$4;\n\n/**\n * Expose \"picomatch\"\n */\n\nvar picomatch_1 = picomatch$4;\n\n(function (module) {\n\n\tmodule.exports = picomatch_1;\n} (picomatch$5));\n\nvar picomatch$3 = /*@__PURE__*/getDefaultExportFromCjs(picomatchExports);\n\nconst extractors = {\n    ArrayPattern(names, param) {\n        for (const element of param.elements) {\n            if (element)\n                extractors[element.type](names, element);\n        }\n    },\n    AssignmentPattern(names, param) {\n        extractors[param.left.type](names, param.left);\n    },\n    Identifier(names, param) {\n        names.push(param.name);\n    },\n    MemberExpression() { },\n    ObjectPattern(names, param) {\n        for (const prop of param.properties) {\n            // @ts-ignore Typescript reports that this is not a valid type\n            if (prop.type === 'RestElement') {\n                extractors.RestElement(names, prop);\n            }\n            else {\n                extractors[prop.value.type](names, prop.value);\n            }\n        }\n    },\n    RestElement(names, param) {\n        extractors[param.argument.type](names, param.argument);\n    }\n};\nconst extractAssignedNames = function extractAssignedNames(param) {\n    const names = [];\n    extractors[param.type](names, param);\n    return names;\n};\n\nconst blockDeclarations = {\n    const: true,\n    let: true\n};\nlet Scope$1 = class Scope {\n    constructor(options = {}) {\n        this.parent = options.parent;\n        this.isBlockScope = !!options.block;\n        this.declarations = Object.create(null);\n        if (options.params) {\n            options.params.forEach((param) => {\n                extractAssignedNames(param).forEach((name) => {\n                    this.declarations[name] = true;\n                });\n            });\n        }\n    }\n    addDeclaration(node, isBlockDeclaration, isVar) {\n        if (!isBlockDeclaration && this.isBlockScope) {\n            // it's a `var` or function node, and this\n            // is a block scope, so we need to go up\n            this.parent.addDeclaration(node, isBlockDeclaration, isVar);\n        }\n        else if (node.id) {\n            extractAssignedNames(node.id).forEach((name) => {\n                this.declarations[name] = true;\n            });\n        }\n    }\n    contains(name) {\n        return this.declarations[name] || (this.parent ? this.parent.contains(name) : false);\n    }\n};\nconst attachScopes = function attachScopes(ast, propertyName = 'scope') {\n    let scope = new Scope$1();\n    walk$3(ast, {\n        enter(n, parent) {\n            const node = n;\n            // function foo () {...}\n            // class Foo {...}\n            if (/(Function|Class)Declaration/.test(node.type)) {\n                scope.addDeclaration(node, false, false);\n            }\n            // var foo = 1\n            if (node.type === 'VariableDeclaration') {\n                const { kind } = node;\n                const isBlockDeclaration = blockDeclarations[kind];\n                node.declarations.forEach((declaration) => {\n                    scope.addDeclaration(declaration, isBlockDeclaration, true);\n                });\n            }\n            let newScope;\n            // create new function scope\n            if (/Function/.test(node.type)) {\n                const func = node;\n                newScope = new Scope$1({\n                    parent: scope,\n                    block: false,\n                    params: func.params\n                });\n                // named function expressions - the name is considered\n                // part of the function's scope\n                if (func.type === 'FunctionExpression' && func.id) {\n                    newScope.addDeclaration(func, false, false);\n                }\n            }\n            // create new for scope\n            if (/For(In|Of)?Statement/.test(node.type)) {\n                newScope = new Scope$1({\n                    parent: scope,\n                    block: true\n                });\n            }\n            // create new block scope\n            if (node.type === 'BlockStatement' && !/Function/.test(parent.type)) {\n                newScope = new Scope$1({\n                    parent: scope,\n                    block: true\n                });\n            }\n            // catch clause has its own block scope\n            if (node.type === 'CatchClause') {\n                newScope = new Scope$1({\n                    parent: scope,\n                    params: node.param ? [node.param] : [],\n                    block: true\n                });\n            }\n            if (newScope) {\n                Object.defineProperty(node, propertyName, {\n                    value: newScope,\n                    configurable: true\n                });\n                scope = newScope;\n            }\n        },\n        leave(n) {\n            const node = n;\n            if (node[propertyName])\n                scope = scope.parent;\n        }\n    });\n    return scope;\n};\n\n// Helper since Typescript can't detect readonly arrays with Array.isArray\nfunction isArray$2(arg) {\n    return Array.isArray(arg);\n}\nfunction ensureArray(thing) {\n    if (isArray$2(thing))\n        return thing;\n    if (thing == null)\n        return [];\n    return [thing];\n}\n\nconst normalizePath$5 = function normalizePath(filename) {\n    return filename.split(win32.sep).join(posix.sep);\n};\n\nfunction getMatcherString(id, resolutionBase) {\n    if (resolutionBase === false || isAbsolute$1(id) || id.startsWith('*')) {\n        return normalizePath$5(id);\n    }\n    // resolve('') is valid and will default to process.cwd()\n    const basePath = normalizePath$5(resolve$3(resolutionBase || ''))\n        // escape all possible (posix + win) path characters that might interfere with regex\n        .replace(/[-^$*+?.()|[\\]{}]/g, '\\\\$&');\n    // Note that we use posix.join because:\n    // 1. the basePath has been normalized to use /\n    // 2. the incoming glob (id) matcher, also uses /\n    // otherwise Node will force backslash (\\) on windows\n    return posix.join(basePath, normalizePath$5(id));\n}\nconst createFilter$1 = function createFilter(include, exclude, options) {\n    const resolutionBase = options && options.resolve;\n    const getMatcher = (id) => id instanceof RegExp\n        ? id\n        : {\n            test: (what) => {\n                // this refactor is a tad overly verbose but makes for easy debugging\n                const pattern = getMatcherString(id, resolutionBase);\n                const fn = picomatch$3(pattern, { dot: true });\n                const result = fn(what);\n                return result;\n            }\n        };\n    const includeMatchers = ensureArray(include).map(getMatcher);\n    const excludeMatchers = ensureArray(exclude).map(getMatcher);\n    return function result(id) {\n        if (typeof id !== 'string')\n            return false;\n        if (/\\0/.test(id))\n            return false;\n        const pathId = normalizePath$5(id);\n        for (let i = 0; i < excludeMatchers.length; ++i) {\n            const matcher = excludeMatchers[i];\n            if (matcher.test(pathId))\n                return false;\n        }\n        for (let i = 0; i < includeMatchers.length; ++i) {\n            const matcher = includeMatchers[i];\n            if (matcher.test(pathId))\n                return true;\n        }\n        return !includeMatchers.length;\n    };\n};\n\nconst reservedWords$1 = 'break case class catch const continue debugger default delete do else export extends finally for function if import in instanceof let new return super switch this throw try typeof var void while with yield enum await implements package protected static interface private public';\nconst builtins$1 = 'arguments Infinity NaN undefined null true false eval uneval isFinite isNaN parseFloat parseInt decodeURI decodeURIComponent encodeURI encodeURIComponent escape unescape Object Function Boolean Symbol Error EvalError InternalError RangeError ReferenceError SyntaxError TypeError URIError Number Math Date String RegExp Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array Map Set WeakMap WeakSet SIMD ArrayBuffer DataView JSON Promise Generator GeneratorFunction Reflect Proxy Intl';\nconst forbiddenIdentifiers = new Set(`${reservedWords$1} ${builtins$1}`.split(' '));\nforbiddenIdentifiers.add('');\nconst makeLegalIdentifier = function makeLegalIdentifier(str) {\n    let identifier = str\n        .replace(/-(\\w)/g, (_, letter) => letter.toUpperCase())\n        .replace(/[^$_a-zA-Z0-9]/g, '_');\n    if (/\\d/.test(identifier[0]) || forbiddenIdentifiers.has(identifier)) {\n        identifier = `_${identifier}`;\n    }\n    return identifier || '_';\n};\n\nfunction stringify$8(obj) {\n    return (JSON.stringify(obj) || 'undefined').replace(/[\\u2028\\u2029]/g, (char) => `\\\\u${`000${char.charCodeAt(0).toString(16)}`.slice(-4)}`);\n}\nfunction serializeArray(arr, indent, baseIndent) {\n    let output = '[';\n    const separator = indent ? `\\n${baseIndent}${indent}` : '';\n    for (let i = 0; i < arr.length; i++) {\n        const key = arr[i];\n        output += `${i > 0 ? ',' : ''}${separator}${serialize(key, indent, baseIndent + indent)}`;\n    }\n    return `${output}${indent ? `\\n${baseIndent}` : ''}]`;\n}\nfunction serializeObject(obj, indent, baseIndent) {\n    let output = '{';\n    const separator = indent ? `\\n${baseIndent}${indent}` : '';\n    const entries = Object.entries(obj);\n    for (let i = 0; i < entries.length; i++) {\n        const [key, value] = entries[i];\n        const stringKey = makeLegalIdentifier(key) === key ? key : stringify$8(key);\n        output += `${i > 0 ? ',' : ''}${separator}${stringKey}:${indent ? ' ' : ''}${serialize(value, indent, baseIndent + indent)}`;\n    }\n    return `${output}${indent ? `\\n${baseIndent}` : ''}}`;\n}\nfunction serialize(obj, indent, baseIndent) {\n    if (typeof obj === 'object' && obj !== null) {\n        if (Array.isArray(obj))\n            return serializeArray(obj, indent, baseIndent);\n        if (obj instanceof Date)\n            return `new Date(${obj.getTime()})`;\n        if (obj instanceof RegExp)\n            return obj.toString();\n        return serializeObject(obj, indent, baseIndent);\n    }\n    if (typeof obj === 'number') {\n        if (obj === Infinity)\n            return 'Infinity';\n        if (obj === -Infinity)\n            return '-Infinity';\n        if (obj === 0)\n            return 1 / obj === Infinity ? '0' : '-0';\n        if (obj !== obj)\n            return 'NaN'; // eslint-disable-line no-self-compare\n    }\n    if (typeof obj === 'symbol') {\n        const key = Symbol.keyFor(obj);\n        // eslint-disable-next-line no-undefined\n        if (key !== undefined)\n            return `Symbol.for(${stringify$8(key)})`;\n    }\n    if (typeof obj === 'bigint')\n        return `${obj}n`;\n    return stringify$8(obj);\n}\nconst dataToEsm = function dataToEsm(data, options = {}) {\n    const t = options.compact ? '' : 'indent' in options ? options.indent : '\\t';\n    const _ = options.compact ? '' : ' ';\n    const n = options.compact ? '' : '\\n';\n    const declarationType = options.preferConst ? 'const' : 'var';\n    if (options.namedExports === false ||\n        typeof data !== 'object' ||\n        Array.isArray(data) ||\n        data instanceof Date ||\n        data instanceof RegExp ||\n        data === null) {\n        const code = serialize(data, options.compact ? null : t, '');\n        const magic = _ || (/^[{[\\-\\/]/.test(code) ? '' : ' '); // eslint-disable-line no-useless-escape\n        return `export default${magic}${code};`;\n    }\n    let namedExportCode = '';\n    const defaultExportRows = [];\n    for (const [key, value] of Object.entries(data)) {\n        if (key === makeLegalIdentifier(key)) {\n            if (options.objectShorthand)\n                defaultExportRows.push(key);\n            else\n                defaultExportRows.push(`${key}:${_}${key}`);\n            namedExportCode += `export ${declarationType} ${key}${_}=${_}${serialize(value, options.compact ? null : t, '')};${n}`;\n        }\n        else {\n            defaultExportRows.push(`${stringify$8(key)}:${_}${serialize(value, options.compact ? null : t, '')}`);\n        }\n    }\n    return `${namedExportCode}export default${_}{${n}${t}${defaultExportRows.join(`,${n}${t}`)}${n}};${n}`;\n};\n\nvar path$l = require$$0$4;\n\nvar commondir = function (basedir, relfiles) {\n    if (relfiles) {\n        var files = relfiles.map(function (r) {\n            return path$l.resolve(basedir, r);\n        });\n    }\n    else {\n        var files = basedir;\n    }\n    \n    var res = files.slice(1).reduce(function (ps, file) {\n        if (!file.match(/^([A-Za-z]:)?\\/|\\\\/)) {\n            throw new Error('relative path without a basedir');\n        }\n        \n        var xs = file.split(/\\/+|\\\\+/);\n        for (\n            var i = 0;\n            ps[i] === xs[i] && i < Math.min(ps.length, xs.length);\n            i++\n        );\n        return ps.slice(0, i);\n    }, files[0].split(/\\/+|\\\\+/));\n    \n    // Windows correctly handles paths with forward-slashes\n    return res.length > 1 ? res.join('/') : '/'\n};\n\nvar old$1 = {};\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar pathModule = require$$0$4;\nvar isWindows$6 = process.platform === 'win32';\nvar fs$k = require$$0__default;\n\n// JavaScript implementation of realpath, ported from node pre-v6\n\nvar DEBUG$1 = process.env.NODE_DEBUG && /fs/.test(process.env.NODE_DEBUG);\n\nfunction rethrow() {\n  // Only enable in debug mode. A backtrace uses ~1000 bytes of heap space and\n  // is fairly slow to generate.\n  var callback;\n  if (DEBUG$1) {\n    var backtrace = new Error;\n    callback = debugCallback;\n  } else\n    callback = missingCallback;\n\n  return callback;\n\n  function debugCallback(err) {\n    if (err) {\n      backtrace.message = err.message;\n      err = backtrace;\n      missingCallback(err);\n    }\n  }\n\n  function missingCallback(err) {\n    if (err) {\n      if (process.throwDeprecation)\n        throw err;  // Forgot a callback but don't know where? Use NODE_DEBUG=fs\n      else if (!process.noDeprecation) {\n        var msg = 'fs: missing callback ' + (err.stack || err.message);\n        if (process.traceDeprecation)\n          console.trace(msg);\n        else\n          console.error(msg);\n      }\n    }\n  }\n}\n\nfunction maybeCallback(cb) {\n  return typeof cb === 'function' ? cb : rethrow();\n}\n\n// Regexp that finds the next partion of a (partial) path\n// result is [base_with_slash, base], e.g. ['somedir/', 'somedir']\nif (isWindows$6) {\n  var nextPartRe = /(.*?)(?:[\\/\\\\]+|$)/g;\n} else {\n  var nextPartRe = /(.*?)(?:[\\/]+|$)/g;\n}\n\n// Regex to find the device root, including trailing slash. E.g. 'c:\\\\'.\nif (isWindows$6) {\n  var splitRootRe = /^(?:[a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/][^\\\\\\/]+)?[\\\\\\/]*/;\n} else {\n  var splitRootRe = /^[\\/]*/;\n}\n\nold$1.realpathSync = function realpathSync(p, cache) {\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return cache[p];\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows$6 && !knownHard[base]) {\n      fs$k.lstatSync(base);\n      knownHard[base] = true;\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  // NB: p.length changes.\n  while (pos < p.length) {\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      continue;\n    }\n\n    var resolvedLink;\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // some known symbolic link.  no need to stat again.\n      resolvedLink = cache[base];\n    } else {\n      var stat = fs$k.lstatSync(base);\n      if (!stat.isSymbolicLink()) {\n        knownHard[base] = true;\n        if (cache) cache[base] = base;\n        continue;\n      }\n\n      // read the link if it wasn't read before\n      // dev/ino always return 0 on windows, so skip the check.\n      var linkTarget = null;\n      if (!isWindows$6) {\n        var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n        if (seenLinks.hasOwnProperty(id)) {\n          linkTarget = seenLinks[id];\n        }\n      }\n      if (linkTarget === null) {\n        fs$k.statSync(base);\n        linkTarget = fs$k.readlinkSync(base);\n      }\n      resolvedLink = pathModule.resolve(previous, linkTarget);\n      // track this, if given a cache.\n      if (cache) cache[base] = resolvedLink;\n      if (!isWindows$6) seenLinks[id] = linkTarget;\n    }\n\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n\n  if (cache) cache[original] = p;\n\n  return p;\n};\n\n\nold$1.realpath = function realpath(p, cache, cb) {\n  if (typeof cb !== 'function') {\n    cb = maybeCallback(cache);\n    cache = null;\n  }\n\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return process.nextTick(cb.bind(null, null, cache[p]));\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows$6 && !knownHard[base]) {\n      fs$k.lstat(base, function(err) {\n        if (err) return cb(err);\n        knownHard[base] = true;\n        LOOP();\n      });\n    } else {\n      process.nextTick(LOOP);\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  function LOOP() {\n    // stop if scanned past end of path\n    if (pos >= p.length) {\n      if (cache) cache[original] = p;\n      return cb(null, p);\n    }\n\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      return process.nextTick(LOOP);\n    }\n\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // known symbolic link.  no need to stat again.\n      return gotResolvedLink(cache[base]);\n    }\n\n    return fs$k.lstat(base, gotStat);\n  }\n\n  function gotStat(err, stat) {\n    if (err) return cb(err);\n\n    // if not a symlink, skip to the next path part\n    if (!stat.isSymbolicLink()) {\n      knownHard[base] = true;\n      if (cache) cache[base] = base;\n      return process.nextTick(LOOP);\n    }\n\n    // stat & read the link if not read before\n    // call gotTarget as soon as the link target is known\n    // dev/ino always return 0 on windows, so skip the check.\n    if (!isWindows$6) {\n      var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n      if (seenLinks.hasOwnProperty(id)) {\n        return gotTarget(null, seenLinks[id], base);\n      }\n    }\n    fs$k.stat(base, function(err) {\n      if (err) return cb(err);\n\n      fs$k.readlink(base, function(err, target) {\n        if (!isWindows$6) seenLinks[id] = target;\n        gotTarget(err, target);\n      });\n    });\n  }\n\n  function gotTarget(err, target, base) {\n    if (err) return cb(err);\n\n    var resolvedLink = pathModule.resolve(previous, target);\n    if (cache) cache[base] = resolvedLink;\n    gotResolvedLink(resolvedLink);\n  }\n\n  function gotResolvedLink(resolvedLink) {\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n};\n\nvar fs_realpath = realpath$2;\nrealpath$2.realpath = realpath$2;\nrealpath$2.sync = realpathSync;\nrealpath$2.realpathSync = realpathSync;\nrealpath$2.monkeypatch = monkeypatch;\nrealpath$2.unmonkeypatch = unmonkeypatch;\n\nvar fs$j = require$$0__default;\nvar origRealpath = fs$j.realpath;\nvar origRealpathSync = fs$j.realpathSync;\n\nvar version$4 = process.version;\nvar ok = /^v[0-5]\\./.test(version$4);\nvar old = old$1;\n\nfunction newError (er) {\n  return er && er.syscall === 'realpath' && (\n    er.code === 'ELOOP' ||\n    er.code === 'ENOMEM' ||\n    er.code === 'ENAMETOOLONG'\n  )\n}\n\nfunction realpath$2 (p, cache, cb) {\n  if (ok) {\n    return origRealpath(p, cache, cb)\n  }\n\n  if (typeof cache === 'function') {\n    cb = cache;\n    cache = null;\n  }\n  origRealpath(p, cache, function (er, result) {\n    if (newError(er)) {\n      old.realpath(p, cache, cb);\n    } else {\n      cb(er, result);\n    }\n  });\n}\n\nfunction realpathSync (p, cache) {\n  if (ok) {\n    return origRealpathSync(p, cache)\n  }\n\n  try {\n    return origRealpathSync(p, cache)\n  } catch (er) {\n    if (newError(er)) {\n      return old.realpathSync(p, cache)\n    } else {\n      throw er\n    }\n  }\n}\n\nfunction monkeypatch () {\n  fs$j.realpath = realpath$2;\n  fs$j.realpathSync = realpathSync;\n}\n\nfunction unmonkeypatch () {\n  fs$j.realpath = origRealpath;\n  fs$j.realpathSync = origRealpathSync;\n}\n\nconst isWindows$5 = typeof process === 'object' &&\n  process &&\n  process.platform === 'win32';\nvar path$k = isWindows$5 ? { sep: '\\\\' } : { sep: '/' };\n\nvar balancedMatch = balanced$1;\nfunction balanced$1(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range$1(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced$1.range = range$1;\nfunction range$1(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if(a===b) {\n      return [ai, bi];\n    }\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n\nvar balanced = balancedMatch;\n\nvar braceExpansion = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand$4(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand$4(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m) return [str];\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand$4(m.post, false)\n    : [''];\n\n  if (/\\$$/.test(m.pre)) {    \n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre+ '{' + m.body + '}' + post[k];\n      expansions.push(expansion);\n    }\n  } else {\n    var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n    var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n    var isSequence = isNumericSequence || isAlphaSequence;\n    var isOptions = m.body.indexOf(',') >= 0;\n    if (!isSequence && !isOptions) {\n      // {a},b}\n      if (m.post.match(/,.*\\}/)) {\n        str = m.pre + '{' + m.body + escClose + m.post;\n        return expand$4(str);\n      }\n      return [str];\n    }\n\n    var n;\n    if (isSequence) {\n      n = m.body.split(/\\.\\./);\n    } else {\n      n = parseCommaParts(m.body);\n      if (n.length === 1) {\n        // x{{a,b}}y ==> x{a}y x{b}y\n        n = expand$4(n[0], false).map(embrace);\n        if (n.length === 1) {\n          return post.map(function(p) {\n            return m.pre + n[0] + p;\n          });\n        }\n      }\n    }\n\n    // at this point, n is the parts, and we know it's not a comma set\n    // with a single entry.\n    var N;\n\n    if (isSequence) {\n      var x = numeric(n[0]);\n      var y = numeric(n[1]);\n      var width = Math.max(n[0].length, n[1].length);\n      var incr = n.length == 3\n        ? Math.abs(numeric(n[2]))\n        : 1;\n      var test = lte;\n      var reverse = y < x;\n      if (reverse) {\n        incr *= -1;\n        test = gte;\n      }\n      var pad = n.some(isPadded);\n\n      N = [];\n\n      for (var i = x; test(i, y); i += incr) {\n        var c;\n        if (isAlphaSequence) {\n          c = String.fromCharCode(i);\n          if (c === '\\\\')\n            c = '';\n        } else {\n          c = String(i);\n          if (pad) {\n            var need = width - c.length;\n            if (need > 0) {\n              var z = new Array(need + 1).join('0');\n              if (i < 0)\n                c = '-' + z + c.slice(1);\n              else\n                c = z + c;\n            }\n          }\n        }\n        N.push(c);\n      }\n    } else {\n      N = [];\n\n      for (var j = 0; j < n.length; j++) {\n        N.push.apply(N, expand$4(n[j], false));\n      }\n    }\n\n    for (var j = 0; j < N.length; j++) {\n      for (var k = 0; k < post.length; k++) {\n        var expansion = pre + N[j] + post[k];\n        if (!isTop || isSequence || expansion)\n          expansions.push(expansion);\n      }\n    }\n  }\n\n  return expansions;\n}\n\nconst minimatch$1 = minimatch_1 = (p, pattern, options = {}) => {\n  assertValidPattern(pattern);\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  return new Minimatch$1(pattern, options).match(p)\n};\n\nvar minimatch_1 = minimatch$1;\n\nconst path$j = path$k;\nminimatch$1.sep = path$j.sep;\n\nconst GLOBSTAR$2 = Symbol('globstar **');\nminimatch$1.GLOBSTAR = GLOBSTAR$2;\nconst expand$3 = braceExpansion;\n\nconst plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n};\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nconst qmark = '[^/]';\n\n// * => any number of characters\nconst star = qmark + '*?';\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nconst twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?';\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nconst twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?';\n\n// \"abc\" -> { a:true, b:true, c:true }\nconst charSet = s => s.split('').reduce((set, c) => {\n  set[c] = true;\n  return set\n}, {});\n\n// characters that need to be escaped in RegExp.\nconst reSpecials = charSet('().*{}+?[]^$\\\\!');\n\n// characters that indicate we have to add the pattern start\nconst addPatternStartSet = charSet('[.(');\n\n// normalizes slashes.\nconst slashSplit = /\\/+/;\n\nminimatch$1.filter = (pattern, options = {}) =>\n  (p, i, list) => minimatch$1(p, pattern, options);\n\nconst ext = (a, b = {}) => {\n  const t = {};\n  Object.keys(a).forEach(k => t[k] = a[k]);\n  Object.keys(b).forEach(k => t[k] = b[k]);\n  return t\n};\n\nminimatch$1.defaults = def => {\n  if (!def || typeof def !== 'object' || !Object.keys(def).length) {\n    return minimatch$1\n  }\n\n  const orig = minimatch$1;\n\n  const m = (p, pattern, options) => orig(p, pattern, ext(def, options));\n  m.Minimatch = class Minimatch extends orig.Minimatch {\n    constructor (pattern, options) {\n      super(pattern, ext(def, options));\n    }\n  };\n  m.Minimatch.defaults = options => orig.defaults(ext(def, options)).Minimatch;\n  m.filter = (pattern, options) => orig.filter(pattern, ext(def, options));\n  m.defaults = options => orig.defaults(ext(def, options));\n  m.makeRe = (pattern, options) => orig.makeRe(pattern, ext(def, options));\n  m.braceExpand = (pattern, options) => orig.braceExpand(pattern, ext(def, options));\n  m.match = (list, pattern, options) => orig.match(list, pattern, ext(def, options));\n\n  return m\n};\n\n\n\n\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch$1.braceExpand = (pattern, options) => braceExpand(pattern, options);\n\nconst braceExpand = (pattern, options = {}) => {\n  assertValidPattern(pattern);\n\n  // Thanks to Yeting Li <https://github.com/yetingli> for\n  // improving this regexp to avoid a ReDOS vulnerability.\n  if (options.nobrace || !/\\{(?:(?!\\{).)*\\}/.test(pattern)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand$3(pattern)\n};\n\nconst MAX_PATTERN_LENGTH = 1024 * 64;\nconst assertValidPattern = pattern => {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('invalid pattern')\n  }\n\n  if (pattern.length > MAX_PATTERN_LENGTH) {\n    throw new TypeError('pattern is too long')\n  }\n};\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nconst SUBPARSE = Symbol('subparse');\n\nminimatch$1.makeRe = (pattern, options) =>\n  new Minimatch$1(pattern, options || {}).makeRe();\n\nminimatch$1.match = (list, pattern, options = {}) => {\n  const mm = new Minimatch$1(pattern, options);\n  list = list.filter(f => mm.match(f));\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern);\n  }\n  return list\n};\n\n// replace stuff like \\* with *\nconst globUnescape = s => s.replace(/\\\\(.)/g, '$1');\nconst regExpEscape = s => s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n\nlet Minimatch$1 = class Minimatch {\n  constructor (pattern, options) {\n    assertValidPattern(pattern);\n\n    if (!options) options = {};\n\n    this.options = options;\n    this.set = [];\n    this.pattern = pattern;\n    this.windowsPathsNoEscape = !!options.windowsPathsNoEscape ||\n      options.allowWindowsEscape === false;\n    if (this.windowsPathsNoEscape) {\n      this.pattern = this.pattern.replace(/\\\\/g, '/');\n    }\n    this.regexp = null;\n    this.negate = false;\n    this.comment = false;\n    this.empty = false;\n    this.partial = !!options.partial;\n\n    // make the set of regexps etc.\n    this.make();\n  }\n\n  debug () {}\n\n  make () {\n    const pattern = this.pattern;\n    const options = this.options;\n\n    // empty patterns and comments match nothing.\n    if (!options.nocomment && pattern.charAt(0) === '#') {\n      this.comment = true;\n      return\n    }\n    if (!pattern) {\n      this.empty = true;\n      return\n    }\n\n    // step 1: figure out negation, etc.\n    this.parseNegate();\n\n    // step 2: expand braces\n    let set = this.globSet = this.braceExpand();\n\n    if (options.debug) this.debug = (...args) => console.error(...args);\n\n    this.debug(this.pattern, set);\n\n    // step 3: now we have a set, so turn each one into a series of path-portion\n    // matching patterns.\n    // These will be regexps, except in the case of \"**\", which is\n    // set to the GLOBSTAR object for globstar behavior,\n    // and will not contain any / characters\n    set = this.globParts = set.map(s => s.split(slashSplit));\n\n    this.debug(this.pattern, set);\n\n    // glob --> regexps\n    set = set.map((s, si, set) => s.map(this.parse, this));\n\n    this.debug(this.pattern, set);\n\n    // filter out everything that didn't compile properly.\n    set = set.filter(s => s.indexOf(false) === -1);\n\n    this.debug(this.pattern, set);\n\n    this.set = set;\n  }\n\n  parseNegate () {\n    if (this.options.nonegate) return\n\n    const pattern = this.pattern;\n    let negate = false;\n    let negateOffset = 0;\n\n    for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {\n      negate = !negate;\n      negateOffset++;\n    }\n\n    if (negateOffset) this.pattern = pattern.substr(negateOffset);\n    this.negate = negate;\n  }\n\n  // set partial to true to test if, for example,\n  // \"/a/b\" matches the start of \"/*/b/*/d\"\n  // Partial means, if you run out of file before you run\n  // out of pattern, then that's fine, as long as all\n  // the parts match.\n  matchOne (file, pattern, partial) {\n    var options = this.options;\n\n    this.debug('matchOne',\n      { 'this': this, file: file, pattern: pattern });\n\n    this.debug('matchOne', file.length, pattern.length);\n\n    for (var fi = 0,\n        pi = 0,\n        fl = file.length,\n        pl = pattern.length\n        ; (fi < fl) && (pi < pl)\n        ; fi++, pi++) {\n      this.debug('matchOne loop');\n      var p = pattern[pi];\n      var f = file[fi];\n\n      this.debug(pattern, p, f);\n\n      // should be impossible.\n      // some invalid regexp stuff in the set.\n      /* istanbul ignore if */\n      if (p === false) return false\n\n      if (p === GLOBSTAR$2) {\n        this.debug('GLOBSTAR', [pattern, p, f]);\n\n        // \"**\"\n        // a/**/b/**/c would match the following:\n        // a/b/x/y/z/c\n        // a/x/y/z/b/c\n        // a/b/x/b/x/c\n        // a/b/c\n        // To do this, take the rest of the pattern after\n        // the **, and see if it would match the file remainder.\n        // If so, return success.\n        // If not, the ** \"swallows\" a segment, and try again.\n        // This is recursively awful.\n        //\n        // a/**/b/**/c matching a/b/x/y/z/c\n        // - a matches a\n        // - doublestar\n        //   - matchOne(b/x/y/z/c, b/**/c)\n        //     - b matches b\n        //     - doublestar\n        //       - matchOne(x/y/z/c, c) -> no\n        //       - matchOne(y/z/c, c) -> no\n        //       - matchOne(z/c, c) -> no\n        //       - matchOne(c, c) yes, hit\n        var fr = fi;\n        var pr = pi + 1;\n        if (pr === pl) {\n          this.debug('** at the end');\n          // a ** at the end will just swallow the rest.\n          // We have found a match.\n          // however, it will not swallow /.x, unless\n          // options.dot is set.\n          // . and .. are *never* matched by **, for explosively\n          // exponential reasons.\n          for (; fi < fl; fi++) {\n            if (file[fi] === '.' || file[fi] === '..' ||\n              (!options.dot && file[fi].charAt(0) === '.')) return false\n          }\n          return true\n        }\n\n        // ok, let's see if we can swallow whatever we can.\n        while (fr < fl) {\n          var swallowee = file[fr];\n\n          this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee);\n\n          // XXX remove this slice.  Just pass the start index.\n          if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n            this.debug('globstar found match!', fr, fl, swallowee);\n            // found a match.\n            return true\n          } else {\n            // can't swallow \".\" or \"..\" ever.\n            // can only swallow \".foo\" when explicitly asked.\n            if (swallowee === '.' || swallowee === '..' ||\n              (!options.dot && swallowee.charAt(0) === '.')) {\n              this.debug('dot detected!', file, fr, pattern, pr);\n              break\n            }\n\n            // ** swallows a segment, and continue.\n            this.debug('globstar swallow a segment, and continue');\n            fr++;\n          }\n        }\n\n        // no match was found.\n        // However, in partial mode, we can't say this is necessarily over.\n        // If there's more *pattern* left, then\n        /* istanbul ignore if */\n        if (partial) {\n          // ran out of file\n          this.debug('\\n>>> no match, partial?', file, fr, pattern, pr);\n          if (fr === fl) return true\n        }\n        return false\n      }\n\n      // something other than **\n      // non-magic patterns just have to match exactly\n      // patterns with magic have been turned into regexps.\n      var hit;\n      if (typeof p === 'string') {\n        hit = f === p;\n        this.debug('string match', p, f, hit);\n      } else {\n        hit = f.match(p);\n        this.debug('pattern match', p, f, hit);\n      }\n\n      if (!hit) return false\n    }\n\n    // Note: ending in / means that we'll get a final \"\"\n    // at the end of the pattern.  This can only match a\n    // corresponding \"\" at the end of the file.\n    // If the file ends in /, then it can only match a\n    // a pattern that ends in /, unless the pattern just\n    // doesn't have any more for it. But, a/b/ should *not*\n    // match \"a/b/*\", even though \"\" matches against the\n    // [^/]*? pattern, except in partial mode, where it might\n    // simply not be reached yet.\n    // However, a/b/ should still satisfy a/*\n\n    // now either we fell off the end of the pattern, or we're done.\n    if (fi === fl && pi === pl) {\n      // ran out of pattern and filename at the same time.\n      // an exact hit!\n      return true\n    } else if (fi === fl) {\n      // ran out of file, but still had pattern left.\n      // this is ok if we're doing the match as part of\n      // a glob fs traversal.\n      return partial\n    } else /* istanbul ignore else */ if (pi === pl) {\n      // ran out of pattern, still have file left.\n      // this is only acceptable if we're on the very last\n      // empty segment of a file with a trailing slash.\n      // a/* should match a/b/\n      return (fi === fl - 1) && (file[fi] === '')\n    }\n\n    // should be unreachable.\n    /* istanbul ignore next */\n    throw new Error('wtf?')\n  }\n\n  braceExpand () {\n    return braceExpand(this.pattern, this.options)\n  }\n\n  parse (pattern, isSub) {\n    assertValidPattern(pattern);\n\n    const options = this.options;\n\n    // shortcuts\n    if (pattern === '**') {\n      if (!options.noglobstar)\n        return GLOBSTAR$2\n      else\n        pattern = '*';\n    }\n    if (pattern === '') return ''\n\n    let re = '';\n    let hasMagic = !!options.nocase;\n    let escaping = false;\n    // ? => one single character\n    const patternListStack = [];\n    const negativeLists = [];\n    let stateChar;\n    let inClass = false;\n    let reClassStart = -1;\n    let classStart = -1;\n    let cs;\n    let pl;\n    let sp;\n    // . and .. never match anything that doesn't start with .,\n    // even when options.dot is set.\n    const patternStart = pattern.charAt(0) === '.' ? '' // anything\n    // not (start or / followed by . or .. followed by / or end)\n    : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n    : '(?!\\\\.)';\n\n    const clearStateChar = () => {\n      if (stateChar) {\n        // we had some state-tracking character\n        // that wasn't consumed by this pass.\n        switch (stateChar) {\n          case '*':\n            re += star;\n            hasMagic = true;\n          break\n          case '?':\n            re += qmark;\n            hasMagic = true;\n          break\n          default:\n            re += '\\\\' + stateChar;\n          break\n        }\n        this.debug('clearStateChar %j %j', stateChar, re);\n        stateChar = false;\n      }\n    };\n\n    for (let i = 0, c; (i < pattern.length) && (c = pattern.charAt(i)); i++) {\n      this.debug('%s\\t%s %s %j', pattern, i, re, c);\n\n      // skip over any that are escaped.\n      if (escaping) {\n        /* istanbul ignore next - completely not allowed, even escaped. */\n        if (c === '/') {\n          return false\n        }\n\n        if (reSpecials[c]) {\n          re += '\\\\';\n        }\n        re += c;\n        escaping = false;\n        continue\n      }\n\n      switch (c) {\n        /* istanbul ignore next */\n        case '/': {\n          // Should already be path-split by now.\n          return false\n        }\n\n        case '\\\\':\n          clearStateChar();\n          escaping = true;\n        continue\n\n        // the various stateChar values\n        // for the \"extglob\" stuff.\n        case '?':\n        case '*':\n        case '+':\n        case '@':\n        case '!':\n          this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c);\n\n          // all of those are literals inside a class, except that\n          // the glob [!a] means [^a] in regexp\n          if (inClass) {\n            this.debug('  in class');\n            if (c === '!' && i === classStart + 1) c = '^';\n            re += c;\n            continue\n          }\n\n          // if we already have a stateChar, then it means\n          // that there was something like ** or +? in there.\n          // Handle the stateChar, then proceed with this one.\n          this.debug('call clearStateChar %j', stateChar);\n          clearStateChar();\n          stateChar = c;\n          // if extglob is disabled, then +(asdf|foo) isn't a thing.\n          // just clear the statechar *now*, rather than even diving into\n          // the patternList stuff.\n          if (options.noext) clearStateChar();\n        continue\n\n        case '(':\n          if (inClass) {\n            re += '(';\n            continue\n          }\n\n          if (!stateChar) {\n            re += '\\\\(';\n            continue\n          }\n\n          patternListStack.push({\n            type: stateChar,\n            start: i - 1,\n            reStart: re.length,\n            open: plTypes[stateChar].open,\n            close: plTypes[stateChar].close\n          });\n          // negation is (?:(?!js)[^/]*)\n          re += stateChar === '!' ? '(?:(?!(?:' : '(?:';\n          this.debug('plType %j %j', stateChar, re);\n          stateChar = false;\n        continue\n\n        case ')':\n          if (inClass || !patternListStack.length) {\n            re += '\\\\)';\n            continue\n          }\n\n          clearStateChar();\n          hasMagic = true;\n          pl = patternListStack.pop();\n          // negation is (?:(?!js)[^/]*)\n          // The others are (?:<pattern>)<type>\n          re += pl.close;\n          if (pl.type === '!') {\n            negativeLists.push(pl);\n          }\n          pl.reEnd = re.length;\n        continue\n\n        case '|':\n          if (inClass || !patternListStack.length) {\n            re += '\\\\|';\n            continue\n          }\n\n          clearStateChar();\n          re += '|';\n        continue\n\n        // these are mostly the same in regexp and glob\n        case '[':\n          // swallow any state-tracking char before the [\n          clearStateChar();\n\n          if (inClass) {\n            re += '\\\\' + c;\n            continue\n          }\n\n          inClass = true;\n          classStart = i;\n          reClassStart = re.length;\n          re += c;\n        continue\n\n        case ']':\n          //  a right bracket shall lose its special\n          //  meaning and represent itself in\n          //  a bracket expression if it occurs\n          //  first in the list.  -- POSIX.2 2.8.3.2\n          if (i === classStart + 1 || !inClass) {\n            re += '\\\\' + c;\n            continue\n          }\n\n          // handle the case where we left a class open.\n          // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          cs = pattern.substring(classStart + 1, i);\n\n          // finish up the class.\n          hasMagic = true;\n          inClass = false;\n          re += c;\n        continue\n\n        default:\n          // swallow any state char that wasn't consumed\n          clearStateChar();\n\n          if (reSpecials[c] && !(c === '^' && inClass)) {\n            re += '\\\\';\n          }\n\n          re += c;\n          break\n\n      } // switch\n    } // for\n\n    // handle the case where we left a class open.\n    // \"[abc\" is valid, equivalent to \"\\[abc\"\n    if (inClass) {\n      // split where the last [ was, and escape it\n      // this is a huge pita.  We now have to re-walk\n      // the contents of the would-be class to re-translate\n      // any characters that were passed through as-is\n      cs = pattern.substr(classStart + 1);\n      sp = this.parse(cs, SUBPARSE);\n      re = re.substr(0, reClassStart) + '\\\\[' + sp[0];\n      hasMagic = hasMagic || sp[1];\n    }\n\n    // handle the case where we had a +( thing at the *end*\n    // of the pattern.\n    // each pattern list stack adds 3 chars, and we need to go through\n    // and escape any | chars that were passed through as-is for the regexp.\n    // Go through and escape them, taking care not to double-escape any\n    // | chars that were already escaped.\n    for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n      let tail;\n      tail = re.slice(pl.reStart + pl.open.length);\n      this.debug('setting tail', re, pl);\n      // maybe some even number of \\, then maybe 1 \\, followed by a |\n      tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, (_, $1, $2) => {\n        /* istanbul ignore else - should already be done */\n        if (!$2) {\n          // the | isn't already escaped, so escape it.\n          $2 = '\\\\';\n        }\n\n        // need to escape all those slashes *again*, without escaping the\n        // one that we need for escaping the | character.  As it works out,\n        // escaping an even number of slashes can be done by simply repeating\n        // it exactly after itself.  That's why this trick works.\n        //\n        // I am sorry that you have to see this.\n        return $1 + $1 + $2 + '|'\n      });\n\n      this.debug('tail=%j\\n   %s', tail, tail, pl, re);\n      const t = pl.type === '*' ? star\n        : pl.type === '?' ? qmark\n        : '\\\\' + pl.type;\n\n      hasMagic = true;\n      re = re.slice(0, pl.reStart) + t + '\\\\(' + tail;\n    }\n\n    // handle trailing things that only matter at the very end.\n    clearStateChar();\n    if (escaping) {\n      // trailing \\\\\n      re += '\\\\\\\\';\n    }\n\n    // only need to apply the nodot start if the re starts with\n    // something that could conceivably capture a dot\n    const addPatternStart = addPatternStartSet[re.charAt(0)];\n\n    // Hack to work around lack of negative lookbehind in JS\n    // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n    // like 'a.xyz.yz' doesn't match.  So, the first negative\n    // lookahead, has to look ALL the way ahead, to the end of\n    // the pattern.\n    for (let n = negativeLists.length - 1; n > -1; n--) {\n      const nl = negativeLists[n];\n\n      const nlBefore = re.slice(0, nl.reStart);\n      const nlFirst = re.slice(nl.reStart, nl.reEnd - 8);\n      let nlAfter = re.slice(nl.reEnd);\n      const nlLast = re.slice(nl.reEnd - 8, nl.reEnd) + nlAfter;\n\n      // Handle nested stuff like *(*.js|!(*.json)), where open parens\n      // mean that we should *not* include the ) in the bit that is considered\n      // \"after\" the negated section.\n      const openParensBefore = nlBefore.split('(').length - 1;\n      let cleanAfter = nlAfter;\n      for (let i = 0; i < openParensBefore; i++) {\n        cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '');\n      }\n      nlAfter = cleanAfter;\n\n      const dollar = nlAfter === '' && isSub !== SUBPARSE ? '$' : '';\n      re = nlBefore + nlFirst + nlAfter + dollar + nlLast;\n    }\n\n    // if the re is not \"\" at this point, then we need to make sure\n    // it doesn't match against an empty path part.\n    // Otherwise a/* will match a/, which it should not.\n    if (re !== '' && hasMagic) {\n      re = '(?=.)' + re;\n    }\n\n    if (addPatternStart) {\n      re = patternStart + re;\n    }\n\n    // parsing just a piece of a larger pattern.\n    if (isSub === SUBPARSE) {\n      return [re, hasMagic]\n    }\n\n    // skip the regexp for non-magical patterns\n    // unescape anything in it, though, so that it'll be\n    // an exact match against a file etc.\n    if (!hasMagic) {\n      return globUnescape(pattern)\n    }\n\n    const flags = options.nocase ? 'i' : '';\n    try {\n      return Object.assign(new RegExp('^' + re + '$', flags), {\n        _glob: pattern,\n        _src: re,\n      })\n    } catch (er) /* istanbul ignore next - should be impossible */ {\n      // If it was an invalid regular expression, then it can't match\n      // anything.  This trick looks for a character after the end of\n      // the string, which is of course impossible, except in multi-line\n      // mode, but it's not a /m regex.\n      return new RegExp('$.')\n    }\n  }\n\n  makeRe () {\n    if (this.regexp || this.regexp === false) return this.regexp\n\n    // at this point, this.set is a 2d array of partial\n    // pattern strings, or \"**\".\n    //\n    // It's better to use .match().  This function shouldn't\n    // be used, really, but it's pretty convenient sometimes,\n    // when you just want to work with a regex.\n    const set = this.set;\n\n    if (!set.length) {\n      this.regexp = false;\n      return this.regexp\n    }\n    const options = this.options;\n\n    const twoStar = options.noglobstar ? star\n      : options.dot ? twoStarDot\n      : twoStarNoDot;\n    const flags = options.nocase ? 'i' : '';\n\n    // coalesce globstars and regexpify non-globstar patterns\n    // if it's the only item, then we just do one twoStar\n    // if it's the first, and there are more, prepend (\\/|twoStar\\/)? to next\n    // if it's the last, append (\\/twoStar|) to previous\n    // if it's in the middle, append (\\/|\\/twoStar\\/) to previous\n    // then filter out GLOBSTAR symbols\n    let re = set.map(pattern => {\n      pattern = pattern.map(p =>\n        typeof p === 'string' ? regExpEscape(p)\n        : p === GLOBSTAR$2 ? GLOBSTAR$2\n        : p._src\n      ).reduce((set, p) => {\n        if (!(set[set.length - 1] === GLOBSTAR$2 && p === GLOBSTAR$2)) {\n          set.push(p);\n        }\n        return set\n      }, []);\n      pattern.forEach((p, i) => {\n        if (p !== GLOBSTAR$2 || pattern[i-1] === GLOBSTAR$2) {\n          return\n        }\n        if (i === 0) {\n          if (pattern.length > 1) {\n            pattern[i+1] = '(?:\\\\\\/|' + twoStar + '\\\\\\/)?' + pattern[i+1];\n          } else {\n            pattern[i] = twoStar;\n          }\n        } else if (i === pattern.length - 1) {\n          pattern[i-1] += '(?:\\\\\\/|' + twoStar + ')?';\n        } else {\n          pattern[i-1] += '(?:\\\\\\/|\\\\\\/' + twoStar + '\\\\\\/)' + pattern[i+1];\n          pattern[i+1] = GLOBSTAR$2;\n        }\n      });\n      return pattern.filter(p => p !== GLOBSTAR$2).join('/')\n    }).join('|');\n\n    // must match entire pattern\n    // ending in a * or ** will make it less strict.\n    re = '^(?:' + re + ')$';\n\n    // can match anything, as long as it's not this.\n    if (this.negate) re = '^(?!' + re + ').*$';\n\n    try {\n      this.regexp = new RegExp(re, flags);\n    } catch (ex) /* istanbul ignore next - should be impossible */ {\n      this.regexp = false;\n    }\n    return this.regexp\n  }\n\n  match (f, partial = this.partial) {\n    this.debug('match', f, this.pattern);\n    // short-circuit in the case of busted things.\n    // comments, etc.\n    if (this.comment) return false\n    if (this.empty) return f === ''\n\n    if (f === '/' && partial) return true\n\n    const options = this.options;\n\n    // windows: need to use /, not \\\n    if (path$j.sep !== '/') {\n      f = f.split(path$j.sep).join('/');\n    }\n\n    // treat the test path as a set of pathparts.\n    f = f.split(slashSplit);\n    this.debug(this.pattern, 'split', f);\n\n    // just ONE of the pattern sets in this.set needs to match\n    // in order for it to be valid.  If negating, then just one\n    // match means that we have failed.\n    // Either way, return on the first hit.\n\n    const set = this.set;\n    this.debug(this.pattern, 'set', set);\n\n    // Find the basename of the path by looking for the last non-empty segment\n    let filename;\n    for (let i = f.length - 1; i >= 0; i--) {\n      filename = f[i];\n      if (filename) break\n    }\n\n    for (let i = 0; i < set.length; i++) {\n      const pattern = set[i];\n      let file = f;\n      if (options.matchBase && pattern.length === 1) {\n        file = [filename];\n      }\n      const hit = this.matchOne(file, pattern, partial);\n      if (hit) {\n        if (options.flipNegate) return true\n        return !this.negate\n      }\n    }\n\n    // didn't get any hits.  this is success if it's a negative\n    // pattern, failure otherwise.\n    if (options.flipNegate) return false\n    return this.negate\n  }\n\n  static defaults (def) {\n    return minimatch$1.defaults(def).Minimatch\n  }\n};\n\nminimatch$1.Minimatch = Minimatch$1;\n\nvar inheritsExports = {};\nvar inherits = {\n  get exports(){ return inheritsExports; },\n  set exports(v){ inheritsExports = v; },\n};\n\nvar inherits_browserExports = {};\nvar inherits_browser = {\n  get exports(){ return inherits_browserExports; },\n  set exports(v){ inherits_browserExports = v; },\n};\n\nvar hasRequiredInherits_browser;\n\nfunction requireInherits_browser () {\n\tif (hasRequiredInherits_browser) return inherits_browserExports;\n\thasRequiredInherits_browser = 1;\n\tif (typeof Object.create === 'function') {\n\t  // implementation from standard node.js 'util' module\n\t  inherits_browser.exports = function inherits(ctor, superCtor) {\n\t    if (superCtor) {\n\t      ctor.super_ = superCtor;\n\t      ctor.prototype = Object.create(superCtor.prototype, {\n\t        constructor: {\n\t          value: ctor,\n\t          enumerable: false,\n\t          writable: true,\n\t          configurable: true\n\t        }\n\t      });\n\t    }\n\t  };\n\t} else {\n\t  // old school shim for old browsers\n\t  inherits_browser.exports = function inherits(ctor, superCtor) {\n\t    if (superCtor) {\n\t      ctor.super_ = superCtor;\n\t      var TempCtor = function () {};\n\t      TempCtor.prototype = superCtor.prototype;\n\t      ctor.prototype = new TempCtor();\n\t      ctor.prototype.constructor = ctor;\n\t    }\n\t  };\n\t}\n\treturn inherits_browserExports;\n}\n\n(function (module) {\n\ttry {\n\t  var util = require('util');\n\t  /* istanbul ignore next */\n\t  if (typeof util.inherits !== 'function') throw '';\n\t  module.exports = util.inherits;\n\t} catch (e) {\n\t  /* istanbul ignore next */\n\t  module.exports = requireInherits_browser();\n\t}\n} (inherits));\n\nvar common$c = {};\n\ncommon$c.setopts = setopts;\ncommon$c.ownProp = ownProp;\ncommon$c.makeAbs = makeAbs;\ncommon$c.finish = finish;\ncommon$c.mark = mark;\ncommon$c.isIgnored = isIgnored;\ncommon$c.childrenIgnored = childrenIgnored;\n\nfunction ownProp (obj, field) {\n  return Object.prototype.hasOwnProperty.call(obj, field)\n}\n\nvar fs$i = require$$0__default;\nvar path$i = require$$0$4;\nvar minimatch = minimatch_1;\nvar isAbsolute = require$$0$4.isAbsolute;\nvar Minimatch = minimatch.Minimatch;\n\nfunction alphasort (a, b) {\n  return a.localeCompare(b, 'en')\n}\n\nfunction setupIgnores (self, options) {\n  self.ignore = options.ignore || [];\n\n  if (!Array.isArray(self.ignore))\n    self.ignore = [self.ignore];\n\n  if (self.ignore.length) {\n    self.ignore = self.ignore.map(ignoreMap);\n  }\n}\n\n// ignore patterns are always in dot:true mode.\nfunction ignoreMap (pattern) {\n  var gmatcher = null;\n  if (pattern.slice(-3) === '/**') {\n    var gpattern = pattern.replace(/(\\/\\*\\*)+$/, '');\n    gmatcher = new Minimatch(gpattern, { dot: true });\n  }\n\n  return {\n    matcher: new Minimatch(pattern, { dot: true }),\n    gmatcher: gmatcher\n  }\n}\n\nfunction setopts (self, pattern, options) {\n  if (!options)\n    options = {};\n\n  // base-matching: just use globstar for that.\n  if (options.matchBase && -1 === pattern.indexOf(\"/\")) {\n    if (options.noglobstar) {\n      throw new Error(\"base matching requires globstar\")\n    }\n    pattern = \"**/\" + pattern;\n  }\n\n  self.silent = !!options.silent;\n  self.pattern = pattern;\n  self.strict = options.strict !== false;\n  self.realpath = !!options.realpath;\n  self.realpathCache = options.realpathCache || Object.create(null);\n  self.follow = !!options.follow;\n  self.dot = !!options.dot;\n  self.mark = !!options.mark;\n  self.nodir = !!options.nodir;\n  if (self.nodir)\n    self.mark = true;\n  self.sync = !!options.sync;\n  self.nounique = !!options.nounique;\n  self.nonull = !!options.nonull;\n  self.nosort = !!options.nosort;\n  self.nocase = !!options.nocase;\n  self.stat = !!options.stat;\n  self.noprocess = !!options.noprocess;\n  self.absolute = !!options.absolute;\n  self.fs = options.fs || fs$i;\n\n  self.maxLength = options.maxLength || Infinity;\n  self.cache = options.cache || Object.create(null);\n  self.statCache = options.statCache || Object.create(null);\n  self.symlinks = options.symlinks || Object.create(null);\n\n  setupIgnores(self, options);\n\n  self.changedCwd = false;\n  var cwd = process.cwd();\n  if (!ownProp(options, \"cwd\"))\n    self.cwd = path$i.resolve(cwd);\n  else {\n    self.cwd = path$i.resolve(options.cwd);\n    self.changedCwd = self.cwd !== cwd;\n  }\n\n  self.root = options.root || path$i.resolve(self.cwd, \"/\");\n  self.root = path$i.resolve(self.root);\n\n  // TODO: is an absolute `cwd` supposed to be resolved against `root`?\n  // e.g. { cwd: '/test', root: __dirname } === path.join(__dirname, '/test')\n  self.cwdAbs = isAbsolute(self.cwd) ? self.cwd : makeAbs(self, self.cwd);\n  self.nomount = !!options.nomount;\n\n  if (process.platform === \"win32\") {\n    self.root = self.root.replace(/\\\\/g, \"/\");\n    self.cwd = self.cwd.replace(/\\\\/g, \"/\");\n    self.cwdAbs = self.cwdAbs.replace(/\\\\/g, \"/\");\n  }\n\n  // disable comments and negation in Minimatch.\n  // Note that they are not supported in Glob itself anyway.\n  options.nonegate = true;\n  options.nocomment = true;\n  // always treat \\ in patterns as escapes, not path separators\n  options.allowWindowsEscape = true;\n\n  self.minimatch = new Minimatch(pattern, options);\n  self.options = self.minimatch.options;\n}\n\nfunction finish (self) {\n  var nou = self.nounique;\n  var all = nou ? [] : Object.create(null);\n\n  for (var i = 0, l = self.matches.length; i < l; i ++) {\n    var matches = self.matches[i];\n    if (!matches || Object.keys(matches).length === 0) {\n      if (self.nonull) {\n        // do like the shell, and spit out the literal glob\n        var literal = self.minimatch.globSet[i];\n        if (nou)\n          all.push(literal);\n        else\n          all[literal] = true;\n      }\n    } else {\n      // had matches\n      var m = Object.keys(matches);\n      if (nou)\n        all.push.apply(all, m);\n      else\n        m.forEach(function (m) {\n          all[m] = true;\n        });\n    }\n  }\n\n  if (!nou)\n    all = Object.keys(all);\n\n  if (!self.nosort)\n    all = all.sort(alphasort);\n\n  // at *some* point we statted all of these\n  if (self.mark) {\n    for (var i = 0; i < all.length; i++) {\n      all[i] = self._mark(all[i]);\n    }\n    if (self.nodir) {\n      all = all.filter(function (e) {\n        var notDir = !(/\\/$/.test(e));\n        var c = self.cache[e] || self.cache[makeAbs(self, e)];\n        if (notDir && c)\n          notDir = c !== 'DIR' && !Array.isArray(c);\n        return notDir\n      });\n    }\n  }\n\n  if (self.ignore.length)\n    all = all.filter(function(m) {\n      return !isIgnored(self, m)\n    });\n\n  self.found = all;\n}\n\nfunction mark (self, p) {\n  var abs = makeAbs(self, p);\n  var c = self.cache[abs];\n  var m = p;\n  if (c) {\n    var isDir = c === 'DIR' || Array.isArray(c);\n    var slash = p.slice(-1) === '/';\n\n    if (isDir && !slash)\n      m += '/';\n    else if (!isDir && slash)\n      m = m.slice(0, -1);\n\n    if (m !== p) {\n      var mabs = makeAbs(self, m);\n      self.statCache[mabs] = self.statCache[abs];\n      self.cache[mabs] = self.cache[abs];\n    }\n  }\n\n  return m\n}\n\n// lotta situps...\nfunction makeAbs (self, f) {\n  var abs = f;\n  if (f.charAt(0) === '/') {\n    abs = path$i.join(self.root, f);\n  } else if (isAbsolute(f) || f === '') {\n    abs = f;\n  } else if (self.changedCwd) {\n    abs = path$i.resolve(self.cwd, f);\n  } else {\n    abs = path$i.resolve(f);\n  }\n\n  if (process.platform === 'win32')\n    abs = abs.replace(/\\\\/g, '/');\n\n  return abs\n}\n\n\n// Return true, if pattern ends with globstar '**', for the accompanying parent directory.\n// Ex:- If node_modules/** is the pattern, add 'node_modules' to ignore list along with it's contents\nfunction isIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return item.matcher.match(path) || !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\nfunction childrenIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\nvar sync$9;\nvar hasRequiredSync;\n\nfunction requireSync () {\n\tif (hasRequiredSync) return sync$9;\n\thasRequiredSync = 1;\n\tsync$9 = globSync;\n\tglobSync.GlobSync = GlobSync;\n\n\tvar rp = fs_realpath;\n\tvar minimatch = minimatch_1;\n\trequireGlob().Glob;\n\tvar path = require$$0$4;\n\tvar assert = require$$5;\n\tvar isAbsolute = require$$0$4.isAbsolute;\n\tvar common = common$c;\n\tvar setopts = common.setopts;\n\tvar ownProp = common.ownProp;\n\tvar childrenIgnored = common.childrenIgnored;\n\tvar isIgnored = common.isIgnored;\n\n\tfunction globSync (pattern, options) {\n\t  if (typeof options === 'function' || arguments.length === 3)\n\t    throw new TypeError('callback provided to sync glob\\n'+\n\t                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n\t  return new GlobSync(pattern, options).found\n\t}\n\n\tfunction GlobSync (pattern, options) {\n\t  if (!pattern)\n\t    throw new Error('must provide pattern')\n\n\t  if (typeof options === 'function' || arguments.length === 3)\n\t    throw new TypeError('callback provided to sync glob\\n'+\n\t                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n\t  if (!(this instanceof GlobSync))\n\t    return new GlobSync(pattern, options)\n\n\t  setopts(this, pattern, options);\n\n\t  if (this.noprocess)\n\t    return this\n\n\t  var n = this.minimatch.set.length;\n\t  this.matches = new Array(n);\n\t  for (var i = 0; i < n; i ++) {\n\t    this._process(this.minimatch.set[i], i, false);\n\t  }\n\t  this._finish();\n\t}\n\n\tGlobSync.prototype._finish = function () {\n\t  assert.ok(this instanceof GlobSync);\n\t  if (this.realpath) {\n\t    var self = this;\n\t    this.matches.forEach(function (matchset, index) {\n\t      var set = self.matches[index] = Object.create(null);\n\t      for (var p in matchset) {\n\t        try {\n\t          p = self._makeAbs(p);\n\t          var real = rp.realpathSync(p, self.realpathCache);\n\t          set[real] = true;\n\t        } catch (er) {\n\t          if (er.syscall === 'stat')\n\t            set[self._makeAbs(p)] = true;\n\t          else\n\t            throw er\n\t        }\n\t      }\n\t    });\n\t  }\n\t  common.finish(this);\n\t};\n\n\n\tGlobSync.prototype._process = function (pattern, index, inGlobStar) {\n\t  assert.ok(this instanceof GlobSync);\n\n\t  // Get the first [n] parts of pattern that are all strings.\n\t  var n = 0;\n\t  while (typeof pattern[n] === 'string') {\n\t    n ++;\n\t  }\n\t  // now n is the index of the first one that is *not* a string.\n\n\t  // See if there's anything else\n\t  var prefix;\n\t  switch (n) {\n\t    // if not, then this is rather simple\n\t    case pattern.length:\n\t      this._processSimple(pattern.join('/'), index);\n\t      return\n\n\t    case 0:\n\t      // pattern *starts* with some non-trivial item.\n\t      // going to readdir(cwd), but not include the prefix in matches.\n\t      prefix = null;\n\t      break\n\n\t    default:\n\t      // pattern has some string bits in the front.\n\t      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n\t      // or 'relative' like '../baz'\n\t      prefix = pattern.slice(0, n).join('/');\n\t      break\n\t  }\n\n\t  var remain = pattern.slice(n);\n\n\t  // get the list of entries.\n\t  var read;\n\t  if (prefix === null)\n\t    read = '.';\n\t  else if (isAbsolute(prefix) ||\n\t      isAbsolute(pattern.map(function (p) {\n\t        return typeof p === 'string' ? p : '[*]'\n\t      }).join('/'))) {\n\t    if (!prefix || !isAbsolute(prefix))\n\t      prefix = '/' + prefix;\n\t    read = prefix;\n\t  } else\n\t    read = prefix;\n\n\t  var abs = this._makeAbs(read);\n\n\t  //if ignored, skip processing\n\t  if (childrenIgnored(this, read))\n\t    return\n\n\t  var isGlobStar = remain[0] === minimatch.GLOBSTAR;\n\t  if (isGlobStar)\n\t    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar);\n\t  else\n\t    this._processReaddir(prefix, read, abs, remain, index, inGlobStar);\n\t};\n\n\n\tGlobSync.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar) {\n\t  var entries = this._readdir(abs, inGlobStar);\n\n\t  // if the abs isn't a dir, then nothing can match!\n\t  if (!entries)\n\t    return\n\n\t  // It will only match dot entries if it starts with a dot, or if\n\t  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n\t  var pn = remain[0];\n\t  var negate = !!this.minimatch.negate;\n\t  var rawGlob = pn._glob;\n\t  var dotOk = this.dot || rawGlob.charAt(0) === '.';\n\n\t  var matchedEntries = [];\n\t  for (var i = 0; i < entries.length; i++) {\n\t    var e = entries[i];\n\t    if (e.charAt(0) !== '.' || dotOk) {\n\t      var m;\n\t      if (negate && !prefix) {\n\t        m = !e.match(pn);\n\t      } else {\n\t        m = e.match(pn);\n\t      }\n\t      if (m)\n\t        matchedEntries.push(e);\n\t    }\n\t  }\n\n\t  var len = matchedEntries.length;\n\t  // If there are no matched entries, then nothing matches.\n\t  if (len === 0)\n\t    return\n\n\t  // if this is the last remaining pattern bit, then no need for\n\t  // an additional stat *unless* the user has specified mark or\n\t  // stat explicitly.  We know they exist, since readdir returned\n\t  // them.\n\n\t  if (remain.length === 1 && !this.mark && !this.stat) {\n\t    if (!this.matches[index])\n\t      this.matches[index] = Object.create(null);\n\n\t    for (var i = 0; i < len; i ++) {\n\t      var e = matchedEntries[i];\n\t      if (prefix) {\n\t        if (prefix.slice(-1) !== '/')\n\t          e = prefix + '/' + e;\n\t        else\n\t          e = prefix + e;\n\t      }\n\n\t      if (e.charAt(0) === '/' && !this.nomount) {\n\t        e = path.join(this.root, e);\n\t      }\n\t      this._emitMatch(index, e);\n\t    }\n\t    // This was the last one, and no stats were needed\n\t    return\n\t  }\n\n\t  // now test all matched entries as stand-ins for that part\n\t  // of the pattern.\n\t  remain.shift();\n\t  for (var i = 0; i < len; i ++) {\n\t    var e = matchedEntries[i];\n\t    var newPattern;\n\t    if (prefix)\n\t      newPattern = [prefix, e];\n\t    else\n\t      newPattern = [e];\n\t    this._process(newPattern.concat(remain), index, inGlobStar);\n\t  }\n\t};\n\n\n\tGlobSync.prototype._emitMatch = function (index, e) {\n\t  if (isIgnored(this, e))\n\t    return\n\n\t  var abs = this._makeAbs(e);\n\n\t  if (this.mark)\n\t    e = this._mark(e);\n\n\t  if (this.absolute) {\n\t    e = abs;\n\t  }\n\n\t  if (this.matches[index][e])\n\t    return\n\n\t  if (this.nodir) {\n\t    var c = this.cache[abs];\n\t    if (c === 'DIR' || Array.isArray(c))\n\t      return\n\t  }\n\n\t  this.matches[index][e] = true;\n\n\t  if (this.stat)\n\t    this._stat(e);\n\t};\n\n\n\tGlobSync.prototype._readdirInGlobStar = function (abs) {\n\t  // follow all symlinked directories forever\n\t  // just proceed as if this is a non-globstar situation\n\t  if (this.follow)\n\t    return this._readdir(abs, false)\n\n\t  var entries;\n\t  var lstat;\n\t  try {\n\t    lstat = this.fs.lstatSync(abs);\n\t  } catch (er) {\n\t    if (er.code === 'ENOENT') {\n\t      // lstat failed, doesn't exist\n\t      return null\n\t    }\n\t  }\n\n\t  var isSym = lstat && lstat.isSymbolicLink();\n\t  this.symlinks[abs] = isSym;\n\n\t  // If it's not a symlink or a dir, then it's definitely a regular file.\n\t  // don't bother doing a readdir in that case.\n\t  if (!isSym && lstat && !lstat.isDirectory())\n\t    this.cache[abs] = 'FILE';\n\t  else\n\t    entries = this._readdir(abs, false);\n\n\t  return entries\n\t};\n\n\tGlobSync.prototype._readdir = function (abs, inGlobStar) {\n\n\t  if (inGlobStar && !ownProp(this.symlinks, abs))\n\t    return this._readdirInGlobStar(abs)\n\n\t  if (ownProp(this.cache, abs)) {\n\t    var c = this.cache[abs];\n\t    if (!c || c === 'FILE')\n\t      return null\n\n\t    if (Array.isArray(c))\n\t      return c\n\t  }\n\n\t  try {\n\t    return this._readdirEntries(abs, this.fs.readdirSync(abs))\n\t  } catch (er) {\n\t    this._readdirError(abs, er);\n\t    return null\n\t  }\n\t};\n\n\tGlobSync.prototype._readdirEntries = function (abs, entries) {\n\t  // if we haven't asked to stat everything, then just\n\t  // assume that everything in there exists, so we can avoid\n\t  // having to stat it a second time.\n\t  if (!this.mark && !this.stat) {\n\t    for (var i = 0; i < entries.length; i ++) {\n\t      var e = entries[i];\n\t      if (abs === '/')\n\t        e = abs + e;\n\t      else\n\t        e = abs + '/' + e;\n\t      this.cache[e] = true;\n\t    }\n\t  }\n\n\t  this.cache[abs] = entries;\n\n\t  // mark and cache dir-ness\n\t  return entries\n\t};\n\n\tGlobSync.prototype._readdirError = function (f, er) {\n\t  // handle errors, and cache the information\n\t  switch (er.code) {\n\t    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n\t    case 'ENOTDIR': // totally normal. means it *does* exist.\n\t      var abs = this._makeAbs(f);\n\t      this.cache[abs] = 'FILE';\n\t      if (abs === this.cwdAbs) {\n\t        var error = new Error(er.code + ' invalid cwd ' + this.cwd);\n\t        error.path = this.cwd;\n\t        error.code = er.code;\n\t        throw error\n\t      }\n\t      break\n\n\t    case 'ENOENT': // not terribly unusual\n\t    case 'ELOOP':\n\t    case 'ENAMETOOLONG':\n\t    case 'UNKNOWN':\n\t      this.cache[this._makeAbs(f)] = false;\n\t      break\n\n\t    default: // some unusual error.  Treat as failure.\n\t      this.cache[this._makeAbs(f)] = false;\n\t      if (this.strict)\n\t        throw er\n\t      if (!this.silent)\n\t        console.error('glob error', er);\n\t      break\n\t  }\n\t};\n\n\tGlobSync.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar) {\n\n\t  var entries = this._readdir(abs, inGlobStar);\n\n\t  // no entries means not a dir, so it can never have matches\n\t  // foo.txt/** doesn't match foo.txt\n\t  if (!entries)\n\t    return\n\n\t  // test without the globstar, and with every child both below\n\t  // and replacing the globstar.\n\t  var remainWithoutGlobStar = remain.slice(1);\n\t  var gspref = prefix ? [ prefix ] : [];\n\t  var noGlobStar = gspref.concat(remainWithoutGlobStar);\n\n\t  // the noGlobStar pattern exits the inGlobStar state\n\t  this._process(noGlobStar, index, false);\n\n\t  var len = entries.length;\n\t  var isSym = this.symlinks[abs];\n\n\t  // If it's a symlink, and we're in a globstar, then stop\n\t  if (isSym && inGlobStar)\n\t    return\n\n\t  for (var i = 0; i < len; i++) {\n\t    var e = entries[i];\n\t    if (e.charAt(0) === '.' && !this.dot)\n\t      continue\n\n\t    // these two cases enter the inGlobStar state\n\t    var instead = gspref.concat(entries[i], remainWithoutGlobStar);\n\t    this._process(instead, index, true);\n\n\t    var below = gspref.concat(entries[i], remain);\n\t    this._process(below, index, true);\n\t  }\n\t};\n\n\tGlobSync.prototype._processSimple = function (prefix, index) {\n\t  // XXX review this.  Shouldn't it be doing the mounting etc\n\t  // before doing stat?  kinda weird?\n\t  var exists = this._stat(prefix);\n\n\t  if (!this.matches[index])\n\t    this.matches[index] = Object.create(null);\n\n\t  // If it doesn't exist, then just mark the lack of results\n\t  if (!exists)\n\t    return\n\n\t  if (prefix && isAbsolute(prefix) && !this.nomount) {\n\t    var trail = /[\\/\\\\]$/.test(prefix);\n\t    if (prefix.charAt(0) === '/') {\n\t      prefix = path.join(this.root, prefix);\n\t    } else {\n\t      prefix = path.resolve(this.root, prefix);\n\t      if (trail)\n\t        prefix += '/';\n\t    }\n\t  }\n\n\t  if (process.platform === 'win32')\n\t    prefix = prefix.replace(/\\\\/g, '/');\n\n\t  // Mark this as a match\n\t  this._emitMatch(index, prefix);\n\t};\n\n\t// Returns either 'DIR', 'FILE', or false\n\tGlobSync.prototype._stat = function (f) {\n\t  var abs = this._makeAbs(f);\n\t  var needDir = f.slice(-1) === '/';\n\n\t  if (f.length > this.maxLength)\n\t    return false\n\n\t  if (!this.stat && ownProp(this.cache, abs)) {\n\t    var c = this.cache[abs];\n\n\t    if (Array.isArray(c))\n\t      c = 'DIR';\n\n\t    // It exists, but maybe not how we need it\n\t    if (!needDir || c === 'DIR')\n\t      return c\n\n\t    if (needDir && c === 'FILE')\n\t      return false\n\n\t    // otherwise we have to stat, because maybe c=true\n\t    // if we know it exists, but not what it is.\n\t  }\n\t  var stat = this.statCache[abs];\n\t  if (!stat) {\n\t    var lstat;\n\t    try {\n\t      lstat = this.fs.lstatSync(abs);\n\t    } catch (er) {\n\t      if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n\t        this.statCache[abs] = false;\n\t        return false\n\t      }\n\t    }\n\n\t    if (lstat && lstat.isSymbolicLink()) {\n\t      try {\n\t        stat = this.fs.statSync(abs);\n\t      } catch (er) {\n\t        stat = lstat;\n\t      }\n\t    } else {\n\t      stat = lstat;\n\t    }\n\t  }\n\n\t  this.statCache[abs] = stat;\n\n\t  var c = true;\n\t  if (stat)\n\t    c = stat.isDirectory() ? 'DIR' : 'FILE';\n\n\t  this.cache[abs] = this.cache[abs] || c;\n\n\t  if (needDir && c === 'FILE')\n\t    return false\n\n\t  return c\n\t};\n\n\tGlobSync.prototype._mark = function (p) {\n\t  return common.mark(this, p)\n\t};\n\n\tGlobSync.prototype._makeAbs = function (f) {\n\t  return common.makeAbs(this, f)\n\t};\n\treturn sync$9;\n}\n\n// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nvar wrappy_1 = wrappy$2;\nfunction wrappy$2 (fn, cb) {\n  if (fn && cb) return wrappy$2(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k];\n  });\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n    var ret = fn.apply(this, args);\n    var cb = args[args.length-1];\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k];\n      });\n    }\n    return ret\n  }\n}\n\nvar onceExports = {};\nvar once$2 = {\n  get exports(){ return onceExports; },\n  set exports(v){ onceExports = v; },\n};\n\nvar wrappy$1 = wrappy_1;\nonce$2.exports = wrappy$1(once$1);\nonceExports.strict = wrappy$1(onceStrict);\n\nonce$1.proto = once$1(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once$1(this)\n    },\n    configurable: true\n  });\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  });\n});\n\nfunction once$1 (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true;\n    return f.value = fn.apply(this, arguments)\n  };\n  f.called = false;\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true;\n    return f.value = fn.apply(this, arguments)\n  };\n  var name = fn.name || 'Function wrapped with `once`';\n  f.onceError = name + \" shouldn't be called more than once\";\n  f.called = false;\n  return f\n}\n\nvar wrappy = wrappy_1;\nvar reqs = Object.create(null);\nvar once = onceExports;\n\nvar inflight_1 = wrappy(inflight);\n\nfunction inflight (key, cb) {\n  if (reqs[key]) {\n    reqs[key].push(cb);\n    return null\n  } else {\n    reqs[key] = [cb];\n    return makeres(key)\n  }\n}\n\nfunction makeres (key) {\n  return once(function RES () {\n    var cbs = reqs[key];\n    var len = cbs.length;\n    var args = slice$1(arguments);\n\n    // XXX It's somewhat ambiguous whether a new callback added in this\n    // pass should be queued for later execution if something in the\n    // list of callbacks throws, or if it should just be discarded.\n    // However, it's such an edge case that it hardly matters, and either\n    // choice is likely as surprising as the other.\n    // As it happens, we do go ahead and schedule it for later execution.\n    try {\n      for (var i = 0; i < len; i++) {\n        cbs[i].apply(null, args);\n      }\n    } finally {\n      if (cbs.length > len) {\n        // added more in the interim.\n        // de-zalgo, just in case, but don't call again.\n        cbs.splice(0, len);\n        process.nextTick(function () {\n          RES.apply(null, args);\n        });\n      } else {\n        delete reqs[key];\n      }\n    }\n  })\n}\n\nfunction slice$1 (args) {\n  var length = args.length;\n  var array = [];\n\n  for (var i = 0; i < length; i++) array[i] = args[i];\n  return array\n}\n\nvar glob_1;\nvar hasRequiredGlob;\n\nfunction requireGlob () {\n\tif (hasRequiredGlob) return glob_1;\n\thasRequiredGlob = 1;\n\t// Approach:\n\t//\n\t// 1. Get the minimatch set\n\t// 2. For each pattern in the set, PROCESS(pattern, false)\n\t// 3. Store matches per-set, then uniq them\n\t//\n\t// PROCESS(pattern, inGlobStar)\n\t// Get the first [n] items from pattern that are all strings\n\t// Join these together.  This is PREFIX.\n\t//   If there is no more remaining, then stat(PREFIX) and\n\t//   add to matches if it succeeds.  END.\n\t//\n\t// If inGlobStar and PREFIX is symlink and points to dir\n\t//   set ENTRIES = []\n\t// else readdir(PREFIX) as ENTRIES\n\t//   If fail, END\n\t//\n\t// with ENTRIES\n\t//   If pattern[n] is GLOBSTAR\n\t//     // handle the case where the globstar match is empty\n\t//     // by pruning it out, and testing the resulting pattern\n\t//     PROCESS(pattern[0..n] + pattern[n+1 .. $], false)\n\t//     // handle other cases.\n\t//     for ENTRY in ENTRIES (not dotfiles)\n\t//       // attach globstar + tail onto the entry\n\t//       // Mark that this entry is a globstar match\n\t//       PROCESS(pattern[0..n] + ENTRY + pattern[n .. $], true)\n\t//\n\t//   else // not globstar\n\t//     for ENTRY in ENTRIES (not dotfiles, unless pattern[n] is dot)\n\t//       Test ENTRY against pattern[n]\n\t//       If fails, continue\n\t//       If passes, PROCESS(pattern[0..n] + item + pattern[n+1 .. $])\n\t//\n\t// Caveat:\n\t//   Cache all stats and readdirs results to minimize syscall.  Since all\n\t//   we ever care about is existence and directory-ness, we can just keep\n\t//   `true` for files, and [children,...] for directories, or `false` for\n\t//   things that don't exist.\n\n\tglob_1 = glob;\n\n\tvar rp = fs_realpath;\n\tvar minimatch = minimatch_1;\n\tvar inherits = inheritsExports;\n\tvar EE = require$$0$5.EventEmitter;\n\tvar path = require$$0$4;\n\tvar assert = require$$5;\n\tvar isAbsolute = require$$0$4.isAbsolute;\n\tvar globSync = requireSync();\n\tvar common = common$c;\n\tvar setopts = common.setopts;\n\tvar ownProp = common.ownProp;\n\tvar inflight = inflight_1;\n\tvar childrenIgnored = common.childrenIgnored;\n\tvar isIgnored = common.isIgnored;\n\n\tvar once = onceExports;\n\n\tfunction glob (pattern, options, cb) {\n\t  if (typeof options === 'function') cb = options, options = {};\n\t  if (!options) options = {};\n\n\t  if (options.sync) {\n\t    if (cb)\n\t      throw new TypeError('callback provided to sync glob')\n\t    return globSync(pattern, options)\n\t  }\n\n\t  return new Glob(pattern, options, cb)\n\t}\n\n\tglob.sync = globSync;\n\tvar GlobSync = glob.GlobSync = globSync.GlobSync;\n\n\t// old api surface\n\tglob.glob = glob;\n\n\tfunction extend (origin, add) {\n\t  if (add === null || typeof add !== 'object') {\n\t    return origin\n\t  }\n\n\t  var keys = Object.keys(add);\n\t  var i = keys.length;\n\t  while (i--) {\n\t    origin[keys[i]] = add[keys[i]];\n\t  }\n\t  return origin\n\t}\n\n\tglob.hasMagic = function (pattern, options_) {\n\t  var options = extend({}, options_);\n\t  options.noprocess = true;\n\n\t  var g = new Glob(pattern, options);\n\t  var set = g.minimatch.set;\n\n\t  if (!pattern)\n\t    return false\n\n\t  if (set.length > 1)\n\t    return true\n\n\t  for (var j = 0; j < set[0].length; j++) {\n\t    if (typeof set[0][j] !== 'string')\n\t      return true\n\t  }\n\n\t  return false\n\t};\n\n\tglob.Glob = Glob;\n\tinherits(Glob, EE);\n\tfunction Glob (pattern, options, cb) {\n\t  if (typeof options === 'function') {\n\t    cb = options;\n\t    options = null;\n\t  }\n\n\t  if (options && options.sync) {\n\t    if (cb)\n\t      throw new TypeError('callback provided to sync glob')\n\t    return new GlobSync(pattern, options)\n\t  }\n\n\t  if (!(this instanceof Glob))\n\t    return new Glob(pattern, options, cb)\n\n\t  setopts(this, pattern, options);\n\t  this._didRealPath = false;\n\n\t  // process each pattern in the minimatch set\n\t  var n = this.minimatch.set.length;\n\n\t  // The matches are stored as {<filename>: true,...} so that\n\t  // duplicates are automagically pruned.\n\t  // Later, we do an Object.keys() on these.\n\t  // Keep them as a list so we can fill in when nonull is set.\n\t  this.matches = new Array(n);\n\n\t  if (typeof cb === 'function') {\n\t    cb = once(cb);\n\t    this.on('error', cb);\n\t    this.on('end', function (matches) {\n\t      cb(null, matches);\n\t    });\n\t  }\n\n\t  var self = this;\n\t  this._processing = 0;\n\n\t  this._emitQueue = [];\n\t  this._processQueue = [];\n\t  this.paused = false;\n\n\t  if (this.noprocess)\n\t    return this\n\n\t  if (n === 0)\n\t    return done()\n\n\t  var sync = true;\n\t  for (var i = 0; i < n; i ++) {\n\t    this._process(this.minimatch.set[i], i, false, done);\n\t  }\n\t  sync = false;\n\n\t  function done () {\n\t    --self._processing;\n\t    if (self._processing <= 0) {\n\t      if (sync) {\n\t        process.nextTick(function () {\n\t          self._finish();\n\t        });\n\t      } else {\n\t        self._finish();\n\t      }\n\t    }\n\t  }\n\t}\n\n\tGlob.prototype._finish = function () {\n\t  assert(this instanceof Glob);\n\t  if (this.aborted)\n\t    return\n\n\t  if (this.realpath && !this._didRealpath)\n\t    return this._realpath()\n\n\t  common.finish(this);\n\t  this.emit('end', this.found);\n\t};\n\n\tGlob.prototype._realpath = function () {\n\t  if (this._didRealpath)\n\t    return\n\n\t  this._didRealpath = true;\n\n\t  var n = this.matches.length;\n\t  if (n === 0)\n\t    return this._finish()\n\n\t  var self = this;\n\t  for (var i = 0; i < this.matches.length; i++)\n\t    this._realpathSet(i, next);\n\n\t  function next () {\n\t    if (--n === 0)\n\t      self._finish();\n\t  }\n\t};\n\n\tGlob.prototype._realpathSet = function (index, cb) {\n\t  var matchset = this.matches[index];\n\t  if (!matchset)\n\t    return cb()\n\n\t  var found = Object.keys(matchset);\n\t  var self = this;\n\t  var n = found.length;\n\n\t  if (n === 0)\n\t    return cb()\n\n\t  var set = this.matches[index] = Object.create(null);\n\t  found.forEach(function (p, i) {\n\t    // If there's a problem with the stat, then it means that\n\t    // one or more of the links in the realpath couldn't be\n\t    // resolved.  just return the abs value in that case.\n\t    p = self._makeAbs(p);\n\t    rp.realpath(p, self.realpathCache, function (er, real) {\n\t      if (!er)\n\t        set[real] = true;\n\t      else if (er.syscall === 'stat')\n\t        set[p] = true;\n\t      else\n\t        self.emit('error', er); // srsly wtf right here\n\n\t      if (--n === 0) {\n\t        self.matches[index] = set;\n\t        cb();\n\t      }\n\t    });\n\t  });\n\t};\n\n\tGlob.prototype._mark = function (p) {\n\t  return common.mark(this, p)\n\t};\n\n\tGlob.prototype._makeAbs = function (f) {\n\t  return common.makeAbs(this, f)\n\t};\n\n\tGlob.prototype.abort = function () {\n\t  this.aborted = true;\n\t  this.emit('abort');\n\t};\n\n\tGlob.prototype.pause = function () {\n\t  if (!this.paused) {\n\t    this.paused = true;\n\t    this.emit('pause');\n\t  }\n\t};\n\n\tGlob.prototype.resume = function () {\n\t  if (this.paused) {\n\t    this.emit('resume');\n\t    this.paused = false;\n\t    if (this._emitQueue.length) {\n\t      var eq = this._emitQueue.slice(0);\n\t      this._emitQueue.length = 0;\n\t      for (var i = 0; i < eq.length; i ++) {\n\t        var e = eq[i];\n\t        this._emitMatch(e[0], e[1]);\n\t      }\n\t    }\n\t    if (this._processQueue.length) {\n\t      var pq = this._processQueue.slice(0);\n\t      this._processQueue.length = 0;\n\t      for (var i = 0; i < pq.length; i ++) {\n\t        var p = pq[i];\n\t        this._processing--;\n\t        this._process(p[0], p[1], p[2], p[3]);\n\t      }\n\t    }\n\t  }\n\t};\n\n\tGlob.prototype._process = function (pattern, index, inGlobStar, cb) {\n\t  assert(this instanceof Glob);\n\t  assert(typeof cb === 'function');\n\n\t  if (this.aborted)\n\t    return\n\n\t  this._processing++;\n\t  if (this.paused) {\n\t    this._processQueue.push([pattern, index, inGlobStar, cb]);\n\t    return\n\t  }\n\n\t  //console.error('PROCESS %d', this._processing, pattern)\n\n\t  // Get the first [n] parts of pattern that are all strings.\n\t  var n = 0;\n\t  while (typeof pattern[n] === 'string') {\n\t    n ++;\n\t  }\n\t  // now n is the index of the first one that is *not* a string.\n\n\t  // see if there's anything else\n\t  var prefix;\n\t  switch (n) {\n\t    // if not, then this is rather simple\n\t    case pattern.length:\n\t      this._processSimple(pattern.join('/'), index, cb);\n\t      return\n\n\t    case 0:\n\t      // pattern *starts* with some non-trivial item.\n\t      // going to readdir(cwd), but not include the prefix in matches.\n\t      prefix = null;\n\t      break\n\n\t    default:\n\t      // pattern has some string bits in the front.\n\t      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n\t      // or 'relative' like '../baz'\n\t      prefix = pattern.slice(0, n).join('/');\n\t      break\n\t  }\n\n\t  var remain = pattern.slice(n);\n\n\t  // get the list of entries.\n\t  var read;\n\t  if (prefix === null)\n\t    read = '.';\n\t  else if (isAbsolute(prefix) ||\n\t      isAbsolute(pattern.map(function (p) {\n\t        return typeof p === 'string' ? p : '[*]'\n\t      }).join('/'))) {\n\t    if (!prefix || !isAbsolute(prefix))\n\t      prefix = '/' + prefix;\n\t    read = prefix;\n\t  } else\n\t    read = prefix;\n\n\t  var abs = this._makeAbs(read);\n\n\t  //if ignored, skip _processing\n\t  if (childrenIgnored(this, read))\n\t    return cb()\n\n\t  var isGlobStar = remain[0] === minimatch.GLOBSTAR;\n\t  if (isGlobStar)\n\t    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar, cb);\n\t  else\n\t    this._processReaddir(prefix, read, abs, remain, index, inGlobStar, cb);\n\t};\n\n\tGlob.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n\t  var self = this;\n\t  this._readdir(abs, inGlobStar, function (er, entries) {\n\t    return self._processReaddir2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n\t  });\n\t};\n\n\tGlob.prototype._processReaddir2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n\n\t  // if the abs isn't a dir, then nothing can match!\n\t  if (!entries)\n\t    return cb()\n\n\t  // It will only match dot entries if it starts with a dot, or if\n\t  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n\t  var pn = remain[0];\n\t  var negate = !!this.minimatch.negate;\n\t  var rawGlob = pn._glob;\n\t  var dotOk = this.dot || rawGlob.charAt(0) === '.';\n\n\t  var matchedEntries = [];\n\t  for (var i = 0; i < entries.length; i++) {\n\t    var e = entries[i];\n\t    if (e.charAt(0) !== '.' || dotOk) {\n\t      var m;\n\t      if (negate && !prefix) {\n\t        m = !e.match(pn);\n\t      } else {\n\t        m = e.match(pn);\n\t      }\n\t      if (m)\n\t        matchedEntries.push(e);\n\t    }\n\t  }\n\n\t  //console.error('prd2', prefix, entries, remain[0]._glob, matchedEntries)\n\n\t  var len = matchedEntries.length;\n\t  // If there are no matched entries, then nothing matches.\n\t  if (len === 0)\n\t    return cb()\n\n\t  // if this is the last remaining pattern bit, then no need for\n\t  // an additional stat *unless* the user has specified mark or\n\t  // stat explicitly.  We know they exist, since readdir returned\n\t  // them.\n\n\t  if (remain.length === 1 && !this.mark && !this.stat) {\n\t    if (!this.matches[index])\n\t      this.matches[index] = Object.create(null);\n\n\t    for (var i = 0; i < len; i ++) {\n\t      var e = matchedEntries[i];\n\t      if (prefix) {\n\t        if (prefix !== '/')\n\t          e = prefix + '/' + e;\n\t        else\n\t          e = prefix + e;\n\t      }\n\n\t      if (e.charAt(0) === '/' && !this.nomount) {\n\t        e = path.join(this.root, e);\n\t      }\n\t      this._emitMatch(index, e);\n\t    }\n\t    // This was the last one, and no stats were needed\n\t    return cb()\n\t  }\n\n\t  // now test all matched entries as stand-ins for that part\n\t  // of the pattern.\n\t  remain.shift();\n\t  for (var i = 0; i < len; i ++) {\n\t    var e = matchedEntries[i];\n\t    if (prefix) {\n\t      if (prefix !== '/')\n\t        e = prefix + '/' + e;\n\t      else\n\t        e = prefix + e;\n\t    }\n\t    this._process([e].concat(remain), index, inGlobStar, cb);\n\t  }\n\t  cb();\n\t};\n\n\tGlob.prototype._emitMatch = function (index, e) {\n\t  if (this.aborted)\n\t    return\n\n\t  if (isIgnored(this, e))\n\t    return\n\n\t  if (this.paused) {\n\t    this._emitQueue.push([index, e]);\n\t    return\n\t  }\n\n\t  var abs = isAbsolute(e) ? e : this._makeAbs(e);\n\n\t  if (this.mark)\n\t    e = this._mark(e);\n\n\t  if (this.absolute)\n\t    e = abs;\n\n\t  if (this.matches[index][e])\n\t    return\n\n\t  if (this.nodir) {\n\t    var c = this.cache[abs];\n\t    if (c === 'DIR' || Array.isArray(c))\n\t      return\n\t  }\n\n\t  this.matches[index][e] = true;\n\n\t  var st = this.statCache[abs];\n\t  if (st)\n\t    this.emit('stat', e, st);\n\n\t  this.emit('match', e);\n\t};\n\n\tGlob.prototype._readdirInGlobStar = function (abs, cb) {\n\t  if (this.aborted)\n\t    return\n\n\t  // follow all symlinked directories forever\n\t  // just proceed as if this is a non-globstar situation\n\t  if (this.follow)\n\t    return this._readdir(abs, false, cb)\n\n\t  var lstatkey = 'lstat\\0' + abs;\n\t  var self = this;\n\t  var lstatcb = inflight(lstatkey, lstatcb_);\n\n\t  if (lstatcb)\n\t    self.fs.lstat(abs, lstatcb);\n\n\t  function lstatcb_ (er, lstat) {\n\t    if (er && er.code === 'ENOENT')\n\t      return cb()\n\n\t    var isSym = lstat && lstat.isSymbolicLink();\n\t    self.symlinks[abs] = isSym;\n\n\t    // If it's not a symlink or a dir, then it's definitely a regular file.\n\t    // don't bother doing a readdir in that case.\n\t    if (!isSym && lstat && !lstat.isDirectory()) {\n\t      self.cache[abs] = 'FILE';\n\t      cb();\n\t    } else\n\t      self._readdir(abs, false, cb);\n\t  }\n\t};\n\n\tGlob.prototype._readdir = function (abs, inGlobStar, cb) {\n\t  if (this.aborted)\n\t    return\n\n\t  cb = inflight('readdir\\0'+abs+'\\0'+inGlobStar, cb);\n\t  if (!cb)\n\t    return\n\n\t  //console.error('RD %j %j', +inGlobStar, abs)\n\t  if (inGlobStar && !ownProp(this.symlinks, abs))\n\t    return this._readdirInGlobStar(abs, cb)\n\n\t  if (ownProp(this.cache, abs)) {\n\t    var c = this.cache[abs];\n\t    if (!c || c === 'FILE')\n\t      return cb()\n\n\t    if (Array.isArray(c))\n\t      return cb(null, c)\n\t  }\n\n\t  var self = this;\n\t  self.fs.readdir(abs, readdirCb(this, abs, cb));\n\t};\n\n\tfunction readdirCb (self, abs, cb) {\n\t  return function (er, entries) {\n\t    if (er)\n\t      self._readdirError(abs, er, cb);\n\t    else\n\t      self._readdirEntries(abs, entries, cb);\n\t  }\n\t}\n\n\tGlob.prototype._readdirEntries = function (abs, entries, cb) {\n\t  if (this.aborted)\n\t    return\n\n\t  // if we haven't asked to stat everything, then just\n\t  // assume that everything in there exists, so we can avoid\n\t  // having to stat it a second time.\n\t  if (!this.mark && !this.stat) {\n\t    for (var i = 0; i < entries.length; i ++) {\n\t      var e = entries[i];\n\t      if (abs === '/')\n\t        e = abs + e;\n\t      else\n\t        e = abs + '/' + e;\n\t      this.cache[e] = true;\n\t    }\n\t  }\n\n\t  this.cache[abs] = entries;\n\t  return cb(null, entries)\n\t};\n\n\tGlob.prototype._readdirError = function (f, er, cb) {\n\t  if (this.aborted)\n\t    return\n\n\t  // handle errors, and cache the information\n\t  switch (er.code) {\n\t    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n\t    case 'ENOTDIR': // totally normal. means it *does* exist.\n\t      var abs = this._makeAbs(f);\n\t      this.cache[abs] = 'FILE';\n\t      if (abs === this.cwdAbs) {\n\t        var error = new Error(er.code + ' invalid cwd ' + this.cwd);\n\t        error.path = this.cwd;\n\t        error.code = er.code;\n\t        this.emit('error', error);\n\t        this.abort();\n\t      }\n\t      break\n\n\t    case 'ENOENT': // not terribly unusual\n\t    case 'ELOOP':\n\t    case 'ENAMETOOLONG':\n\t    case 'UNKNOWN':\n\t      this.cache[this._makeAbs(f)] = false;\n\t      break\n\n\t    default: // some unusual error.  Treat as failure.\n\t      this.cache[this._makeAbs(f)] = false;\n\t      if (this.strict) {\n\t        this.emit('error', er);\n\t        // If the error is handled, then we abort\n\t        // if not, we threw out of here\n\t        this.abort();\n\t      }\n\t      if (!this.silent)\n\t        console.error('glob error', er);\n\t      break\n\t  }\n\n\t  return cb()\n\t};\n\n\tGlob.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n\t  var self = this;\n\t  this._readdir(abs, inGlobStar, function (er, entries) {\n\t    self._processGlobStar2(prefix, read, abs, remain, index, inGlobStar, entries, cb);\n\t  });\n\t};\n\n\n\tGlob.prototype._processGlobStar2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n\t  //console.error('pgs2', prefix, remain[0], entries)\n\n\t  // no entries means not a dir, so it can never have matches\n\t  // foo.txt/** doesn't match foo.txt\n\t  if (!entries)\n\t    return cb()\n\n\t  // test without the globstar, and with every child both below\n\t  // and replacing the globstar.\n\t  var remainWithoutGlobStar = remain.slice(1);\n\t  var gspref = prefix ? [ prefix ] : [];\n\t  var noGlobStar = gspref.concat(remainWithoutGlobStar);\n\n\t  // the noGlobStar pattern exits the inGlobStar state\n\t  this._process(noGlobStar, index, false, cb);\n\n\t  var isSym = this.symlinks[abs];\n\t  var len = entries.length;\n\n\t  // If it's a symlink, and we're in a globstar, then stop\n\t  if (isSym && inGlobStar)\n\t    return cb()\n\n\t  for (var i = 0; i < len; i++) {\n\t    var e = entries[i];\n\t    if (e.charAt(0) === '.' && !this.dot)\n\t      continue\n\n\t    // these two cases enter the inGlobStar state\n\t    var instead = gspref.concat(entries[i], remainWithoutGlobStar);\n\t    this._process(instead, index, true, cb);\n\n\t    var below = gspref.concat(entries[i], remain);\n\t    this._process(below, index, true, cb);\n\t  }\n\n\t  cb();\n\t};\n\n\tGlob.prototype._processSimple = function (prefix, index, cb) {\n\t  // XXX review this.  Shouldn't it be doing the mounting etc\n\t  // before doing stat?  kinda weird?\n\t  var self = this;\n\t  this._stat(prefix, function (er, exists) {\n\t    self._processSimple2(prefix, index, er, exists, cb);\n\t  });\n\t};\n\tGlob.prototype._processSimple2 = function (prefix, index, er, exists, cb) {\n\n\t  //console.error('ps2', prefix, exists)\n\n\t  if (!this.matches[index])\n\t    this.matches[index] = Object.create(null);\n\n\t  // If it doesn't exist, then just mark the lack of results\n\t  if (!exists)\n\t    return cb()\n\n\t  if (prefix && isAbsolute(prefix) && !this.nomount) {\n\t    var trail = /[\\/\\\\]$/.test(prefix);\n\t    if (prefix.charAt(0) === '/') {\n\t      prefix = path.join(this.root, prefix);\n\t    } else {\n\t      prefix = path.resolve(this.root, prefix);\n\t      if (trail)\n\t        prefix += '/';\n\t    }\n\t  }\n\n\t  if (process.platform === 'win32')\n\t    prefix = prefix.replace(/\\\\/g, '/');\n\n\t  // Mark this as a match\n\t  this._emitMatch(index, prefix);\n\t  cb();\n\t};\n\n\t// Returns either 'DIR', 'FILE', or false\n\tGlob.prototype._stat = function (f, cb) {\n\t  var abs = this._makeAbs(f);\n\t  var needDir = f.slice(-1) === '/';\n\n\t  if (f.length > this.maxLength)\n\t    return cb()\n\n\t  if (!this.stat && ownProp(this.cache, abs)) {\n\t    var c = this.cache[abs];\n\n\t    if (Array.isArray(c))\n\t      c = 'DIR';\n\n\t    // It exists, but maybe not how we need it\n\t    if (!needDir || c === 'DIR')\n\t      return cb(null, c)\n\n\t    if (needDir && c === 'FILE')\n\t      return cb()\n\n\t    // otherwise we have to stat, because maybe c=true\n\t    // if we know it exists, but not what it is.\n\t  }\n\t  var stat = this.statCache[abs];\n\t  if (stat !== undefined) {\n\t    if (stat === false)\n\t      return cb(null, stat)\n\t    else {\n\t      var type = stat.isDirectory() ? 'DIR' : 'FILE';\n\t      if (needDir && type === 'FILE')\n\t        return cb()\n\t      else\n\t        return cb(null, type, stat)\n\t    }\n\t  }\n\n\t  var self = this;\n\t  var statcb = inflight('stat\\0' + abs, lstatcb_);\n\t  if (statcb)\n\t    self.fs.lstat(abs, statcb);\n\n\t  function lstatcb_ (er, lstat) {\n\t    if (lstat && lstat.isSymbolicLink()) {\n\t      // If it's a symlink, then treat it as the target, unless\n\t      // the target does not exist, then treat it as a file.\n\t      return self.fs.stat(abs, function (er, stat) {\n\t        if (er)\n\t          self._stat2(f, abs, null, lstat, cb);\n\t        else\n\t          self._stat2(f, abs, er, stat, cb);\n\t      })\n\t    } else {\n\t      self._stat2(f, abs, er, lstat, cb);\n\t    }\n\t  }\n\t};\n\n\tGlob.prototype._stat2 = function (f, abs, er, stat, cb) {\n\t  if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n\t    this.statCache[abs] = false;\n\t    return cb()\n\t  }\n\n\t  var needDir = f.slice(-1) === '/';\n\t  this.statCache[abs] = stat;\n\n\t  if (abs.slice(-1) === '/' && stat && !stat.isDirectory())\n\t    return cb(null, false, stat)\n\n\t  var c = true;\n\t  if (stat)\n\t    c = stat.isDirectory() ? 'DIR' : 'FILE';\n\t  this.cache[abs] = this.cache[abs] || c;\n\n\t  if (needDir && c === 'FILE')\n\t    return cb()\n\n\t  return cb(null, c, stat)\n\t};\n\treturn glob_1;\n}\n\nvar globExports = requireGlob();\nvar glob = /*@__PURE__*/getDefaultExportFromCjs(globExports);\n\nconst comma = ','.charCodeAt(0);\nconst semicolon = ';'.charCodeAt(0);\nconst chars$1 = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';\nconst intToChar = new Uint8Array(64); // 64 possible chars.\nconst charToInt = new Uint8Array(128); // z is 122 in ASCII\nfor (let i = 0; i < chars$1.length; i++) {\n    const c = chars$1.charCodeAt(i);\n    intToChar[i] = c;\n    charToInt[c] = i;\n}\n// Provide a fallback for older environments.\nconst td = typeof TextDecoder !== 'undefined'\n    ? /* #__PURE__ */ new TextDecoder()\n    : typeof Buffer !== 'undefined'\n        ? {\n            decode(buf) {\n                const out = Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength);\n                return out.toString();\n            },\n        }\n        : {\n            decode(buf) {\n                let out = '';\n                for (let i = 0; i < buf.length; i++) {\n                    out += String.fromCharCode(buf[i]);\n                }\n                return out;\n            },\n        };\nfunction decode(mappings) {\n    const state = new Int32Array(5);\n    const decoded = [];\n    let index = 0;\n    do {\n        const semi = indexOf(mappings, index);\n        const line = [];\n        let sorted = true;\n        let lastCol = 0;\n        state[0] = 0;\n        for (let i = index; i < semi; i++) {\n            let seg;\n            i = decodeInteger(mappings, i, state, 0); // genColumn\n            const col = state[0];\n            if (col < lastCol)\n                sorted = false;\n            lastCol = col;\n            if (hasMoreVlq(mappings, i, semi)) {\n                i = decodeInteger(mappings, i, state, 1); // sourcesIndex\n                i = decodeInteger(mappings, i, state, 2); // sourceLine\n                i = decodeInteger(mappings, i, state, 3); // sourceColumn\n                if (hasMoreVlq(mappings, i, semi)) {\n                    i = decodeInteger(mappings, i, state, 4); // namesIndex\n                    seg = [col, state[1], state[2], state[3], state[4]];\n                }\n                else {\n                    seg = [col, state[1], state[2], state[3]];\n                }\n            }\n            else {\n                seg = [col];\n            }\n            line.push(seg);\n        }\n        if (!sorted)\n            sort(line);\n        decoded.push(line);\n        index = semi + 1;\n    } while (index <= mappings.length);\n    return decoded;\n}\nfunction indexOf(mappings, index) {\n    const idx = mappings.indexOf(';', index);\n    return idx === -1 ? mappings.length : idx;\n}\nfunction decodeInteger(mappings, pos, state, j) {\n    let value = 0;\n    let shift = 0;\n    let integer = 0;\n    do {\n        const c = mappings.charCodeAt(pos++);\n        integer = charToInt[c];\n        value |= (integer & 31) << shift;\n        shift += 5;\n    } while (integer & 32);\n    const shouldNegate = value & 1;\n    value >>>= 1;\n    if (shouldNegate) {\n        value = -0x80000000 | -value;\n    }\n    state[j] += value;\n    return pos;\n}\nfunction hasMoreVlq(mappings, i, length) {\n    if (i >= length)\n        return false;\n    return mappings.charCodeAt(i) !== comma;\n}\nfunction sort(line) {\n    line.sort(sortComparator$1);\n}\nfunction sortComparator$1(a, b) {\n    return a[0] - b[0];\n}\nfunction encode$1(decoded) {\n    const state = new Int32Array(5);\n    const bufLength = 1024 * 16;\n    const subLength = bufLength - 36;\n    const buf = new Uint8Array(bufLength);\n    const sub = buf.subarray(0, subLength);\n    let pos = 0;\n    let out = '';\n    for (let i = 0; i < decoded.length; i++) {\n        const line = decoded[i];\n        if (i > 0) {\n            if (pos === bufLength) {\n                out += td.decode(buf);\n                pos = 0;\n            }\n            buf[pos++] = semicolon;\n        }\n        if (line.length === 0)\n            continue;\n        state[0] = 0;\n        for (let j = 0; j < line.length; j++) {\n            const segment = line[j];\n            // We can push up to 5 ints, each int can take at most 7 chars, and we\n            // may push a comma.\n            if (pos > subLength) {\n                out += td.decode(sub);\n                buf.copyWithin(0, subLength, pos);\n                pos -= subLength;\n            }\n            if (j > 0)\n                buf[pos++] = comma;\n            pos = encodeInteger(buf, pos, state, segment, 0); // genColumn\n            if (segment.length === 1)\n                continue;\n            pos = encodeInteger(buf, pos, state, segment, 1); // sourcesIndex\n            pos = encodeInteger(buf, pos, state, segment, 2); // sourceLine\n            pos = encodeInteger(buf, pos, state, segment, 3); // sourceColumn\n            if (segment.length === 4)\n                continue;\n            pos = encodeInteger(buf, pos, state, segment, 4); // namesIndex\n        }\n    }\n    return out + td.decode(buf.subarray(0, pos));\n}\nfunction encodeInteger(buf, pos, state, segment, j) {\n    const next = segment[j];\n    let num = next - state[j];\n    state[j] = next;\n    num = num < 0 ? (-num << 1) | 1 : num << 1;\n    do {\n        let clamped = num & 0b011111;\n        num >>>= 5;\n        if (num > 0)\n            clamped |= 0b100000;\n        buf[pos++] = intToChar[clamped];\n    } while (num > 0);\n    return pos;\n}\n\nclass BitSet {\n\tconstructor(arg) {\n\t\tthis.bits = arg instanceof BitSet ? arg.bits.slice() : [];\n\t}\n\n\tadd(n) {\n\t\tthis.bits[n >> 5] |= 1 << (n & 31);\n\t}\n\n\thas(n) {\n\t\treturn !!(this.bits[n >> 5] & (1 << (n & 31)));\n\t}\n}\n\nclass Chunk {\n\tconstructor(start, end, content) {\n\t\tthis.start = start;\n\t\tthis.end = end;\n\t\tthis.original = content;\n\n\t\tthis.intro = '';\n\t\tthis.outro = '';\n\n\t\tthis.content = content;\n\t\tthis.storeName = false;\n\t\tthis.edited = false;\n\n\t\t{\n\t\t\tthis.previous = null;\n\t\t\tthis.next = null;\n\t\t}\n\t}\n\n\tappendLeft(content) {\n\t\tthis.outro += content;\n\t}\n\n\tappendRight(content) {\n\t\tthis.intro = this.intro + content;\n\t}\n\n\tclone() {\n\t\tconst chunk = new Chunk(this.start, this.end, this.original);\n\n\t\tchunk.intro = this.intro;\n\t\tchunk.outro = this.outro;\n\t\tchunk.content = this.content;\n\t\tchunk.storeName = this.storeName;\n\t\tchunk.edited = this.edited;\n\n\t\treturn chunk;\n\t}\n\n\tcontains(index) {\n\t\treturn this.start < index && index < this.end;\n\t}\n\n\teachNext(fn) {\n\t\tlet chunk = this;\n\t\twhile (chunk) {\n\t\t\tfn(chunk);\n\t\t\tchunk = chunk.next;\n\t\t}\n\t}\n\n\teachPrevious(fn) {\n\t\tlet chunk = this;\n\t\twhile (chunk) {\n\t\t\tfn(chunk);\n\t\t\tchunk = chunk.previous;\n\t\t}\n\t}\n\n\tedit(content, storeName, contentOnly) {\n\t\tthis.content = content;\n\t\tif (!contentOnly) {\n\t\t\tthis.intro = '';\n\t\t\tthis.outro = '';\n\t\t}\n\t\tthis.storeName = storeName;\n\n\t\tthis.edited = true;\n\n\t\treturn this;\n\t}\n\n\tprependLeft(content) {\n\t\tthis.outro = content + this.outro;\n\t}\n\n\tprependRight(content) {\n\t\tthis.intro = content + this.intro;\n\t}\n\n\tsplit(index) {\n\t\tconst sliceIndex = index - this.start;\n\n\t\tconst originalBefore = this.original.slice(0, sliceIndex);\n\t\tconst originalAfter = this.original.slice(sliceIndex);\n\n\t\tthis.original = originalBefore;\n\n\t\tconst newChunk = new Chunk(index, this.end, originalAfter);\n\t\tnewChunk.outro = this.outro;\n\t\tthis.outro = '';\n\n\t\tthis.end = index;\n\n\t\tif (this.edited) {\n\t\t\t// TODO is this block necessary?...\n\t\t\tnewChunk.edit('', false);\n\t\t\tthis.content = '';\n\t\t} else {\n\t\t\tthis.content = originalBefore;\n\t\t}\n\n\t\tnewChunk.next = this.next;\n\t\tif (newChunk.next) newChunk.next.previous = newChunk;\n\t\tnewChunk.previous = this;\n\t\tthis.next = newChunk;\n\n\t\treturn newChunk;\n\t}\n\n\ttoString() {\n\t\treturn this.intro + this.content + this.outro;\n\t}\n\n\ttrimEnd(rx) {\n\t\tthis.outro = this.outro.replace(rx, '');\n\t\tif (this.outro.length) return true;\n\n\t\tconst trimmed = this.content.replace(rx, '');\n\n\t\tif (trimmed.length) {\n\t\t\tif (trimmed !== this.content) {\n\t\t\t\tthis.split(this.start + trimmed.length).edit('', undefined, true);\n\t\t\t}\n\t\t\treturn true;\n\t\t} else {\n\t\t\tthis.edit('', undefined, true);\n\n\t\t\tthis.intro = this.intro.replace(rx, '');\n\t\t\tif (this.intro.length) return true;\n\t\t}\n\t}\n\n\ttrimStart(rx) {\n\t\tthis.intro = this.intro.replace(rx, '');\n\t\tif (this.intro.length) return true;\n\n\t\tconst trimmed = this.content.replace(rx, '');\n\n\t\tif (trimmed.length) {\n\t\t\tif (trimmed !== this.content) {\n\t\t\t\tthis.split(this.end - trimmed.length);\n\t\t\t\tthis.edit('', undefined, true);\n\t\t\t}\n\t\t\treturn true;\n\t\t} else {\n\t\t\tthis.edit('', undefined, true);\n\n\t\t\tthis.outro = this.outro.replace(rx, '');\n\t\t\tif (this.outro.length) return true;\n\t\t}\n\t}\n}\n\nfunction getBtoa () {\n\tif (typeof window !== 'undefined' && typeof window.btoa === 'function') {\n\t\treturn (str) => window.btoa(unescape(encodeURIComponent(str)));\n\t} else if (typeof Buffer === 'function') {\n\t\treturn (str) => Buffer.from(str, 'utf-8').toString('base64');\n\t} else {\n\t\treturn () => {\n\t\t\tthrow new Error('Unsupported environment: `window.btoa` or `Buffer` should be supported.');\n\t\t};\n\t}\n}\n\nconst btoa$1 = /*#__PURE__*/ getBtoa();\n\nlet SourceMap$1 = class SourceMap {\n\tconstructor(properties) {\n\t\tthis.version = 3;\n\t\tthis.file = properties.file;\n\t\tthis.sources = properties.sources;\n\t\tthis.sourcesContent = properties.sourcesContent;\n\t\tthis.names = properties.names;\n\t\tthis.mappings = encode$1(properties.mappings);\n\t}\n\n\ttoString() {\n\t\treturn JSON.stringify(this);\n\t}\n\n\ttoUrl() {\n\t\treturn 'data:application/json;charset=utf-8;base64,' + btoa$1(this.toString());\n\t}\n};\n\nfunction guessIndent(code) {\n\tconst lines = code.split('\\n');\n\n\tconst tabbed = lines.filter((line) => /^\\t+/.test(line));\n\tconst spaced = lines.filter((line) => /^ {2,}/.test(line));\n\n\tif (tabbed.length === 0 && spaced.length === 0) {\n\t\treturn null;\n\t}\n\n\t// More lines tabbed than spaced? Assume tabs, and\n\t// default to tabs in the case of a tie (or nothing\n\t// to go on)\n\tif (tabbed.length >= spaced.length) {\n\t\treturn '\\t';\n\t}\n\n\t// Otherwise, we need to guess the multiple\n\tconst min = spaced.reduce((previous, current) => {\n\t\tconst numSpaces = /^ +/.exec(current)[0].length;\n\t\treturn Math.min(numSpaces, previous);\n\t}, Infinity);\n\n\treturn new Array(min + 1).join(' ');\n}\n\nfunction getRelativePath(from, to) {\n\tconst fromParts = from.split(/[/\\\\]/);\n\tconst toParts = to.split(/[/\\\\]/);\n\n\tfromParts.pop(); // get dirname\n\n\twhile (fromParts[0] === toParts[0]) {\n\t\tfromParts.shift();\n\t\ttoParts.shift();\n\t}\n\n\tif (fromParts.length) {\n\t\tlet i = fromParts.length;\n\t\twhile (i--) fromParts[i] = '..';\n\t}\n\n\treturn fromParts.concat(toParts).join('/');\n}\n\nconst toString$2 = Object.prototype.toString;\n\nfunction isObject$2(thing) {\n\treturn toString$2.call(thing) === '[object Object]';\n}\n\nfunction getLocator(source) {\n\tconst originalLines = source.split('\\n');\n\tconst lineOffsets = [];\n\n\tfor (let i = 0, pos = 0; i < originalLines.length; i++) {\n\t\tlineOffsets.push(pos);\n\t\tpos += originalLines[i].length + 1;\n\t}\n\n\treturn function locate(index) {\n\t\tlet i = 0;\n\t\tlet j = lineOffsets.length;\n\t\twhile (i < j) {\n\t\t\tconst m = (i + j) >> 1;\n\t\t\tif (index < lineOffsets[m]) {\n\t\t\t\tj = m;\n\t\t\t} else {\n\t\t\t\ti = m + 1;\n\t\t\t}\n\t\t}\n\t\tconst line = i - 1;\n\t\tconst column = index - lineOffsets[line];\n\t\treturn { line, column };\n\t};\n}\n\nclass Mappings {\n\tconstructor(hires) {\n\t\tthis.hires = hires;\n\t\tthis.generatedCodeLine = 0;\n\t\tthis.generatedCodeColumn = 0;\n\t\tthis.raw = [];\n\t\tthis.rawSegments = this.raw[this.generatedCodeLine] = [];\n\t\tthis.pending = null;\n\t}\n\n\taddEdit(sourceIndex, content, loc, nameIndex) {\n\t\tif (content.length) {\n\t\t\tconst segment = [this.generatedCodeColumn, sourceIndex, loc.line, loc.column];\n\t\t\tif (nameIndex >= 0) {\n\t\t\t\tsegment.push(nameIndex);\n\t\t\t}\n\t\t\tthis.rawSegments.push(segment);\n\t\t} else if (this.pending) {\n\t\t\tthis.rawSegments.push(this.pending);\n\t\t}\n\n\t\tthis.advance(content);\n\t\tthis.pending = null;\n\t}\n\n\taddUneditedChunk(sourceIndex, chunk, original, loc, sourcemapLocations) {\n\t\tlet originalCharIndex = chunk.start;\n\t\tlet first = true;\n\n\t\twhile (originalCharIndex < chunk.end) {\n\t\t\tif (this.hires || first || sourcemapLocations.has(originalCharIndex)) {\n\t\t\t\tthis.rawSegments.push([this.generatedCodeColumn, sourceIndex, loc.line, loc.column]);\n\t\t\t}\n\n\t\t\tif (original[originalCharIndex] === '\\n') {\n\t\t\t\tloc.line += 1;\n\t\t\t\tloc.column = 0;\n\t\t\t\tthis.generatedCodeLine += 1;\n\t\t\t\tthis.raw[this.generatedCodeLine] = this.rawSegments = [];\n\t\t\t\tthis.generatedCodeColumn = 0;\n\t\t\t\tfirst = true;\n\t\t\t} else {\n\t\t\t\tloc.column += 1;\n\t\t\t\tthis.generatedCodeColumn += 1;\n\t\t\t\tfirst = false;\n\t\t\t}\n\n\t\t\toriginalCharIndex += 1;\n\t\t}\n\n\t\tthis.pending = null;\n\t}\n\n\tadvance(str) {\n\t\tif (!str) return;\n\n\t\tconst lines = str.split('\\n');\n\n\t\tif (lines.length > 1) {\n\t\t\tfor (let i = 0; i < lines.length - 1; i++) {\n\t\t\t\tthis.generatedCodeLine++;\n\t\t\t\tthis.raw[this.generatedCodeLine] = this.rawSegments = [];\n\t\t\t}\n\t\t\tthis.generatedCodeColumn = 0;\n\t\t}\n\n\t\tthis.generatedCodeColumn += lines[lines.length - 1].length;\n\t}\n}\n\nconst n$1 = '\\n';\n\nconst warned = {\n\tinsertLeft: false,\n\tinsertRight: false,\n\tstoreName: false,\n};\n\nclass MagicString {\n\tconstructor(string, options = {}) {\n\t\tconst chunk = new Chunk(0, string.length, string);\n\n\t\tObject.defineProperties(this, {\n\t\t\toriginal: { writable: true, value: string },\n\t\t\toutro: { writable: true, value: '' },\n\t\t\tintro: { writable: true, value: '' },\n\t\t\tfirstChunk: { writable: true, value: chunk },\n\t\t\tlastChunk: { writable: true, value: chunk },\n\t\t\tlastSearchedChunk: { writable: true, value: chunk },\n\t\t\tbyStart: { writable: true, value: {} },\n\t\t\tbyEnd: { writable: true, value: {} },\n\t\t\tfilename: { writable: true, value: options.filename },\n\t\t\tindentExclusionRanges: { writable: true, value: options.indentExclusionRanges },\n\t\t\tsourcemapLocations: { writable: true, value: new BitSet() },\n\t\t\tstoredNames: { writable: true, value: {} },\n\t\t\tindentStr: { writable: true, value: undefined },\n\t\t});\n\n\t\tthis.byStart[0] = chunk;\n\t\tthis.byEnd[string.length] = chunk;\n\t}\n\n\taddSourcemapLocation(char) {\n\t\tthis.sourcemapLocations.add(char);\n\t}\n\n\tappend(content) {\n\t\tif (typeof content !== 'string') throw new TypeError('outro content must be a string');\n\n\t\tthis.outro += content;\n\t\treturn this;\n\t}\n\n\tappendLeft(index, content) {\n\t\tif (typeof content !== 'string') throw new TypeError('inserted content must be a string');\n\n\t\tthis._split(index);\n\n\t\tconst chunk = this.byEnd[index];\n\n\t\tif (chunk) {\n\t\t\tchunk.appendLeft(content);\n\t\t} else {\n\t\t\tthis.intro += content;\n\t\t}\n\t\treturn this;\n\t}\n\n\tappendRight(index, content) {\n\t\tif (typeof content !== 'string') throw new TypeError('inserted content must be a string');\n\n\t\tthis._split(index);\n\n\t\tconst chunk = this.byStart[index];\n\n\t\tif (chunk) {\n\t\t\tchunk.appendRight(content);\n\t\t} else {\n\t\t\tthis.outro += content;\n\t\t}\n\t\treturn this;\n\t}\n\n\tclone() {\n\t\tconst cloned = new MagicString(this.original, { filename: this.filename });\n\n\t\tlet originalChunk = this.firstChunk;\n\t\tlet clonedChunk = (cloned.firstChunk = cloned.lastSearchedChunk = originalChunk.clone());\n\n\t\twhile (originalChunk) {\n\t\t\tcloned.byStart[clonedChunk.start] = clonedChunk;\n\t\t\tcloned.byEnd[clonedChunk.end] = clonedChunk;\n\n\t\t\tconst nextOriginalChunk = originalChunk.next;\n\t\t\tconst nextClonedChunk = nextOriginalChunk && nextOriginalChunk.clone();\n\n\t\t\tif (nextClonedChunk) {\n\t\t\t\tclonedChunk.next = nextClonedChunk;\n\t\t\t\tnextClonedChunk.previous = clonedChunk;\n\n\t\t\t\tclonedChunk = nextClonedChunk;\n\t\t\t}\n\n\t\t\toriginalChunk = nextOriginalChunk;\n\t\t}\n\n\t\tcloned.lastChunk = clonedChunk;\n\n\t\tif (this.indentExclusionRanges) {\n\t\t\tcloned.indentExclusionRanges = this.indentExclusionRanges.slice();\n\t\t}\n\n\t\tcloned.sourcemapLocations = new BitSet(this.sourcemapLocations);\n\n\t\tcloned.intro = this.intro;\n\t\tcloned.outro = this.outro;\n\n\t\treturn cloned;\n\t}\n\n\tgenerateDecodedMap(options) {\n\t\toptions = options || {};\n\n\t\tconst sourceIndex = 0;\n\t\tconst names = Object.keys(this.storedNames);\n\t\tconst mappings = new Mappings(options.hires);\n\n\t\tconst locate = getLocator(this.original);\n\n\t\tif (this.intro) {\n\t\t\tmappings.advance(this.intro);\n\t\t}\n\n\t\tthis.firstChunk.eachNext((chunk) => {\n\t\t\tconst loc = locate(chunk.start);\n\n\t\t\tif (chunk.intro.length) mappings.advance(chunk.intro);\n\n\t\t\tif (chunk.edited) {\n\t\t\t\tmappings.addEdit(\n\t\t\t\t\tsourceIndex,\n\t\t\t\t\tchunk.content,\n\t\t\t\t\tloc,\n\t\t\t\t\tchunk.storeName ? names.indexOf(chunk.original) : -1\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\tmappings.addUneditedChunk(sourceIndex, chunk, this.original, loc, this.sourcemapLocations);\n\t\t\t}\n\n\t\t\tif (chunk.outro.length) mappings.advance(chunk.outro);\n\t\t});\n\n\t\treturn {\n\t\t\tfile: options.file ? options.file.split(/[/\\\\]/).pop() : null,\n\t\t\tsources: [options.source ? getRelativePath(options.file || '', options.source) : null],\n\t\t\tsourcesContent: options.includeContent ? [this.original] : [null],\n\t\t\tnames,\n\t\t\tmappings: mappings.raw,\n\t\t};\n\t}\n\n\tgenerateMap(options) {\n\t\treturn new SourceMap$1(this.generateDecodedMap(options));\n\t}\n\n\t_ensureindentStr() {\n\t\tif (this.indentStr === undefined) {\n\t\t\tthis.indentStr = guessIndent(this.original);\n\t\t}\n\t}\n\n\t_getRawIndentString() {\n\t\tthis._ensureindentStr();\n\t\treturn this.indentStr;\n\t}\n\n\tgetIndentString() {\n\t\tthis._ensureindentStr();\n\t\treturn this.indentStr === null ? '\\t' : this.indentStr;\n\t}\n\n\tindent(indentStr, options) {\n\t\tconst pattern = /^[^\\r\\n]/gm;\n\n\t\tif (isObject$2(indentStr)) {\n\t\t\toptions = indentStr;\n\t\t\tindentStr = undefined;\n\t\t}\n\n\t\tif (indentStr === undefined) {\n\t\t\tthis._ensureindentStr();\n\t\t\tindentStr = this.indentStr || '\\t';\n\t\t}\n\n\t\tif (indentStr === '') return this; // noop\n\n\t\toptions = options || {};\n\n\t\t// Process exclusion ranges\n\t\tconst isExcluded = {};\n\n\t\tif (options.exclude) {\n\t\t\tconst exclusions =\n\t\t\t\ttypeof options.exclude[0] === 'number' ? [options.exclude] : options.exclude;\n\t\t\texclusions.forEach((exclusion) => {\n\t\t\t\tfor (let i = exclusion[0]; i < exclusion[1]; i += 1) {\n\t\t\t\t\tisExcluded[i] = true;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\n\t\tlet shouldIndentNextCharacter = options.indentStart !== false;\n\t\tconst replacer = (match) => {\n\t\t\tif (shouldIndentNextCharacter) return `${indentStr}${match}`;\n\t\t\tshouldIndentNextCharacter = true;\n\t\t\treturn match;\n\t\t};\n\n\t\tthis.intro = this.intro.replace(pattern, replacer);\n\n\t\tlet charIndex = 0;\n\t\tlet chunk = this.firstChunk;\n\n\t\twhile (chunk) {\n\t\t\tconst end = chunk.end;\n\n\t\t\tif (chunk.edited) {\n\t\t\t\tif (!isExcluded[charIndex]) {\n\t\t\t\t\tchunk.content = chunk.content.replace(pattern, replacer);\n\n\t\t\t\t\tif (chunk.content.length) {\n\t\t\t\t\t\tshouldIndentNextCharacter = chunk.content[chunk.content.length - 1] === '\\n';\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcharIndex = chunk.start;\n\n\t\t\t\twhile (charIndex < end) {\n\t\t\t\t\tif (!isExcluded[charIndex]) {\n\t\t\t\t\t\tconst char = this.original[charIndex];\n\n\t\t\t\t\t\tif (char === '\\n') {\n\t\t\t\t\t\t\tshouldIndentNextCharacter = true;\n\t\t\t\t\t\t} else if (char !== '\\r' && shouldIndentNextCharacter) {\n\t\t\t\t\t\t\tshouldIndentNextCharacter = false;\n\n\t\t\t\t\t\t\tif (charIndex === chunk.start) {\n\t\t\t\t\t\t\t\tchunk.prependRight(indentStr);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tthis._splitChunk(chunk, charIndex);\n\t\t\t\t\t\t\t\tchunk = chunk.next;\n\t\t\t\t\t\t\t\tchunk.prependRight(indentStr);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tcharIndex += 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcharIndex = chunk.end;\n\t\t\tchunk = chunk.next;\n\t\t}\n\n\t\tthis.outro = this.outro.replace(pattern, replacer);\n\n\t\treturn this;\n\t}\n\n\tinsert() {\n\t\tthrow new Error(\n\t\t\t'magicString.insert(...) is deprecated. Use prependRight(...) or appendLeft(...)'\n\t\t);\n\t}\n\n\tinsertLeft(index, content) {\n\t\tif (!warned.insertLeft) {\n\t\t\tconsole.warn(\n\t\t\t\t'magicString.insertLeft(...) is deprecated. Use magicString.appendLeft(...) instead'\n\t\t\t); // eslint-disable-line no-console\n\t\t\twarned.insertLeft = true;\n\t\t}\n\n\t\treturn this.appendLeft(index, content);\n\t}\n\n\tinsertRight(index, content) {\n\t\tif (!warned.insertRight) {\n\t\t\tconsole.warn(\n\t\t\t\t'magicString.insertRight(...) is deprecated. Use magicString.prependRight(...) instead'\n\t\t\t); // eslint-disable-line no-console\n\t\t\twarned.insertRight = true;\n\t\t}\n\n\t\treturn this.prependRight(index, content);\n\t}\n\n\tmove(start, end, index) {\n\t\tif (index >= start && index <= end) throw new Error('Cannot move a selection inside itself');\n\n\t\tthis._split(start);\n\t\tthis._split(end);\n\t\tthis._split(index);\n\n\t\tconst first = this.byStart[start];\n\t\tconst last = this.byEnd[end];\n\n\t\tconst oldLeft = first.previous;\n\t\tconst oldRight = last.next;\n\n\t\tconst newRight = this.byStart[index];\n\t\tif (!newRight && last === this.lastChunk) return this;\n\t\tconst newLeft = newRight ? newRight.previous : this.lastChunk;\n\n\t\tif (oldLeft) oldLeft.next = oldRight;\n\t\tif (oldRight) oldRight.previous = oldLeft;\n\n\t\tif (newLeft) newLeft.next = first;\n\t\tif (newRight) newRight.previous = last;\n\n\t\tif (!first.previous) this.firstChunk = last.next;\n\t\tif (!last.next) {\n\t\t\tthis.lastChunk = first.previous;\n\t\t\tthis.lastChunk.next = null;\n\t\t}\n\n\t\tfirst.previous = newLeft;\n\t\tlast.next = newRight || null;\n\n\t\tif (!newLeft) this.firstChunk = first;\n\t\tif (!newRight) this.lastChunk = last;\n\t\treturn this;\n\t}\n\n\toverwrite(start, end, content, options) {\n\t\toptions = options || {};\n\t\treturn this.update(start, end, content, { ...options, overwrite: !options.contentOnly });\n\t}\n\n\tupdate(start, end, content, options) {\n\t\tif (typeof content !== 'string') throw new TypeError('replacement content must be a string');\n\n\t\twhile (start < 0) start += this.original.length;\n\t\twhile (end < 0) end += this.original.length;\n\n\t\tif (end > this.original.length) throw new Error('end is out of bounds');\n\t\tif (start === end)\n\t\t\tthrow new Error(\n\t\t\t\t'Cannot overwrite a zero-length range – use appendLeft or prependRight instead'\n\t\t\t);\n\n\t\tthis._split(start);\n\t\tthis._split(end);\n\n\t\tif (options === true) {\n\t\t\tif (!warned.storeName) {\n\t\t\t\tconsole.warn(\n\t\t\t\t\t'The final argument to magicString.overwrite(...) should be an options object. See https://github.com/rich-harris/magic-string'\n\t\t\t\t); // eslint-disable-line no-console\n\t\t\t\twarned.storeName = true;\n\t\t\t}\n\n\t\t\toptions = { storeName: true };\n\t\t}\n\t\tconst storeName = options !== undefined ? options.storeName : false;\n\t\tconst overwrite = options !== undefined ? options.overwrite : false;\n\n\t\tif (storeName) {\n\t\t\tconst original = this.original.slice(start, end);\n\t\t\tObject.defineProperty(this.storedNames, original, {\n\t\t\t\twritable: true,\n\t\t\t\tvalue: true,\n\t\t\t\tenumerable: true,\n\t\t\t});\n\t\t}\n\n\t\tconst first = this.byStart[start];\n\t\tconst last = this.byEnd[end];\n\n\t\tif (first) {\n\t\t\tlet chunk = first;\n\t\t\twhile (chunk !== last) {\n\t\t\t\tif (chunk.next !== this.byStart[chunk.end]) {\n\t\t\t\t\tthrow new Error('Cannot overwrite across a split point');\n\t\t\t\t}\n\t\t\t\tchunk = chunk.next;\n\t\t\t\tchunk.edit('', false);\n\t\t\t}\n\n\t\t\tfirst.edit(content, storeName, !overwrite);\n\t\t} else {\n\t\t\t// must be inserting at the end\n\t\t\tconst newChunk = new Chunk(start, end, '').edit(content, storeName);\n\n\t\t\t// TODO last chunk in the array may not be the last chunk, if it's moved...\n\t\t\tlast.next = newChunk;\n\t\t\tnewChunk.previous = last;\n\t\t}\n\t\treturn this;\n\t}\n\n\tprepend(content) {\n\t\tif (typeof content !== 'string') throw new TypeError('outro content must be a string');\n\n\t\tthis.intro = content + this.intro;\n\t\treturn this;\n\t}\n\n\tprependLeft(index, content) {\n\t\tif (typeof content !== 'string') throw new TypeError('inserted content must be a string');\n\n\t\tthis._split(index);\n\n\t\tconst chunk = this.byEnd[index];\n\n\t\tif (chunk) {\n\t\t\tchunk.prependLeft(content);\n\t\t} else {\n\t\t\tthis.intro = content + this.intro;\n\t\t}\n\t\treturn this;\n\t}\n\n\tprependRight(index, content) {\n\t\tif (typeof content !== 'string') throw new TypeError('inserted content must be a string');\n\n\t\tthis._split(index);\n\n\t\tconst chunk = this.byStart[index];\n\n\t\tif (chunk) {\n\t\t\tchunk.prependRight(content);\n\t\t} else {\n\t\t\tthis.outro = content + this.outro;\n\t\t}\n\t\treturn this;\n\t}\n\n\tremove(start, end) {\n\t\twhile (start < 0) start += this.original.length;\n\t\twhile (end < 0) end += this.original.length;\n\n\t\tif (start === end) return this;\n\n\t\tif (start < 0 || end > this.original.length) throw new Error('Character is out of bounds');\n\t\tif (start > end) throw new Error('end must be greater than start');\n\n\t\tthis._split(start);\n\t\tthis._split(end);\n\n\t\tlet chunk = this.byStart[start];\n\n\t\twhile (chunk) {\n\t\t\tchunk.intro = '';\n\t\t\tchunk.outro = '';\n\t\t\tchunk.edit('');\n\n\t\t\tchunk = end > chunk.end ? this.byStart[chunk.end] : null;\n\t\t}\n\t\treturn this;\n\t}\n\n\tlastChar() {\n\t\tif (this.outro.length) return this.outro[this.outro.length - 1];\n\t\tlet chunk = this.lastChunk;\n\t\tdo {\n\t\t\tif (chunk.outro.length) return chunk.outro[chunk.outro.length - 1];\n\t\t\tif (chunk.content.length) return chunk.content[chunk.content.length - 1];\n\t\t\tif (chunk.intro.length) return chunk.intro[chunk.intro.length - 1];\n\t\t} while ((chunk = chunk.previous));\n\t\tif (this.intro.length) return this.intro[this.intro.length - 1];\n\t\treturn '';\n\t}\n\n\tlastLine() {\n\t\tlet lineIndex = this.outro.lastIndexOf(n$1);\n\t\tif (lineIndex !== -1) return this.outro.substr(lineIndex + 1);\n\t\tlet lineStr = this.outro;\n\t\tlet chunk = this.lastChunk;\n\t\tdo {\n\t\t\tif (chunk.outro.length > 0) {\n\t\t\t\tlineIndex = chunk.outro.lastIndexOf(n$1);\n\t\t\t\tif (lineIndex !== -1) return chunk.outro.substr(lineIndex + 1) + lineStr;\n\t\t\t\tlineStr = chunk.outro + lineStr;\n\t\t\t}\n\n\t\t\tif (chunk.content.length > 0) {\n\t\t\t\tlineIndex = chunk.content.lastIndexOf(n$1);\n\t\t\t\tif (lineIndex !== -1) return chunk.content.substr(lineIndex + 1) + lineStr;\n\t\t\t\tlineStr = chunk.content + lineStr;\n\t\t\t}\n\n\t\t\tif (chunk.intro.length > 0) {\n\t\t\t\tlineIndex = chunk.intro.lastIndexOf(n$1);\n\t\t\t\tif (lineIndex !== -1) return chunk.intro.substr(lineIndex + 1) + lineStr;\n\t\t\t\tlineStr = chunk.intro + lineStr;\n\t\t\t}\n\t\t} while ((chunk = chunk.previous));\n\t\tlineIndex = this.intro.lastIndexOf(n$1);\n\t\tif (lineIndex !== -1) return this.intro.substr(lineIndex + 1) + lineStr;\n\t\treturn this.intro + lineStr;\n\t}\n\n\tslice(start = 0, end = this.original.length) {\n\t\twhile (start < 0) start += this.original.length;\n\t\twhile (end < 0) end += this.original.length;\n\n\t\tlet result = '';\n\n\t\t// find start chunk\n\t\tlet chunk = this.firstChunk;\n\t\twhile (chunk && (chunk.start > start || chunk.end <= start)) {\n\t\t\t// found end chunk before start\n\t\t\tif (chunk.start < end && chunk.end >= end) {\n\t\t\t\treturn result;\n\t\t\t}\n\n\t\t\tchunk = chunk.next;\n\t\t}\n\n\t\tif (chunk && chunk.edited && chunk.start !== start)\n\t\t\tthrow new Error(`Cannot use replaced character ${start} as slice start anchor.`);\n\n\t\tconst startChunk = chunk;\n\t\twhile (chunk) {\n\t\t\tif (chunk.intro && (startChunk !== chunk || chunk.start === start)) {\n\t\t\t\tresult += chunk.intro;\n\t\t\t}\n\n\t\t\tconst containsEnd = chunk.start < end && chunk.end >= end;\n\t\t\tif (containsEnd && chunk.edited && chunk.end !== end)\n\t\t\t\tthrow new Error(`Cannot use replaced character ${end} as slice end anchor.`);\n\n\t\t\tconst sliceStart = startChunk === chunk ? start - chunk.start : 0;\n\t\t\tconst sliceEnd = containsEnd ? chunk.content.length + end - chunk.end : chunk.content.length;\n\n\t\t\tresult += chunk.content.slice(sliceStart, sliceEnd);\n\n\t\t\tif (chunk.outro && (!containsEnd || chunk.end === end)) {\n\t\t\t\tresult += chunk.outro;\n\t\t\t}\n\n\t\t\tif (containsEnd) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tchunk = chunk.next;\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t// TODO deprecate this? not really very useful\n\tsnip(start, end) {\n\t\tconst clone = this.clone();\n\t\tclone.remove(0, start);\n\t\tclone.remove(end, clone.original.length);\n\n\t\treturn clone;\n\t}\n\n\t_split(index) {\n\t\tif (this.byStart[index] || this.byEnd[index]) return;\n\n\t\tlet chunk = this.lastSearchedChunk;\n\t\tconst searchForward = index > chunk.end;\n\n\t\twhile (chunk) {\n\t\t\tif (chunk.contains(index)) return this._splitChunk(chunk, index);\n\n\t\t\tchunk = searchForward ? this.byStart[chunk.end] : this.byEnd[chunk.start];\n\t\t}\n\t}\n\n\t_splitChunk(chunk, index) {\n\t\tif (chunk.edited && chunk.content.length) {\n\t\t\t// zero-length edited chunks are a special case (overlapping replacements)\n\t\t\tconst loc = getLocator(this.original)(index);\n\t\t\tthrow new Error(\n\t\t\t\t`Cannot split a chunk that has already been edited (${loc.line}:${loc.column} – \"${chunk.original}\")`\n\t\t\t);\n\t\t}\n\n\t\tconst newChunk = chunk.split(index);\n\n\t\tthis.byEnd[index] = chunk;\n\t\tthis.byStart[index] = newChunk;\n\t\tthis.byEnd[newChunk.end] = newChunk;\n\n\t\tif (chunk === this.lastChunk) this.lastChunk = newChunk;\n\n\t\tthis.lastSearchedChunk = chunk;\n\t\treturn true;\n\t}\n\n\ttoString() {\n\t\tlet str = this.intro;\n\n\t\tlet chunk = this.firstChunk;\n\t\twhile (chunk) {\n\t\t\tstr += chunk.toString();\n\t\t\tchunk = chunk.next;\n\t\t}\n\n\t\treturn str + this.outro;\n\t}\n\n\tisEmpty() {\n\t\tlet chunk = this.firstChunk;\n\t\tdo {\n\t\t\tif (\n\t\t\t\t(chunk.intro.length && chunk.intro.trim()) ||\n\t\t\t\t(chunk.content.length && chunk.content.trim()) ||\n\t\t\t\t(chunk.outro.length && chunk.outro.trim())\n\t\t\t)\n\t\t\t\treturn false;\n\t\t} while ((chunk = chunk.next));\n\t\treturn true;\n\t}\n\n\tlength() {\n\t\tlet chunk = this.firstChunk;\n\t\tlet length = 0;\n\t\tdo {\n\t\t\tlength += chunk.intro.length + chunk.content.length + chunk.outro.length;\n\t\t} while ((chunk = chunk.next));\n\t\treturn length;\n\t}\n\n\ttrimLines() {\n\t\treturn this.trim('[\\\\r\\\\n]');\n\t}\n\n\ttrim(charType) {\n\t\treturn this.trimStart(charType).trimEnd(charType);\n\t}\n\n\ttrimEndAborted(charType) {\n\t\tconst rx = new RegExp((charType || '\\\\s') + '+$');\n\n\t\tthis.outro = this.outro.replace(rx, '');\n\t\tif (this.outro.length) return true;\n\n\t\tlet chunk = this.lastChunk;\n\n\t\tdo {\n\t\t\tconst end = chunk.end;\n\t\t\tconst aborted = chunk.trimEnd(rx);\n\n\t\t\t// if chunk was trimmed, we have a new lastChunk\n\t\t\tif (chunk.end !== end) {\n\t\t\t\tif (this.lastChunk === chunk) {\n\t\t\t\t\tthis.lastChunk = chunk.next;\n\t\t\t\t}\n\n\t\t\t\tthis.byEnd[chunk.end] = chunk;\n\t\t\t\tthis.byStart[chunk.next.start] = chunk.next;\n\t\t\t\tthis.byEnd[chunk.next.end] = chunk.next;\n\t\t\t}\n\n\t\t\tif (aborted) return true;\n\t\t\tchunk = chunk.previous;\n\t\t} while (chunk);\n\n\t\treturn false;\n\t}\n\n\ttrimEnd(charType) {\n\t\tthis.trimEndAborted(charType);\n\t\treturn this;\n\t}\n\ttrimStartAborted(charType) {\n\t\tconst rx = new RegExp('^' + (charType || '\\\\s') + '+');\n\n\t\tthis.intro = this.intro.replace(rx, '');\n\t\tif (this.intro.length) return true;\n\n\t\tlet chunk = this.firstChunk;\n\n\t\tdo {\n\t\t\tconst end = chunk.end;\n\t\t\tconst aborted = chunk.trimStart(rx);\n\n\t\t\tif (chunk.end !== end) {\n\t\t\t\t// special case...\n\t\t\t\tif (chunk === this.lastChunk) this.lastChunk = chunk.next;\n\n\t\t\t\tthis.byEnd[chunk.end] = chunk;\n\t\t\t\tthis.byStart[chunk.next.start] = chunk.next;\n\t\t\t\tthis.byEnd[chunk.next.end] = chunk.next;\n\t\t\t}\n\n\t\t\tif (aborted) return true;\n\t\t\tchunk = chunk.next;\n\t\t} while (chunk);\n\n\t\treturn false;\n\t}\n\n\ttrimStart(charType) {\n\t\tthis.trimStartAborted(charType);\n\t\treturn this;\n\t}\n\n\thasChanged() {\n\t\treturn this.original !== this.toString();\n\t}\n\n\t_replaceRegexp(searchValue, replacement) {\n\t\tfunction getReplacement(match, str) {\n\t\t\tif (typeof replacement === 'string') {\n\t\t\t\treturn replacement.replace(/\\$(\\$|&|\\d+)/g, (_, i) => {\n\t\t\t\t\t// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/replace#specifying_a_string_as_a_parameter\n\t\t\t\t\tif (i === '$') return '$';\n\t\t\t\t\tif (i === '&') return match[0];\n\t\t\t\t\tconst num = +i;\n\t\t\t\t\tif (num < match.length) return match[+i];\n\t\t\t\t\treturn `$${i}`;\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\treturn replacement(...match, match.index, str, match.groups);\n\t\t\t}\n\t\t}\n\t\tfunction matchAll(re, str) {\n\t\t\tlet match;\n\t\t\tconst matches = [];\n\t\t\twhile ((match = re.exec(str))) {\n\t\t\t\tmatches.push(match);\n\t\t\t}\n\t\t\treturn matches;\n\t\t}\n\t\tif (searchValue.global) {\n\t\t\tconst matches = matchAll(searchValue, this.original);\n\t\t\tmatches.forEach((match) => {\n\t\t\t\tif (match.index != null)\n\t\t\t\t\tthis.overwrite(\n\t\t\t\t\t\tmatch.index,\n\t\t\t\t\t\tmatch.index + match[0].length,\n\t\t\t\t\t\tgetReplacement(match, this.original)\n\t\t\t\t\t);\n\t\t\t});\n\t\t} else {\n\t\t\tconst match = this.original.match(searchValue);\n\t\t\tif (match && match.index != null)\n\t\t\t\tthis.overwrite(\n\t\t\t\t\tmatch.index,\n\t\t\t\t\tmatch.index + match[0].length,\n\t\t\t\t\tgetReplacement(match, this.original)\n\t\t\t\t);\n\t\t}\n\t\treturn this;\n\t}\n\n\t_replaceString(string, replacement) {\n\t\tconst { original } = this;\n\t\tconst index = original.indexOf(string);\n\n\t\tif (index !== -1) {\n\t\t\tthis.overwrite(index, index + string.length, replacement);\n\t\t}\n\n\t\treturn this;\n\t}\n\n\treplace(searchValue, replacement) {\n\t\tif (typeof searchValue === 'string') {\n\t\t\treturn this._replaceString(searchValue, replacement);\n\t\t}\n\n\t\treturn this._replaceRegexp(searchValue, replacement);\n\t}\n\n\t_replaceAllString(string, replacement) {\n\t\tconst { original } = this;\n\t\tconst stringLength = string.length;\n\t\tfor (\n\t\t\tlet index = original.indexOf(string);\n\t\t\tindex !== -1;\n\t\t\tindex = original.indexOf(string, index + stringLength)\n\t\t) {\n\t\t\tthis.overwrite(index, index + stringLength, replacement);\n\t\t}\n\n\t\treturn this;\n\t}\n\n\treplaceAll(searchValue, replacement) {\n\t\tif (typeof searchValue === 'string') {\n\t\t\treturn this._replaceAllString(searchValue, replacement);\n\t\t}\n\n\t\tif (!searchValue.global) {\n\t\t\tthrow new TypeError(\n\t\t\t\t'MagicString.prototype.replaceAll called with a non-global RegExp argument'\n\t\t\t);\n\t\t}\n\n\t\treturn this._replaceRegexp(searchValue, replacement);\n\t}\n}\n\nfunction isReference(node, parent) {\n    if (node.type === 'MemberExpression') {\n        return !node.computed && isReference(node.object, node);\n    }\n    if (node.type === 'Identifier') {\n        if (!parent)\n            return true;\n        switch (parent.type) {\n            // disregard `bar` in `foo.bar`\n            case 'MemberExpression': return parent.computed || node === parent.object;\n            // disregard the `foo` in `class {foo(){}}` but keep it in `class {[foo](){}}`\n            case 'MethodDefinition': return parent.computed;\n            // disregard the `foo` in `class {foo=bar}` but keep it in `class {[foo]=bar}` and `class {bar=foo}`\n            case 'FieldDefinition': return parent.computed || node === parent.value;\n            // disregard the `bar` in `{ bar: foo }`, but keep it in `{ [bar]: foo }`\n            case 'Property': return parent.computed || node === parent.value;\n            // disregard the `bar` in `export { foo as bar }` or\n            // the foo in `import { foo as bar }`\n            case 'ExportSpecifier':\n            case 'ImportSpecifier': return node === parent.local;\n            // disregard the `foo` in `foo: while (...) { ... break foo; ... continue foo;}`\n            case 'LabeledStatement':\n            case 'BreakStatement':\n            case 'ContinueStatement': return false;\n            default: return true;\n        }\n    }\n    return false;\n}\n\nvar version$3 = \"24.0.1\";\nvar peerDependencies = {\n\trollup: \"^2.68.0||^3.0.0\"\n};\n\nfunction tryParse(parse, code, id) {\n  try {\n    return parse(code, { allowReturnOutsideFunction: true });\n  } catch (err) {\n    err.message += ` in ${id}`;\n    throw err;\n  }\n}\n\nconst firstpassGlobal = /\\b(?:require|module|exports|global)\\b/;\n\nconst firstpassNoGlobal = /\\b(?:require|module|exports)\\b/;\n\nfunction hasCjsKeywords(code, ignoreGlobal) {\n  const firstpass = ignoreGlobal ? firstpassNoGlobal : firstpassGlobal;\n  return firstpass.test(code);\n}\n\n/* eslint-disable no-underscore-dangle */\n\nfunction analyzeTopLevelStatements(parse, code, id) {\n  const ast = tryParse(parse, code, id);\n\n  let isEsModule = false;\n  let hasDefaultExport = false;\n  let hasNamedExports = false;\n\n  for (const node of ast.body) {\n    switch (node.type) {\n      case 'ExportDefaultDeclaration':\n        isEsModule = true;\n        hasDefaultExport = true;\n        break;\n      case 'ExportNamedDeclaration':\n        isEsModule = true;\n        if (node.declaration) {\n          hasNamedExports = true;\n        } else {\n          for (const specifier of node.specifiers) {\n            if (specifier.exported.name === 'default') {\n              hasDefaultExport = true;\n            } else {\n              hasNamedExports = true;\n            }\n          }\n        }\n        break;\n      case 'ExportAllDeclaration':\n        isEsModule = true;\n        if (node.exported && node.exported.name === 'default') {\n          hasDefaultExport = true;\n        } else {\n          hasNamedExports = true;\n        }\n        break;\n      case 'ImportDeclaration':\n        isEsModule = true;\n        break;\n    }\n  }\n\n  return { isEsModule, hasDefaultExport, hasNamedExports, ast };\n}\n\n/* eslint-disable import/prefer-default-export */\n\nfunction deconflict(scopes, globals, identifier) {\n  let i = 1;\n  let deconflicted = makeLegalIdentifier(identifier);\n  const hasConflicts = () =>\n    scopes.some((scope) => scope.contains(deconflicted)) || globals.has(deconflicted);\n\n  while (hasConflicts()) {\n    deconflicted = makeLegalIdentifier(`${identifier}_${i}`);\n    i += 1;\n  }\n\n  for (const scope of scopes) {\n    scope.declarations[deconflicted] = true;\n  }\n\n  return deconflicted;\n}\n\nfunction getName(id) {\n  const name = makeLegalIdentifier(basename$1(id, extname(id)));\n  if (name !== 'index') {\n    return name;\n  }\n  return makeLegalIdentifier(basename$1(dirname$1(id)));\n}\n\nfunction normalizePathSlashes(path) {\n  return path.replace(/\\\\/g, '/');\n}\n\nconst getVirtualPathForDynamicRequirePath = (path, commonDir) =>\n  `/${normalizePathSlashes(relative$1(commonDir, path))}`;\n\nfunction capitalize(name) {\n  return name[0].toUpperCase() + name.slice(1);\n}\n\nfunction getStrictRequiresFilter({ strictRequires }) {\n  switch (strictRequires) {\n    case true:\n      return { strictRequiresFilter: () => true, detectCyclesAndConditional: false };\n    // eslint-disable-next-line no-undefined\n    case undefined:\n    case 'auto':\n    case 'debug':\n    case null:\n      return { strictRequiresFilter: () => false, detectCyclesAndConditional: true };\n    case false:\n      return { strictRequiresFilter: () => false, detectCyclesAndConditional: false };\n    default:\n      if (typeof strictRequires === 'string' || Array.isArray(strictRequires)) {\n        return {\n          strictRequiresFilter: createFilter$1(strictRequires),\n          detectCyclesAndConditional: false\n        };\n      }\n      throw new Error('Unexpected value for \"strictRequires\" option.');\n  }\n}\n\nfunction getPackageEntryPoint(dirPath) {\n  let entryPoint = 'index.js';\n\n  try {\n    if (existsSync(join$1(dirPath, 'package.json'))) {\n      entryPoint =\n        JSON.parse(readFileSync(join$1(dirPath, 'package.json'), { encoding: 'utf8' })).main ||\n        entryPoint;\n    }\n  } catch (ignored) {\n    // ignored\n  }\n\n  return entryPoint;\n}\n\nfunction isDirectory(path) {\n  try {\n    if (statSync$1(path).isDirectory()) return true;\n  } catch (ignored) {\n    // Nothing to do here\n  }\n  return false;\n}\n\nfunction getDynamicRequireModules(patterns, dynamicRequireRoot) {\n  const dynamicRequireModules = new Map();\n  const dirNames = new Set();\n  for (const pattern of !patterns || Array.isArray(patterns) ? patterns || [] : [patterns]) {\n    const isNegated = pattern.startsWith('!');\n    const modifyMap = (targetPath, resolvedPath) =>\n      isNegated\n        ? dynamicRequireModules.delete(targetPath)\n        : dynamicRequireModules.set(targetPath, resolvedPath);\n    for (const path of glob.sync(isNegated ? pattern.substr(1) : pattern)) {\n      const resolvedPath = resolve$3(path);\n      const requirePath = normalizePathSlashes(resolvedPath);\n      if (isDirectory(resolvedPath)) {\n        dirNames.add(resolvedPath);\n        const modulePath = resolve$3(join$1(resolvedPath, getPackageEntryPoint(path)));\n        modifyMap(requirePath, modulePath);\n        modifyMap(normalizePathSlashes(modulePath), modulePath);\n      } else {\n        dirNames.add(dirname$1(resolvedPath));\n        modifyMap(requirePath, resolvedPath);\n      }\n    }\n  }\n  return {\n    commonDir: dirNames.size ? commondir([...dirNames, dynamicRequireRoot]) : null,\n    dynamicRequireModules\n  };\n}\n\nconst FAILED_REQUIRE_ERROR = `throw new Error('Could not dynamically require \"' + path + '\". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');`;\n\nconst COMMONJS_REQUIRE_EXPORT = 'commonjsRequire';\nconst CREATE_COMMONJS_REQUIRE_EXPORT = 'createCommonjsRequire';\n\nfunction getDynamicModuleRegistry(\n  isDynamicRequireModulesEnabled,\n  dynamicRequireModules,\n  commonDir,\n  ignoreDynamicRequires\n) {\n  if (!isDynamicRequireModulesEnabled) {\n    return `export function ${COMMONJS_REQUIRE_EXPORT}(path) {\n\t${FAILED_REQUIRE_ERROR}\n}`;\n  }\n  const dynamicModuleImports = [...dynamicRequireModules.values()]\n    .map(\n      (id, index) =>\n        `import ${\n          id.endsWith('.json') ? `json${index}` : `{ __require as require${index} }`\n        } from ${JSON.stringify(id)};`\n    )\n    .join('\\n');\n  const dynamicModuleProps = [...dynamicRequireModules.keys()]\n    .map(\n      (id, index) =>\n        `\\t\\t${JSON.stringify(getVirtualPathForDynamicRequirePath(id, commonDir))}: ${\n          id.endsWith('.json') ? `function () { return json${index}; }` : `require${index}`\n        }`\n    )\n    .join(',\\n');\n  return `${dynamicModuleImports}\n\nvar dynamicModules;\n\nfunction getDynamicModules() {\n\treturn dynamicModules || (dynamicModules = {\n${dynamicModuleProps}\n\t});\n}\n\nexport function ${CREATE_COMMONJS_REQUIRE_EXPORT}(originalModuleDir) {\n\tfunction handleRequire(path) {\n\t\tvar resolvedPath = commonjsResolve(path, originalModuleDir);\n\t\tif (resolvedPath !== null) {\n\t\t\treturn getDynamicModules()[resolvedPath]();\n\t\t}\n\t\t${ignoreDynamicRequires ? 'return require(path);' : FAILED_REQUIRE_ERROR}\n\t}\n\thandleRequire.resolve = function (path) {\n\t\tvar resolvedPath = commonjsResolve(path, originalModuleDir);\n\t\tif (resolvedPath !== null) {\n\t\t\treturn resolvedPath;\n\t\t}\n\t\treturn require.resolve(path);\n\t}\n\treturn handleRequire;\n}\n\nfunction commonjsResolve (path, originalModuleDir) {\n\tvar shouldTryNodeModules = isPossibleNodeModulesPath(path);\n\tpath = normalize(path);\n\tvar relPath;\n\tif (path[0] === '/') {\n\t\toriginalModuleDir = '';\n\t}\n\tvar modules = getDynamicModules();\n\tvar checkedExtensions = ['', '.js', '.json'];\n\twhile (true) {\n\t\tif (!shouldTryNodeModules) {\n\t\t\trelPath = normalize(originalModuleDir + '/' + path);\n\t\t} else {\n\t\t\trelPath = normalize(originalModuleDir + '/node_modules/' + path);\n\t\t}\n\n\t\tif (relPath.endsWith('/..')) {\n\t\t\tbreak; // Travelled too far up, avoid infinite loop\n\t\t}\n\n\t\tfor (var extensionIndex = 0; extensionIndex < checkedExtensions.length; extensionIndex++) {\n\t\t\tvar resolvedPath = relPath + checkedExtensions[extensionIndex];\n\t\t\tif (modules[resolvedPath]) {\n\t\t\t\treturn resolvedPath;\n\t\t\t}\n\t\t}\n\t\tif (!shouldTryNodeModules) break;\n\t\tvar nextDir = normalize(originalModuleDir + '/..');\n\t\tif (nextDir === originalModuleDir) break;\n\t\toriginalModuleDir = nextDir;\n\t}\n\treturn null;\n}\n\nfunction isPossibleNodeModulesPath (modulePath) {\n\tvar c0 = modulePath[0];\n\tif (c0 === '/' || c0 === '\\\\\\\\') return false;\n\tvar c1 = modulePath[1], c2 = modulePath[2];\n\tif ((c0 === '.' && (!c1 || c1 === '/' || c1 === '\\\\\\\\')) ||\n\t\t(c0 === '.' && c1 === '.' && (!c2 || c2 === '/' || c2 === '\\\\\\\\'))) return false;\n\tif (c1 === ':' && (c2 === '/' || c2 === '\\\\\\\\')) return false;\n\treturn true;\n}\n\nfunction normalize (path) {\n\tpath = path.replace(/\\\\\\\\/g, '/');\n\tvar parts = path.split('/');\n\tvar slashed = parts[0] === '';\n\tfor (var i = 1; i < parts.length; i++) {\n\t\tif (parts[i] === '.' || parts[i] === '') {\n\t\t\tparts.splice(i--, 1);\n\t\t}\n\t}\n\tfor (var i = 1; i < parts.length; i++) {\n\t\tif (parts[i] !== '..') continue;\n\t\tif (i > 0 && parts[i - 1] !== '..' && parts[i - 1] !== '.') {\n\t\t\tparts.splice(--i, 2);\n\t\t\ti--;\n\t\t}\n\t}\n\tpath = parts.join('/');\n\tif (slashed && path[0] !== '/') path = '/' + path;\n\telse if (path.length === 0) path = '.';\n\treturn path;\n}`;\n}\n\nconst isWrappedId = (id, suffix) => id.endsWith(suffix);\nconst wrapId$1 = (id, suffix) => `\\0${id}${suffix}`;\nconst unwrapId$1 = (wrappedId, suffix) => wrappedId.slice(1, -suffix.length);\n\nconst PROXY_SUFFIX = '?commonjs-proxy';\nconst WRAPPED_SUFFIX = '?commonjs-wrapped';\nconst EXTERNAL_SUFFIX = '?commonjs-external';\nconst EXPORTS_SUFFIX = '?commonjs-exports';\nconst MODULE_SUFFIX = '?commonjs-module';\nconst ENTRY_SUFFIX = '?commonjs-entry';\nconst ES_IMPORT_SUFFIX = '?commonjs-es-import';\n\nconst DYNAMIC_MODULES_ID = '\\0commonjs-dynamic-modules';\nconst HELPERS_ID = '\\0commonjsHelpers.js';\n\nconst IS_WRAPPED_COMMONJS = 'withRequireFunction';\n\n// `x['default']` is used instead of `x.default` for backward compatibility with ES3 browsers.\n// Minifiers like uglify will usually transpile it back if compatibility with ES3 is not enabled.\n// This could be improved by inspecting Rollup's \"generatedCode\" option\n\nconst HELPERS = `\nexport var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};\n\nexport function getDefaultExportFromCjs (x) {\n\treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n}\n\nexport function getDefaultExportFromNamespaceIfPresent (n) {\n\treturn n && Object.prototype.hasOwnProperty.call(n, 'default') ? n['default'] : n;\n}\n\nexport function getDefaultExportFromNamespaceIfNotNamed (n) {\n\treturn n && Object.prototype.hasOwnProperty.call(n, 'default') && Object.keys(n).length === 1 ? n['default'] : n;\n}\n\nexport function getAugmentedNamespace(n) {\n  if (n.__esModule) return n;\n  var f = n.default;\n\tif (typeof f == \"function\") {\n\t\tvar a = function a () {\n\t\t\tif (this instanceof a) {\n\t\t\t\tvar args = [null];\n\t\t\t\targs.push.apply(args, arguments);\n\t\t\t\tvar Ctor = Function.bind.apply(f, args);\n\t\t\t\treturn new Ctor();\n\t\t\t}\n\t\t\treturn f.apply(this, arguments);\n\t\t};\n\t\ta.prototype = f.prototype;\n  } else a = {};\n  Object.defineProperty(a, '__esModule', {value: true});\n\tObject.keys(n).forEach(function (k) {\n\t\tvar d = Object.getOwnPropertyDescriptor(n, k);\n\t\tObject.defineProperty(a, k, d.get ? d : {\n\t\t\tenumerable: true,\n\t\t\tget: function () {\n\t\t\t\treturn n[k];\n\t\t\t}\n\t\t});\n\t});\n\treturn a;\n}\n`;\n\nfunction getHelpersModule() {\n  return HELPERS;\n}\n\nfunction getUnknownRequireProxy(id, requireReturnsDefault) {\n  if (requireReturnsDefault === true || id.endsWith('.json')) {\n    return `export { default } from ${JSON.stringify(id)};`;\n  }\n  const name = getName(id);\n  const exported =\n    requireReturnsDefault === 'auto'\n      ? `import { getDefaultExportFromNamespaceIfNotNamed } from \"${HELPERS_ID}\"; export default /*@__PURE__*/getDefaultExportFromNamespaceIfNotNamed(${name});`\n      : requireReturnsDefault === 'preferred'\n      ? `import { getDefaultExportFromNamespaceIfPresent } from \"${HELPERS_ID}\"; export default /*@__PURE__*/getDefaultExportFromNamespaceIfPresent(${name});`\n      : !requireReturnsDefault\n      ? `import { getAugmentedNamespace } from \"${HELPERS_ID}\"; export default /*@__PURE__*/getAugmentedNamespace(${name});`\n      : `export default ${name};`;\n  return `import * as ${name} from ${JSON.stringify(id)}; ${exported}`;\n}\n\nasync function getStaticRequireProxy(id, requireReturnsDefault, loadModule) {\n  const name = getName(id);\n  const {\n    meta: { commonjs: commonjsMeta }\n  } = await loadModule({ id });\n  if (!commonjsMeta) {\n    return getUnknownRequireProxy(id, requireReturnsDefault);\n  } else if (commonjsMeta.isCommonJS) {\n    return `export { __moduleExports as default } from ${JSON.stringify(id)};`;\n  } else if (!requireReturnsDefault) {\n    return `import { getAugmentedNamespace } from \"${HELPERS_ID}\"; import * as ${name} from ${JSON.stringify(\n      id\n    )}; export default /*@__PURE__*/getAugmentedNamespace(${name});`;\n  } else if (\n    requireReturnsDefault !== true &&\n    (requireReturnsDefault === 'namespace' ||\n      !commonjsMeta.hasDefaultExport ||\n      (requireReturnsDefault === 'auto' && commonjsMeta.hasNamedExports))\n  ) {\n    return `import * as ${name} from ${JSON.stringify(id)}; export default ${name};`;\n  }\n  return `export { default } from ${JSON.stringify(id)};`;\n}\n\nfunction getEntryProxy(id, defaultIsModuleExports, getModuleInfo) {\n  const {\n    meta: { commonjs: commonjsMeta },\n    hasDefaultExport\n  } = getModuleInfo(id);\n  if (!commonjsMeta || commonjsMeta.isCommonJS !== IS_WRAPPED_COMMONJS) {\n    const stringifiedId = JSON.stringify(id);\n    let code = `export * from ${stringifiedId};`;\n    if (hasDefaultExport) {\n      code += `export { default } from ${stringifiedId};`;\n    }\n    return code;\n  }\n  return getEsImportProxy(id, defaultIsModuleExports);\n}\n\nfunction getEsImportProxy(id, defaultIsModuleExports) {\n  const name = getName(id);\n  const exportsName = `${name}Exports`;\n  const requireModule = `require${capitalize(name)}`;\n  let code =\n    `import { getDefaultExportFromCjs } from \"${HELPERS_ID}\";\\n` +\n    `import { __require as ${requireModule} } from ${JSON.stringify(id)};\\n` +\n    `var ${exportsName} = ${requireModule}();\\n` +\n    `export { ${exportsName} as __moduleExports };`;\n  if (defaultIsModuleExports === true) {\n    code += `\\nexport { ${exportsName} as default };`;\n  } else {\n    code += `export default /*@__PURE__*/getDefaultExportFromCjs(${exportsName});`;\n  }\n  return {\n    code,\n    syntheticNamedExports: '__moduleExports'\n  };\n}\n\n/* eslint-disable no-param-reassign, no-undefined */\n\nfunction getCandidatesForExtension(resolved, extension) {\n  return [resolved + extension, `${resolved}${sep}index${extension}`];\n}\n\nfunction getCandidates(resolved, extensions) {\n  return extensions.reduce(\n    (paths, extension) => paths.concat(getCandidatesForExtension(resolved, extension)),\n    [resolved]\n  );\n}\n\nfunction resolveExtensions(importee, importer, extensions) {\n  // not our problem\n  if (importee[0] !== '.' || !importer) return undefined;\n\n  const resolved = resolve$3(dirname$1(importer), importee);\n  const candidates = getCandidates(resolved, extensions);\n\n  for (let i = 0; i < candidates.length; i += 1) {\n    try {\n      const stats = statSync$1(candidates[i]);\n      if (stats.isFile()) return { id: candidates[i] };\n    } catch (err) {\n      /* noop */\n    }\n  }\n\n  return undefined;\n}\n\nfunction getResolveId(extensions, isPossibleCjsId) {\n  const currentlyResolving = new Map();\n\n  return {\n    /**\n     * This is a Maps of importers to Sets of require sources being resolved at\n     * the moment by resolveRequireSourcesAndUpdateMeta\n     */\n    currentlyResolving,\n    async resolveId(importee, importer, resolveOptions) {\n      const customOptions = resolveOptions.custom;\n      // All logic below is specific to ES imports.\n      // Also, if we do not skip this logic for requires that are resolved while\n      // transforming a commonjs file, it can easily lead to deadlocks.\n      if (\n        customOptions &&\n        customOptions['node-resolve'] &&\n        customOptions['node-resolve'].isRequire\n      ) {\n        return null;\n      }\n      const currentlyResolvingForParent = currentlyResolving.get(importer);\n      if (currentlyResolvingForParent && currentlyResolvingForParent.has(importee)) {\n        this.warn({\n          code: 'THIS_RESOLVE_WITHOUT_OPTIONS',\n          message:\n            'It appears a plugin has implemented a \"resolveId\" hook that uses \"this.resolve\" without forwarding the third \"options\" parameter of \"resolveId\". This is problematic as it can lead to wrong module resolutions especially for the node-resolve plugin and in certain cases cause early exit errors for the commonjs plugin.\\nIn rare cases, this warning can appear if the same file is both imported and required from the same mixed ES/CommonJS module, in which case it can be ignored.',\n          url: 'https://rollupjs.org/guide/en/#resolveid'\n        });\n        return null;\n      }\n\n      if (isWrappedId(importee, WRAPPED_SUFFIX)) {\n        return unwrapId$1(importee, WRAPPED_SUFFIX);\n      }\n\n      if (\n        importee.endsWith(ENTRY_SUFFIX) ||\n        isWrappedId(importee, MODULE_SUFFIX) ||\n        isWrappedId(importee, EXPORTS_SUFFIX) ||\n        isWrappedId(importee, PROXY_SUFFIX) ||\n        isWrappedId(importee, ES_IMPORT_SUFFIX) ||\n        isWrappedId(importee, EXTERNAL_SUFFIX) ||\n        importee.startsWith(HELPERS_ID) ||\n        importee === DYNAMIC_MODULES_ID\n      ) {\n        return importee;\n      }\n\n      if (importer) {\n        if (\n          importer === DYNAMIC_MODULES_ID ||\n          // Proxies are only importing resolved ids, no need to resolve again\n          isWrappedId(importer, PROXY_SUFFIX) ||\n          isWrappedId(importer, ES_IMPORT_SUFFIX) ||\n          importer.endsWith(ENTRY_SUFFIX)\n        ) {\n          return importee;\n        }\n        if (isWrappedId(importer, EXTERNAL_SUFFIX)) {\n          // We need to return null for unresolved imports so that the proper warning is shown\n          if (\n            !(await this.resolve(\n              importee,\n              importer,\n              Object.assign({ skipSelf: true }, resolveOptions)\n            ))\n          ) {\n            return null;\n          }\n          // For other external imports, we need to make sure they are handled as external\n          return { id: importee, external: true };\n        }\n      }\n\n      if (importee.startsWith('\\0')) {\n        return null;\n      }\n\n      // If this is an entry point or ESM import, we need to figure out if the importee is wrapped and\n      // if that is the case, we need to add a proxy.\n      const resolved =\n        (await this.resolve(\n          importee,\n          importer,\n          Object.assign({ skipSelf: true }, resolveOptions)\n        )) || resolveExtensions(importee, importer, extensions);\n      // Make sure that even if other plugins resolve again, we ignore our own proxies\n      if (\n        !resolved ||\n        resolved.external ||\n        resolved.id.endsWith(ENTRY_SUFFIX) ||\n        isWrappedId(resolved.id, ES_IMPORT_SUFFIX) ||\n        !isPossibleCjsId(resolved.id)\n      ) {\n        return resolved;\n      }\n      const moduleInfo = await this.load(resolved);\n      const {\n        meta: { commonjs: commonjsMeta }\n      } = moduleInfo;\n      if (commonjsMeta) {\n        const { isCommonJS } = commonjsMeta;\n        if (isCommonJS) {\n          if (resolveOptions.isEntry) {\n            moduleInfo.moduleSideEffects = true;\n            // We must not precede entry proxies with a `\\0` as that will mess up relative external resolution\n            return resolved.id + ENTRY_SUFFIX;\n          }\n          if (isCommonJS === IS_WRAPPED_COMMONJS) {\n            return { id: wrapId$1(resolved.id, ES_IMPORT_SUFFIX), meta: { commonjs: { resolved } } };\n          }\n        }\n      }\n      return resolved;\n    }\n  };\n}\n\nfunction getRequireResolver(extensions, detectCyclesAndConditional, currentlyResolving) {\n  const knownCjsModuleTypes = Object.create(null);\n  const requiredIds = Object.create(null);\n  const unconditionallyRequiredIds = Object.create(null);\n  const dependencies = Object.create(null);\n  const getDependencies = (id) => dependencies[id] || (dependencies[id] = new Set());\n\n  const isCyclic = (id) => {\n    const dependenciesToCheck = new Set(getDependencies(id));\n    for (const dependency of dependenciesToCheck) {\n      if (dependency === id) {\n        return true;\n      }\n      for (const childDependency of getDependencies(dependency)) {\n        dependenciesToCheck.add(childDependency);\n      }\n    }\n    return false;\n  };\n\n  // Once a module is listed here, its type (wrapped or not) is fixed and may\n  // not change for the rest of the current build, to not break already\n  // transformed modules.\n  const fullyAnalyzedModules = Object.create(null);\n\n  const getTypeForFullyAnalyzedModule = (id) => {\n    const knownType = knownCjsModuleTypes[id];\n    if (knownType !== true || !detectCyclesAndConditional || fullyAnalyzedModules[id]) {\n      return knownType;\n    }\n    if (isCyclic(id)) {\n      return (knownCjsModuleTypes[id] = IS_WRAPPED_COMMONJS);\n    }\n    return knownType;\n  };\n\n  const setInitialParentType = (id, initialCommonJSType) => {\n    // Fully analyzed modules may never change type\n    if (fullyAnalyzedModules[id]) {\n      return;\n    }\n    knownCjsModuleTypes[id] = initialCommonJSType;\n    if (\n      detectCyclesAndConditional &&\n      knownCjsModuleTypes[id] === true &&\n      requiredIds[id] &&\n      !unconditionallyRequiredIds[id]\n    ) {\n      knownCjsModuleTypes[id] = IS_WRAPPED_COMMONJS;\n    }\n  };\n\n  const analyzeRequiredModule = async (parentId, resolved, isConditional, loadModule) => {\n    const childId = resolved.id;\n    requiredIds[childId] = true;\n    if (!(isConditional || knownCjsModuleTypes[parentId] === IS_WRAPPED_COMMONJS)) {\n      unconditionallyRequiredIds[childId] = true;\n    }\n\n    getDependencies(parentId).add(childId);\n    if (!isCyclic(childId)) {\n      // This makes sure the current transform handler waits for all direct\n      // dependencies to be loaded and transformed and therefore for all\n      // transitive CommonJS dependencies to be loaded as well so that all\n      // cycles have been found and knownCjsModuleTypes is reliable.\n      await loadModule(resolved);\n    }\n  };\n\n  const getTypeForImportedModule = async (resolved, loadModule) => {\n    if (resolved.id in knownCjsModuleTypes) {\n      // This handles cyclic ES dependencies\n      return knownCjsModuleTypes[resolved.id];\n    }\n    const {\n      meta: { commonjs }\n    } = await loadModule(resolved);\n    return (commonjs && commonjs.isCommonJS) || false;\n  };\n\n  return {\n    getWrappedIds: () =>\n      Object.keys(knownCjsModuleTypes).filter(\n        (id) => knownCjsModuleTypes[id] === IS_WRAPPED_COMMONJS\n      ),\n    isRequiredId: (id) => requiredIds[id],\n    async shouldTransformCachedModule({\n      id: parentId,\n      resolvedSources,\n      meta: { commonjs: parentMeta }\n    }) {\n      // We explicitly track ES modules to handle circular imports\n      if (!(parentMeta && parentMeta.isCommonJS)) knownCjsModuleTypes[parentId] = false;\n      if (isWrappedId(parentId, ES_IMPORT_SUFFIX)) return false;\n      const parentRequires = parentMeta && parentMeta.requires;\n      if (parentRequires) {\n        setInitialParentType(parentId, parentMeta.initialCommonJSType);\n        await Promise.all(\n          parentRequires.map(({ resolved, isConditional }) =>\n            analyzeRequiredModule(parentId, resolved, isConditional, this.load)\n          )\n        );\n        if (getTypeForFullyAnalyzedModule(parentId) !== parentMeta.isCommonJS) {\n          return true;\n        }\n        for (const {\n          resolved: { id }\n        } of parentRequires) {\n          if (getTypeForFullyAnalyzedModule(id) !== parentMeta.isRequiredCommonJS[id]) {\n            return true;\n          }\n        }\n        // Now that we decided to go with the cached copy, neither the parent\n        // module nor any of its children may change types anymore\n        fullyAnalyzedModules[parentId] = true;\n        for (const {\n          resolved: { id }\n        } of parentRequires) {\n          fullyAnalyzedModules[id] = true;\n        }\n      }\n      const parentRequireSet = new Set((parentRequires || []).map(({ resolved: { id } }) => id));\n      return (\n        await Promise.all(\n          Object.keys(resolvedSources)\n            .map((source) => resolvedSources[source])\n            .filter(({ id, external }) => !(external || parentRequireSet.has(id)))\n            .map(async (resolved) => {\n              if (isWrappedId(resolved.id, ES_IMPORT_SUFFIX)) {\n                return (\n                  (await getTypeForImportedModule(\n                    (\n                      await this.load({ id: resolved.id })\n                    ).meta.commonjs.resolved,\n                    this.load\n                  )) !== IS_WRAPPED_COMMONJS\n                );\n              }\n              return (await getTypeForImportedModule(resolved, this.load)) === IS_WRAPPED_COMMONJS;\n            })\n        )\n      ).some((shouldTransform) => shouldTransform);\n    },\n    /* eslint-disable no-param-reassign */\n    resolveRequireSourcesAndUpdateMeta:\n      (rollupContext) => async (parentId, isParentCommonJS, parentMeta, sources) => {\n        parentMeta.initialCommonJSType = isParentCommonJS;\n        parentMeta.requires = [];\n        parentMeta.isRequiredCommonJS = Object.create(null);\n        setInitialParentType(parentId, isParentCommonJS);\n        const currentlyResolvingForParent = currentlyResolving.get(parentId) || new Set();\n        currentlyResolving.set(parentId, currentlyResolvingForParent);\n        const requireTargets = await Promise.all(\n          sources.map(async ({ source, isConditional }) => {\n            // Never analyze or proxy internal modules\n            if (source.startsWith('\\0')) {\n              return { id: source, allowProxy: false };\n            }\n            currentlyResolvingForParent.add(source);\n            const resolved =\n              (await rollupContext.resolve(source, parentId, {\n                custom: { 'node-resolve': { isRequire: true } }\n              })) || resolveExtensions(source, parentId, extensions);\n            currentlyResolvingForParent.delete(source);\n            if (!resolved) {\n              return { id: wrapId$1(source, EXTERNAL_SUFFIX), allowProxy: false };\n            }\n            const childId = resolved.id;\n            if (resolved.external) {\n              return { id: wrapId$1(childId, EXTERNAL_SUFFIX), allowProxy: false };\n            }\n            parentMeta.requires.push({ resolved, isConditional });\n            await analyzeRequiredModule(parentId, resolved, isConditional, rollupContext.load);\n            return { id: childId, allowProxy: true };\n          })\n        );\n        parentMeta.isCommonJS = getTypeForFullyAnalyzedModule(parentId);\n        fullyAnalyzedModules[parentId] = true;\n        return requireTargets.map(({ id: dependencyId, allowProxy }, index) => {\n          // eslint-disable-next-line no-multi-assign\n          const isCommonJS = (parentMeta.isRequiredCommonJS[dependencyId] =\n            getTypeForFullyAnalyzedModule(dependencyId));\n          fullyAnalyzedModules[dependencyId] = true;\n          return {\n            source: sources[index].source,\n            id: allowProxy\n              ? isCommonJS === IS_WRAPPED_COMMONJS\n                ? wrapId$1(dependencyId, WRAPPED_SUFFIX)\n                : wrapId$1(dependencyId, PROXY_SUFFIX)\n              : dependencyId,\n            isCommonJS\n          };\n        });\n      },\n    isCurrentlyResolving(source, parentId) {\n      const currentlyResolvingForParent = currentlyResolving.get(parentId);\n      return currentlyResolvingForParent && currentlyResolvingForParent.has(source);\n    }\n  };\n}\n\nfunction validateVersion(actualVersion, peerDependencyVersion, name) {\n  const versionRegexp = /\\^(\\d+\\.\\d+\\.\\d+)/g;\n  let minMajor = Infinity;\n  let minMinor = Infinity;\n  let minPatch = Infinity;\n  let foundVersion;\n  // eslint-disable-next-line no-cond-assign\n  while ((foundVersion = versionRegexp.exec(peerDependencyVersion))) {\n    const [foundMajor, foundMinor, foundPatch] = foundVersion[1].split('.').map(Number);\n    if (foundMajor < minMajor) {\n      minMajor = foundMajor;\n      minMinor = foundMinor;\n      minPatch = foundPatch;\n    }\n  }\n  if (!actualVersion) {\n    throw new Error(\n      `Insufficient ${name} version: \"@rollup/plugin-commonjs\" requires at least ${name}@${minMajor}.${minMinor}.${minPatch}.`\n    );\n  }\n  const [major, minor, patch] = actualVersion.split('.').map(Number);\n  if (\n    major < minMajor ||\n    (major === minMajor && (minor < minMinor || (minor === minMinor && patch < minPatch)))\n  ) {\n    throw new Error(\n      `Insufficient ${name} version: \"@rollup/plugin-commonjs\" requires at least ${name}@${minMajor}.${minMinor}.${minPatch} but found ${name}@${actualVersion}.`\n    );\n  }\n}\n\nconst operators = {\n  '==': (x) => equals(x.left, x.right, false),\n\n  '!=': (x) => not(operators['=='](x)),\n\n  '===': (x) => equals(x.left, x.right, true),\n\n  '!==': (x) => not(operators['==='](x)),\n\n  '!': (x) => isFalsy(x.argument),\n\n  '&&': (x) => isTruthy(x.left) && isTruthy(x.right),\n\n  '||': (x) => isTruthy(x.left) || isTruthy(x.right)\n};\n\nfunction not(value) {\n  return value === null ? value : !value;\n}\n\nfunction equals(a, b, strict) {\n  if (a.type !== b.type) return null;\n  // eslint-disable-next-line eqeqeq\n  if (a.type === 'Literal') return strict ? a.value === b.value : a.value == b.value;\n  return null;\n}\n\nfunction isTruthy(node) {\n  if (!node) return false;\n  if (node.type === 'Literal') return !!node.value;\n  if (node.type === 'ParenthesizedExpression') return isTruthy(node.expression);\n  if (node.operator in operators) return operators[node.operator](node);\n  return null;\n}\n\nfunction isFalsy(node) {\n  return not(isTruthy(node));\n}\n\nfunction getKeypath(node) {\n  const parts = [];\n\n  while (node.type === 'MemberExpression') {\n    if (node.computed) return null;\n\n    parts.unshift(node.property.name);\n    // eslint-disable-next-line no-param-reassign\n    node = node.object;\n  }\n\n  if (node.type !== 'Identifier') return null;\n\n  const { name } = node;\n  parts.unshift(name);\n\n  return { name, keypath: parts.join('.') };\n}\n\nconst KEY_COMPILED_ESM = '__esModule';\n\nfunction isDefineCompiledEsm(node) {\n  const definedProperty =\n    getDefinePropertyCallName(node, 'exports') || getDefinePropertyCallName(node, 'module.exports');\n  if (definedProperty && definedProperty.key === KEY_COMPILED_ESM) {\n    return isTruthy(definedProperty.value);\n  }\n  return false;\n}\n\nfunction getDefinePropertyCallName(node, targetName) {\n  const {\n    callee: { object, property }\n  } = node;\n  if (!object || object.type !== 'Identifier' || object.name !== 'Object') return;\n  if (!property || property.type !== 'Identifier' || property.name !== 'defineProperty') return;\n  if (node.arguments.length !== 3) return;\n\n  const targetNames = targetName.split('.');\n  const [target, key, value] = node.arguments;\n  if (targetNames.length === 1) {\n    if (target.type !== 'Identifier' || target.name !== targetNames[0]) {\n      return;\n    }\n  }\n\n  if (targetNames.length === 2) {\n    if (\n      target.type !== 'MemberExpression' ||\n      target.object.name !== targetNames[0] ||\n      target.property.name !== targetNames[1]\n    ) {\n      return;\n    }\n  }\n\n  if (value.type !== 'ObjectExpression' || !value.properties) return;\n\n  const valueProperty = value.properties.find((p) => p.key && p.key.name === 'value');\n  if (!valueProperty || !valueProperty.value) return;\n\n  // eslint-disable-next-line consistent-return\n  return { key: key.value, value: valueProperty.value };\n}\n\nfunction isShorthandProperty(parent) {\n  return parent && parent.type === 'Property' && parent.shorthand;\n}\n\nfunction hasDefineEsmProperty(node) {\n  return node.properties.some((property) => {\n    if (\n      property.type === 'Property' &&\n      property.key.type === 'Identifier' &&\n      property.key.name === '__esModule' &&\n      isTruthy(property.value)\n    ) {\n      return true;\n    }\n    return false;\n  });\n}\n\nfunction wrapCode(magicString, uses, moduleName, exportsName, indentExclusionRanges) {\n  const args = [];\n  const passedArgs = [];\n  if (uses.module) {\n    args.push('module');\n    passedArgs.push(moduleName);\n  }\n  if (uses.exports) {\n    args.push('exports');\n    passedArgs.push(exportsName);\n  }\n  magicString\n    .trim()\n    .indent('\\t', { exclude: indentExclusionRanges })\n    .prepend(`(function (${args.join(', ')}) {\\n`)\n    .append(`\\n} (${passedArgs.join(', ')}));`);\n}\n\nfunction rewriteExportsAndGetExportsBlock(\n  magicString,\n  moduleName,\n  exportsName,\n  wrapped,\n  moduleExportsAssignments,\n  firstTopLevelModuleExportsAssignment,\n  exportsAssignmentsByName,\n  topLevelAssignments,\n  defineCompiledEsmExpressions,\n  deconflictedExportNames,\n  code,\n  HELPERS_NAME,\n  exportMode,\n  detectWrappedDefault,\n  defaultIsModuleExports,\n  usesRequireWrapper,\n  requireName\n) {\n  const exports = [];\n  const exportDeclarations = [];\n\n  if (usesRequireWrapper) {\n    getExportsWhenUsingRequireWrapper(\n      magicString,\n      wrapped,\n      exportMode,\n      exports,\n      moduleExportsAssignments,\n      exportsAssignmentsByName,\n      moduleName,\n      exportsName,\n      requireName,\n      defineCompiledEsmExpressions\n    );\n  } else if (exportMode === 'replace') {\n    getExportsForReplacedModuleExports(\n      magicString,\n      exports,\n      exportDeclarations,\n      moduleExportsAssignments,\n      firstTopLevelModuleExportsAssignment,\n      exportsName\n    );\n  } else {\n    exports.push(`${exportsName} as __moduleExports`);\n    if (wrapped) {\n      getExportsWhenWrapping(\n        exportDeclarations,\n        exportsName,\n        detectWrappedDefault,\n        HELPERS_NAME,\n        defaultIsModuleExports\n      );\n    } else {\n      getExports(\n        magicString,\n        exports,\n        exportDeclarations,\n        moduleExportsAssignments,\n        exportsAssignmentsByName,\n        deconflictedExportNames,\n        topLevelAssignments,\n        moduleName,\n        exportsName,\n        defineCompiledEsmExpressions,\n        HELPERS_NAME,\n        defaultIsModuleExports\n      );\n    }\n  }\n  if (exports.length) {\n    exportDeclarations.push(`export { ${exports.join(', ')} };`);\n  }\n\n  return `\\n\\n${exportDeclarations.join('\\n')}`;\n}\n\nfunction getExportsWhenUsingRequireWrapper(\n  magicString,\n  wrapped,\n  exportMode,\n  exports,\n  moduleExportsAssignments,\n  exportsAssignmentsByName,\n  moduleName,\n  exportsName,\n  requireName,\n  defineCompiledEsmExpressions\n) {\n  if (!wrapped) {\n    if (exportMode === 'replace') {\n      for (const { left } of moduleExportsAssignments) {\n        magicString.overwrite(left.start, left.end, exportsName);\n      }\n    } else {\n      // Collect and rewrite module.exports assignments\n      for (const { left } of moduleExportsAssignments) {\n        magicString.overwrite(left.start, left.end, `${moduleName}.exports`);\n      }\n      // Collect and rewrite named exports\n      for (const [exportName, { nodes }] of exportsAssignmentsByName) {\n        for (const node of nodes) {\n          magicString.overwrite(node.start, node.left.end, `${exportsName}.${exportName}`);\n        }\n      }\n      // Collect and rewrite exports.__esModule assignments\n      for (const expression of defineCompiledEsmExpressions) {\n        const moduleExportsExpression =\n          expression.type === 'CallExpression' ? expression.arguments[0] : expression.left.object;\n        magicString.overwrite(\n          moduleExportsExpression.start,\n          moduleExportsExpression.end,\n          exportsName\n        );\n      }\n    }\n  }\n  exports.push(`${requireName} as __require`);\n}\n\nfunction getExportsForReplacedModuleExports(\n  magicString,\n  exports,\n  exportDeclarations,\n  moduleExportsAssignments,\n  firstTopLevelModuleExportsAssignment,\n  exportsName\n) {\n  for (const { left } of moduleExportsAssignments) {\n    magicString.overwrite(left.start, left.end, exportsName);\n  }\n  magicString.prependRight(firstTopLevelModuleExportsAssignment.left.start, 'var ');\n  exports.push(`${exportsName} as __moduleExports`);\n  exportDeclarations.push(`export default ${exportsName};`);\n}\n\nfunction getExportsWhenWrapping(\n  exportDeclarations,\n  exportsName,\n  detectWrappedDefault,\n  HELPERS_NAME,\n  defaultIsModuleExports\n) {\n  exportDeclarations.push(\n    `export default ${\n      detectWrappedDefault && defaultIsModuleExports === 'auto'\n        ? `/*@__PURE__*/${HELPERS_NAME}.getDefaultExportFromCjs(${exportsName})`\n        : defaultIsModuleExports === false\n        ? `${exportsName}.default`\n        : exportsName\n    };`\n  );\n}\n\nfunction getExports(\n  magicString,\n  exports,\n  exportDeclarations,\n  moduleExportsAssignments,\n  exportsAssignmentsByName,\n  deconflictedExportNames,\n  topLevelAssignments,\n  moduleName,\n  exportsName,\n  defineCompiledEsmExpressions,\n  HELPERS_NAME,\n  defaultIsModuleExports\n) {\n  let deconflictedDefaultExportName;\n  // Collect and rewrite module.exports assignments\n  for (const { left } of moduleExportsAssignments) {\n    magicString.overwrite(left.start, left.end, `${moduleName}.exports`);\n  }\n\n  // Collect and rewrite named exports\n  for (const [exportName, { nodes }] of exportsAssignmentsByName) {\n    const deconflicted = deconflictedExportNames[exportName];\n    let needsDeclaration = true;\n    for (const node of nodes) {\n      let replacement = `${deconflicted} = ${exportsName}.${exportName}`;\n      if (needsDeclaration && topLevelAssignments.has(node)) {\n        replacement = `var ${replacement}`;\n        needsDeclaration = false;\n      }\n      magicString.overwrite(node.start, node.left.end, replacement);\n    }\n    if (needsDeclaration) {\n      magicString.prepend(`var ${deconflicted};\\n`);\n    }\n\n    if (exportName === 'default') {\n      deconflictedDefaultExportName = deconflicted;\n    } else {\n      exports.push(exportName === deconflicted ? exportName : `${deconflicted} as ${exportName}`);\n    }\n  }\n\n  // Collect and rewrite exports.__esModule assignments\n  let isRestorableCompiledEsm = false;\n  for (const expression of defineCompiledEsmExpressions) {\n    isRestorableCompiledEsm = true;\n    const moduleExportsExpression =\n      expression.type === 'CallExpression' ? expression.arguments[0] : expression.left.object;\n    magicString.overwrite(moduleExportsExpression.start, moduleExportsExpression.end, exportsName);\n  }\n\n  if (!isRestorableCompiledEsm || defaultIsModuleExports === true) {\n    exports.push(`${exportsName} as default`);\n  } else if (moduleExportsAssignments.length === 0 || defaultIsModuleExports === false) {\n    exports.push(`${deconflictedDefaultExportName || exportsName} as default`);\n  } else {\n    exportDeclarations.push(\n      `export default /*@__PURE__*/${HELPERS_NAME}.getDefaultExportFromCjs(${exportsName});`\n    );\n  }\n}\n\nfunction isRequireExpression(node, scope) {\n  if (!node) return false;\n  if (node.type !== 'CallExpression') return false;\n\n  // Weird case of `require()` or `module.require()` without arguments\n  if (node.arguments.length === 0) return false;\n\n  return isRequire(node.callee, scope);\n}\n\nfunction isRequire(node, scope) {\n  return (\n    (node.type === 'Identifier' && node.name === 'require' && !scope.contains('require')) ||\n    (node.type === 'MemberExpression' && isModuleRequire(node, scope))\n  );\n}\n\nfunction isModuleRequire({ object, property }, scope) {\n  return (\n    object.type === 'Identifier' &&\n    object.name === 'module' &&\n    property.type === 'Identifier' &&\n    property.name === 'require' &&\n    !scope.contains('module')\n  );\n}\n\nfunction hasDynamicArguments(node) {\n  return (\n    node.arguments.length > 1 ||\n    (node.arguments[0].type !== 'Literal' &&\n      (node.arguments[0].type !== 'TemplateLiteral' || node.arguments[0].expressions.length > 0))\n  );\n}\n\nconst reservedMethod = { resolve: true, cache: true, main: true };\n\nfunction isNodeRequirePropertyAccess(parent) {\n  return parent && parent.property && reservedMethod[parent.property.name];\n}\n\nfunction getRequireStringArg(node) {\n  return node.arguments[0].type === 'Literal'\n    ? node.arguments[0].value\n    : node.arguments[0].quasis[0].value.cooked;\n}\n\nfunction getRequireHandlers() {\n  const requireExpressions = [];\n\n  function addRequireExpression(\n    sourceId,\n    node,\n    scope,\n    usesReturnValue,\n    isInsideTryBlock,\n    isInsideConditional,\n    toBeRemoved\n  ) {\n    requireExpressions.push({\n      sourceId,\n      node,\n      scope,\n      usesReturnValue,\n      isInsideTryBlock,\n      isInsideConditional,\n      toBeRemoved\n    });\n  }\n\n  async function rewriteRequireExpressionsAndGetImportBlock(\n    magicString,\n    topLevelDeclarations,\n    reassignedNames,\n    helpersName,\n    dynamicRequireName,\n    moduleName,\n    exportsName,\n    id,\n    exportMode,\n    resolveRequireSourcesAndUpdateMeta,\n    needsRequireWrapper,\n    isEsModule,\n    isDynamicRequireModulesEnabled,\n    getIgnoreTryCatchRequireStatementMode,\n    commonjsMeta\n  ) {\n    const imports = [];\n    imports.push(`import * as ${helpersName} from \"${HELPERS_ID}\";`);\n    if (dynamicRequireName) {\n      imports.push(\n        `import { ${\n          isDynamicRequireModulesEnabled ? CREATE_COMMONJS_REQUIRE_EXPORT : COMMONJS_REQUIRE_EXPORT\n        } as ${dynamicRequireName} } from \"${DYNAMIC_MODULES_ID}\";`\n      );\n    }\n    if (exportMode === 'module') {\n      imports.push(\n        `import { __module as ${moduleName}, exports as ${exportsName} } from ${JSON.stringify(\n          wrapId$1(id, MODULE_SUFFIX)\n        )}`\n      );\n    } else if (exportMode === 'exports') {\n      imports.push(\n        `import { __exports as ${exportsName} } from ${JSON.stringify(wrapId$1(id, EXPORTS_SUFFIX))}`\n      );\n    }\n    const requiresBySource = collectSources(requireExpressions);\n    const requireTargets = await resolveRequireSourcesAndUpdateMeta(\n      id,\n      needsRequireWrapper ? IS_WRAPPED_COMMONJS : !isEsModule,\n      commonjsMeta,\n      Object.keys(requiresBySource).map((source) => {\n        return {\n          source,\n          isConditional: requiresBySource[source].every((require) => require.isInsideConditional)\n        };\n      })\n    );\n    processRequireExpressions(\n      imports,\n      requireTargets,\n      requiresBySource,\n      getIgnoreTryCatchRequireStatementMode,\n      magicString\n    );\n    return imports.length ? `${imports.join('\\n')}\\n\\n` : '';\n  }\n\n  return {\n    addRequireExpression,\n    rewriteRequireExpressionsAndGetImportBlock\n  };\n}\n\nfunction collectSources(requireExpressions) {\n  const requiresBySource = Object.create(null);\n  for (const requireExpression of requireExpressions) {\n    const { sourceId } = requireExpression;\n    if (!requiresBySource[sourceId]) {\n      requiresBySource[sourceId] = [];\n    }\n    const requires = requiresBySource[sourceId];\n    requires.push(requireExpression);\n  }\n  return requiresBySource;\n}\n\nfunction processRequireExpressions(\n  imports,\n  requireTargets,\n  requiresBySource,\n  getIgnoreTryCatchRequireStatementMode,\n  magicString\n) {\n  const generateRequireName = getGenerateRequireName();\n  for (const { source, id: resolvedId, isCommonJS } of requireTargets) {\n    const requires = requiresBySource[source];\n    const name = generateRequireName(requires);\n    let usesRequired = false;\n    let needsImport = false;\n    for (const { node, usesReturnValue, toBeRemoved, isInsideTryBlock } of requires) {\n      const { canConvertRequire, shouldRemoveRequire } =\n        isInsideTryBlock && isWrappedId(resolvedId, EXTERNAL_SUFFIX)\n          ? getIgnoreTryCatchRequireStatementMode(source)\n          : { canConvertRequire: true, shouldRemoveRequire: false };\n      if (shouldRemoveRequire) {\n        if (usesReturnValue) {\n          magicString.overwrite(node.start, node.end, 'undefined');\n        } else {\n          magicString.remove(toBeRemoved.start, toBeRemoved.end);\n        }\n      } else if (canConvertRequire) {\n        needsImport = true;\n        if (isCommonJS === IS_WRAPPED_COMMONJS) {\n          magicString.overwrite(node.start, node.end, `${name}()`);\n        } else if (usesReturnValue) {\n          usesRequired = true;\n          magicString.overwrite(node.start, node.end, name);\n        } else {\n          magicString.remove(toBeRemoved.start, toBeRemoved.end);\n        }\n      }\n    }\n    if (needsImport) {\n      if (isCommonJS === IS_WRAPPED_COMMONJS) {\n        imports.push(`import { __require as ${name} } from ${JSON.stringify(resolvedId)};`);\n      } else {\n        imports.push(`import ${usesRequired ? `${name} from ` : ''}${JSON.stringify(resolvedId)};`);\n      }\n    }\n  }\n}\n\nfunction getGenerateRequireName() {\n  let uid = 0;\n  return (requires) => {\n    let name;\n    const hasNameConflict = ({ scope }) => scope.contains(name);\n    do {\n      name = `require$$${uid}`;\n      uid += 1;\n    } while (requires.some(hasNameConflict));\n    return name;\n  };\n}\n\n/* eslint-disable no-param-reassign, no-shadow, no-underscore-dangle, no-continue */\n\nconst exportsPattern = /^(?:module\\.)?exports(?:\\.([a-zA-Z_$][a-zA-Z_$0-9]*))?$/;\n\nconst functionType = /^(?:FunctionDeclaration|FunctionExpression|ArrowFunctionExpression)$/;\n\nasync function transformCommonjs(\n  parse,\n  code,\n  id,\n  isEsModule,\n  ignoreGlobal,\n  ignoreRequire,\n  ignoreDynamicRequires,\n  getIgnoreTryCatchRequireStatementMode,\n  sourceMap,\n  isDynamicRequireModulesEnabled,\n  dynamicRequireModules,\n  commonDir,\n  astCache,\n  defaultIsModuleExports,\n  needsRequireWrapper,\n  resolveRequireSourcesAndUpdateMeta,\n  isRequired,\n  checkDynamicRequire,\n  commonjsMeta\n) {\n  const ast = astCache || tryParse(parse, code, id);\n  const magicString = new MagicString(code);\n  const uses = {\n    module: false,\n    exports: false,\n    global: false,\n    require: false\n  };\n  const virtualDynamicRequirePath =\n    isDynamicRequireModulesEnabled && getVirtualPathForDynamicRequirePath(dirname$1(id), commonDir);\n  let scope = attachScopes(ast, 'scope');\n  let lexicalDepth = 0;\n  let programDepth = 0;\n  let currentTryBlockEnd = null;\n  let shouldWrap = false;\n  let reexports = false;\n\n  const globals = new Set();\n  // A conditionalNode is a node for which execution is not guaranteed. If such a node is a require\n  // or contains nested requires, those should be handled as function calls unless there is an\n  // unconditional require elsewhere.\n  let currentConditionalNodeEnd = null;\n  const conditionalNodes = new Set();\n  const { addRequireExpression, rewriteRequireExpressionsAndGetImportBlock } = getRequireHandlers();\n\n  // See which names are assigned to. This is necessary to prevent\n  // illegally replacing `var foo = require('foo')` with `import foo from 'foo'`,\n  // where `foo` is later reassigned. (This happens in the wild. CommonJS, sigh)\n  const reassignedNames = new Set();\n  const topLevelDeclarations = [];\n  const skippedNodes = new Set();\n  const moduleAccessScopes = new Set([scope]);\n  const exportsAccessScopes = new Set([scope]);\n  const moduleExportsAssignments = [];\n  let firstTopLevelModuleExportsAssignment = null;\n  const exportsAssignmentsByName = new Map();\n  const topLevelAssignments = new Set();\n  const topLevelDefineCompiledEsmExpressions = [];\n  const replacedGlobal = [];\n  const replacedDynamicRequires = [];\n  const importedVariables = new Set();\n  const indentExclusionRanges = [];\n\n  walk$3(ast, {\n    enter(node, parent) {\n      if (skippedNodes.has(node)) {\n        this.skip();\n        return;\n      }\n\n      if (currentTryBlockEnd !== null && node.start > currentTryBlockEnd) {\n        currentTryBlockEnd = null;\n      }\n      if (currentConditionalNodeEnd !== null && node.start > currentConditionalNodeEnd) {\n        currentConditionalNodeEnd = null;\n      }\n      if (currentConditionalNodeEnd === null && conditionalNodes.has(node)) {\n        currentConditionalNodeEnd = node.end;\n      }\n\n      programDepth += 1;\n      if (node.scope) ({ scope } = node);\n      if (functionType.test(node.type)) lexicalDepth += 1;\n      if (sourceMap) {\n        magicString.addSourcemapLocation(node.start);\n        magicString.addSourcemapLocation(node.end);\n      }\n\n      // eslint-disable-next-line default-case\n      switch (node.type) {\n        case 'AssignmentExpression':\n          if (node.left.type === 'MemberExpression') {\n            const flattened = getKeypath(node.left);\n            if (!flattened || scope.contains(flattened.name)) return;\n\n            const exportsPatternMatch = exportsPattern.exec(flattened.keypath);\n            if (!exportsPatternMatch || flattened.keypath === 'exports') return;\n\n            const [, exportName] = exportsPatternMatch;\n            uses[flattened.name] = true;\n\n            // we're dealing with `module.exports = ...` or `[module.]exports.foo = ...` –\n            if (flattened.keypath === 'module.exports') {\n              moduleExportsAssignments.push(node);\n              if (programDepth > 3) {\n                moduleAccessScopes.add(scope);\n              } else if (!firstTopLevelModuleExportsAssignment) {\n                firstTopLevelModuleExportsAssignment = node;\n              }\n\n              if (defaultIsModuleExports === false) {\n                shouldWrap = true;\n              } else if (defaultIsModuleExports === 'auto') {\n                if (node.right.type === 'ObjectExpression') {\n                  if (hasDefineEsmProperty(node.right)) {\n                    shouldWrap = true;\n                  }\n                } else if (isRequireExpression(node.right, scope)) {\n                  shouldWrap = true;\n                  reexports = true;\n                }\n              }\n            } else if (exportName === KEY_COMPILED_ESM) {\n              if (programDepth > 3) {\n                shouldWrap = true;\n              } else {\n                topLevelDefineCompiledEsmExpressions.push(node);\n              }\n            } else {\n              const exportsAssignments = exportsAssignmentsByName.get(exportName) || {\n                nodes: [],\n                scopes: new Set()\n              };\n              exportsAssignments.nodes.push(node);\n              exportsAssignments.scopes.add(scope);\n              exportsAccessScopes.add(scope);\n              exportsAssignmentsByName.set(exportName, exportsAssignments);\n              if (programDepth <= 3) {\n                topLevelAssignments.add(node);\n              }\n            }\n\n            skippedNodes.add(node.left);\n          } else {\n            for (const name of extractAssignedNames(node.left)) {\n              reassignedNames.add(name);\n            }\n          }\n          return;\n        case 'CallExpression': {\n          if (isDefineCompiledEsm(node)) {\n            if (programDepth === 3 && parent.type === 'ExpressionStatement') {\n              // skip special handling for [module.]exports until we know we render this\n              skippedNodes.add(node.arguments[0]);\n              topLevelDefineCompiledEsmExpressions.push(node);\n            } else {\n              shouldWrap = true;\n            }\n            return;\n          }\n\n          // Transform require.resolve\n          if (\n            isDynamicRequireModulesEnabled &&\n            node.callee.object &&\n            isRequire(node.callee.object, scope) &&\n            node.callee.property.name === 'resolve'\n          ) {\n            checkDynamicRequire(node.start);\n            uses.require = true;\n            const requireNode = node.callee.object;\n            replacedDynamicRequires.push(requireNode);\n            return;\n          }\n\n          if (!isRequireExpression(node, scope)) {\n            const keypath = getKeypath(node.callee);\n            if (keypath && importedVariables.has(keypath.name)) {\n              // Heuristic to deoptimize requires after a required function has been called\n              currentConditionalNodeEnd = Infinity;\n            }\n            return;\n          }\n\n          skippedNodes.add(node.callee);\n          uses.require = true;\n\n          if (hasDynamicArguments(node)) {\n            if (isDynamicRequireModulesEnabled) {\n              checkDynamicRequire(node.start);\n            }\n            if (!ignoreDynamicRequires) {\n              replacedDynamicRequires.push(node.callee);\n            }\n            return;\n          }\n\n          const requireStringArg = getRequireStringArg(node);\n          if (!ignoreRequire(requireStringArg)) {\n            const usesReturnValue = parent.type !== 'ExpressionStatement';\n            const toBeRemoved =\n              parent.type === 'ExpressionStatement' &&\n              (!currentConditionalNodeEnd ||\n                // We should completely remove requires directly in a try-catch\n                // so that Rollup can remove up the try-catch\n                (currentTryBlockEnd !== null && currentTryBlockEnd < currentConditionalNodeEnd))\n                ? parent\n                : node;\n            addRequireExpression(\n              requireStringArg,\n              node,\n              scope,\n              usesReturnValue,\n              currentTryBlockEnd !== null,\n              currentConditionalNodeEnd !== null,\n              toBeRemoved\n            );\n            if (parent.type === 'VariableDeclarator' && parent.id.type === 'Identifier') {\n              for (const name of extractAssignedNames(parent.id)) {\n                importedVariables.add(name);\n              }\n            }\n          }\n          return;\n        }\n        case 'ConditionalExpression':\n        case 'IfStatement':\n          // skip dead branches\n          if (isFalsy(node.test)) {\n            skippedNodes.add(node.consequent);\n          } else if (isTruthy(node.test)) {\n            if (node.alternate) {\n              skippedNodes.add(node.alternate);\n            }\n          } else {\n            conditionalNodes.add(node.consequent);\n            if (node.alternate) {\n              conditionalNodes.add(node.alternate);\n            }\n          }\n          return;\n        case 'ArrowFunctionExpression':\n        case 'FunctionDeclaration':\n        case 'FunctionExpression':\n          // requires in functions should be conditional unless it is an IIFE\n          if (\n            currentConditionalNodeEnd === null &&\n            !(parent.type === 'CallExpression' && parent.callee === node)\n          ) {\n            currentConditionalNodeEnd = node.end;\n          }\n          return;\n        case 'Identifier': {\n          const { name } = node;\n          if (!isReference(node, parent) || scope.contains(name)) return;\n          switch (name) {\n            case 'require':\n              uses.require = true;\n              if (isNodeRequirePropertyAccess(parent)) {\n                return;\n              }\n              if (!ignoreDynamicRequires) {\n                if (isShorthandProperty(parent)) {\n                  magicString.prependRight(node.start, 'require: ');\n                }\n                replacedDynamicRequires.push(node);\n              }\n              return;\n            case 'module':\n            case 'exports':\n              shouldWrap = true;\n              uses[name] = true;\n              return;\n            case 'global':\n              uses.global = true;\n              if (!ignoreGlobal) {\n                replacedGlobal.push(node);\n              }\n              return;\n            case 'define':\n              magicString.overwrite(node.start, node.end, 'undefined', {\n                storeName: true\n              });\n              return;\n            default:\n              globals.add(name);\n              return;\n          }\n        }\n        case 'LogicalExpression':\n          // skip dead branches\n          if (node.operator === '&&') {\n            if (isFalsy(node.left)) {\n              skippedNodes.add(node.right);\n            } else if (!isTruthy(node.left)) {\n              conditionalNodes.add(node.right);\n            }\n          } else if (node.operator === '||') {\n            if (isTruthy(node.left)) {\n              skippedNodes.add(node.right);\n            } else if (!isFalsy(node.left)) {\n              conditionalNodes.add(node.right);\n            }\n          }\n          return;\n        case 'MemberExpression':\n          if (!isDynamicRequireModulesEnabled && isModuleRequire(node, scope)) {\n            uses.require = true;\n            replacedDynamicRequires.push(node);\n            skippedNodes.add(node.object);\n            skippedNodes.add(node.property);\n          }\n          return;\n        case 'ReturnStatement':\n          // if top-level return, we need to wrap it\n          if (lexicalDepth === 0) {\n            shouldWrap = true;\n          }\n          return;\n        case 'ThisExpression':\n          // rewrite top-level `this` as `commonjsHelpers.commonjsGlobal`\n          if (lexicalDepth === 0) {\n            uses.global = true;\n            if (!ignoreGlobal) {\n              replacedGlobal.push(node);\n            }\n          }\n          return;\n        case 'TryStatement':\n          if (currentTryBlockEnd === null) {\n            currentTryBlockEnd = node.block.end;\n          }\n          if (currentConditionalNodeEnd === null) {\n            currentConditionalNodeEnd = node.end;\n          }\n          return;\n        case 'UnaryExpression':\n          // rewrite `typeof module`, `typeof module.exports` and `typeof exports` (https://github.com/rollup/rollup-plugin-commonjs/issues/151)\n          if (node.operator === 'typeof') {\n            const flattened = getKeypath(node.argument);\n            if (!flattened) return;\n\n            if (scope.contains(flattened.name)) return;\n\n            if (\n              !isEsModule &&\n              (flattened.keypath === 'module.exports' ||\n                flattened.keypath === 'module' ||\n                flattened.keypath === 'exports')\n            ) {\n              magicString.overwrite(node.start, node.end, `'object'`, {\n                storeName: false\n              });\n            }\n          }\n          return;\n        case 'VariableDeclaration':\n          if (!scope.parent) {\n            topLevelDeclarations.push(node);\n          }\n          return;\n        case 'TemplateElement':\n          if (node.value.raw.includes('\\n')) {\n            indentExclusionRanges.push([node.start, node.end]);\n          }\n      }\n    },\n\n    leave(node) {\n      programDepth -= 1;\n      if (node.scope) scope = scope.parent;\n      if (functionType.test(node.type)) lexicalDepth -= 1;\n    }\n  });\n\n  const nameBase = getName(id);\n  const exportsName = deconflict([...exportsAccessScopes], globals, nameBase);\n  const moduleName = deconflict([...moduleAccessScopes], globals, `${nameBase}Module`);\n  const requireName = deconflict([scope], globals, `require${capitalize(nameBase)}`);\n  const isRequiredName = deconflict([scope], globals, `hasRequired${capitalize(nameBase)}`);\n  const helpersName = deconflict([scope], globals, 'commonjsHelpers');\n  const dynamicRequireName =\n    replacedDynamicRequires.length > 0 &&\n    deconflict(\n      [scope],\n      globals,\n      isDynamicRequireModulesEnabled ? CREATE_COMMONJS_REQUIRE_EXPORT : COMMONJS_REQUIRE_EXPORT\n    );\n  const deconflictedExportNames = Object.create(null);\n  for (const [exportName, { scopes }] of exportsAssignmentsByName) {\n    deconflictedExportNames[exportName] = deconflict([...scopes], globals, exportName);\n  }\n\n  for (const node of replacedGlobal) {\n    magicString.overwrite(node.start, node.end, `${helpersName}.commonjsGlobal`, {\n      storeName: true\n    });\n  }\n  for (const node of replacedDynamicRequires) {\n    magicString.overwrite(\n      node.start,\n      node.end,\n      isDynamicRequireModulesEnabled\n        ? `${dynamicRequireName}(${JSON.stringify(virtualDynamicRequirePath)})`\n        : dynamicRequireName,\n      {\n        contentOnly: true,\n        storeName: true\n      }\n    );\n  }\n\n  // We cannot wrap ES/mixed modules\n  shouldWrap = !isEsModule && (shouldWrap || (uses.exports && moduleExportsAssignments.length > 0));\n  const detectWrappedDefault =\n    shouldWrap &&\n    (reexports ||\n      topLevelDefineCompiledEsmExpressions.length > 0 ||\n      code.indexOf('__esModule') >= 0);\n\n  if (\n    !(\n      shouldWrap ||\n      isRequired ||\n      needsRequireWrapper ||\n      uses.module ||\n      uses.exports ||\n      uses.require ||\n      topLevelDefineCompiledEsmExpressions.length > 0\n    ) &&\n    (ignoreGlobal || !uses.global)\n  ) {\n    return { meta: { commonjs: { isCommonJS: false } } };\n  }\n\n  let leadingComment = '';\n  if (code.startsWith('/*')) {\n    const commentEnd = code.indexOf('*/', 2) + 2;\n    leadingComment = `${code.slice(0, commentEnd)}\\n`;\n    magicString.remove(0, commentEnd).trim();\n  }\n\n  const exportMode = isEsModule\n    ? 'none'\n    : shouldWrap\n    ? uses.module\n      ? 'module'\n      : 'exports'\n    : firstTopLevelModuleExportsAssignment\n    ? exportsAssignmentsByName.size === 0 && topLevelDefineCompiledEsmExpressions.length === 0\n      ? 'replace'\n      : 'module'\n    : moduleExportsAssignments.length === 0\n    ? 'exports'\n    : 'module';\n\n  const importBlock = await rewriteRequireExpressionsAndGetImportBlock(\n    magicString,\n    topLevelDeclarations,\n    reassignedNames,\n    helpersName,\n    dynamicRequireName,\n    moduleName,\n    exportsName,\n    id,\n    exportMode,\n    resolveRequireSourcesAndUpdateMeta,\n    needsRequireWrapper,\n    isEsModule,\n    isDynamicRequireModulesEnabled,\n    getIgnoreTryCatchRequireStatementMode,\n    commonjsMeta\n  );\n  const usesRequireWrapper = commonjsMeta.isCommonJS === IS_WRAPPED_COMMONJS;\n  const exportBlock = isEsModule\n    ? ''\n    : rewriteExportsAndGetExportsBlock(\n        magicString,\n        moduleName,\n        exportsName,\n        shouldWrap,\n        moduleExportsAssignments,\n        firstTopLevelModuleExportsAssignment,\n        exportsAssignmentsByName,\n        topLevelAssignments,\n        topLevelDefineCompiledEsmExpressions,\n        deconflictedExportNames,\n        code,\n        helpersName,\n        exportMode,\n        detectWrappedDefault,\n        defaultIsModuleExports,\n        usesRequireWrapper,\n        requireName\n      );\n\n  if (shouldWrap) {\n    wrapCode(magicString, uses, moduleName, exportsName, indentExclusionRanges);\n  }\n\n  if (usesRequireWrapper) {\n    magicString.trim().indent('\\t', {\n      exclude: indentExclusionRanges\n    });\n    magicString.prepend(\n      `var ${isRequiredName};\n\nfunction ${requireName} () {\n\\tif (${isRequiredName}) return ${exportsName};\n\\t${isRequiredName} = 1;\n`\n    ).append(`\n\\treturn ${exportsName};\n}`);\n    if (exportMode === 'replace') {\n      magicString.prepend(`var ${exportsName};\\n`);\n    }\n  }\n\n  magicString\n    .trim()\n    .prepend(leadingComment + importBlock)\n    .append(exportBlock);\n\n  return {\n    code: magicString.toString(),\n    map: sourceMap ? magicString.generateMap() : null,\n    syntheticNamedExports: isEsModule || usesRequireWrapper ? false : '__moduleExports',\n    meta: { commonjs: commonjsMeta }\n  };\n}\n\nconst PLUGIN_NAME = 'commonjs';\n\nfunction commonjs(options = {}) {\n  const {\n    ignoreGlobal,\n    ignoreDynamicRequires,\n    requireReturnsDefault: requireReturnsDefaultOption,\n    defaultIsModuleExports: defaultIsModuleExportsOption,\n    esmExternals\n  } = options;\n  const extensions = options.extensions || ['.js'];\n  const filter = createFilter$1(options.include, options.exclude);\n  const isPossibleCjsId = (id) => {\n    const extName = extname(id);\n    return extName === '.cjs' || (extensions.includes(extName) && filter(id));\n  };\n\n  const { strictRequiresFilter, detectCyclesAndConditional } = getStrictRequiresFilter(options);\n\n  const getRequireReturnsDefault =\n    typeof requireReturnsDefaultOption === 'function'\n      ? requireReturnsDefaultOption\n      : () => requireReturnsDefaultOption;\n\n  let esmExternalIds;\n  const isEsmExternal =\n    typeof esmExternals === 'function'\n      ? esmExternals\n      : Array.isArray(esmExternals)\n      ? ((esmExternalIds = new Set(esmExternals)), (id) => esmExternalIds.has(id))\n      : () => esmExternals;\n\n  const getDefaultIsModuleExports =\n    typeof defaultIsModuleExportsOption === 'function'\n      ? defaultIsModuleExportsOption\n      : () =>\n          typeof defaultIsModuleExportsOption === 'boolean' ? defaultIsModuleExportsOption : 'auto';\n\n  const dynamicRequireRoot =\n    typeof options.dynamicRequireRoot === 'string'\n      ? resolve$3(options.dynamicRequireRoot)\n      : process.cwd();\n  const { commonDir, dynamicRequireModules } = getDynamicRequireModules(\n    options.dynamicRequireTargets,\n    dynamicRequireRoot\n  );\n  const isDynamicRequireModulesEnabled = dynamicRequireModules.size > 0;\n\n  const ignoreRequire =\n    typeof options.ignore === 'function'\n      ? options.ignore\n      : Array.isArray(options.ignore)\n      ? (id) => options.ignore.includes(id)\n      : () => false;\n\n  const getIgnoreTryCatchRequireStatementMode = (id) => {\n    const mode =\n      typeof options.ignoreTryCatch === 'function'\n        ? options.ignoreTryCatch(id)\n        : Array.isArray(options.ignoreTryCatch)\n        ? options.ignoreTryCatch.includes(id)\n        : typeof options.ignoreTryCatch !== 'undefined'\n        ? options.ignoreTryCatch\n        : true;\n\n    return {\n      canConvertRequire: mode !== 'remove' && mode !== true,\n      shouldRemoveRequire: mode === 'remove'\n    };\n  };\n\n  const { currentlyResolving, resolveId } = getResolveId(extensions, isPossibleCjsId);\n\n  const sourceMap = options.sourceMap !== false;\n\n  // Initialized in buildStart\n  let requireResolver;\n\n  function transformAndCheckExports(code, id) {\n    const { isEsModule, hasDefaultExport, hasNamedExports, ast } = analyzeTopLevelStatements(\n      this.parse,\n      code,\n      id\n    );\n\n    const commonjsMeta = this.getModuleInfo(id).meta.commonjs || {};\n    if (hasDefaultExport) {\n      commonjsMeta.hasDefaultExport = true;\n    }\n    if (hasNamedExports) {\n      commonjsMeta.hasNamedExports = true;\n    }\n\n    if (\n      !dynamicRequireModules.has(normalizePathSlashes(id)) &&\n      (!(hasCjsKeywords(code, ignoreGlobal) || requireResolver.isRequiredId(id)) ||\n        (isEsModule && !options.transformMixedEsModules))\n    ) {\n      commonjsMeta.isCommonJS = false;\n      return { meta: { commonjs: commonjsMeta } };\n    }\n\n    const needsRequireWrapper =\n      !isEsModule &&\n      (dynamicRequireModules.has(normalizePathSlashes(id)) || strictRequiresFilter(id));\n\n    const checkDynamicRequire = (position) => {\n      if (id.indexOf(dynamicRequireRoot) !== 0) {\n        this.error(\n          {\n            code: 'DYNAMIC_REQUIRE_OUTSIDE_ROOT',\n            id,\n            dynamicRequireRoot,\n            message: `\"${id}\" contains dynamic require statements but it is not within the current dynamicRequireRoot \"${dynamicRequireRoot}\". You should set dynamicRequireRoot to \"${dirname$1(\n              id\n            )}\" or one of its parent directories.`\n          },\n          position\n        );\n      }\n    };\n\n    return transformCommonjs(\n      this.parse,\n      code,\n      id,\n      isEsModule,\n      ignoreGlobal || isEsModule,\n      ignoreRequire,\n      ignoreDynamicRequires && !isDynamicRequireModulesEnabled,\n      getIgnoreTryCatchRequireStatementMode,\n      sourceMap,\n      isDynamicRequireModulesEnabled,\n      dynamicRequireModules,\n      commonDir,\n      ast,\n      getDefaultIsModuleExports(id),\n      needsRequireWrapper,\n      requireResolver.resolveRequireSourcesAndUpdateMeta(this),\n      requireResolver.isRequiredId(id),\n      checkDynamicRequire,\n      commonjsMeta\n    );\n  }\n\n  return {\n    name: PLUGIN_NAME,\n\n    version: version$3,\n\n    options(rawOptions) {\n      // We inject the resolver in the beginning so that \"catch-all-resolver\" like node-resolver\n      // do not prevent our plugin from resolving entry points ot proxies.\n      const plugins = Array.isArray(rawOptions.plugins)\n        ? [...rawOptions.plugins]\n        : rawOptions.plugins\n        ? [rawOptions.plugins]\n        : [];\n      plugins.unshift({\n        name: 'commonjs--resolver',\n        resolveId\n      });\n      return { ...rawOptions, plugins };\n    },\n\n    buildStart({ plugins }) {\n      validateVersion(this.meta.rollupVersion, peerDependencies.rollup, 'rollup');\n      const nodeResolve = plugins.find(({ name }) => name === 'node-resolve');\n      if (nodeResolve) {\n        validateVersion(nodeResolve.version, '^13.0.6', '@rollup/plugin-node-resolve');\n      }\n      if (options.namedExports != null) {\n        this.warn(\n          'The namedExports option from \"@rollup/plugin-commonjs\" is deprecated. Named exports are now handled automatically.'\n        );\n      }\n      requireResolver = getRequireResolver(\n        extensions,\n        detectCyclesAndConditional,\n        currentlyResolving\n      );\n    },\n\n    buildEnd() {\n      if (options.strictRequires === 'debug') {\n        const wrappedIds = requireResolver.getWrappedIds();\n        if (wrappedIds.length) {\n          this.warn({\n            code: 'WRAPPED_IDS',\n            ids: wrappedIds,\n            message: `The commonjs plugin automatically wrapped the following files:\\n[\\n${wrappedIds\n              .map((id) => `\\t${JSON.stringify(relative$1(process.cwd(), id))}`)\n              .join(',\\n')}\\n]`\n          });\n        } else {\n          this.warn({\n            code: 'WRAPPED_IDS',\n            ids: wrappedIds,\n            message: 'The commonjs plugin did not wrap any files.'\n          });\n        }\n      }\n    },\n\n    load(id) {\n      if (id === HELPERS_ID) {\n        return getHelpersModule();\n      }\n\n      if (isWrappedId(id, MODULE_SUFFIX)) {\n        const module = getName(unwrapId$1(id, MODULE_SUFFIX));\n        const moduleExports = `${module}Exports`;\n        return {\n          code: `var ${moduleExports} = {};\nvar ${module} = {\n  get exports(){ return ${moduleExports}; },\n  set exports(v){ ${moduleExports} = v; },\n};\nexport {${module} as __module, ${moduleExports} as exports}`,\n          meta: { commonjs: { isCommonJS: false } }\n        };\n      }\n\n      if (isWrappedId(id, EXPORTS_SUFFIX)) {\n        const name = getName(unwrapId$1(id, EXPORTS_SUFFIX));\n        return {\n          code: `var ${name} = {}; export {${name} as __exports}`,\n          meta: { commonjs: { isCommonJS: false } }\n        };\n      }\n\n      if (isWrappedId(id, EXTERNAL_SUFFIX)) {\n        const actualId = unwrapId$1(id, EXTERNAL_SUFFIX);\n        return getUnknownRequireProxy(\n          actualId,\n          isEsmExternal(actualId) ? getRequireReturnsDefault(actualId) : true\n        );\n      }\n\n      // entry suffix is just appended to not mess up relative external resolution\n      if (id.endsWith(ENTRY_SUFFIX)) {\n        const acutalId = id.slice(0, -ENTRY_SUFFIX.length);\n        return getEntryProxy(acutalId, getDefaultIsModuleExports(acutalId), this.getModuleInfo);\n      }\n\n      if (isWrappedId(id, ES_IMPORT_SUFFIX)) {\n        const actualId = unwrapId$1(id, ES_IMPORT_SUFFIX);\n        return getEsImportProxy(actualId, getDefaultIsModuleExports(actualId));\n      }\n\n      if (id === DYNAMIC_MODULES_ID) {\n        return getDynamicModuleRegistry(\n          isDynamicRequireModulesEnabled,\n          dynamicRequireModules,\n          commonDir,\n          ignoreDynamicRequires\n        );\n      }\n\n      if (isWrappedId(id, PROXY_SUFFIX)) {\n        const actualId = unwrapId$1(id, PROXY_SUFFIX);\n        return getStaticRequireProxy(actualId, getRequireReturnsDefault(actualId), this.load);\n      }\n\n      return null;\n    },\n\n    shouldTransformCachedModule(...args) {\n      return requireResolver.shouldTransformCachedModule.call(this, ...args);\n    },\n\n    transform(code, id) {\n      if (!isPossibleCjsId(id)) return null;\n\n      try {\n        return transformAndCheckExports.call(this, code, id);\n      } catch (err) {\n        return this.error(err, err.loc);\n      }\n    }\n  };\n}\n\n// Matches the scheme of a URL, eg \"http://\"\nconst schemeRegex = /^[\\w+.-]+:\\/\\//;\n/**\n * Matches the parts of a URL:\n * 1. Scheme, including \":\", guaranteed.\n * 2. User/password, including \"@\", optional.\n * 3. Host, guaranteed.\n * 4. Port, including \":\", optional.\n * 5. Path, including \"/\", optional.\n * 6. Query, including \"?\", optional.\n * 7. Hash, including \"#\", optional.\n */\nconst urlRegex = /^([\\w+.-]+:)\\/\\/([^@/#?]*@)?([^:/#?]*)(:\\d+)?(\\/[^#?]*)?(\\?[^#]*)?(#.*)?/;\n/**\n * File URLs are weird. They dont' need the regular `//` in the scheme, they may or may not start\n * with a leading `/`, they can have a domain (but only if they don't start with a Windows drive).\n *\n * 1. Host, optional.\n * 2. Path, which may include \"/\", guaranteed.\n * 3. Query, including \"?\", optional.\n * 4. Hash, including \"#\", optional.\n */\nconst fileRegex = /^file:(?:\\/\\/((?![a-z]:)[^/#?]*)?)?(\\/?[^#?]*)(\\?[^#]*)?(#.*)?/i;\nvar UrlType;\n(function (UrlType) {\n    UrlType[UrlType[\"Empty\"] = 1] = \"Empty\";\n    UrlType[UrlType[\"Hash\"] = 2] = \"Hash\";\n    UrlType[UrlType[\"Query\"] = 3] = \"Query\";\n    UrlType[UrlType[\"RelativePath\"] = 4] = \"RelativePath\";\n    UrlType[UrlType[\"AbsolutePath\"] = 5] = \"AbsolutePath\";\n    UrlType[UrlType[\"SchemeRelative\"] = 6] = \"SchemeRelative\";\n    UrlType[UrlType[\"Absolute\"] = 7] = \"Absolute\";\n})(UrlType || (UrlType = {}));\nfunction isAbsoluteUrl(input) {\n    return schemeRegex.test(input);\n}\nfunction isSchemeRelativeUrl(input) {\n    return input.startsWith('//');\n}\nfunction isAbsolutePath(input) {\n    return input.startsWith('/');\n}\nfunction isFileUrl(input) {\n    return input.startsWith('file:');\n}\nfunction isRelative(input) {\n    return /^[.?#]/.test(input);\n}\nfunction parseAbsoluteUrl(input) {\n    const match = urlRegex.exec(input);\n    return makeUrl(match[1], match[2] || '', match[3], match[4] || '', match[5] || '/', match[6] || '', match[7] || '');\n}\nfunction parseFileUrl(input) {\n    const match = fileRegex.exec(input);\n    const path = match[2];\n    return makeUrl('file:', '', match[1] || '', '', isAbsolutePath(path) ? path : '/' + path, match[3] || '', match[4] || '');\n}\nfunction makeUrl(scheme, user, host, port, path, query, hash) {\n    return {\n        scheme,\n        user,\n        host,\n        port,\n        path,\n        query,\n        hash,\n        type: UrlType.Absolute,\n    };\n}\nfunction parseUrl$2(input) {\n    if (isSchemeRelativeUrl(input)) {\n        const url = parseAbsoluteUrl('http:' + input);\n        url.scheme = '';\n        url.type = UrlType.SchemeRelative;\n        return url;\n    }\n    if (isAbsolutePath(input)) {\n        const url = parseAbsoluteUrl('http://foo.com' + input);\n        url.scheme = '';\n        url.host = '';\n        url.type = UrlType.AbsolutePath;\n        return url;\n    }\n    if (isFileUrl(input))\n        return parseFileUrl(input);\n    if (isAbsoluteUrl(input))\n        return parseAbsoluteUrl(input);\n    const url = parseAbsoluteUrl('http://foo.com/' + input);\n    url.scheme = '';\n    url.host = '';\n    url.type = input\n        ? input.startsWith('?')\n            ? UrlType.Query\n            : input.startsWith('#')\n                ? UrlType.Hash\n                : UrlType.RelativePath\n        : UrlType.Empty;\n    return url;\n}\nfunction stripPathFilename(path) {\n    // If a path ends with a parent directory \"..\", then it's a relative path with excess parent\n    // paths. It's not a file, so we can't strip it.\n    if (path.endsWith('/..'))\n        return path;\n    const index = path.lastIndexOf('/');\n    return path.slice(0, index + 1);\n}\nfunction mergePaths(url, base) {\n    normalizePath$4(base, base.type);\n    // If the path is just a \"/\", then it was an empty path to begin with (remember, we're a relative\n    // path).\n    if (url.path === '/') {\n        url.path = base.path;\n    }\n    else {\n        // Resolution happens relative to the base path's directory, not the file.\n        url.path = stripPathFilename(base.path) + url.path;\n    }\n}\n/**\n * The path can have empty directories \"//\", unneeded parents \"foo/..\", or current directory\n * \"foo/.\". We need to normalize to a standard representation.\n */\nfunction normalizePath$4(url, type) {\n    const rel = type <= UrlType.RelativePath;\n    const pieces = url.path.split('/');\n    // We need to preserve the first piece always, so that we output a leading slash. The item at\n    // pieces[0] is an empty string.\n    let pointer = 1;\n    // Positive is the number of real directories we've output, used for popping a parent directory.\n    // Eg, \"foo/bar/..\" will have a positive 2, and we can decrement to be left with just \"foo\".\n    let positive = 0;\n    // We need to keep a trailing slash if we encounter an empty directory (eg, splitting \"foo/\" will\n    // generate `[\"foo\", \"\"]` pieces). And, if we pop a parent directory. But once we encounter a\n    // real directory, we won't need to append, unless the other conditions happen again.\n    let addTrailingSlash = false;\n    for (let i = 1; i < pieces.length; i++) {\n        const piece = pieces[i];\n        // An empty directory, could be a trailing slash, or just a double \"//\" in the path.\n        if (!piece) {\n            addTrailingSlash = true;\n            continue;\n        }\n        // If we encounter a real directory, then we don't need to append anymore.\n        addTrailingSlash = false;\n        // A current directory, which we can always drop.\n        if (piece === '.')\n            continue;\n        // A parent directory, we need to see if there are any real directories we can pop. Else, we\n        // have an excess of parents, and we'll need to keep the \"..\".\n        if (piece === '..') {\n            if (positive) {\n                addTrailingSlash = true;\n                positive--;\n                pointer--;\n            }\n            else if (rel) {\n                // If we're in a relativePath, then we need to keep the excess parents. Else, in an absolute\n                // URL, protocol relative URL, or an absolute path, we don't need to keep excess.\n                pieces[pointer++] = piece;\n            }\n            continue;\n        }\n        // We've encountered a real directory. Move it to the next insertion pointer, which accounts for\n        // any popped or dropped directories.\n        pieces[pointer++] = piece;\n        positive++;\n    }\n    let path = '';\n    for (let i = 1; i < pointer; i++) {\n        path += '/' + pieces[i];\n    }\n    if (!path || (addTrailingSlash && !path.endsWith('/..'))) {\n        path += '/';\n    }\n    url.path = path;\n}\n/**\n * Attempts to resolve `input` URL/path relative to `base`.\n */\nfunction resolve$2(input, base) {\n    if (!input && !base)\n        return '';\n    const url = parseUrl$2(input);\n    let inputType = url.type;\n    if (base && inputType !== UrlType.Absolute) {\n        const baseUrl = parseUrl$2(base);\n        const baseType = baseUrl.type;\n        switch (inputType) {\n            case UrlType.Empty:\n                url.hash = baseUrl.hash;\n            // fall through\n            case UrlType.Hash:\n                url.query = baseUrl.query;\n            // fall through\n            case UrlType.Query:\n            case UrlType.RelativePath:\n                mergePaths(url, baseUrl);\n            // fall through\n            case UrlType.AbsolutePath:\n                // The host, user, and port are joined, you can't copy one without the others.\n                url.user = baseUrl.user;\n                url.host = baseUrl.host;\n                url.port = baseUrl.port;\n            // fall through\n            case UrlType.SchemeRelative:\n                // The input doesn't have a schema at least, so we need to copy at least that over.\n                url.scheme = baseUrl.scheme;\n        }\n        if (baseType > inputType)\n            inputType = baseType;\n    }\n    normalizePath$4(url, inputType);\n    const queryHash = url.query + url.hash;\n    switch (inputType) {\n        // This is impossible, because of the empty checks at the start of the function.\n        // case UrlType.Empty:\n        case UrlType.Hash:\n        case UrlType.Query:\n            return queryHash;\n        case UrlType.RelativePath: {\n            // The first char is always a \"/\", and we need it to be relative.\n            const path = url.path.slice(1);\n            if (!path)\n                return queryHash || '.';\n            if (isRelative(base || input) && !isRelative(path)) {\n                // If base started with a leading \".\", or there is no base and input started with a \".\",\n                // then we need to ensure that the relative path starts with a \".\". We don't know if\n                // relative starts with a \"..\", though, so check before prepending.\n                return './' + path + queryHash;\n            }\n            return path + queryHash;\n        }\n        case UrlType.AbsolutePath:\n            return url.path + queryHash;\n        default:\n            return url.scheme + '//' + url.user + url.host + url.port + url.path + queryHash;\n    }\n}\n\nfunction resolve$1(input, base) {\n    // The base is always treated as a directory, if it's not empty.\n    // https://github.com/mozilla/source-map/blob/8cb3ee57/lib/util.js#L327\n    // https://github.com/chromium/chromium/blob/da4adbb3/third_party/blink/renderer/devtools/front_end/sdk/SourceMap.js#L400-L401\n    if (base && !base.endsWith('/'))\n        base += '/';\n    return resolve$2(input, base);\n}\n\n/**\n * Removes everything after the last \"/\", but leaves the slash.\n */\nfunction stripFilename(path) {\n    if (!path)\n        return '';\n    const index = path.lastIndexOf('/');\n    return path.slice(0, index + 1);\n}\n\nconst COLUMN = 0;\nconst SOURCES_INDEX = 1;\nconst SOURCE_LINE = 2;\nconst SOURCE_COLUMN = 3;\nconst NAMES_INDEX = 4;\n\nfunction maybeSort(mappings, owned) {\n    const unsortedIndex = nextUnsortedSegmentLine(mappings, 0);\n    if (unsortedIndex === mappings.length)\n        return mappings;\n    // If we own the array (meaning we parsed it from JSON), then we're free to directly mutate it. If\n    // not, we do not want to modify the consumer's input array.\n    if (!owned)\n        mappings = mappings.slice();\n    for (let i = unsortedIndex; i < mappings.length; i = nextUnsortedSegmentLine(mappings, i + 1)) {\n        mappings[i] = sortSegments(mappings[i], owned);\n    }\n    return mappings;\n}\nfunction nextUnsortedSegmentLine(mappings, start) {\n    for (let i = start; i < mappings.length; i++) {\n        if (!isSorted(mappings[i]))\n            return i;\n    }\n    return mappings.length;\n}\nfunction isSorted(line) {\n    for (let j = 1; j < line.length; j++) {\n        if (line[j][COLUMN] < line[j - 1][COLUMN]) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction sortSegments(line, owned) {\n    if (!owned)\n        line = line.slice();\n    return line.sort(sortComparator);\n}\nfunction sortComparator(a, b) {\n    return a[COLUMN] - b[COLUMN];\n}\n\nlet found = false;\n/**\n * A binary search implementation that returns the index if a match is found.\n * If no match is found, then the left-index (the index associated with the item that comes just\n * before the desired index) is returned. To maintain proper sort order, a splice would happen at\n * the next index:\n *\n * ```js\n * const array = [1, 3];\n * const needle = 2;\n * const index = binarySearch(array, needle, (item, needle) => item - needle);\n *\n * assert.equal(index, 0);\n * array.splice(index + 1, 0, needle);\n * assert.deepEqual(array, [1, 2, 3]);\n * ```\n */\nfunction binarySearch(haystack, needle, low, high) {\n    while (low <= high) {\n        const mid = low + ((high - low) >> 1);\n        const cmp = haystack[mid][COLUMN] - needle;\n        if (cmp === 0) {\n            found = true;\n            return mid;\n        }\n        if (cmp < 0) {\n            low = mid + 1;\n        }\n        else {\n            high = mid - 1;\n        }\n    }\n    found = false;\n    return low - 1;\n}\nfunction upperBound(haystack, needle, index) {\n    for (let i = index + 1; i < haystack.length; index = i++) {\n        if (haystack[i][COLUMN] !== needle)\n            break;\n    }\n    return index;\n}\nfunction lowerBound(haystack, needle, index) {\n    for (let i = index - 1; i >= 0; index = i--) {\n        if (haystack[i][COLUMN] !== needle)\n            break;\n    }\n    return index;\n}\nfunction memoizedState() {\n    return {\n        lastKey: -1,\n        lastNeedle: -1,\n        lastIndex: -1,\n    };\n}\n/**\n * This overly complicated beast is just to record the last tested line/column and the resulting\n * index, allowing us to skip a few tests if mappings are monotonically increasing.\n */\nfunction memoizedBinarySearch(haystack, needle, state, key) {\n    const { lastKey, lastNeedle, lastIndex } = state;\n    let low = 0;\n    let high = haystack.length - 1;\n    if (key === lastKey) {\n        if (needle === lastNeedle) {\n            found = lastIndex !== -1 && haystack[lastIndex][COLUMN] === needle;\n            return lastIndex;\n        }\n        if (needle >= lastNeedle) {\n            // lastIndex may be -1 if the previous needle was not found.\n            low = lastIndex === -1 ? 0 : lastIndex;\n        }\n        else {\n            high = lastIndex;\n        }\n    }\n    state.lastKey = key;\n    state.lastNeedle = needle;\n    return (state.lastIndex = binarySearch(haystack, needle, low, high));\n}\n\nconst LINE_GTR_ZERO = '`line` must be greater than 0 (lines start at line 1)';\nconst COL_GTR_EQ_ZERO = '`column` must be greater than or equal to 0 (columns start at column 0)';\nconst LEAST_UPPER_BOUND = -1;\nconst GREATEST_LOWER_BOUND = 1;\n/**\n * Returns the decoded (array of lines of segments) form of the SourceMap's mappings field.\n */\nlet decodedMappings;\n/**\n * A low-level API to find the segment associated with a generated line/column (think, from a\n * stack trace). Line and column here are 0-based, unlike `originalPositionFor`.\n */\nlet traceSegment;\n/**\n * A higher-level API to find the source/line/column associated with a generated line/column\n * (think, from a stack trace). Line is 1-based, but column is 0-based, due to legacy behavior in\n * `source-map` library.\n */\nlet originalPositionFor$1;\nclass TraceMap {\n    constructor(map, mapUrl) {\n        const isString = typeof map === 'string';\n        if (!isString && map._decodedMemo)\n            return map;\n        const parsed = (isString ? JSON.parse(map) : map);\n        const { version, file, names, sourceRoot, sources, sourcesContent } = parsed;\n        this.version = version;\n        this.file = file;\n        this.names = names;\n        this.sourceRoot = sourceRoot;\n        this.sources = sources;\n        this.sourcesContent = sourcesContent;\n        const from = resolve$1(sourceRoot || '', stripFilename(mapUrl));\n        this.resolvedSources = sources.map((s) => resolve$1(s || '', from));\n        const { mappings } = parsed;\n        if (typeof mappings === 'string') {\n            this._encoded = mappings;\n            this._decoded = undefined;\n        }\n        else {\n            this._encoded = undefined;\n            this._decoded = maybeSort(mappings, isString);\n        }\n        this._decodedMemo = memoizedState();\n        this._bySources = undefined;\n        this._bySourceMemos = undefined;\n    }\n}\n(() => {\n    decodedMappings = (map) => {\n        return (map._decoded || (map._decoded = decode(map._encoded)));\n    };\n    traceSegment = (map, line, column) => {\n        const decoded = decodedMappings(map);\n        // It's common for parent source maps to have pointers to lines that have no\n        // mapping (like a \"//# sourceMappingURL=\") at the end of the child file.\n        if (line >= decoded.length)\n            return null;\n        const segments = decoded[line];\n        const index = traceSegmentInternal(segments, map._decodedMemo, line, column, GREATEST_LOWER_BOUND);\n        return index === -1 ? null : segments[index];\n    };\n    originalPositionFor$1 = (map, { line, column, bias }) => {\n        line--;\n        if (line < 0)\n            throw new Error(LINE_GTR_ZERO);\n        if (column < 0)\n            throw new Error(COL_GTR_EQ_ZERO);\n        const decoded = decodedMappings(map);\n        // It's common for parent source maps to have pointers to lines that have no\n        // mapping (like a \"//# sourceMappingURL=\") at the end of the child file.\n        if (line >= decoded.length)\n            return OMapping(null, null, null, null);\n        const segments = decoded[line];\n        const index = traceSegmentInternal(segments, map._decodedMemo, line, column, bias || GREATEST_LOWER_BOUND);\n        if (index === -1)\n            return OMapping(null, null, null, null);\n        const segment = segments[index];\n        if (segment.length === 1)\n            return OMapping(null, null, null, null);\n        const { names, resolvedSources } = map;\n        return OMapping(resolvedSources[segment[SOURCES_INDEX]], segment[SOURCE_LINE] + 1, segment[SOURCE_COLUMN], segment.length === 5 ? names[segment[NAMES_INDEX]] : null);\n    };\n})();\nfunction OMapping(source, line, column, name) {\n    return { source, line, column, name };\n}\nfunction traceSegmentInternal(segments, memo, line, column, bias) {\n    let index = memoizedBinarySearch(segments, column, memo, line);\n    if (found) {\n        index = (bias === LEAST_UPPER_BOUND ? upperBound : lowerBound)(segments, column, index);\n    }\n    else if (bias === LEAST_UPPER_BOUND)\n        index++;\n    if (index === -1 || index === segments.length)\n        return -1;\n    return index;\n}\n\n/**\n * Gets the index associated with `key` in the backing array, if it is already present.\n */\nlet get;\n/**\n * Puts `key` into the backing array, if it is not already present. Returns\n * the index of the `key` in the backing array.\n */\nlet put;\n/**\n * SetArray acts like a `Set` (allowing only one occurrence of a string `key`), but provides the\n * index of the `key` in the backing array.\n *\n * This is designed to allow synchronizing a second array with the contents of the backing array,\n * like how in a sourcemap `sourcesContent[i]` is the source content associated with `source[i]`,\n * and there are never duplicates.\n */\nclass SetArray {\n    constructor() {\n        this._indexes = { __proto__: null };\n        this.array = [];\n    }\n}\n(() => {\n    get = (strarr, key) => strarr._indexes[key];\n    put = (strarr, key) => {\n        // The key may or may not be present. If it is present, it's a number.\n        const index = get(strarr, key);\n        if (index !== undefined)\n            return index;\n        const { array, _indexes: indexes } = strarr;\n        return (indexes[key] = array.push(key) - 1);\n    };\n})();\n\n/**\n * A low-level API to associate a generated position with an original source position. Line and\n * column here are 0-based, unlike `addMapping`.\n */\nlet addSegment;\n/**\n * Adds/removes the content of the source file to the source map.\n */\nlet setSourceContent;\n/**\n * Returns a sourcemap object (with decoded mappings) suitable for passing to a library that expects\n * a sourcemap, or to JSON.stringify.\n */\nlet decodedMap;\n/**\n * Returns a sourcemap object (with encoded mappings) suitable for passing to a library that expects\n * a sourcemap, or to JSON.stringify.\n */\nlet encodedMap;\n/**\n * Provides the state to generate a sourcemap.\n */\nclass GenMapping {\n    constructor({ file, sourceRoot } = {}) {\n        this._names = new SetArray();\n        this._sources = new SetArray();\n        this._sourcesContent = [];\n        this._mappings = [];\n        this.file = file;\n        this.sourceRoot = sourceRoot;\n    }\n}\n(() => {\n    addSegment = (map, genLine, genColumn, source, sourceLine, sourceColumn, name) => {\n        const { _mappings: mappings, _sources: sources, _sourcesContent: sourcesContent, _names: names, } = map;\n        const line = getLine(mappings, genLine);\n        if (source == null) {\n            const seg = [genColumn];\n            const index = getColumnIndex(line, genColumn, seg);\n            return insert(line, index, seg);\n        }\n        const sourcesIndex = put(sources, source);\n        const seg = name\n            ? [genColumn, sourcesIndex, sourceLine, sourceColumn, put(names, name)]\n            : [genColumn, sourcesIndex, sourceLine, sourceColumn];\n        const index = getColumnIndex(line, genColumn, seg);\n        if (sourcesIndex === sourcesContent.length)\n            sourcesContent[sourcesIndex] = null;\n        insert(line, index, seg);\n    };\n    setSourceContent = (map, source, content) => {\n        const { _sources: sources, _sourcesContent: sourcesContent } = map;\n        sourcesContent[put(sources, source)] = content;\n    };\n    decodedMap = (map) => {\n        const { file, sourceRoot, _mappings: mappings, _sources: sources, _sourcesContent: sourcesContent, _names: names, } = map;\n        return {\n            version: 3,\n            file,\n            names: names.array,\n            sourceRoot: sourceRoot || undefined,\n            sources: sources.array,\n            sourcesContent,\n            mappings,\n        };\n    };\n    encodedMap = (map) => {\n        const decoded = decodedMap(map);\n        return Object.assign(Object.assign({}, decoded), { mappings: encode$1(decoded.mappings) });\n    };\n})();\nfunction getLine(mappings, index) {\n    for (let i = mappings.length; i <= index; i++) {\n        mappings[i] = [];\n    }\n    return mappings[index];\n}\nfunction getColumnIndex(line, column, seg) {\n    let index = line.length;\n    for (let i = index - 1; i >= 0; i--, index--) {\n        const current = line[i];\n        const col = current[0];\n        if (col > column)\n            continue;\n        if (col < column)\n            break;\n        const cmp = compare$1(current, seg);\n        if (cmp === 0)\n            return index;\n        if (cmp < 0)\n            break;\n    }\n    return index;\n}\nfunction compare$1(a, b) {\n    let cmp = compareNum(a.length, b.length);\n    if (cmp !== 0)\n        return cmp;\n    // We've already checked genColumn\n    if (a.length === 1)\n        return 0;\n    cmp = compareNum(a[1], b[1]);\n    if (cmp !== 0)\n        return cmp;\n    cmp = compareNum(a[2], b[2]);\n    if (cmp !== 0)\n        return cmp;\n    cmp = compareNum(a[3], b[3]);\n    if (cmp !== 0)\n        return cmp;\n    if (a.length === 4)\n        return 0;\n    return compareNum(a[4], b[4]);\n}\nfunction compareNum(a, b) {\n    return a - b;\n}\nfunction insert(array, index, value) {\n    if (index === -1)\n        return;\n    for (let i = array.length; i > index; i--) {\n        array[i] = array[i - 1];\n    }\n    array[index] = value;\n}\n\nconst SOURCELESS_MAPPING = {\n    source: null,\n    column: null,\n    line: null,\n    name: null,\n    content: null,\n};\nconst EMPTY_SOURCES = [];\nfunction Source(map, sources, source, content) {\n    return {\n        map,\n        sources,\n        source,\n        content,\n    };\n}\n/**\n * MapSource represents a single sourcemap, with the ability to trace mappings into its child nodes\n * (which may themselves be SourceMapTrees).\n */\nfunction MapSource(map, sources) {\n    return Source(map, sources, '', null);\n}\n/**\n * A \"leaf\" node in the sourcemap tree, representing an original, unmodified source file. Recursive\n * segment tracing ends at the `OriginalSource`.\n */\nfunction OriginalSource(source, content) {\n    return Source(null, EMPTY_SOURCES, source, content);\n}\n/**\n * traceMappings is only called on the root level SourceMapTree, and begins the process of\n * resolving each mapping in terms of the original source files.\n */\nfunction traceMappings(tree) {\n    const gen = new GenMapping({ file: tree.map.file });\n    const { sources: rootSources, map } = tree;\n    const rootNames = map.names;\n    const rootMappings = decodedMappings(map);\n    for (let i = 0; i < rootMappings.length; i++) {\n        const segments = rootMappings[i];\n        let lastSource = null;\n        let lastSourceLine = null;\n        let lastSourceColumn = null;\n        for (let j = 0; j < segments.length; j++) {\n            const segment = segments[j];\n            const genCol = segment[0];\n            let traced = SOURCELESS_MAPPING;\n            // 1-length segments only move the current generated column, there's no source information\n            // to gather from it.\n            if (segment.length !== 1) {\n                const source = rootSources[segment[1]];\n                traced = originalPositionFor(source, segment[2], segment[3], segment.length === 5 ? rootNames[segment[4]] : '');\n                // If the trace is invalid, then the trace ran into a sourcemap that doesn't contain a\n                // respective segment into an original source.\n                if (traced == null)\n                    continue;\n            }\n            // So we traced a segment down into its original source file. Now push a\n            // new segment pointing to this location.\n            const { column, line, name, content, source } = traced;\n            if (line === lastSourceLine && column === lastSourceColumn && source === lastSource) {\n                continue;\n            }\n            lastSourceLine = line;\n            lastSourceColumn = column;\n            lastSource = source;\n            // Sigh, TypeScript can't figure out source/line/column are either all null, or all non-null...\n            addSegment(gen, i, genCol, source, line, column, name);\n            if (content != null)\n                setSourceContent(gen, source, content);\n        }\n    }\n    return gen;\n}\n/**\n * originalPositionFor is only called on children SourceMapTrees. It recurses down into its own\n * child SourceMapTrees, until we find the original source map.\n */\nfunction originalPositionFor(source, line, column, name) {\n    if (!source.map) {\n        return { column, line, name, source: source.source, content: source.content };\n    }\n    const segment = traceSegment(source.map, line, column);\n    // If we couldn't find a segment, then this doesn't exist in the sourcemap.\n    if (segment == null)\n        return null;\n    // 1-length segments only move the current generated column, there's no source information\n    // to gather from it.\n    if (segment.length === 1)\n        return SOURCELESS_MAPPING;\n    return originalPositionFor(source.sources[segment[1]], segment[2], segment[3], segment.length === 5 ? source.map.names[segment[4]] : name);\n}\n\nfunction asArray(value) {\n    if (Array.isArray(value))\n        return value;\n    return [value];\n}\n/**\n * Recursively builds a tree structure out of sourcemap files, with each node\n * being either an `OriginalSource` \"leaf\" or a `SourceMapTree` composed of\n * `OriginalSource`s and `SourceMapTree`s.\n *\n * Every sourcemap is composed of a collection of source files and mappings\n * into locations of those source files. When we generate a `SourceMapTree` for\n * the sourcemap, we attempt to load each source file's own sourcemap. If it\n * does not have an associated sourcemap, it is considered an original,\n * unmodified source file.\n */\nfunction buildSourceMapTree(input, loader) {\n    const maps = asArray(input).map((m) => new TraceMap(m, ''));\n    const map = maps.pop();\n    for (let i = 0; i < maps.length; i++) {\n        if (maps[i].sources.length > 1) {\n            throw new Error(`Transformation map ${i} must have exactly one source file.\\n` +\n                'Did you specify these with the most recent transformation maps first?');\n        }\n    }\n    let tree = build$2(map, loader, '', 0);\n    for (let i = maps.length - 1; i >= 0; i--) {\n        tree = MapSource(maps[i], [tree]);\n    }\n    return tree;\n}\nfunction build$2(map, loader, importer, importerDepth) {\n    const { resolvedSources, sourcesContent } = map;\n    const depth = importerDepth + 1;\n    const children = resolvedSources.map((sourceFile, i) => {\n        // The loading context gives the loader more information about why this file is being loaded\n        // (eg, from which importer). It also allows the loader to override the location of the loaded\n        // sourcemap/original source, or to override the content in the sourcesContent field if it's\n        // an unmodified source file.\n        const ctx = {\n            importer,\n            depth,\n            source: sourceFile || '',\n            content: undefined,\n        };\n        // Use the provided loader callback to retrieve the file's sourcemap.\n        // TODO: We should eventually support async loading of sourcemap files.\n        const sourceMap = loader(ctx.source, ctx);\n        const { source, content } = ctx;\n        // If there is a sourcemap, then we need to recurse into it to load its source files.\n        if (sourceMap)\n            return build$2(new TraceMap(sourceMap, source), loader, source, depth);\n        // Else, it's an an unmodified source file.\n        // The contents of this unmodified source file can be overridden via the loader context,\n        // allowing it to be explicitly null or a string. If it remains undefined, we fall back to\n        // the importing sourcemap's `sourcesContent` field.\n        const sourceContent = content !== undefined ? content : sourcesContent ? sourcesContent[i] : null;\n        return OriginalSource(source, sourceContent);\n    });\n    return MapSource(map, children);\n}\n\n/**\n * A SourceMap v3 compatible sourcemap, which only includes fields that were\n * provided to it.\n */\nclass SourceMap {\n    constructor(map, options) {\n        const out = options.decodedMappings ? decodedMap(map) : encodedMap(map);\n        this.version = out.version; // SourceMap spec says this should be first.\n        this.file = out.file;\n        this.mappings = out.mappings;\n        this.names = out.names;\n        this.sourceRoot = out.sourceRoot;\n        this.sources = out.sources;\n        if (!options.excludeContent) {\n            this.sourcesContent = out.sourcesContent;\n        }\n    }\n    toString() {\n        return JSON.stringify(this);\n    }\n}\n\n/**\n * Traces through all the mappings in the root sourcemap, through the sources\n * (and their sourcemaps), all the way back to the original source location.\n *\n * `loader` will be called every time we encounter a source file. If it returns\n * a sourcemap, we will recurse into that sourcemap to continue the trace. If\n * it returns a falsey value, that source file is treated as an original,\n * unmodified source file.\n *\n * Pass `excludeContent` to exclude any self-containing source file content\n * from the output sourcemap.\n *\n * Pass `decodedMappings` to receive a SourceMap with decoded (instead of\n * VLQ encoded) mappings.\n */\nfunction remapping(input, loader, options) {\n    const opts = typeof options === 'object' ? options : { excludeContent: !!options, decodedMappings: false };\n    const tree = buildSourceMapTree(input, loader);\n    return new SourceMap(traceMappings(tree), opts);\n}\n\nvar srcExports$1 = {};\nvar src$2 = {\n  get exports(){ return srcExports$1; },\n  set exports(v){ srcExports$1 = v; },\n};\n\nvar browserExports$1 = {};\nvar browser$2 = {\n  get exports(){ return browserExports$1; },\n  set exports(v){ browserExports$1 = v; },\n};\n\n/**\n * Helpers.\n */\n\nvar ms$1;\nvar hasRequiredMs$1;\n\nfunction requireMs$1 () {\n\tif (hasRequiredMs$1) return ms$1;\n\thasRequiredMs$1 = 1;\n\tvar s = 1000;\n\tvar m = s * 60;\n\tvar h = m * 60;\n\tvar d = h * 24;\n\tvar w = d * 7;\n\tvar y = d * 365.25;\n\n\t/**\n\t * Parse or format the given `val`.\n\t *\n\t * Options:\n\t *\n\t *  - `long` verbose formatting [false]\n\t *\n\t * @param {String|Number} val\n\t * @param {Object} [options]\n\t * @throws {Error} throw an error if val is not a non-empty string or a number\n\t * @return {String|Number}\n\t * @api public\n\t */\n\n\tms$1 = function(val, options) {\n\t  options = options || {};\n\t  var type = typeof val;\n\t  if (type === 'string' && val.length > 0) {\n\t    return parse(val);\n\t  } else if (type === 'number' && isFinite(val)) {\n\t    return options.long ? fmtLong(val) : fmtShort(val);\n\t  }\n\t  throw new Error(\n\t    'val is not a non-empty string or a valid number. val=' +\n\t      JSON.stringify(val)\n\t  );\n\t};\n\n\t/**\n\t * Parse the given `str` and return milliseconds.\n\t *\n\t * @param {String} str\n\t * @return {Number}\n\t * @api private\n\t */\n\n\tfunction parse(str) {\n\t  str = String(str);\n\t  if (str.length > 100) {\n\t    return;\n\t  }\n\t  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n\t    str\n\t  );\n\t  if (!match) {\n\t    return;\n\t  }\n\t  var n = parseFloat(match[1]);\n\t  var type = (match[2] || 'ms').toLowerCase();\n\t  switch (type) {\n\t    case 'years':\n\t    case 'year':\n\t    case 'yrs':\n\t    case 'yr':\n\t    case 'y':\n\t      return n * y;\n\t    case 'weeks':\n\t    case 'week':\n\t    case 'w':\n\t      return n * w;\n\t    case 'days':\n\t    case 'day':\n\t    case 'd':\n\t      return n * d;\n\t    case 'hours':\n\t    case 'hour':\n\t    case 'hrs':\n\t    case 'hr':\n\t    case 'h':\n\t      return n * h;\n\t    case 'minutes':\n\t    case 'minute':\n\t    case 'mins':\n\t    case 'min':\n\t    case 'm':\n\t      return n * m;\n\t    case 'seconds':\n\t    case 'second':\n\t    case 'secs':\n\t    case 'sec':\n\t    case 's':\n\t      return n * s;\n\t    case 'milliseconds':\n\t    case 'millisecond':\n\t    case 'msecs':\n\t    case 'msec':\n\t    case 'ms':\n\t      return n;\n\t    default:\n\t      return undefined;\n\t  }\n\t}\n\n\t/**\n\t * Short format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\n\tfunction fmtShort(ms) {\n\t  var msAbs = Math.abs(ms);\n\t  if (msAbs >= d) {\n\t    return Math.round(ms / d) + 'd';\n\t  }\n\t  if (msAbs >= h) {\n\t    return Math.round(ms / h) + 'h';\n\t  }\n\t  if (msAbs >= m) {\n\t    return Math.round(ms / m) + 'm';\n\t  }\n\t  if (msAbs >= s) {\n\t    return Math.round(ms / s) + 's';\n\t  }\n\t  return ms + 'ms';\n\t}\n\n\t/**\n\t * Long format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\n\tfunction fmtLong(ms) {\n\t  var msAbs = Math.abs(ms);\n\t  if (msAbs >= d) {\n\t    return plural(ms, msAbs, d, 'day');\n\t  }\n\t  if (msAbs >= h) {\n\t    return plural(ms, msAbs, h, 'hour');\n\t  }\n\t  if (msAbs >= m) {\n\t    return plural(ms, msAbs, m, 'minute');\n\t  }\n\t  if (msAbs >= s) {\n\t    return plural(ms, msAbs, s, 'second');\n\t  }\n\t  return ms + ' ms';\n\t}\n\n\t/**\n\t * Pluralization helper.\n\t */\n\n\tfunction plural(ms, msAbs, n, name) {\n\t  var isPlural = msAbs >= n * 1.5;\n\t  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n\t}\n\treturn ms$1;\n}\n\nvar common$b;\nvar hasRequiredCommon;\n\nfunction requireCommon () {\n\tif (hasRequiredCommon) return common$b;\n\thasRequiredCommon = 1;\n\t/**\n\t * This is the common logic for both the Node.js and web browser\n\t * implementations of `debug()`.\n\t */\n\n\tfunction setup(env) {\n\t\tcreateDebug.debug = createDebug;\n\t\tcreateDebug.default = createDebug;\n\t\tcreateDebug.coerce = coerce;\n\t\tcreateDebug.disable = disable;\n\t\tcreateDebug.enable = enable;\n\t\tcreateDebug.enabled = enabled;\n\t\tcreateDebug.humanize = requireMs$1();\n\t\tcreateDebug.destroy = destroy;\n\n\t\tObject.keys(env).forEach(key => {\n\t\t\tcreateDebug[key] = env[key];\n\t\t});\n\n\t\t/**\n\t\t* The currently active debug mode names, and names to skip.\n\t\t*/\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\t/**\n\t\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t\t*\n\t\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t\t*/\n\t\tcreateDebug.formatters = {};\n\n\t\t/**\n\t\t* Selects a color for a debug namespace\n\t\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t\t* @return {Number|String} An ANSI color code for the given namespace\n\t\t* @api private\n\t\t*/\n\t\tfunction selectColor(namespace) {\n\t\t\tlet hash = 0;\n\n\t\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\t\thash |= 0; // Convert to 32bit integer\n\t\t\t}\n\n\t\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t\t}\n\t\tcreateDebug.selectColor = selectColor;\n\n\t\t/**\n\t\t* Create a debugger with the given `namespace`.\n\t\t*\n\t\t* @param {String} namespace\n\t\t* @return {Function}\n\t\t* @api public\n\t\t*/\n\t\tfunction createDebug(namespace) {\n\t\t\tlet prevTime;\n\t\t\tlet enableOverride = null;\n\t\t\tlet namespacesCache;\n\t\t\tlet enabledCache;\n\n\t\t\tfunction debug(...args) {\n\t\t\t\t// Disabled?\n\t\t\t\tif (!debug.enabled) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tconst self = debug;\n\n\t\t\t\t// Set `diff` timestamp\n\t\t\t\tconst curr = Number(new Date());\n\t\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\t\tself.diff = ms;\n\t\t\t\tself.prev = prevTime;\n\t\t\t\tself.curr = curr;\n\t\t\t\tprevTime = curr;\n\n\t\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\t\targs.unshift('%O');\n\t\t\t\t}\n\n\t\t\t\t// Apply any `formatters` transformations\n\t\t\t\tlet index = 0;\n\t\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\t\tif (match === '%%') {\n\t\t\t\t\t\treturn '%';\n\t\t\t\t\t}\n\t\t\t\t\tindex++;\n\t\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\t\tconst val = args[index];\n\t\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\t\tindex--;\n\t\t\t\t\t}\n\t\t\t\t\treturn match;\n\t\t\t\t});\n\n\t\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\t\tlogFn.apply(self, args);\n\t\t\t}\n\n\t\t\tdebug.namespace = namespace;\n\t\t\tdebug.useColors = createDebug.useColors();\n\t\t\tdebug.color = createDebug.selectColor(namespace);\n\t\t\tdebug.extend = extend;\n\t\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\t\tenumerable: true,\n\t\t\t\tconfigurable: false,\n\t\t\t\tget: () => {\n\t\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\t\treturn enableOverride;\n\t\t\t\t\t}\n\t\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t\t}\n\n\t\t\t\t\treturn enabledCache;\n\t\t\t\t},\n\t\t\t\tset: v => {\n\t\t\t\t\tenableOverride = v;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\t// Env-specific initialization logic for debug instances\n\t\t\tif (typeof createDebug.init === 'function') {\n\t\t\t\tcreateDebug.init(debug);\n\t\t\t}\n\n\t\t\treturn debug;\n\t\t}\n\n\t\tfunction extend(namespace, delimiter) {\n\t\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\t\tnewDebug.log = this.log;\n\t\t\treturn newDebug;\n\t\t}\n\n\t\t/**\n\t\t* Enables a debug mode by namespaces. This can include modes\n\t\t* separated by a colon and wildcards.\n\t\t*\n\t\t* @param {String} namespaces\n\t\t* @api public\n\t\t*/\n\t\tfunction enable(namespaces) {\n\t\t\tcreateDebug.save(namespaces);\n\t\t\tcreateDebug.namespaces = namespaces;\n\n\t\t\tcreateDebug.names = [];\n\t\t\tcreateDebug.skips = [];\n\n\t\t\tlet i;\n\t\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\t\tconst len = split.length;\n\n\t\t\tfor (i = 0; i < len; i++) {\n\t\t\t\tif (!split[i]) {\n\t\t\t\t\t// ignore empty strings\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\t\tif (namespaces[0] === '-') {\n\t\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t\t} else {\n\t\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t* Disable debug output.\n\t\t*\n\t\t* @return {String} namespaces\n\t\t* @api public\n\t\t*/\n\t\tfunction disable() {\n\t\t\tconst namespaces = [\n\t\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t\t].join(',');\n\t\t\tcreateDebug.enable('');\n\t\t\treturn namespaces;\n\t\t}\n\n\t\t/**\n\t\t* Returns true if the given mode name is enabled, false otherwise.\n\t\t*\n\t\t* @param {String} name\n\t\t* @return {Boolean}\n\t\t* @api public\n\t\t*/\n\t\tfunction enabled(name) {\n\t\t\tif (name[name.length - 1] === '*') {\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\tlet i;\n\t\t\tlet len;\n\n\t\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn false;\n\t\t}\n\n\t\t/**\n\t\t* Convert regexp to namespace\n\t\t*\n\t\t* @param {RegExp} regxep\n\t\t* @return {String} namespace\n\t\t* @api private\n\t\t*/\n\t\tfunction toNamespace(regexp) {\n\t\t\treturn regexp.toString()\n\t\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t\t}\n\n\t\t/**\n\t\t* Coerce `val`.\n\t\t*\n\t\t* @param {Mixed} val\n\t\t* @return {Mixed}\n\t\t* @api private\n\t\t*/\n\t\tfunction coerce(val) {\n\t\t\tif (val instanceof Error) {\n\t\t\t\treturn val.stack || val.message;\n\t\t\t}\n\t\t\treturn val;\n\t\t}\n\n\t\t/**\n\t\t* XXX DO NOT USE. This is a temporary stub function.\n\t\t* XXX It WILL be removed in the next major release.\n\t\t*/\n\t\tfunction destroy() {\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\n\t\tcreateDebug.enable(createDebug.load());\n\n\t\treturn createDebug;\n\t}\n\n\tcommon$b = setup;\n\treturn common$b;\n}\n\n/* eslint-env browser */\n\nvar hasRequiredBrowser$1;\n\nfunction requireBrowser$1 () {\n\tif (hasRequiredBrowser$1) return browserExports$1;\n\thasRequiredBrowser$1 = 1;\n\t(function (module, exports) {\n\t\t/**\n\t\t * This is the web browser implementation of `debug()`.\n\t\t */\n\n\t\texports.formatArgs = formatArgs;\n\t\texports.save = save;\n\t\texports.load = load;\n\t\texports.useColors = useColors;\n\t\texports.storage = localstorage();\n\t\texports.destroy = (() => {\n\t\t\tlet warned = false;\n\n\t\t\treturn () => {\n\t\t\t\tif (!warned) {\n\t\t\t\t\twarned = true;\n\t\t\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t\t\t}\n\t\t\t};\n\t\t})();\n\n\t\t/**\n\t\t * Colors.\n\t\t */\n\n\t\texports.colors = [\n\t\t\t'#0000CC',\n\t\t\t'#0000FF',\n\t\t\t'#0033CC',\n\t\t\t'#0033FF',\n\t\t\t'#0066CC',\n\t\t\t'#0066FF',\n\t\t\t'#0099CC',\n\t\t\t'#0099FF',\n\t\t\t'#00CC00',\n\t\t\t'#00CC33',\n\t\t\t'#00CC66',\n\t\t\t'#00CC99',\n\t\t\t'#00CCCC',\n\t\t\t'#00CCFF',\n\t\t\t'#3300CC',\n\t\t\t'#3300FF',\n\t\t\t'#3333CC',\n\t\t\t'#3333FF',\n\t\t\t'#3366CC',\n\t\t\t'#3366FF',\n\t\t\t'#3399CC',\n\t\t\t'#3399FF',\n\t\t\t'#33CC00',\n\t\t\t'#33CC33',\n\t\t\t'#33CC66',\n\t\t\t'#33CC99',\n\t\t\t'#33CCCC',\n\t\t\t'#33CCFF',\n\t\t\t'#6600CC',\n\t\t\t'#6600FF',\n\t\t\t'#6633CC',\n\t\t\t'#6633FF',\n\t\t\t'#66CC00',\n\t\t\t'#66CC33',\n\t\t\t'#9900CC',\n\t\t\t'#9900FF',\n\t\t\t'#9933CC',\n\t\t\t'#9933FF',\n\t\t\t'#99CC00',\n\t\t\t'#99CC33',\n\t\t\t'#CC0000',\n\t\t\t'#CC0033',\n\t\t\t'#CC0066',\n\t\t\t'#CC0099',\n\t\t\t'#CC00CC',\n\t\t\t'#CC00FF',\n\t\t\t'#CC3300',\n\t\t\t'#CC3333',\n\t\t\t'#CC3366',\n\t\t\t'#CC3399',\n\t\t\t'#CC33CC',\n\t\t\t'#CC33FF',\n\t\t\t'#CC6600',\n\t\t\t'#CC6633',\n\t\t\t'#CC9900',\n\t\t\t'#CC9933',\n\t\t\t'#CCCC00',\n\t\t\t'#CCCC33',\n\t\t\t'#FF0000',\n\t\t\t'#FF0033',\n\t\t\t'#FF0066',\n\t\t\t'#FF0099',\n\t\t\t'#FF00CC',\n\t\t\t'#FF00FF',\n\t\t\t'#FF3300',\n\t\t\t'#FF3333',\n\t\t\t'#FF3366',\n\t\t\t'#FF3399',\n\t\t\t'#FF33CC',\n\t\t\t'#FF33FF',\n\t\t\t'#FF6600',\n\t\t\t'#FF6633',\n\t\t\t'#FF9900',\n\t\t\t'#FF9933',\n\t\t\t'#FFCC00',\n\t\t\t'#FFCC33'\n\t\t];\n\n\t\t/**\n\t\t * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n\t\t * and the Firebug extension (any Firefox version) are known\n\t\t * to support \"%c\" CSS customizations.\n\t\t *\n\t\t * TODO: add a `localStorage` variable to explicitly enable/disable colors\n\t\t */\n\n\t\t// eslint-disable-next-line complexity\n\t\tfunction useColors() {\n\t\t\t// NB: In an Electron preload script, document will be defined but not fully\n\t\t\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t\t\t// explicitly\n\t\t\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\t// Internet Explorer and Edge do not support colors.\n\t\t\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t\t\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\t\t\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t\t\t// Is firefox >= v31?\n\t\t\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n\t\t}\n\n\t\t/**\n\t\t * Colorize log arguments if enabled.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction formatArgs(args) {\n\t\t\targs[0] = (this.useColors ? '%c' : '') +\n\t\t\t\tthis.namespace +\n\t\t\t\t(this.useColors ? ' %c' : ' ') +\n\t\t\t\targs[0] +\n\t\t\t\t(this.useColors ? '%c ' : ' ') +\n\t\t\t\t'+' + module.exports.humanize(this.diff);\n\n\t\t\tif (!this.useColors) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst c = 'color: ' + this.color;\n\t\t\targs.splice(1, 0, c, 'color: inherit');\n\n\t\t\t// The final \"%c\" is somewhat tricky, because there could be other\n\t\t\t// arguments passed either before or after the %c, so we need to\n\t\t\t// figure out the correct index to insert the CSS into\n\t\t\tlet index = 0;\n\t\t\tlet lastC = 0;\n\t\t\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tif (match === '%c') {\n\t\t\t\t\t// We only are interested in the *last* %c\n\t\t\t\t\t// (the user may have provided their own)\n\t\t\t\t\tlastC = index;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\targs.splice(lastC, 0, c);\n\t\t}\n\n\t\t/**\n\t\t * Invokes `console.debug()` when available.\n\t\t * No-op when `console.debug` is not a \"function\".\n\t\t * If `console.debug` is not available, falls back\n\t\t * to `console.log`.\n\t\t *\n\t\t * @api public\n\t\t */\n\t\texports.log = console.debug || console.log || (() => {});\n\n\t\t/**\n\t\t * Save `namespaces`.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api private\n\t\t */\n\t\tfunction save(namespaces) {\n\t\t\ttry {\n\t\t\t\tif (namespaces) {\n\t\t\t\t\texports.storage.setItem('debug', namespaces);\n\t\t\t\t} else {\n\t\t\t\t\texports.storage.removeItem('debug');\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\t// Swallow\n\t\t\t\t// XXX (@Qix-) should we be logging these?\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Load `namespaces`.\n\t\t *\n\t\t * @return {String} returns the previously persisted debug modes\n\t\t * @api private\n\t\t */\n\t\tfunction load() {\n\t\t\tlet r;\n\t\t\ttry {\n\t\t\t\tr = exports.storage.getItem('debug');\n\t\t\t} catch (error) {\n\t\t\t\t// Swallow\n\t\t\t\t// XXX (@Qix-) should we be logging these?\n\t\t\t}\n\n\t\t\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\t\t\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\t\t\tr = process.env.DEBUG;\n\t\t\t}\n\n\t\t\treturn r;\n\t\t}\n\n\t\t/**\n\t\t * Localstorage attempts to return the localstorage.\n\t\t *\n\t\t * This is necessary because safari throws\n\t\t * when a user disables cookies/localstorage\n\t\t * and you attempt to access it.\n\t\t *\n\t\t * @return {LocalStorage}\n\t\t * @api private\n\t\t */\n\n\t\tfunction localstorage() {\n\t\t\ttry {\n\t\t\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t\t\t// The Browser also has localStorage in the global context.\n\t\t\t\treturn localStorage;\n\t\t\t} catch (error) {\n\t\t\t\t// Swallow\n\t\t\t\t// XXX (@Qix-) should we be logging these?\n\t\t\t}\n\t\t}\n\n\t\tmodule.exports = requireCommon()(exports);\n\n\t\tconst {formatters} = module.exports;\n\n\t\t/**\n\t\t * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n\t\t */\n\n\t\tformatters.j = function (v) {\n\t\t\ttry {\n\t\t\t\treturn JSON.stringify(v);\n\t\t\t} catch (error) {\n\t\t\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t\t\t}\n\t\t};\n} (browser$2, browserExports$1));\n\treturn browserExports$1;\n}\n\nvar nodeExports$1 = {};\nvar node$1 = {\n  get exports(){ return nodeExports$1; },\n  set exports(v){ nodeExports$1 = v; },\n};\n\n/**\n * Module dependencies.\n */\n\nvar hasRequiredNode$1;\n\nfunction requireNode$1 () {\n\tif (hasRequiredNode$1) return nodeExports$1;\n\thasRequiredNode$1 = 1;\n\t(function (module, exports) {\n\t\tconst tty = require$$0$3;\n\t\tconst util = require$$0$6;\n\n\t\t/**\n\t\t * This is the Node.js implementation of `debug()`.\n\t\t */\n\n\t\texports.init = init;\n\t\texports.log = log;\n\t\texports.formatArgs = formatArgs;\n\t\texports.save = save;\n\t\texports.load = load;\n\t\texports.useColors = useColors;\n\t\texports.destroy = util.deprecate(\n\t\t\t() => {},\n\t\t\t'Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.'\n\t\t);\n\n\t\t/**\n\t\t * Colors.\n\t\t */\n\n\t\texports.colors = [6, 2, 3, 4, 5, 1];\n\n\t\ttry {\n\t\t\t// Optional dependency (as in, doesn't need to be installed, NOT like optionalDependencies in package.json)\n\t\t\t// eslint-disable-next-line import/no-extraneous-dependencies\n\t\t\tconst supportsColor = require('supports-color');\n\n\t\t\tif (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {\n\t\t\t\texports.colors = [\n\t\t\t\t\t20,\n\t\t\t\t\t21,\n\t\t\t\t\t26,\n\t\t\t\t\t27,\n\t\t\t\t\t32,\n\t\t\t\t\t33,\n\t\t\t\t\t38,\n\t\t\t\t\t39,\n\t\t\t\t\t40,\n\t\t\t\t\t41,\n\t\t\t\t\t42,\n\t\t\t\t\t43,\n\t\t\t\t\t44,\n\t\t\t\t\t45,\n\t\t\t\t\t56,\n\t\t\t\t\t57,\n\t\t\t\t\t62,\n\t\t\t\t\t63,\n\t\t\t\t\t68,\n\t\t\t\t\t69,\n\t\t\t\t\t74,\n\t\t\t\t\t75,\n\t\t\t\t\t76,\n\t\t\t\t\t77,\n\t\t\t\t\t78,\n\t\t\t\t\t79,\n\t\t\t\t\t80,\n\t\t\t\t\t81,\n\t\t\t\t\t92,\n\t\t\t\t\t93,\n\t\t\t\t\t98,\n\t\t\t\t\t99,\n\t\t\t\t\t112,\n\t\t\t\t\t113,\n\t\t\t\t\t128,\n\t\t\t\t\t129,\n\t\t\t\t\t134,\n\t\t\t\t\t135,\n\t\t\t\t\t148,\n\t\t\t\t\t149,\n\t\t\t\t\t160,\n\t\t\t\t\t161,\n\t\t\t\t\t162,\n\t\t\t\t\t163,\n\t\t\t\t\t164,\n\t\t\t\t\t165,\n\t\t\t\t\t166,\n\t\t\t\t\t167,\n\t\t\t\t\t168,\n\t\t\t\t\t169,\n\t\t\t\t\t170,\n\t\t\t\t\t171,\n\t\t\t\t\t172,\n\t\t\t\t\t173,\n\t\t\t\t\t178,\n\t\t\t\t\t179,\n\t\t\t\t\t184,\n\t\t\t\t\t185,\n\t\t\t\t\t196,\n\t\t\t\t\t197,\n\t\t\t\t\t198,\n\t\t\t\t\t199,\n\t\t\t\t\t200,\n\t\t\t\t\t201,\n\t\t\t\t\t202,\n\t\t\t\t\t203,\n\t\t\t\t\t204,\n\t\t\t\t\t205,\n\t\t\t\t\t206,\n\t\t\t\t\t207,\n\t\t\t\t\t208,\n\t\t\t\t\t209,\n\t\t\t\t\t214,\n\t\t\t\t\t215,\n\t\t\t\t\t220,\n\t\t\t\t\t221\n\t\t\t\t];\n\t\t\t}\n\t\t} catch (error) {\n\t\t\t// Swallow - we only care if `supports-color` is available; it doesn't have to be.\n\t\t}\n\n\t\t/**\n\t\t * Build up the default `inspectOpts` object from the environment variables.\n\t\t *\n\t\t *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n\t\t */\n\n\t\texports.inspectOpts = Object.keys(process.env).filter(key => {\n\t\t\treturn /^debug_/i.test(key);\n\t\t}).reduce((obj, key) => {\n\t\t\t// Camel-case\n\t\t\tconst prop = key\n\t\t\t\t.substring(6)\n\t\t\t\t.toLowerCase()\n\t\t\t\t.replace(/_([a-z])/g, (_, k) => {\n\t\t\t\t\treturn k.toUpperCase();\n\t\t\t\t});\n\n\t\t\t// Coerce string value into JS value\n\t\t\tlet val = process.env[key];\n\t\t\tif (/^(yes|on|true|enabled)$/i.test(val)) {\n\t\t\t\tval = true;\n\t\t\t} else if (/^(no|off|false|disabled)$/i.test(val)) {\n\t\t\t\tval = false;\n\t\t\t} else if (val === 'null') {\n\t\t\t\tval = null;\n\t\t\t} else {\n\t\t\t\tval = Number(val);\n\t\t\t}\n\n\t\t\tobj[prop] = val;\n\t\t\treturn obj;\n\t\t}, {});\n\n\t\t/**\n\t\t * Is stdout a TTY? Colored output is enabled when `true`.\n\t\t */\n\n\t\tfunction useColors() {\n\t\t\treturn 'colors' in exports.inspectOpts ?\n\t\t\t\tBoolean(exports.inspectOpts.colors) :\n\t\t\t\ttty.isatty(process.stderr.fd);\n\t\t}\n\n\t\t/**\n\t\t * Adds ANSI color escape codes if enabled.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction formatArgs(args) {\n\t\t\tconst {namespace: name, useColors} = this;\n\n\t\t\tif (useColors) {\n\t\t\t\tconst c = this.color;\n\t\t\t\tconst colorCode = '\\u001B[3' + (c < 8 ? c : '8;5;' + c);\n\t\t\t\tconst prefix = `  ${colorCode};1m${name} \\u001B[0m`;\n\n\t\t\t\targs[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n\t\t\t\targs.push(colorCode + 'm+' + module.exports.humanize(this.diff) + '\\u001B[0m');\n\t\t\t} else {\n\t\t\t\targs[0] = getDate() + name + ' ' + args[0];\n\t\t\t}\n\t\t}\n\n\t\tfunction getDate() {\n\t\t\tif (exports.inspectOpts.hideDate) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\treturn new Date().toISOString() + ' ';\n\t\t}\n\n\t\t/**\n\t\t * Invokes `util.format()` with the specified arguments and writes to stderr.\n\t\t */\n\n\t\tfunction log(...args) {\n\t\t\treturn process.stderr.write(util.format(...args) + '\\n');\n\t\t}\n\n\t\t/**\n\t\t * Save `namespaces`.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api private\n\t\t */\n\t\tfunction save(namespaces) {\n\t\t\tif (namespaces) {\n\t\t\t\tprocess.env.DEBUG = namespaces;\n\t\t\t} else {\n\t\t\t\t// If you set a process.env field to null or undefined, it gets cast to the\n\t\t\t\t// string 'null' or 'undefined'. Just delete instead.\n\t\t\t\tdelete process.env.DEBUG;\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Load `namespaces`.\n\t\t *\n\t\t * @return {String} returns the previously persisted debug modes\n\t\t * @api private\n\t\t */\n\n\t\tfunction load() {\n\t\t\treturn process.env.DEBUG;\n\t\t}\n\n\t\t/**\n\t\t * Init logic for `debug` instances.\n\t\t *\n\t\t * Create a new `inspectOpts` object in case `useColors` is set\n\t\t * differently for a particular `debug` instance.\n\t\t */\n\n\t\tfunction init(debug) {\n\t\t\tdebug.inspectOpts = {};\n\n\t\t\tconst keys = Object.keys(exports.inspectOpts);\n\t\t\tfor (let i = 0; i < keys.length; i++) {\n\t\t\t\tdebug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];\n\t\t\t}\n\t\t}\n\n\t\tmodule.exports = requireCommon()(exports);\n\n\t\tconst {formatters} = module.exports;\n\n\t\t/**\n\t\t * Map %o to `util.inspect()`, all on a single line.\n\t\t */\n\n\t\tformatters.o = function (v) {\n\t\t\tthis.inspectOpts.colors = this.useColors;\n\t\t\treturn util.inspect(v, this.inspectOpts)\n\t\t\t\t.split('\\n')\n\t\t\t\t.map(str => str.trim())\n\t\t\t\t.join(' ');\n\t\t};\n\n\t\t/**\n\t\t * Map %O to `util.inspect()`, allowing multiple lines if needed.\n\t\t */\n\n\t\tformatters.O = function (v) {\n\t\t\tthis.inspectOpts.colors = this.useColors;\n\t\t\treturn util.inspect(v, this.inspectOpts);\n\t\t};\n} (node$1, nodeExports$1));\n\treturn nodeExports$1;\n}\n\n/**\n * Detect Electron renderer / nwjs process, which is node, but we should\n * treat as a browser.\n */\n\n(function (module) {\n\tif (typeof process === 'undefined' || process.type === 'renderer' || process.browser === true || process.__nwjs) {\n\t\tmodule.exports = requireBrowser$1();\n\t} else {\n\t\tmodule.exports = requireNode$1();\n\t}\n} (src$2));\n\nvar _debug = /*@__PURE__*/getDefaultExportFromCjs(srcExports$1);\n\nconst createFilter = createFilter$1;\nfunction slash$1(p) {\n    return p.replace(/\\\\/g, '/');\n}\n/**\n * Prepend `/@id/` and replace null byte so the id is URL-safe.\n * This is prepended to resolved ids that are not valid browser\n * import specifiers by the importAnalysis plugin.\n */\nfunction wrapId(id) {\n    return id.startsWith(VALID_ID_PREFIX)\n        ? id\n        : VALID_ID_PREFIX + id.replace('\\0', NULL_BYTE_PLACEHOLDER);\n}\n/**\n * Undo {@link wrapId}'s `/@id/` and null byte replacements.\n */\nfunction unwrapId(id) {\n    return id.startsWith(VALID_ID_PREFIX)\n        ? id.slice(VALID_ID_PREFIX.length).replace(NULL_BYTE_PLACEHOLDER, '\\0')\n        : id;\n}\nconst flattenId = (id) => id\n    .replace(/[/:]/g, '_')\n    .replace(/\\./g, '__')\n    .replace(/(\\s*>\\s*)/g, '___');\nconst normalizeId = (id) => id.replace(/(\\s*>\\s*)/g, ' > ');\n//TODO: revisit later to see if the edge case that \"compiling using node v12 code to be run in node v16 in the server\" is what we intend to support.\nconst builtins = new Set([\n    ...builtinModules,\n    'assert/strict',\n    'diagnostics_channel',\n    'dns/promises',\n    'fs/promises',\n    'path/posix',\n    'path/win32',\n    'readline/promises',\n    'stream/consumers',\n    'stream/promises',\n    'stream/web',\n    'timers/promises',\n    'util/types',\n    'wasi',\n]);\nfunction isBuiltin(id) {\n    return builtins.has(id.replace(/^node:/, ''));\n}\nfunction moduleListContains(moduleList, id) {\n    return moduleList?.some((m) => m === id || id.startsWith(m + '/'));\n}\nfunction isOptimizable(id, optimizeDeps) {\n    const { extensions } = optimizeDeps;\n    return (OPTIMIZABLE_ENTRY_RE.test(id) ||\n        (extensions?.some((ext) => id.endsWith(ext)) ?? false));\n}\nconst bareImportRE = /^[\\w@](?!.*:\\/\\/)/;\nlet isRunningWithYarnPnp;\n// TODO: use import()\nconst _require$3 = createRequire$1(import.meta.url);\ntry {\n    isRunningWithYarnPnp = Boolean(_require$3('pnpapi'));\n}\ncatch { }\nconst ssrExtensions = ['.js', '.cjs', '.json', '.node'];\nfunction resolveFrom(id, basedir, preserveSymlinks = false, ssr = false) {\n    return resolve$4.sync(id, {\n        basedir,\n        paths: [],\n        extensions: ssr ? ssrExtensions : DEFAULT_EXTENSIONS$1,\n        // necessary to work with pnpm\n        preserveSymlinks: preserveSymlinks || isRunningWithYarnPnp || false,\n    });\n}\n/**\n * like `resolveFrom` but supports resolving `>` path in `id`,\n * for example: `foo > bar > baz`\n */\nfunction nestedResolveFrom(id, basedir, preserveSymlinks = false) {\n    const pkgs = id.split('>').map((pkg) => pkg.trim());\n    try {\n        for (const pkg of pkgs) {\n            basedir = resolveFrom(pkg, basedir, preserveSymlinks);\n        }\n    }\n    catch { }\n    return basedir;\n}\n// set in bin/vite.js\nconst filter = process.env.VITE_DEBUG_FILTER;\nconst DEBUG = process.env.DEBUG;\nfunction createDebugger(namespace, options = {}) {\n    const log = _debug(namespace);\n    const { onlyWhenFocused } = options;\n    const focus = typeof onlyWhenFocused === 'string' ? onlyWhenFocused : namespace;\n    return (msg, ...args) => {\n        if (filter && !msg.includes(filter)) {\n            return;\n        }\n        if (onlyWhenFocused && !DEBUG?.includes(focus)) {\n            return;\n        }\n        log(msg, ...args);\n    };\n}\nfunction testCaseInsensitiveFS() {\n    if (!CLIENT_ENTRY.endsWith('client.mjs')) {\n        throw new Error(`cannot test case insensitive FS, CLIENT_ENTRY const doesn't contain client.mjs`);\n    }\n    if (!fs$l.existsSync(CLIENT_ENTRY)) {\n        throw new Error('cannot test case insensitive FS, CLIENT_ENTRY does not point to an existing file: ' +\n            CLIENT_ENTRY);\n    }\n    return fs$l.existsSync(CLIENT_ENTRY.replace('client.mjs', 'cLiEnT.mjs'));\n}\nconst isCaseInsensitiveFS = testCaseInsensitiveFS();\nconst isWindows$4 = os$3.platform() === 'win32';\nconst VOLUME_RE = /^[A-Z]:/i;\nfunction normalizePath$3(id) {\n    return path$o.posix.normalize(isWindows$4 ? slash$1(id) : id);\n}\nfunction fsPathFromId(id) {\n    const fsPath = normalizePath$3(id.startsWith(FS_PREFIX) ? id.slice(FS_PREFIX.length) : id);\n    return fsPath.startsWith('/') || fsPath.match(VOLUME_RE)\n        ? fsPath\n        : `/${fsPath}`;\n}\nfunction fsPathFromUrl(url) {\n    return fsPathFromId(cleanUrl(url));\n}\n/**\n * Check if dir is a parent of file\n *\n * Warning: parameters are not validated, only works with normalized absolute paths\n *\n * @param dir - normalized absolute path\n * @param file - normalized absolute path\n * @returns true if dir is a parent of file\n */\nfunction isParentDirectory(dir, file) {\n    if (!dir.endsWith('/')) {\n        dir = `${dir}/`;\n    }\n    return (file.startsWith(dir) ||\n        (isCaseInsensitiveFS && file.toLowerCase().startsWith(dir.toLowerCase())));\n}\nfunction ensureVolumeInPath(file) {\n    return isWindows$4 ? path$o.resolve(file) : file;\n}\nconst queryRE = /\\?.*$/s;\nconst hashRE = /#.*$/s;\nconst cleanUrl = (url) => url.replace(hashRE, '').replace(queryRE, '');\nconst externalRE = /^(https?:)?\\/\\//;\nconst isExternalUrl = (url) => externalRE.test(url);\nconst dataUrlRE = /^\\s*data:/i;\nconst isDataUrl = (url) => dataUrlRE.test(url);\nconst virtualModuleRE = /^virtual-module:.*/;\nconst virtualModulePrefix = 'virtual-module:';\nconst knownJsSrcRE = /\\.(?:[jt]sx?|m[jt]s|vue|marko|svelte|astro|imba)(?:$|\\?)/;\nconst isJSRequest = (url) => {\n    url = cleanUrl(url);\n    if (knownJsSrcRE.test(url)) {\n        return true;\n    }\n    if (!path$o.extname(url) && !url.endsWith('/')) {\n        return true;\n    }\n    return false;\n};\nconst knownTsRE = /\\.(?:ts|mts|cts|tsx)$/;\nconst knownTsOutputRE = /\\.(?:js|mjs|cjs|jsx)$/;\nconst isTsRequest = (url) => knownTsRE.test(url);\nconst isPossibleTsOutput = (url) => knownTsOutputRE.test(cleanUrl(url));\nfunction getPotentialTsSrcPaths(filePath) {\n    const [name, type, query = ''] = filePath.split(/(\\.(?:[cm]?js|jsx))(\\?.*)?$/);\n    const paths = [name + type.replace('js', 'ts') + query];\n    if (!type.endsWith('x')) {\n        paths.push(name + type.replace('js', 'tsx') + query);\n    }\n    return paths;\n}\nconst importQueryRE = /(\\?|&)import=?(?:&|$)/;\nconst directRequestRE$1 = /(\\?|&)direct=?(?:&|$)/;\nconst internalPrefixes = [\n    FS_PREFIX,\n    VALID_ID_PREFIX,\n    CLIENT_PUBLIC_PATH,\n    ENV_PUBLIC_PATH,\n];\nconst InternalPrefixRE = new RegExp(`^(?:${internalPrefixes.join('|')})`);\nconst trailingSeparatorRE = /[?&]$/;\nconst isImportRequest = (url) => importQueryRE.test(url);\nconst isInternalRequest = (url) => InternalPrefixRE.test(url);\nfunction removeImportQuery(url) {\n    return url.replace(importQueryRE, '$1').replace(trailingSeparatorRE, '');\n}\nfunction removeDirectQuery(url) {\n    return url.replace(directRequestRE$1, '$1').replace(trailingSeparatorRE, '');\n}\nfunction injectQuery(url, queryToInject) {\n    // encode percents for consistent behavior with pathToFileURL\n    // see #2614 for details\n    const resolvedUrl = new URL$3(url.replace(/%/g, '%25'), 'relative:///');\n    const { search, hash } = resolvedUrl;\n    let pathname = cleanUrl(url);\n    pathname = isWindows$4 ? slash$1(pathname) : pathname;\n    return `${pathname}?${queryToInject}${search ? `&` + search.slice(1) : ''}${hash ?? ''}`;\n}\nconst timestampRE = /\\bt=\\d{13}&?\\b/;\nfunction removeTimestampQuery(url) {\n    return url.replace(timestampRE, '').replace(trailingSeparatorRE, '');\n}\nasync function asyncReplace(input, re, replacer) {\n    let match;\n    let remaining = input;\n    let rewritten = '';\n    while ((match = re.exec(remaining))) {\n        rewritten += remaining.slice(0, match.index);\n        rewritten += await replacer(match);\n        remaining = remaining.slice(match.index + match[0].length);\n    }\n    rewritten += remaining;\n    return rewritten;\n}\nfunction timeFrom(start, subtract = 0) {\n    const time = performance.now() - start - subtract;\n    const timeString = (time.toFixed(2) + `ms`).padEnd(5, ' ');\n    if (time < 10) {\n        return picocolorsExports.green(timeString);\n    }\n    else if (time < 50) {\n        return picocolorsExports.yellow(timeString);\n    }\n    else {\n        return picocolorsExports.red(timeString);\n    }\n}\n/**\n * pretty url for logging.\n */\nfunction prettifyUrl(url, root) {\n    url = removeTimestampQuery(url);\n    const isAbsoluteFile = url.startsWith(root);\n    if (isAbsoluteFile || url.startsWith(FS_PREFIX)) {\n        let file = path$o.relative(root, isAbsoluteFile ? url : fsPathFromId(url));\n        const seg = file.split('/');\n        const npmIndex = seg.indexOf(`node_modules`);\n        const isSourceMap = file.endsWith('.map');\n        if (npmIndex > 0) {\n            file = seg[npmIndex + 1];\n            if (file.startsWith('@')) {\n                file = `${file}/${seg[npmIndex + 2]}`;\n            }\n            file = `npm: ${picocolorsExports.dim(file)}${isSourceMap ? ` (source map)` : ``}`;\n        }\n        return picocolorsExports.dim(file);\n    }\n    else {\n        return picocolorsExports.dim(url);\n    }\n}\nfunction isObject$1(value) {\n    return Object.prototype.toString.call(value) === '[object Object]';\n}\nfunction isDefined(value) {\n    return value != null;\n}\nfunction lookupFile(dir, formats, options) {\n    for (const format of formats) {\n        const fullPath = path$o.join(dir, format);\n        if (fs$l.existsSync(fullPath) && fs$l.statSync(fullPath).isFile()) {\n            const result = options?.pathOnly\n                ? fullPath\n                : fs$l.readFileSync(fullPath, 'utf-8');\n            if (!options?.predicate || options.predicate(result)) {\n                return result;\n            }\n        }\n    }\n    const parentDir = path$o.dirname(dir);\n    if (parentDir !== dir &&\n        (!options?.rootDir || parentDir.startsWith(options?.rootDir))) {\n        return lookupFile(parentDir, formats, options);\n    }\n}\nconst splitRE = /\\r?\\n/;\nconst range = 2;\nfunction pad$1(source, n = 2) {\n    const lines = source.split(splitRE);\n    return lines.map((l) => ` `.repeat(n) + l).join(`\\n`);\n}\nfunction posToNumber(source, pos) {\n    if (typeof pos === 'number')\n        return pos;\n    const lines = source.split(splitRE);\n    const { line, column } = pos;\n    let start = 0;\n    for (let i = 0; i < line - 1 && i < lines.length; i++) {\n        start += lines[i].length + 1;\n    }\n    return start + column;\n}\nfunction numberToPos(source, offset) {\n    if (typeof offset !== 'number')\n        return offset;\n    if (offset > source.length) {\n        throw new Error(`offset is longer than source length! offset ${offset} > length ${source.length}`);\n    }\n    const lines = source.split(splitRE);\n    let counted = 0;\n    let line = 0;\n    let column = 0;\n    for (; line < lines.length; line++) {\n        const lineLength = lines[line].length + 1;\n        if (counted + lineLength >= offset) {\n            column = offset - counted + 1;\n            break;\n        }\n        counted += lineLength;\n    }\n    return { line: line + 1, column };\n}\nfunction generateCodeFrame(source, start = 0, end) {\n    start = posToNumber(source, start);\n    end = end || start;\n    const lines = source.split(splitRE);\n    let count = 0;\n    const res = [];\n    for (let i = 0; i < lines.length; i++) {\n        count += lines[i].length + 1;\n        if (count >= start) {\n            for (let j = i - range; j <= i + range || end > count; j++) {\n                if (j < 0 || j >= lines.length)\n                    continue;\n                const line = j + 1;\n                res.push(`${line}${' '.repeat(Math.max(3 - String(line).length, 0))}|  ${lines[j]}`);\n                const lineLength = lines[j].length;\n                if (j === i) {\n                    // push underline\n                    const pad = Math.max(start - (count - lineLength) + 1, 0);\n                    const length = Math.max(1, end > count ? lineLength - pad : end - start);\n                    res.push(`   |  ` + ' '.repeat(pad) + '^'.repeat(length));\n                }\n                else if (j > i) {\n                    if (end > count) {\n                        const length = Math.max(Math.min(end - count, lineLength), 1);\n                        res.push(`   |  ` + '^'.repeat(length));\n                    }\n                    count += lineLength + 1;\n                }\n            }\n            break;\n        }\n    }\n    return res.join('\\n');\n}\nfunction writeFile(filename, content) {\n    const dir = path$o.dirname(filename);\n    if (!fs$l.existsSync(dir)) {\n        fs$l.mkdirSync(dir, { recursive: true });\n    }\n    fs$l.writeFileSync(filename, content);\n}\nfunction isFileReadable(filename) {\n    try {\n        fs$l.accessSync(filename, fs$l.constants.R_OK);\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\nconst splitFirstDirRE = /(.+?)[\\\\/](.+)/;\n/**\n * Delete every file and subdirectory. **The given directory must exist.**\n * Pass an optional `skip` array to preserve files under the root directory.\n */\nfunction emptyDir(dir, skip) {\n    const skipInDir = [];\n    let nested = null;\n    if (skip?.length) {\n        for (const file of skip) {\n            if (path$o.dirname(file) !== '.') {\n                const matched = file.match(splitFirstDirRE);\n                if (matched) {\n                    nested ?? (nested = new Map());\n                    const [, nestedDir, skipPath] = matched;\n                    let nestedSkip = nested.get(nestedDir);\n                    if (!nestedSkip) {\n                        nestedSkip = [];\n                        nested.set(nestedDir, nestedSkip);\n                    }\n                    if (!nestedSkip.includes(skipPath)) {\n                        nestedSkip.push(skipPath);\n                    }\n                }\n            }\n            else {\n                skipInDir.push(file);\n            }\n        }\n    }\n    for (const file of fs$l.readdirSync(dir)) {\n        if (skipInDir.includes(file)) {\n            continue;\n        }\n        if (nested?.has(file)) {\n            emptyDir(path$o.resolve(dir, file), nested.get(file));\n        }\n        else {\n            fs$l.rmSync(path$o.resolve(dir, file), { recursive: true, force: true });\n        }\n    }\n}\nfunction copyDir(srcDir, destDir) {\n    fs$l.mkdirSync(destDir, { recursive: true });\n    for (const file of fs$l.readdirSync(srcDir)) {\n        const srcFile = path$o.resolve(srcDir, file);\n        if (srcFile === destDir) {\n            continue;\n        }\n        const destFile = path$o.resolve(destDir, file);\n        const stat = fs$l.statSync(srcFile);\n        if (stat.isDirectory()) {\n            copyDir(srcFile, destFile);\n        }\n        else {\n            fs$l.copyFileSync(srcFile, destFile);\n        }\n    }\n}\nconst removeDir = isWindows$4\n    ? promisify$4(gracefulRemoveDir)\n    : function removeDirSync(dir) {\n        // when removing `.vite/deps`, if it doesn't exist, nodejs may also remove\n        // other directories within `.vite/`, including `.vite/deps_temp` (bug).\n        // workaround by checking for directory existence before removing for now.\n        if (fs$l.existsSync(dir)) {\n            fs$l.rmSync(dir, { recursive: true, force: true });\n        }\n    };\nconst renameDir = isWindows$4 ? promisify$4(gracefulRename) : fs$l.renameSync;\nfunction ensureWatchedFile(watcher, file, root) {\n    if (file &&\n        // only need to watch if out of root\n        !file.startsWith(root + '/') &&\n        // some rollup plugins use null bytes for private resolved Ids\n        !file.includes('\\0') &&\n        fs$l.existsSync(file)) {\n        // resolve file to normalized system path\n        watcher.add(path$o.resolve(file));\n    }\n}\nconst escapedSpaceCharacters = /( |\\\\t|\\\\n|\\\\f|\\\\r)+/g;\nconst imageSetUrlRE = /^(?:[\\w\\-]+\\(.*?\\)|'.*?'|\".*?\"|\\S*)/;\nfunction reduceSrcset(ret) {\n    return ret.reduce((prev, { url, descriptor }, index) => {\n        descriptor ?? (descriptor = '');\n        return (prev +=\n            url + ` ${descriptor}${index === ret.length - 1 ? '' : ', '}`);\n    }, '');\n}\nfunction splitSrcSetDescriptor(srcs) {\n    return splitSrcSet(srcs)\n        .map((s) => {\n        const src = s.replace(escapedSpaceCharacters, ' ').trim();\n        const [url] = imageSetUrlRE.exec(src) || [''];\n        return {\n            url,\n            descriptor: src?.slice(url.length).trim(),\n        };\n    })\n        .filter(({ url }) => !!url);\n}\nfunction processSrcSet(srcs, replacer) {\n    return Promise.all(splitSrcSetDescriptor(srcs).map(async ({ url, descriptor }) => ({\n        url: await replacer({ url, descriptor }),\n        descriptor,\n    }))).then((ret) => reduceSrcset(ret));\n}\nfunction processSrcSetSync(srcs, replacer) {\n    return reduceSrcset(splitSrcSetDescriptor(srcs).map(({ url, descriptor }) => ({\n        url: replacer({ url, descriptor }),\n        descriptor,\n    })));\n}\nfunction splitSrcSet(srcs) {\n    const parts = [];\n    // There could be a ',' inside of url(data:...), linear-gradient(...) or \"data:...\"\n    const cleanedSrcs = srcs.replace(/(?:url|image|gradient|cross-fade)\\([^)]*\\)|\"([^\"]|(?<=\\\\)\")*\"|'([^']|(?<=\\\\)')*'/g, blankReplacer);\n    let startIndex = 0;\n    let splitIndex;\n    do {\n        splitIndex = cleanedSrcs.indexOf(',', startIndex);\n        parts.push(srcs.slice(startIndex, splitIndex !== -1 ? splitIndex : undefined));\n        startIndex = splitIndex + 1;\n    } while (splitIndex !== -1);\n    return parts;\n}\nfunction escapeToLinuxLikePath(path) {\n    if (/^[A-Z]:/.test(path)) {\n        return path.replace(/^([A-Z]):\\//, '/windows/$1/');\n    }\n    if (/^\\/[^/]/.test(path)) {\n        return `/linux${path}`;\n    }\n    return path;\n}\nfunction unescapeToLinuxLikePath(path) {\n    if (path.startsWith('/linux/')) {\n        return path.slice('/linux'.length);\n    }\n    if (path.startsWith('/windows/')) {\n        return path.replace(/^\\/windows\\/([A-Z])\\//, '$1:/');\n    }\n    return path;\n}\n// based on https://github.com/sveltejs/svelte/blob/abf11bb02b2afbd3e4cac509a0f70e318c306364/src/compiler/utils/mapped_code.ts#L221\nconst nullSourceMap = {\n    names: [],\n    sources: [],\n    mappings: '',\n    version: 3,\n};\nfunction combineSourcemaps(filename, sourcemapList, excludeContent = true) {\n    if (sourcemapList.length === 0 ||\n        sourcemapList.every((m) => m.sources.length === 0)) {\n        return { ...nullSourceMap };\n    }\n    // hack for parse broken with normalized absolute paths on windows (C:/path/to/something).\n    // escape them to linux like paths\n    // also avoid mutation here to prevent breaking plugin's using cache to generate sourcemaps like vue (see #7442)\n    sourcemapList = sourcemapList.map((sourcemap) => {\n        const newSourcemaps = { ...sourcemap };\n        newSourcemaps.sources = sourcemap.sources.map((source) => source ? escapeToLinuxLikePath(source) : null);\n        if (sourcemap.sourceRoot) {\n            newSourcemaps.sourceRoot = escapeToLinuxLikePath(sourcemap.sourceRoot);\n        }\n        return newSourcemaps;\n    });\n    const escapedFilename = escapeToLinuxLikePath(filename);\n    // We don't declare type here so we can convert/fake/map as RawSourceMap\n    let map; //: SourceMap\n    let mapIndex = 1;\n    const useArrayInterface = sourcemapList.slice(0, -1).find((m) => m.sources.length !== 1) === undefined;\n    if (useArrayInterface) {\n        map = remapping(sourcemapList, () => null, excludeContent);\n    }\n    else {\n        map = remapping(sourcemapList[0], function loader(sourcefile) {\n            if (sourcefile === escapedFilename && sourcemapList[mapIndex]) {\n                return sourcemapList[mapIndex++];\n            }\n            else {\n                return null;\n            }\n        }, excludeContent);\n    }\n    if (!map.file) {\n        delete map.file;\n    }\n    // unescape the previous hack\n    map.sources = map.sources.map((source) => source ? unescapeToLinuxLikePath(source) : source);\n    map.file = filename;\n    return map;\n}\nfunction unique(arr) {\n    return Array.from(new Set(arr));\n}\n/**\n * Returns resolved localhost address when `dns.lookup` result differs from DNS\n *\n * `dns.lookup` result is same when defaultResultOrder is `verbatim`.\n * Even if defaultResultOrder is `ipv4first`, `dns.lookup` result maybe same.\n * For example, when IPv6 is not supported on that machine/network.\n */\nasync function getLocalhostAddressIfDiffersFromDNS() {\n    const [nodeResult, dnsResult] = await Promise.all([\n        promises.lookup('localhost'),\n        promises.lookup('localhost', { verbatim: true }),\n    ]);\n    const isSame = nodeResult.family === dnsResult.family &&\n        nodeResult.address === dnsResult.address;\n    return isSame ? undefined : nodeResult.address;\n}\nasync function resolveHostname(optionsHost) {\n    let host;\n    if (optionsHost === undefined || optionsHost === false) {\n        // Use a secure default\n        host = 'localhost';\n    }\n    else if (optionsHost === true) {\n        // If passed --host in the CLI without arguments\n        host = undefined; // undefined typically means 0.0.0.0 or :: (listen on all IPs)\n    }\n    else {\n        host = optionsHost;\n    }\n    // Set host name to localhost when possible\n    let name = host === undefined || wildcardHosts.has(host) ? 'localhost' : host;\n    if (host === 'localhost') {\n        // See #8647 for more details.\n        const localhostAddr = await getLocalhostAddressIfDiffersFromDNS();\n        if (localhostAddr) {\n            name = localhostAddr;\n        }\n    }\n    return { host, name };\n}\nasync function resolveServerUrls(server, options, config) {\n    const address = server.address();\n    const isAddressInfo = (x) => x?.address;\n    if (!isAddressInfo(address)) {\n        return { local: [], network: [] };\n    }\n    const local = [];\n    const network = [];\n    const hostname = await resolveHostname(options.host);\n    const protocol = options.https ? 'https' : 'http';\n    const port = address.port;\n    const base = config.rawBase === './' || config.rawBase === '' ? '/' : config.rawBase;\n    if (hostname.host && loopbackHosts.has(hostname.host)) {\n        let hostnameName = hostname.name;\n        // ipv6 host\n        if (hostnameName.includes(':')) {\n            hostnameName = `[${hostnameName}]`;\n        }\n        local.push(`${protocol}://${hostnameName}:${port}${base}`);\n    }\n    else {\n        Object.values(os$3.networkInterfaces())\n            .flatMap((nInterface) => nInterface ?? [])\n            .filter((detail) => detail &&\n            detail.address &&\n            ((typeof detail.family === 'string' && detail.family === 'IPv4') ||\n                // @ts-expect-error Node 18.0 - 18.3 returns number\n                (typeof detail.family === 'number' && detail.family === 4)))\n            .forEach((detail) => {\n            let host = detail.address.replace('127.0.0.1', hostname.name);\n            // ipv6 host\n            if (host.includes(':')) {\n                host = `[${host}]`;\n            }\n            const url = `${protocol}://${host}:${port}${base}`;\n            if (detail.address.includes('127.0.0.1')) {\n                local.push(url);\n            }\n            else {\n                network.push(url);\n            }\n        });\n    }\n    return { local, network };\n}\nfunction arraify(target) {\n    return Array.isArray(target) ? target : [target];\n}\nfunction toUpperCaseDriveLetter(pathName) {\n    return pathName.replace(/^\\w:/, (letter) => letter.toUpperCase());\n}\n// Taken from https://stackoverflow.com/a/36328890\nconst multilineCommentsRE$1 = /\\/\\*[^*]*\\*+(?:[^/*][^*]*\\*+)*\\//g;\nconst singlelineCommentsRE$1 = /\\/\\/.*/g;\nconst requestQuerySplitRE = /\\?(?!.*[/|}])/;\n// @ts-expect-error jest only exists when running Jest\nconst usingDynamicImport = typeof jest === 'undefined';\n/**\n * Dynamically import files. It will make sure it's not being compiled away by TS/Rollup.\n *\n * As a temporary workaround for Jest's lack of stable ESM support, we fallback to require\n * if we're in a Jest environment.\n * See https://github.com/vitejs/vite/pull/5197#issuecomment-938054077\n *\n * @param file File path to import.\n */\nconst dynamicImport = usingDynamicImport\n    ? new Function('file', 'return import(file)')\n    : _require$3;\nfunction parseRequest(id) {\n    const [_, search] = id.split(requestQuerySplitRE, 2);\n    if (!search) {\n        return null;\n    }\n    return Object.fromEntries(new URLSearchParams(search));\n}\nconst blankReplacer = (match) => ' '.repeat(match.length);\nfunction getHash(text) {\n    return createHash$2('sha256').update(text).digest('hex').substring(0, 8);\n}\nconst requireResolveFromRootWithFallback = (root, id) => {\n    const paths = _require$3.resolve.paths?.(id) || [];\n    // Search in the root directory first, and fallback to the default require paths.\n    paths.unshift(root);\n    // Use `resolve` package to check existence first, so if the package is not found,\n    // it won't be cached by nodejs, since there isn't a way to invalidate them:\n    // https://github.com/nodejs/node/issues/44663\n    resolve$4.sync(id, { basedir: root, paths });\n    // Use `require.resolve` again as the `resolve` package doesn't support the `exports` field\n    return _require$3.resolve(id, { paths });\n};\n// Based on node-graceful-fs\n// The ISC License\n// Copyright (c) 2011-2022 Isaac Z. Schlueter, Ben Noordhuis, and Contributors\n// https://github.com/isaacs/node-graceful-fs/blob/main/LICENSE\n// On Windows, A/V software can lock the directory, causing this\n// to fail with an EACCES or EPERM if the directory contains newly\n// created files. The original tried for up to 60 seconds, we only\n// wait for 5 seconds, as a longer time would be seen as an error\nconst GRACEFUL_RENAME_TIMEOUT = 5000;\nfunction gracefulRename(from, to, cb) {\n    const start = Date.now();\n    let backoff = 0;\n    fs$l.rename(from, to, function CB(er) {\n        if (er &&\n            (er.code === 'EACCES' || er.code === 'EPERM') &&\n            Date.now() - start < GRACEFUL_RENAME_TIMEOUT) {\n            setTimeout(function () {\n                fs$l.stat(to, function (stater, st) {\n                    if (stater && stater.code === 'ENOENT')\n                        fs$l.rename(from, to, CB);\n                    else\n                        CB(er);\n                });\n            }, backoff);\n            if (backoff < 100)\n                backoff += 10;\n            return;\n        }\n        if (cb)\n            cb(er);\n    });\n}\nconst GRACEFUL_REMOVE_DIR_TIMEOUT = 5000;\nfunction gracefulRemoveDir(dir, cb) {\n    const start = Date.now();\n    let backoff = 0;\n    fs$l.rm(dir, { recursive: true }, function CB(er) {\n        if (er) {\n            if ((er.code === 'ENOTEMPTY' ||\n                er.code === 'EACCES' ||\n                er.code === 'EPERM') &&\n                Date.now() - start < GRACEFUL_REMOVE_DIR_TIMEOUT) {\n                setTimeout(function () {\n                    fs$l.rm(dir, { recursive: true }, CB);\n                }, backoff);\n                if (backoff < 100)\n                    backoff += 10;\n                return;\n            }\n            if (er.code === 'ENOENT') {\n                er = null;\n            }\n        }\n        if (cb)\n            cb(er);\n    });\n}\nfunction emptyCssComments(raw) {\n    return raw.replace(multilineCommentsRE$1, (s) => ' '.repeat(s.length));\n}\nfunction removeComments(raw) {\n    return raw.replace(multilineCommentsRE$1, '').replace(singlelineCommentsRE$1, '');\n}\nfunction mergeConfigRecursively(defaults, overrides, rootPath) {\n    const merged = { ...defaults };\n    for (const key in overrides) {\n        const value = overrides[key];\n        if (value == null) {\n            continue;\n        }\n        const existing = merged[key];\n        if (existing == null) {\n            merged[key] = value;\n            continue;\n        }\n        // fields that require special handling\n        if (key === 'alias' && (rootPath === 'resolve' || rootPath === '')) {\n            merged[key] = mergeAlias(existing, value);\n            continue;\n        }\n        else if (key === 'assetsInclude' && rootPath === '') {\n            merged[key] = [].concat(existing, value);\n            continue;\n        }\n        else if (key === 'noExternal' &&\n            rootPath === 'ssr' &&\n            (existing === true || value === true)) {\n            merged[key] = true;\n            continue;\n        }\n        if (Array.isArray(existing) || Array.isArray(value)) {\n            merged[key] = [...arraify(existing ?? []), ...arraify(value ?? [])];\n            continue;\n        }\n        if (isObject$1(existing) && isObject$1(value)) {\n            merged[key] = mergeConfigRecursively(existing, value, rootPath ? `${rootPath}.${key}` : key);\n            continue;\n        }\n        merged[key] = value;\n    }\n    return merged;\n}\nfunction mergeConfig(defaults, overrides, isRoot = true) {\n    return mergeConfigRecursively(defaults, overrides, isRoot ? '' : '.');\n}\nfunction mergeAlias(a, b) {\n    if (!a)\n        return b;\n    if (!b)\n        return a;\n    if (isObject$1(a) && isObject$1(b)) {\n        return { ...a, ...b };\n    }\n    // the order is flipped because the alias is resolved from top-down,\n    // where the later should have higher priority\n    return [...normalizeAlias(b), ...normalizeAlias(a)];\n}\nfunction normalizeAlias(o = []) {\n    return Array.isArray(o)\n        ? o.map(normalizeSingleAlias)\n        : Object.keys(o).map((find) => normalizeSingleAlias({\n            find,\n            replacement: o[find],\n        }));\n}\n// https://github.com/vitejs/vite/issues/1363\n// work around https://github.com/rollup/plugins/issues/759\nfunction normalizeSingleAlias({ find, replacement, customResolver, }) {\n    if (typeof find === 'string' &&\n        find.endsWith('/') &&\n        replacement.endsWith('/')) {\n        find = find.slice(0, find.length - 1);\n        replacement = replacement.slice(0, replacement.length - 1);\n    }\n    const alias = {\n        find,\n        replacement,\n    };\n    if (customResolver) {\n        alias.customResolver = customResolver;\n    }\n    return alias;\n}\n/**\n * Transforms transpiled code result where line numbers aren't altered,\n * so we can skip sourcemap generation during dev\n */\nfunction transformStableResult(s, id, config) {\n    return {\n        code: s.toString(),\n        map: config.command === 'build' && config.build.sourcemap\n            ? s.generateMap({ hires: true, source: id })\n            : null,\n    };\n}\nasync function asyncFlatten(arr) {\n    do {\n        arr = (await Promise.all(arr)).flat(Infinity);\n    } while (arr.some((v) => v?.then));\n    return arr;\n}\n// strip UTF-8 BOM\nfunction stripBomTag(content) {\n    if (content.charCodeAt(0) === 0xfeff) {\n        return content.slice(1);\n    }\n    return content;\n}\nconst windowsDrivePathPrefixRE = /^[A-Za-z]:[/\\\\]/;\n/**\n * path.isAbsolute also returns true for drive relative paths on windows (e.g. /something)\n * this function returns false for them but true for absolute paths (e.g. C:/something)\n */\nconst isNonDriveRelativeAbsolutePath = (p) => {\n    if (!isWindows$4)\n        return p.startsWith('/');\n    return windowsDrivePathPrefixRE.test(p);\n};\n/**\n * Determine if a file is being requested with the correct case, to ensure\n * consistent behaviour between dev and prod and across operating systems.\n */\nfunction shouldServeFile(filePath, root) {\n    // can skip case check on Linux\n    if (!isCaseInsensitiveFS)\n        return true;\n    return hasCorrectCase(filePath, root);\n}\n/**\n * Note that we can't use realpath here, because we don't want to follow\n * symlinks.\n */\nfunction hasCorrectCase(file, assets) {\n    if (file === assets)\n        return true;\n    const parent = path$o.dirname(file);\n    if (fs$l.readdirSync(parent).includes(path$o.basename(file))) {\n        return hasCorrectCase(parent, assets);\n    }\n    return false;\n}\nfunction joinUrlSegments(a, b) {\n    if (!a || !b) {\n        return a || b || '';\n    }\n    if (a.endsWith('/')) {\n        a = a.substring(0, a.length - 1);\n    }\n    if (!b.startsWith('/')) {\n        b = '/' + b;\n    }\n    return a + b;\n}\nfunction stripBase(path, base) {\n    if (path === base) {\n        return '/';\n    }\n    const devBase = base.endsWith('/') ? base : base + '/';\n    return path.replace(RegExp('^' + devBase), '/');\n}\nfunction arrayEqual(a, b) {\n    if (a === b)\n        return true;\n    if (a.length !== b.length)\n        return false;\n    for (let i = 0; i < a.length; i++) {\n        if (a[i] !== b[i])\n            return false;\n    }\n    return true;\n}\nfunction evalValue(rawValue) {\n    const fn = new Function(`\n    var console, exports, global, module, process, require\n    return (\\n${rawValue}\\n)\n  `);\n    return fn();\n}\n\n/* eslint no-console: 0 */\nconst LogLevels = {\n    silent: 0,\n    error: 1,\n    warn: 2,\n    info: 3,\n};\nlet lastType;\nlet lastMsg;\nlet sameCount = 0;\nfunction clearScreen() {\n    const repeatCount = process.stdout.rows - 2;\n    const blank = repeatCount > 0 ? '\\n'.repeat(repeatCount) : '';\n    console.log(blank);\n    readline.cursorTo(process.stdout, 0, 0);\n    readline.clearScreenDown(process.stdout);\n}\nfunction createLogger(level = 'info', options = {}) {\n    if (options.customLogger) {\n        return options.customLogger;\n    }\n    const loggedErrors = new WeakSet();\n    const { prefix = '[vite]', allowClearScreen = true } = options;\n    const thresh = LogLevels[level];\n    const canClearScreen = allowClearScreen && process.stdout.isTTY && !process.env.CI;\n    const clear = canClearScreen ? clearScreen : () => { };\n    function output(type, msg, options = {}) {\n        if (thresh >= LogLevels[type]) {\n            const method = type === 'info' ? 'log' : type;\n            const format = () => {\n                if (options.timestamp) {\n                    const tag = type === 'info'\n                        ? picocolorsExports.cyan(picocolorsExports.bold(prefix))\n                        : type === 'warn'\n                            ? picocolorsExports.yellow(picocolorsExports.bold(prefix))\n                            : picocolorsExports.red(picocolorsExports.bold(prefix));\n                    return `${picocolorsExports.dim(new Date().toLocaleTimeString())} ${tag} ${msg}`;\n                }\n                else {\n                    return msg;\n                }\n            };\n            if (options.error) {\n                loggedErrors.add(options.error);\n            }\n            if (canClearScreen) {\n                if (type === lastType && msg === lastMsg) {\n                    sameCount++;\n                    clear();\n                    console[method](format(), picocolorsExports.yellow(`(x${sameCount + 1})`));\n                }\n                else {\n                    sameCount = 0;\n                    lastMsg = msg;\n                    lastType = type;\n                    if (options.clear) {\n                        clear();\n                    }\n                    console[method](format());\n                }\n            }\n            else {\n                console[method](format());\n            }\n        }\n    }\n    const warnedMessages = new Set();\n    const logger = {\n        hasWarned: false,\n        info(msg, opts) {\n            output('info', msg, opts);\n        },\n        warn(msg, opts) {\n            logger.hasWarned = true;\n            output('warn', msg, opts);\n        },\n        warnOnce(msg, opts) {\n            if (warnedMessages.has(msg))\n                return;\n            logger.hasWarned = true;\n            output('warn', msg, opts);\n            warnedMessages.add(msg);\n        },\n        error(msg, opts) {\n            logger.hasWarned = true;\n            output('error', msg, opts);\n        },\n        clearScreen(type) {\n            if (thresh >= LogLevels[type]) {\n                clear();\n            }\n        },\n        hasErrorLogged(error) {\n            return loggedErrors.has(error);\n        },\n    };\n    return logger;\n}\nfunction printServerUrls(urls, optionsHost, info) {\n    const colorUrl = (url) => picocolorsExports.cyan(url.replace(/:(\\d+)\\//, (_, port) => `:${picocolorsExports.bold(port)}/`));\n    for (const url of urls.local) {\n        info(`  ${picocolorsExports.green('➜')}  ${picocolorsExports.bold('Local')}:   ${colorUrl(url)}`);\n    }\n    for (const url of urls.network) {\n        info(`  ${picocolorsExports.green('➜')}  ${picocolorsExports.bold('Network')}: ${colorUrl(url)}`);\n    }\n    if (urls.network.length === 0 && optionsHost === undefined) {\n        info(picocolorsExports.dim(`  ${picocolorsExports.green('➜')}  ${picocolorsExports.bold('Network')}: use `) +\n            picocolorsExports.bold('--host') +\n            picocolorsExports.dim(' to expose'));\n    }\n}\n\nconst groups = [\n    { name: 'Assets', color: picocolorsExports.green },\n    { name: 'CSS', color: picocolorsExports.magenta },\n    { name: 'JS', color: picocolorsExports.cyan },\n];\nfunction buildReporterPlugin(config) {\n    const compress = promisify$4(gzip);\n    const chunkLimit = config.build.chunkSizeWarningLimit;\n    const tty = process.stdout.isTTY && !process.env.CI;\n    const shouldLogInfo = LogLevels[config.logLevel || 'info'] >= LogLevels.info;\n    let hasTransformed = false;\n    let hasRenderedChunk = false;\n    let hasCompressChunk = false;\n    let transformedCount = 0;\n    let chunkCount = 0;\n    let compressedCount = 0;\n    async function getCompressedSize(code) {\n        if (config.build.ssr || !config.build.reportCompressedSize) {\n            return null;\n        }\n        if (shouldLogInfo && !hasCompressChunk) {\n            if (!tty) {\n                config.logger.info('computing gzip size...');\n            }\n            else {\n                writeLine('computing gzip size (0)...');\n            }\n            hasCompressChunk = true;\n        }\n        const compressed = await compress(typeof code === 'string' ? code : Buffer.from(code));\n        compressedCount++;\n        if (shouldLogInfo && tty) {\n            writeLine(`computing gzip size (${compressedCount})...`);\n        }\n        return compressed.length;\n    }\n    const logTransform = throttle((id) => {\n        writeLine(`transforming (${transformedCount}) ${picocolorsExports.dim(path$o.relative(config.root, id))}`);\n    });\n    return {\n        name: 'vite:reporter',\n        transform(_, id) {\n            transformedCount++;\n            if (shouldLogInfo) {\n                if (!tty) {\n                    if (!hasTransformed) {\n                        config.logger.info(`transforming...`);\n                    }\n                }\n                else {\n                    if (id.includes(`?`))\n                        return;\n                    logTransform(id);\n                }\n                hasTransformed = true;\n            }\n            return null;\n        },\n        buildEnd() {\n            if (shouldLogInfo) {\n                if (tty) {\n                    process.stdout.clearLine(0);\n                    process.stdout.cursorTo(0);\n                }\n                config.logger.info(`${picocolorsExports.green(`✓`)} ${transformedCount} modules transformed.`);\n            }\n        },\n        renderStart() {\n            chunkCount = 0;\n            compressedCount = 0;\n        },\n        renderChunk() {\n            chunkCount++;\n            if (shouldLogInfo) {\n                if (!tty) {\n                    if (!hasRenderedChunk) {\n                        config.logger.info('rendering chunks...');\n                    }\n                }\n                else {\n                    writeLine(`rendering chunks (${chunkCount})...`);\n                }\n                hasRenderedChunk = true;\n            }\n            return null;\n        },\n        generateBundle() {\n            if (shouldLogInfo && tty)\n                clearLine();\n        },\n        async writeBundle({ dir: outDir }, output) {\n            let hasLargeChunks = false;\n            if (shouldLogInfo) {\n                const entries = (await Promise.all(Object.values(output).map(async (chunk) => {\n                    if (chunk.type === 'chunk') {\n                        return {\n                            name: chunk.fileName,\n                            group: 'JS',\n                            size: chunk.code.length,\n                            compressedSize: await getCompressedSize(chunk.code),\n                            mapSize: chunk.map ? chunk.map.toString().length : null,\n                        };\n                    }\n                    else {\n                        if (chunk.fileName.endsWith('.map'))\n                            return null;\n                        const isCSS = chunk.fileName.endsWith('.css');\n                        return {\n                            name: chunk.fileName,\n                            group: isCSS ? 'CSS' : 'Assets',\n                            size: chunk.source.length,\n                            mapSize: null,\n                            compressedSize: isCSS\n                                ? await getCompressedSize(chunk.source)\n                                : null,\n                        };\n                    }\n                }))).filter(isDefined);\n                if (tty)\n                    clearLine();\n                let longest = 0;\n                let biggestSize = 0;\n                let biggestMap = 0;\n                let biggestCompressSize = 0;\n                for (const entry of entries) {\n                    if (entry.name.length > longest)\n                        longest = entry.name.length;\n                    if (entry.size > biggestSize)\n                        biggestSize = entry.size;\n                    if (entry.mapSize && entry.mapSize > biggestMap) {\n                        biggestMap = entry.mapSize;\n                    }\n                    if (entry.compressedSize &&\n                        entry.compressedSize > biggestCompressSize) {\n                        biggestCompressSize = entry.compressedSize;\n                    }\n                }\n                const sizePad = displaySize(biggestSize).length;\n                const mapPad = displaySize(biggestMap).length;\n                const compressPad = displaySize(biggestCompressSize).length;\n                const relativeOutDir = normalizePath$3(path$o.relative(config.root, path$o.resolve(config.root, outDir ?? config.build.outDir)));\n                const assetsDir = `${config.build.assetsDir}/`;\n                for (const group of groups) {\n                    const filtered = entries.filter((e) => e.group === group.name);\n                    if (!filtered.length)\n                        continue;\n                    for (const entry of filtered.sort((a, z) => a.size - z.size)) {\n                        const isLarge = group.name === 'JS' && entry.size / 1000 > chunkLimit;\n                        if (isLarge)\n                            hasLargeChunks = true;\n                        const sizeColor = isLarge ? picocolorsExports.yellow : picocolorsExports.dim;\n                        let log = picocolorsExports.dim(relativeOutDir + '/');\n                        log += entry.name.startsWith(assetsDir)\n                            ? picocolorsExports.dim(assetsDir) +\n                                group.color(entry.name\n                                    .slice(assetsDir.length)\n                                    .padEnd(longest + 2 - assetsDir.length))\n                            : group.color(entry.name.padEnd(longest + 2));\n                        log += picocolorsExports.bold(sizeColor(displaySize(entry.size).padStart(sizePad)));\n                        if (entry.compressedSize) {\n                            log += picocolorsExports.dim(` │ gzip: ${displaySize(entry.compressedSize).padStart(compressPad)}`);\n                        }\n                        if (entry.mapSize) {\n                            log += picocolorsExports.dim(` │ map: ${displaySize(entry.mapSize).padStart(mapPad)}`);\n                        }\n                        config.logger.info(log);\n                    }\n                }\n            }\n            else {\n                hasLargeChunks = Object.values(output).some((chunk) => {\n                    return chunk.type === 'chunk' && chunk.code.length / 1000 > chunkLimit;\n                });\n            }\n            if (hasLargeChunks &&\n                config.build.minify &&\n                !config.build.lib &&\n                !config.build.ssr) {\n                config.logger.warn(picocolorsExports.yellow(`\\n(!) Some chunks are larger than ${chunkLimit} kBs after minification. Consider:\\n` +\n                    `- Using dynamic import() to code-split the application\\n` +\n                    `- Use build.rollupOptions.output.manualChunks to improve chunking: https://rollupjs.org/configuration-options/#output-manualchunks\\n` +\n                    `- Adjust chunk size limit for this warning via build.chunkSizeWarningLimit.`));\n            }\n        },\n    };\n}\nfunction writeLine(output) {\n    clearLine();\n    if (output.length < process.stdout.columns) {\n        process.stdout.write(output);\n    }\n    else {\n        process.stdout.write(output.substring(0, process.stdout.columns - 1));\n    }\n}\nfunction clearLine() {\n    process.stdout.clearLine(0);\n    process.stdout.cursorTo(0);\n}\nfunction throttle(fn) {\n    let timerHandle = null;\n    return (...args) => {\n        if (timerHandle)\n            return;\n        fn(...args);\n        timerHandle = setTimeout(() => {\n            timerHandle = null;\n        }, 100);\n    };\n}\nfunction displaySize(bytes) {\n    return `${(bytes / 1000).toLocaleString('en', {\n        maximumFractionDigits: 2,\n        minimumFractionDigits: 2,\n    })} kB`;\n}\n\n// src/find.ts\nasync function find(filename, options) {\n  let dir = require$$0$4.dirname(require$$0$4.resolve(filename));\n  const root = (options == null ? void 0 : options.root) ? require$$0$4.resolve(options.root) : null;\n  while (dir) {\n    const tsconfig = await tsconfigInDir(dir, options);\n    if (tsconfig) {\n      return tsconfig;\n    } else {\n      if (root === dir) {\n        break;\n      }\n      const parent = require$$0$4.dirname(dir);\n      if (parent === dir) {\n        break;\n      } else {\n        dir = parent;\n      }\n    }\n  }\n  throw new Error(`no tsconfig file found for ${filename}`);\n}\nasync function tsconfigInDir(dir, options) {\n  const tsconfig = require$$0$4.join(dir, \"tsconfig.json\");\n  if (options == null ? void 0 : options.tsConfigPaths) {\n    return options.tsConfigPaths.has(tsconfig) ? tsconfig : void 0;\n  }\n  try {\n    const stat = await promises$1.stat(tsconfig);\n    if (stat.isFile() || stat.isFIFO()) {\n      return tsconfig;\n    }\n  } catch (e) {\n    if (e.code !== \"ENOENT\") {\n      throw e;\n    }\n  }\n}\nasync function findAll(dir, options) {\n  const files = [];\n  for await (const tsconfigFile of findTSConfig(require$$0$4.resolve(dir), options)) {\n    files.push(tsconfigFile);\n  }\n  return files;\n}\nasync function* findTSConfig(dir, options, visited = /* @__PURE__ */ new Set()) {\n  if (!visited.has(dir)) {\n    visited.add(dir);\n    try {\n      const dirents = await promises$1.readdir(dir, { withFileTypes: true });\n      for (const dirent of dirents) {\n        if (dirent.isDirectory() && (!(options == null ? void 0 : options.skip) || !options.skip(dirent.name))) {\n          yield* findTSConfig(require$$0$4.resolve(dir, dirent.name), options, visited);\n        } else if (dirent.isFile() && dirent.name === \"tsconfig.json\") {\n          yield require$$0$4.resolve(dir, dirent.name);\n        }\n      }\n    } catch (e) {\n      if (e.code === \"EACCES\" || e.code === \"ENOENT\") {\n        return;\n      }\n      throw e;\n    }\n  }\n}\n\n// src/to-json.ts\nfunction toJson(tsconfigJson) {\n  const stripped = stripDanglingComma(stripJsonComments(stripBom(tsconfigJson)));\n  if (stripped.trim() === \"\") {\n    return \"{}\";\n  } else {\n    return stripped;\n  }\n}\nfunction stripDanglingComma(pseudoJson) {\n  let insideString = false;\n  let offset = 0;\n  let result = \"\";\n  let danglingCommaPos = null;\n  for (let i = 0; i < pseudoJson.length; i++) {\n    const currentCharacter = pseudoJson[i];\n    if (currentCharacter === '\"') {\n      const escaped = isEscaped(pseudoJson, i);\n      if (!escaped) {\n        insideString = !insideString;\n      }\n    }\n    if (insideString) {\n      danglingCommaPos = null;\n      continue;\n    }\n    if (currentCharacter === \",\") {\n      danglingCommaPos = i;\n      continue;\n    }\n    if (danglingCommaPos) {\n      if (currentCharacter === \"}\" || currentCharacter === \"]\") {\n        result += pseudoJson.slice(offset, danglingCommaPos) + \" \";\n        offset = danglingCommaPos + 1;\n        danglingCommaPos = null;\n      } else if (!currentCharacter.match(/\\s/)) {\n        danglingCommaPos = null;\n      }\n    }\n  }\n  return result + pseudoJson.substring(offset);\n}\nfunction isEscaped(jsonString, quotePosition) {\n  let index = quotePosition - 1;\n  let backslashCount = 0;\n  while (jsonString[index] === \"\\\\\") {\n    index -= 1;\n    backslashCount += 1;\n  }\n  return Boolean(backslashCount % 2);\n}\nfunction strip(string, start, end) {\n  return string.slice(start, end).replace(/\\S/g, \" \");\n}\nvar singleComment = Symbol(\"singleComment\");\nvar multiComment = Symbol(\"multiComment\");\nfunction stripJsonComments(jsonString) {\n  let isInsideString = false;\n  let isInsideComment = false;\n  let offset = 0;\n  let result = \"\";\n  for (let index = 0; index < jsonString.length; index++) {\n    const currentCharacter = jsonString[index];\n    const nextCharacter = jsonString[index + 1];\n    if (!isInsideComment && currentCharacter === '\"') {\n      const escaped = isEscaped(jsonString, index);\n      if (!escaped) {\n        isInsideString = !isInsideString;\n      }\n    }\n    if (isInsideString) {\n      continue;\n    }\n    if (!isInsideComment && currentCharacter + nextCharacter === \"//\") {\n      result += jsonString.slice(offset, index);\n      offset = index;\n      isInsideComment = singleComment;\n      index++;\n    } else if (isInsideComment === singleComment && currentCharacter + nextCharacter === \"\\r\\n\") {\n      index++;\n      isInsideComment = false;\n      result += strip(jsonString, offset, index);\n      offset = index;\n    } else if (isInsideComment === singleComment && currentCharacter === \"\\n\") {\n      isInsideComment = false;\n      result += strip(jsonString, offset, index);\n      offset = index;\n    } else if (!isInsideComment && currentCharacter + nextCharacter === \"/*\") {\n      result += jsonString.slice(offset, index);\n      offset = index;\n      isInsideComment = multiComment;\n      index++;\n    } else if (isInsideComment === multiComment && currentCharacter + nextCharacter === \"*/\") {\n      index++;\n      isInsideComment = false;\n      result += strip(jsonString, offset, index + 1);\n      offset = index + 1;\n    }\n  }\n  return result + (isInsideComment ? strip(jsonString.slice(offset)) : jsonString.slice(offset));\n}\nfunction stripBom(string) {\n  if (string.charCodeAt(0) === 65279) {\n    return string.slice(1);\n  }\n  return string;\n}\nvar POSIX_SEP_RE = new RegExp(\"\\\\\" + require$$0$4.posix.sep, \"g\");\nvar NATIVE_SEP_RE = new RegExp(\"\\\\\" + require$$0$4.sep, \"g\");\nvar PATTERN_REGEX_CACHE = /* @__PURE__ */ new Map();\nvar GLOB_ALL_PATTERN = `**/*`;\nvar DEFAULT_EXTENSIONS = [\".ts\", \".tsx\", \".mts\", \".cts\"];\nvar DEFAULT_EXTENSIONS_RE_GROUP = `\\\\.(?:${DEFAULT_EXTENSIONS.map((ext) => ext.substring(1)).join(\n  \"|\"\n)})`;\nnew Function(\"path\", \"return import(path).then(m => m.default)\");\nasync function resolveTSConfig(filename) {\n  if (require$$0$4.extname(filename) !== \".json\") {\n    return;\n  }\n  const tsconfig = require$$0$4.resolve(filename);\n  try {\n    const stat = await promises$1.stat(tsconfig);\n    if (stat.isFile() || stat.isFIFO()) {\n      return tsconfig;\n    }\n  } catch (e) {\n    if (e.code !== \"ENOENT\") {\n      throw e;\n    }\n  }\n  throw new Error(`no tsconfig file found for ${filename}`);\n}\nfunction posix2native(filename) {\n  return require$$0$4.posix.sep !== require$$0$4.sep && filename.includes(require$$0$4.posix.sep) ? filename.replace(POSIX_SEP_RE, require$$0$4.sep) : filename;\n}\nfunction native2posix(filename) {\n  return require$$0$4.posix.sep !== require$$0$4.sep && filename.includes(require$$0$4.sep) ? filename.replace(NATIVE_SEP_RE, require$$0$4.posix.sep) : filename;\n}\nfunction resolve2posix(dir, filename) {\n  if (require$$0$4.sep === require$$0$4.posix.sep) {\n    return dir ? require$$0$4.resolve(dir, filename) : require$$0$4.resolve(filename);\n  }\n  return native2posix(\n    dir ? require$$0$4.resolve(posix2native(dir), posix2native(filename)) : require$$0$4.resolve(posix2native(filename))\n  );\n}\nfunction resolveReferencedTSConfigFiles(result) {\n  const dir = require$$0$4.dirname(result.tsconfigFile);\n  return result.tsconfig.references.map((ref) => {\n    const refPath = ref.path.endsWith(\".json\") ? ref.path : require$$0$4.join(ref.path, \"tsconfig.json\");\n    return resolve2posix(dir, refPath);\n  });\n}\nfunction resolveSolutionTSConfig(filename, result) {\n  if (result.referenced && DEFAULT_EXTENSIONS.some((ext) => filename.endsWith(ext)) && !isIncluded(filename, result)) {\n    const solutionTSConfig = result.referenced.find(\n      (referenced) => isIncluded(filename, referenced)\n    );\n    if (solutionTSConfig) {\n      return {\n        ...solutionTSConfig,\n        solution: result\n      };\n    }\n  }\n  return result;\n}\nfunction isIncluded(filename, result) {\n  const dir = native2posix(require$$0$4.dirname(result.tsconfigFile));\n  const files = (result.tsconfig.files || []).map((file) => resolve2posix(dir, file));\n  const absoluteFilename = resolve2posix(null, filename);\n  if (files.includes(filename)) {\n    return true;\n  }\n  const isIncluded2 = isGlobMatch(\n    absoluteFilename,\n    dir,\n    result.tsconfig.include || (result.tsconfig.files ? [] : [GLOB_ALL_PATTERN])\n  );\n  if (isIncluded2) {\n    const isExcluded = isGlobMatch(absoluteFilename, dir, result.tsconfig.exclude || []);\n    return !isExcluded;\n  }\n  return false;\n}\nfunction isGlobMatch(filename, dir, patterns) {\n  return patterns.some((pattern) => {\n    let lastWildcardIndex = pattern.length;\n    let hasWildcard = false;\n    for (let i = pattern.length - 1; i > -1; i--) {\n      if (pattern[i] === \"*\" || pattern[i] === \"?\") {\n        lastWildcardIndex = i;\n        hasWildcard = true;\n        break;\n      }\n    }\n    if (lastWildcardIndex < pattern.length - 1 && !filename.endsWith(pattern.slice(lastWildcardIndex + 1))) {\n      return false;\n    }\n    if (pattern.endsWith(\"*\") && !DEFAULT_EXTENSIONS.some((ext) => filename.endsWith(ext))) {\n      return false;\n    }\n    if (pattern === GLOB_ALL_PATTERN) {\n      return filename.startsWith(`${dir}/`);\n    }\n    const resolvedPattern = resolve2posix(dir, pattern);\n    let firstWildcardIndex = -1;\n    for (let i = 0; i < resolvedPattern.length; i++) {\n      if (resolvedPattern[i] === \"*\" || resolvedPattern[i] === \"?\") {\n        firstWildcardIndex = i;\n        hasWildcard = true;\n        break;\n      }\n    }\n    if (firstWildcardIndex > 1 && !filename.startsWith(resolvedPattern.slice(0, firstWildcardIndex - 1))) {\n      return false;\n    }\n    if (!hasWildcard) {\n      return filename === resolvedPattern;\n    }\n    if (PATTERN_REGEX_CACHE.has(resolvedPattern)) {\n      return PATTERN_REGEX_CACHE.get(resolvedPattern).test(filename);\n    }\n    const regex = pattern2regex(resolvedPattern);\n    PATTERN_REGEX_CACHE.set(resolvedPattern, regex);\n    return regex.test(filename);\n  });\n}\nfunction pattern2regex(resolvedPattern) {\n  let regexStr = \"^\";\n  for (let i = 0; i < resolvedPattern.length; i++) {\n    const char = resolvedPattern[i];\n    if (char === \"?\") {\n      regexStr += \"[^\\\\/]\";\n      continue;\n    }\n    if (char === \"*\") {\n      if (resolvedPattern[i + 1] === \"*\" && resolvedPattern[i + 2] === \"/\") {\n        i += 2;\n        regexStr += \"(?:[^\\\\/]*\\\\/)*\";\n        continue;\n      }\n      regexStr += \"[^\\\\/]*\";\n      continue;\n    }\n    if (\"/.+^${}()|[]\\\\\".includes(char)) {\n      regexStr += `\\\\`;\n    }\n    regexStr += char;\n  }\n  if (resolvedPattern.endsWith(\"*\")) {\n    regexStr += DEFAULT_EXTENSIONS_RE_GROUP;\n  }\n  regexStr += \"$\";\n  return new RegExp(regexStr);\n}\n\n// src/parse.ts\nasync function parse$f(filename, options) {\n  const cache = options == null ? void 0 : options.cache;\n  if (cache == null ? void 0 : cache.has(filename)) {\n    return cache.get(filename);\n  }\n  let tsconfigFile;\n  if (options == null ? void 0 : options.resolveWithEmptyIfConfigNotFound) {\n    try {\n      tsconfigFile = await resolveTSConfig(filename) || await find(filename, options);\n    } catch (e) {\n      const notFoundResult = {\n        tsconfigFile: \"no_tsconfig_file_found\",\n        tsconfig: {}\n      };\n      cache == null ? void 0 : cache.set(filename, notFoundResult);\n      return notFoundResult;\n    }\n  } else {\n    tsconfigFile = await resolveTSConfig(filename) || await find(filename, options);\n  }\n  let result;\n  if (cache == null ? void 0 : cache.has(tsconfigFile)) {\n    result = cache.get(tsconfigFile);\n  } else {\n    result = await parseFile$1(tsconfigFile, cache);\n    await Promise.all([parseExtends(result, cache), parseReferences(result, cache)]);\n    cache == null ? void 0 : cache.set(tsconfigFile, result);\n  }\n  result = resolveSolutionTSConfig(filename, result);\n  cache == null ? void 0 : cache.set(filename, result);\n  return result;\n}\nasync function parseFile$1(tsconfigFile, cache) {\n  if (cache == null ? void 0 : cache.has(tsconfigFile)) {\n    return cache.get(tsconfigFile);\n  }\n  try {\n    const tsconfigJson = await promises$1.readFile(tsconfigFile, \"utf-8\");\n    const json = toJson(tsconfigJson);\n    const result = {\n      tsconfigFile,\n      tsconfig: normalizeTSConfig(JSON.parse(json), require$$0$4.dirname(tsconfigFile))\n    };\n    cache == null ? void 0 : cache.set(tsconfigFile, result);\n    return result;\n  } catch (e) {\n    throw new TSConfckParseError(\n      `parsing ${tsconfigFile} failed: ${e}`,\n      \"PARSE_FILE\",\n      tsconfigFile,\n      e\n    );\n  }\n}\nfunction normalizeTSConfig(tsconfig, dir) {\n  var _a;\n  if (((_a = tsconfig.compilerOptions) == null ? void 0 : _a.baseUrl) && !require$$0$4.isAbsolute(tsconfig.compilerOptions.baseUrl)) {\n    tsconfig.compilerOptions.baseUrl = resolve2posix(dir, tsconfig.compilerOptions.baseUrl);\n  }\n  return tsconfig;\n}\nasync function parseReferences(result, cache) {\n  if (!result.tsconfig.references) {\n    return;\n  }\n  const referencedFiles = resolveReferencedTSConfigFiles(result);\n  const referenced = await Promise.all(referencedFiles.map((file) => parseFile$1(file, cache)));\n  await Promise.all(referenced.map((ref) => parseExtends(ref, cache)));\n  result.referenced = referenced;\n}\nasync function parseExtends(result, cache) {\n  if (!result.tsconfig.extends) {\n    return;\n  }\n  const extended = [\n    { tsconfigFile: result.tsconfigFile, tsconfig: JSON.parse(JSON.stringify(result.tsconfig)) }\n  ];\n  while (extended[extended.length - 1].tsconfig.extends) {\n    const extending = extended[extended.length - 1];\n    const extendedTSConfigFile = resolveExtends(extending.tsconfig.extends, extending.tsconfigFile);\n    if (extended.some((x) => x.tsconfigFile === extendedTSConfigFile)) {\n      const circle = extended.concat({ tsconfigFile: extendedTSConfigFile, tsconfig: null }).map((e) => e.tsconfigFile).join(\" -> \");\n      throw new TSConfckParseError(\n        `Circular dependency in \"extends\": ${circle}`,\n        \"EXTENDS_CIRCULAR\",\n        result.tsconfigFile\n      );\n    }\n    extended.push(await parseFile$1(extendedTSConfigFile, cache));\n  }\n  result.extended = extended;\n  for (const ext of result.extended.slice(1)) {\n    extendTSConfig(result, ext);\n  }\n}\nfunction resolveExtends(extended, from) {\n  let error;\n  try {\n    return createRequire$2(from).resolve(extended);\n  } catch (e) {\n    error = e;\n  }\n  if (!require$$0$4.isAbsolute(extended) && !extended.startsWith(\"./\") && !extended.startsWith(\"../\")) {\n    try {\n      const fallbackExtended = require$$0$4.join(extended, \"tsconfig.json\");\n      return createRequire$2(from).resolve(fallbackExtended);\n    } catch (e) {\n      error = e;\n    }\n  }\n  throw new TSConfckParseError(\n    `failed to resolve \"extends\":\"${extended}\" in ${from}`,\n    \"EXTENDS_RESOLVE\",\n    from,\n    error\n  );\n}\nvar EXTENDABLE_KEYS = [\n  \"compilerOptions\",\n  \"files\",\n  \"include\",\n  \"exclude\",\n  \"watchOptions\",\n  \"compileOnSave\",\n  \"typeAcquisition\",\n  \"buildOptions\"\n];\nfunction extendTSConfig(extending, extended) {\n  const extendingConfig = extending.tsconfig;\n  const extendedConfig = extended.tsconfig;\n  const relativePath = native2posix(\n    require$$0$4.relative(require$$0$4.dirname(extending.tsconfigFile), require$$0$4.dirname(extended.tsconfigFile))\n  );\n  for (const key of Object.keys(extendedConfig).filter((key2) => EXTENDABLE_KEYS.includes(key2))) {\n    if (key === \"compilerOptions\") {\n      if (!extendingConfig.compilerOptions) {\n        extendingConfig.compilerOptions = {};\n      }\n      for (const option of Object.keys(extendedConfig.compilerOptions)) {\n        if (Object.prototype.hasOwnProperty.call(extendingConfig.compilerOptions, option)) {\n          continue;\n        }\n        extendingConfig.compilerOptions[option] = rebaseRelative(\n          option,\n          extendedConfig.compilerOptions[option],\n          relativePath\n        );\n      }\n    } else if (extendingConfig[key] === void 0) {\n      if (key === \"watchOptions\") {\n        extendingConfig.watchOptions = {};\n        for (const option of Object.keys(extendedConfig.watchOptions)) {\n          extendingConfig.watchOptions[option] = rebaseRelative(\n            option,\n            extendedConfig.watchOptions[option],\n            relativePath\n          );\n        }\n      } else {\n        extendingConfig[key] = rebaseRelative(key, extendedConfig[key], relativePath);\n      }\n    }\n  }\n}\nvar REBASE_KEYS = [\n  \"files\",\n  \"include\",\n  \"exclude\",\n  \"baseUrl\",\n  \"rootDir\",\n  \"rootDirs\",\n  \"typeRoots\",\n  \"outDir\",\n  \"outFile\",\n  \"declarationDir\",\n  \"excludeDirectories\",\n  \"excludeFiles\"\n];\nfunction rebaseRelative(key, value, prependPath) {\n  if (!REBASE_KEYS.includes(key)) {\n    return value;\n  }\n  if (Array.isArray(value)) {\n    return value.map((x) => rebasePath(x, prependPath));\n  } else {\n    return rebasePath(value, prependPath);\n  }\n}\nfunction rebasePath(value, prependPath) {\n  if (require$$0$4.isAbsolute(value)) {\n    return value;\n  } else {\n    return require$$0$4.posix.normalize(require$$0$4.posix.join(prependPath, value));\n  }\n}\nvar TSConfckParseError = class extends Error {\n  constructor(message, code, tsconfigFile, cause) {\n    super(message);\n    Object.setPrototypeOf(this, TSConfckParseError.prototype);\n    this.name = TSConfckParseError.name;\n    this.code = code;\n    this.cause = cause;\n    this.tsconfigFile = tsconfigFile;\n  }\n};\n\nconst debug$f = createDebugger('vite:esbuild');\nconst INJECT_HELPERS_IIFE_RE = /^(.*?)((?:const|var)\\s+\\S+\\s*=\\s*function\\s*\\([^)]*\\)\\s*\\{.*?\"use strict\";)/s;\nconst INJECT_HELPERS_UMD_RE = /^(.*?)(\\(function\\([^)]*\\)\\s*\\{.+?amd.+?function\\([^)]*\\)\\s*\\{.*?\"use strict\";)/s;\nlet server;\nasync function transformWithEsbuild(code, filename, options, inMap) {\n    let loader = options?.loader;\n    if (!loader) {\n        // if the id ends with a valid ext, use it (e.g. vue blocks)\n        // otherwise, cleanup the query before checking the ext\n        const ext = path$o\n            .extname(/\\.\\w+$/.test(filename) ? filename : cleanUrl(filename))\n            .slice(1);\n        if (ext === 'cjs' || ext === 'mjs') {\n            loader = 'js';\n        }\n        else if (ext === 'cts' || ext === 'mts') {\n            loader = 'ts';\n        }\n        else {\n            loader = ext;\n        }\n    }\n    let tsconfigRaw = options?.tsconfigRaw;\n    // if options provide tsconfigRaw in string, it takes highest precedence\n    if (typeof tsconfigRaw !== 'string') {\n        // these fields would affect the compilation result\n        // https://esbuild.github.io/content-types/#tsconfig-json\n        const meaningfulFields = [\n            'alwaysStrict',\n            'importsNotUsedAsValues',\n            'jsx',\n            'jsxFactory',\n            'jsxFragmentFactory',\n            'jsxImportSource',\n            'preserveValueImports',\n            'target',\n            'useDefineForClassFields',\n        ];\n        const compilerOptionsForFile = {};\n        if (loader === 'ts' || loader === 'tsx') {\n            const loadedTsconfig = await loadTsconfigJsonForFile(filename);\n            const loadedCompilerOptions = loadedTsconfig.compilerOptions ?? {};\n            for (const field of meaningfulFields) {\n                if (field in loadedCompilerOptions) {\n                    // @ts-expect-error TypeScript can't tell they are of the same type\n                    compilerOptionsForFile[field] = loadedCompilerOptions[field];\n                }\n            }\n        }\n        tsconfigRaw = {\n            ...tsconfigRaw,\n            compilerOptions: {\n                ...compilerOptionsForFile,\n                ...tsconfigRaw?.compilerOptions,\n            },\n        };\n        const { compilerOptions } = tsconfigRaw;\n        if (compilerOptions) {\n            // esbuild derives `useDefineForClassFields` from `target` instead of `tsconfig.compilerOptions.target`\n            // https://github.com/evanw/esbuild/issues/2584\n            // but we want `useDefineForClassFields` to be derived from `tsconfig.compilerOptions.target`\n            if (compilerOptions.useDefineForClassFields === undefined) {\n                const lowercaseTarget = compilerOptions.target?.toLowerCase() ?? 'es3';\n                if (lowercaseTarget.startsWith('es')) {\n                    const esVersion = lowercaseTarget.slice(2);\n                    compilerOptions.useDefineForClassFields =\n                        esVersion === 'next' || +esVersion >= 2022;\n                }\n                else {\n                    compilerOptions.useDefineForClassFields = false;\n                }\n            }\n        }\n    }\n    const resolvedOptions = {\n        sourcemap: true,\n        // ensure source file name contains full query\n        sourcefile: filename,\n        ...options,\n        loader,\n        tsconfigRaw,\n    };\n    // esbuild uses tsconfig fields when both the normal options and tsconfig was set\n    // but we want to prioritize the normal options\n    if (options &&\n        typeof resolvedOptions.tsconfigRaw === 'object' &&\n        resolvedOptions.tsconfigRaw.compilerOptions) {\n        options.jsx && (resolvedOptions.tsconfigRaw.compilerOptions.jsx = undefined);\n        options.jsxFactory &&\n            (resolvedOptions.tsconfigRaw.compilerOptions.jsxFactory = undefined);\n        options.jsxFragment &&\n            (resolvedOptions.tsconfigRaw.compilerOptions.jsxFragmentFactory =\n                undefined);\n        options.jsxImportSource &&\n            (resolvedOptions.tsconfigRaw.compilerOptions.jsxImportSource = undefined);\n        options.target &&\n            (resolvedOptions.tsconfigRaw.compilerOptions.target = undefined);\n    }\n    delete resolvedOptions.include;\n    delete resolvedOptions.exclude;\n    delete resolvedOptions.jsxInject;\n    try {\n        const result = await transform$2(code, resolvedOptions);\n        let map;\n        if (inMap && resolvedOptions.sourcemap) {\n            const nextMap = JSON.parse(result.map);\n            nextMap.sourcesContent = [];\n            map = combineSourcemaps(filename, [\n                nextMap,\n                inMap,\n            ]);\n        }\n        else {\n            map =\n                resolvedOptions.sourcemap && resolvedOptions.sourcemap !== 'inline'\n                    ? JSON.parse(result.map)\n                    : { mappings: '' };\n        }\n        if (Array.isArray(map.sources)) {\n            map.sources = map.sources.map((it) => toUpperCaseDriveLetter(it));\n        }\n        return {\n            ...result,\n            map,\n        };\n    }\n    catch (e) {\n        debug$f(`esbuild error with options used: `, resolvedOptions);\n        // patch error information\n        if (e.errors) {\n            e.frame = '';\n            e.errors.forEach((m) => {\n                e.frame += `\\n` + prettifyMessage(m, code);\n            });\n            e.loc = e.errors[0].location;\n        }\n        throw e;\n    }\n}\nfunction esbuildPlugin(options = {}) {\n    const filter = createFilter(options.include || /\\.(m?ts|[jt]sx)$/, options.exclude || /\\.js$/);\n    // Remove optimization options for dev as we only need to transpile them,\n    // and for build as the final optimization is in `buildEsbuildPlugin`\n    const transformOptions = {\n        target: 'esnext',\n        charset: 'utf8',\n        ...options,\n        minify: false,\n        minifyIdentifiers: false,\n        minifySyntax: false,\n        minifyWhitespace: false,\n        treeShaking: false,\n        // keepNames is not needed when minify is disabled.\n        // Also transforming multiple times with keepNames enabled breaks\n        // tree-shaking. (#9164)\n        keepNames: false,\n    };\n    return {\n        name: 'vite:esbuild',\n        configureServer(_server) {\n            server = _server;\n            server.watcher\n                .on('add', reloadOnTsconfigChange)\n                .on('change', reloadOnTsconfigChange)\n                .on('unlink', reloadOnTsconfigChange);\n        },\n        async configResolved(config) {\n            await initTSConfck(config);\n        },\n        buildEnd() {\n            // recycle serve to avoid preventing Node self-exit (#6815)\n            server = null;\n        },\n        async transform(code, id) {\n            if (filter(id) || filter(cleanUrl(id))) {\n                const result = await transformWithEsbuild(code, id, transformOptions);\n                if (result.warnings.length) {\n                    result.warnings.forEach((m) => {\n                        this.warn(prettifyMessage(m, code));\n                    });\n                }\n                if (options.jsxInject && /\\.(?:j|t)sx\\b/.test(id)) {\n                    result.code = options.jsxInject + ';' + result.code;\n                }\n                return {\n                    code: result.code,\n                    map: result.map,\n                };\n            }\n        },\n    };\n}\nconst rollupToEsbuildFormatMap = {\n    es: 'esm',\n    cjs: 'cjs',\n    // passing `var Lib = (() => {})()` to esbuild with format = \"iife\"\n    // will turn it to `(() => { var Lib = (() => {})() })()`,\n    // so we remove the format config to tell esbuild not doing this\n    //\n    // although esbuild doesn't change format, there is still possibility\n    // that `{ treeShaking: true }` removes a top-level no-side-effect variable\n    // like: `var Lib = 1`, which becomes `` after esbuild transforming,\n    // but thankfully rollup does not do this optimization now\n    iife: undefined,\n};\nconst buildEsbuildPlugin = (config) => {\n    return {\n        name: 'vite:esbuild-transpile',\n        async configResolved(config) {\n            await initTSConfck(config);\n        },\n        async renderChunk(code, chunk, opts) {\n            // @ts-expect-error injected by @vitejs/plugin-legacy\n            if (opts.__vite_skip_esbuild__) {\n                return null;\n            }\n            const options = resolveEsbuildTranspileOptions(config, opts.format);\n            if (!options) {\n                return null;\n            }\n            const res = await transformWithEsbuild(code, chunk.fileName, options);\n            if (config.build.lib) {\n                // #7188, esbuild adds helpers out of the UMD and IIFE wrappers, and the\n                // names are minified potentially causing collision with other globals.\n                // We use a regex to inject the helpers inside the wrappers.\n                // We don't need to create a MagicString here because both the helpers and\n                // the headers don't modify the sourcemap\n                const injectHelpers = opts.format === 'umd'\n                    ? INJECT_HELPERS_UMD_RE\n                    : opts.format === 'iife'\n                        ? INJECT_HELPERS_IIFE_RE\n                        : undefined;\n                if (injectHelpers) {\n                    res.code = res.code.replace(injectHelpers, (_, helpers, header) => header + helpers);\n                }\n            }\n            return res;\n        },\n    };\n};\nfunction resolveEsbuildTranspileOptions(config, format) {\n    const target = config.build.target;\n    const minify = config.build.minify === 'esbuild';\n    if ((!target || target === 'esnext') && !minify) {\n        return null;\n    }\n    // Do not minify whitespace for ES lib output since that would remove\n    // pure annotations and break tree-shaking\n    // https://github.com/vuejs/core/issues/2860#issuecomment-926882793\n    const isEsLibBuild = config.build.lib && format === 'es';\n    const esbuildOptions = config.esbuild || {};\n    const options = {\n        charset: 'utf8',\n        ...esbuildOptions,\n        target: target || undefined,\n        format: rollupToEsbuildFormatMap[format],\n        // the final build should always support dynamic import and import.meta.\n        // if they need to be polyfilled, plugin-legacy should be used.\n        // plugin-legacy detects these two features when checking for modern code.\n        supported: {\n            'dynamic-import': true,\n            'import-meta': true,\n            ...esbuildOptions.supported,\n        },\n    };\n    // If no minify, disable all minify options\n    if (!minify) {\n        return {\n            ...options,\n            minify: false,\n            minifyIdentifiers: false,\n            minifySyntax: false,\n            minifyWhitespace: false,\n            treeShaking: false,\n        };\n    }\n    // If user enable fine-grain minify options, minify with their options instead\n    if (options.minifyIdentifiers != null ||\n        options.minifySyntax != null ||\n        options.minifyWhitespace != null) {\n        if (isEsLibBuild) {\n            // Disable minify whitespace as it breaks tree-shaking\n            return {\n                ...options,\n                minify: false,\n                minifyIdentifiers: options.minifyIdentifiers ?? true,\n                minifySyntax: options.minifySyntax ?? true,\n                minifyWhitespace: false,\n                treeShaking: true,\n            };\n        }\n        else {\n            return {\n                ...options,\n                minify: false,\n                minifyIdentifiers: options.minifyIdentifiers ?? true,\n                minifySyntax: options.minifySyntax ?? true,\n                minifyWhitespace: options.minifyWhitespace ?? true,\n                treeShaking: true,\n            };\n        }\n    }\n    // Else apply default minify options\n    if (isEsLibBuild) {\n        // Minify all except whitespace as it breaks tree-shaking\n        return {\n            ...options,\n            minify: false,\n            minifyIdentifiers: true,\n            minifySyntax: true,\n            minifyWhitespace: false,\n            treeShaking: true,\n        };\n    }\n    else {\n        return {\n            ...options,\n            minify: true,\n            treeShaking: true,\n        };\n    }\n}\nfunction prettifyMessage(m, code) {\n    let res = picocolorsExports.yellow(m.text);\n    if (m.location) {\n        const lines = code.split(/\\r?\\n/g);\n        const line = Number(m.location.line);\n        const column = Number(m.location.column);\n        const offset = lines\n            .slice(0, line - 1)\n            .map((l) => l.length)\n            .reduce((total, l) => total + l + 1, 0) + column;\n        res += `\\n` + generateCodeFrame(code, offset, offset + 1);\n    }\n    return res + `\\n`;\n}\nconst tsconfckParseOptions = {\n    cache: new Map(),\n    tsConfigPaths: undefined,\n    root: undefined,\n    resolveWithEmptyIfConfigNotFound: true,\n};\nasync function initTSConfck(config) {\n    const workspaceRoot = searchForWorkspaceRoot(config.root);\n    debug$f(`init tsconfck (root: ${picocolorsExports.cyan(workspaceRoot)})`);\n    tsconfckParseOptions.cache.clear();\n    tsconfckParseOptions.root = workspaceRoot;\n    tsconfckParseOptions.tsConfigPaths = new Set([\n        ...(await findAll(workspaceRoot, {\n            skip: (dir) => dir === 'node_modules' || dir === '.git',\n        })),\n    ]);\n    debug$f(`init tsconfck end`);\n}\nasync function loadTsconfigJsonForFile(filename) {\n    try {\n        const result = await parse$f(filename, tsconfckParseOptions);\n        // tsconfig could be out of root, make sure it is watched on dev\n        if (server && result.tsconfigFile !== 'no_tsconfig_file_found') {\n            ensureWatchedFile(server.watcher, result.tsconfigFile, server.config.root);\n        }\n        return result.tsconfig;\n    }\n    catch (e) {\n        if (e instanceof TSConfckParseError) {\n            // tsconfig could be out of root, make sure it is watched on dev\n            if (server && e.tsconfigFile) {\n                ensureWatchedFile(server.watcher, e.tsconfigFile, server.config.root);\n            }\n        }\n        throw e;\n    }\n}\nfunction reloadOnTsconfigChange(changedFile) {\n    // server could be closed externally after a file change is detected\n    if (!server)\n        return;\n    // any tsconfig.json that's added in the workspace could be closer to a code file than a previously cached one\n    // any json file in the tsconfig cache could have been used to compile ts\n    if (path$o.basename(changedFile) === 'tsconfig.json' ||\n        (changedFile.endsWith('.json') &&\n            tsconfckParseOptions?.cache?.has(changedFile))) {\n        server.config.logger.info(`changed tsconfig file detected: ${changedFile} - Clearing cache and forcing full-reload to ensure TypeScript is compiled with updated config values.`, { clear: server.config.clearScreen, timestamp: true });\n        // clear module graph to remove code compiled with outdated config\n        server.moduleGraph.invalidateAll();\n        // reset tsconfck so that recompile works with up2date configs\n        initTSConfck(server.config).finally(() => {\n            // server may not be available if vite config is updated at the same time\n            if (server) {\n                // force full reload\n                server.ws.send({\n                    type: 'full-reload',\n                    path: '*',\n                });\n            }\n        });\n    }\n}\n\nvar dist$1 = {};\n\nvar __importDefault = (commonjsGlobal && commonjsGlobal.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(dist$1, \"__esModule\", { value: true });\nvar Worker_1 = dist$1.Worker = void 0;\nconst os_1 = __importDefault(require$$2);\nconst worker_threads_1 = require$$1;\nclass Worker {\n    constructor(fn, options = {}) {\n        this.code = genWorkerCode(fn);\n        this.max = options.max || Math.max(1, os_1.default.cpus().length - 1);\n        this.pool = [];\n        this.idlePool = [];\n        this.queue = [];\n    }\n    async run(...args) {\n        const worker = await this._getAvailableWorker();\n        return new Promise((resolve, reject) => {\n            worker.currentResolve = resolve;\n            worker.currentReject = reject;\n            worker.postMessage(args);\n        });\n    }\n    stop() {\n        this.pool.forEach((w) => w.unref());\n        this.queue.forEach(([_, reject]) => reject(new Error('Main worker pool stopped before a worker was available.')));\n        this.pool = [];\n        this.idlePool = [];\n        this.queue = [];\n    }\n    async _getAvailableWorker() {\n        // has idle one?\n        if (this.idlePool.length) {\n            return this.idlePool.shift();\n        }\n        // can spawn more?\n        if (this.pool.length < this.max) {\n            const worker = new worker_threads_1.Worker(this.code, { eval: true });\n            worker.on('message', (res) => {\n                worker.currentResolve && worker.currentResolve(res);\n                worker.currentResolve = null;\n                this._assignDoneWorker(worker);\n            });\n            worker.on('error', (err) => {\n                worker.currentReject && worker.currentReject(err);\n                worker.currentReject = null;\n            });\n            worker.on('exit', (code) => {\n                const i = this.pool.indexOf(worker);\n                if (i > -1)\n                    this.pool.splice(i, 1);\n                if (code !== 0 && worker.currentReject) {\n                    worker.currentReject(new Error(`Wroker stopped with non-0 exit code ${code}`));\n                    worker.currentReject = null;\n                }\n            });\n            this.pool.push(worker);\n            return worker;\n        }\n        // no one is available, we have to wait\n        let resolve;\n        let reject;\n        const onWorkerAvailablePromise = new Promise((r, rj) => {\n            resolve = r;\n            reject = rj;\n        });\n        this.queue.push([resolve, reject]);\n        return onWorkerAvailablePromise;\n    }\n    _assignDoneWorker(worker) {\n        // someone's waiting already?\n        if (this.queue.length) {\n            const [resolve] = this.queue.shift();\n            resolve(worker);\n            return;\n        }\n        // take a rest.\n        this.idlePool.push(worker);\n    }\n}\nWorker_1 = dist$1.Worker = Worker;\nfunction genWorkerCode(fn) {\n    return `\nconst doWork = ${fn.toString()}\n\nconst { parentPort } = require('worker_threads')\n\nparentPort.on('message', async (args) => {\n  const res = await doWork(...args)\n  parentPort.postMessage(res)\n})\n  `;\n}\n\nlet terserPath;\nconst loadTerserPath = (root) => {\n    if (terserPath)\n        return terserPath;\n    try {\n        terserPath = requireResolveFromRootWithFallback(root, 'terser');\n    }\n    catch (e) {\n        if (e.code === 'MODULE_NOT_FOUND') {\n            throw new Error('terser not found. Since Vite v3, terser has become an optional dependency. You need to install it.');\n        }\n        else {\n            const message = new Error(`terser failed to load:\\n${e.message}`);\n            message.stack = e.stack + '\\n' + message.stack;\n            throw message;\n        }\n    }\n    return terserPath;\n};\nfunction terserPlugin(config) {\n    const makeWorker = () => new Worker_1(async (terserPath, code, options) => {\n        // test fails when using `import`. maybe related: https://github.com/nodejs/node/issues/43205\n        // eslint-disable-next-line no-restricted-globals -- this function runs inside cjs\n        const terser = require(terserPath);\n        return terser.minify(code, options);\n    });\n    let worker;\n    return {\n        name: 'vite:terser',\n        async renderChunk(code, _chunk, outputOptions) {\n            // This plugin is included for any non-false value of config.build.minify,\n            // so that normal chunks can use the preferred minifier, and legacy chunks\n            // can use terser.\n            if (config.build.minify !== 'terser' &&\n                // @ts-expect-error injected by @vitejs/plugin-legacy\n                !outputOptions.__vite_force_terser__) {\n                return null;\n            }\n            // Do not minify ES lib output since that would remove pure annotations\n            // and break tree-shaking.\n            if (config.build.lib && outputOptions.format === 'es') {\n                return null;\n            }\n            // Lazy load worker.\n            worker || (worker = makeWorker());\n            const terserPath = loadTerserPath(config.root);\n            const res = await worker.run(terserPath, code, {\n                safari10: true,\n                ...config.build.terserOptions,\n                sourceMap: !!outputOptions.sourcemap,\n                module: outputOptions.format.startsWith('es'),\n                toplevel: outputOptions.format === 'cjs',\n            });\n            return {\n                code: res.code,\n                map: res.map,\n            };\n        },\n        closeBundle() {\n            worker?.stop();\n        },\n    };\n}\n\nvar json = JSON;\n\nvar isArray$1 = Array.isArray || function (x) {\n\treturn {}.toString.call(x) === '[object Array]';\n};\n\nvar objectKeys = Object.keys || function (obj) {\n\tvar has = Object.prototype.hasOwnProperty || function () { return true; };\n\tvar keys = [];\n\tfor (var key in obj) {\n\t\tif (has.call(obj, key)) { keys.push(key); }\n\t}\n\treturn keys;\n};\n\nvar jsonStableStringify = function (obj, opts) {\n\tif (!opts) { opts = {}; }\n\tif (typeof opts === 'function') { opts = { cmp: opts }; }\n\tvar space = opts.space || '';\n\tif (typeof space === 'number') { space = Array(space + 1).join(' '); }\n\tvar cycles = typeof opts.cycles === 'boolean' ? opts.cycles : false;\n\tvar replacer = opts.replacer || function (key, value) { return value; };\n\n\tvar cmp = opts.cmp && (function (f) {\n\t\treturn function (node) {\n\t\t\treturn function (a, b) {\n\t\t\t\tvar aobj = { key: a, value: node[a] };\n\t\t\t\tvar bobj = { key: b, value: node[b] };\n\t\t\t\treturn f(aobj, bobj);\n\t\t\t};\n\t\t};\n\t}(opts.cmp));\n\n\tvar seen = [];\n\treturn (function stringify(parent, key, node, level) {\n\t\tvar indent = space ? '\\n' + new Array(level + 1).join(space) : '';\n\t\tvar colonSeparator = space ? ': ' : ':';\n\n\t\tif (node && node.toJSON && typeof node.toJSON === 'function') {\n\t\t\tnode = node.toJSON();\n\t\t}\n\n\t\tnode = replacer.call(parent, key, node);\n\n\t\tif (node === undefined) {\n\t\t\treturn;\n\t\t}\n\t\tif (typeof node !== 'object' || node === null) {\n\t\t\treturn json.stringify(node);\n\t\t}\n\t\tif (isArray$1(node)) {\n\t\t\tvar out = [];\n\t\t\tfor (var i = 0; i < node.length; i++) {\n\t\t\t\tvar item = stringify(node, i, node[i], level + 1) || json.stringify(null);\n\t\t\t\tout.push(indent + space + item);\n\t\t\t}\n\t\t\treturn '[' + out.join(',') + indent + ']';\n\t\t}\n\n\t\tif (seen.indexOf(node) !== -1) {\n\t\t\tif (cycles) { return json.stringify('__cycle__'); }\n\t\t\tthrow new TypeError('Converting circular structure to JSON');\n\t\t} else { seen.push(node); }\n\n\t\tvar keys = objectKeys(node).sort(cmp && cmp(node));\n\t\tvar out = [];\n\t\tfor (var i = 0; i < keys.length; i++) {\n\t\t\tvar key = keys[i];\n\t\t\tvar value = stringify(node, key, node[key], level + 1);\n\n\t\t\tif (!value) { continue; }\n\n\t\t\tvar keyValue = json.stringify(key)\n\t\t\t\t\t+ colonSeparator\n\t\t\t\t\t+ value;\n\n\t\t\tout.push(indent + space + keyValue);\n\t\t}\n\t\tseen.splice(seen.indexOf(node), 1);\n\t\treturn '{' + out.join(',') + indent + '}';\n\n\t}({ '': obj }, '', obj, 0));\n};\n\nconst mimes$1 = {\n  \"ez\": \"application/andrew-inset\",\n  \"aw\": \"application/applixware\",\n  \"atom\": \"application/atom+xml\",\n  \"atomcat\": \"application/atomcat+xml\",\n  \"atomdeleted\": \"application/atomdeleted+xml\",\n  \"atomsvc\": \"application/atomsvc+xml\",\n  \"dwd\": \"application/atsc-dwd+xml\",\n  \"held\": \"application/atsc-held+xml\",\n  \"rsat\": \"application/atsc-rsat+xml\",\n  \"bdoc\": \"application/bdoc\",\n  \"xcs\": \"application/calendar+xml\",\n  \"ccxml\": \"application/ccxml+xml\",\n  \"cdfx\": \"application/cdfx+xml\",\n  \"cdmia\": \"application/cdmi-capability\",\n  \"cdmic\": \"application/cdmi-container\",\n  \"cdmid\": \"application/cdmi-domain\",\n  \"cdmio\": \"application/cdmi-object\",\n  \"cdmiq\": \"application/cdmi-queue\",\n  \"cu\": \"application/cu-seeme\",\n  \"mpd\": \"application/dash+xml\",\n  \"davmount\": \"application/davmount+xml\",\n  \"dbk\": \"application/docbook+xml\",\n  \"dssc\": \"application/dssc+der\",\n  \"xdssc\": \"application/dssc+xml\",\n  \"es\": \"application/ecmascript\",\n  \"ecma\": \"application/ecmascript\",\n  \"emma\": \"application/emma+xml\",\n  \"emotionml\": \"application/emotionml+xml\",\n  \"epub\": \"application/epub+zip\",\n  \"exi\": \"application/exi\",\n  \"fdt\": \"application/fdt+xml\",\n  \"pfr\": \"application/font-tdpfr\",\n  \"geojson\": \"application/geo+json\",\n  \"gml\": \"application/gml+xml\",\n  \"gpx\": \"application/gpx+xml\",\n  \"gxf\": \"application/gxf\",\n  \"gz\": \"application/gzip\",\n  \"hjson\": \"application/hjson\",\n  \"stk\": \"application/hyperstudio\",\n  \"ink\": \"application/inkml+xml\",\n  \"inkml\": \"application/inkml+xml\",\n  \"ipfix\": \"application/ipfix\",\n  \"its\": \"application/its+xml\",\n  \"jar\": \"application/java-archive\",\n  \"war\": \"application/java-archive\",\n  \"ear\": \"application/java-archive\",\n  \"ser\": \"application/java-serialized-object\",\n  \"class\": \"application/java-vm\",\n  \"js\": \"application/javascript\",\n  \"mjs\": \"application/javascript\",\n  \"json\": \"application/json\",\n  \"map\": \"application/json\",\n  \"json5\": \"application/json5\",\n  \"jsonml\": \"application/jsonml+json\",\n  \"jsonld\": \"application/ld+json\",\n  \"lgr\": \"application/lgr+xml\",\n  \"lostxml\": \"application/lost+xml\",\n  \"hqx\": \"application/mac-binhex40\",\n  \"cpt\": \"application/mac-compactpro\",\n  \"mads\": \"application/mads+xml\",\n  \"webmanifest\": \"application/manifest+json\",\n  \"mrc\": \"application/marc\",\n  \"mrcx\": \"application/marcxml+xml\",\n  \"ma\": \"application/mathematica\",\n  \"nb\": \"application/mathematica\",\n  \"mb\": \"application/mathematica\",\n  \"mathml\": \"application/mathml+xml\",\n  \"mbox\": \"application/mbox\",\n  \"mscml\": \"application/mediaservercontrol+xml\",\n  \"metalink\": \"application/metalink+xml\",\n  \"meta4\": \"application/metalink4+xml\",\n  \"mets\": \"application/mets+xml\",\n  \"maei\": \"application/mmt-aei+xml\",\n  \"musd\": \"application/mmt-usd+xml\",\n  \"mods\": \"application/mods+xml\",\n  \"m21\": \"application/mp21\",\n  \"mp21\": \"application/mp21\",\n  \"mp4s\": \"application/mp4\",\n  \"m4p\": \"application/mp4\",\n  \"doc\": \"application/msword\",\n  \"dot\": \"application/msword\",\n  \"mxf\": \"application/mxf\",\n  \"nq\": \"application/n-quads\",\n  \"nt\": \"application/n-triples\",\n  \"cjs\": \"application/node\",\n  \"bin\": \"application/octet-stream\",\n  \"dms\": \"application/octet-stream\",\n  \"lrf\": \"application/octet-stream\",\n  \"mar\": \"application/octet-stream\",\n  \"so\": \"application/octet-stream\",\n  \"dist\": \"application/octet-stream\",\n  \"distz\": \"application/octet-stream\",\n  \"pkg\": \"application/octet-stream\",\n  \"bpk\": \"application/octet-stream\",\n  \"dump\": \"application/octet-stream\",\n  \"elc\": \"application/octet-stream\",\n  \"deploy\": \"application/octet-stream\",\n  \"exe\": \"application/octet-stream\",\n  \"dll\": \"application/octet-stream\",\n  \"deb\": \"application/octet-stream\",\n  \"dmg\": \"application/octet-stream\",\n  \"iso\": \"application/octet-stream\",\n  \"img\": \"application/octet-stream\",\n  \"msi\": \"application/octet-stream\",\n  \"msp\": \"application/octet-stream\",\n  \"msm\": \"application/octet-stream\",\n  \"buffer\": \"application/octet-stream\",\n  \"oda\": \"application/oda\",\n  \"opf\": \"application/oebps-package+xml\",\n  \"ogx\": \"application/ogg\",\n  \"omdoc\": \"application/omdoc+xml\",\n  \"onetoc\": \"application/onenote\",\n  \"onetoc2\": \"application/onenote\",\n  \"onetmp\": \"application/onenote\",\n  \"onepkg\": \"application/onenote\",\n  \"oxps\": \"application/oxps\",\n  \"relo\": \"application/p2p-overlay+xml\",\n  \"xer\": \"application/patch-ops-error+xml\",\n  \"pdf\": \"application/pdf\",\n  \"pgp\": \"application/pgp-encrypted\",\n  \"asc\": \"application/pgp-signature\",\n  \"sig\": \"application/pgp-signature\",\n  \"prf\": \"application/pics-rules\",\n  \"p10\": \"application/pkcs10\",\n  \"p7m\": \"application/pkcs7-mime\",\n  \"p7c\": \"application/pkcs7-mime\",\n  \"p7s\": \"application/pkcs7-signature\",\n  \"p8\": \"application/pkcs8\",\n  \"ac\": \"application/pkix-attr-cert\",\n  \"cer\": \"application/pkix-cert\",\n  \"crl\": \"application/pkix-crl\",\n  \"pkipath\": \"application/pkix-pkipath\",\n  \"pki\": \"application/pkixcmp\",\n  \"pls\": \"application/pls+xml\",\n  \"ai\": \"application/postscript\",\n  \"eps\": \"application/postscript\",\n  \"ps\": \"application/postscript\",\n  \"provx\": \"application/provenance+xml\",\n  \"cww\": \"application/prs.cww\",\n  \"pskcxml\": \"application/pskc+xml\",\n  \"raml\": \"application/raml+yaml\",\n  \"rdf\": \"application/rdf+xml\",\n  \"owl\": \"application/rdf+xml\",\n  \"rif\": \"application/reginfo+xml\",\n  \"rnc\": \"application/relax-ng-compact-syntax\",\n  \"rl\": \"application/resource-lists+xml\",\n  \"rld\": \"application/resource-lists-diff+xml\",\n  \"rs\": \"application/rls-services+xml\",\n  \"rapd\": \"application/route-apd+xml\",\n  \"sls\": \"application/route-s-tsid+xml\",\n  \"rusd\": \"application/route-usd+xml\",\n  \"gbr\": \"application/rpki-ghostbusters\",\n  \"mft\": \"application/rpki-manifest\",\n  \"roa\": \"application/rpki-roa\",\n  \"rsd\": \"application/rsd+xml\",\n  \"rss\": \"application/rss+xml\",\n  \"rtf\": \"application/rtf\",\n  \"sbml\": \"application/sbml+xml\",\n  \"scq\": \"application/scvp-cv-request\",\n  \"scs\": \"application/scvp-cv-response\",\n  \"spq\": \"application/scvp-vp-request\",\n  \"spp\": \"application/scvp-vp-response\",\n  \"sdp\": \"application/sdp\",\n  \"senmlx\": \"application/senml+xml\",\n  \"sensmlx\": \"application/sensml+xml\",\n  \"setpay\": \"application/set-payment-initiation\",\n  \"setreg\": \"application/set-registration-initiation\",\n  \"shf\": \"application/shf+xml\",\n  \"siv\": \"application/sieve\",\n  \"sieve\": \"application/sieve\",\n  \"smi\": \"application/smil+xml\",\n  \"smil\": \"application/smil+xml\",\n  \"rq\": \"application/sparql-query\",\n  \"srx\": \"application/sparql-results+xml\",\n  \"gram\": \"application/srgs\",\n  \"grxml\": \"application/srgs+xml\",\n  \"sru\": \"application/sru+xml\",\n  \"ssdl\": \"application/ssdl+xml\",\n  \"ssml\": \"application/ssml+xml\",\n  \"swidtag\": \"application/swid+xml\",\n  \"tei\": \"application/tei+xml\",\n  \"teicorpus\": \"application/tei+xml\",\n  \"tfi\": \"application/thraud+xml\",\n  \"tsd\": \"application/timestamped-data\",\n  \"toml\": \"application/toml\",\n  \"trig\": \"application/trig\",\n  \"ttml\": \"application/ttml+xml\",\n  \"ubj\": \"application/ubjson\",\n  \"rsheet\": \"application/urc-ressheet+xml\",\n  \"td\": \"application/urc-targetdesc+xml\",\n  \"vxml\": \"application/voicexml+xml\",\n  \"wasm\": \"application/wasm\",\n  \"wgt\": \"application/widget\",\n  \"hlp\": \"application/winhlp\",\n  \"wsdl\": \"application/wsdl+xml\",\n  \"wspolicy\": \"application/wspolicy+xml\",\n  \"xaml\": \"application/xaml+xml\",\n  \"xav\": \"application/xcap-att+xml\",\n  \"xca\": \"application/xcap-caps+xml\",\n  \"xdf\": \"application/xcap-diff+xml\",\n  \"xel\": \"application/xcap-el+xml\",\n  \"xns\": \"application/xcap-ns+xml\",\n  \"xenc\": \"application/xenc+xml\",\n  \"xhtml\": \"application/xhtml+xml\",\n  \"xht\": \"application/xhtml+xml\",\n  \"xlf\": \"application/xliff+xml\",\n  \"xml\": \"application/xml\",\n  \"xsl\": \"application/xml\",\n  \"xsd\": \"application/xml\",\n  \"rng\": \"application/xml\",\n  \"dtd\": \"application/xml-dtd\",\n  \"xop\": \"application/xop+xml\",\n  \"xpl\": \"application/xproc+xml\",\n  \"xslt\": \"application/xml\",\n  \"xspf\": \"application/xspf+xml\",\n  \"mxml\": \"application/xv+xml\",\n  \"xhvml\": \"application/xv+xml\",\n  \"xvml\": \"application/xv+xml\",\n  \"xvm\": \"application/xv+xml\",\n  \"yang\": \"application/yang\",\n  \"yin\": \"application/yin+xml\",\n  \"zip\": \"application/zip\",\n  \"3gpp\": \"video/3gpp\",\n  \"adp\": \"audio/adpcm\",\n  \"amr\": \"audio/amr\",\n  \"au\": \"audio/basic\",\n  \"snd\": \"audio/basic\",\n  \"mid\": \"audio/midi\",\n  \"midi\": \"audio/midi\",\n  \"kar\": \"audio/midi\",\n  \"rmi\": \"audio/midi\",\n  \"mxmf\": \"audio/mobile-xmf\",\n  \"mp3\": \"audio/mpeg\",\n  \"m4a\": \"audio/mp4\",\n  \"mp4a\": \"audio/mp4\",\n  \"mpga\": \"audio/mpeg\",\n  \"mp2\": \"audio/mpeg\",\n  \"mp2a\": \"audio/mpeg\",\n  \"m2a\": \"audio/mpeg\",\n  \"m3a\": \"audio/mpeg\",\n  \"oga\": \"audio/ogg\",\n  \"ogg\": \"audio/ogg\",\n  \"spx\": \"audio/ogg\",\n  \"opus\": \"audio/ogg\",\n  \"s3m\": \"audio/s3m\",\n  \"sil\": \"audio/silk\",\n  \"wav\": \"audio/wav\",\n  \"weba\": \"audio/webm\",\n  \"xm\": \"audio/xm\",\n  \"ttc\": \"font/collection\",\n  \"otf\": \"font/otf\",\n  \"ttf\": \"font/ttf\",\n  \"woff\": \"font/woff\",\n  \"woff2\": \"font/woff2\",\n  \"exr\": \"image/aces\",\n  \"apng\": \"image/apng\",\n  \"avif\": \"image/avif\",\n  \"bmp\": \"image/bmp\",\n  \"cgm\": \"image/cgm\",\n  \"drle\": \"image/dicom-rle\",\n  \"emf\": \"image/emf\",\n  \"fits\": \"image/fits\",\n  \"g3\": \"image/g3fax\",\n  \"gif\": \"image/gif\",\n  \"heic\": \"image/heic\",\n  \"heics\": \"image/heic-sequence\",\n  \"heif\": \"image/heif\",\n  \"heifs\": \"image/heif-sequence\",\n  \"hej2\": \"image/hej2k\",\n  \"hsj2\": \"image/hsj2\",\n  \"ief\": \"image/ief\",\n  \"jls\": \"image/jls\",\n  \"jp2\": \"image/jp2\",\n  \"jpg2\": \"image/jp2\",\n  \"jpeg\": \"image/jpeg\",\n  \"jpg\": \"image/jpeg\",\n  \"jpe\": \"image/jpeg\",\n  \"jph\": \"image/jph\",\n  \"jhc\": \"image/jphc\",\n  \"jpm\": \"image/jpm\",\n  \"jpx\": \"image/jpx\",\n  \"jpf\": \"image/jpx\",\n  \"jxr\": \"image/jxr\",\n  \"jxra\": \"image/jxra\",\n  \"jxrs\": \"image/jxrs\",\n  \"jxs\": \"image/jxs\",\n  \"jxsc\": \"image/jxsc\",\n  \"jxsi\": \"image/jxsi\",\n  \"jxss\": \"image/jxss\",\n  \"ktx\": \"image/ktx\",\n  \"ktx2\": \"image/ktx2\",\n  \"png\": \"image/png\",\n  \"btif\": \"image/prs.btif\",\n  \"pti\": \"image/prs.pti\",\n  \"sgi\": \"image/sgi\",\n  \"svg\": \"image/svg+xml\",\n  \"svgz\": \"image/svg+xml\",\n  \"t38\": \"image/t38\",\n  \"tif\": \"image/tiff\",\n  \"tiff\": \"image/tiff\",\n  \"tfx\": \"image/tiff-fx\",\n  \"webp\": \"image/webp\",\n  \"wmf\": \"image/wmf\",\n  \"disposition-notification\": \"message/disposition-notification\",\n  \"u8msg\": \"message/global\",\n  \"u8dsn\": \"message/global-delivery-status\",\n  \"u8mdn\": \"message/global-disposition-notification\",\n  \"u8hdr\": \"message/global-headers\",\n  \"eml\": \"message/rfc822\",\n  \"mime\": \"message/rfc822\",\n  \"3mf\": \"model/3mf\",\n  \"gltf\": \"model/gltf+json\",\n  \"glb\": \"model/gltf-binary\",\n  \"igs\": \"model/iges\",\n  \"iges\": \"model/iges\",\n  \"msh\": \"model/mesh\",\n  \"mesh\": \"model/mesh\",\n  \"silo\": \"model/mesh\",\n  \"mtl\": \"model/mtl\",\n  \"obj\": \"model/obj\",\n  \"stpz\": \"model/step+zip\",\n  \"stpxz\": \"model/step-xml+zip\",\n  \"stl\": \"model/stl\",\n  \"wrl\": \"model/vrml\",\n  \"vrml\": \"model/vrml\",\n  \"x3db\": \"model/x3d+fastinfoset\",\n  \"x3dbz\": \"model/x3d+binary\",\n  \"x3dv\": \"model/x3d-vrml\",\n  \"x3dvz\": \"model/x3d+vrml\",\n  \"x3d\": \"model/x3d+xml\",\n  \"x3dz\": \"model/x3d+xml\",\n  \"appcache\": \"text/cache-manifest\",\n  \"manifest\": \"text/cache-manifest\",\n  \"ics\": \"text/calendar\",\n  \"ifb\": \"text/calendar\",\n  \"coffee\": \"text/coffeescript\",\n  \"litcoffee\": \"text/coffeescript\",\n  \"css\": \"text/css\",\n  \"csv\": \"text/csv\",\n  \"html\": \"text/html\",\n  \"htm\": \"text/html\",\n  \"shtml\": \"text/html\",\n  \"jade\": \"text/jade\",\n  \"jsx\": \"text/jsx\",\n  \"less\": \"text/less\",\n  \"markdown\": \"text/markdown\",\n  \"md\": \"text/markdown\",\n  \"mml\": \"text/mathml\",\n  \"mdx\": \"text/mdx\",\n  \"n3\": \"text/n3\",\n  \"txt\": \"text/plain\",\n  \"text\": \"text/plain\",\n  \"conf\": \"text/plain\",\n  \"def\": \"text/plain\",\n  \"list\": \"text/plain\",\n  \"log\": \"text/plain\",\n  \"in\": \"text/plain\",\n  \"ini\": \"text/plain\",\n  \"dsc\": \"text/prs.lines.tag\",\n  \"rtx\": \"text/richtext\",\n  \"sgml\": \"text/sgml\",\n  \"sgm\": \"text/sgml\",\n  \"shex\": \"text/shex\",\n  \"slim\": \"text/slim\",\n  \"slm\": \"text/slim\",\n  \"spdx\": \"text/spdx\",\n  \"stylus\": \"text/stylus\",\n  \"styl\": \"text/stylus\",\n  \"tsv\": \"text/tab-separated-values\",\n  \"t\": \"text/troff\",\n  \"tr\": \"text/troff\",\n  \"roff\": \"text/troff\",\n  \"man\": \"text/troff\",\n  \"me\": \"text/troff\",\n  \"ms\": \"text/troff\",\n  \"ttl\": \"text/turtle\",\n  \"uri\": \"text/uri-list\",\n  \"uris\": \"text/uri-list\",\n  \"urls\": \"text/uri-list\",\n  \"vcard\": \"text/vcard\",\n  \"vtt\": \"text/vtt\",\n  \"yaml\": \"text/yaml\",\n  \"yml\": \"text/yaml\",\n  \"3gp\": \"video/3gpp\",\n  \"3g2\": \"video/3gpp2\",\n  \"h261\": \"video/h261\",\n  \"h263\": \"video/h263\",\n  \"h264\": \"video/h264\",\n  \"m4s\": \"video/iso.segment\",\n  \"jpgv\": \"video/jpeg\",\n  \"jpgm\": \"image/jpm\",\n  \"mj2\": \"video/mj2\",\n  \"mjp2\": \"video/mj2\",\n  \"ts\": \"video/mp2t\",\n  \"mp4\": \"video/mp4\",\n  \"mp4v\": \"video/mp4\",\n  \"mpg4\": \"video/mp4\",\n  \"mpeg\": \"video/mpeg\",\n  \"mpg\": \"video/mpeg\",\n  \"mpe\": \"video/mpeg\",\n  \"m1v\": \"video/mpeg\",\n  \"m2v\": \"video/mpeg\",\n  \"ogv\": \"video/ogg\",\n  \"qt\": \"video/quicktime\",\n  \"mov\": \"video/quicktime\",\n  \"webm\": \"video/webm\"\n};\n\nfunction lookup(extn) {\n\tlet tmp = ('' + extn).trim().toLowerCase();\n\tlet idx = tmp.lastIndexOf('.');\n\treturn mimes$1[!~idx ? tmp : tmp.substring(++idx)];\n}\n\nconst assetUrlRE = /__VITE_ASSET__([a-z\\d]+)__(?:\\$_(.*?)__)?/g;\nconst rawRE = /(?:\\?|&)raw(?:&|$)/;\nconst urlRE = /(\\?|&)url(?:&|$)/;\nconst jsSourceMapRE = /\\.[cm]?js\\.map$/;\nconst assetCache = new WeakMap();\nconst generatedAssets = new WeakMap();\n// add own dictionary entry by directly assigning mrmime\nfunction registerCustomMime() {\n    // https://github.com/lukeed/mrmime/issues/3\n    mimes$1['ico'] = 'image/x-icon';\n    // https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Containers#flac\n    mimes$1['flac'] = 'audio/flac';\n    // mrmime and mime-db is not released yet: https://github.com/jshttp/mime-db/commit/c9242a9b7d4bb25d7a0c9244adec74aeef08d8a1\n    mimes$1['aac'] = 'audio/aac';\n    // https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types\n    mimes$1['eot'] = 'application/vnd.ms-fontobject';\n}\nfunction renderAssetUrlInJS(ctx, config, chunk, opts, code) {\n    const toRelativeRuntime = createToImportMetaURLBasedRelativeRuntime(opts.format);\n    let match;\n    let s;\n    // Urls added with JS using e.g.\n    // imgElement.src = \"__VITE_ASSET__5aa0ddc0__\" are using quotes\n    // Urls added in CSS that is imported in JS end up like\n    // var inlined = \".inlined{color:green;background:url(__VITE_ASSET__5aa0ddc0__)}\\n\";\n    // In both cases, the wrapping should already be fine\n    assetUrlRE.lastIndex = 0;\n    while ((match = assetUrlRE.exec(code))) {\n        s || (s = new MagicString(code));\n        const [full, referenceId, postfix = ''] = match;\n        const file = ctx.getFileName(referenceId);\n        chunk.viteMetadata.importedAssets.add(cleanUrl(file));\n        const filename = file + postfix;\n        const replacement = toOutputFilePathInJS(filename, 'asset', chunk.fileName, 'js', config, toRelativeRuntime);\n        const replacementString = typeof replacement === 'string'\n            ? JSON.stringify(replacement).slice(1, -1)\n            : `\"+${replacement.runtime}+\"`;\n        s.update(match.index, match.index + full.length, replacementString);\n    }\n    // Replace __VITE_PUBLIC_ASSET__5aa0ddc0__ with absolute paths\n    const publicAssetUrlMap = publicAssetUrlCache.get(config);\n    publicAssetUrlRE.lastIndex = 0;\n    while ((match = publicAssetUrlRE.exec(code))) {\n        s || (s = new MagicString(code));\n        const [full, hash] = match;\n        const publicUrl = publicAssetUrlMap.get(hash).slice(1);\n        const replacement = toOutputFilePathInJS(publicUrl, 'public', chunk.fileName, 'js', config, toRelativeRuntime);\n        const replacementString = typeof replacement === 'string'\n            ? JSON.stringify(replacement).slice(1, -1)\n            : `\"+${replacement.runtime}+\"`;\n        s.update(match.index, match.index + full.length, replacementString);\n    }\n    return s;\n}\n/**\n * Also supports loading plain strings with import text from './foo.txt?raw'\n */\nfunction assetPlugin(config) {\n    registerCustomMime();\n    return {\n        name: 'vite:asset',\n        buildStart() {\n            assetCache.set(config, new Map());\n            generatedAssets.set(config, new Map());\n        },\n        resolveId(id) {\n            if (!config.assetsInclude(cleanUrl(id))) {\n                return;\n            }\n            // imports to absolute urls pointing to files in /public\n            // will fail to resolve in the main resolver. handle them here.\n            const publicFile = checkPublicFile(id, config);\n            if (publicFile) {\n                return id;\n            }\n        },\n        async load(id) {\n            if (id.startsWith('\\0')) {\n                // Rollup convention, this id should be handled by the\n                // plugin that marked it with \\0\n                return;\n            }\n            // raw requests, read from disk\n            if (rawRE.test(id)) {\n                const file = checkPublicFile(id, config) || cleanUrl(id);\n                // raw query, read file and return as string\n                return `export default ${JSON.stringify(await promises$2.readFile(file, 'utf-8'))}`;\n            }\n            if (!config.assetsInclude(cleanUrl(id)) && !urlRE.test(id)) {\n                return;\n            }\n            id = id.replace(urlRE, '$1').replace(/[?&]$/, '');\n            const url = await fileToUrl(id, config, this);\n            return `export default ${JSON.stringify(url)}`;\n        },\n        renderChunk(code, chunk, opts) {\n            const s = renderAssetUrlInJS(this, config, chunk, opts, code);\n            if (s) {\n                return {\n                    code: s.toString(),\n                    map: config.build.sourcemap ? s.generateMap({ hires: true }) : null,\n                };\n            }\n            else {\n                return null;\n            }\n        },\n        generateBundle(_, bundle) {\n            // do not emit assets for SSR build\n            if (config.command === 'build' &&\n                config.build.ssr &&\n                !config.build.ssrEmitAssets) {\n                for (const file in bundle) {\n                    if (bundle[file].type === 'asset' &&\n                        !file.endsWith('ssr-manifest.json') &&\n                        !jsSourceMapRE.test(file)) {\n                        delete bundle[file];\n                    }\n                }\n            }\n        },\n    };\n}\nfunction checkPublicFile(url, { publicDir }) {\n    // note if the file is in /public, the resolver would have returned it\n    // as-is so it's not going to be a fully resolved path.\n    if (!publicDir || !url.startsWith('/')) {\n        return;\n    }\n    const publicFile = path$o.join(publicDir, cleanUrl(url));\n    if (!publicFile.startsWith(publicDir)) {\n        // can happen if URL starts with '../'\n        return;\n    }\n    if (fs$l.existsSync(publicFile)) {\n        return publicFile;\n    }\n    else {\n        return;\n    }\n}\nasync function fileToUrl(id, config, ctx) {\n    if (config.command === 'serve') {\n        return fileToDevUrl(id, config);\n    }\n    else {\n        return fileToBuiltUrl(id, config, ctx);\n    }\n}\nfunction fileToDevUrl(id, config) {\n    let rtn;\n    if (checkPublicFile(id, config)) {\n        // in public dir, keep the url as-is\n        rtn = id;\n    }\n    else if (id.startsWith(config.root)) {\n        // in project root, infer short public path\n        rtn = '/' + path$o.posix.relative(config.root, id);\n    }\n    else {\n        // outside of project root, use absolute fs path\n        // (this is special handled by the serve static middleware\n        rtn = path$o.posix.join(FS_PREFIX, id);\n    }\n    const base = joinUrlSegments(config.server?.origin ?? '', config.base);\n    return joinUrlSegments(base, rtn.replace(/^\\//, ''));\n}\nfunction getPublicAssetFilename(hash, config) {\n    return publicAssetUrlCache.get(config)?.get(hash);\n}\nconst publicAssetUrlCache = new WeakMap();\nconst publicAssetUrlRE = /__VITE_PUBLIC_ASSET__([a-z\\d]{8})__/g;\nfunction publicFileToBuiltUrl(url, config) {\n    if (config.command !== 'build') {\n        // We don't need relative base or renderBuiltUrl support during dev\n        return joinUrlSegments(config.base, url);\n    }\n    const hash = getHash(url);\n    let cache = publicAssetUrlCache.get(config);\n    if (!cache) {\n        cache = new Map();\n        publicAssetUrlCache.set(config, cache);\n    }\n    if (!cache.get(hash)) {\n        cache.set(hash, url);\n    }\n    return `__VITE_PUBLIC_ASSET__${hash}__`;\n}\nconst GIT_LFS_PREFIX = Buffer$1.from('version https://git-lfs.github.com');\nfunction isGitLfsPlaceholder(content) {\n    if (content.length < GIT_LFS_PREFIX.length)\n        return false;\n    // Check whether the content begins with the characteristic string of Git LFS placeholders\n    return GIT_LFS_PREFIX.compare(content, 0, GIT_LFS_PREFIX.length) === 0;\n}\n/**\n * Register an asset to be emitted as part of the bundle (if necessary)\n * and returns the resolved public URL\n */\nasync function fileToBuiltUrl(id, config, pluginContext, skipPublicCheck = false) {\n    if (!skipPublicCheck && checkPublicFile(id, config)) {\n        return publicFileToBuiltUrl(id, config);\n    }\n    const cache = assetCache.get(config);\n    const cached = cache.get(id);\n    if (cached) {\n        return cached;\n    }\n    const file = cleanUrl(id);\n    const content = await promises$2.readFile(file);\n    let url;\n    if (config.build.lib ||\n        (!file.endsWith('.svg') &&\n            !file.endsWith('.html') &&\n            content.length < Number(config.build.assetsInlineLimit) &&\n            !isGitLfsPlaceholder(content))) {\n        if (config.build.lib && isGitLfsPlaceholder(content)) {\n            config.logger.warn(picocolorsExports.yellow(`Inlined file ${id} was not downloaded via Git LFS`));\n        }\n        const mimeType = lookup(file) ?? 'application/octet-stream';\n        // base64 inlined as a string\n        url = `data:${mimeType};base64,${content.toString('base64')}`;\n    }\n    else {\n        // emit as asset\n        const { search, hash } = parse$i(id);\n        const postfix = (search || '') + (hash || '');\n        const referenceId = pluginContext.emitFile({\n            // Ignore directory structure for asset file names\n            name: path$o.basename(file),\n            type: 'asset',\n            source: content,\n        });\n        const originalName = normalizePath$3(path$o.relative(config.root, file));\n        generatedAssets.get(config).set(referenceId, { originalName });\n        url = `__VITE_ASSET__${referenceId}__${postfix ? `$_${postfix}__` : ``}`; // TODO_BASE\n    }\n    cache.set(id, url);\n    return url;\n}\nasync function urlToBuiltUrl(url, importer, config, pluginContext) {\n    if (checkPublicFile(url, config)) {\n        return publicFileToBuiltUrl(url, config);\n    }\n    const file = url.startsWith('/')\n        ? path$o.join(config.root, url)\n        : path$o.join(path$o.dirname(importer), url);\n    return fileToBuiltUrl(file, config, pluginContext, \n    // skip public check since we just did it above\n    true);\n}\n\nfunction manifestPlugin(config) {\n    const manifest = {};\n    let outputCount;\n    return {\n        name: 'vite:manifest',\n        buildStart() {\n            outputCount = 0;\n        },\n        generateBundle({ format }, bundle) {\n            function getChunkName(chunk) {\n                if (chunk.facadeModuleId) {\n                    let name = normalizePath$3(path$o.relative(config.root, chunk.facadeModuleId));\n                    if (format === 'system' && !chunk.name.includes('-legacy')) {\n                        const ext = path$o.extname(name);\n                        const endPos = ext.length !== 0 ? -ext.length : undefined;\n                        name = name.slice(0, endPos) + `-legacy` + ext;\n                    }\n                    return name.replace(/\\0/g, '');\n                }\n                else {\n                    return `_` + path$o.basename(chunk.fileName);\n                }\n            }\n            function getInternalImports(imports) {\n                const filteredImports = [];\n                for (const file of imports) {\n                    if (bundle[file] === undefined) {\n                        continue;\n                    }\n                    filteredImports.push(getChunkName(bundle[file]));\n                }\n                return filteredImports;\n            }\n            function createChunk(chunk) {\n                const manifestChunk = {\n                    file: chunk.fileName,\n                };\n                if (chunk.facadeModuleId) {\n                    manifestChunk.src = getChunkName(chunk);\n                }\n                if (chunk.isEntry) {\n                    manifestChunk.isEntry = true;\n                }\n                if (chunk.isDynamicEntry) {\n                    manifestChunk.isDynamicEntry = true;\n                }\n                if (chunk.imports.length) {\n                    const internalImports = getInternalImports(chunk.imports);\n                    if (internalImports.length > 0) {\n                        manifestChunk.imports = internalImports;\n                    }\n                }\n                if (chunk.dynamicImports.length) {\n                    const internalImports = getInternalImports(chunk.dynamicImports);\n                    if (internalImports.length > 0) {\n                        manifestChunk.dynamicImports = internalImports;\n                    }\n                }\n                if (chunk.viteMetadata?.importedCss.size) {\n                    manifestChunk.css = [...chunk.viteMetadata.importedCss];\n                }\n                if (chunk.viteMetadata?.importedAssets.size) {\n                    manifestChunk.assets = [...chunk.viteMetadata.importedAssets];\n                }\n                return manifestChunk;\n            }\n            function createAsset(asset, src, isEntry) {\n                const manifestChunk = {\n                    file: asset.fileName,\n                    src,\n                };\n                if (isEntry)\n                    manifestChunk.isEntry = true;\n                return manifestChunk;\n            }\n            const fileNameToAssetMeta = new Map();\n            const assets = generatedAssets.get(config);\n            assets.forEach((asset, referenceId) => {\n                const fileName = this.getFileName(referenceId);\n                fileNameToAssetMeta.set(fileName, asset);\n            });\n            const fileNameToAsset = new Map();\n            for (const file in bundle) {\n                const chunk = bundle[file];\n                if (chunk.type === 'chunk') {\n                    manifest[getChunkName(chunk)] = createChunk(chunk);\n                }\n                else if (chunk.type === 'asset' && typeof chunk.name === 'string') {\n                    // Add every unique asset to the manifest, keyed by its original name\n                    const assetMeta = fileNameToAssetMeta.get(chunk.fileName);\n                    const src = assetMeta?.originalName ?? chunk.name;\n                    const asset = createAsset(chunk, src, assetMeta?.isEntry);\n                    manifest[src] = asset;\n                    fileNameToAsset.set(chunk.fileName, asset);\n                }\n            }\n            // Add deduplicated assets to the manifest\n            assets.forEach(({ originalName }, referenceId) => {\n                if (!manifest[originalName]) {\n                    const fileName = this.getFileName(referenceId);\n                    const asset = fileNameToAsset.get(fileName);\n                    if (asset) {\n                        manifest[originalName] = asset;\n                    }\n                }\n            });\n            outputCount++;\n            const output = config.build.rollupOptions?.output;\n            const outputLength = Array.isArray(output) ? output.length : 1;\n            if (outputCount >= outputLength) {\n                this.emitFile({\n                    fileName: typeof config.build.manifest === 'string'\n                        ? config.build.manifest\n                        : 'manifest.json',\n                    type: 'asset',\n                    source: jsonStableStringify(manifest, { space: 2 }),\n                });\n            }\n        },\n    };\n}\n\n// This is based on @rollup/plugin-data-uri\nconst dataUriRE = /^([^/]+\\/[^;,]+)(;base64)?,([\\s\\S]*)$/;\nconst dataUriPrefix = `/@data-uri/`;\n/**\n * Build only, since importing from a data URI works natively.\n */\nfunction dataURIPlugin() {\n    let resolved;\n    return {\n        name: 'vite:data-uri',\n        buildStart() {\n            resolved = {};\n        },\n        resolveId(id) {\n            if (!dataUriRE.test(id)) {\n                return null;\n            }\n            const uri = new URL$3(id);\n            if (uri.protocol !== 'data:') {\n                return null;\n            }\n            const match = uri.pathname.match(dataUriRE);\n            if (!match) {\n                return null;\n            }\n            const [, mime, format, data] = match;\n            if (mime !== 'text/javascript') {\n                throw new Error(`data URI with non-JavaScript mime type is not supported.`);\n            }\n            // decode data\n            const base64 = format && /base64/i.test(format.substring(1));\n            const content = base64\n                ? Buffer.from(data, 'base64').toString('utf-8')\n                : data;\n            resolved[id] = content;\n            return dataUriPrefix + id;\n        },\n        load(id) {\n            if (id.startsWith(dataUriPrefix)) {\n                id = id.slice(dataUriPrefix.length);\n                return resolved[id] || null;\n            }\n        },\n    };\n}\n\n/* es-module-lexer 1.1.0 */\nconst A=1===new Uint8Array(new Uint16Array([1]).buffer)[0];function parse$e(E,g=\"@\"){if(!C)return init.then((()=>parse$e(E)));const I=E.length+1,K=(C.__heap_base.value||C.__heap_base)+4*I-C.memory.buffer.byteLength;K>0&&C.memory.grow(Math.ceil(K/65536));const k=C.sa(I-1);if((A?B:Q)(E,new Uint16Array(C.memory.buffer,k,I)),!C.parse())throw Object.assign(new Error(`Parse error ${g}:${E.slice(0,C.e()).split(\"\\n\").length}:${C.e()-E.lastIndexOf(\"\\n\",C.e()-1)}`),{idx:C.e()});const o=[],D=[];for(;C.ri();){const A=C.is(),Q=C.ie(),B=C.ai(),g=C.id(),I=C.ss(),K=C.se();let k;C.ip()&&(k=w(E.slice(-1===g?A-1:A,-1===g?Q+1:Q))),o.push({n:k,s:A,e:Q,ss:I,se:K,d:g,a:B});}for(;C.re();){const A=C.es(),Q=C.ee(),B=C.els(),g=C.ele(),I=E.slice(A,Q),K=I[0],k=B<0?void 0:E.slice(B,g),o=k?k[0]:\"\";D.push({s:A,e:Q,ls:B,le:g,n:'\"'===K||\"'\"===K?w(I):I,ln:'\"'===o||\"'\"===o?w(k):k});}function w(A){try{return (0, eval)(A)}catch(A){}}return [o,D,!!C.f()]}function Q(A,Q){const B=A.length;let C=0;for(;C<B;){const B=A.charCodeAt(C);Q[C++]=(255&B)<<8|B>>>8;}}function B(A,Q){const B=A.length;let C=0;for(;C<B;)Q[C]=A.charCodeAt(C++);}let C;const init=WebAssembly.compile((E=\"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\",\"undefined\"!=typeof Buffer?Buffer.from(E,\"base64\"):Uint8Array.from(atob(E),(A=>A.charCodeAt(0))))).then(WebAssembly.instantiate).then((({exports:A})=>{C=A;}));var E;\n\nconst isDebug$6 = !!process.env.DEBUG;\nconst debug$e = createDebugger('vite:sourcemap', {\n    onlyWhenFocused: true,\n});\n// Virtual modules should be prefixed with a null byte to avoid a\n// false positive \"missing source\" warning. We also check for certain\n// prefixes used for special handling in esbuildDepPlugin.\nconst virtualSourceRE = /^(?:\\0|dep:|browser-external:)/;\nasync function injectSourcesContent(map, file, logger) {\n    let sourceRoot;\n    try {\n        // The source root is undefined for virtual modules and permission errors.\n        sourceRoot = await promises$2.realpath(path$o.resolve(path$o.dirname(file), map.sourceRoot || ''));\n    }\n    catch { }\n    const missingSources = [];\n    map.sourcesContent = await Promise.all(map.sources.map((sourcePath) => {\n        if (sourcePath && !virtualSourceRE.test(sourcePath)) {\n            sourcePath = decodeURI(sourcePath);\n            if (sourceRoot) {\n                sourcePath = path$o.resolve(sourceRoot, sourcePath);\n            }\n            return promises$2.readFile(sourcePath, 'utf-8').catch(() => {\n                missingSources.push(sourcePath);\n                return null;\n            });\n        }\n        return null;\n    }));\n    // Use this command…\n    //    DEBUG=\"vite:sourcemap\" vite build\n    // …to log the missing sources.\n    if (missingSources.length) {\n        logger.warnOnce(`Sourcemap for \"${file}\" points to missing source files`);\n        isDebug$6 && debug$e(`Missing sources:\\n  ` + missingSources.join(`\\n  `));\n    }\n}\nfunction genSourceMapUrl(map) {\n    if (typeof map !== 'string') {\n        map = JSON.stringify(map);\n    }\n    return `data:application/json;base64,${Buffer.from(map).toString('base64')}`;\n}\nfunction getCodeWithSourcemap(type, code, map) {\n    if (isDebug$6) {\n        code += `\\n/*${JSON.stringify(map, null, 2).replace(/\\*\\//g, '*\\\\/')}*/\\n`;\n    }\n    if (type === 'js') {\n        code += `\\n//# sourceMappingURL=${genSourceMapUrl(map)}`;\n    }\n    else if (type === 'css') {\n        code += `\\n/*# sourceMappingURL=${genSourceMapUrl(map)} */`;\n    }\n    return code;\n}\n\nfunction e(e,n,r){throw new Error(r?`No known conditions for \"${n}\" specifier in \"${e}\" package`:`Missing \"${n}\" specifier in \"${e}\" package`)}function n(n,i,o,f){let s,u,l=r(n,o),c=function(e){let n=new Set([\"default\",...e.conditions||[]]);return e.unsafe||n.add(e.require?\"require\":\"import\"),e.unsafe||n.add(e.browser?\"browser\":\"node\"),n}(f||{}),a=i[l];if(void 0===a){let e,n,r,t;for(t in i)n&&t.length<n.length||(\"/\"===t[t.length-1]&&l.startsWith(t)?(u=l.substring(t.length),n=t):t.length>1&&(r=t.indexOf(\"*\",2),~r&&(e=RegExp(\"^\"+t.substring(0,r)+\"(.*)\"+t.substring(1+r)).exec(l),e&&e[1]&&(u=e[1],n=t))));a=i[n];}return a||e(n,l),s=t(a,c),s||e(n,l,1),u&&function(e,n){let r,t=0,i=e.length,o=/[*]/g;for(;t<i;t++)e[t]=o.test(r=e[t])?r.replace(o,n):r+n;}(s,u),s}function r(e,n,r){if(e===n||\".\"===n)return \".\";let t=e+\"/\",i=t.length,o=n.slice(0,i)===t,f=o?n.slice(i):n;return \"#\"===f[0]?f:o||!r?\"./\"===f.slice(0,2)?f:\"./\"+f:f}function t(e,n,r){if(e){if(\"string\"==typeof e)return r&&r.add(e),[e];let i,o;if(Array.isArray(e)){for(o=r||new Set,i=0;i<e.length;i++)t(e[i],n,o);if(!r&&o.size)return [...o]}else for(i in e)if(n.has(i))return t(e[i],n,r)}}function o(e,r,t){let i,o=e.exports;if(o){if(\"string\"==typeof o)o={\".\":o};else for(i in o){\".\"!==i[0]&&(o={\".\":o});break}return n(e.name,o,r||\".\",t)}}\n\n// This file was generated. Do not modify manually!\nvar astralIdentifierCodes = [509, 0, 227, 0, 150, 4, 294, 9, 1368, 2, 2, 1, 6, 3, 41, 2, 5, 0, 166, 1, 574, 3, 9, 9, 370, 1, 81, 2, 71, 10, 50, 3, 123, 2, 54, 14, 32, 10, 3, 1, 11, 3, 46, 10, 8, 0, 46, 9, 7, 2, 37, 13, 2, 9, 6, 1, 45, 0, 13, 2, 49, 13, 9, 3, 2, 11, 83, 11, 7, 0, 3, 0, 158, 11, 6, 9, 7, 3, 56, 1, 2, 6, 3, 1, 3, 2, 10, 0, 11, 1, 3, 6, 4, 4, 193, 17, 10, 9, 5, 0, 82, 19, 13, 9, 214, 6, 3, 8, 28, 1, 83, 16, 16, 9, 82, 12, 9, 9, 84, 14, 5, 9, 243, 14, 166, 9, 71, 5, 2, 1, 3, 3, 2, 0, 2, 1, 13, 9, 120, 6, 3, 6, 4, 0, 29, 9, 41, 6, 2, 3, 9, 0, 10, 10, 47, 15, 406, 7, 2, 7, 17, 9, 57, 21, 2, 13, 123, 5, 4, 0, 2, 1, 2, 6, 2, 0, 9, 9, 49, 4, 2, 1, 2, 4, 9, 9, 330, 3, 10, 1, 2, 0, 49, 6, 4, 4, 14, 9, 5351, 0, 7, 14, 13835, 9, 87, 9, 39, 4, 60, 6, 26, 9, 1014, 0, 2, 54, 8, 3, 82, 0, 12, 1, 19628, 1, 4706, 45, 3, 22, 543, 4, 4, 5, 9, 7, 3, 6, 31, 3, 149, 2, 1418, 49, 513, 54, 5, 49, 9, 0, 15, 0, 23, 4, 2, 14, 1361, 6, 2, 16, 3, 6, 2, 1, 2, 4, 101, 0, 161, 6, 10, 9, 357, 0, 62, 13, 499, 13, 983, 6, 110, 6, 6, 9, 4759, 9, 787719, 239];\n\n// This file was generated. Do not modify manually!\nvar astralIdentifierStartCodes = [0, 11, 2, 25, 2, 18, 2, 1, 2, 14, 3, 13, 35, 122, 70, 52, 268, 28, 4, 48, 48, 31, 14, 29, 6, 37, 11, 29, 3, 35, 5, 7, 2, 4, 43, 157, 19, 35, 5, 35, 5, 39, 9, 51, 13, 10, 2, 14, 2, 6, 2, 1, 2, 10, 2, 14, 2, 6, 2, 1, 68, 310, 10, 21, 11, 7, 25, 5, 2, 41, 2, 8, 70, 5, 3, 0, 2, 43, 2, 1, 4, 0, 3, 22, 11, 22, 10, 30, 66, 18, 2, 1, 11, 21, 11, 25, 71, 55, 7, 1, 65, 0, 16, 3, 2, 2, 2, 28, 43, 28, 4, 28, 36, 7, 2, 27, 28, 53, 11, 21, 11, 18, 14, 17, 111, 72, 56, 50, 14, 50, 14, 35, 349, 41, 7, 1, 79, 28, 11, 0, 9, 21, 43, 17, 47, 20, 28, 22, 13, 52, 58, 1, 3, 0, 14, 44, 33, 24, 27, 35, 30, 0, 3, 0, 9, 34, 4, 0, 13, 47, 15, 3, 22, 0, 2, 0, 36, 17, 2, 24, 20, 1, 64, 6, 2, 0, 2, 3, 2, 14, 2, 9, 8, 46, 39, 7, 3, 1, 3, 21, 2, 6, 2, 1, 2, 4, 4, 0, 19, 0, 13, 4, 159, 52, 19, 3, 21, 2, 31, 47, 21, 1, 2, 0, 185, 46, 42, 3, 37, 47, 21, 0, 60, 42, 14, 0, 72, 26, 38, 6, 186, 43, 117, 63, 32, 7, 3, 0, 3, 7, 2, 1, 2, 23, 16, 0, 2, 0, 95, 7, 3, 38, 17, 0, 2, 0, 29, 0, 11, 39, 8, 0, 22, 0, 12, 45, 20, 0, 19, 72, 264, 8, 2, 36, 18, 0, 50, 29, 113, 6, 2, 1, 2, 37, 22, 0, 26, 5, 2, 1, 2, 31, 15, 0, 328, 18, 16, 0, 2, 12, 2, 33, 125, 0, 80, 921, 103, 110, 18, 195, 2637, 96, 16, 1071, 18, 5, 4026, 582, 8634, 568, 8, 30, 18, 78, 18, 29, 19, 47, 17, 3, 32, 20, 6, 18, 689, 63, 129, 74, 6, 0, 67, 12, 65, 1, 2, 0, 29, 6135, 9, 1237, 43, 8, 8936, 3, 2, 6, 2, 1, 2, 290, 16, 0, 30, 2, 3, 0, 15, 3, 9, 395, 2309, 106, 6, 12, 4, 8, 8, 9, 5991, 84, 2, 70, 2, 1, 3, 0, 3, 1, 3, 3, 2, 11, 2, 0, 2, 6, 2, 64, 2, 3, 3, 7, 2, 6, 2, 27, 2, 3, 2, 4, 2, 0, 4, 6, 2, 339, 3, 24, 2, 24, 2, 30, 2, 24, 2, 30, 2, 24, 2, 30, 2, 24, 2, 30, 2, 24, 2, 7, 1845, 30, 7, 5, 262, 61, 147, 44, 11, 6, 17, 0, 322, 29, 19, 43, 485, 27, 757, 6, 2, 3, 2, 1, 2, 14, 2, 196, 60, 67, 8, 0, 1205, 3, 2, 26, 2, 1, 2, 0, 3, 0, 2, 9, 2, 3, 2, 0, 2, 0, 7, 0, 5, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 0, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 3, 3, 2, 6, 2, 3, 2, 3, 2, 0, 2, 9, 2, 16, 6, 2, 2, 4, 2, 16, 4421, 42719, 33, 4153, 7, 221, 3, 5761, 15, 7472, 3104, 541, 1507, 4938, 6, 4191];\n\n// This file was generated. Do not modify manually!\nvar nonASCIIidentifierChars = \"\\u200c\\u200d\\xb7\\u0300-\\u036f\\u0387\\u0483-\\u0487\\u0591-\\u05bd\\u05bf\\u05c1\\u05c2\\u05c4\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u0669\\u0670\\u06d6-\\u06dc\\u06df-\\u06e4\\u06e7\\u06e8\\u06ea-\\u06ed\\u06f0-\\u06f9\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07c0-\\u07c9\\u07eb-\\u07f3\\u07fd\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0859-\\u085b\\u0898-\\u089f\\u08ca-\\u08e1\\u08e3-\\u0903\\u093a-\\u093c\\u093e-\\u094f\\u0951-\\u0957\\u0962\\u0963\\u0966-\\u096f\\u0981-\\u0983\\u09bc\\u09be-\\u09c4\\u09c7\\u09c8\\u09cb-\\u09cd\\u09d7\\u09e2\\u09e3\\u09e6-\\u09ef\\u09fe\\u0a01-\\u0a03\\u0a3c\\u0a3e-\\u0a42\\u0a47\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a66-\\u0a71\\u0a75\\u0a81-\\u0a83\\u0abc\\u0abe-\\u0ac5\\u0ac7-\\u0ac9\\u0acb-\\u0acd\\u0ae2\\u0ae3\\u0ae6-\\u0aef\\u0afa-\\u0aff\\u0b01-\\u0b03\\u0b3c\\u0b3e-\\u0b44\\u0b47\\u0b48\\u0b4b-\\u0b4d\\u0b55-\\u0b57\\u0b62\\u0b63\\u0b66-\\u0b6f\\u0b82\\u0bbe-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcd\\u0bd7\\u0be6-\\u0bef\\u0c00-\\u0c04\\u0c3c\\u0c3e-\\u0c44\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55\\u0c56\\u0c62\\u0c63\\u0c66-\\u0c6f\\u0c81-\\u0c83\\u0cbc\\u0cbe-\\u0cc4\\u0cc6-\\u0cc8\\u0cca-\\u0ccd\\u0cd5\\u0cd6\\u0ce2\\u0ce3\\u0ce6-\\u0cef\\u0cf3\\u0d00-\\u0d03\\u0d3b\\u0d3c\\u0d3e-\\u0d44\\u0d46-\\u0d48\\u0d4a-\\u0d4d\\u0d57\\u0d62\\u0d63\\u0d66-\\u0d6f\\u0d81-\\u0d83\\u0dca\\u0dcf-\\u0dd4\\u0dd6\\u0dd8-\\u0ddf\\u0de6-\\u0def\\u0df2\\u0df3\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0e50-\\u0e59\\u0eb1\\u0eb4-\\u0ebc\\u0ec8-\\u0ece\\u0ed0-\\u0ed9\\u0f18\\u0f19\\u0f20-\\u0f29\\u0f35\\u0f37\\u0f39\\u0f3e\\u0f3f\\u0f71-\\u0f84\\u0f86\\u0f87\\u0f8d-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102b-\\u103e\\u1040-\\u1049\\u1056-\\u1059\\u105e-\\u1060\\u1062-\\u1064\\u1067-\\u106d\\u1071-\\u1074\\u1082-\\u108d\\u108f-\\u109d\\u135d-\\u135f\\u1369-\\u1371\\u1712-\\u1715\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17b4-\\u17d3\\u17dd\\u17e0-\\u17e9\\u180b-\\u180d\\u180f-\\u1819\\u18a9\\u1920-\\u192b\\u1930-\\u193b\\u1946-\\u194f\\u19d0-\\u19da\\u1a17-\\u1a1b\\u1a55-\\u1a5e\\u1a60-\\u1a7c\\u1a7f-\\u1a89\\u1a90-\\u1a99\\u1ab0-\\u1abd\\u1abf-\\u1ace\\u1b00-\\u1b04\\u1b34-\\u1b44\\u1b50-\\u1b59\\u1b6b-\\u1b73\\u1b80-\\u1b82\\u1ba1-\\u1bad\\u1bb0-\\u1bb9\\u1be6-\\u1bf3\\u1c24-\\u1c37\\u1c40-\\u1c49\\u1c50-\\u1c59\\u1cd0-\\u1cd2\\u1cd4-\\u1ce8\\u1ced\\u1cf4\\u1cf7-\\u1cf9\\u1dc0-\\u1dff\\u203f\\u2040\\u2054\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2cef-\\u2cf1\\u2d7f\\u2de0-\\u2dff\\u302a-\\u302f\\u3099\\u309a\\ua620-\\ua629\\ua66f\\ua674-\\ua67d\\ua69e\\ua69f\\ua6f0\\ua6f1\\ua802\\ua806\\ua80b\\ua823-\\ua827\\ua82c\\ua880\\ua881\\ua8b4-\\ua8c5\\ua8d0-\\ua8d9\\ua8e0-\\ua8f1\\ua8ff-\\ua909\\ua926-\\ua92d\\ua947-\\ua953\\ua980-\\ua983\\ua9b3-\\ua9c0\\ua9d0-\\ua9d9\\ua9e5\\ua9f0-\\ua9f9\\uaa29-\\uaa36\\uaa43\\uaa4c\\uaa4d\\uaa50-\\uaa59\\uaa7b-\\uaa7d\\uaab0\\uaab2-\\uaab4\\uaab7\\uaab8\\uaabe\\uaabf\\uaac1\\uaaeb-\\uaaef\\uaaf5\\uaaf6\\uabe3-\\uabea\\uabec\\uabed\\uabf0-\\uabf9\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe2f\\ufe33\\ufe34\\ufe4d-\\ufe4f\\uff10-\\uff19\\uff3f\";\n\n// This file was generated. Do not modify manually!\nvar nonASCIIidentifierStartChars = \"\\xaa\\xb5\\xba\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0370-\\u0374\\u0376\\u0377\\u037a-\\u037d\\u037f\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u03a1\\u03a3-\\u03f5\\u03f7-\\u0481\\u048a-\\u052f\\u0531-\\u0556\\u0559\\u0560-\\u0588\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0620-\\u064a\\u066e\\u066f\\u0671-\\u06d3\\u06d5\\u06e5\\u06e6\\u06ee\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5\\u07b1\\u07ca-\\u07ea\\u07f4\\u07f5\\u07fa\\u0800-\\u0815\\u081a\\u0824\\u0828\\u0840-\\u0858\\u0860-\\u086a\\u0870-\\u0887\\u0889-\\u088e\\u08a0-\\u08c9\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961\\u0971-\\u0980\\u0985-\\u098c\\u098f\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bd\\u09ce\\u09dc\\u09dd\\u09df-\\u09e1\\u09f0\\u09f1\\u09fc\\u0a05-\\u0a0a\\u0a0f\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32\\u0a33\\u0a35\\u0a36\\u0a38\\u0a39\\u0a59-\\u0a5c\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2\\u0ab3\\u0ab5-\\u0ab9\\u0abd\\u0ad0\\u0ae0\\u0ae1\\u0af9\\u0b05-\\u0b0c\\u0b0f\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32\\u0b33\\u0b35-\\u0b39\\u0b3d\\u0b5c\\u0b5d\\u0b5f-\\u0b61\\u0b71\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99\\u0b9a\\u0b9c\\u0b9e\\u0b9f\\u0ba3\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bd0\\u0c05-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d\\u0c58-\\u0c5a\\u0c5d\\u0c60\\u0c61\\u0c80\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbd\\u0cdd\\u0cde\\u0ce0\\u0ce1\\u0cf1\\u0cf2\\u0d04-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d3a\\u0d3d\\u0d4e\\u0d54-\\u0d56\\u0d5f-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0e01-\\u0e30\\u0e32\\u0e33\\u0e40-\\u0e46\\u0e81\\u0e82\\u0e84\\u0e86-\\u0e8a\\u0e8c-\\u0ea3\\u0ea5\\u0ea7-\\u0eb0\\u0eb2\\u0eb3\\u0ebd\\u0ec0-\\u0ec4\\u0ec6\\u0edc-\\u0edf\\u0f00\\u0f40-\\u0f47\\u0f49-\\u0f6c\\u0f88-\\u0f8c\\u1000-\\u102a\\u103f\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065\\u1066\\u106e-\\u1070\\u1075-\\u1081\\u108e\\u10a0-\\u10c5\\u10c7\\u10cd\\u10d0-\\u10fa\\u10fc-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u1380-\\u138f\\u13a0-\\u13f5\\u13f8-\\u13fd\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u16f8\\u1700-\\u1711\\u171f-\\u1731\\u1740-\\u1751\\u1760-\\u176c\\u176e-\\u1770\\u1780-\\u17b3\\u17d7\\u17dc\\u1820-\\u1878\\u1880-\\u18a8\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1950-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u1a00-\\u1a16\\u1a20-\\u1a54\\u1aa7\\u1b05-\\u1b33\\u1b45-\\u1b4c\\u1b83-\\u1ba0\\u1bae\\u1baf\\u1bba-\\u1be5\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c7d\\u1c80-\\u1c88\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1ce9-\\u1cec\\u1cee-\\u1cf3\\u1cf5\\u1cf6\\u1cfa\\u1d00-\\u1dbf\\u1e00-\\u1f15\\u1f18-\\u1f1d\\u1f20-\\u1f45\\u1f48-\\u1f4d\\u1f50-\\u1f57\\u1f59\\u1f5b\\u1f5d\\u1f5f-\\u1f7d\\u1f80-\\u1fb4\\u1fb6-\\u1fbc\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fcc\\u1fd0-\\u1fd3\\u1fd6-\\u1fdb\\u1fe0-\\u1fec\\u1ff2-\\u1ff4\\u1ff6-\\u1ffc\\u2071\\u207f\\u2090-\\u209c\\u2102\\u2107\\u210a-\\u2113\\u2115\\u2118-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u2139\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2ce4\\u2ceb-\\u2cee\\u2cf2\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\u2d30-\\u2d67\\u2d6f\\u2d80-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u3005-\\u3007\\u3021-\\u3029\\u3031-\\u3035\\u3038-\\u303c\\u3041-\\u3096\\u309b-\\u309f\\u30a1-\\u30fa\\u30fc-\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31bf\\u31f0-\\u31ff\\u3400-\\u4dbf\\u4e00-\\ua48c\\ua4d0-\\ua4fd\\ua500-\\ua60c\\ua610-\\ua61f\\ua62a\\ua62b\\ua640-\\ua66e\\ua67f-\\ua69d\\ua6a0-\\ua6ef\\ua717-\\ua71f\\ua722-\\ua788\\ua78b-\\ua7ca\\ua7d0\\ua7d1\\ua7d3\\ua7d5-\\ua7d9\\ua7f2-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822\\ua840-\\ua873\\ua882-\\ua8b3\\ua8f2-\\ua8f7\\ua8fb\\ua8fd\\ua8fe\\ua90a-\\ua925\\ua930-\\ua946\\ua960-\\ua97c\\ua984-\\ua9b2\\ua9cf\\ua9e0-\\ua9e4\\ua9e6-\\ua9ef\\ua9fa-\\ua9fe\\uaa00-\\uaa28\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uaa60-\\uaa76\\uaa7a\\uaa7e-\\uaaaf\\uaab1\\uaab5\\uaab6\\uaab9-\\uaabd\\uaac0\\uaac2\\uaadb-\\uaadd\\uaae0-\\uaaea\\uaaf2-\\uaaf4\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uab30-\\uab5a\\uab5c-\\uab69\\uab70-\\uabe2\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb00-\\ufb06\\ufb13-\\ufb17\\ufb1d\\ufb1f-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40\\ufb41\\ufb43\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdfb\\ufe70-\\ufe74\\ufe76-\\ufefc\\uff21-\\uff3a\\uff41-\\uff5a\\uff66-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\";\n\n// These are a run-length and offset encoded representation of the\n\n// Reserved word lists for various dialects of the language\n\nvar reservedWords = {\n  3: \"abstract boolean byte char class double enum export extends final float goto implements import int interface long native package private protected public short static super synchronized throws transient volatile\",\n  5: \"class enum extends super const export import\",\n  6: \"enum\",\n  strict: \"implements interface let package private protected public static yield\",\n  strictBind: \"eval arguments\"\n};\n\n// And the keywords\n\nvar ecma5AndLessKeywords = \"break case catch continue debugger default do else finally for function if return switch throw try var while with null true false instanceof typeof void delete new in this\";\n\nvar keywords$1 = {\n  5: ecma5AndLessKeywords,\n  \"5module\": ecma5AndLessKeywords + \" export import\",\n  6: ecma5AndLessKeywords + \" const class extends export import super\"\n};\n\nvar keywordRelationalOperator = /^in(stanceof)?$/;\n\n// ## Character categories\n\nvar nonASCIIidentifierStart = new RegExp(\"[\" + nonASCIIidentifierStartChars + \"]\");\nvar nonASCIIidentifier = new RegExp(\"[\" + nonASCIIidentifierStartChars + nonASCIIidentifierChars + \"]\");\n\n// This has a complexity linear to the value of the code. The\n// assumption is that looking up astral identifier characters is\n// rare.\nfunction isInAstralSet(code, set) {\n  var pos = 0x10000;\n  for (var i = 0; i < set.length; i += 2) {\n    pos += set[i];\n    if (pos > code) { return false }\n    pos += set[i + 1];\n    if (pos >= code) { return true }\n  }\n  return false\n}\n\n// Test whether a given character code starts an identifier.\n\nfunction isIdentifierStart(code, astral) {\n  if (code < 65) { return code === 36 }\n  if (code < 91) { return true }\n  if (code < 97) { return code === 95 }\n  if (code < 123) { return true }\n  if (code <= 0xffff) { return code >= 0xaa && nonASCIIidentifierStart.test(String.fromCharCode(code)) }\n  if (astral === false) { return false }\n  return isInAstralSet(code, astralIdentifierStartCodes)\n}\n\n// Test whether a given character is part of an identifier.\n\nfunction isIdentifierChar(code, astral) {\n  if (code < 48) { return code === 36 }\n  if (code < 58) { return true }\n  if (code < 65) { return false }\n  if (code < 91) { return true }\n  if (code < 97) { return code === 95 }\n  if (code < 123) { return true }\n  if (code <= 0xffff) { return code >= 0xaa && nonASCIIidentifier.test(String.fromCharCode(code)) }\n  if (astral === false) { return false }\n  return isInAstralSet(code, astralIdentifierStartCodes) || isInAstralSet(code, astralIdentifierCodes)\n}\n\n// ## Token types\n\n// The assignment of fine-grained, information-carrying type objects\n// allows the tokenizer to store the information it has about a\n// token in a way that is very cheap for the parser to look up.\n\n// All token type variables start with an underscore, to make them\n// easy to recognize.\n\n// The `beforeExpr` property is used to disambiguate between regular\n// expressions and divisions. It is set on all token types that can\n// be followed by an expression (thus, a slash after them would be a\n// regular expression).\n//\n// The `startsExpr` property is used to check if the token ends a\n// `yield` expression. It is set on all token types that either can\n// directly start an expression (like a quotation mark) or can\n// continue an expression (like the body of a string).\n//\n// `isLoop` marks a keyword as starting a loop, which is important\n// to know when parsing a label, in order to allow or disallow\n// continue jumps to that label.\n\nvar TokenType = function TokenType(label, conf) {\n  if ( conf === void 0 ) conf = {};\n\n  this.label = label;\n  this.keyword = conf.keyword;\n  this.beforeExpr = !!conf.beforeExpr;\n  this.startsExpr = !!conf.startsExpr;\n  this.isLoop = !!conf.isLoop;\n  this.isAssign = !!conf.isAssign;\n  this.prefix = !!conf.prefix;\n  this.postfix = !!conf.postfix;\n  this.binop = conf.binop || null;\n  this.updateContext = null;\n};\n\nfunction binop(name, prec) {\n  return new TokenType(name, {beforeExpr: true, binop: prec})\n}\nvar beforeExpr = {beforeExpr: true}, startsExpr = {startsExpr: true};\n\n// Map keyword names to token types.\n\nvar keywords$2 = {};\n\n// Succinct definitions of keyword token types\nfunction kw(name, options) {\n  if ( options === void 0 ) options = {};\n\n  options.keyword = name;\n  return keywords$2[name] = new TokenType(name, options)\n}\n\nvar types$1 = {\n  num: new TokenType(\"num\", startsExpr),\n  regexp: new TokenType(\"regexp\", startsExpr),\n  string: new TokenType(\"string\", startsExpr),\n  name: new TokenType(\"name\", startsExpr),\n  privateId: new TokenType(\"privateId\", startsExpr),\n  eof: new TokenType(\"eof\"),\n\n  // Punctuation token types.\n  bracketL: new TokenType(\"[\", {beforeExpr: true, startsExpr: true}),\n  bracketR: new TokenType(\"]\"),\n  braceL: new TokenType(\"{\", {beforeExpr: true, startsExpr: true}),\n  braceR: new TokenType(\"}\"),\n  parenL: new TokenType(\"(\", {beforeExpr: true, startsExpr: true}),\n  parenR: new TokenType(\")\"),\n  comma: new TokenType(\",\", beforeExpr),\n  semi: new TokenType(\";\", beforeExpr),\n  colon: new TokenType(\":\", beforeExpr),\n  dot: new TokenType(\".\"),\n  question: new TokenType(\"?\", beforeExpr),\n  questionDot: new TokenType(\"?.\"),\n  arrow: new TokenType(\"=>\", beforeExpr),\n  template: new TokenType(\"template\"),\n  invalidTemplate: new TokenType(\"invalidTemplate\"),\n  ellipsis: new TokenType(\"...\", beforeExpr),\n  backQuote: new TokenType(\"`\", startsExpr),\n  dollarBraceL: new TokenType(\"${\", {beforeExpr: true, startsExpr: true}),\n\n  // Operators. These carry several kinds of properties to help the\n  // parser use them properly (the presence of these properties is\n  // what categorizes them as operators).\n  //\n  // `binop`, when present, specifies that this operator is a binary\n  // operator, and will refer to its precedence.\n  //\n  // `prefix` and `postfix` mark the operator as a prefix or postfix\n  // unary operator.\n  //\n  // `isAssign` marks all of `=`, `+=`, `-=` etcetera, which act as\n  // binary operators with a very low precedence, that should result\n  // in AssignmentExpression nodes.\n\n  eq: new TokenType(\"=\", {beforeExpr: true, isAssign: true}),\n  assign: new TokenType(\"_=\", {beforeExpr: true, isAssign: true}),\n  incDec: new TokenType(\"++/--\", {prefix: true, postfix: true, startsExpr: true}),\n  prefix: new TokenType(\"!/~\", {beforeExpr: true, prefix: true, startsExpr: true}),\n  logicalOR: binop(\"||\", 1),\n  logicalAND: binop(\"&&\", 2),\n  bitwiseOR: binop(\"|\", 3),\n  bitwiseXOR: binop(\"^\", 4),\n  bitwiseAND: binop(\"&\", 5),\n  equality: binop(\"==/!=/===/!==\", 6),\n  relational: binop(\"</>/<=/>=\", 7),\n  bitShift: binop(\"<</>>/>>>\", 8),\n  plusMin: new TokenType(\"+/-\", {beforeExpr: true, binop: 9, prefix: true, startsExpr: true}),\n  modulo: binop(\"%\", 10),\n  star: binop(\"*\", 10),\n  slash: binop(\"/\", 10),\n  starstar: new TokenType(\"**\", {beforeExpr: true}),\n  coalesce: binop(\"??\", 1),\n\n  // Keyword token types.\n  _break: kw(\"break\"),\n  _case: kw(\"case\", beforeExpr),\n  _catch: kw(\"catch\"),\n  _continue: kw(\"continue\"),\n  _debugger: kw(\"debugger\"),\n  _default: kw(\"default\", beforeExpr),\n  _do: kw(\"do\", {isLoop: true, beforeExpr: true}),\n  _else: kw(\"else\", beforeExpr),\n  _finally: kw(\"finally\"),\n  _for: kw(\"for\", {isLoop: true}),\n  _function: kw(\"function\", startsExpr),\n  _if: kw(\"if\"),\n  _return: kw(\"return\", beforeExpr),\n  _switch: kw(\"switch\"),\n  _throw: kw(\"throw\", beforeExpr),\n  _try: kw(\"try\"),\n  _var: kw(\"var\"),\n  _const: kw(\"const\"),\n  _while: kw(\"while\", {isLoop: true}),\n  _with: kw(\"with\"),\n  _new: kw(\"new\", {beforeExpr: true, startsExpr: true}),\n  _this: kw(\"this\", startsExpr),\n  _super: kw(\"super\", startsExpr),\n  _class: kw(\"class\", startsExpr),\n  _extends: kw(\"extends\", beforeExpr),\n  _export: kw(\"export\"),\n  _import: kw(\"import\", startsExpr),\n  _null: kw(\"null\", startsExpr),\n  _true: kw(\"true\", startsExpr),\n  _false: kw(\"false\", startsExpr),\n  _in: kw(\"in\", {beforeExpr: true, binop: 7}),\n  _instanceof: kw(\"instanceof\", {beforeExpr: true, binop: 7}),\n  _typeof: kw(\"typeof\", {beforeExpr: true, prefix: true, startsExpr: true}),\n  _void: kw(\"void\", {beforeExpr: true, prefix: true, startsExpr: true}),\n  _delete: kw(\"delete\", {beforeExpr: true, prefix: true, startsExpr: true})\n};\n\n// Matches a whole line break (where CRLF is considered a single\n// line break). Used to count lines.\n\nvar lineBreak = /\\r\\n?|\\n|\\u2028|\\u2029/;\nvar lineBreakG = new RegExp(lineBreak.source, \"g\");\n\nfunction isNewLine(code) {\n  return code === 10 || code === 13 || code === 0x2028 || code === 0x2029\n}\n\nfunction nextLineBreak(code, from, end) {\n  if ( end === void 0 ) end = code.length;\n\n  for (var i = from; i < end; i++) {\n    var next = code.charCodeAt(i);\n    if (isNewLine(next))\n      { return i < end - 1 && next === 13 && code.charCodeAt(i + 1) === 10 ? i + 2 : i + 1 }\n  }\n  return -1\n}\n\nvar nonASCIIwhitespace = /[\\u1680\\u2000-\\u200a\\u202f\\u205f\\u3000\\ufeff]/;\n\nvar skipWhiteSpace = /(?:\\s|\\/\\/.*|\\/\\*[^]*?\\*\\/)*/g;\n\nvar ref = Object.prototype;\nvar hasOwnProperty$1 = ref.hasOwnProperty;\nvar toString$1 = ref.toString;\n\nvar hasOwn = Object.hasOwn || (function (obj, propName) { return (\n  hasOwnProperty$1.call(obj, propName)\n); });\n\nvar isArray = Array.isArray || (function (obj) { return (\n  toString$1.call(obj) === \"[object Array]\"\n); });\n\nfunction wordsRegexp(words) {\n  return new RegExp(\"^(?:\" + words.replace(/ /g, \"|\") + \")$\")\n}\n\nfunction codePointToString(code) {\n  // UTF-16 Decoding\n  if (code <= 0xFFFF) { return String.fromCharCode(code) }\n  code -= 0x10000;\n  return String.fromCharCode((code >> 10) + 0xD800, (code & 1023) + 0xDC00)\n}\n\nvar loneSurrogate = /(?:[\\uD800-\\uDBFF](?![\\uDC00-\\uDFFF])|(?:[^\\uD800-\\uDBFF]|^)[\\uDC00-\\uDFFF])/;\n\n// These are used when `options.locations` is on, for the\n// `startLoc` and `endLoc` properties.\n\nvar Position = function Position(line, col) {\n  this.line = line;\n  this.column = col;\n};\n\nPosition.prototype.offset = function offset (n) {\n  return new Position(this.line, this.column + n)\n};\n\nvar SourceLocation = function SourceLocation(p, start, end) {\n  this.start = start;\n  this.end = end;\n  if (p.sourceFile !== null) { this.source = p.sourceFile; }\n};\n\n// The `getLineInfo` function is mostly useful when the\n// `locations` option is off (for performance reasons) and you\n// want to find the line/column position for a given character\n// offset. `input` should be the code string that the offset refers\n// into.\n\nfunction getLineInfo(input, offset) {\n  for (var line = 1, cur = 0;;) {\n    var nextBreak = nextLineBreak(input, cur, offset);\n    if (nextBreak < 0) { return new Position(line, offset - cur) }\n    ++line;\n    cur = nextBreak;\n  }\n}\n\n// A second argument must be given to configure the parser process.\n// These options are recognized (only `ecmaVersion` is required):\n\nvar defaultOptions = {\n  // `ecmaVersion` indicates the ECMAScript version to parse. Must be\n  // either 3, 5, 6 (or 2015), 7 (2016), 8 (2017), 9 (2018), 10\n  // (2019), 11 (2020), 12 (2021), 13 (2022), 14 (2023), or `\"latest\"`\n  // (the latest version the library supports). This influences\n  // support for strict mode, the set of reserved words, and support\n  // for new syntax features.\n  ecmaVersion: null,\n  // `sourceType` indicates the mode the code should be parsed in.\n  // Can be either `\"script\"` or `\"module\"`. This influences global\n  // strict mode and parsing of `import` and `export` declarations.\n  sourceType: \"script\",\n  // `onInsertedSemicolon` can be a callback that will be called\n  // when a semicolon is automatically inserted. It will be passed\n  // the position of the comma as an offset, and if `locations` is\n  // enabled, it is given the location as a `{line, column}` object\n  // as second argument.\n  onInsertedSemicolon: null,\n  // `onTrailingComma` is similar to `onInsertedSemicolon`, but for\n  // trailing commas.\n  onTrailingComma: null,\n  // By default, reserved words are only enforced if ecmaVersion >= 5.\n  // Set `allowReserved` to a boolean value to explicitly turn this on\n  // an off. When this option has the value \"never\", reserved words\n  // and keywords can also not be used as property names.\n  allowReserved: null,\n  // When enabled, a return at the top level is not considered an\n  // error.\n  allowReturnOutsideFunction: false,\n  // When enabled, import/export statements are not constrained to\n  // appearing at the top of the program, and an import.meta expression\n  // in a script isn't considered an error.\n  allowImportExportEverywhere: false,\n  // By default, await identifiers are allowed to appear at the top-level scope only if ecmaVersion >= 2022.\n  // When enabled, await identifiers are allowed to appear at the top-level scope,\n  // but they are still not allowed in non-async functions.\n  allowAwaitOutsideFunction: null,\n  // When enabled, super identifiers are not constrained to\n  // appearing in methods and do not raise an error when they appear elsewhere.\n  allowSuperOutsideMethod: null,\n  // When enabled, hashbang directive in the beginning of file is\n  // allowed and treated as a line comment. Enabled by default when\n  // `ecmaVersion` >= 2023.\n  allowHashBang: false,\n  // When `locations` is on, `loc` properties holding objects with\n  // `start` and `end` properties in `{line, column}` form (with\n  // line being 1-based and column 0-based) will be attached to the\n  // nodes.\n  locations: false,\n  // A function can be passed as `onToken` option, which will\n  // cause Acorn to call that function with object in the same\n  // format as tokens returned from `tokenizer().getToken()`. Note\n  // that you are not allowed to call the parser from the\n  // callback—that will corrupt its internal state.\n  onToken: null,\n  // A function can be passed as `onComment` option, which will\n  // cause Acorn to call that function with `(block, text, start,\n  // end)` parameters whenever a comment is skipped. `block` is a\n  // boolean indicating whether this is a block (`/* */`) comment,\n  // `text` is the content of the comment, and `start` and `end` are\n  // character offsets that denote the start and end of the comment.\n  // When the `locations` option is on, two more parameters are\n  // passed, the full `{line, column}` locations of the start and\n  // end of the comments. Note that you are not allowed to call the\n  // parser from the callback—that will corrupt its internal state.\n  onComment: null,\n  // Nodes have their start and end characters offsets recorded in\n  // `start` and `end` properties (directly on the node, rather than\n  // the `loc` object, which holds line/column data. To also add a\n  // [semi-standardized][range] `range` property holding a `[start,\n  // end]` array with the same numbers, set the `ranges` option to\n  // `true`.\n  //\n  // [range]: https://bugzilla.mozilla.org/show_bug.cgi?id=745678\n  ranges: false,\n  // It is possible to parse multiple files into a single AST by\n  // passing the tree produced by parsing the first file as\n  // `program` option in subsequent parses. This will add the\n  // toplevel forms of the parsed file to the `Program` (top) node\n  // of an existing parse tree.\n  program: null,\n  // When `locations` is on, you can pass this to record the source\n  // file in every node's `loc` object.\n  sourceFile: null,\n  // This value, if given, is stored in every node, whether\n  // `locations` is on or off.\n  directSourceFile: null,\n  // When enabled, parenthesized expressions are represented by\n  // (non-standard) ParenthesizedExpression nodes\n  preserveParens: false\n};\n\n// Interpret and default an options object\n\nvar warnedAboutEcmaVersion = false;\n\nfunction getOptions(opts) {\n  var options = {};\n\n  for (var opt in defaultOptions)\n    { options[opt] = opts && hasOwn(opts, opt) ? opts[opt] : defaultOptions[opt]; }\n\n  if (options.ecmaVersion === \"latest\") {\n    options.ecmaVersion = 1e8;\n  } else if (options.ecmaVersion == null) {\n    if (!warnedAboutEcmaVersion && typeof console === \"object\" && console.warn) {\n      warnedAboutEcmaVersion = true;\n      console.warn(\"Since Acorn 8.0.0, options.ecmaVersion is required.\\nDefaulting to 2020, but this will stop working in the future.\");\n    }\n    options.ecmaVersion = 11;\n  } else if (options.ecmaVersion >= 2015) {\n    options.ecmaVersion -= 2009;\n  }\n\n  if (options.allowReserved == null)\n    { options.allowReserved = options.ecmaVersion < 5; }\n\n  if (!opts || opts.allowHashBang == null)\n    { options.allowHashBang = options.ecmaVersion >= 14; }\n\n  if (isArray(options.onToken)) {\n    var tokens = options.onToken;\n    options.onToken = function (token) { return tokens.push(token); };\n  }\n  if (isArray(options.onComment))\n    { options.onComment = pushComment(options, options.onComment); }\n\n  return options\n}\n\nfunction pushComment(options, array) {\n  return function(block, text, start, end, startLoc, endLoc) {\n    var comment = {\n      type: block ? \"Block\" : \"Line\",\n      value: text,\n      start: start,\n      end: end\n    };\n    if (options.locations)\n      { comment.loc = new SourceLocation(this, startLoc, endLoc); }\n    if (options.ranges)\n      { comment.range = [start, end]; }\n    array.push(comment);\n  }\n}\n\n// Each scope gets a bitset that may contain these flags\nvar\n    SCOPE_TOP = 1,\n    SCOPE_FUNCTION = 2,\n    SCOPE_ASYNC = 4,\n    SCOPE_GENERATOR = 8,\n    SCOPE_ARROW = 16,\n    SCOPE_SIMPLE_CATCH = 32,\n    SCOPE_SUPER = 64,\n    SCOPE_DIRECT_SUPER = 128,\n    SCOPE_CLASS_STATIC_BLOCK = 256,\n    SCOPE_VAR = SCOPE_TOP | SCOPE_FUNCTION | SCOPE_CLASS_STATIC_BLOCK;\n\nfunction functionFlags(async, generator) {\n  return SCOPE_FUNCTION | (async ? SCOPE_ASYNC : 0) | (generator ? SCOPE_GENERATOR : 0)\n}\n\n// Used in checkLVal* and declareName to determine the type of a binding\nvar\n    BIND_NONE = 0, // Not a binding\n    BIND_VAR = 1, // Var-style binding\n    BIND_LEXICAL = 2, // Let- or const-style binding\n    BIND_FUNCTION = 3, // Function declaration\n    BIND_SIMPLE_CATCH = 4, // Simple (identifier pattern) catch binding\n    BIND_OUTSIDE = 5; // Special case for function names as bound inside the function\n\nvar Parser$1 = function Parser(options, input, startPos) {\n  this.options = options = getOptions(options);\n  this.sourceFile = options.sourceFile;\n  this.keywords = wordsRegexp(keywords$1[options.ecmaVersion >= 6 ? 6 : options.sourceType === \"module\" ? \"5module\" : 5]);\n  var reserved = \"\";\n  if (options.allowReserved !== true) {\n    reserved = reservedWords[options.ecmaVersion >= 6 ? 6 : options.ecmaVersion === 5 ? 5 : 3];\n    if (options.sourceType === \"module\") { reserved += \" await\"; }\n  }\n  this.reservedWords = wordsRegexp(reserved);\n  var reservedStrict = (reserved ? reserved + \" \" : \"\") + reservedWords.strict;\n  this.reservedWordsStrict = wordsRegexp(reservedStrict);\n  this.reservedWordsStrictBind = wordsRegexp(reservedStrict + \" \" + reservedWords.strictBind);\n  this.input = String(input);\n\n  // Used to signal to callers of `readWord1` whether the word\n  // contained any escape sequences. This is needed because words with\n  // escape sequences must not be interpreted as keywords.\n  this.containsEsc = false;\n\n  // Set up token state\n\n  // The current position of the tokenizer in the input.\n  if (startPos) {\n    this.pos = startPos;\n    this.lineStart = this.input.lastIndexOf(\"\\n\", startPos - 1) + 1;\n    this.curLine = this.input.slice(0, this.lineStart).split(lineBreak).length;\n  } else {\n    this.pos = this.lineStart = 0;\n    this.curLine = 1;\n  }\n\n  // Properties of the current token:\n  // Its type\n  this.type = types$1.eof;\n  // For tokens that include more information than their type, the value\n  this.value = null;\n  // Its start and end offset\n  this.start = this.end = this.pos;\n  // And, if locations are used, the {line, column} object\n  // corresponding to those offsets\n  this.startLoc = this.endLoc = this.curPosition();\n\n  // Position information for the previous token\n  this.lastTokEndLoc = this.lastTokStartLoc = null;\n  this.lastTokStart = this.lastTokEnd = this.pos;\n\n  // The context stack is used to superficially track syntactic\n  // context to predict whether a regular expression is allowed in a\n  // given position.\n  this.context = this.initialContext();\n  this.exprAllowed = true;\n\n  // Figure out if it's a module code.\n  this.inModule = options.sourceType === \"module\";\n  this.strict = this.inModule || this.strictDirective(this.pos);\n\n  // Used to signify the start of a potential arrow function\n  this.potentialArrowAt = -1;\n  this.potentialArrowInForAwait = false;\n\n  // Positions to delayed-check that yield/await does not exist in default parameters.\n  this.yieldPos = this.awaitPos = this.awaitIdentPos = 0;\n  // Labels in scope.\n  this.labels = [];\n  // Thus-far undefined exports.\n  this.undefinedExports = Object.create(null);\n\n  // If enabled, skip leading hashbang line.\n  if (this.pos === 0 && options.allowHashBang && this.input.slice(0, 2) === \"#!\")\n    { this.skipLineComment(2); }\n\n  // Scope tracking for duplicate variable names (see scope.js)\n  this.scopeStack = [];\n  this.enterScope(SCOPE_TOP);\n\n  // For RegExp validation\n  this.regexpState = null;\n\n  // The stack of private names.\n  // Each element has two properties: 'declared' and 'used'.\n  // When it exited from the outermost class definition, all used private names must be declared.\n  this.privateNameStack = [];\n};\n\nvar prototypeAccessors = { inFunction: { configurable: true },inGenerator: { configurable: true },inAsync: { configurable: true },canAwait: { configurable: true },allowSuper: { configurable: true },allowDirectSuper: { configurable: true },treatFunctionsAsVar: { configurable: true },allowNewDotTarget: { configurable: true },inClassStaticBlock: { configurable: true } };\n\nParser$1.prototype.parse = function parse () {\n  var node = this.options.program || this.startNode();\n  this.nextToken();\n  return this.parseTopLevel(node)\n};\n\nprototypeAccessors.inFunction.get = function () { return (this.currentVarScope().flags & SCOPE_FUNCTION) > 0 };\n\nprototypeAccessors.inGenerator.get = function () { return (this.currentVarScope().flags & SCOPE_GENERATOR) > 0 && !this.currentVarScope().inClassFieldInit };\n\nprototypeAccessors.inAsync.get = function () { return (this.currentVarScope().flags & SCOPE_ASYNC) > 0 && !this.currentVarScope().inClassFieldInit };\n\nprototypeAccessors.canAwait.get = function () {\n  for (var i = this.scopeStack.length - 1; i >= 0; i--) {\n    var scope = this.scopeStack[i];\n    if (scope.inClassFieldInit || scope.flags & SCOPE_CLASS_STATIC_BLOCK) { return false }\n    if (scope.flags & SCOPE_FUNCTION) { return (scope.flags & SCOPE_ASYNC) > 0 }\n  }\n  return (this.inModule && this.options.ecmaVersion >= 13) || this.options.allowAwaitOutsideFunction\n};\n\nprototypeAccessors.allowSuper.get = function () {\n  var ref = this.currentThisScope();\n    var flags = ref.flags;\n    var inClassFieldInit = ref.inClassFieldInit;\n  return (flags & SCOPE_SUPER) > 0 || inClassFieldInit || this.options.allowSuperOutsideMethod\n};\n\nprototypeAccessors.allowDirectSuper.get = function () { return (this.currentThisScope().flags & SCOPE_DIRECT_SUPER) > 0 };\n\nprototypeAccessors.treatFunctionsAsVar.get = function () { return this.treatFunctionsAsVarInScope(this.currentScope()) };\n\nprototypeAccessors.allowNewDotTarget.get = function () {\n  var ref = this.currentThisScope();\n    var flags = ref.flags;\n    var inClassFieldInit = ref.inClassFieldInit;\n  return (flags & (SCOPE_FUNCTION | SCOPE_CLASS_STATIC_BLOCK)) > 0 || inClassFieldInit\n};\n\nprototypeAccessors.inClassStaticBlock.get = function () {\n  return (this.currentVarScope().flags & SCOPE_CLASS_STATIC_BLOCK) > 0\n};\n\nParser$1.extend = function extend () {\n    var plugins = [], len = arguments.length;\n    while ( len-- ) plugins[ len ] = arguments[ len ];\n\n  var cls = this;\n  for (var i = 0; i < plugins.length; i++) { cls = plugins[i](cls); }\n  return cls\n};\n\nParser$1.parse = function parse (input, options) {\n  return new this(options, input).parse()\n};\n\nParser$1.parseExpressionAt = function parseExpressionAt (input, pos, options) {\n  var parser = new this(options, input, pos);\n  parser.nextToken();\n  return parser.parseExpression()\n};\n\nParser$1.tokenizer = function tokenizer (input, options) {\n  return new this(options, input)\n};\n\nObject.defineProperties( Parser$1.prototype, prototypeAccessors );\n\nvar pp$9 = Parser$1.prototype;\n\n// ## Parser utilities\n\nvar literal = /^(?:'((?:\\\\.|[^'\\\\])*?)'|\"((?:\\\\.|[^\"\\\\])*?)\")/;\npp$9.strictDirective = function(start) {\n  if (this.options.ecmaVersion < 5) { return false }\n  for (;;) {\n    // Try to find string literal.\n    skipWhiteSpace.lastIndex = start;\n    start += skipWhiteSpace.exec(this.input)[0].length;\n    var match = literal.exec(this.input.slice(start));\n    if (!match) { return false }\n    if ((match[1] || match[2]) === \"use strict\") {\n      skipWhiteSpace.lastIndex = start + match[0].length;\n      var spaceAfter = skipWhiteSpace.exec(this.input), end = spaceAfter.index + spaceAfter[0].length;\n      var next = this.input.charAt(end);\n      return next === \";\" || next === \"}\" ||\n        (lineBreak.test(spaceAfter[0]) &&\n         !(/[(`.[+\\-/*%<>=,?^&]/.test(next) || next === \"!\" && this.input.charAt(end + 1) === \"=\"))\n    }\n    start += match[0].length;\n\n    // Skip semicolon, if any.\n    skipWhiteSpace.lastIndex = start;\n    start += skipWhiteSpace.exec(this.input)[0].length;\n    if (this.input[start] === \";\")\n      { start++; }\n  }\n};\n\n// Predicate that tests whether the next token is of the given\n// type, and if yes, consumes it as a side effect.\n\npp$9.eat = function(type) {\n  if (this.type === type) {\n    this.next();\n    return true\n  } else {\n    return false\n  }\n};\n\n// Tests whether parsed token is a contextual keyword.\n\npp$9.isContextual = function(name) {\n  return this.type === types$1.name && this.value === name && !this.containsEsc\n};\n\n// Consumes contextual keyword if possible.\n\npp$9.eatContextual = function(name) {\n  if (!this.isContextual(name)) { return false }\n  this.next();\n  return true\n};\n\n// Asserts that following token is given contextual keyword.\n\npp$9.expectContextual = function(name) {\n  if (!this.eatContextual(name)) { this.unexpected(); }\n};\n\n// Test whether a semicolon can be inserted at the current position.\n\npp$9.canInsertSemicolon = function() {\n  return this.type === types$1.eof ||\n    this.type === types$1.braceR ||\n    lineBreak.test(this.input.slice(this.lastTokEnd, this.start))\n};\n\npp$9.insertSemicolon = function() {\n  if (this.canInsertSemicolon()) {\n    if (this.options.onInsertedSemicolon)\n      { this.options.onInsertedSemicolon(this.lastTokEnd, this.lastTokEndLoc); }\n    return true\n  }\n};\n\n// Consume a semicolon, or, failing that, see if we are allowed to\n// pretend that there is a semicolon at this position.\n\npp$9.semicolon = function() {\n  if (!this.eat(types$1.semi) && !this.insertSemicolon()) { this.unexpected(); }\n};\n\npp$9.afterTrailingComma = function(tokType, notNext) {\n  if (this.type === tokType) {\n    if (this.options.onTrailingComma)\n      { this.options.onTrailingComma(this.lastTokStart, this.lastTokStartLoc); }\n    if (!notNext)\n      { this.next(); }\n    return true\n  }\n};\n\n// Expect a token of a given type. If found, consume it, otherwise,\n// raise an unexpected token error.\n\npp$9.expect = function(type) {\n  this.eat(type) || this.unexpected();\n};\n\n// Raise an unexpected token error.\n\npp$9.unexpected = function(pos) {\n  this.raise(pos != null ? pos : this.start, \"Unexpected token\");\n};\n\nvar DestructuringErrors = function DestructuringErrors() {\n  this.shorthandAssign =\n  this.trailingComma =\n  this.parenthesizedAssign =\n  this.parenthesizedBind =\n  this.doubleProto =\n    -1;\n};\n\npp$9.checkPatternErrors = function(refDestructuringErrors, isAssign) {\n  if (!refDestructuringErrors) { return }\n  if (refDestructuringErrors.trailingComma > -1)\n    { this.raiseRecoverable(refDestructuringErrors.trailingComma, \"Comma is not permitted after the rest element\"); }\n  var parens = isAssign ? refDestructuringErrors.parenthesizedAssign : refDestructuringErrors.parenthesizedBind;\n  if (parens > -1) { this.raiseRecoverable(parens, isAssign ? \"Assigning to rvalue\" : \"Parenthesized pattern\"); }\n};\n\npp$9.checkExpressionErrors = function(refDestructuringErrors, andThrow) {\n  if (!refDestructuringErrors) { return false }\n  var shorthandAssign = refDestructuringErrors.shorthandAssign;\n  var doubleProto = refDestructuringErrors.doubleProto;\n  if (!andThrow) { return shorthandAssign >= 0 || doubleProto >= 0 }\n  if (shorthandAssign >= 0)\n    { this.raise(shorthandAssign, \"Shorthand property assignments are valid only in destructuring patterns\"); }\n  if (doubleProto >= 0)\n    { this.raiseRecoverable(doubleProto, \"Redefinition of __proto__ property\"); }\n};\n\npp$9.checkYieldAwaitInDefaultParams = function() {\n  if (this.yieldPos && (!this.awaitPos || this.yieldPos < this.awaitPos))\n    { this.raise(this.yieldPos, \"Yield expression cannot be a default value\"); }\n  if (this.awaitPos)\n    { this.raise(this.awaitPos, \"Await expression cannot be a default value\"); }\n};\n\npp$9.isSimpleAssignTarget = function(expr) {\n  if (expr.type === \"ParenthesizedExpression\")\n    { return this.isSimpleAssignTarget(expr.expression) }\n  return expr.type === \"Identifier\" || expr.type === \"MemberExpression\"\n};\n\nvar pp$8 = Parser$1.prototype;\n\n// ### Statement parsing\n\n// Parse a program. Initializes the parser, reads any number of\n// statements, and wraps them in a Program node.  Optionally takes a\n// `program` argument.  If present, the statements will be appended\n// to its body instead of creating a new node.\n\npp$8.parseTopLevel = function(node) {\n  var exports = Object.create(null);\n  if (!node.body) { node.body = []; }\n  while (this.type !== types$1.eof) {\n    var stmt = this.parseStatement(null, true, exports);\n    node.body.push(stmt);\n  }\n  if (this.inModule)\n    { for (var i = 0, list = Object.keys(this.undefinedExports); i < list.length; i += 1)\n      {\n        var name = list[i];\n\n        this.raiseRecoverable(this.undefinedExports[name].start, (\"Export '\" + name + \"' is not defined\"));\n      } }\n  this.adaptDirectivePrologue(node.body);\n  this.next();\n  node.sourceType = this.options.sourceType;\n  return this.finishNode(node, \"Program\")\n};\n\nvar loopLabel = {kind: \"loop\"}, switchLabel = {kind: \"switch\"};\n\npp$8.isLet = function(context) {\n  if (this.options.ecmaVersion < 6 || !this.isContextual(\"let\")) { return false }\n  skipWhiteSpace.lastIndex = this.pos;\n  var skip = skipWhiteSpace.exec(this.input);\n  var next = this.pos + skip[0].length, nextCh = this.input.charCodeAt(next);\n  // For ambiguous cases, determine if a LexicalDeclaration (or only a\n  // Statement) is allowed here. If context is not empty then only a Statement\n  // is allowed. However, `let [` is an explicit negative lookahead for\n  // ExpressionStatement, so special-case it first.\n  if (nextCh === 91 || nextCh === 92) { return true } // '[', '/'\n  if (context) { return false }\n\n  if (nextCh === 123 || nextCh > 0xd7ff && nextCh < 0xdc00) { return true } // '{', astral\n  if (isIdentifierStart(nextCh, true)) {\n    var pos = next + 1;\n    while (isIdentifierChar(nextCh = this.input.charCodeAt(pos), true)) { ++pos; }\n    if (nextCh === 92 || nextCh > 0xd7ff && nextCh < 0xdc00) { return true }\n    var ident = this.input.slice(next, pos);\n    if (!keywordRelationalOperator.test(ident)) { return true }\n  }\n  return false\n};\n\n// check 'async [no LineTerminator here] function'\n// - 'async /*foo*/ function' is OK.\n// - 'async /*\\n*/ function' is invalid.\npp$8.isAsyncFunction = function() {\n  if (this.options.ecmaVersion < 8 || !this.isContextual(\"async\"))\n    { return false }\n\n  skipWhiteSpace.lastIndex = this.pos;\n  var skip = skipWhiteSpace.exec(this.input);\n  var next = this.pos + skip[0].length, after;\n  return !lineBreak.test(this.input.slice(this.pos, next)) &&\n    this.input.slice(next, next + 8) === \"function\" &&\n    (next + 8 === this.input.length ||\n     !(isIdentifierChar(after = this.input.charCodeAt(next + 8)) || after > 0xd7ff && after < 0xdc00))\n};\n\n// Parse a single statement.\n//\n// If expecting a statement and finding a slash operator, parse a\n// regular expression literal. This is to handle cases like\n// `if (foo) /blah/.exec(foo)`, where looking at the previous token\n// does not help.\n\npp$8.parseStatement = function(context, topLevel, exports) {\n  var starttype = this.type, node = this.startNode(), kind;\n\n  if (this.isLet(context)) {\n    starttype = types$1._var;\n    kind = \"let\";\n  }\n\n  // Most types of statements are recognized by the keyword they\n  // start with. Many are trivial to parse, some require a bit of\n  // complexity.\n\n  switch (starttype) {\n  case types$1._break: case types$1._continue: return this.parseBreakContinueStatement(node, starttype.keyword)\n  case types$1._debugger: return this.parseDebuggerStatement(node)\n  case types$1._do: return this.parseDoStatement(node)\n  case types$1._for: return this.parseForStatement(node)\n  case types$1._function:\n    // Function as sole body of either an if statement or a labeled statement\n    // works, but not when it is part of a labeled statement that is the sole\n    // body of an if statement.\n    if ((context && (this.strict || context !== \"if\" && context !== \"label\")) && this.options.ecmaVersion >= 6) { this.unexpected(); }\n    return this.parseFunctionStatement(node, false, !context)\n  case types$1._class:\n    if (context) { this.unexpected(); }\n    return this.parseClass(node, true)\n  case types$1._if: return this.parseIfStatement(node)\n  case types$1._return: return this.parseReturnStatement(node)\n  case types$1._switch: return this.parseSwitchStatement(node)\n  case types$1._throw: return this.parseThrowStatement(node)\n  case types$1._try: return this.parseTryStatement(node)\n  case types$1._const: case types$1._var:\n    kind = kind || this.value;\n    if (context && kind !== \"var\") { this.unexpected(); }\n    return this.parseVarStatement(node, kind)\n  case types$1._while: return this.parseWhileStatement(node)\n  case types$1._with: return this.parseWithStatement(node)\n  case types$1.braceL: return this.parseBlock(true, node)\n  case types$1.semi: return this.parseEmptyStatement(node)\n  case types$1._export:\n  case types$1._import:\n    if (this.options.ecmaVersion > 10 && starttype === types$1._import) {\n      skipWhiteSpace.lastIndex = this.pos;\n      var skip = skipWhiteSpace.exec(this.input);\n      var next = this.pos + skip[0].length, nextCh = this.input.charCodeAt(next);\n      if (nextCh === 40 || nextCh === 46) // '(' or '.'\n        { return this.parseExpressionStatement(node, this.parseExpression()) }\n    }\n\n    if (!this.options.allowImportExportEverywhere) {\n      if (!topLevel)\n        { this.raise(this.start, \"'import' and 'export' may only appear at the top level\"); }\n      if (!this.inModule)\n        { this.raise(this.start, \"'import' and 'export' may appear only with 'sourceType: module'\"); }\n    }\n    return starttype === types$1._import ? this.parseImport(node) : this.parseExport(node, exports)\n\n    // If the statement does not start with a statement keyword or a\n    // brace, it's an ExpressionStatement or LabeledStatement. We\n    // simply start parsing an expression, and afterwards, if the\n    // next token is a colon and the expression was a simple\n    // Identifier node, we switch to interpreting it as a label.\n  default:\n    if (this.isAsyncFunction()) {\n      if (context) { this.unexpected(); }\n      this.next();\n      return this.parseFunctionStatement(node, true, !context)\n    }\n\n    var maybeName = this.value, expr = this.parseExpression();\n    if (starttype === types$1.name && expr.type === \"Identifier\" && this.eat(types$1.colon))\n      { return this.parseLabeledStatement(node, maybeName, expr, context) }\n    else { return this.parseExpressionStatement(node, expr) }\n  }\n};\n\npp$8.parseBreakContinueStatement = function(node, keyword) {\n  var isBreak = keyword === \"break\";\n  this.next();\n  if (this.eat(types$1.semi) || this.insertSemicolon()) { node.label = null; }\n  else if (this.type !== types$1.name) { this.unexpected(); }\n  else {\n    node.label = this.parseIdent();\n    this.semicolon();\n  }\n\n  // Verify that there is an actual destination to break or\n  // continue to.\n  var i = 0;\n  for (; i < this.labels.length; ++i) {\n    var lab = this.labels[i];\n    if (node.label == null || lab.name === node.label.name) {\n      if (lab.kind != null && (isBreak || lab.kind === \"loop\")) { break }\n      if (node.label && isBreak) { break }\n    }\n  }\n  if (i === this.labels.length) { this.raise(node.start, \"Unsyntactic \" + keyword); }\n  return this.finishNode(node, isBreak ? \"BreakStatement\" : \"ContinueStatement\")\n};\n\npp$8.parseDebuggerStatement = function(node) {\n  this.next();\n  this.semicolon();\n  return this.finishNode(node, \"DebuggerStatement\")\n};\n\npp$8.parseDoStatement = function(node) {\n  this.next();\n  this.labels.push(loopLabel);\n  node.body = this.parseStatement(\"do\");\n  this.labels.pop();\n  this.expect(types$1._while);\n  node.test = this.parseParenExpression();\n  if (this.options.ecmaVersion >= 6)\n    { this.eat(types$1.semi); }\n  else\n    { this.semicolon(); }\n  return this.finishNode(node, \"DoWhileStatement\")\n};\n\n// Disambiguating between a `for` and a `for`/`in` or `for`/`of`\n// loop is non-trivial. Basically, we have to parse the init `var`\n// statement or expression, disallowing the `in` operator (see\n// the second parameter to `parseExpression`), and then check\n// whether the next token is `in` or `of`. When there is no init\n// part (semicolon immediately after the opening parenthesis), it\n// is a regular `for` loop.\n\npp$8.parseForStatement = function(node) {\n  this.next();\n  var awaitAt = (this.options.ecmaVersion >= 9 && this.canAwait && this.eatContextual(\"await\")) ? this.lastTokStart : -1;\n  this.labels.push(loopLabel);\n  this.enterScope(0);\n  this.expect(types$1.parenL);\n  if (this.type === types$1.semi) {\n    if (awaitAt > -1) { this.unexpected(awaitAt); }\n    return this.parseFor(node, null)\n  }\n  var isLet = this.isLet();\n  if (this.type === types$1._var || this.type === types$1._const || isLet) {\n    var init$1 = this.startNode(), kind = isLet ? \"let\" : this.value;\n    this.next();\n    this.parseVar(init$1, true, kind);\n    this.finishNode(init$1, \"VariableDeclaration\");\n    if ((this.type === types$1._in || (this.options.ecmaVersion >= 6 && this.isContextual(\"of\"))) && init$1.declarations.length === 1) {\n      if (this.options.ecmaVersion >= 9) {\n        if (this.type === types$1._in) {\n          if (awaitAt > -1) { this.unexpected(awaitAt); }\n        } else { node.await = awaitAt > -1; }\n      }\n      return this.parseForIn(node, init$1)\n    }\n    if (awaitAt > -1) { this.unexpected(awaitAt); }\n    return this.parseFor(node, init$1)\n  }\n  var startsWithLet = this.isContextual(\"let\"), isForOf = false;\n  var refDestructuringErrors = new DestructuringErrors;\n  var init = this.parseExpression(awaitAt > -1 ? \"await\" : true, refDestructuringErrors);\n  if (this.type === types$1._in || (isForOf = this.options.ecmaVersion >= 6 && this.isContextual(\"of\"))) {\n    if (this.options.ecmaVersion >= 9) {\n      if (this.type === types$1._in) {\n        if (awaitAt > -1) { this.unexpected(awaitAt); }\n      } else { node.await = awaitAt > -1; }\n    }\n    if (startsWithLet && isForOf) { this.raise(init.start, \"The left-hand side of a for-of loop may not start with 'let'.\"); }\n    this.toAssignable(init, false, refDestructuringErrors);\n    this.checkLValPattern(init);\n    return this.parseForIn(node, init)\n  } else {\n    this.checkExpressionErrors(refDestructuringErrors, true);\n  }\n  if (awaitAt > -1) { this.unexpected(awaitAt); }\n  return this.parseFor(node, init)\n};\n\npp$8.parseFunctionStatement = function(node, isAsync, declarationPosition) {\n  this.next();\n  return this.parseFunction(node, FUNC_STATEMENT | (declarationPosition ? 0 : FUNC_HANGING_STATEMENT), false, isAsync)\n};\n\npp$8.parseIfStatement = function(node) {\n  this.next();\n  node.test = this.parseParenExpression();\n  // allow function declarations in branches, but only in non-strict mode\n  node.consequent = this.parseStatement(\"if\");\n  node.alternate = this.eat(types$1._else) ? this.parseStatement(\"if\") : null;\n  return this.finishNode(node, \"IfStatement\")\n};\n\npp$8.parseReturnStatement = function(node) {\n  if (!this.inFunction && !this.options.allowReturnOutsideFunction)\n    { this.raise(this.start, \"'return' outside of function\"); }\n  this.next();\n\n  // In `return` (and `break`/`continue`), the keywords with\n  // optional arguments, we eagerly look for a semicolon or the\n  // possibility to insert one.\n\n  if (this.eat(types$1.semi) || this.insertSemicolon()) { node.argument = null; }\n  else { node.argument = this.parseExpression(); this.semicolon(); }\n  return this.finishNode(node, \"ReturnStatement\")\n};\n\npp$8.parseSwitchStatement = function(node) {\n  this.next();\n  node.discriminant = this.parseParenExpression();\n  node.cases = [];\n  this.expect(types$1.braceL);\n  this.labels.push(switchLabel);\n  this.enterScope(0);\n\n  // Statements under must be grouped (by label) in SwitchCase\n  // nodes. `cur` is used to keep the node that we are currently\n  // adding statements to.\n\n  var cur;\n  for (var sawDefault = false; this.type !== types$1.braceR;) {\n    if (this.type === types$1._case || this.type === types$1._default) {\n      var isCase = this.type === types$1._case;\n      if (cur) { this.finishNode(cur, \"SwitchCase\"); }\n      node.cases.push(cur = this.startNode());\n      cur.consequent = [];\n      this.next();\n      if (isCase) {\n        cur.test = this.parseExpression();\n      } else {\n        if (sawDefault) { this.raiseRecoverable(this.lastTokStart, \"Multiple default clauses\"); }\n        sawDefault = true;\n        cur.test = null;\n      }\n      this.expect(types$1.colon);\n    } else {\n      if (!cur) { this.unexpected(); }\n      cur.consequent.push(this.parseStatement(null));\n    }\n  }\n  this.exitScope();\n  if (cur) { this.finishNode(cur, \"SwitchCase\"); }\n  this.next(); // Closing brace\n  this.labels.pop();\n  return this.finishNode(node, \"SwitchStatement\")\n};\n\npp$8.parseThrowStatement = function(node) {\n  this.next();\n  if (lineBreak.test(this.input.slice(this.lastTokEnd, this.start)))\n    { this.raise(this.lastTokEnd, \"Illegal newline after throw\"); }\n  node.argument = this.parseExpression();\n  this.semicolon();\n  return this.finishNode(node, \"ThrowStatement\")\n};\n\n// Reused empty array added for node fields that are always empty.\n\nvar empty$1 = [];\n\npp$8.parseTryStatement = function(node) {\n  this.next();\n  node.block = this.parseBlock();\n  node.handler = null;\n  if (this.type === types$1._catch) {\n    var clause = this.startNode();\n    this.next();\n    if (this.eat(types$1.parenL)) {\n      clause.param = this.parseBindingAtom();\n      var simple = clause.param.type === \"Identifier\";\n      this.enterScope(simple ? SCOPE_SIMPLE_CATCH : 0);\n      this.checkLValPattern(clause.param, simple ? BIND_SIMPLE_CATCH : BIND_LEXICAL);\n      this.expect(types$1.parenR);\n    } else {\n      if (this.options.ecmaVersion < 10) { this.unexpected(); }\n      clause.param = null;\n      this.enterScope(0);\n    }\n    clause.body = this.parseBlock(false);\n    this.exitScope();\n    node.handler = this.finishNode(clause, \"CatchClause\");\n  }\n  node.finalizer = this.eat(types$1._finally) ? this.parseBlock() : null;\n  if (!node.handler && !node.finalizer)\n    { this.raise(node.start, \"Missing catch or finally clause\"); }\n  return this.finishNode(node, \"TryStatement\")\n};\n\npp$8.parseVarStatement = function(node, kind) {\n  this.next();\n  this.parseVar(node, false, kind);\n  this.semicolon();\n  return this.finishNode(node, \"VariableDeclaration\")\n};\n\npp$8.parseWhileStatement = function(node) {\n  this.next();\n  node.test = this.parseParenExpression();\n  this.labels.push(loopLabel);\n  node.body = this.parseStatement(\"while\");\n  this.labels.pop();\n  return this.finishNode(node, \"WhileStatement\")\n};\n\npp$8.parseWithStatement = function(node) {\n  if (this.strict) { this.raise(this.start, \"'with' in strict mode\"); }\n  this.next();\n  node.object = this.parseParenExpression();\n  node.body = this.parseStatement(\"with\");\n  return this.finishNode(node, \"WithStatement\")\n};\n\npp$8.parseEmptyStatement = function(node) {\n  this.next();\n  return this.finishNode(node, \"EmptyStatement\")\n};\n\npp$8.parseLabeledStatement = function(node, maybeName, expr, context) {\n  for (var i$1 = 0, list = this.labels; i$1 < list.length; i$1 += 1)\n    {\n    var label = list[i$1];\n\n    if (label.name === maybeName)\n      { this.raise(expr.start, \"Label '\" + maybeName + \"' is already declared\");\n  } }\n  var kind = this.type.isLoop ? \"loop\" : this.type === types$1._switch ? \"switch\" : null;\n  for (var i = this.labels.length - 1; i >= 0; i--) {\n    var label$1 = this.labels[i];\n    if (label$1.statementStart === node.start) {\n      // Update information about previous labels on this node\n      label$1.statementStart = this.start;\n      label$1.kind = kind;\n    } else { break }\n  }\n  this.labels.push({name: maybeName, kind: kind, statementStart: this.start});\n  node.body = this.parseStatement(context ? context.indexOf(\"label\") === -1 ? context + \"label\" : context : \"label\");\n  this.labels.pop();\n  node.label = expr;\n  return this.finishNode(node, \"LabeledStatement\")\n};\n\npp$8.parseExpressionStatement = function(node, expr) {\n  node.expression = expr;\n  this.semicolon();\n  return this.finishNode(node, \"ExpressionStatement\")\n};\n\n// Parse a semicolon-enclosed block of statements, handling `\"use\n// strict\"` declarations when `allowStrict` is true (used for\n// function bodies).\n\npp$8.parseBlock = function(createNewLexicalScope, node, exitStrict) {\n  if ( createNewLexicalScope === void 0 ) createNewLexicalScope = true;\n  if ( node === void 0 ) node = this.startNode();\n\n  node.body = [];\n  this.expect(types$1.braceL);\n  if (createNewLexicalScope) { this.enterScope(0); }\n  while (this.type !== types$1.braceR) {\n    var stmt = this.parseStatement(null);\n    node.body.push(stmt);\n  }\n  if (exitStrict) { this.strict = false; }\n  this.next();\n  if (createNewLexicalScope) { this.exitScope(); }\n  return this.finishNode(node, \"BlockStatement\")\n};\n\n// Parse a regular `for` loop. The disambiguation code in\n// `parseStatement` will already have parsed the init statement or\n// expression.\n\npp$8.parseFor = function(node, init) {\n  node.init = init;\n  this.expect(types$1.semi);\n  node.test = this.type === types$1.semi ? null : this.parseExpression();\n  this.expect(types$1.semi);\n  node.update = this.type === types$1.parenR ? null : this.parseExpression();\n  this.expect(types$1.parenR);\n  node.body = this.parseStatement(\"for\");\n  this.exitScope();\n  this.labels.pop();\n  return this.finishNode(node, \"ForStatement\")\n};\n\n// Parse a `for`/`in` and `for`/`of` loop, which are almost\n// same from parser's perspective.\n\npp$8.parseForIn = function(node, init) {\n  var isForIn = this.type === types$1._in;\n  this.next();\n\n  if (\n    init.type === \"VariableDeclaration\" &&\n    init.declarations[0].init != null &&\n    (\n      !isForIn ||\n      this.options.ecmaVersion < 8 ||\n      this.strict ||\n      init.kind !== \"var\" ||\n      init.declarations[0].id.type !== \"Identifier\"\n    )\n  ) {\n    this.raise(\n      init.start,\n      ((isForIn ? \"for-in\" : \"for-of\") + \" loop variable declaration may not have an initializer\")\n    );\n  }\n  node.left = init;\n  node.right = isForIn ? this.parseExpression() : this.parseMaybeAssign();\n  this.expect(types$1.parenR);\n  node.body = this.parseStatement(\"for\");\n  this.exitScope();\n  this.labels.pop();\n  return this.finishNode(node, isForIn ? \"ForInStatement\" : \"ForOfStatement\")\n};\n\n// Parse a list of variable declarations.\n\npp$8.parseVar = function(node, isFor, kind) {\n  node.declarations = [];\n  node.kind = kind;\n  for (;;) {\n    var decl = this.startNode();\n    this.parseVarId(decl, kind);\n    if (this.eat(types$1.eq)) {\n      decl.init = this.parseMaybeAssign(isFor);\n    } else if (kind === \"const\" && !(this.type === types$1._in || (this.options.ecmaVersion >= 6 && this.isContextual(\"of\")))) {\n      this.unexpected();\n    } else if (decl.id.type !== \"Identifier\" && !(isFor && (this.type === types$1._in || this.isContextual(\"of\")))) {\n      this.raise(this.lastTokEnd, \"Complex binding patterns require an initialization value\");\n    } else {\n      decl.init = null;\n    }\n    node.declarations.push(this.finishNode(decl, \"VariableDeclarator\"));\n    if (!this.eat(types$1.comma)) { break }\n  }\n  return node\n};\n\npp$8.parseVarId = function(decl, kind) {\n  decl.id = this.parseBindingAtom();\n  this.checkLValPattern(decl.id, kind === \"var\" ? BIND_VAR : BIND_LEXICAL, false);\n};\n\nvar FUNC_STATEMENT = 1, FUNC_HANGING_STATEMENT = 2, FUNC_NULLABLE_ID = 4;\n\n// Parse a function declaration or literal (depending on the\n// `statement & FUNC_STATEMENT`).\n\n// Remove `allowExpressionBody` for 7.0.0, as it is only called with false\npp$8.parseFunction = function(node, statement, allowExpressionBody, isAsync, forInit) {\n  this.initFunction(node);\n  if (this.options.ecmaVersion >= 9 || this.options.ecmaVersion >= 6 && !isAsync) {\n    if (this.type === types$1.star && (statement & FUNC_HANGING_STATEMENT))\n      { this.unexpected(); }\n    node.generator = this.eat(types$1.star);\n  }\n  if (this.options.ecmaVersion >= 8)\n    { node.async = !!isAsync; }\n\n  if (statement & FUNC_STATEMENT) {\n    node.id = (statement & FUNC_NULLABLE_ID) && this.type !== types$1.name ? null : this.parseIdent();\n    if (node.id && !(statement & FUNC_HANGING_STATEMENT))\n      // If it is a regular function declaration in sloppy mode, then it is\n      // subject to Annex B semantics (BIND_FUNCTION). Otherwise, the binding\n      // mode depends on properties of the current scope (see\n      // treatFunctionsAsVar).\n      { this.checkLValSimple(node.id, (this.strict || node.generator || node.async) ? this.treatFunctionsAsVar ? BIND_VAR : BIND_LEXICAL : BIND_FUNCTION); }\n  }\n\n  var oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n  this.yieldPos = 0;\n  this.awaitPos = 0;\n  this.awaitIdentPos = 0;\n  this.enterScope(functionFlags(node.async, node.generator));\n\n  if (!(statement & FUNC_STATEMENT))\n    { node.id = this.type === types$1.name ? this.parseIdent() : null; }\n\n  this.parseFunctionParams(node);\n  this.parseFunctionBody(node, allowExpressionBody, false, forInit);\n\n  this.yieldPos = oldYieldPos;\n  this.awaitPos = oldAwaitPos;\n  this.awaitIdentPos = oldAwaitIdentPos;\n  return this.finishNode(node, (statement & FUNC_STATEMENT) ? \"FunctionDeclaration\" : \"FunctionExpression\")\n};\n\npp$8.parseFunctionParams = function(node) {\n  this.expect(types$1.parenL);\n  node.params = this.parseBindingList(types$1.parenR, false, this.options.ecmaVersion >= 8);\n  this.checkYieldAwaitInDefaultParams();\n};\n\n// Parse a class declaration or literal (depending on the\n// `isStatement` parameter).\n\npp$8.parseClass = function(node, isStatement) {\n  this.next();\n\n  // ecma-262 14.6 Class Definitions\n  // A class definition is always strict mode code.\n  var oldStrict = this.strict;\n  this.strict = true;\n\n  this.parseClassId(node, isStatement);\n  this.parseClassSuper(node);\n  var privateNameMap = this.enterClassBody();\n  var classBody = this.startNode();\n  var hadConstructor = false;\n  classBody.body = [];\n  this.expect(types$1.braceL);\n  while (this.type !== types$1.braceR) {\n    var element = this.parseClassElement(node.superClass !== null);\n    if (element) {\n      classBody.body.push(element);\n      if (element.type === \"MethodDefinition\" && element.kind === \"constructor\") {\n        if (hadConstructor) { this.raise(element.start, \"Duplicate constructor in the same class\"); }\n        hadConstructor = true;\n      } else if (element.key && element.key.type === \"PrivateIdentifier\" && isPrivateNameConflicted(privateNameMap, element)) {\n        this.raiseRecoverable(element.key.start, (\"Identifier '#\" + (element.key.name) + \"' has already been declared\"));\n      }\n    }\n  }\n  this.strict = oldStrict;\n  this.next();\n  node.body = this.finishNode(classBody, \"ClassBody\");\n  this.exitClassBody();\n  return this.finishNode(node, isStatement ? \"ClassDeclaration\" : \"ClassExpression\")\n};\n\npp$8.parseClassElement = function(constructorAllowsSuper) {\n  if (this.eat(types$1.semi)) { return null }\n\n  var ecmaVersion = this.options.ecmaVersion;\n  var node = this.startNode();\n  var keyName = \"\";\n  var isGenerator = false;\n  var isAsync = false;\n  var kind = \"method\";\n  var isStatic = false;\n\n  if (this.eatContextual(\"static\")) {\n    // Parse static init block\n    if (ecmaVersion >= 13 && this.eat(types$1.braceL)) {\n      this.parseClassStaticBlock(node);\n      return node\n    }\n    if (this.isClassElementNameStart() || this.type === types$1.star) {\n      isStatic = true;\n    } else {\n      keyName = \"static\";\n    }\n  }\n  node.static = isStatic;\n  if (!keyName && ecmaVersion >= 8 && this.eatContextual(\"async\")) {\n    if ((this.isClassElementNameStart() || this.type === types$1.star) && !this.canInsertSemicolon()) {\n      isAsync = true;\n    } else {\n      keyName = \"async\";\n    }\n  }\n  if (!keyName && (ecmaVersion >= 9 || !isAsync) && this.eat(types$1.star)) {\n    isGenerator = true;\n  }\n  if (!keyName && !isAsync && !isGenerator) {\n    var lastValue = this.value;\n    if (this.eatContextual(\"get\") || this.eatContextual(\"set\")) {\n      if (this.isClassElementNameStart()) {\n        kind = lastValue;\n      } else {\n        keyName = lastValue;\n      }\n    }\n  }\n\n  // Parse element name\n  if (keyName) {\n    // 'async', 'get', 'set', or 'static' were not a keyword contextually.\n    // The last token is any of those. Make it the element name.\n    node.computed = false;\n    node.key = this.startNodeAt(this.lastTokStart, this.lastTokStartLoc);\n    node.key.name = keyName;\n    this.finishNode(node.key, \"Identifier\");\n  } else {\n    this.parseClassElementName(node);\n  }\n\n  // Parse element value\n  if (ecmaVersion < 13 || this.type === types$1.parenL || kind !== \"method\" || isGenerator || isAsync) {\n    var isConstructor = !node.static && checkKeyName(node, \"constructor\");\n    var allowsDirectSuper = isConstructor && constructorAllowsSuper;\n    // Couldn't move this check into the 'parseClassMethod' method for backward compatibility.\n    if (isConstructor && kind !== \"method\") { this.raise(node.key.start, \"Constructor can't have get/set modifier\"); }\n    node.kind = isConstructor ? \"constructor\" : kind;\n    this.parseClassMethod(node, isGenerator, isAsync, allowsDirectSuper);\n  } else {\n    this.parseClassField(node);\n  }\n\n  return node\n};\n\npp$8.isClassElementNameStart = function() {\n  return (\n    this.type === types$1.name ||\n    this.type === types$1.privateId ||\n    this.type === types$1.num ||\n    this.type === types$1.string ||\n    this.type === types$1.bracketL ||\n    this.type.keyword\n  )\n};\n\npp$8.parseClassElementName = function(element) {\n  if (this.type === types$1.privateId) {\n    if (this.value === \"constructor\") {\n      this.raise(this.start, \"Classes can't have an element named '#constructor'\");\n    }\n    element.computed = false;\n    element.key = this.parsePrivateIdent();\n  } else {\n    this.parsePropertyName(element);\n  }\n};\n\npp$8.parseClassMethod = function(method, isGenerator, isAsync, allowsDirectSuper) {\n  // Check key and flags\n  var key = method.key;\n  if (method.kind === \"constructor\") {\n    if (isGenerator) { this.raise(key.start, \"Constructor can't be a generator\"); }\n    if (isAsync) { this.raise(key.start, \"Constructor can't be an async method\"); }\n  } else if (method.static && checkKeyName(method, \"prototype\")) {\n    this.raise(key.start, \"Classes may not have a static property named prototype\");\n  }\n\n  // Parse value\n  var value = method.value = this.parseMethod(isGenerator, isAsync, allowsDirectSuper);\n\n  // Check value\n  if (method.kind === \"get\" && value.params.length !== 0)\n    { this.raiseRecoverable(value.start, \"getter should have no params\"); }\n  if (method.kind === \"set\" && value.params.length !== 1)\n    { this.raiseRecoverable(value.start, \"setter should have exactly one param\"); }\n  if (method.kind === \"set\" && value.params[0].type === \"RestElement\")\n    { this.raiseRecoverable(value.params[0].start, \"Setter cannot use rest params\"); }\n\n  return this.finishNode(method, \"MethodDefinition\")\n};\n\npp$8.parseClassField = function(field) {\n  if (checkKeyName(field, \"constructor\")) {\n    this.raise(field.key.start, \"Classes can't have a field named 'constructor'\");\n  } else if (field.static && checkKeyName(field, \"prototype\")) {\n    this.raise(field.key.start, \"Classes can't have a static field named 'prototype'\");\n  }\n\n  if (this.eat(types$1.eq)) {\n    // To raise SyntaxError if 'arguments' exists in the initializer.\n    var scope = this.currentThisScope();\n    var inClassFieldInit = scope.inClassFieldInit;\n    scope.inClassFieldInit = true;\n    field.value = this.parseMaybeAssign();\n    scope.inClassFieldInit = inClassFieldInit;\n  } else {\n    field.value = null;\n  }\n  this.semicolon();\n\n  return this.finishNode(field, \"PropertyDefinition\")\n};\n\npp$8.parseClassStaticBlock = function(node) {\n  node.body = [];\n\n  var oldLabels = this.labels;\n  this.labels = [];\n  this.enterScope(SCOPE_CLASS_STATIC_BLOCK | SCOPE_SUPER);\n  while (this.type !== types$1.braceR) {\n    var stmt = this.parseStatement(null);\n    node.body.push(stmt);\n  }\n  this.next();\n  this.exitScope();\n  this.labels = oldLabels;\n\n  return this.finishNode(node, \"StaticBlock\")\n};\n\npp$8.parseClassId = function(node, isStatement) {\n  if (this.type === types$1.name) {\n    node.id = this.parseIdent();\n    if (isStatement)\n      { this.checkLValSimple(node.id, BIND_LEXICAL, false); }\n  } else {\n    if (isStatement === true)\n      { this.unexpected(); }\n    node.id = null;\n  }\n};\n\npp$8.parseClassSuper = function(node) {\n  node.superClass = this.eat(types$1._extends) ? this.parseExprSubscripts(null, false) : null;\n};\n\npp$8.enterClassBody = function() {\n  var element = {declared: Object.create(null), used: []};\n  this.privateNameStack.push(element);\n  return element.declared\n};\n\npp$8.exitClassBody = function() {\n  var ref = this.privateNameStack.pop();\n  var declared = ref.declared;\n  var used = ref.used;\n  var len = this.privateNameStack.length;\n  var parent = len === 0 ? null : this.privateNameStack[len - 1];\n  for (var i = 0; i < used.length; ++i) {\n    var id = used[i];\n    if (!hasOwn(declared, id.name)) {\n      if (parent) {\n        parent.used.push(id);\n      } else {\n        this.raiseRecoverable(id.start, (\"Private field '#\" + (id.name) + \"' must be declared in an enclosing class\"));\n      }\n    }\n  }\n};\n\nfunction isPrivateNameConflicted(privateNameMap, element) {\n  var name = element.key.name;\n  var curr = privateNameMap[name];\n\n  var next = \"true\";\n  if (element.type === \"MethodDefinition\" && (element.kind === \"get\" || element.kind === \"set\")) {\n    next = (element.static ? \"s\" : \"i\") + element.kind;\n  }\n\n  // `class { get #a(){}; static set #a(_){} }` is also conflict.\n  if (\n    curr === \"iget\" && next === \"iset\" ||\n    curr === \"iset\" && next === \"iget\" ||\n    curr === \"sget\" && next === \"sset\" ||\n    curr === \"sset\" && next === \"sget\"\n  ) {\n    privateNameMap[name] = \"true\";\n    return false\n  } else if (!curr) {\n    privateNameMap[name] = next;\n    return false\n  } else {\n    return true\n  }\n}\n\nfunction checkKeyName(node, name) {\n  var computed = node.computed;\n  var key = node.key;\n  return !computed && (\n    key.type === \"Identifier\" && key.name === name ||\n    key.type === \"Literal\" && key.value === name\n  )\n}\n\n// Parses module export declaration.\n\npp$8.parseExport = function(node, exports) {\n  this.next();\n  // export * from '...'\n  if (this.eat(types$1.star)) {\n    if (this.options.ecmaVersion >= 11) {\n      if (this.eatContextual(\"as\")) {\n        node.exported = this.parseModuleExportName();\n        this.checkExport(exports, node.exported, this.lastTokStart);\n      } else {\n        node.exported = null;\n      }\n    }\n    this.expectContextual(\"from\");\n    if (this.type !== types$1.string) { this.unexpected(); }\n    node.source = this.parseExprAtom();\n    this.semicolon();\n    return this.finishNode(node, \"ExportAllDeclaration\")\n  }\n  if (this.eat(types$1._default)) { // export default ...\n    this.checkExport(exports, \"default\", this.lastTokStart);\n    var isAsync;\n    if (this.type === types$1._function || (isAsync = this.isAsyncFunction())) {\n      var fNode = this.startNode();\n      this.next();\n      if (isAsync) { this.next(); }\n      node.declaration = this.parseFunction(fNode, FUNC_STATEMENT | FUNC_NULLABLE_ID, false, isAsync);\n    } else if (this.type === types$1._class) {\n      var cNode = this.startNode();\n      node.declaration = this.parseClass(cNode, \"nullableID\");\n    } else {\n      node.declaration = this.parseMaybeAssign();\n      this.semicolon();\n    }\n    return this.finishNode(node, \"ExportDefaultDeclaration\")\n  }\n  // export var|const|let|function|class ...\n  if (this.shouldParseExportStatement()) {\n    node.declaration = this.parseStatement(null);\n    if (node.declaration.type === \"VariableDeclaration\")\n      { this.checkVariableExport(exports, node.declaration.declarations); }\n    else\n      { this.checkExport(exports, node.declaration.id, node.declaration.id.start); }\n    node.specifiers = [];\n    node.source = null;\n  } else { // export { x, y as z } [from '...']\n    node.declaration = null;\n    node.specifiers = this.parseExportSpecifiers(exports);\n    if (this.eatContextual(\"from\")) {\n      if (this.type !== types$1.string) { this.unexpected(); }\n      node.source = this.parseExprAtom();\n    } else {\n      for (var i = 0, list = node.specifiers; i < list.length; i += 1) {\n        // check for keywords used as local names\n        var spec = list[i];\n\n        this.checkUnreserved(spec.local);\n        // check if export is defined\n        this.checkLocalExport(spec.local);\n\n        if (spec.local.type === \"Literal\") {\n          this.raise(spec.local.start, \"A string literal cannot be used as an exported binding without `from`.\");\n        }\n      }\n\n      node.source = null;\n    }\n    this.semicolon();\n  }\n  return this.finishNode(node, \"ExportNamedDeclaration\")\n};\n\npp$8.checkExport = function(exports, name, pos) {\n  if (!exports) { return }\n  if (typeof name !== \"string\")\n    { name = name.type === \"Identifier\" ? name.name : name.value; }\n  if (hasOwn(exports, name))\n    { this.raiseRecoverable(pos, \"Duplicate export '\" + name + \"'\"); }\n  exports[name] = true;\n};\n\npp$8.checkPatternExport = function(exports, pat) {\n  var type = pat.type;\n  if (type === \"Identifier\")\n    { this.checkExport(exports, pat, pat.start); }\n  else if (type === \"ObjectPattern\")\n    { for (var i = 0, list = pat.properties; i < list.length; i += 1)\n      {\n        var prop = list[i];\n\n        this.checkPatternExport(exports, prop);\n      } }\n  else if (type === \"ArrayPattern\")\n    { for (var i$1 = 0, list$1 = pat.elements; i$1 < list$1.length; i$1 += 1) {\n      var elt = list$1[i$1];\n\n        if (elt) { this.checkPatternExport(exports, elt); }\n    } }\n  else if (type === \"Property\")\n    { this.checkPatternExport(exports, pat.value); }\n  else if (type === \"AssignmentPattern\")\n    { this.checkPatternExport(exports, pat.left); }\n  else if (type === \"RestElement\")\n    { this.checkPatternExport(exports, pat.argument); }\n  else if (type === \"ParenthesizedExpression\")\n    { this.checkPatternExport(exports, pat.expression); }\n};\n\npp$8.checkVariableExport = function(exports, decls) {\n  if (!exports) { return }\n  for (var i = 0, list = decls; i < list.length; i += 1)\n    {\n    var decl = list[i];\n\n    this.checkPatternExport(exports, decl.id);\n  }\n};\n\npp$8.shouldParseExportStatement = function() {\n  return this.type.keyword === \"var\" ||\n    this.type.keyword === \"const\" ||\n    this.type.keyword === \"class\" ||\n    this.type.keyword === \"function\" ||\n    this.isLet() ||\n    this.isAsyncFunction()\n};\n\n// Parses a comma-separated list of module exports.\n\npp$8.parseExportSpecifiers = function(exports) {\n  var nodes = [], first = true;\n  // export { x, y as z } [from '...']\n  this.expect(types$1.braceL);\n  while (!this.eat(types$1.braceR)) {\n    if (!first) {\n      this.expect(types$1.comma);\n      if (this.afterTrailingComma(types$1.braceR)) { break }\n    } else { first = false; }\n\n    var node = this.startNode();\n    node.local = this.parseModuleExportName();\n    node.exported = this.eatContextual(\"as\") ? this.parseModuleExportName() : node.local;\n    this.checkExport(\n      exports,\n      node.exported,\n      node.exported.start\n    );\n    nodes.push(this.finishNode(node, \"ExportSpecifier\"));\n  }\n  return nodes\n};\n\n// Parses import declaration.\n\npp$8.parseImport = function(node) {\n  this.next();\n  // import '...'\n  if (this.type === types$1.string) {\n    node.specifiers = empty$1;\n    node.source = this.parseExprAtom();\n  } else {\n    node.specifiers = this.parseImportSpecifiers();\n    this.expectContextual(\"from\");\n    node.source = this.type === types$1.string ? this.parseExprAtom() : this.unexpected();\n  }\n  this.semicolon();\n  return this.finishNode(node, \"ImportDeclaration\")\n};\n\n// Parses a comma-separated list of module imports.\n\npp$8.parseImportSpecifiers = function() {\n  var nodes = [], first = true;\n  if (this.type === types$1.name) {\n    // import defaultObj, { x, y as z } from '...'\n    var node = this.startNode();\n    node.local = this.parseIdent();\n    this.checkLValSimple(node.local, BIND_LEXICAL);\n    nodes.push(this.finishNode(node, \"ImportDefaultSpecifier\"));\n    if (!this.eat(types$1.comma)) { return nodes }\n  }\n  if (this.type === types$1.star) {\n    var node$1 = this.startNode();\n    this.next();\n    this.expectContextual(\"as\");\n    node$1.local = this.parseIdent();\n    this.checkLValSimple(node$1.local, BIND_LEXICAL);\n    nodes.push(this.finishNode(node$1, \"ImportNamespaceSpecifier\"));\n    return nodes\n  }\n  this.expect(types$1.braceL);\n  while (!this.eat(types$1.braceR)) {\n    if (!first) {\n      this.expect(types$1.comma);\n      if (this.afterTrailingComma(types$1.braceR)) { break }\n    } else { first = false; }\n\n    var node$2 = this.startNode();\n    node$2.imported = this.parseModuleExportName();\n    if (this.eatContextual(\"as\")) {\n      node$2.local = this.parseIdent();\n    } else {\n      this.checkUnreserved(node$2.imported);\n      node$2.local = node$2.imported;\n    }\n    this.checkLValSimple(node$2.local, BIND_LEXICAL);\n    nodes.push(this.finishNode(node$2, \"ImportSpecifier\"));\n  }\n  return nodes\n};\n\npp$8.parseModuleExportName = function() {\n  if (this.options.ecmaVersion >= 13 && this.type === types$1.string) {\n    var stringLiteral = this.parseLiteral(this.value);\n    if (loneSurrogate.test(stringLiteral.value)) {\n      this.raise(stringLiteral.start, \"An export name cannot include a lone surrogate.\");\n    }\n    return stringLiteral\n  }\n  return this.parseIdent(true)\n};\n\n// Set `ExpressionStatement#directive` property for directive prologues.\npp$8.adaptDirectivePrologue = function(statements) {\n  for (var i = 0; i < statements.length && this.isDirectiveCandidate(statements[i]); ++i) {\n    statements[i].directive = statements[i].expression.raw.slice(1, -1);\n  }\n};\npp$8.isDirectiveCandidate = function(statement) {\n  return (\n    this.options.ecmaVersion >= 5 &&\n    statement.type === \"ExpressionStatement\" &&\n    statement.expression.type === \"Literal\" &&\n    typeof statement.expression.value === \"string\" &&\n    // Reject parenthesized strings.\n    (this.input[statement.start] === \"\\\"\" || this.input[statement.start] === \"'\")\n  )\n};\n\nvar pp$7 = Parser$1.prototype;\n\n// Convert existing expression atom to assignable pattern\n// if possible.\n\npp$7.toAssignable = function(node, isBinding, refDestructuringErrors) {\n  if (this.options.ecmaVersion >= 6 && node) {\n    switch (node.type) {\n    case \"Identifier\":\n      if (this.inAsync && node.name === \"await\")\n        { this.raise(node.start, \"Cannot use 'await' as identifier inside an async function\"); }\n      break\n\n    case \"ObjectPattern\":\n    case \"ArrayPattern\":\n    case \"AssignmentPattern\":\n    case \"RestElement\":\n      break\n\n    case \"ObjectExpression\":\n      node.type = \"ObjectPattern\";\n      if (refDestructuringErrors) { this.checkPatternErrors(refDestructuringErrors, true); }\n      for (var i = 0, list = node.properties; i < list.length; i += 1) {\n        var prop = list[i];\n\n      this.toAssignable(prop, isBinding);\n        // Early error:\n        //   AssignmentRestProperty[Yield, Await] :\n        //     `...` DestructuringAssignmentTarget[Yield, Await]\n        //\n        //   It is a Syntax Error if |DestructuringAssignmentTarget| is an |ArrayLiteral| or an |ObjectLiteral|.\n        if (\n          prop.type === \"RestElement\" &&\n          (prop.argument.type === \"ArrayPattern\" || prop.argument.type === \"ObjectPattern\")\n        ) {\n          this.raise(prop.argument.start, \"Unexpected token\");\n        }\n      }\n      break\n\n    case \"Property\":\n      // AssignmentProperty has type === \"Property\"\n      if (node.kind !== \"init\") { this.raise(node.key.start, \"Object pattern can't contain getter or setter\"); }\n      this.toAssignable(node.value, isBinding);\n      break\n\n    case \"ArrayExpression\":\n      node.type = \"ArrayPattern\";\n      if (refDestructuringErrors) { this.checkPatternErrors(refDestructuringErrors, true); }\n      this.toAssignableList(node.elements, isBinding);\n      break\n\n    case \"SpreadElement\":\n      node.type = \"RestElement\";\n      this.toAssignable(node.argument, isBinding);\n      if (node.argument.type === \"AssignmentPattern\")\n        { this.raise(node.argument.start, \"Rest elements cannot have a default value\"); }\n      break\n\n    case \"AssignmentExpression\":\n      if (node.operator !== \"=\") { this.raise(node.left.end, \"Only '=' operator can be used for specifying default value.\"); }\n      node.type = \"AssignmentPattern\";\n      delete node.operator;\n      this.toAssignable(node.left, isBinding);\n      break\n\n    case \"ParenthesizedExpression\":\n      this.toAssignable(node.expression, isBinding, refDestructuringErrors);\n      break\n\n    case \"ChainExpression\":\n      this.raiseRecoverable(node.start, \"Optional chaining cannot appear in left-hand side\");\n      break\n\n    case \"MemberExpression\":\n      if (!isBinding) { break }\n\n    default:\n      this.raise(node.start, \"Assigning to rvalue\");\n    }\n  } else if (refDestructuringErrors) { this.checkPatternErrors(refDestructuringErrors, true); }\n  return node\n};\n\n// Convert list of expression atoms to binding list.\n\npp$7.toAssignableList = function(exprList, isBinding) {\n  var end = exprList.length;\n  for (var i = 0; i < end; i++) {\n    var elt = exprList[i];\n    if (elt) { this.toAssignable(elt, isBinding); }\n  }\n  if (end) {\n    var last = exprList[end - 1];\n    if (this.options.ecmaVersion === 6 && isBinding && last && last.type === \"RestElement\" && last.argument.type !== \"Identifier\")\n      { this.unexpected(last.argument.start); }\n  }\n  return exprList\n};\n\n// Parses spread element.\n\npp$7.parseSpread = function(refDestructuringErrors) {\n  var node = this.startNode();\n  this.next();\n  node.argument = this.parseMaybeAssign(false, refDestructuringErrors);\n  return this.finishNode(node, \"SpreadElement\")\n};\n\npp$7.parseRestBinding = function() {\n  var node = this.startNode();\n  this.next();\n\n  // RestElement inside of a function parameter must be an identifier\n  if (this.options.ecmaVersion === 6 && this.type !== types$1.name)\n    { this.unexpected(); }\n\n  node.argument = this.parseBindingAtom();\n\n  return this.finishNode(node, \"RestElement\")\n};\n\n// Parses lvalue (assignable) atom.\n\npp$7.parseBindingAtom = function() {\n  if (this.options.ecmaVersion >= 6) {\n    switch (this.type) {\n    case types$1.bracketL:\n      var node = this.startNode();\n      this.next();\n      node.elements = this.parseBindingList(types$1.bracketR, true, true);\n      return this.finishNode(node, \"ArrayPattern\")\n\n    case types$1.braceL:\n      return this.parseObj(true)\n    }\n  }\n  return this.parseIdent()\n};\n\npp$7.parseBindingList = function(close, allowEmpty, allowTrailingComma) {\n  var elts = [], first = true;\n  while (!this.eat(close)) {\n    if (first) { first = false; }\n    else { this.expect(types$1.comma); }\n    if (allowEmpty && this.type === types$1.comma) {\n      elts.push(null);\n    } else if (allowTrailingComma && this.afterTrailingComma(close)) {\n      break\n    } else if (this.type === types$1.ellipsis) {\n      var rest = this.parseRestBinding();\n      this.parseBindingListItem(rest);\n      elts.push(rest);\n      if (this.type === types$1.comma) { this.raise(this.start, \"Comma is not permitted after the rest element\"); }\n      this.expect(close);\n      break\n    } else {\n      var elem = this.parseMaybeDefault(this.start, this.startLoc);\n      this.parseBindingListItem(elem);\n      elts.push(elem);\n    }\n  }\n  return elts\n};\n\npp$7.parseBindingListItem = function(param) {\n  return param\n};\n\n// Parses assignment pattern around given atom if possible.\n\npp$7.parseMaybeDefault = function(startPos, startLoc, left) {\n  left = left || this.parseBindingAtom();\n  if (this.options.ecmaVersion < 6 || !this.eat(types$1.eq)) { return left }\n  var node = this.startNodeAt(startPos, startLoc);\n  node.left = left;\n  node.right = this.parseMaybeAssign();\n  return this.finishNode(node, \"AssignmentPattern\")\n};\n\n// The following three functions all verify that a node is an lvalue —\n// something that can be bound, or assigned to. In order to do so, they perform\n// a variety of checks:\n//\n// - Check that none of the bound/assigned-to identifiers are reserved words.\n// - Record name declarations for bindings in the appropriate scope.\n// - Check duplicate argument names, if checkClashes is set.\n//\n// If a complex binding pattern is encountered (e.g., object and array\n// destructuring), the entire pattern is recursively checked.\n//\n// There are three versions of checkLVal*() appropriate for different\n// circumstances:\n//\n// - checkLValSimple() shall be used if the syntactic construct supports\n//   nothing other than identifiers and member expressions. Parenthesized\n//   expressions are also correctly handled. This is generally appropriate for\n//   constructs for which the spec says\n//\n//   > It is a Syntax Error if AssignmentTargetType of [the production] is not\n//   > simple.\n//\n//   It is also appropriate for checking if an identifier is valid and not\n//   defined elsewhere, like import declarations or function/class identifiers.\n//\n//   Examples where this is used include:\n//     a += …;\n//     import a from '…';\n//   where a is the node to be checked.\n//\n// - checkLValPattern() shall be used if the syntactic construct supports\n//   anything checkLValSimple() supports, as well as object and array\n//   destructuring patterns. This is generally appropriate for constructs for\n//   which the spec says\n//\n//   > It is a Syntax Error if [the production] is neither an ObjectLiteral nor\n//   > an ArrayLiteral and AssignmentTargetType of [the production] is not\n//   > simple.\n//\n//   Examples where this is used include:\n//     (a = …);\n//     const a = …;\n//     try { … } catch (a) { … }\n//   where a is the node to be checked.\n//\n// - checkLValInnerPattern() shall be used if the syntactic construct supports\n//   anything checkLValPattern() supports, as well as default assignment\n//   patterns, rest elements, and other constructs that may appear within an\n//   object or array destructuring pattern.\n//\n//   As a special case, function parameters also use checkLValInnerPattern(),\n//   as they also support defaults and rest constructs.\n//\n// These functions deliberately support both assignment and binding constructs,\n// as the logic for both is exceedingly similar. If the node is the target of\n// an assignment, then bindingType should be set to BIND_NONE. Otherwise, it\n// should be set to the appropriate BIND_* constant, like BIND_VAR or\n// BIND_LEXICAL.\n//\n// If the function is called with a non-BIND_NONE bindingType, then\n// additionally a checkClashes object may be specified to allow checking for\n// duplicate argument names. checkClashes is ignored if the provided construct\n// is an assignment (i.e., bindingType is BIND_NONE).\n\npp$7.checkLValSimple = function(expr, bindingType, checkClashes) {\n  if ( bindingType === void 0 ) bindingType = BIND_NONE;\n\n  var isBind = bindingType !== BIND_NONE;\n\n  switch (expr.type) {\n  case \"Identifier\":\n    if (this.strict && this.reservedWordsStrictBind.test(expr.name))\n      { this.raiseRecoverable(expr.start, (isBind ? \"Binding \" : \"Assigning to \") + expr.name + \" in strict mode\"); }\n    if (isBind) {\n      if (bindingType === BIND_LEXICAL && expr.name === \"let\")\n        { this.raiseRecoverable(expr.start, \"let is disallowed as a lexically bound name\"); }\n      if (checkClashes) {\n        if (hasOwn(checkClashes, expr.name))\n          { this.raiseRecoverable(expr.start, \"Argument name clash\"); }\n        checkClashes[expr.name] = true;\n      }\n      if (bindingType !== BIND_OUTSIDE) { this.declareName(expr.name, bindingType, expr.start); }\n    }\n    break\n\n  case \"ChainExpression\":\n    this.raiseRecoverable(expr.start, \"Optional chaining cannot appear in left-hand side\");\n    break\n\n  case \"MemberExpression\":\n    if (isBind) { this.raiseRecoverable(expr.start, \"Binding member expression\"); }\n    break\n\n  case \"ParenthesizedExpression\":\n    if (isBind) { this.raiseRecoverable(expr.start, \"Binding parenthesized expression\"); }\n    return this.checkLValSimple(expr.expression, bindingType, checkClashes)\n\n  default:\n    this.raise(expr.start, (isBind ? \"Binding\" : \"Assigning to\") + \" rvalue\");\n  }\n};\n\npp$7.checkLValPattern = function(expr, bindingType, checkClashes) {\n  if ( bindingType === void 0 ) bindingType = BIND_NONE;\n\n  switch (expr.type) {\n  case \"ObjectPattern\":\n    for (var i = 0, list = expr.properties; i < list.length; i += 1) {\n      var prop = list[i];\n\n    this.checkLValInnerPattern(prop, bindingType, checkClashes);\n    }\n    break\n\n  case \"ArrayPattern\":\n    for (var i$1 = 0, list$1 = expr.elements; i$1 < list$1.length; i$1 += 1) {\n      var elem = list$1[i$1];\n\n    if (elem) { this.checkLValInnerPattern(elem, bindingType, checkClashes); }\n    }\n    break\n\n  default:\n    this.checkLValSimple(expr, bindingType, checkClashes);\n  }\n};\n\npp$7.checkLValInnerPattern = function(expr, bindingType, checkClashes) {\n  if ( bindingType === void 0 ) bindingType = BIND_NONE;\n\n  switch (expr.type) {\n  case \"Property\":\n    // AssignmentProperty has type === \"Property\"\n    this.checkLValInnerPattern(expr.value, bindingType, checkClashes);\n    break\n\n  case \"AssignmentPattern\":\n    this.checkLValPattern(expr.left, bindingType, checkClashes);\n    break\n\n  case \"RestElement\":\n    this.checkLValPattern(expr.argument, bindingType, checkClashes);\n    break\n\n  default:\n    this.checkLValPattern(expr, bindingType, checkClashes);\n  }\n};\n\n// The algorithm used to determine whether a regexp can appear at a\n\nvar TokContext = function TokContext(token, isExpr, preserveSpace, override, generator) {\n  this.token = token;\n  this.isExpr = !!isExpr;\n  this.preserveSpace = !!preserveSpace;\n  this.override = override;\n  this.generator = !!generator;\n};\n\nvar types$2 = {\n  b_stat: new TokContext(\"{\", false),\n  b_expr: new TokContext(\"{\", true),\n  b_tmpl: new TokContext(\"${\", false),\n  p_stat: new TokContext(\"(\", false),\n  p_expr: new TokContext(\"(\", true),\n  q_tmpl: new TokContext(\"`\", true, true, function (p) { return p.tryReadTemplateToken(); }),\n  f_stat: new TokContext(\"function\", false),\n  f_expr: new TokContext(\"function\", true),\n  f_expr_gen: new TokContext(\"function\", true, false, null, true),\n  f_gen: new TokContext(\"function\", false, false, null, true)\n};\n\nvar pp$6 = Parser$1.prototype;\n\npp$6.initialContext = function() {\n  return [types$2.b_stat]\n};\n\npp$6.curContext = function() {\n  return this.context[this.context.length - 1]\n};\n\npp$6.braceIsBlock = function(prevType) {\n  var parent = this.curContext();\n  if (parent === types$2.f_expr || parent === types$2.f_stat)\n    { return true }\n  if (prevType === types$1.colon && (parent === types$2.b_stat || parent === types$2.b_expr))\n    { return !parent.isExpr }\n\n  // The check for `tt.name && exprAllowed` detects whether we are\n  // after a `yield` or `of` construct. See the `updateContext` for\n  // `tt.name`.\n  if (prevType === types$1._return || prevType === types$1.name && this.exprAllowed)\n    { return lineBreak.test(this.input.slice(this.lastTokEnd, this.start)) }\n  if (prevType === types$1._else || prevType === types$1.semi || prevType === types$1.eof || prevType === types$1.parenR || prevType === types$1.arrow)\n    { return true }\n  if (prevType === types$1.braceL)\n    { return parent === types$2.b_stat }\n  if (prevType === types$1._var || prevType === types$1._const || prevType === types$1.name)\n    { return false }\n  return !this.exprAllowed\n};\n\npp$6.inGeneratorContext = function() {\n  for (var i = this.context.length - 1; i >= 1; i--) {\n    var context = this.context[i];\n    if (context.token === \"function\")\n      { return context.generator }\n  }\n  return false\n};\n\npp$6.updateContext = function(prevType) {\n  var update, type = this.type;\n  if (type.keyword && prevType === types$1.dot)\n    { this.exprAllowed = false; }\n  else if (update = type.updateContext)\n    { update.call(this, prevType); }\n  else\n    { this.exprAllowed = type.beforeExpr; }\n};\n\n// Used to handle egde cases when token context could not be inferred correctly during tokenization phase\n\npp$6.overrideContext = function(tokenCtx) {\n  if (this.curContext() !== tokenCtx) {\n    this.context[this.context.length - 1] = tokenCtx;\n  }\n};\n\n// Token-specific context update code\n\ntypes$1.parenR.updateContext = types$1.braceR.updateContext = function() {\n  if (this.context.length === 1) {\n    this.exprAllowed = true;\n    return\n  }\n  var out = this.context.pop();\n  if (out === types$2.b_stat && this.curContext().token === \"function\") {\n    out = this.context.pop();\n  }\n  this.exprAllowed = !out.isExpr;\n};\n\ntypes$1.braceL.updateContext = function(prevType) {\n  this.context.push(this.braceIsBlock(prevType) ? types$2.b_stat : types$2.b_expr);\n  this.exprAllowed = true;\n};\n\ntypes$1.dollarBraceL.updateContext = function() {\n  this.context.push(types$2.b_tmpl);\n  this.exprAllowed = true;\n};\n\ntypes$1.parenL.updateContext = function(prevType) {\n  var statementParens = prevType === types$1._if || prevType === types$1._for || prevType === types$1._with || prevType === types$1._while;\n  this.context.push(statementParens ? types$2.p_stat : types$2.p_expr);\n  this.exprAllowed = true;\n};\n\ntypes$1.incDec.updateContext = function() {\n  // tokExprAllowed stays unchanged\n};\n\ntypes$1._function.updateContext = types$1._class.updateContext = function(prevType) {\n  if (prevType.beforeExpr && prevType !== types$1._else &&\n      !(prevType === types$1.semi && this.curContext() !== types$2.p_stat) &&\n      !(prevType === types$1._return && lineBreak.test(this.input.slice(this.lastTokEnd, this.start))) &&\n      !((prevType === types$1.colon || prevType === types$1.braceL) && this.curContext() === types$2.b_stat))\n    { this.context.push(types$2.f_expr); }\n  else\n    { this.context.push(types$2.f_stat); }\n  this.exprAllowed = false;\n};\n\ntypes$1.backQuote.updateContext = function() {\n  if (this.curContext() === types$2.q_tmpl)\n    { this.context.pop(); }\n  else\n    { this.context.push(types$2.q_tmpl); }\n  this.exprAllowed = false;\n};\n\ntypes$1.star.updateContext = function(prevType) {\n  if (prevType === types$1._function) {\n    var index = this.context.length - 1;\n    if (this.context[index] === types$2.f_expr)\n      { this.context[index] = types$2.f_expr_gen; }\n    else\n      { this.context[index] = types$2.f_gen; }\n  }\n  this.exprAllowed = true;\n};\n\ntypes$1.name.updateContext = function(prevType) {\n  var allowed = false;\n  if (this.options.ecmaVersion >= 6 && prevType !== types$1.dot) {\n    if (this.value === \"of\" && !this.exprAllowed ||\n        this.value === \"yield\" && this.inGeneratorContext())\n      { allowed = true; }\n  }\n  this.exprAllowed = allowed;\n};\n\n// A recursive descent parser operates by defining functions for all\n\nvar pp$5 = Parser$1.prototype;\n\n// Check if property name clashes with already added.\n// Object/class getters and setters are not allowed to clash —\n// either with each other or with an init property — and in\n// strict mode, init properties are also not allowed to be repeated.\n\npp$5.checkPropClash = function(prop, propHash, refDestructuringErrors) {\n  if (this.options.ecmaVersion >= 9 && prop.type === \"SpreadElement\")\n    { return }\n  if (this.options.ecmaVersion >= 6 && (prop.computed || prop.method || prop.shorthand))\n    { return }\n  var key = prop.key;\n  var name;\n  switch (key.type) {\n  case \"Identifier\": name = key.name; break\n  case \"Literal\": name = String(key.value); break\n  default: return\n  }\n  var kind = prop.kind;\n  if (this.options.ecmaVersion >= 6) {\n    if (name === \"__proto__\" && kind === \"init\") {\n      if (propHash.proto) {\n        if (refDestructuringErrors) {\n          if (refDestructuringErrors.doubleProto < 0) {\n            refDestructuringErrors.doubleProto = key.start;\n          }\n        } else {\n          this.raiseRecoverable(key.start, \"Redefinition of __proto__ property\");\n        }\n      }\n      propHash.proto = true;\n    }\n    return\n  }\n  name = \"$\" + name;\n  var other = propHash[name];\n  if (other) {\n    var redefinition;\n    if (kind === \"init\") {\n      redefinition = this.strict && other.init || other.get || other.set;\n    } else {\n      redefinition = other.init || other[kind];\n    }\n    if (redefinition)\n      { this.raiseRecoverable(key.start, \"Redefinition of property\"); }\n  } else {\n    other = propHash[name] = {\n      init: false,\n      get: false,\n      set: false\n    };\n  }\n  other[kind] = true;\n};\n\n// ### Expression parsing\n\n// These nest, from the most general expression type at the top to\n// 'atomic', nondivisible expression types at the bottom. Most of\n// the functions will simply let the function(s) below them parse,\n// and, *if* the syntactic construct they handle is present, wrap\n// the AST node that the inner parser gave them in another node.\n\n// Parse a full expression. The optional arguments are used to\n// forbid the `in` operator (in for loops initalization expressions)\n// and provide reference for storing '=' operator inside shorthand\n// property assignment in contexts where both object expression\n// and object pattern might appear (so it's possible to raise\n// delayed syntax error at correct position).\n\npp$5.parseExpression = function(forInit, refDestructuringErrors) {\n  var startPos = this.start, startLoc = this.startLoc;\n  var expr = this.parseMaybeAssign(forInit, refDestructuringErrors);\n  if (this.type === types$1.comma) {\n    var node = this.startNodeAt(startPos, startLoc);\n    node.expressions = [expr];\n    while (this.eat(types$1.comma)) { node.expressions.push(this.parseMaybeAssign(forInit, refDestructuringErrors)); }\n    return this.finishNode(node, \"SequenceExpression\")\n  }\n  return expr\n};\n\n// Parse an assignment expression. This includes applications of\n// operators like `+=`.\n\npp$5.parseMaybeAssign = function(forInit, refDestructuringErrors, afterLeftParse) {\n  if (this.isContextual(\"yield\")) {\n    if (this.inGenerator) { return this.parseYield(forInit) }\n    // The tokenizer will assume an expression is allowed after\n    // `yield`, but this isn't that kind of yield\n    else { this.exprAllowed = false; }\n  }\n\n  var ownDestructuringErrors = false, oldParenAssign = -1, oldTrailingComma = -1, oldDoubleProto = -1;\n  if (refDestructuringErrors) {\n    oldParenAssign = refDestructuringErrors.parenthesizedAssign;\n    oldTrailingComma = refDestructuringErrors.trailingComma;\n    oldDoubleProto = refDestructuringErrors.doubleProto;\n    refDestructuringErrors.parenthesizedAssign = refDestructuringErrors.trailingComma = -1;\n  } else {\n    refDestructuringErrors = new DestructuringErrors;\n    ownDestructuringErrors = true;\n  }\n\n  var startPos = this.start, startLoc = this.startLoc;\n  if (this.type === types$1.parenL || this.type === types$1.name) {\n    this.potentialArrowAt = this.start;\n    this.potentialArrowInForAwait = forInit === \"await\";\n  }\n  var left = this.parseMaybeConditional(forInit, refDestructuringErrors);\n  if (afterLeftParse) { left = afterLeftParse.call(this, left, startPos, startLoc); }\n  if (this.type.isAssign) {\n    var node = this.startNodeAt(startPos, startLoc);\n    node.operator = this.value;\n    if (this.type === types$1.eq)\n      { left = this.toAssignable(left, false, refDestructuringErrors); }\n    if (!ownDestructuringErrors) {\n      refDestructuringErrors.parenthesizedAssign = refDestructuringErrors.trailingComma = refDestructuringErrors.doubleProto = -1;\n    }\n    if (refDestructuringErrors.shorthandAssign >= left.start)\n      { refDestructuringErrors.shorthandAssign = -1; } // reset because shorthand default was used correctly\n    if (this.type === types$1.eq)\n      { this.checkLValPattern(left); }\n    else\n      { this.checkLValSimple(left); }\n    node.left = left;\n    this.next();\n    node.right = this.parseMaybeAssign(forInit);\n    if (oldDoubleProto > -1) { refDestructuringErrors.doubleProto = oldDoubleProto; }\n    return this.finishNode(node, \"AssignmentExpression\")\n  } else {\n    if (ownDestructuringErrors) { this.checkExpressionErrors(refDestructuringErrors, true); }\n  }\n  if (oldParenAssign > -1) { refDestructuringErrors.parenthesizedAssign = oldParenAssign; }\n  if (oldTrailingComma > -1) { refDestructuringErrors.trailingComma = oldTrailingComma; }\n  return left\n};\n\n// Parse a ternary conditional (`?:`) operator.\n\npp$5.parseMaybeConditional = function(forInit, refDestructuringErrors) {\n  var startPos = this.start, startLoc = this.startLoc;\n  var expr = this.parseExprOps(forInit, refDestructuringErrors);\n  if (this.checkExpressionErrors(refDestructuringErrors)) { return expr }\n  if (this.eat(types$1.question)) {\n    var node = this.startNodeAt(startPos, startLoc);\n    node.test = expr;\n    node.consequent = this.parseMaybeAssign();\n    this.expect(types$1.colon);\n    node.alternate = this.parseMaybeAssign(forInit);\n    return this.finishNode(node, \"ConditionalExpression\")\n  }\n  return expr\n};\n\n// Start the precedence parser.\n\npp$5.parseExprOps = function(forInit, refDestructuringErrors) {\n  var startPos = this.start, startLoc = this.startLoc;\n  var expr = this.parseMaybeUnary(refDestructuringErrors, false, false, forInit);\n  if (this.checkExpressionErrors(refDestructuringErrors)) { return expr }\n  return expr.start === startPos && expr.type === \"ArrowFunctionExpression\" ? expr : this.parseExprOp(expr, startPos, startLoc, -1, forInit)\n};\n\n// Parse binary operators with the operator precedence parsing\n// algorithm. `left` is the left-hand side of the operator.\n// `minPrec` provides context that allows the function to stop and\n// defer further parser to one of its callers when it encounters an\n// operator that has a lower precedence than the set it is parsing.\n\npp$5.parseExprOp = function(left, leftStartPos, leftStartLoc, minPrec, forInit) {\n  var prec = this.type.binop;\n  if (prec != null && (!forInit || this.type !== types$1._in)) {\n    if (prec > minPrec) {\n      var logical = this.type === types$1.logicalOR || this.type === types$1.logicalAND;\n      var coalesce = this.type === types$1.coalesce;\n      if (coalesce) {\n        // Handle the precedence of `tt.coalesce` as equal to the range of logical expressions.\n        // In other words, `node.right` shouldn't contain logical expressions in order to check the mixed error.\n        prec = types$1.logicalAND.binop;\n      }\n      var op = this.value;\n      this.next();\n      var startPos = this.start, startLoc = this.startLoc;\n      var right = this.parseExprOp(this.parseMaybeUnary(null, false, false, forInit), startPos, startLoc, prec, forInit);\n      var node = this.buildBinary(leftStartPos, leftStartLoc, left, right, op, logical || coalesce);\n      if ((logical && this.type === types$1.coalesce) || (coalesce && (this.type === types$1.logicalOR || this.type === types$1.logicalAND))) {\n        this.raiseRecoverable(this.start, \"Logical expressions and coalesce expressions cannot be mixed. Wrap either by parentheses\");\n      }\n      return this.parseExprOp(node, leftStartPos, leftStartLoc, minPrec, forInit)\n    }\n  }\n  return left\n};\n\npp$5.buildBinary = function(startPos, startLoc, left, right, op, logical) {\n  if (right.type === \"PrivateIdentifier\") { this.raise(right.start, \"Private identifier can only be left side of binary expression\"); }\n  var node = this.startNodeAt(startPos, startLoc);\n  node.left = left;\n  node.operator = op;\n  node.right = right;\n  return this.finishNode(node, logical ? \"LogicalExpression\" : \"BinaryExpression\")\n};\n\n// Parse unary operators, both prefix and postfix.\n\npp$5.parseMaybeUnary = function(refDestructuringErrors, sawUnary, incDec, forInit) {\n  var startPos = this.start, startLoc = this.startLoc, expr;\n  if (this.isContextual(\"await\") && this.canAwait) {\n    expr = this.parseAwait(forInit);\n    sawUnary = true;\n  } else if (this.type.prefix) {\n    var node = this.startNode(), update = this.type === types$1.incDec;\n    node.operator = this.value;\n    node.prefix = true;\n    this.next();\n    node.argument = this.parseMaybeUnary(null, true, update, forInit);\n    this.checkExpressionErrors(refDestructuringErrors, true);\n    if (update) { this.checkLValSimple(node.argument); }\n    else if (this.strict && node.operator === \"delete\" &&\n             node.argument.type === \"Identifier\")\n      { this.raiseRecoverable(node.start, \"Deleting local variable in strict mode\"); }\n    else if (node.operator === \"delete\" && isPrivateFieldAccess(node.argument))\n      { this.raiseRecoverable(node.start, \"Private fields can not be deleted\"); }\n    else { sawUnary = true; }\n    expr = this.finishNode(node, update ? \"UpdateExpression\" : \"UnaryExpression\");\n  } else if (!sawUnary && this.type === types$1.privateId) {\n    if (forInit || this.privateNameStack.length === 0) { this.unexpected(); }\n    expr = this.parsePrivateIdent();\n    // only could be private fields in 'in', such as #x in obj\n    if (this.type !== types$1._in) { this.unexpected(); }\n  } else {\n    expr = this.parseExprSubscripts(refDestructuringErrors, forInit);\n    if (this.checkExpressionErrors(refDestructuringErrors)) { return expr }\n    while (this.type.postfix && !this.canInsertSemicolon()) {\n      var node$1 = this.startNodeAt(startPos, startLoc);\n      node$1.operator = this.value;\n      node$1.prefix = false;\n      node$1.argument = expr;\n      this.checkLValSimple(expr);\n      this.next();\n      expr = this.finishNode(node$1, \"UpdateExpression\");\n    }\n  }\n\n  if (!incDec && this.eat(types$1.starstar)) {\n    if (sawUnary)\n      { this.unexpected(this.lastTokStart); }\n    else\n      { return this.buildBinary(startPos, startLoc, expr, this.parseMaybeUnary(null, false, false, forInit), \"**\", false) }\n  } else {\n    return expr\n  }\n};\n\nfunction isPrivateFieldAccess(node) {\n  return (\n    node.type === \"MemberExpression\" && node.property.type === \"PrivateIdentifier\" ||\n    node.type === \"ChainExpression\" && isPrivateFieldAccess(node.expression)\n  )\n}\n\n// Parse call, dot, and `[]`-subscript expressions.\n\npp$5.parseExprSubscripts = function(refDestructuringErrors, forInit) {\n  var startPos = this.start, startLoc = this.startLoc;\n  var expr = this.parseExprAtom(refDestructuringErrors, forInit);\n  if (expr.type === \"ArrowFunctionExpression\" && this.input.slice(this.lastTokStart, this.lastTokEnd) !== \")\")\n    { return expr }\n  var result = this.parseSubscripts(expr, startPos, startLoc, false, forInit);\n  if (refDestructuringErrors && result.type === \"MemberExpression\") {\n    if (refDestructuringErrors.parenthesizedAssign >= result.start) { refDestructuringErrors.parenthesizedAssign = -1; }\n    if (refDestructuringErrors.parenthesizedBind >= result.start) { refDestructuringErrors.parenthesizedBind = -1; }\n    if (refDestructuringErrors.trailingComma >= result.start) { refDestructuringErrors.trailingComma = -1; }\n  }\n  return result\n};\n\npp$5.parseSubscripts = function(base, startPos, startLoc, noCalls, forInit) {\n  var maybeAsyncArrow = this.options.ecmaVersion >= 8 && base.type === \"Identifier\" && base.name === \"async\" &&\n      this.lastTokEnd === base.end && !this.canInsertSemicolon() && base.end - base.start === 5 &&\n      this.potentialArrowAt === base.start;\n  var optionalChained = false;\n\n  while (true) {\n    var element = this.parseSubscript(base, startPos, startLoc, noCalls, maybeAsyncArrow, optionalChained, forInit);\n\n    if (element.optional) { optionalChained = true; }\n    if (element === base || element.type === \"ArrowFunctionExpression\") {\n      if (optionalChained) {\n        var chainNode = this.startNodeAt(startPos, startLoc);\n        chainNode.expression = element;\n        element = this.finishNode(chainNode, \"ChainExpression\");\n      }\n      return element\n    }\n\n    base = element;\n  }\n};\n\npp$5.parseSubscript = function(base, startPos, startLoc, noCalls, maybeAsyncArrow, optionalChained, forInit) {\n  var optionalSupported = this.options.ecmaVersion >= 11;\n  var optional = optionalSupported && this.eat(types$1.questionDot);\n  if (noCalls && optional) { this.raise(this.lastTokStart, \"Optional chaining cannot appear in the callee of new expressions\"); }\n\n  var computed = this.eat(types$1.bracketL);\n  if (computed || (optional && this.type !== types$1.parenL && this.type !== types$1.backQuote) || this.eat(types$1.dot)) {\n    var node = this.startNodeAt(startPos, startLoc);\n    node.object = base;\n    if (computed) {\n      node.property = this.parseExpression();\n      this.expect(types$1.bracketR);\n    } else if (this.type === types$1.privateId && base.type !== \"Super\") {\n      node.property = this.parsePrivateIdent();\n    } else {\n      node.property = this.parseIdent(this.options.allowReserved !== \"never\");\n    }\n    node.computed = !!computed;\n    if (optionalSupported) {\n      node.optional = optional;\n    }\n    base = this.finishNode(node, \"MemberExpression\");\n  } else if (!noCalls && this.eat(types$1.parenL)) {\n    var refDestructuringErrors = new DestructuringErrors, oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n    this.yieldPos = 0;\n    this.awaitPos = 0;\n    this.awaitIdentPos = 0;\n    var exprList = this.parseExprList(types$1.parenR, this.options.ecmaVersion >= 8, false, refDestructuringErrors);\n    if (maybeAsyncArrow && !optional && !this.canInsertSemicolon() && this.eat(types$1.arrow)) {\n      this.checkPatternErrors(refDestructuringErrors, false);\n      this.checkYieldAwaitInDefaultParams();\n      if (this.awaitIdentPos > 0)\n        { this.raise(this.awaitIdentPos, \"Cannot use 'await' as identifier inside an async function\"); }\n      this.yieldPos = oldYieldPos;\n      this.awaitPos = oldAwaitPos;\n      this.awaitIdentPos = oldAwaitIdentPos;\n      return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), exprList, true, forInit)\n    }\n    this.checkExpressionErrors(refDestructuringErrors, true);\n    this.yieldPos = oldYieldPos || this.yieldPos;\n    this.awaitPos = oldAwaitPos || this.awaitPos;\n    this.awaitIdentPos = oldAwaitIdentPos || this.awaitIdentPos;\n    var node$1 = this.startNodeAt(startPos, startLoc);\n    node$1.callee = base;\n    node$1.arguments = exprList;\n    if (optionalSupported) {\n      node$1.optional = optional;\n    }\n    base = this.finishNode(node$1, \"CallExpression\");\n  } else if (this.type === types$1.backQuote) {\n    if (optional || optionalChained) {\n      this.raise(this.start, \"Optional chaining cannot appear in the tag of tagged template expressions\");\n    }\n    var node$2 = this.startNodeAt(startPos, startLoc);\n    node$2.tag = base;\n    node$2.quasi = this.parseTemplate({isTagged: true});\n    base = this.finishNode(node$2, \"TaggedTemplateExpression\");\n  }\n  return base\n};\n\n// Parse an atomic expression — either a single token that is an\n// expression, an expression started by a keyword like `function` or\n// `new`, or an expression wrapped in punctuation like `()`, `[]`,\n// or `{}`.\n\npp$5.parseExprAtom = function(refDestructuringErrors, forInit) {\n  // If a division operator appears in an expression position, the\n  // tokenizer got confused, and we force it to read a regexp instead.\n  if (this.type === types$1.slash) { this.readRegexp(); }\n\n  var node, canBeArrow = this.potentialArrowAt === this.start;\n  switch (this.type) {\n  case types$1._super:\n    if (!this.allowSuper)\n      { this.raise(this.start, \"'super' keyword outside a method\"); }\n    node = this.startNode();\n    this.next();\n    if (this.type === types$1.parenL && !this.allowDirectSuper)\n      { this.raise(node.start, \"super() call outside constructor of a subclass\"); }\n    // The `super` keyword can appear at below:\n    // SuperProperty:\n    //     super [ Expression ]\n    //     super . IdentifierName\n    // SuperCall:\n    //     super ( Arguments )\n    if (this.type !== types$1.dot && this.type !== types$1.bracketL && this.type !== types$1.parenL)\n      { this.unexpected(); }\n    return this.finishNode(node, \"Super\")\n\n  case types$1._this:\n    node = this.startNode();\n    this.next();\n    return this.finishNode(node, \"ThisExpression\")\n\n  case types$1.name:\n    var startPos = this.start, startLoc = this.startLoc, containsEsc = this.containsEsc;\n    var id = this.parseIdent(false);\n    if (this.options.ecmaVersion >= 8 && !containsEsc && id.name === \"async\" && !this.canInsertSemicolon() && this.eat(types$1._function)) {\n      this.overrideContext(types$2.f_expr);\n      return this.parseFunction(this.startNodeAt(startPos, startLoc), 0, false, true, forInit)\n    }\n    if (canBeArrow && !this.canInsertSemicolon()) {\n      if (this.eat(types$1.arrow))\n        { return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), [id], false, forInit) }\n      if (this.options.ecmaVersion >= 8 && id.name === \"async\" && this.type === types$1.name && !containsEsc &&\n          (!this.potentialArrowInForAwait || this.value !== \"of\" || this.containsEsc)) {\n        id = this.parseIdent(false);\n        if (this.canInsertSemicolon() || !this.eat(types$1.arrow))\n          { this.unexpected(); }\n        return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), [id], true, forInit)\n      }\n    }\n    return id\n\n  case types$1.regexp:\n    var value = this.value;\n    node = this.parseLiteral(value.value);\n    node.regex = {pattern: value.pattern, flags: value.flags};\n    return node\n\n  case types$1.num: case types$1.string:\n    return this.parseLiteral(this.value)\n\n  case types$1._null: case types$1._true: case types$1._false:\n    node = this.startNode();\n    node.value = this.type === types$1._null ? null : this.type === types$1._true;\n    node.raw = this.type.keyword;\n    this.next();\n    return this.finishNode(node, \"Literal\")\n\n  case types$1.parenL:\n    var start = this.start, expr = this.parseParenAndDistinguishExpression(canBeArrow, forInit);\n    if (refDestructuringErrors) {\n      if (refDestructuringErrors.parenthesizedAssign < 0 && !this.isSimpleAssignTarget(expr))\n        { refDestructuringErrors.parenthesizedAssign = start; }\n      if (refDestructuringErrors.parenthesizedBind < 0)\n        { refDestructuringErrors.parenthesizedBind = start; }\n    }\n    return expr\n\n  case types$1.bracketL:\n    node = this.startNode();\n    this.next();\n    node.elements = this.parseExprList(types$1.bracketR, true, true, refDestructuringErrors);\n    return this.finishNode(node, \"ArrayExpression\")\n\n  case types$1.braceL:\n    this.overrideContext(types$2.b_expr);\n    return this.parseObj(false, refDestructuringErrors)\n\n  case types$1._function:\n    node = this.startNode();\n    this.next();\n    return this.parseFunction(node, 0)\n\n  case types$1._class:\n    return this.parseClass(this.startNode(), false)\n\n  case types$1._new:\n    return this.parseNew()\n\n  case types$1.backQuote:\n    return this.parseTemplate()\n\n  case types$1._import:\n    if (this.options.ecmaVersion >= 11) {\n      return this.parseExprImport()\n    } else {\n      return this.unexpected()\n    }\n\n  default:\n    this.unexpected();\n  }\n};\n\npp$5.parseExprImport = function() {\n  var node = this.startNode();\n\n  // Consume `import` as an identifier for `import.meta`.\n  // Because `this.parseIdent(true)` doesn't check escape sequences, it needs the check of `this.containsEsc`.\n  if (this.containsEsc) { this.raiseRecoverable(this.start, \"Escape sequence in keyword import\"); }\n  var meta = this.parseIdent(true);\n\n  switch (this.type) {\n  case types$1.parenL:\n    return this.parseDynamicImport(node)\n  case types$1.dot:\n    node.meta = meta;\n    return this.parseImportMeta(node)\n  default:\n    this.unexpected();\n  }\n};\n\npp$5.parseDynamicImport = function(node) {\n  this.next(); // skip `(`\n\n  // Parse node.source.\n  node.source = this.parseMaybeAssign();\n\n  // Verify ending.\n  if (!this.eat(types$1.parenR)) {\n    var errorPos = this.start;\n    if (this.eat(types$1.comma) && this.eat(types$1.parenR)) {\n      this.raiseRecoverable(errorPos, \"Trailing comma is not allowed in import()\");\n    } else {\n      this.unexpected(errorPos);\n    }\n  }\n\n  return this.finishNode(node, \"ImportExpression\")\n};\n\npp$5.parseImportMeta = function(node) {\n  this.next(); // skip `.`\n\n  var containsEsc = this.containsEsc;\n  node.property = this.parseIdent(true);\n\n  if (node.property.name !== \"meta\")\n    { this.raiseRecoverable(node.property.start, \"The only valid meta property for import is 'import.meta'\"); }\n  if (containsEsc)\n    { this.raiseRecoverable(node.start, \"'import.meta' must not contain escaped characters\"); }\n  if (this.options.sourceType !== \"module\" && !this.options.allowImportExportEverywhere)\n    { this.raiseRecoverable(node.start, \"Cannot use 'import.meta' outside a module\"); }\n\n  return this.finishNode(node, \"MetaProperty\")\n};\n\npp$5.parseLiteral = function(value) {\n  var node = this.startNode();\n  node.value = value;\n  node.raw = this.input.slice(this.start, this.end);\n  if (node.raw.charCodeAt(node.raw.length - 1) === 110) { node.bigint = node.raw.slice(0, -1).replace(/_/g, \"\"); }\n  this.next();\n  return this.finishNode(node, \"Literal\")\n};\n\npp$5.parseParenExpression = function() {\n  this.expect(types$1.parenL);\n  var val = this.parseExpression();\n  this.expect(types$1.parenR);\n  return val\n};\n\npp$5.parseParenAndDistinguishExpression = function(canBeArrow, forInit) {\n  var startPos = this.start, startLoc = this.startLoc, val, allowTrailingComma = this.options.ecmaVersion >= 8;\n  if (this.options.ecmaVersion >= 6) {\n    this.next();\n\n    var innerStartPos = this.start, innerStartLoc = this.startLoc;\n    var exprList = [], first = true, lastIsComma = false;\n    var refDestructuringErrors = new DestructuringErrors, oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, spreadStart;\n    this.yieldPos = 0;\n    this.awaitPos = 0;\n    // Do not save awaitIdentPos to allow checking awaits nested in parameters\n    while (this.type !== types$1.parenR) {\n      first ? first = false : this.expect(types$1.comma);\n      if (allowTrailingComma && this.afterTrailingComma(types$1.parenR, true)) {\n        lastIsComma = true;\n        break\n      } else if (this.type === types$1.ellipsis) {\n        spreadStart = this.start;\n        exprList.push(this.parseParenItem(this.parseRestBinding()));\n        if (this.type === types$1.comma) { this.raise(this.start, \"Comma is not permitted after the rest element\"); }\n        break\n      } else {\n        exprList.push(this.parseMaybeAssign(false, refDestructuringErrors, this.parseParenItem));\n      }\n    }\n    var innerEndPos = this.lastTokEnd, innerEndLoc = this.lastTokEndLoc;\n    this.expect(types$1.parenR);\n\n    if (canBeArrow && !this.canInsertSemicolon() && this.eat(types$1.arrow)) {\n      this.checkPatternErrors(refDestructuringErrors, false);\n      this.checkYieldAwaitInDefaultParams();\n      this.yieldPos = oldYieldPos;\n      this.awaitPos = oldAwaitPos;\n      return this.parseParenArrowList(startPos, startLoc, exprList, forInit)\n    }\n\n    if (!exprList.length || lastIsComma) { this.unexpected(this.lastTokStart); }\n    if (spreadStart) { this.unexpected(spreadStart); }\n    this.checkExpressionErrors(refDestructuringErrors, true);\n    this.yieldPos = oldYieldPos || this.yieldPos;\n    this.awaitPos = oldAwaitPos || this.awaitPos;\n\n    if (exprList.length > 1) {\n      val = this.startNodeAt(innerStartPos, innerStartLoc);\n      val.expressions = exprList;\n      this.finishNodeAt(val, \"SequenceExpression\", innerEndPos, innerEndLoc);\n    } else {\n      val = exprList[0];\n    }\n  } else {\n    val = this.parseParenExpression();\n  }\n\n  if (this.options.preserveParens) {\n    var par = this.startNodeAt(startPos, startLoc);\n    par.expression = val;\n    return this.finishNode(par, \"ParenthesizedExpression\")\n  } else {\n    return val\n  }\n};\n\npp$5.parseParenItem = function(item) {\n  return item\n};\n\npp$5.parseParenArrowList = function(startPos, startLoc, exprList, forInit) {\n  return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), exprList, false, forInit)\n};\n\n// New's precedence is slightly tricky. It must allow its argument to\n// be a `[]` or dot subscript expression, but not a call — at least,\n// not without wrapping it in parentheses. Thus, it uses the noCalls\n// argument to parseSubscripts to prevent it from consuming the\n// argument list.\n\nvar empty = [];\n\npp$5.parseNew = function() {\n  if (this.containsEsc) { this.raiseRecoverable(this.start, \"Escape sequence in keyword new\"); }\n  var node = this.startNode();\n  var meta = this.parseIdent(true);\n  if (this.options.ecmaVersion >= 6 && this.eat(types$1.dot)) {\n    node.meta = meta;\n    var containsEsc = this.containsEsc;\n    node.property = this.parseIdent(true);\n    if (node.property.name !== \"target\")\n      { this.raiseRecoverable(node.property.start, \"The only valid meta property for new is 'new.target'\"); }\n    if (containsEsc)\n      { this.raiseRecoverable(node.start, \"'new.target' must not contain escaped characters\"); }\n    if (!this.allowNewDotTarget)\n      { this.raiseRecoverable(node.start, \"'new.target' can only be used in functions and class static block\"); }\n    return this.finishNode(node, \"MetaProperty\")\n  }\n  var startPos = this.start, startLoc = this.startLoc, isImport = this.type === types$1._import;\n  node.callee = this.parseSubscripts(this.parseExprAtom(), startPos, startLoc, true, false);\n  if (isImport && node.callee.type === \"ImportExpression\") {\n    this.raise(startPos, \"Cannot use new with import()\");\n  }\n  if (this.eat(types$1.parenL)) { node.arguments = this.parseExprList(types$1.parenR, this.options.ecmaVersion >= 8, false); }\n  else { node.arguments = empty; }\n  return this.finishNode(node, \"NewExpression\")\n};\n\n// Parse template expression.\n\npp$5.parseTemplateElement = function(ref) {\n  var isTagged = ref.isTagged;\n\n  var elem = this.startNode();\n  if (this.type === types$1.invalidTemplate) {\n    if (!isTagged) {\n      this.raiseRecoverable(this.start, \"Bad escape sequence in untagged template literal\");\n    }\n    elem.value = {\n      raw: this.value,\n      cooked: null\n    };\n  } else {\n    elem.value = {\n      raw: this.input.slice(this.start, this.end).replace(/\\r\\n?/g, \"\\n\"),\n      cooked: this.value\n    };\n  }\n  this.next();\n  elem.tail = this.type === types$1.backQuote;\n  return this.finishNode(elem, \"TemplateElement\")\n};\n\npp$5.parseTemplate = function(ref) {\n  if ( ref === void 0 ) ref = {};\n  var isTagged = ref.isTagged; if ( isTagged === void 0 ) isTagged = false;\n\n  var node = this.startNode();\n  this.next();\n  node.expressions = [];\n  var curElt = this.parseTemplateElement({isTagged: isTagged});\n  node.quasis = [curElt];\n  while (!curElt.tail) {\n    if (this.type === types$1.eof) { this.raise(this.pos, \"Unterminated template literal\"); }\n    this.expect(types$1.dollarBraceL);\n    node.expressions.push(this.parseExpression());\n    this.expect(types$1.braceR);\n    node.quasis.push(curElt = this.parseTemplateElement({isTagged: isTagged}));\n  }\n  this.next();\n  return this.finishNode(node, \"TemplateLiteral\")\n};\n\npp$5.isAsyncProp = function(prop) {\n  return !prop.computed && prop.key.type === \"Identifier\" && prop.key.name === \"async\" &&\n    (this.type === types$1.name || this.type === types$1.num || this.type === types$1.string || this.type === types$1.bracketL || this.type.keyword || (this.options.ecmaVersion >= 9 && this.type === types$1.star)) &&\n    !lineBreak.test(this.input.slice(this.lastTokEnd, this.start))\n};\n\n// Parse an object literal or binding pattern.\n\npp$5.parseObj = function(isPattern, refDestructuringErrors) {\n  var node = this.startNode(), first = true, propHash = {};\n  node.properties = [];\n  this.next();\n  while (!this.eat(types$1.braceR)) {\n    if (!first) {\n      this.expect(types$1.comma);\n      if (this.options.ecmaVersion >= 5 && this.afterTrailingComma(types$1.braceR)) { break }\n    } else { first = false; }\n\n    var prop = this.parseProperty(isPattern, refDestructuringErrors);\n    if (!isPattern) { this.checkPropClash(prop, propHash, refDestructuringErrors); }\n    node.properties.push(prop);\n  }\n  return this.finishNode(node, isPattern ? \"ObjectPattern\" : \"ObjectExpression\")\n};\n\npp$5.parseProperty = function(isPattern, refDestructuringErrors) {\n  var prop = this.startNode(), isGenerator, isAsync, startPos, startLoc;\n  if (this.options.ecmaVersion >= 9 && this.eat(types$1.ellipsis)) {\n    if (isPattern) {\n      prop.argument = this.parseIdent(false);\n      if (this.type === types$1.comma) {\n        this.raise(this.start, \"Comma is not permitted after the rest element\");\n      }\n      return this.finishNode(prop, \"RestElement\")\n    }\n    // Parse argument.\n    prop.argument = this.parseMaybeAssign(false, refDestructuringErrors);\n    // To disallow trailing comma via `this.toAssignable()`.\n    if (this.type === types$1.comma && refDestructuringErrors && refDestructuringErrors.trailingComma < 0) {\n      refDestructuringErrors.trailingComma = this.start;\n    }\n    // Finish\n    return this.finishNode(prop, \"SpreadElement\")\n  }\n  if (this.options.ecmaVersion >= 6) {\n    prop.method = false;\n    prop.shorthand = false;\n    if (isPattern || refDestructuringErrors) {\n      startPos = this.start;\n      startLoc = this.startLoc;\n    }\n    if (!isPattern)\n      { isGenerator = this.eat(types$1.star); }\n  }\n  var containsEsc = this.containsEsc;\n  this.parsePropertyName(prop);\n  if (!isPattern && !containsEsc && this.options.ecmaVersion >= 8 && !isGenerator && this.isAsyncProp(prop)) {\n    isAsync = true;\n    isGenerator = this.options.ecmaVersion >= 9 && this.eat(types$1.star);\n    this.parsePropertyName(prop);\n  } else {\n    isAsync = false;\n  }\n  this.parsePropertyValue(prop, isPattern, isGenerator, isAsync, startPos, startLoc, refDestructuringErrors, containsEsc);\n  return this.finishNode(prop, \"Property\")\n};\n\npp$5.parsePropertyValue = function(prop, isPattern, isGenerator, isAsync, startPos, startLoc, refDestructuringErrors, containsEsc) {\n  if ((isGenerator || isAsync) && this.type === types$1.colon)\n    { this.unexpected(); }\n\n  if (this.eat(types$1.colon)) {\n    prop.value = isPattern ? this.parseMaybeDefault(this.start, this.startLoc) : this.parseMaybeAssign(false, refDestructuringErrors);\n    prop.kind = \"init\";\n  } else if (this.options.ecmaVersion >= 6 && this.type === types$1.parenL) {\n    if (isPattern) { this.unexpected(); }\n    prop.kind = \"init\";\n    prop.method = true;\n    prop.value = this.parseMethod(isGenerator, isAsync);\n  } else if (!isPattern && !containsEsc &&\n             this.options.ecmaVersion >= 5 && !prop.computed && prop.key.type === \"Identifier\" &&\n             (prop.key.name === \"get\" || prop.key.name === \"set\") &&\n             (this.type !== types$1.comma && this.type !== types$1.braceR && this.type !== types$1.eq)) {\n    if (isGenerator || isAsync) { this.unexpected(); }\n    prop.kind = prop.key.name;\n    this.parsePropertyName(prop);\n    prop.value = this.parseMethod(false);\n    var paramCount = prop.kind === \"get\" ? 0 : 1;\n    if (prop.value.params.length !== paramCount) {\n      var start = prop.value.start;\n      if (prop.kind === \"get\")\n        { this.raiseRecoverable(start, \"getter should have no params\"); }\n      else\n        { this.raiseRecoverable(start, \"setter should have exactly one param\"); }\n    } else {\n      if (prop.kind === \"set\" && prop.value.params[0].type === \"RestElement\")\n        { this.raiseRecoverable(prop.value.params[0].start, \"Setter cannot use rest params\"); }\n    }\n  } else if (this.options.ecmaVersion >= 6 && !prop.computed && prop.key.type === \"Identifier\") {\n    if (isGenerator || isAsync) { this.unexpected(); }\n    this.checkUnreserved(prop.key);\n    if (prop.key.name === \"await\" && !this.awaitIdentPos)\n      { this.awaitIdentPos = startPos; }\n    prop.kind = \"init\";\n    if (isPattern) {\n      prop.value = this.parseMaybeDefault(startPos, startLoc, this.copyNode(prop.key));\n    } else if (this.type === types$1.eq && refDestructuringErrors) {\n      if (refDestructuringErrors.shorthandAssign < 0)\n        { refDestructuringErrors.shorthandAssign = this.start; }\n      prop.value = this.parseMaybeDefault(startPos, startLoc, this.copyNode(prop.key));\n    } else {\n      prop.value = this.copyNode(prop.key);\n    }\n    prop.shorthand = true;\n  } else { this.unexpected(); }\n};\n\npp$5.parsePropertyName = function(prop) {\n  if (this.options.ecmaVersion >= 6) {\n    if (this.eat(types$1.bracketL)) {\n      prop.computed = true;\n      prop.key = this.parseMaybeAssign();\n      this.expect(types$1.bracketR);\n      return prop.key\n    } else {\n      prop.computed = false;\n    }\n  }\n  return prop.key = this.type === types$1.num || this.type === types$1.string ? this.parseExprAtom() : this.parseIdent(this.options.allowReserved !== \"never\")\n};\n\n// Initialize empty function node.\n\npp$5.initFunction = function(node) {\n  node.id = null;\n  if (this.options.ecmaVersion >= 6) { node.generator = node.expression = false; }\n  if (this.options.ecmaVersion >= 8) { node.async = false; }\n};\n\n// Parse object or class method.\n\npp$5.parseMethod = function(isGenerator, isAsync, allowDirectSuper) {\n  var node = this.startNode(), oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n\n  this.initFunction(node);\n  if (this.options.ecmaVersion >= 6)\n    { node.generator = isGenerator; }\n  if (this.options.ecmaVersion >= 8)\n    { node.async = !!isAsync; }\n\n  this.yieldPos = 0;\n  this.awaitPos = 0;\n  this.awaitIdentPos = 0;\n  this.enterScope(functionFlags(isAsync, node.generator) | SCOPE_SUPER | (allowDirectSuper ? SCOPE_DIRECT_SUPER : 0));\n\n  this.expect(types$1.parenL);\n  node.params = this.parseBindingList(types$1.parenR, false, this.options.ecmaVersion >= 8);\n  this.checkYieldAwaitInDefaultParams();\n  this.parseFunctionBody(node, false, true, false);\n\n  this.yieldPos = oldYieldPos;\n  this.awaitPos = oldAwaitPos;\n  this.awaitIdentPos = oldAwaitIdentPos;\n  return this.finishNode(node, \"FunctionExpression\")\n};\n\n// Parse arrow function expression with given parameters.\n\npp$5.parseArrowExpression = function(node, params, isAsync, forInit) {\n  var oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n\n  this.enterScope(functionFlags(isAsync, false) | SCOPE_ARROW);\n  this.initFunction(node);\n  if (this.options.ecmaVersion >= 8) { node.async = !!isAsync; }\n\n  this.yieldPos = 0;\n  this.awaitPos = 0;\n  this.awaitIdentPos = 0;\n\n  node.params = this.toAssignableList(params, true);\n  this.parseFunctionBody(node, true, false, forInit);\n\n  this.yieldPos = oldYieldPos;\n  this.awaitPos = oldAwaitPos;\n  this.awaitIdentPos = oldAwaitIdentPos;\n  return this.finishNode(node, \"ArrowFunctionExpression\")\n};\n\n// Parse function body and check parameters.\n\npp$5.parseFunctionBody = function(node, isArrowFunction, isMethod, forInit) {\n  var isExpression = isArrowFunction && this.type !== types$1.braceL;\n  var oldStrict = this.strict, useStrict = false;\n\n  if (isExpression) {\n    node.body = this.parseMaybeAssign(forInit);\n    node.expression = true;\n    this.checkParams(node, false);\n  } else {\n    var nonSimple = this.options.ecmaVersion >= 7 && !this.isSimpleParamList(node.params);\n    if (!oldStrict || nonSimple) {\n      useStrict = this.strictDirective(this.end);\n      // If this is a strict mode function, verify that argument names\n      // are not repeated, and it does not try to bind the words `eval`\n      // or `arguments`.\n      if (useStrict && nonSimple)\n        { this.raiseRecoverable(node.start, \"Illegal 'use strict' directive in function with non-simple parameter list\"); }\n    }\n    // Start a new scope with regard to labels and the `inFunction`\n    // flag (restore them to their old value afterwards).\n    var oldLabels = this.labels;\n    this.labels = [];\n    if (useStrict) { this.strict = true; }\n\n    // Add the params to varDeclaredNames to ensure that an error is thrown\n    // if a let/const declaration in the function clashes with one of the params.\n    this.checkParams(node, !oldStrict && !useStrict && !isArrowFunction && !isMethod && this.isSimpleParamList(node.params));\n    // Ensure the function name isn't a forbidden identifier in strict mode, e.g. 'eval'\n    if (this.strict && node.id) { this.checkLValSimple(node.id, BIND_OUTSIDE); }\n    node.body = this.parseBlock(false, undefined, useStrict && !oldStrict);\n    node.expression = false;\n    this.adaptDirectivePrologue(node.body.body);\n    this.labels = oldLabels;\n  }\n  this.exitScope();\n};\n\npp$5.isSimpleParamList = function(params) {\n  for (var i = 0, list = params; i < list.length; i += 1)\n    {\n    var param = list[i];\n\n    if (param.type !== \"Identifier\") { return false\n  } }\n  return true\n};\n\n// Checks function params for various disallowed patterns such as using \"eval\"\n// or \"arguments\" and duplicate parameters.\n\npp$5.checkParams = function(node, allowDuplicates) {\n  var nameHash = Object.create(null);\n  for (var i = 0, list = node.params; i < list.length; i += 1)\n    {\n    var param = list[i];\n\n    this.checkLValInnerPattern(param, BIND_VAR, allowDuplicates ? null : nameHash);\n  }\n};\n\n// Parses a comma-separated list of expressions, and returns them as\n// an array. `close` is the token type that ends the list, and\n// `allowEmpty` can be turned on to allow subsequent commas with\n// nothing in between them to be parsed as `null` (which is needed\n// for array literals).\n\npp$5.parseExprList = function(close, allowTrailingComma, allowEmpty, refDestructuringErrors) {\n  var elts = [], first = true;\n  while (!this.eat(close)) {\n    if (!first) {\n      this.expect(types$1.comma);\n      if (allowTrailingComma && this.afterTrailingComma(close)) { break }\n    } else { first = false; }\n\n    var elt = (void 0);\n    if (allowEmpty && this.type === types$1.comma)\n      { elt = null; }\n    else if (this.type === types$1.ellipsis) {\n      elt = this.parseSpread(refDestructuringErrors);\n      if (refDestructuringErrors && this.type === types$1.comma && refDestructuringErrors.trailingComma < 0)\n        { refDestructuringErrors.trailingComma = this.start; }\n    } else {\n      elt = this.parseMaybeAssign(false, refDestructuringErrors);\n    }\n    elts.push(elt);\n  }\n  return elts\n};\n\npp$5.checkUnreserved = function(ref) {\n  var start = ref.start;\n  var end = ref.end;\n  var name = ref.name;\n\n  if (this.inGenerator && name === \"yield\")\n    { this.raiseRecoverable(start, \"Cannot use 'yield' as identifier inside a generator\"); }\n  if (this.inAsync && name === \"await\")\n    { this.raiseRecoverable(start, \"Cannot use 'await' as identifier inside an async function\"); }\n  if (this.currentThisScope().inClassFieldInit && name === \"arguments\")\n    { this.raiseRecoverable(start, \"Cannot use 'arguments' in class field initializer\"); }\n  if (this.inClassStaticBlock && (name === \"arguments\" || name === \"await\"))\n    { this.raise(start, (\"Cannot use \" + name + \" in class static initialization block\")); }\n  if (this.keywords.test(name))\n    { this.raise(start, (\"Unexpected keyword '\" + name + \"'\")); }\n  if (this.options.ecmaVersion < 6 &&\n    this.input.slice(start, end).indexOf(\"\\\\\") !== -1) { return }\n  var re = this.strict ? this.reservedWordsStrict : this.reservedWords;\n  if (re.test(name)) {\n    if (!this.inAsync && name === \"await\")\n      { this.raiseRecoverable(start, \"Cannot use keyword 'await' outside an async function\"); }\n    this.raiseRecoverable(start, (\"The keyword '\" + name + \"' is reserved\"));\n  }\n};\n\n// Parse the next token as an identifier. If `liberal` is true (used\n// when parsing properties), it will also convert keywords into\n// identifiers.\n\npp$5.parseIdent = function(liberal) {\n  var node = this.startNode();\n  if (this.type === types$1.name) {\n    node.name = this.value;\n  } else if (this.type.keyword) {\n    node.name = this.type.keyword;\n\n    // To fix https://github.com/acornjs/acorn/issues/575\n    // `class` and `function` keywords push new context into this.context.\n    // But there is no chance to pop the context if the keyword is consumed as an identifier such as a property name.\n    // If the previous token is a dot, this does not apply because the context-managing code already ignored the keyword\n    if ((node.name === \"class\" || node.name === \"function\") &&\n        (this.lastTokEnd !== this.lastTokStart + 1 || this.input.charCodeAt(this.lastTokStart) !== 46)) {\n      this.context.pop();\n    }\n  } else {\n    this.unexpected();\n  }\n  this.next(!!liberal);\n  this.finishNode(node, \"Identifier\");\n  if (!liberal) {\n    this.checkUnreserved(node);\n    if (node.name === \"await\" && !this.awaitIdentPos)\n      { this.awaitIdentPos = node.start; }\n  }\n  return node\n};\n\npp$5.parsePrivateIdent = function() {\n  var node = this.startNode();\n  if (this.type === types$1.privateId) {\n    node.name = this.value;\n  } else {\n    this.unexpected();\n  }\n  this.next();\n  this.finishNode(node, \"PrivateIdentifier\");\n\n  // For validating existence\n  if (this.privateNameStack.length === 0) {\n    this.raise(node.start, (\"Private field '#\" + (node.name) + \"' must be declared in an enclosing class\"));\n  } else {\n    this.privateNameStack[this.privateNameStack.length - 1].used.push(node);\n  }\n\n  return node\n};\n\n// Parses yield expression inside generator.\n\npp$5.parseYield = function(forInit) {\n  if (!this.yieldPos) { this.yieldPos = this.start; }\n\n  var node = this.startNode();\n  this.next();\n  if (this.type === types$1.semi || this.canInsertSemicolon() || (this.type !== types$1.star && !this.type.startsExpr)) {\n    node.delegate = false;\n    node.argument = null;\n  } else {\n    node.delegate = this.eat(types$1.star);\n    node.argument = this.parseMaybeAssign(forInit);\n  }\n  return this.finishNode(node, \"YieldExpression\")\n};\n\npp$5.parseAwait = function(forInit) {\n  if (!this.awaitPos) { this.awaitPos = this.start; }\n\n  var node = this.startNode();\n  this.next();\n  node.argument = this.parseMaybeUnary(null, true, false, forInit);\n  return this.finishNode(node, \"AwaitExpression\")\n};\n\nvar pp$4 = Parser$1.prototype;\n\n// This function is used to raise exceptions on parse errors. It\n// takes an offset integer (into the current `input`) to indicate\n// the location of the error, attaches the position to the end\n// of the error message, and then raises a `SyntaxError` with that\n// message.\n\npp$4.raise = function(pos, message) {\n  var loc = getLineInfo(this.input, pos);\n  message += \" (\" + loc.line + \":\" + loc.column + \")\";\n  var err = new SyntaxError(message);\n  err.pos = pos; err.loc = loc; err.raisedAt = this.pos;\n  throw err\n};\n\npp$4.raiseRecoverable = pp$4.raise;\n\npp$4.curPosition = function() {\n  if (this.options.locations) {\n    return new Position(this.curLine, this.pos - this.lineStart)\n  }\n};\n\nvar pp$3 = Parser$1.prototype;\n\nvar Scope = function Scope(flags) {\n  this.flags = flags;\n  // A list of var-declared names in the current lexical scope\n  this.var = [];\n  // A list of lexically-declared names in the current lexical scope\n  this.lexical = [];\n  // A list of lexically-declared FunctionDeclaration names in the current lexical scope\n  this.functions = [];\n  // A switch to disallow the identifier reference 'arguments'\n  this.inClassFieldInit = false;\n};\n\n// The functions in this module keep track of declared variables in the current scope in order to detect duplicate variable names.\n\npp$3.enterScope = function(flags) {\n  this.scopeStack.push(new Scope(flags));\n};\n\npp$3.exitScope = function() {\n  this.scopeStack.pop();\n};\n\n// The spec says:\n// > At the top level of a function, or script, function declarations are\n// > treated like var declarations rather than like lexical declarations.\npp$3.treatFunctionsAsVarInScope = function(scope) {\n  return (scope.flags & SCOPE_FUNCTION) || !this.inModule && (scope.flags & SCOPE_TOP)\n};\n\npp$3.declareName = function(name, bindingType, pos) {\n  var redeclared = false;\n  if (bindingType === BIND_LEXICAL) {\n    var scope = this.currentScope();\n    redeclared = scope.lexical.indexOf(name) > -1 || scope.functions.indexOf(name) > -1 || scope.var.indexOf(name) > -1;\n    scope.lexical.push(name);\n    if (this.inModule && (scope.flags & SCOPE_TOP))\n      { delete this.undefinedExports[name]; }\n  } else if (bindingType === BIND_SIMPLE_CATCH) {\n    var scope$1 = this.currentScope();\n    scope$1.lexical.push(name);\n  } else if (bindingType === BIND_FUNCTION) {\n    var scope$2 = this.currentScope();\n    if (this.treatFunctionsAsVar)\n      { redeclared = scope$2.lexical.indexOf(name) > -1; }\n    else\n      { redeclared = scope$2.lexical.indexOf(name) > -1 || scope$2.var.indexOf(name) > -1; }\n    scope$2.functions.push(name);\n  } else {\n    for (var i = this.scopeStack.length - 1; i >= 0; --i) {\n      var scope$3 = this.scopeStack[i];\n      if (scope$3.lexical.indexOf(name) > -1 && !((scope$3.flags & SCOPE_SIMPLE_CATCH) && scope$3.lexical[0] === name) ||\n          !this.treatFunctionsAsVarInScope(scope$3) && scope$3.functions.indexOf(name) > -1) {\n        redeclared = true;\n        break\n      }\n      scope$3.var.push(name);\n      if (this.inModule && (scope$3.flags & SCOPE_TOP))\n        { delete this.undefinedExports[name]; }\n      if (scope$3.flags & SCOPE_VAR) { break }\n    }\n  }\n  if (redeclared) { this.raiseRecoverable(pos, (\"Identifier '\" + name + \"' has already been declared\")); }\n};\n\npp$3.checkLocalExport = function(id) {\n  // scope.functions must be empty as Module code is always strict.\n  if (this.scopeStack[0].lexical.indexOf(id.name) === -1 &&\n      this.scopeStack[0].var.indexOf(id.name) === -1) {\n    this.undefinedExports[id.name] = id;\n  }\n};\n\npp$3.currentScope = function() {\n  return this.scopeStack[this.scopeStack.length - 1]\n};\n\npp$3.currentVarScope = function() {\n  for (var i = this.scopeStack.length - 1;; i--) {\n    var scope = this.scopeStack[i];\n    if (scope.flags & SCOPE_VAR) { return scope }\n  }\n};\n\n// Could be useful for `this`, `new.target`, `super()`, `super.property`, and `super[property]`.\npp$3.currentThisScope = function() {\n  for (var i = this.scopeStack.length - 1;; i--) {\n    var scope = this.scopeStack[i];\n    if (scope.flags & SCOPE_VAR && !(scope.flags & SCOPE_ARROW)) { return scope }\n  }\n};\n\nvar Node = function Node(parser, pos, loc) {\n  this.type = \"\";\n  this.start = pos;\n  this.end = 0;\n  if (parser.options.locations)\n    { this.loc = new SourceLocation(parser, loc); }\n  if (parser.options.directSourceFile)\n    { this.sourceFile = parser.options.directSourceFile; }\n  if (parser.options.ranges)\n    { this.range = [pos, 0]; }\n};\n\n// Start an AST node, attaching a start offset.\n\nvar pp$2 = Parser$1.prototype;\n\npp$2.startNode = function() {\n  return new Node(this, this.start, this.startLoc)\n};\n\npp$2.startNodeAt = function(pos, loc) {\n  return new Node(this, pos, loc)\n};\n\n// Finish an AST node, adding `type` and `end` properties.\n\nfunction finishNodeAt(node, type, pos, loc) {\n  node.type = type;\n  node.end = pos;\n  if (this.options.locations)\n    { node.loc.end = loc; }\n  if (this.options.ranges)\n    { node.range[1] = pos; }\n  return node\n}\n\npp$2.finishNode = function(node, type) {\n  return finishNodeAt.call(this, node, type, this.lastTokEnd, this.lastTokEndLoc)\n};\n\n// Finish node at given position\n\npp$2.finishNodeAt = function(node, type, pos, loc) {\n  return finishNodeAt.call(this, node, type, pos, loc)\n};\n\npp$2.copyNode = function(node) {\n  var newNode = new Node(this, node.start, this.startLoc);\n  for (var prop in node) { newNode[prop] = node[prop]; }\n  return newNode\n};\n\n// This file contains Unicode properties extracted from the ECMAScript specification.\n// The lists are extracted like so:\n// $$('#table-binary-unicode-properties > figure > table > tbody > tr > td:nth-child(1) code').map(el => el.innerText)\n\n// #table-binary-unicode-properties\nvar ecma9BinaryProperties = \"ASCII ASCII_Hex_Digit AHex Alphabetic Alpha Any Assigned Bidi_Control Bidi_C Bidi_Mirrored Bidi_M Case_Ignorable CI Cased Changes_When_Casefolded CWCF Changes_When_Casemapped CWCM Changes_When_Lowercased CWL Changes_When_NFKC_Casefolded CWKCF Changes_When_Titlecased CWT Changes_When_Uppercased CWU Dash Default_Ignorable_Code_Point DI Deprecated Dep Diacritic Dia Emoji Emoji_Component Emoji_Modifier Emoji_Modifier_Base Emoji_Presentation Extender Ext Grapheme_Base Gr_Base Grapheme_Extend Gr_Ext Hex_Digit Hex IDS_Binary_Operator IDSB IDS_Trinary_Operator IDST ID_Continue IDC ID_Start IDS Ideographic Ideo Join_Control Join_C Logical_Order_Exception LOE Lowercase Lower Math Noncharacter_Code_Point NChar Pattern_Syntax Pat_Syn Pattern_White_Space Pat_WS Quotation_Mark QMark Radical Regional_Indicator RI Sentence_Terminal STerm Soft_Dotted SD Terminal_Punctuation Term Unified_Ideograph UIdeo Uppercase Upper Variation_Selector VS White_Space space XID_Continue XIDC XID_Start XIDS\";\nvar ecma10BinaryProperties = ecma9BinaryProperties + \" Extended_Pictographic\";\nvar ecma11BinaryProperties = ecma10BinaryProperties;\nvar ecma12BinaryProperties = ecma11BinaryProperties + \" EBase EComp EMod EPres ExtPict\";\nvar ecma13BinaryProperties = ecma12BinaryProperties;\nvar ecma14BinaryProperties = ecma13BinaryProperties;\n\nvar unicodeBinaryProperties = {\n  9: ecma9BinaryProperties,\n  10: ecma10BinaryProperties,\n  11: ecma11BinaryProperties,\n  12: ecma12BinaryProperties,\n  13: ecma13BinaryProperties,\n  14: ecma14BinaryProperties\n};\n\n// #table-unicode-general-category-values\nvar unicodeGeneralCategoryValues = \"Cased_Letter LC Close_Punctuation Pe Connector_Punctuation Pc Control Cc cntrl Currency_Symbol Sc Dash_Punctuation Pd Decimal_Number Nd digit Enclosing_Mark Me Final_Punctuation Pf Format Cf Initial_Punctuation Pi Letter L Letter_Number Nl Line_Separator Zl Lowercase_Letter Ll Mark M Combining_Mark Math_Symbol Sm Modifier_Letter Lm Modifier_Symbol Sk Nonspacing_Mark Mn Number N Open_Punctuation Ps Other C Other_Letter Lo Other_Number No Other_Punctuation Po Other_Symbol So Paragraph_Separator Zp Private_Use Co Punctuation P punct Separator Z Space_Separator Zs Spacing_Mark Mc Surrogate Cs Symbol S Titlecase_Letter Lt Unassigned Cn Uppercase_Letter Lu\";\n\n// #table-unicode-script-values\nvar ecma9ScriptValues = \"Adlam Adlm Ahom Anatolian_Hieroglyphs Hluw Arabic Arab Armenian Armn Avestan Avst Balinese Bali Bamum Bamu Bassa_Vah Bass Batak Batk Bengali Beng Bhaiksuki Bhks Bopomofo Bopo Brahmi Brah Braille Brai Buginese Bugi Buhid Buhd Canadian_Aboriginal Cans Carian Cari Caucasian_Albanian Aghb Chakma Cakm Cham Cham Cherokee Cher Common Zyyy Coptic Copt Qaac Cuneiform Xsux Cypriot Cprt Cyrillic Cyrl Deseret Dsrt Devanagari Deva Duployan Dupl Egyptian_Hieroglyphs Egyp Elbasan Elba Ethiopic Ethi Georgian Geor Glagolitic Glag Gothic Goth Grantha Gran Greek Grek Gujarati Gujr Gurmukhi Guru Han Hani Hangul Hang Hanunoo Hano Hatran Hatr Hebrew Hebr Hiragana Hira Imperial_Aramaic Armi Inherited Zinh Qaai Inscriptional_Pahlavi Phli Inscriptional_Parthian Prti Javanese Java Kaithi Kthi Kannada Knda Katakana Kana Kayah_Li Kali Kharoshthi Khar Khmer Khmr Khojki Khoj Khudawadi Sind Lao Laoo Latin Latn Lepcha Lepc Limbu Limb Linear_A Lina Linear_B Linb Lisu Lisu Lycian Lyci Lydian Lydi Mahajani Mahj Malayalam Mlym Mandaic Mand Manichaean Mani Marchen Marc Masaram_Gondi Gonm Meetei_Mayek Mtei Mende_Kikakui Mend Meroitic_Cursive Merc Meroitic_Hieroglyphs Mero Miao Plrd Modi Mongolian Mong Mro Mroo Multani Mult Myanmar Mymr Nabataean Nbat New_Tai_Lue Talu Newa Newa Nko Nkoo Nushu Nshu Ogham Ogam Ol_Chiki Olck Old_Hungarian Hung Old_Italic Ital Old_North_Arabian Narb Old_Permic Perm Old_Persian Xpeo Old_South_Arabian Sarb Old_Turkic Orkh Oriya Orya Osage Osge Osmanya Osma Pahawh_Hmong Hmng Palmyrene Palm Pau_Cin_Hau Pauc Phags_Pa Phag Phoenician Phnx Psalter_Pahlavi Phlp Rejang Rjng Runic Runr Samaritan Samr Saurashtra Saur Sharada Shrd Shavian Shaw Siddham Sidd SignWriting Sgnw Sinhala Sinh Sora_Sompeng Sora Soyombo Soyo Sundanese Sund Syloti_Nagri Sylo Syriac Syrc Tagalog Tglg Tagbanwa Tagb Tai_Le Tale Tai_Tham Lana Tai_Viet Tavt Takri Takr Tamil Taml Tangut Tang Telugu Telu Thaana Thaa Thai Thai Tibetan Tibt Tifinagh Tfng Tirhuta Tirh Ugaritic Ugar Vai Vaii Warang_Citi Wara Yi Yiii Zanabazar_Square Zanb\";\nvar ecma10ScriptValues = ecma9ScriptValues + \" Dogra Dogr Gunjala_Gondi Gong Hanifi_Rohingya Rohg Makasar Maka Medefaidrin Medf Old_Sogdian Sogo Sogdian Sogd\";\nvar ecma11ScriptValues = ecma10ScriptValues + \" Elymaic Elym Nandinagari Nand Nyiakeng_Puachue_Hmong Hmnp Wancho Wcho\";\nvar ecma12ScriptValues = ecma11ScriptValues + \" Chorasmian Chrs Diak Dives_Akuru Khitan_Small_Script Kits Yezi Yezidi\";\nvar ecma13ScriptValues = ecma12ScriptValues + \" Cypro_Minoan Cpmn Old_Uyghur Ougr Tangsa Tnsa Toto Vithkuqi Vith\";\nvar ecma14ScriptValues = ecma13ScriptValues + \" Kawi Nag_Mundari Nagm\";\n\nvar unicodeScriptValues = {\n  9: ecma9ScriptValues,\n  10: ecma10ScriptValues,\n  11: ecma11ScriptValues,\n  12: ecma12ScriptValues,\n  13: ecma13ScriptValues,\n  14: ecma14ScriptValues\n};\n\nvar data = {};\nfunction buildUnicodeData(ecmaVersion) {\n  var d = data[ecmaVersion] = {\n    binary: wordsRegexp(unicodeBinaryProperties[ecmaVersion] + \" \" + unicodeGeneralCategoryValues),\n    nonBinary: {\n      General_Category: wordsRegexp(unicodeGeneralCategoryValues),\n      Script: wordsRegexp(unicodeScriptValues[ecmaVersion])\n    }\n  };\n  d.nonBinary.Script_Extensions = d.nonBinary.Script;\n\n  d.nonBinary.gc = d.nonBinary.General_Category;\n  d.nonBinary.sc = d.nonBinary.Script;\n  d.nonBinary.scx = d.nonBinary.Script_Extensions;\n}\n\nfor (var i$1 = 0, list = [9, 10, 11, 12, 13, 14]; i$1 < list.length; i$1 += 1) {\n  var ecmaVersion = list[i$1];\n\n  buildUnicodeData(ecmaVersion);\n}\n\nvar pp$1 = Parser$1.prototype;\n\nvar RegExpValidationState = function RegExpValidationState(parser) {\n  this.parser = parser;\n  this.validFlags = \"gim\" + (parser.options.ecmaVersion >= 6 ? \"uy\" : \"\") + (parser.options.ecmaVersion >= 9 ? \"s\" : \"\") + (parser.options.ecmaVersion >= 13 ? \"d\" : \"\");\n  this.unicodeProperties = data[parser.options.ecmaVersion >= 14 ? 14 : parser.options.ecmaVersion];\n  this.source = \"\";\n  this.flags = \"\";\n  this.start = 0;\n  this.switchU = false;\n  this.switchN = false;\n  this.pos = 0;\n  this.lastIntValue = 0;\n  this.lastStringValue = \"\";\n  this.lastAssertionIsQuantifiable = false;\n  this.numCapturingParens = 0;\n  this.maxBackReference = 0;\n  this.groupNames = [];\n  this.backReferenceNames = [];\n};\n\nRegExpValidationState.prototype.reset = function reset (start, pattern, flags) {\n  var unicode = flags.indexOf(\"u\") !== -1;\n  this.start = start | 0;\n  this.source = pattern + \"\";\n  this.flags = flags;\n  this.switchU = unicode && this.parser.options.ecmaVersion >= 6;\n  this.switchN = unicode && this.parser.options.ecmaVersion >= 9;\n};\n\nRegExpValidationState.prototype.raise = function raise (message) {\n  this.parser.raiseRecoverable(this.start, (\"Invalid regular expression: /\" + (this.source) + \"/: \" + message));\n};\n\n// If u flag is given, this returns the code point at the index (it combines a surrogate pair).\n// Otherwise, this returns the code unit of the index (can be a part of a surrogate pair).\nRegExpValidationState.prototype.at = function at (i, forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n  var s = this.source;\n  var l = s.length;\n  if (i >= l) {\n    return -1\n  }\n  var c = s.charCodeAt(i);\n  if (!(forceU || this.switchU) || c <= 0xD7FF || c >= 0xE000 || i + 1 >= l) {\n    return c\n  }\n  var next = s.charCodeAt(i + 1);\n  return next >= 0xDC00 && next <= 0xDFFF ? (c << 10) + next - 0x35FDC00 : c\n};\n\nRegExpValidationState.prototype.nextIndex = function nextIndex (i, forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n  var s = this.source;\n  var l = s.length;\n  if (i >= l) {\n    return l\n  }\n  var c = s.charCodeAt(i), next;\n  if (!(forceU || this.switchU) || c <= 0xD7FF || c >= 0xE000 || i + 1 >= l ||\n      (next = s.charCodeAt(i + 1)) < 0xDC00 || next > 0xDFFF) {\n    return i + 1\n  }\n  return i + 2\n};\n\nRegExpValidationState.prototype.current = function current (forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n  return this.at(this.pos, forceU)\n};\n\nRegExpValidationState.prototype.lookahead = function lookahead (forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n  return this.at(this.nextIndex(this.pos, forceU), forceU)\n};\n\nRegExpValidationState.prototype.advance = function advance (forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n  this.pos = this.nextIndex(this.pos, forceU);\n};\n\nRegExpValidationState.prototype.eat = function eat (ch, forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n  if (this.current(forceU) === ch) {\n    this.advance(forceU);\n    return true\n  }\n  return false\n};\n\n/**\n * Validate the flags part of a given RegExpLiteral.\n *\n * @param {RegExpValidationState} state The state to validate RegExp.\n * @returns {void}\n */\npp$1.validateRegExpFlags = function(state) {\n  var validFlags = state.validFlags;\n  var flags = state.flags;\n\n  for (var i = 0; i < flags.length; i++) {\n    var flag = flags.charAt(i);\n    if (validFlags.indexOf(flag) === -1) {\n      this.raise(state.start, \"Invalid regular expression flag\");\n    }\n    if (flags.indexOf(flag, i + 1) > -1) {\n      this.raise(state.start, \"Duplicate regular expression flag\");\n    }\n  }\n};\n\n/**\n * Validate the pattern part of a given RegExpLiteral.\n *\n * @param {RegExpValidationState} state The state to validate RegExp.\n * @returns {void}\n */\npp$1.validateRegExpPattern = function(state) {\n  this.regexp_pattern(state);\n\n  // The goal symbol for the parse is |Pattern[~U, ~N]|. If the result of\n  // parsing contains a |GroupName|, reparse with the goal symbol\n  // |Pattern[~U, +N]| and use this result instead. Throw a *SyntaxError*\n  // exception if _P_ did not conform to the grammar, if any elements of _P_\n  // were not matched by the parse, or if any Early Error conditions exist.\n  if (!state.switchN && this.options.ecmaVersion >= 9 && state.groupNames.length > 0) {\n    state.switchN = true;\n    this.regexp_pattern(state);\n  }\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-Pattern\npp$1.regexp_pattern = function(state) {\n  state.pos = 0;\n  state.lastIntValue = 0;\n  state.lastStringValue = \"\";\n  state.lastAssertionIsQuantifiable = false;\n  state.numCapturingParens = 0;\n  state.maxBackReference = 0;\n  state.groupNames.length = 0;\n  state.backReferenceNames.length = 0;\n\n  this.regexp_disjunction(state);\n\n  if (state.pos !== state.source.length) {\n    // Make the same messages as V8.\n    if (state.eat(0x29 /* ) */)) {\n      state.raise(\"Unmatched ')'\");\n    }\n    if (state.eat(0x5D /* ] */) || state.eat(0x7D /* } */)) {\n      state.raise(\"Lone quantifier brackets\");\n    }\n  }\n  if (state.maxBackReference > state.numCapturingParens) {\n    state.raise(\"Invalid escape\");\n  }\n  for (var i = 0, list = state.backReferenceNames; i < list.length; i += 1) {\n    var name = list[i];\n\n    if (state.groupNames.indexOf(name) === -1) {\n      state.raise(\"Invalid named capture referenced\");\n    }\n  }\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-Disjunction\npp$1.regexp_disjunction = function(state) {\n  this.regexp_alternative(state);\n  while (state.eat(0x7C /* | */)) {\n    this.regexp_alternative(state);\n  }\n\n  // Make the same message as V8.\n  if (this.regexp_eatQuantifier(state, true)) {\n    state.raise(\"Nothing to repeat\");\n  }\n  if (state.eat(0x7B /* { */)) {\n    state.raise(\"Lone quantifier brackets\");\n  }\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-Alternative\npp$1.regexp_alternative = function(state) {\n  while (state.pos < state.source.length && this.regexp_eatTerm(state))\n    { }\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-Term\npp$1.regexp_eatTerm = function(state) {\n  if (this.regexp_eatAssertion(state)) {\n    // Handle `QuantifiableAssertion Quantifier` alternative.\n    // `state.lastAssertionIsQuantifiable` is true if the last eaten Assertion\n    // is a QuantifiableAssertion.\n    if (state.lastAssertionIsQuantifiable && this.regexp_eatQuantifier(state)) {\n      // Make the same message as V8.\n      if (state.switchU) {\n        state.raise(\"Invalid quantifier\");\n      }\n    }\n    return true\n  }\n\n  if (state.switchU ? this.regexp_eatAtom(state) : this.regexp_eatExtendedAtom(state)) {\n    this.regexp_eatQuantifier(state);\n    return true\n  }\n\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-Assertion\npp$1.regexp_eatAssertion = function(state) {\n  var start = state.pos;\n  state.lastAssertionIsQuantifiable = false;\n\n  // ^, $\n  if (state.eat(0x5E /* ^ */) || state.eat(0x24 /* $ */)) {\n    return true\n  }\n\n  // \\b \\B\n  if (state.eat(0x5C /* \\ */)) {\n    if (state.eat(0x42 /* B */) || state.eat(0x62 /* b */)) {\n      return true\n    }\n    state.pos = start;\n  }\n\n  // Lookahead / Lookbehind\n  if (state.eat(0x28 /* ( */) && state.eat(0x3F /* ? */)) {\n    var lookbehind = false;\n    if (this.options.ecmaVersion >= 9) {\n      lookbehind = state.eat(0x3C /* < */);\n    }\n    if (state.eat(0x3D /* = */) || state.eat(0x21 /* ! */)) {\n      this.regexp_disjunction(state);\n      if (!state.eat(0x29 /* ) */)) {\n        state.raise(\"Unterminated group\");\n      }\n      state.lastAssertionIsQuantifiable = !lookbehind;\n      return true\n    }\n  }\n\n  state.pos = start;\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-Quantifier\npp$1.regexp_eatQuantifier = function(state, noError) {\n  if ( noError === void 0 ) noError = false;\n\n  if (this.regexp_eatQuantifierPrefix(state, noError)) {\n    state.eat(0x3F /* ? */);\n    return true\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-QuantifierPrefix\npp$1.regexp_eatQuantifierPrefix = function(state, noError) {\n  return (\n    state.eat(0x2A /* * */) ||\n    state.eat(0x2B /* + */) ||\n    state.eat(0x3F /* ? */) ||\n    this.regexp_eatBracedQuantifier(state, noError)\n  )\n};\npp$1.regexp_eatBracedQuantifier = function(state, noError) {\n  var start = state.pos;\n  if (state.eat(0x7B /* { */)) {\n    var min = 0, max = -1;\n    if (this.regexp_eatDecimalDigits(state)) {\n      min = state.lastIntValue;\n      if (state.eat(0x2C /* , */) && this.regexp_eatDecimalDigits(state)) {\n        max = state.lastIntValue;\n      }\n      if (state.eat(0x7D /* } */)) {\n        // SyntaxError in https://www.ecma-international.org/ecma-262/8.0/#sec-term\n        if (max !== -1 && max < min && !noError) {\n          state.raise(\"numbers out of order in {} quantifier\");\n        }\n        return true\n      }\n    }\n    if (state.switchU && !noError) {\n      state.raise(\"Incomplete quantifier\");\n    }\n    state.pos = start;\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-Atom\npp$1.regexp_eatAtom = function(state) {\n  return (\n    this.regexp_eatPatternCharacters(state) ||\n    state.eat(0x2E /* . */) ||\n    this.regexp_eatReverseSolidusAtomEscape(state) ||\n    this.regexp_eatCharacterClass(state) ||\n    this.regexp_eatUncapturingGroup(state) ||\n    this.regexp_eatCapturingGroup(state)\n  )\n};\npp$1.regexp_eatReverseSolidusAtomEscape = function(state) {\n  var start = state.pos;\n  if (state.eat(0x5C /* \\ */)) {\n    if (this.regexp_eatAtomEscape(state)) {\n      return true\n    }\n    state.pos = start;\n  }\n  return false\n};\npp$1.regexp_eatUncapturingGroup = function(state) {\n  var start = state.pos;\n  if (state.eat(0x28 /* ( */)) {\n    if (state.eat(0x3F /* ? */) && state.eat(0x3A /* : */)) {\n      this.regexp_disjunction(state);\n      if (state.eat(0x29 /* ) */)) {\n        return true\n      }\n      state.raise(\"Unterminated group\");\n    }\n    state.pos = start;\n  }\n  return false\n};\npp$1.regexp_eatCapturingGroup = function(state) {\n  if (state.eat(0x28 /* ( */)) {\n    if (this.options.ecmaVersion >= 9) {\n      this.regexp_groupSpecifier(state);\n    } else if (state.current() === 0x3F /* ? */) {\n      state.raise(\"Invalid group\");\n    }\n    this.regexp_disjunction(state);\n    if (state.eat(0x29 /* ) */)) {\n      state.numCapturingParens += 1;\n      return true\n    }\n    state.raise(\"Unterminated group\");\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ExtendedAtom\npp$1.regexp_eatExtendedAtom = function(state) {\n  return (\n    state.eat(0x2E /* . */) ||\n    this.regexp_eatReverseSolidusAtomEscape(state) ||\n    this.regexp_eatCharacterClass(state) ||\n    this.regexp_eatUncapturingGroup(state) ||\n    this.regexp_eatCapturingGroup(state) ||\n    this.regexp_eatInvalidBracedQuantifier(state) ||\n    this.regexp_eatExtendedPatternCharacter(state)\n  )\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-InvalidBracedQuantifier\npp$1.regexp_eatInvalidBracedQuantifier = function(state) {\n  if (this.regexp_eatBracedQuantifier(state, true)) {\n    state.raise(\"Nothing to repeat\");\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-SyntaxCharacter\npp$1.regexp_eatSyntaxCharacter = function(state) {\n  var ch = state.current();\n  if (isSyntaxCharacter(ch)) {\n    state.lastIntValue = ch;\n    state.advance();\n    return true\n  }\n  return false\n};\nfunction isSyntaxCharacter(ch) {\n  return (\n    ch === 0x24 /* $ */ ||\n    ch >= 0x28 /* ( */ && ch <= 0x2B /* + */ ||\n    ch === 0x2E /* . */ ||\n    ch === 0x3F /* ? */ ||\n    ch >= 0x5B /* [ */ && ch <= 0x5E /* ^ */ ||\n    ch >= 0x7B /* { */ && ch <= 0x7D /* } */\n  )\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-PatternCharacter\n// But eat eager.\npp$1.regexp_eatPatternCharacters = function(state) {\n  var start = state.pos;\n  var ch = 0;\n  while ((ch = state.current()) !== -1 && !isSyntaxCharacter(ch)) {\n    state.advance();\n  }\n  return state.pos !== start\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ExtendedPatternCharacter\npp$1.regexp_eatExtendedPatternCharacter = function(state) {\n  var ch = state.current();\n  if (\n    ch !== -1 &&\n    ch !== 0x24 /* $ */ &&\n    !(ch >= 0x28 /* ( */ && ch <= 0x2B /* + */) &&\n    ch !== 0x2E /* . */ &&\n    ch !== 0x3F /* ? */ &&\n    ch !== 0x5B /* [ */ &&\n    ch !== 0x5E /* ^ */ &&\n    ch !== 0x7C /* | */\n  ) {\n    state.advance();\n    return true\n  }\n  return false\n};\n\n// GroupSpecifier ::\n//   [empty]\n//   `?` GroupName\npp$1.regexp_groupSpecifier = function(state) {\n  if (state.eat(0x3F /* ? */)) {\n    if (this.regexp_eatGroupName(state)) {\n      if (state.groupNames.indexOf(state.lastStringValue) !== -1) {\n        state.raise(\"Duplicate capture group name\");\n      }\n      state.groupNames.push(state.lastStringValue);\n      return\n    }\n    state.raise(\"Invalid group\");\n  }\n};\n\n// GroupName ::\n//   `<` RegExpIdentifierName `>`\n// Note: this updates `state.lastStringValue` property with the eaten name.\npp$1.regexp_eatGroupName = function(state) {\n  state.lastStringValue = \"\";\n  if (state.eat(0x3C /* < */)) {\n    if (this.regexp_eatRegExpIdentifierName(state) && state.eat(0x3E /* > */)) {\n      return true\n    }\n    state.raise(\"Invalid capture group name\");\n  }\n  return false\n};\n\n// RegExpIdentifierName ::\n//   RegExpIdentifierStart\n//   RegExpIdentifierName RegExpIdentifierPart\n// Note: this updates `state.lastStringValue` property with the eaten name.\npp$1.regexp_eatRegExpIdentifierName = function(state) {\n  state.lastStringValue = \"\";\n  if (this.regexp_eatRegExpIdentifierStart(state)) {\n    state.lastStringValue += codePointToString(state.lastIntValue);\n    while (this.regexp_eatRegExpIdentifierPart(state)) {\n      state.lastStringValue += codePointToString(state.lastIntValue);\n    }\n    return true\n  }\n  return false\n};\n\n// RegExpIdentifierStart ::\n//   UnicodeIDStart\n//   `$`\n//   `_`\n//   `\\` RegExpUnicodeEscapeSequence[+U]\npp$1.regexp_eatRegExpIdentifierStart = function(state) {\n  var start = state.pos;\n  var forceU = this.options.ecmaVersion >= 11;\n  var ch = state.current(forceU);\n  state.advance(forceU);\n\n  if (ch === 0x5C /* \\ */ && this.regexp_eatRegExpUnicodeEscapeSequence(state, forceU)) {\n    ch = state.lastIntValue;\n  }\n  if (isRegExpIdentifierStart(ch)) {\n    state.lastIntValue = ch;\n    return true\n  }\n\n  state.pos = start;\n  return false\n};\nfunction isRegExpIdentifierStart(ch) {\n  return isIdentifierStart(ch, true) || ch === 0x24 /* $ */ || ch === 0x5F /* _ */\n}\n\n// RegExpIdentifierPart ::\n//   UnicodeIDContinue\n//   `$`\n//   `_`\n//   `\\` RegExpUnicodeEscapeSequence[+U]\n//   <ZWNJ>\n//   <ZWJ>\npp$1.regexp_eatRegExpIdentifierPart = function(state) {\n  var start = state.pos;\n  var forceU = this.options.ecmaVersion >= 11;\n  var ch = state.current(forceU);\n  state.advance(forceU);\n\n  if (ch === 0x5C /* \\ */ && this.regexp_eatRegExpUnicodeEscapeSequence(state, forceU)) {\n    ch = state.lastIntValue;\n  }\n  if (isRegExpIdentifierPart(ch)) {\n    state.lastIntValue = ch;\n    return true\n  }\n\n  state.pos = start;\n  return false\n};\nfunction isRegExpIdentifierPart(ch) {\n  return isIdentifierChar(ch, true) || ch === 0x24 /* $ */ || ch === 0x5F /* _ */ || ch === 0x200C /* <ZWNJ> */ || ch === 0x200D /* <ZWJ> */\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-AtomEscape\npp$1.regexp_eatAtomEscape = function(state) {\n  if (\n    this.regexp_eatBackReference(state) ||\n    this.regexp_eatCharacterClassEscape(state) ||\n    this.regexp_eatCharacterEscape(state) ||\n    (state.switchN && this.regexp_eatKGroupName(state))\n  ) {\n    return true\n  }\n  if (state.switchU) {\n    // Make the same message as V8.\n    if (state.current() === 0x63 /* c */) {\n      state.raise(\"Invalid unicode escape\");\n    }\n    state.raise(\"Invalid escape\");\n  }\n  return false\n};\npp$1.regexp_eatBackReference = function(state) {\n  var start = state.pos;\n  if (this.regexp_eatDecimalEscape(state)) {\n    var n = state.lastIntValue;\n    if (state.switchU) {\n      // For SyntaxError in https://www.ecma-international.org/ecma-262/8.0/#sec-atomescape\n      if (n > state.maxBackReference) {\n        state.maxBackReference = n;\n      }\n      return true\n    }\n    if (n <= state.numCapturingParens) {\n      return true\n    }\n    state.pos = start;\n  }\n  return false\n};\npp$1.regexp_eatKGroupName = function(state) {\n  if (state.eat(0x6B /* k */)) {\n    if (this.regexp_eatGroupName(state)) {\n      state.backReferenceNames.push(state.lastStringValue);\n      return true\n    }\n    state.raise(\"Invalid named reference\");\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-CharacterEscape\npp$1.regexp_eatCharacterEscape = function(state) {\n  return (\n    this.regexp_eatControlEscape(state) ||\n    this.regexp_eatCControlLetter(state) ||\n    this.regexp_eatZero(state) ||\n    this.regexp_eatHexEscapeSequence(state) ||\n    this.regexp_eatRegExpUnicodeEscapeSequence(state, false) ||\n    (!state.switchU && this.regexp_eatLegacyOctalEscapeSequence(state)) ||\n    this.regexp_eatIdentityEscape(state)\n  )\n};\npp$1.regexp_eatCControlLetter = function(state) {\n  var start = state.pos;\n  if (state.eat(0x63 /* c */)) {\n    if (this.regexp_eatControlLetter(state)) {\n      return true\n    }\n    state.pos = start;\n  }\n  return false\n};\npp$1.regexp_eatZero = function(state) {\n  if (state.current() === 0x30 /* 0 */ && !isDecimalDigit(state.lookahead())) {\n    state.lastIntValue = 0;\n    state.advance();\n    return true\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-ControlEscape\npp$1.regexp_eatControlEscape = function(state) {\n  var ch = state.current();\n  if (ch === 0x74 /* t */) {\n    state.lastIntValue = 0x09; /* \\t */\n    state.advance();\n    return true\n  }\n  if (ch === 0x6E /* n */) {\n    state.lastIntValue = 0x0A; /* \\n */\n    state.advance();\n    return true\n  }\n  if (ch === 0x76 /* v */) {\n    state.lastIntValue = 0x0B; /* \\v */\n    state.advance();\n    return true\n  }\n  if (ch === 0x66 /* f */) {\n    state.lastIntValue = 0x0C; /* \\f */\n    state.advance();\n    return true\n  }\n  if (ch === 0x72 /* r */) {\n    state.lastIntValue = 0x0D; /* \\r */\n    state.advance();\n    return true\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-ControlLetter\npp$1.regexp_eatControlLetter = function(state) {\n  var ch = state.current();\n  if (isControlLetter(ch)) {\n    state.lastIntValue = ch % 0x20;\n    state.advance();\n    return true\n  }\n  return false\n};\nfunction isControlLetter(ch) {\n  return (\n    (ch >= 0x41 /* A */ && ch <= 0x5A /* Z */) ||\n    (ch >= 0x61 /* a */ && ch <= 0x7A /* z */)\n  )\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-RegExpUnicodeEscapeSequence\npp$1.regexp_eatRegExpUnicodeEscapeSequence = function(state, forceU) {\n  if ( forceU === void 0 ) forceU = false;\n\n  var start = state.pos;\n  var switchU = forceU || state.switchU;\n\n  if (state.eat(0x75 /* u */)) {\n    if (this.regexp_eatFixedHexDigits(state, 4)) {\n      var lead = state.lastIntValue;\n      if (switchU && lead >= 0xD800 && lead <= 0xDBFF) {\n        var leadSurrogateEnd = state.pos;\n        if (state.eat(0x5C /* \\ */) && state.eat(0x75 /* u */) && this.regexp_eatFixedHexDigits(state, 4)) {\n          var trail = state.lastIntValue;\n          if (trail >= 0xDC00 && trail <= 0xDFFF) {\n            state.lastIntValue = (lead - 0xD800) * 0x400 + (trail - 0xDC00) + 0x10000;\n            return true\n          }\n        }\n        state.pos = leadSurrogateEnd;\n        state.lastIntValue = lead;\n      }\n      return true\n    }\n    if (\n      switchU &&\n      state.eat(0x7B /* { */) &&\n      this.regexp_eatHexDigits(state) &&\n      state.eat(0x7D /* } */) &&\n      isValidUnicode(state.lastIntValue)\n    ) {\n      return true\n    }\n    if (switchU) {\n      state.raise(\"Invalid unicode escape\");\n    }\n    state.pos = start;\n  }\n\n  return false\n};\nfunction isValidUnicode(ch) {\n  return ch >= 0 && ch <= 0x10FFFF\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-IdentityEscape\npp$1.regexp_eatIdentityEscape = function(state) {\n  if (state.switchU) {\n    if (this.regexp_eatSyntaxCharacter(state)) {\n      return true\n    }\n    if (state.eat(0x2F /* / */)) {\n      state.lastIntValue = 0x2F; /* / */\n      return true\n    }\n    return false\n  }\n\n  var ch = state.current();\n  if (ch !== 0x63 /* c */ && (!state.switchN || ch !== 0x6B /* k */)) {\n    state.lastIntValue = ch;\n    state.advance();\n    return true\n  }\n\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-DecimalEscape\npp$1.regexp_eatDecimalEscape = function(state) {\n  state.lastIntValue = 0;\n  var ch = state.current();\n  if (ch >= 0x31 /* 1 */ && ch <= 0x39 /* 9 */) {\n    do {\n      state.lastIntValue = 10 * state.lastIntValue + (ch - 0x30 /* 0 */);\n      state.advance();\n    } while ((ch = state.current()) >= 0x30 /* 0 */ && ch <= 0x39 /* 9 */)\n    return true\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-CharacterClassEscape\npp$1.regexp_eatCharacterClassEscape = function(state) {\n  var ch = state.current();\n\n  if (isCharacterClassEscape(ch)) {\n    state.lastIntValue = -1;\n    state.advance();\n    return true\n  }\n\n  if (\n    state.switchU &&\n    this.options.ecmaVersion >= 9 &&\n    (ch === 0x50 /* P */ || ch === 0x70 /* p */)\n  ) {\n    state.lastIntValue = -1;\n    state.advance();\n    if (\n      state.eat(0x7B /* { */) &&\n      this.regexp_eatUnicodePropertyValueExpression(state) &&\n      state.eat(0x7D /* } */)\n    ) {\n      return true\n    }\n    state.raise(\"Invalid property name\");\n  }\n\n  return false\n};\nfunction isCharacterClassEscape(ch) {\n  return (\n    ch === 0x64 /* d */ ||\n    ch === 0x44 /* D */ ||\n    ch === 0x73 /* s */ ||\n    ch === 0x53 /* S */ ||\n    ch === 0x77 /* w */ ||\n    ch === 0x57 /* W */\n  )\n}\n\n// UnicodePropertyValueExpression ::\n//   UnicodePropertyName `=` UnicodePropertyValue\n//   LoneUnicodePropertyNameOrValue\npp$1.regexp_eatUnicodePropertyValueExpression = function(state) {\n  var start = state.pos;\n\n  // UnicodePropertyName `=` UnicodePropertyValue\n  if (this.regexp_eatUnicodePropertyName(state) && state.eat(0x3D /* = */)) {\n    var name = state.lastStringValue;\n    if (this.regexp_eatUnicodePropertyValue(state)) {\n      var value = state.lastStringValue;\n      this.regexp_validateUnicodePropertyNameAndValue(state, name, value);\n      return true\n    }\n  }\n  state.pos = start;\n\n  // LoneUnicodePropertyNameOrValue\n  if (this.regexp_eatLoneUnicodePropertyNameOrValue(state)) {\n    var nameOrValue = state.lastStringValue;\n    this.regexp_validateUnicodePropertyNameOrValue(state, nameOrValue);\n    return true\n  }\n  return false\n};\npp$1.regexp_validateUnicodePropertyNameAndValue = function(state, name, value) {\n  if (!hasOwn(state.unicodeProperties.nonBinary, name))\n    { state.raise(\"Invalid property name\"); }\n  if (!state.unicodeProperties.nonBinary[name].test(value))\n    { state.raise(\"Invalid property value\"); }\n};\npp$1.regexp_validateUnicodePropertyNameOrValue = function(state, nameOrValue) {\n  if (!state.unicodeProperties.binary.test(nameOrValue))\n    { state.raise(\"Invalid property name\"); }\n};\n\n// UnicodePropertyName ::\n//   UnicodePropertyNameCharacters\npp$1.regexp_eatUnicodePropertyName = function(state) {\n  var ch = 0;\n  state.lastStringValue = \"\";\n  while (isUnicodePropertyNameCharacter(ch = state.current())) {\n    state.lastStringValue += codePointToString(ch);\n    state.advance();\n  }\n  return state.lastStringValue !== \"\"\n};\nfunction isUnicodePropertyNameCharacter(ch) {\n  return isControlLetter(ch) || ch === 0x5F /* _ */\n}\n\n// UnicodePropertyValue ::\n//   UnicodePropertyValueCharacters\npp$1.regexp_eatUnicodePropertyValue = function(state) {\n  var ch = 0;\n  state.lastStringValue = \"\";\n  while (isUnicodePropertyValueCharacter(ch = state.current())) {\n    state.lastStringValue += codePointToString(ch);\n    state.advance();\n  }\n  return state.lastStringValue !== \"\"\n};\nfunction isUnicodePropertyValueCharacter(ch) {\n  return isUnicodePropertyNameCharacter(ch) || isDecimalDigit(ch)\n}\n\n// LoneUnicodePropertyNameOrValue ::\n//   UnicodePropertyValueCharacters\npp$1.regexp_eatLoneUnicodePropertyNameOrValue = function(state) {\n  return this.regexp_eatUnicodePropertyValue(state)\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-CharacterClass\npp$1.regexp_eatCharacterClass = function(state) {\n  if (state.eat(0x5B /* [ */)) {\n    state.eat(0x5E /* ^ */);\n    this.regexp_classRanges(state);\n    if (state.eat(0x5D /* ] */)) {\n      return true\n    }\n    // Unreachable since it threw \"unterminated regular expression\" error before.\n    state.raise(\"Unterminated character class\");\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-ClassRanges\n// https://www.ecma-international.org/ecma-262/8.0/#prod-NonemptyClassRanges\n// https://www.ecma-international.org/ecma-262/8.0/#prod-NonemptyClassRangesNoDash\npp$1.regexp_classRanges = function(state) {\n  while (this.regexp_eatClassAtom(state)) {\n    var left = state.lastIntValue;\n    if (state.eat(0x2D /* - */) && this.regexp_eatClassAtom(state)) {\n      var right = state.lastIntValue;\n      if (state.switchU && (left === -1 || right === -1)) {\n        state.raise(\"Invalid character class\");\n      }\n      if (left !== -1 && right !== -1 && left > right) {\n        state.raise(\"Range out of order in character class\");\n      }\n    }\n  }\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-ClassAtom\n// https://www.ecma-international.org/ecma-262/8.0/#prod-ClassAtomNoDash\npp$1.regexp_eatClassAtom = function(state) {\n  var start = state.pos;\n\n  if (state.eat(0x5C /* \\ */)) {\n    if (this.regexp_eatClassEscape(state)) {\n      return true\n    }\n    if (state.switchU) {\n      // Make the same message as V8.\n      var ch$1 = state.current();\n      if (ch$1 === 0x63 /* c */ || isOctalDigit(ch$1)) {\n        state.raise(\"Invalid class escape\");\n      }\n      state.raise(\"Invalid escape\");\n    }\n    state.pos = start;\n  }\n\n  var ch = state.current();\n  if (ch !== 0x5D /* ] */) {\n    state.lastIntValue = ch;\n    state.advance();\n    return true\n  }\n\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ClassEscape\npp$1.regexp_eatClassEscape = function(state) {\n  var start = state.pos;\n\n  if (state.eat(0x62 /* b */)) {\n    state.lastIntValue = 0x08; /* <BS> */\n    return true\n  }\n\n  if (state.switchU && state.eat(0x2D /* - */)) {\n    state.lastIntValue = 0x2D; /* - */\n    return true\n  }\n\n  if (!state.switchU && state.eat(0x63 /* c */)) {\n    if (this.regexp_eatClassControlLetter(state)) {\n      return true\n    }\n    state.pos = start;\n  }\n\n  return (\n    this.regexp_eatCharacterClassEscape(state) ||\n    this.regexp_eatCharacterEscape(state)\n  )\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ClassControlLetter\npp$1.regexp_eatClassControlLetter = function(state) {\n  var ch = state.current();\n  if (isDecimalDigit(ch) || ch === 0x5F /* _ */) {\n    state.lastIntValue = ch % 0x20;\n    state.advance();\n    return true\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-HexEscapeSequence\npp$1.regexp_eatHexEscapeSequence = function(state) {\n  var start = state.pos;\n  if (state.eat(0x78 /* x */)) {\n    if (this.regexp_eatFixedHexDigits(state, 2)) {\n      return true\n    }\n    if (state.switchU) {\n      state.raise(\"Invalid escape\");\n    }\n    state.pos = start;\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-DecimalDigits\npp$1.regexp_eatDecimalDigits = function(state) {\n  var start = state.pos;\n  var ch = 0;\n  state.lastIntValue = 0;\n  while (isDecimalDigit(ch = state.current())) {\n    state.lastIntValue = 10 * state.lastIntValue + (ch - 0x30 /* 0 */);\n    state.advance();\n  }\n  return state.pos !== start\n};\nfunction isDecimalDigit(ch) {\n  return ch >= 0x30 /* 0 */ && ch <= 0x39 /* 9 */\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-HexDigits\npp$1.regexp_eatHexDigits = function(state) {\n  var start = state.pos;\n  var ch = 0;\n  state.lastIntValue = 0;\n  while (isHexDigit(ch = state.current())) {\n    state.lastIntValue = 16 * state.lastIntValue + hexToInt(ch);\n    state.advance();\n  }\n  return state.pos !== start\n};\nfunction isHexDigit(ch) {\n  return (\n    (ch >= 0x30 /* 0 */ && ch <= 0x39 /* 9 */) ||\n    (ch >= 0x41 /* A */ && ch <= 0x46 /* F */) ||\n    (ch >= 0x61 /* a */ && ch <= 0x66 /* f */)\n  )\n}\nfunction hexToInt(ch) {\n  if (ch >= 0x41 /* A */ && ch <= 0x46 /* F */) {\n    return 10 + (ch - 0x41 /* A */)\n  }\n  if (ch >= 0x61 /* a */ && ch <= 0x66 /* f */) {\n    return 10 + (ch - 0x61 /* a */)\n  }\n  return ch - 0x30 /* 0 */\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-LegacyOctalEscapeSequence\n// Allows only 0-377(octal) i.e. 0-255(decimal).\npp$1.regexp_eatLegacyOctalEscapeSequence = function(state) {\n  if (this.regexp_eatOctalDigit(state)) {\n    var n1 = state.lastIntValue;\n    if (this.regexp_eatOctalDigit(state)) {\n      var n2 = state.lastIntValue;\n      if (n1 <= 3 && this.regexp_eatOctalDigit(state)) {\n        state.lastIntValue = n1 * 64 + n2 * 8 + state.lastIntValue;\n      } else {\n        state.lastIntValue = n1 * 8 + n2;\n      }\n    } else {\n      state.lastIntValue = n1;\n    }\n    return true\n  }\n  return false\n};\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-OctalDigit\npp$1.regexp_eatOctalDigit = function(state) {\n  var ch = state.current();\n  if (isOctalDigit(ch)) {\n    state.lastIntValue = ch - 0x30; /* 0 */\n    state.advance();\n    return true\n  }\n  state.lastIntValue = 0;\n  return false\n};\nfunction isOctalDigit(ch) {\n  return ch >= 0x30 /* 0 */ && ch <= 0x37 /* 7 */\n}\n\n// https://www.ecma-international.org/ecma-262/8.0/#prod-Hex4Digits\n// https://www.ecma-international.org/ecma-262/8.0/#prod-HexDigit\n// And HexDigit HexDigit in https://www.ecma-international.org/ecma-262/8.0/#prod-HexEscapeSequence\npp$1.regexp_eatFixedHexDigits = function(state, length) {\n  var start = state.pos;\n  state.lastIntValue = 0;\n  for (var i = 0; i < length; ++i) {\n    var ch = state.current();\n    if (!isHexDigit(ch)) {\n      state.pos = start;\n      return false\n    }\n    state.lastIntValue = 16 * state.lastIntValue + hexToInt(ch);\n    state.advance();\n  }\n  return true\n};\n\n// Object type used to represent tokens. Note that normally, tokens\n// simply exist as properties on the parser object. This is only\n// used for the onToken callback and the external tokenizer.\n\nvar Token = function Token(p) {\n  this.type = p.type;\n  this.value = p.value;\n  this.start = p.start;\n  this.end = p.end;\n  if (p.options.locations)\n    { this.loc = new SourceLocation(p, p.startLoc, p.endLoc); }\n  if (p.options.ranges)\n    { this.range = [p.start, p.end]; }\n};\n\n// ## Tokenizer\n\nvar pp = Parser$1.prototype;\n\n// Move to the next token\n\npp.next = function(ignoreEscapeSequenceInKeyword) {\n  if (!ignoreEscapeSequenceInKeyword && this.type.keyword && this.containsEsc)\n    { this.raiseRecoverable(this.start, \"Escape sequence in keyword \" + this.type.keyword); }\n  if (this.options.onToken)\n    { this.options.onToken(new Token(this)); }\n\n  this.lastTokEnd = this.end;\n  this.lastTokStart = this.start;\n  this.lastTokEndLoc = this.endLoc;\n  this.lastTokStartLoc = this.startLoc;\n  this.nextToken();\n};\n\npp.getToken = function() {\n  this.next();\n  return new Token(this)\n};\n\n// If we're in an ES6 environment, make parsers iterable\nif (typeof Symbol !== \"undefined\")\n  { pp[Symbol.iterator] = function() {\n    var this$1$1 = this;\n\n    return {\n      next: function () {\n        var token = this$1$1.getToken();\n        return {\n          done: token.type === types$1.eof,\n          value: token\n        }\n      }\n    }\n  }; }\n\n// Toggle strict mode. Re-reads the next number or string to please\n// pedantic tests (`\"use strict\"; 010;` should fail).\n\n// Read a single token, updating the parser object's token-related\n// properties.\n\npp.nextToken = function() {\n  var curContext = this.curContext();\n  if (!curContext || !curContext.preserveSpace) { this.skipSpace(); }\n\n  this.start = this.pos;\n  if (this.options.locations) { this.startLoc = this.curPosition(); }\n  if (this.pos >= this.input.length) { return this.finishToken(types$1.eof) }\n\n  if (curContext.override) { return curContext.override(this) }\n  else { this.readToken(this.fullCharCodeAtPos()); }\n};\n\npp.readToken = function(code) {\n  // Identifier or keyword. '\\uXXXX' sequences are allowed in\n  // identifiers, so '\\' also dispatches to that.\n  if (isIdentifierStart(code, this.options.ecmaVersion >= 6) || code === 92 /* '\\' */)\n    { return this.readWord() }\n\n  return this.getTokenFromCode(code)\n};\n\npp.fullCharCodeAtPos = function() {\n  var code = this.input.charCodeAt(this.pos);\n  if (code <= 0xd7ff || code >= 0xdc00) { return code }\n  var next = this.input.charCodeAt(this.pos + 1);\n  return next <= 0xdbff || next >= 0xe000 ? code : (code << 10) + next - 0x35fdc00\n};\n\npp.skipBlockComment = function() {\n  var startLoc = this.options.onComment && this.curPosition();\n  var start = this.pos, end = this.input.indexOf(\"*/\", this.pos += 2);\n  if (end === -1) { this.raise(this.pos - 2, \"Unterminated comment\"); }\n  this.pos = end + 2;\n  if (this.options.locations) {\n    for (var nextBreak = (void 0), pos = start; (nextBreak = nextLineBreak(this.input, pos, this.pos)) > -1;) {\n      ++this.curLine;\n      pos = this.lineStart = nextBreak;\n    }\n  }\n  if (this.options.onComment)\n    { this.options.onComment(true, this.input.slice(start + 2, end), start, this.pos,\n                           startLoc, this.curPosition()); }\n};\n\npp.skipLineComment = function(startSkip) {\n  var start = this.pos;\n  var startLoc = this.options.onComment && this.curPosition();\n  var ch = this.input.charCodeAt(this.pos += startSkip);\n  while (this.pos < this.input.length && !isNewLine(ch)) {\n    ch = this.input.charCodeAt(++this.pos);\n  }\n  if (this.options.onComment)\n    { this.options.onComment(false, this.input.slice(start + startSkip, this.pos), start, this.pos,\n                           startLoc, this.curPosition()); }\n};\n\n// Called at the start of the parse and after every token. Skips\n// whitespace and comments, and.\n\npp.skipSpace = function() {\n  loop: while (this.pos < this.input.length) {\n    var ch = this.input.charCodeAt(this.pos);\n    switch (ch) {\n    case 32: case 160: // ' '\n      ++this.pos;\n      break\n    case 13:\n      if (this.input.charCodeAt(this.pos + 1) === 10) {\n        ++this.pos;\n      }\n    case 10: case 8232: case 8233:\n      ++this.pos;\n      if (this.options.locations) {\n        ++this.curLine;\n        this.lineStart = this.pos;\n      }\n      break\n    case 47: // '/'\n      switch (this.input.charCodeAt(this.pos + 1)) {\n      case 42: // '*'\n        this.skipBlockComment();\n        break\n      case 47:\n        this.skipLineComment(2);\n        break\n      default:\n        break loop\n      }\n      break\n    default:\n      if (ch > 8 && ch < 14 || ch >= 5760 && nonASCIIwhitespace.test(String.fromCharCode(ch))) {\n        ++this.pos;\n      } else {\n        break loop\n      }\n    }\n  }\n};\n\n// Called at the end of every token. Sets `end`, `val`, and\n// maintains `context` and `exprAllowed`, and skips the space after\n// the token, so that the next one's `start` will point at the\n// right position.\n\npp.finishToken = function(type, val) {\n  this.end = this.pos;\n  if (this.options.locations) { this.endLoc = this.curPosition(); }\n  var prevType = this.type;\n  this.type = type;\n  this.value = val;\n\n  this.updateContext(prevType);\n};\n\n// ### Token reading\n\n// This is the function that is called to fetch the next token. It\n// is somewhat obscure, because it works in character codes rather\n// than characters, and because operator parsing has been inlined\n// into it.\n//\n// All in the name of speed.\n//\npp.readToken_dot = function() {\n  var next = this.input.charCodeAt(this.pos + 1);\n  if (next >= 48 && next <= 57) { return this.readNumber(true) }\n  var next2 = this.input.charCodeAt(this.pos + 2);\n  if (this.options.ecmaVersion >= 6 && next === 46 && next2 === 46) { // 46 = dot '.'\n    this.pos += 3;\n    return this.finishToken(types$1.ellipsis)\n  } else {\n    ++this.pos;\n    return this.finishToken(types$1.dot)\n  }\n};\n\npp.readToken_slash = function() { // '/'\n  var next = this.input.charCodeAt(this.pos + 1);\n  if (this.exprAllowed) { ++this.pos; return this.readRegexp() }\n  if (next === 61) { return this.finishOp(types$1.assign, 2) }\n  return this.finishOp(types$1.slash, 1)\n};\n\npp.readToken_mult_modulo_exp = function(code) { // '%*'\n  var next = this.input.charCodeAt(this.pos + 1);\n  var size = 1;\n  var tokentype = code === 42 ? types$1.star : types$1.modulo;\n\n  // exponentiation operator ** and **=\n  if (this.options.ecmaVersion >= 7 && code === 42 && next === 42) {\n    ++size;\n    tokentype = types$1.starstar;\n    next = this.input.charCodeAt(this.pos + 2);\n  }\n\n  if (next === 61) { return this.finishOp(types$1.assign, size + 1) }\n  return this.finishOp(tokentype, size)\n};\n\npp.readToken_pipe_amp = function(code) { // '|&'\n  var next = this.input.charCodeAt(this.pos + 1);\n  if (next === code) {\n    if (this.options.ecmaVersion >= 12) {\n      var next2 = this.input.charCodeAt(this.pos + 2);\n      if (next2 === 61) { return this.finishOp(types$1.assign, 3) }\n    }\n    return this.finishOp(code === 124 ? types$1.logicalOR : types$1.logicalAND, 2)\n  }\n  if (next === 61) { return this.finishOp(types$1.assign, 2) }\n  return this.finishOp(code === 124 ? types$1.bitwiseOR : types$1.bitwiseAND, 1)\n};\n\npp.readToken_caret = function() { // '^'\n  var next = this.input.charCodeAt(this.pos + 1);\n  if (next === 61) { return this.finishOp(types$1.assign, 2) }\n  return this.finishOp(types$1.bitwiseXOR, 1)\n};\n\npp.readToken_plus_min = function(code) { // '+-'\n  var next = this.input.charCodeAt(this.pos + 1);\n  if (next === code) {\n    if (next === 45 && !this.inModule && this.input.charCodeAt(this.pos + 2) === 62 &&\n        (this.lastTokEnd === 0 || lineBreak.test(this.input.slice(this.lastTokEnd, this.pos)))) {\n      // A `-->` line comment\n      this.skipLineComment(3);\n      this.skipSpace();\n      return this.nextToken()\n    }\n    return this.finishOp(types$1.incDec, 2)\n  }\n  if (next === 61) { return this.finishOp(types$1.assign, 2) }\n  return this.finishOp(types$1.plusMin, 1)\n};\n\npp.readToken_lt_gt = function(code) { // '<>'\n  var next = this.input.charCodeAt(this.pos + 1);\n  var size = 1;\n  if (next === code) {\n    size = code === 62 && this.input.charCodeAt(this.pos + 2) === 62 ? 3 : 2;\n    if (this.input.charCodeAt(this.pos + size) === 61) { return this.finishOp(types$1.assign, size + 1) }\n    return this.finishOp(types$1.bitShift, size)\n  }\n  if (next === 33 && code === 60 && !this.inModule && this.input.charCodeAt(this.pos + 2) === 45 &&\n      this.input.charCodeAt(this.pos + 3) === 45) {\n    // `<!--`, an XML-style comment that should be interpreted as a line comment\n    this.skipLineComment(4);\n    this.skipSpace();\n    return this.nextToken()\n  }\n  if (next === 61) { size = 2; }\n  return this.finishOp(types$1.relational, size)\n};\n\npp.readToken_eq_excl = function(code) { // '=!'\n  var next = this.input.charCodeAt(this.pos + 1);\n  if (next === 61) { return this.finishOp(types$1.equality, this.input.charCodeAt(this.pos + 2) === 61 ? 3 : 2) }\n  if (code === 61 && next === 62 && this.options.ecmaVersion >= 6) { // '=>'\n    this.pos += 2;\n    return this.finishToken(types$1.arrow)\n  }\n  return this.finishOp(code === 61 ? types$1.eq : types$1.prefix, 1)\n};\n\npp.readToken_question = function() { // '?'\n  var ecmaVersion = this.options.ecmaVersion;\n  if (ecmaVersion >= 11) {\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next === 46) {\n      var next2 = this.input.charCodeAt(this.pos + 2);\n      if (next2 < 48 || next2 > 57) { return this.finishOp(types$1.questionDot, 2) }\n    }\n    if (next === 63) {\n      if (ecmaVersion >= 12) {\n        var next2$1 = this.input.charCodeAt(this.pos + 2);\n        if (next2$1 === 61) { return this.finishOp(types$1.assign, 3) }\n      }\n      return this.finishOp(types$1.coalesce, 2)\n    }\n  }\n  return this.finishOp(types$1.question, 1)\n};\n\npp.readToken_numberSign = function() { // '#'\n  var ecmaVersion = this.options.ecmaVersion;\n  var code = 35; // '#'\n  if (ecmaVersion >= 13) {\n    ++this.pos;\n    code = this.fullCharCodeAtPos();\n    if (isIdentifierStart(code, true) || code === 92 /* '\\' */) {\n      return this.finishToken(types$1.privateId, this.readWord1())\n    }\n  }\n\n  this.raise(this.pos, \"Unexpected character '\" + codePointToString(code) + \"'\");\n};\n\npp.getTokenFromCode = function(code) {\n  switch (code) {\n  // The interpretation of a dot depends on whether it is followed\n  // by a digit or another two dots.\n  case 46: // '.'\n    return this.readToken_dot()\n\n  // Punctuation tokens.\n  case 40: ++this.pos; return this.finishToken(types$1.parenL)\n  case 41: ++this.pos; return this.finishToken(types$1.parenR)\n  case 59: ++this.pos; return this.finishToken(types$1.semi)\n  case 44: ++this.pos; return this.finishToken(types$1.comma)\n  case 91: ++this.pos; return this.finishToken(types$1.bracketL)\n  case 93: ++this.pos; return this.finishToken(types$1.bracketR)\n  case 123: ++this.pos; return this.finishToken(types$1.braceL)\n  case 125: ++this.pos; return this.finishToken(types$1.braceR)\n  case 58: ++this.pos; return this.finishToken(types$1.colon)\n\n  case 96: // '`'\n    if (this.options.ecmaVersion < 6) { break }\n    ++this.pos;\n    return this.finishToken(types$1.backQuote)\n\n  case 48: // '0'\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next === 120 || next === 88) { return this.readRadixNumber(16) } // '0x', '0X' - hex number\n    if (this.options.ecmaVersion >= 6) {\n      if (next === 111 || next === 79) { return this.readRadixNumber(8) } // '0o', '0O' - octal number\n      if (next === 98 || next === 66) { return this.readRadixNumber(2) } // '0b', '0B' - binary number\n    }\n\n  // Anything else beginning with a digit is an integer, octal\n  // number, or float.\n  case 49: case 50: case 51: case 52: case 53: case 54: case 55: case 56: case 57: // 1-9\n    return this.readNumber(false)\n\n  // Quotes produce strings.\n  case 34: case 39: // '\"', \"'\"\n    return this.readString(code)\n\n  // Operators are parsed inline in tiny state machines. '=' (61) is\n  // often referred to. `finishOp` simply skips the amount of\n  // characters it is given as second argument, and returns a token\n  // of the type given by its first argument.\n  case 47: // '/'\n    return this.readToken_slash()\n\n  case 37: case 42: // '%*'\n    return this.readToken_mult_modulo_exp(code)\n\n  case 124: case 38: // '|&'\n    return this.readToken_pipe_amp(code)\n\n  case 94: // '^'\n    return this.readToken_caret()\n\n  case 43: case 45: // '+-'\n    return this.readToken_plus_min(code)\n\n  case 60: case 62: // '<>'\n    return this.readToken_lt_gt(code)\n\n  case 61: case 33: // '=!'\n    return this.readToken_eq_excl(code)\n\n  case 63: // '?'\n    return this.readToken_question()\n\n  case 126: // '~'\n    return this.finishOp(types$1.prefix, 1)\n\n  case 35: // '#'\n    return this.readToken_numberSign()\n  }\n\n  this.raise(this.pos, \"Unexpected character '\" + codePointToString(code) + \"'\");\n};\n\npp.finishOp = function(type, size) {\n  var str = this.input.slice(this.pos, this.pos + size);\n  this.pos += size;\n  return this.finishToken(type, str)\n};\n\npp.readRegexp = function() {\n  var escaped, inClass, start = this.pos;\n  for (;;) {\n    if (this.pos >= this.input.length) { this.raise(start, \"Unterminated regular expression\"); }\n    var ch = this.input.charAt(this.pos);\n    if (lineBreak.test(ch)) { this.raise(start, \"Unterminated regular expression\"); }\n    if (!escaped) {\n      if (ch === \"[\") { inClass = true; }\n      else if (ch === \"]\" && inClass) { inClass = false; }\n      else if (ch === \"/\" && !inClass) { break }\n      escaped = ch === \"\\\\\";\n    } else { escaped = false; }\n    ++this.pos;\n  }\n  var pattern = this.input.slice(start, this.pos);\n  ++this.pos;\n  var flagsStart = this.pos;\n  var flags = this.readWord1();\n  if (this.containsEsc) { this.unexpected(flagsStart); }\n\n  // Validate pattern\n  var state = this.regexpState || (this.regexpState = new RegExpValidationState(this));\n  state.reset(start, pattern, flags);\n  this.validateRegExpFlags(state);\n  this.validateRegExpPattern(state);\n\n  // Create Literal#value property value.\n  var value = null;\n  try {\n    value = new RegExp(pattern, flags);\n  } catch (e) {\n    // ESTree requires null if it failed to instantiate RegExp object.\n    // https://github.com/estree/estree/blob/a27003adf4fd7bfad44de9cef372a2eacd527b1c/es5.md#regexpliteral\n  }\n\n  return this.finishToken(types$1.regexp, {pattern: pattern, flags: flags, value: value})\n};\n\n// Read an integer in the given radix. Return null if zero digits\n// were read, the integer value otherwise. When `len` is given, this\n// will return `null` unless the integer has exactly `len` digits.\n\npp.readInt = function(radix, len, maybeLegacyOctalNumericLiteral) {\n  // `len` is used for character escape sequences. In that case, disallow separators.\n  var allowSeparators = this.options.ecmaVersion >= 12 && len === undefined;\n\n  // `maybeLegacyOctalNumericLiteral` is true if it doesn't have prefix (0x,0o,0b)\n  // and isn't fraction part nor exponent part. In that case, if the first digit\n  // is zero then disallow separators.\n  var isLegacyOctalNumericLiteral = maybeLegacyOctalNumericLiteral && this.input.charCodeAt(this.pos) === 48;\n\n  var start = this.pos, total = 0, lastCode = 0;\n  for (var i = 0, e = len == null ? Infinity : len; i < e; ++i, ++this.pos) {\n    var code = this.input.charCodeAt(this.pos), val = (void 0);\n\n    if (allowSeparators && code === 95) {\n      if (isLegacyOctalNumericLiteral) { this.raiseRecoverable(this.pos, \"Numeric separator is not allowed in legacy octal numeric literals\"); }\n      if (lastCode === 95) { this.raiseRecoverable(this.pos, \"Numeric separator must be exactly one underscore\"); }\n      if (i === 0) { this.raiseRecoverable(this.pos, \"Numeric separator is not allowed at the first of digits\"); }\n      lastCode = code;\n      continue\n    }\n\n    if (code >= 97) { val = code - 97 + 10; } // a\n    else if (code >= 65) { val = code - 65 + 10; } // A\n    else if (code >= 48 && code <= 57) { val = code - 48; } // 0-9\n    else { val = Infinity; }\n    if (val >= radix) { break }\n    lastCode = code;\n    total = total * radix + val;\n  }\n\n  if (allowSeparators && lastCode === 95) { this.raiseRecoverable(this.pos - 1, \"Numeric separator is not allowed at the last of digits\"); }\n  if (this.pos === start || len != null && this.pos - start !== len) { return null }\n\n  return total\n};\n\nfunction stringToNumber(str, isLegacyOctalNumericLiteral) {\n  if (isLegacyOctalNumericLiteral) {\n    return parseInt(str, 8)\n  }\n\n  // `parseFloat(value)` stops parsing at the first numeric separator then returns a wrong value.\n  return parseFloat(str.replace(/_/g, \"\"))\n}\n\nfunction stringToBigInt(str) {\n  if (typeof BigInt !== \"function\") {\n    return null\n  }\n\n  // `BigInt(value)` throws syntax error if the string contains numeric separators.\n  return BigInt(str.replace(/_/g, \"\"))\n}\n\npp.readRadixNumber = function(radix) {\n  var start = this.pos;\n  this.pos += 2; // 0x\n  var val = this.readInt(radix);\n  if (val == null) { this.raise(this.start + 2, \"Expected number in radix \" + radix); }\n  if (this.options.ecmaVersion >= 11 && this.input.charCodeAt(this.pos) === 110) {\n    val = stringToBigInt(this.input.slice(start, this.pos));\n    ++this.pos;\n  } else if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, \"Identifier directly after number\"); }\n  return this.finishToken(types$1.num, val)\n};\n\n// Read an integer, octal integer, or floating-point number.\n\npp.readNumber = function(startsWithDot) {\n  var start = this.pos;\n  if (!startsWithDot && this.readInt(10, undefined, true) === null) { this.raise(start, \"Invalid number\"); }\n  var octal = this.pos - start >= 2 && this.input.charCodeAt(start) === 48;\n  if (octal && this.strict) { this.raise(start, \"Invalid number\"); }\n  var next = this.input.charCodeAt(this.pos);\n  if (!octal && !startsWithDot && this.options.ecmaVersion >= 11 && next === 110) {\n    var val$1 = stringToBigInt(this.input.slice(start, this.pos));\n    ++this.pos;\n    if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, \"Identifier directly after number\"); }\n    return this.finishToken(types$1.num, val$1)\n  }\n  if (octal && /[89]/.test(this.input.slice(start, this.pos))) { octal = false; }\n  if (next === 46 && !octal) { // '.'\n    ++this.pos;\n    this.readInt(10);\n    next = this.input.charCodeAt(this.pos);\n  }\n  if ((next === 69 || next === 101) && !octal) { // 'eE'\n    next = this.input.charCodeAt(++this.pos);\n    if (next === 43 || next === 45) { ++this.pos; } // '+-'\n    if (this.readInt(10) === null) { this.raise(start, \"Invalid number\"); }\n  }\n  if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, \"Identifier directly after number\"); }\n\n  var val = stringToNumber(this.input.slice(start, this.pos), octal);\n  return this.finishToken(types$1.num, val)\n};\n\n// Read a string value, interpreting backslash-escapes.\n\npp.readCodePoint = function() {\n  var ch = this.input.charCodeAt(this.pos), code;\n\n  if (ch === 123) { // '{'\n    if (this.options.ecmaVersion < 6) { this.unexpected(); }\n    var codePos = ++this.pos;\n    code = this.readHexChar(this.input.indexOf(\"}\", this.pos) - this.pos);\n    ++this.pos;\n    if (code > 0x10FFFF) { this.invalidStringToken(codePos, \"Code point out of bounds\"); }\n  } else {\n    code = this.readHexChar(4);\n  }\n  return code\n};\n\npp.readString = function(quote) {\n  var out = \"\", chunkStart = ++this.pos;\n  for (;;) {\n    if (this.pos >= this.input.length) { this.raise(this.start, \"Unterminated string constant\"); }\n    var ch = this.input.charCodeAt(this.pos);\n    if (ch === quote) { break }\n    if (ch === 92) { // '\\'\n      out += this.input.slice(chunkStart, this.pos);\n      out += this.readEscapedChar(false);\n      chunkStart = this.pos;\n    } else if (ch === 0x2028 || ch === 0x2029) {\n      if (this.options.ecmaVersion < 10) { this.raise(this.start, \"Unterminated string constant\"); }\n      ++this.pos;\n      if (this.options.locations) {\n        this.curLine++;\n        this.lineStart = this.pos;\n      }\n    } else {\n      if (isNewLine(ch)) { this.raise(this.start, \"Unterminated string constant\"); }\n      ++this.pos;\n    }\n  }\n  out += this.input.slice(chunkStart, this.pos++);\n  return this.finishToken(types$1.string, out)\n};\n\n// Reads template string tokens.\n\nvar INVALID_TEMPLATE_ESCAPE_ERROR = {};\n\npp.tryReadTemplateToken = function() {\n  this.inTemplateElement = true;\n  try {\n    this.readTmplToken();\n  } catch (err) {\n    if (err === INVALID_TEMPLATE_ESCAPE_ERROR) {\n      this.readInvalidTemplateToken();\n    } else {\n      throw err\n    }\n  }\n\n  this.inTemplateElement = false;\n};\n\npp.invalidStringToken = function(position, message) {\n  if (this.inTemplateElement && this.options.ecmaVersion >= 9) {\n    throw INVALID_TEMPLATE_ESCAPE_ERROR\n  } else {\n    this.raise(position, message);\n  }\n};\n\npp.readTmplToken = function() {\n  var out = \"\", chunkStart = this.pos;\n  for (;;) {\n    if (this.pos >= this.input.length) { this.raise(this.start, \"Unterminated template\"); }\n    var ch = this.input.charCodeAt(this.pos);\n    if (ch === 96 || ch === 36 && this.input.charCodeAt(this.pos + 1) === 123) { // '`', '${'\n      if (this.pos === this.start && (this.type === types$1.template || this.type === types$1.invalidTemplate)) {\n        if (ch === 36) {\n          this.pos += 2;\n          return this.finishToken(types$1.dollarBraceL)\n        } else {\n          ++this.pos;\n          return this.finishToken(types$1.backQuote)\n        }\n      }\n      out += this.input.slice(chunkStart, this.pos);\n      return this.finishToken(types$1.template, out)\n    }\n    if (ch === 92) { // '\\'\n      out += this.input.slice(chunkStart, this.pos);\n      out += this.readEscapedChar(true);\n      chunkStart = this.pos;\n    } else if (isNewLine(ch)) {\n      out += this.input.slice(chunkStart, this.pos);\n      ++this.pos;\n      switch (ch) {\n      case 13:\n        if (this.input.charCodeAt(this.pos) === 10) { ++this.pos; }\n      case 10:\n        out += \"\\n\";\n        break\n      default:\n        out += String.fromCharCode(ch);\n        break\n      }\n      if (this.options.locations) {\n        ++this.curLine;\n        this.lineStart = this.pos;\n      }\n      chunkStart = this.pos;\n    } else {\n      ++this.pos;\n    }\n  }\n};\n\n// Reads a template token to search for the end, without validating any escape sequences\npp.readInvalidTemplateToken = function() {\n  for (; this.pos < this.input.length; this.pos++) {\n    switch (this.input[this.pos]) {\n    case \"\\\\\":\n      ++this.pos;\n      break\n\n    case \"$\":\n      if (this.input[this.pos + 1] !== \"{\") {\n        break\n      }\n\n    // falls through\n    case \"`\":\n      return this.finishToken(types$1.invalidTemplate, this.input.slice(this.start, this.pos))\n\n    // no default\n    }\n  }\n  this.raise(this.start, \"Unterminated template\");\n};\n\n// Used to read escaped characters\n\npp.readEscapedChar = function(inTemplate) {\n  var ch = this.input.charCodeAt(++this.pos);\n  ++this.pos;\n  switch (ch) {\n  case 110: return \"\\n\" // 'n' -> '\\n'\n  case 114: return \"\\r\" // 'r' -> '\\r'\n  case 120: return String.fromCharCode(this.readHexChar(2)) // 'x'\n  case 117: return codePointToString(this.readCodePoint()) // 'u'\n  case 116: return \"\\t\" // 't' -> '\\t'\n  case 98: return \"\\b\" // 'b' -> '\\b'\n  case 118: return \"\\u000b\" // 'v' -> '\\u000b'\n  case 102: return \"\\f\" // 'f' -> '\\f'\n  case 13: if (this.input.charCodeAt(this.pos) === 10) { ++this.pos; } // '\\r\\n'\n  case 10: // ' \\n'\n    if (this.options.locations) { this.lineStart = this.pos; ++this.curLine; }\n    return \"\"\n  case 56:\n  case 57:\n    if (this.strict) {\n      this.invalidStringToken(\n        this.pos - 1,\n        \"Invalid escape sequence\"\n      );\n    }\n    if (inTemplate) {\n      var codePos = this.pos - 1;\n\n      this.invalidStringToken(\n        codePos,\n        \"Invalid escape sequence in template string\"\n      );\n    }\n  default:\n    if (ch >= 48 && ch <= 55) {\n      var octalStr = this.input.substr(this.pos - 1, 3).match(/^[0-7]+/)[0];\n      var octal = parseInt(octalStr, 8);\n      if (octal > 255) {\n        octalStr = octalStr.slice(0, -1);\n        octal = parseInt(octalStr, 8);\n      }\n      this.pos += octalStr.length - 1;\n      ch = this.input.charCodeAt(this.pos);\n      if ((octalStr !== \"0\" || ch === 56 || ch === 57) && (this.strict || inTemplate)) {\n        this.invalidStringToken(\n          this.pos - 1 - octalStr.length,\n          inTemplate\n            ? \"Octal literal in template string\"\n            : \"Octal literal in strict mode\"\n        );\n      }\n      return String.fromCharCode(octal)\n    }\n    if (isNewLine(ch)) {\n      // Unicode new line characters after \\ get removed from output in both\n      // template literals and strings\n      return \"\"\n    }\n    return String.fromCharCode(ch)\n  }\n};\n\n// Used to read character escape sequences ('\\x', '\\u', '\\U').\n\npp.readHexChar = function(len) {\n  var codePos = this.pos;\n  var n = this.readInt(16, len);\n  if (n === null) { this.invalidStringToken(codePos, \"Bad character escape sequence\"); }\n  return n\n};\n\n// Read an identifier, and return it as a string. Sets `this.containsEsc`\n// to whether the word contained a '\\u' escape.\n//\n// Incrementally adds only escaped chars, adding other chunks as-is\n// as a micro-optimization.\n\npp.readWord1 = function() {\n  this.containsEsc = false;\n  var word = \"\", first = true, chunkStart = this.pos;\n  var astral = this.options.ecmaVersion >= 6;\n  while (this.pos < this.input.length) {\n    var ch = this.fullCharCodeAtPos();\n    if (isIdentifierChar(ch, astral)) {\n      this.pos += ch <= 0xffff ? 1 : 2;\n    } else if (ch === 92) { // \"\\\"\n      this.containsEsc = true;\n      word += this.input.slice(chunkStart, this.pos);\n      var escStart = this.pos;\n      if (this.input.charCodeAt(++this.pos) !== 117) // \"u\"\n        { this.invalidStringToken(this.pos, \"Expecting Unicode escape sequence \\\\uXXXX\"); }\n      ++this.pos;\n      var esc = this.readCodePoint();\n      if (!(first ? isIdentifierStart : isIdentifierChar)(esc, astral))\n        { this.invalidStringToken(escStart, \"Invalid Unicode escape\"); }\n      word += codePointToString(esc);\n      chunkStart = this.pos;\n    } else {\n      break\n    }\n    first = false;\n  }\n  return word + this.input.slice(chunkStart, this.pos)\n};\n\n// Read an identifier or keyword token. Will check for reserved\n// words when necessary.\n\npp.readWord = function() {\n  var word = this.readWord1();\n  var type = types$1.name;\n  if (this.keywords.test(word)) {\n    type = keywords$2[word];\n  }\n  return this.finishToken(type, word)\n};\n\n// Acorn is a tiny, fast JavaScript parser written in JavaScript.\n\nvar version$2 = \"8.8.2\";\n\nParser$1.acorn = {\n  Parser: Parser$1,\n  version: version$2,\n  defaultOptions: defaultOptions,\n  Position: Position,\n  SourceLocation: SourceLocation,\n  getLineInfo: getLineInfo,\n  Node: Node,\n  TokenType: TokenType,\n  tokTypes: types$1,\n  keywordTypes: keywords$2,\n  TokContext: TokContext,\n  tokContexts: types$2,\n  isIdentifierChar: isIdentifierChar,\n  isIdentifierStart: isIdentifierStart,\n  Token: Token,\n  isNewLine: isNewLine,\n  lineBreak: lineBreak,\n  lineBreakG: lineBreakG,\n  nonASCIIwhitespace: nonASCIIwhitespace\n};\n\n// The main exported interface (under `self.acorn` when in the\n// browser) is a `parse` function that takes a code string and\n// returns an abstract syntax tree as specified by [Mozilla parser\n// API][api].\n//\n// [api]: https://developer.mozilla.org/en-US/docs/SpiderMonkey/Parser_API\n\nfunction parse$d(input, options) {\n  return Parser$1.parse(input, options)\n}\n\n// This function tries to parse a single expression at a given\n// offset in a string. Useful for parsing mixed-language formats\n// that embed JavaScript expressions.\n\nfunction parseExpressionAt(input, pos, options) {\n  return Parser$1.parseExpressionAt(input, pos, options)\n}\n\n// Acorn is organized as a tokenizer and a recursive-descent parser.\n// The `tokenizer` export provides an interface to the tokenizer.\n\nfunction tokenizer(input, options) {\n  return Parser$1.tokenizer(input, options)\n}\n\nvar acorn = {\n  __proto__: null,\n  Node: Node,\n  Parser: Parser$1,\n  Position: Position,\n  SourceLocation: SourceLocation,\n  TokContext: TokContext,\n  Token: Token,\n  TokenType: TokenType,\n  defaultOptions: defaultOptions,\n  getLineInfo: getLineInfo,\n  isIdentifierChar: isIdentifierChar,\n  isIdentifierStart: isIdentifierStart,\n  isNewLine: isNewLine,\n  keywordTypes: keywords$2,\n  lineBreak: lineBreak,\n  lineBreakG: lineBreakG,\n  nonASCIIwhitespace: nonASCIIwhitespace,\n  parse: parse$d,\n  parseExpressionAt: parseExpressionAt,\n  tokContexts: types$2,\n  tokTypes: types$1,\n  tokenizer: tokenizer,\n  version: version$2\n};\n\nconst HASH_RE = /#/g;\nconst AMPERSAND_RE = /&/g;\nconst EQUAL_RE = /=/g;\nconst PLUS_RE = /\\+/g;\nconst ENC_BRACKET_OPEN_RE = /%5b/gi;\nconst ENC_BRACKET_CLOSE_RE = /%5d/gi;\nconst ENC_CARET_RE = /%5e/gi;\nconst ENC_BACKTICK_RE = /%60/gi;\nconst ENC_CURLY_OPEN_RE = /%7b/gi;\nconst ENC_PIPE_RE = /%7c/gi;\nconst ENC_CURLY_CLOSE_RE = /%7d/gi;\nconst ENC_SPACE_RE = /%20/gi;\nfunction encode(text) {\n  return encodeURI(\"\" + text).replace(ENC_PIPE_RE, \"|\").replace(ENC_BRACKET_OPEN_RE, \"[\").replace(ENC_BRACKET_CLOSE_RE, \"]\");\n}\nfunction encodeQueryValue(text) {\n  return encode(text).replace(PLUS_RE, \"%2B\").replace(ENC_SPACE_RE, \"+\").replace(HASH_RE, \"%23\").replace(AMPERSAND_RE, \"%26\").replace(ENC_BACKTICK_RE, \"`\").replace(ENC_CURLY_OPEN_RE, \"{\").replace(ENC_CURLY_CLOSE_RE, \"}\").replace(ENC_CARET_RE, \"^\");\n}\nfunction encodeQueryKey(text) {\n  return encodeQueryValue(text).replace(EQUAL_RE, \"%3D\");\n}\nfunction encodeQueryItem(key, value) {\n  if (typeof value === \"number\" || typeof value === \"boolean\") {\n    value = String(value);\n  }\n  if (!value) {\n    return encodeQueryKey(key);\n  }\n  if (Array.isArray(value)) {\n    return value.map((_value) => `${encodeQueryKey(key)}=${encodeQueryValue(_value)}`).join(\"&\");\n  }\n  return `${encodeQueryKey(key)}=${encodeQueryValue(value)}`;\n}\nfunction stringifyQuery(query) {\n  return Object.keys(query).filter((k) => query[k] !== void 0).map((k) => encodeQueryItem(k, query[k])).join(\"&\");\n}\n\nfunction matchAll(regex, string, addition) {\n  const matches = [];\n  for (const match of string.matchAll(regex)) {\n    matches.push({\n      ...addition,\n      ...match.groups,\n      code: match[0],\n      start: match.index,\n      end: match.index + match[0].length\n    });\n  }\n  return matches;\n}\n\n/**\n * @typedef ErrnoExceptionFields\n * @property {number | undefined} [errnode]\n * @property {string | undefined} [code]\n * @property {string | undefined} [path]\n * @property {string | undefined} [syscall]\n * @property {string | undefined} [url]\n *\n * @typedef {Error & ErrnoExceptionFields} ErrnoException\n */\n\nconst isWindows$3 = process$1.platform === 'win32';\n\nconst own$1 = {}.hasOwnProperty;\n\n/**\n * Create a list string in the form like 'A and B' or 'A, B, ..., and Z'.\n * We cannot use Intl.ListFormat because it's not available in\n * --without-intl builds.\n *\n * @param {Array<string>} array\n *   An array of strings.\n * @param {string} [type]\n *   The list type to be inserted before the last element.\n * @returns {string}\n */\nfunction formatList(array, type = 'and') {\n  return array.length < 3\n    ? array.join(` ${type} `)\n    : `${array.slice(0, -1).join(', ')}, ${type} ${array[array.length - 1]}`\n}\n\n/** @type {Map<string, MessageFunction|string>} */\nconst messages = new Map();\nconst nodeInternalPrefix = '__node_internal_';\n/** @type {number} */\nlet userStackTraceLimit;\n\ncreateError(\n  'ERR_INVALID_MODULE_SPECIFIER',\n  /**\n   * @param {string} request\n   * @param {string} reason\n   * @param {string} [base]\n   */\n  (request, reason, base = undefined) => {\n    return `Invalid module \"${request}\" ${reason}${\n      base ? ` imported from ${base}` : ''\n    }`\n  },\n  TypeError\n);\n\ncreateError(\n  'ERR_INVALID_PACKAGE_CONFIG',\n  /**\n   * @param {string} path\n   * @param {string} [base]\n   * @param {string} [message]\n   */\n  (path, base, message) => {\n    return `Invalid package config ${path}${\n      base ? ` while importing ${base}` : ''\n    }${message ? `. ${message}` : ''}`\n  },\n  Error\n);\n\ncreateError(\n  'ERR_INVALID_PACKAGE_TARGET',\n  /**\n   * @param {string} pkgPath\n   * @param {string} key\n   * @param {unknown} target\n   * @param {boolean} [isImport=false]\n   * @param {string} [base]\n   */\n  (pkgPath, key, target, isImport = false, base = undefined) => {\n    const relError =\n      typeof target === 'string' &&\n      !isImport &&\n      target.length > 0 &&\n      !target.startsWith('./');\n    if (key === '.') {\n      assert$1(isImport === false);\n      return (\n        `Invalid \"exports\" main target ${JSON.stringify(target)} defined ` +\n        `in the package config ${pkgPath}package.json${\n          base ? ` imported from ${base}` : ''\n        }${relError ? '; targets must start with \"./\"' : ''}`\n      )\n    }\n\n    return `Invalid \"${\n      isImport ? 'imports' : 'exports'\n    }\" target ${JSON.stringify(\n      target\n    )} defined for '${key}' in the package config ${pkgPath}package.json${\n      base ? ` imported from ${base}` : ''\n    }${relError ? '; targets must start with \"./\"' : ''}`\n  },\n  Error\n);\n\ncreateError(\n  'ERR_MODULE_NOT_FOUND',\n  /**\n   * @param {string} path\n   * @param {string} base\n   * @param {string} [type]\n   */\n  (path, base, type = 'package') => {\n    return `Cannot find ${type} '${path}' imported from ${base}`\n  },\n  Error\n);\n\ncreateError(\n  'ERR_NETWORK_IMPORT_DISALLOWED',\n  \"import of '%s' by %s is not supported: %s\",\n  Error\n);\n\ncreateError(\n  'ERR_PACKAGE_IMPORT_NOT_DEFINED',\n  /**\n   * @param {string} specifier\n   * @param {string} packagePath\n   * @param {string} base\n   */\n  (specifier, packagePath, base) => {\n    return `Package import specifier \"${specifier}\" is not defined${\n      packagePath ? ` in package ${packagePath}package.json` : ''\n    } imported from ${base}`\n  },\n  TypeError\n);\n\ncreateError(\n  'ERR_PACKAGE_PATH_NOT_EXPORTED',\n  /**\n   * @param {string} pkgPath\n   * @param {string} subpath\n   * @param {string} [base]\n   */\n  (pkgPath, subpath, base = undefined) => {\n    if (subpath === '.')\n      return `No \"exports\" main defined in ${pkgPath}package.json${\n        base ? ` imported from ${base}` : ''\n      }`\n    return `Package subpath '${subpath}' is not defined by \"exports\" in ${pkgPath}package.json${\n      base ? ` imported from ${base}` : ''\n    }`\n  },\n  Error\n);\n\ncreateError(\n  'ERR_UNSUPPORTED_DIR_IMPORT',\n  \"Directory import '%s' is not supported \" +\n    'resolving ES modules imported from %s',\n  Error\n);\n\ncreateError(\n  'ERR_UNKNOWN_FILE_EXTENSION',\n  /**\n   * @param {string} ext\n   * @param {string} path\n   */\n  (ext, path) => {\n    return `Unknown file extension \"${ext}\" for ${path}`\n  },\n  TypeError\n);\n\ncreateError(\n  'ERR_INVALID_ARG_VALUE',\n  /**\n   * @param {string} name\n   * @param {unknown} value\n   * @param {string} [reason='is invalid']\n   */\n  (name, value, reason = 'is invalid') => {\n    let inspected = inspect(value);\n\n    if (inspected.length > 128) {\n      inspected = `${inspected.slice(0, 128)}...`;\n    }\n\n    const type = name.includes('.') ? 'property' : 'argument';\n\n    return `The ${type} '${name}' ${reason}. Received ${inspected}`\n  },\n  TypeError\n  // Note: extra classes have been shaken out.\n  // , RangeError\n);\n\ncreateError(\n  'ERR_UNSUPPORTED_ESM_URL_SCHEME',\n  /**\n   * @param {URL} url\n   * @param {Array<string>} supported\n   */\n  (url, supported) => {\n    let message = `Only URLs with a scheme in: ${formatList(\n      supported\n    )} are supported by the default ESM loader`;\n\n    if (isWindows$3 && url.protocol.length === 2) {\n      message += '. On Windows, absolute paths must be valid file:// URLs';\n    }\n\n    message += `. Received protocol '${url.protocol}'`;\n    return message\n  },\n  Error\n);\n\n/**\n * Utility function for registering the error codes. Only used here. Exported\n * *only* to allow for testing.\n * @param {string} sym\n * @param {MessageFunction|string} value\n * @param {ErrorConstructor} def\n * @returns {new (...args: Array<any>) => Error}\n */\nfunction createError(sym, value, def) {\n  // Special case for SystemError that formats the error message differently\n  // The SystemErrors only have SystemError as their base classes.\n  messages.set(sym, value);\n\n  return makeNodeErrorWithCode(def, sym)\n}\n\n/**\n * @param {ErrorConstructor} Base\n * @param {string} key\n * @returns {ErrorConstructor}\n */\nfunction makeNodeErrorWithCode(Base, key) {\n  // @ts-expect-error It’s a Node error.\n  return NodeError\n  /**\n   * @param {Array<unknown>} args\n   */\n  function NodeError(...args) {\n    const limit = Error.stackTraceLimit;\n    if (isErrorStackTraceLimitWritable()) Error.stackTraceLimit = 0;\n    const error = new Base();\n    // Reset the limit and setting the name property.\n    if (isErrorStackTraceLimitWritable()) Error.stackTraceLimit = limit;\n    const message = getMessage(key, args, error);\n    Object.defineProperties(error, {\n      // Note: no need to implement `kIsNodeError` symbol, would be hard,\n      // probably.\n      message: {\n        value: message,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      },\n      toString: {\n        /** @this {Error} */\n        value() {\n          return `${this.name} [${key}]: ${this.message}`\n        },\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n\n    captureLargerStackTrace(error);\n    // @ts-expect-error It’s a Node error.\n    error.code = key;\n    return error\n  }\n}\n\n/**\n * @returns {boolean}\n */\nfunction isErrorStackTraceLimitWritable() {\n  // Do no touch Error.stackTraceLimit as V8 would attempt to install\n  // it again during deserialization.\n  try {\n    // @ts-expect-error: not in types?\n    if (v8.startupSnapshot.isBuildingSnapshot()) {\n      return false\n    }\n  } catch {}\n\n  const desc = Object.getOwnPropertyDescriptor(Error, 'stackTraceLimit');\n  if (desc === undefined) {\n    return Object.isExtensible(Error)\n  }\n\n  return own$1.call(desc, 'writable') && desc.writable !== undefined\n    ? desc.writable\n    : desc.set !== undefined\n}\n\n/**\n * This function removes unnecessary frames from Node.js core errors.\n * @template {(...args: unknown[]) => unknown} T\n * @param {T} fn\n * @returns {T}\n */\nfunction hideStackFrames(fn) {\n  // We rename the functions that will be hidden to cut off the stacktrace\n  // at the outermost one\n  const hidden = nodeInternalPrefix + fn.name;\n  Object.defineProperty(fn, 'name', {value: hidden});\n  return fn\n}\n\nconst captureLargerStackTrace = hideStackFrames(\n  /**\n   * @param {Error} error\n   * @returns {Error}\n   */\n  // @ts-expect-error: fine\n  function (error) {\n    const stackTraceLimitIsWritable = isErrorStackTraceLimitWritable();\n    if (stackTraceLimitIsWritable) {\n      userStackTraceLimit = Error.stackTraceLimit;\n      Error.stackTraceLimit = Number.POSITIVE_INFINITY;\n    }\n\n    Error.captureStackTrace(error);\n\n    // Reset the limit\n    if (stackTraceLimitIsWritable) Error.stackTraceLimit = userStackTraceLimit;\n\n    return error\n  }\n);\n\n/**\n * @param {string} key\n * @param {Array<unknown>} args\n * @param {Error} self\n * @returns {string}\n */\nfunction getMessage(key, args, self) {\n  const message = messages.get(key);\n  assert$1(typeof message !== 'undefined', 'expected `message` to be found');\n\n  if (typeof message === 'function') {\n    assert$1(\n      message.length <= args.length, // Default options do not count.\n      `Code: ${key}; The provided arguments length (${args.length}) does not ` +\n        `match the required ones (${message.length}).`\n    );\n    return Reflect.apply(message, self, args)\n  }\n\n  const regex = /%[dfijoOs]/g;\n  let expectedLength = 0;\n  while (regex.exec(message) !== null) expectedLength++;\n  assert$1(\n    expectedLength === args.length,\n    `Code: ${key}; The provided arguments length (${args.length}) does not ` +\n      `match the required ones (${expectedLength}).`\n  );\n  if (args.length === 0) return message\n\n  args.unshift(message);\n  return Reflect.apply(format$2, null, args)\n}\npathToFileURL(process.cwd());\n\nconst ESM_STATIC_IMPORT_RE = /(?<=\\s|^|;)import\\s*([\\s\"']*(?<imports>[\\w\\t\\n\\r $*,/{}]+)from\\s*)?[\"']\\s*(?<specifier>(?<=\"\\s*)[^\"]*[^\\s\"](?=\\s*\")|(?<='\\s*)[^']*[^\\s'](?=\\s*'))\\s*[\"'][\\s;]*/gm;\nconst TYPE_RE = /^\\s*?type\\s/;\nfunction findStaticImports(code) {\n  return matchAll(ESM_STATIC_IMPORT_RE, code, { type: \"static\" });\n}\nfunction parseStaticImport(matched) {\n  const cleanedImports = (matched.imports || \"\").replace(/(\\/\\/[^\\n]*\\n|\\/\\*.*\\*\\/)/g, \"\").replace(/\\s+/g, \" \");\n  const namedImports = {};\n  for (const namedImport of cleanedImports.match(/{([^}]*)}/)?.[1]?.split(\",\") || []) {\n    const [, source = namedImport.trim(), importName = source] = namedImport.match(/^\\s*(\\S*) as (\\S*)\\s*$/) || [];\n    if (source && !TYPE_RE.test(source)) {\n      namedImports[source] = importName;\n    }\n  }\n  const topLevelImports = cleanedImports.replace(/{([^}]*)}/, \"\");\n  const namespacedImport = topLevelImports.match(/\\* as \\s*(\\S*)/)?.[1];\n  const defaultImport = topLevelImports.split(\",\").find((index) => !/[*{}]/.test(index))?.trim() || void 0;\n  return {\n    ...matched,\n    defaultImport,\n    namespacedImport,\n    namedImports\n  };\n}\n\nconst ESM_RE = /([\\s;]|^)(import[\\s\\w*,{}]*from|import\\s*[\"'*{]|export\\b\\s*(?:[*{]|default|class|type|function|const|var|let|async function)|import\\.meta\\b)/m;\nfunction hasESMSyntax(code) {\n  return ESM_RE.test(code);\n}\n\nconst isDebug$5 = process.env.DEBUG;\nconst debug$d = createDebugger('vite:resolve-details', {\n    onlyWhenFocused: true,\n});\nfunction invalidatePackageData(packageCache, pkgPath) {\n    packageCache.delete(pkgPath);\n    const pkgDir = path$o.dirname(pkgPath);\n    packageCache.forEach((pkg, cacheKey) => {\n        if (pkg.dir === pkgDir) {\n            packageCache.delete(cacheKey);\n        }\n    });\n}\nfunction resolvePackageData(id, basedir, preserveSymlinks = false, packageCache) {\n    let pkg;\n    let cacheKey;\n    if (packageCache) {\n        cacheKey = `${id}&${basedir}&${preserveSymlinks}`;\n        if ((pkg = packageCache.get(cacheKey))) {\n            return pkg;\n        }\n    }\n    let pkgPath;\n    try {\n        pkgPath = resolveFrom(`${id}/package.json`, basedir, preserveSymlinks);\n        pkg = loadPackageData(pkgPath, true, packageCache);\n        if (packageCache) {\n            packageCache.set(cacheKey, pkg);\n        }\n        return pkg;\n    }\n    catch (e) {\n        if (e instanceof SyntaxError) {\n            isDebug$5 && debug$d(`Parsing failed: ${pkgPath}`);\n        }\n        // Ignore error for missing package.json\n        else if (e.code !== 'MODULE_NOT_FOUND') {\n            throw e;\n        }\n    }\n    return null;\n}\nfunction loadPackageData(pkgPath, preserveSymlinks, packageCache) {\n    if (!preserveSymlinks) {\n        pkgPath = fs$l.realpathSync.native(pkgPath);\n    }\n    let cached;\n    if ((cached = packageCache?.get(pkgPath))) {\n        return cached;\n    }\n    const data = JSON.parse(fs$l.readFileSync(pkgPath, 'utf-8'));\n    const pkgDir = path$o.dirname(pkgPath);\n    const { sideEffects } = data;\n    let hasSideEffects;\n    if (typeof sideEffects === 'boolean') {\n        hasSideEffects = () => sideEffects;\n    }\n    else if (Array.isArray(sideEffects)) {\n        const finalPackageSideEffects = sideEffects.map((sideEffect) => {\n            /*\n             * The array accepts simple glob patterns to the relevant files... Patterns like *.css, which do not include a /, will be treated like **\\/*.css.\n             * https://webpack.js.org/guides/tree-shaking/\n             * https://github.com/vitejs/vite/pull/11807\n             */\n            if (sideEffect.includes('/')) {\n                return sideEffect;\n            }\n            return `**/${sideEffect}`;\n        });\n        hasSideEffects = createFilter(finalPackageSideEffects, null, {\n            resolve: pkgDir,\n        });\n    }\n    else {\n        hasSideEffects = () => true;\n    }\n    const pkg = {\n        dir: pkgDir,\n        data,\n        hasSideEffects,\n        webResolvedImports: {},\n        nodeResolvedImports: {},\n        setResolvedCache(key, entry, targetWeb) {\n            if (targetWeb) {\n                pkg.webResolvedImports[key] = entry;\n            }\n            else {\n                pkg.nodeResolvedImports[key] = entry;\n            }\n        },\n        getResolvedCache(key, targetWeb) {\n            if (targetWeb) {\n                return pkg.webResolvedImports[key];\n            }\n            else {\n                return pkg.nodeResolvedImports[key];\n            }\n        },\n    };\n    packageCache?.set(pkgPath, pkg);\n    return pkg;\n}\nfunction watchPackageDataPlugin(config) {\n    const watchQueue = new Set();\n    let watchFile = (id) => {\n        watchQueue.add(id);\n    };\n    const { packageCache } = config;\n    const setPackageData = packageCache.set.bind(packageCache);\n    packageCache.set = (id, pkg) => {\n        if (id.endsWith('.json')) {\n            watchFile(id);\n        }\n        return setPackageData(id, pkg);\n    };\n    return {\n        name: 'vite:watch-package-data',\n        buildStart() {\n            watchFile = this.addWatchFile;\n            watchQueue.forEach(watchFile);\n            watchQueue.clear();\n        },\n        buildEnd() {\n            watchFile = (id) => watchQueue.add(id);\n        },\n        watchChange(id) {\n            if (id.endsWith('/package.json')) {\n                invalidatePackageData(packageCache, id);\n            }\n        },\n    };\n}\n\nconst WORKER_FILE_ID = 'worker_file';\nconst workerCache = new WeakMap();\nfunction isWorkerRequest(id) {\n    const query = parseRequest(id);\n    if (query && query[WORKER_FILE_ID] != null) {\n        return true;\n    }\n    return false;\n}\nfunction saveEmitWorkerAsset(config, asset) {\n    const fileName = asset.fileName;\n    const workerMap = workerCache.get(config.mainConfig || config);\n    workerMap.assets.set(fileName, asset);\n}\n// Ensure that only one rollup build is called at the same time to avoid\n// leaking state in plugins between worker builds.\n// TODO: Review if we can parallelize the bundling of workers.\nconst workerConfigSemaphore = new WeakMap();\nasync function bundleWorkerEntry(config, id, query) {\n    const processing = workerConfigSemaphore.get(config);\n    if (processing) {\n        await processing;\n        return bundleWorkerEntry(config, id, query);\n    }\n    const promise = serialBundleWorkerEntry(config, id, query);\n    workerConfigSemaphore.set(config, promise);\n    promise.then(() => workerConfigSemaphore.delete(config));\n    return promise;\n}\nasync function serialBundleWorkerEntry(config, id, query) {\n    // bundle the file as entry to support imports\n    const { rollup } = await import('rollup');\n    const { plugins, rollupOptions, format } = config.worker;\n    const bundle = await rollup({\n        ...rollupOptions,\n        input: cleanUrl(id),\n        plugins,\n        onwarn(warning, warn) {\n            onRollupWarning(warning, warn, config);\n        },\n        preserveEntrySignatures: false,\n    });\n    let chunk;\n    try {\n        const workerOutputConfig = config.worker.rollupOptions.output;\n        const workerConfig = workerOutputConfig\n            ? Array.isArray(workerOutputConfig)\n                ? workerOutputConfig[0] || {}\n                : workerOutputConfig\n            : {};\n        const { output: [outputChunk, ...outputChunks], } = await bundle.generate({\n            entryFileNames: path$o.posix.join(config.build.assetsDir, '[name]-[hash].js'),\n            chunkFileNames: path$o.posix.join(config.build.assetsDir, '[name]-[hash].js'),\n            assetFileNames: path$o.posix.join(config.build.assetsDir, '[name]-[hash].[ext]'),\n            ...workerConfig,\n            format,\n            sourcemap: config.build.sourcemap,\n        });\n        chunk = outputChunk;\n        outputChunks.forEach((outputChunk) => {\n            if (outputChunk.type === 'asset') {\n                saveEmitWorkerAsset(config, outputChunk);\n            }\n            else if (outputChunk.type === 'chunk') {\n                saveEmitWorkerAsset(config, {\n                    fileName: outputChunk.fileName,\n                    source: outputChunk.code,\n                    type: 'asset',\n                });\n            }\n        });\n    }\n    finally {\n        await bundle.close();\n    }\n    return emitSourcemapForWorkerEntry(config, query, chunk);\n}\nfunction emitSourcemapForWorkerEntry(config, query, chunk) {\n    const { map: sourcemap } = chunk;\n    if (sourcemap) {\n        if (config.build.sourcemap === 'hidden' ||\n            config.build.sourcemap === true) {\n            const data = sourcemap.toString();\n            const mapFileName = chunk.fileName + '.map';\n            saveEmitWorkerAsset(config, {\n                fileName: mapFileName,\n                type: 'asset',\n                source: data,\n            });\n        }\n    }\n    return chunk;\n}\nconst workerAssetUrlRE = /__VITE_WORKER_ASSET__([a-z\\d]{8})__/g;\nfunction encodeWorkerAssetFileName(fileName, workerCache) {\n    const { fileNameHash } = workerCache;\n    const hash = getHash(fileName);\n    if (!fileNameHash.get(hash)) {\n        fileNameHash.set(hash, fileName);\n    }\n    return `__VITE_WORKER_ASSET__${hash}__`;\n}\nasync function workerFileToUrl(config, id, query) {\n    const workerMap = workerCache.get(config.mainConfig || config);\n    let fileName = workerMap.bundle.get(id);\n    if (!fileName) {\n        const outputChunk = await bundleWorkerEntry(config, id, query);\n        fileName = outputChunk.fileName;\n        saveEmitWorkerAsset(config, {\n            fileName,\n            source: outputChunk.code,\n            type: 'asset',\n        });\n        workerMap.bundle.set(id, fileName);\n    }\n    return encodeWorkerAssetFileName(fileName, workerMap);\n}\nfunction webWorkerPlugin(config) {\n    const isBuild = config.command === 'build';\n    let server;\n    const isWorker = config.isWorker;\n    return {\n        name: 'vite:worker',\n        configureServer(_server) {\n            server = _server;\n        },\n        buildStart() {\n            if (isWorker) {\n                return;\n            }\n            workerCache.set(config, {\n                assets: new Map(),\n                bundle: new Map(),\n                fileNameHash: new Map(),\n            });\n        },\n        load(id) {\n            if (isBuild) {\n                const parsedQuery = parseRequest(id);\n                if (parsedQuery &&\n                    (parsedQuery.worker ?? parsedQuery.sharedworker) != null) {\n                    return '';\n                }\n            }\n        },\n        async transform(raw, id, options) {\n            const ssr = options?.ssr === true;\n            const query = parseRequest(id);\n            if (query && query[WORKER_FILE_ID] != null) {\n                // if import worker by worker constructor will have query.type\n                // other type will be import worker by esm\n                const workerType = query['type'];\n                let injectEnv = '';\n                if (workerType === 'classic') {\n                    injectEnv = `importScripts('${ENV_PUBLIC_PATH}')\\n`;\n                }\n                else if (workerType === 'module') {\n                    injectEnv = `import '${ENV_PUBLIC_PATH}'\\n`;\n                }\n                else if (workerType === 'ignore') {\n                    if (isBuild) {\n                        injectEnv = '';\n                    }\n                    else if (server) {\n                        // dynamic worker type we can't know how import the env\n                        // so we copy /@vite/env code of server transform result into file header\n                        const { moduleGraph } = server;\n                        const module = moduleGraph.getModuleById(ENV_ENTRY);\n                        injectEnv = module?.transformResult?.code || '';\n                    }\n                }\n                return {\n                    code: injectEnv + raw,\n                };\n            }\n            if (query == null ||\n                (query && (query.worker ?? query.sharedworker) == null)) {\n                return;\n            }\n            // stringified url or `new URL(...)`\n            let url;\n            const { format } = config.worker;\n            const workerConstructor = query.sharedworker != null ? 'SharedWorker' : 'Worker';\n            const workerType = isBuild\n                ? format === 'es'\n                    ? 'module'\n                    : 'classic'\n                : 'module';\n            const workerOptions = workerType === 'classic' ? '' : ',{type: \"module\"}';\n            if (isBuild) {\n                getDepsOptimizer(config, ssr)?.registerWorkersSource(id);\n                if (query.inline != null) {\n                    const chunk = await bundleWorkerEntry(config, id, query);\n                    // inline as blob data url\n                    return {\n                        code: `const encodedJs = \"${Buffer.from(chunk.code).toString('base64')}\";\n            const blob = typeof window !== \"undefined\" && window.Blob && new Blob([atob(encodedJs)], { type: \"text/javascript;charset=utf-8\" });\n            export default function WorkerWrapper() {\n              const objURL = blob && (window.URL || window.webkitURL).createObjectURL(blob);\n              try {\n                return objURL ? new ${workerConstructor}(objURL) : new ${workerConstructor}(\"data:application/javascript;base64,\" + encodedJs${workerOptions});\n              } finally {\n                objURL && (window.URL || window.webkitURL).revokeObjectURL(objURL);\n              }\n            }`,\n                        // Empty sourcemap to suppress Rollup warning\n                        map: { mappings: '' },\n                    };\n                }\n                else {\n                    url = await workerFileToUrl(config, id, query);\n                }\n            }\n            else {\n                url = await fileToUrl(cleanUrl(id), config, this);\n                url = injectQuery(url, WORKER_FILE_ID);\n                url = injectQuery(url, `type=${workerType}`);\n            }\n            if (query.url != null) {\n                return {\n                    code: `export default ${JSON.stringify(url)}`,\n                    map: { mappings: '' }, // Empty sourcemap to suppress Rollup warning\n                };\n            }\n            return {\n                code: `export default function WorkerWrapper() {\n          return new ${workerConstructor}(${JSON.stringify(url)}${workerOptions})\n        }`,\n                map: { mappings: '' }, // Empty sourcemap to suppress Rollup warning\n            };\n        },\n        renderChunk(code, chunk, outputOptions) {\n            let s;\n            const result = () => {\n                return (s && {\n                    code: s.toString(),\n                    map: config.build.sourcemap ? s.generateMap({ hires: true }) : null,\n                });\n            };\n            if (code.match(workerAssetUrlRE) || code.includes('import.meta.url')) {\n                const toRelativeRuntime = createToImportMetaURLBasedRelativeRuntime(outputOptions.format);\n                let match;\n                s = new MagicString(code);\n                workerAssetUrlRE.lastIndex = 0;\n                // Replace \"__VITE_WORKER_ASSET__5aa0ddc0__\" using relative paths\n                const workerMap = workerCache.get(config.mainConfig || config);\n                const { fileNameHash } = workerMap;\n                while ((match = workerAssetUrlRE.exec(code))) {\n                    const [full, hash] = match;\n                    const filename = fileNameHash.get(hash);\n                    const replacement = toOutputFilePathInJS(filename, 'asset', chunk.fileName, 'js', config, toRelativeRuntime);\n                    const replacementString = typeof replacement === 'string'\n                        ? JSON.stringify(replacement).slice(1, -1)\n                        : `\"+${replacement.runtime}+\"`;\n                    s.update(match.index, match.index + full.length, replacementString);\n                }\n            }\n            return result();\n        },\n        generateBundle(opts) {\n            // @ts-expect-error asset emits are skipped in legacy bundle\n            if (opts.__vite_skip_asset_emit__ || isWorker) {\n                return;\n            }\n            const workerMap = workerCache.get(config);\n            workerMap.assets.forEach((asset) => {\n                this.emitFile(asset);\n                workerMap.assets.delete(asset.fileName);\n            });\n        },\n    };\n}\n\nconst normalizedClientEntry$1 = normalizePath$3(CLIENT_ENTRY);\nconst normalizedEnvEntry$1 = normalizePath$3(ENV_ENTRY);\n// special id for paths marked with browser: false\n// https://github.com/defunctzombie/package-browser-field-spec#ignore-a-module\nconst browserExternalId = '__vite-browser-external';\n// special id for packages that are optional peer deps\nconst optionalPeerDepId = '__vite-optional-peer-dep';\nconst nodeModulesInPathRE = /(?:^|\\/)node_modules\\//;\nconst isDebug$4 = process.env.DEBUG;\nconst debug$c = createDebugger('vite:resolve-details', {\n    onlyWhenFocused: true,\n});\nfunction resolvePlugin(resolveOptions) {\n    const { root, isProduction, asSrc, ssrConfig, preferRelative = false, } = resolveOptions;\n    const { target: ssrTarget, noExternal: ssrNoExternal } = ssrConfig ?? {};\n    return {\n        name: 'vite:resolve',\n        async resolveId(id, importer, resolveOpts) {\n            const ssr = resolveOpts?.ssr === true;\n            // We need to delay depsOptimizer until here instead of passing it as an option\n            // the resolvePlugin because the optimizer is created on server listen during dev\n            const depsOptimizer = resolveOptions.getDepsOptimizer?.(ssr);\n            if (id.startsWith(browserExternalId)) {\n                return id;\n            }\n            const targetWeb = !ssr || ssrTarget === 'webworker';\n            // this is passed by @rollup/plugin-commonjs\n            const isRequire = resolveOpts?.custom?.['node-resolve']?.isRequire ?? false;\n            const options = {\n                isRequire,\n                ...resolveOptions,\n                scan: resolveOpts?.scan ?? resolveOptions.scan,\n            };\n            if (importer) {\n                const _importer = isWorkerRequest(importer)\n                    ? splitFileAndPostfix(importer).file\n                    : importer;\n                if (isTsRequest(_importer) ||\n                    resolveOpts.custom?.depScan?.loader?.startsWith('ts')) {\n                    options.isFromTsImporter = true;\n                }\n                else {\n                    const moduleLang = this.getModuleInfo(_importer)?.meta?.vite?.lang;\n                    options.isFromTsImporter = moduleLang && isTsRequest(`.${moduleLang}`);\n                }\n            }\n            let res;\n            // resolve pre-bundled deps requests, these could be resolved by\n            // tryFileResolve or /fs/ resolution but these files may not yet\n            // exists if we are in the middle of a deps re-processing\n            if (asSrc && depsOptimizer?.isOptimizedDepUrl(id)) {\n                const optimizedPath = id.startsWith(FS_PREFIX)\n                    ? fsPathFromId(id)\n                    : normalizePath$3(ensureVolumeInPath(path$o.resolve(root, id.slice(1))));\n                return optimizedPath;\n            }\n            const ensureVersionQuery = (resolved) => {\n                if (!options.isBuild &&\n                    !options.scan &&\n                    depsOptimizer &&\n                    !(resolved === normalizedClientEntry$1 ||\n                        resolved === normalizedEnvEntry$1)) {\n                    // Ensure that direct imports of node_modules have the same version query\n                    // as if they would have been imported through a bare import\n                    // Use the original id to do the check as the resolved id may be the real\n                    // file path after symlinks resolution\n                    const isNodeModule = nodeModulesInPathRE.test(normalizePath$3(id)) ||\n                        nodeModulesInPathRE.test(normalizePath$3(resolved));\n                    if (isNodeModule && !resolved.match(DEP_VERSION_RE)) {\n                        const versionHash = depsOptimizer.metadata.browserHash;\n                        if (versionHash && isOptimizable(resolved, depsOptimizer.options)) {\n                            resolved = injectQuery(resolved, `v=${versionHash}`);\n                        }\n                    }\n                }\n                return resolved;\n            };\n            // explicit fs paths that starts with /@fs/*\n            if (asSrc && id.startsWith(FS_PREFIX)) {\n                const fsPath = fsPathFromId(id);\n                res = tryFsResolve(fsPath, options);\n                isDebug$4 && debug$c(`[@fs] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(res)}`);\n                // always return here even if res doesn't exist since /@fs/ is explicit\n                // if the file doesn't exist it should be a 404\n                return ensureVersionQuery(res || fsPath);\n            }\n            // URL\n            // /foo -> /fs-root/foo\n            if (asSrc && id.startsWith('/')) {\n                const fsPath = path$o.resolve(root, id.slice(1));\n                if ((res = tryFsResolve(fsPath, options))) {\n                    isDebug$4 && debug$c(`[url] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(res)}`);\n                    return ensureVersionQuery(res);\n                }\n            }\n            // relative\n            if (id.startsWith('.') ||\n                ((preferRelative || importer?.endsWith('.html')) && /^\\w/.test(id))) {\n                const basedir = importer ? path$o.dirname(importer) : process.cwd();\n                const fsPath = path$o.resolve(basedir, id);\n                // handle browser field mapping for relative imports\n                const normalizedFsPath = normalizePath$3(fsPath);\n                if (depsOptimizer?.isOptimizedDepFile(normalizedFsPath)) {\n                    // Optimized files could not yet exist in disk, resolve to the full path\n                    // Inject the current browserHash version if the path doesn't have one\n                    if (!normalizedFsPath.match(DEP_VERSION_RE)) {\n                        const browserHash = optimizedDepInfoFromFile(depsOptimizer.metadata, normalizedFsPath)?.browserHash;\n                        if (browserHash) {\n                            return injectQuery(normalizedFsPath, `v=${browserHash}`);\n                        }\n                    }\n                    return normalizedFsPath;\n                }\n                if (targetWeb &&\n                    options.browserField &&\n                    (res = tryResolveBrowserMapping(fsPath, importer, options, true))) {\n                    return res;\n                }\n                if ((res = tryFsResolve(fsPath, options))) {\n                    res = ensureVersionQuery(res);\n                    isDebug$4 &&\n                        debug$c(`[relative] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(res)}`);\n                    const pkg = importer != null && idToPkgMap.get(importer);\n                    if (pkg) {\n                        idToPkgMap.set(res, pkg);\n                        return {\n                            id: res,\n                            moduleSideEffects: pkg.hasSideEffects(res),\n                        };\n                    }\n                    return res;\n                }\n            }\n            // drive relative fs paths (only windows)\n            if (isWindows$4 && id.startsWith('/')) {\n                const basedir = importer ? path$o.dirname(importer) : process.cwd();\n                const fsPath = path$o.resolve(basedir, id);\n                if ((res = tryFsResolve(fsPath, options))) {\n                    isDebug$4 &&\n                        debug$c(`[drive-relative] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(res)}`);\n                    return ensureVersionQuery(res);\n                }\n            }\n            // absolute fs paths\n            if (isNonDriveRelativeAbsolutePath(id) &&\n                (res = tryFsResolve(id, options))) {\n                isDebug$4 && debug$c(`[fs] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(res)}`);\n                return ensureVersionQuery(res);\n            }\n            // external\n            if (isExternalUrl(id)) {\n                return {\n                    id,\n                    external: true,\n                };\n            }\n            // data uri: pass through (this only happens during build and will be\n            // handled by dedicated plugin)\n            if (isDataUrl(id)) {\n                return null;\n            }\n            // bare package imports, perform node resolve\n            if (bareImportRE.test(id)) {\n                const external = options.shouldExternalize?.(id);\n                if (!external &&\n                    asSrc &&\n                    depsOptimizer &&\n                    !options.scan &&\n                    (res = await tryOptimizedResolve(depsOptimizer, id, importer))) {\n                    return res;\n                }\n                if (targetWeb &&\n                    options.browserField &&\n                    (res = tryResolveBrowserMapping(id, importer, options, false, external))) {\n                    return res;\n                }\n                if ((res = tryNodeResolve(id, importer, options, targetWeb, depsOptimizer, ssr, external))) {\n                    return res;\n                }\n                // node built-ins.\n                // externalize if building for SSR, otherwise redirect to empty module\n                if (isBuiltin(id)) {\n                    if (ssr) {\n                        if (ssrNoExternal === true) {\n                            let message = `Cannot bundle Node.js built-in \"${id}\"`;\n                            if (importer) {\n                                message += ` imported from \"${path$o.relative(process.cwd(), importer)}\"`;\n                            }\n                            message += `. Consider disabling ssr.noExternal or remove the built-in dependency.`;\n                            this.error(message);\n                        }\n                        return {\n                            id,\n                            external: true,\n                        };\n                    }\n                    else {\n                        if (!asSrc) {\n                            debug$c(`externalized node built-in \"${id}\" to empty module. ` +\n                                `(imported by: ${picocolorsExports.white(picocolorsExports.dim(importer))})`);\n                        }\n                        return isProduction\n                            ? browserExternalId\n                            : `${browserExternalId}:${id}`;\n                    }\n                }\n            }\n            isDebug$4 && debug$c(`[fallthrough] ${picocolorsExports.dim(id)}`);\n        },\n        load(id) {\n            if (id.startsWith(browserExternalId)) {\n                if (isProduction) {\n                    return `export default {}`;\n                }\n                else {\n                    id = id.slice(browserExternalId.length + 1);\n                    return `\\\nexport default new Proxy({}, {\n  get(_, key) {\n    throw new Error(\\`Module \"${id}\" has been externalized for browser compatibility. Cannot access \"${id}.\\${key}\" in client code.  See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.\\`)\n  }\n})`;\n                }\n            }\n            if (id.startsWith(optionalPeerDepId)) {\n                if (isProduction) {\n                    return `export default {}`;\n                }\n                else {\n                    const [, peerDep, parentDep] = id.split(':');\n                    return `throw new Error(\\`Could not resolve \"${peerDep}\" imported by \"${parentDep}\". Is it installed?\\`)`;\n                }\n            }\n        },\n    };\n}\nfunction splitFileAndPostfix(path) {\n    let file = path;\n    let postfix = '';\n    let postfixIndex = path.indexOf('?');\n    if (postfixIndex < 0) {\n        postfixIndex = path.indexOf('#');\n    }\n    if (postfixIndex > 0) {\n        file = path.slice(0, postfixIndex);\n        postfix = path.slice(postfixIndex);\n    }\n    return { file, postfix };\n}\nfunction tryFsResolve(fsPath, options, tryIndex = true, targetWeb = true) {\n    const { file, postfix } = splitFileAndPostfix(fsPath);\n    let res;\n    // if there is a postfix, try resolving it as a complete path first (#4703)\n    if (postfix &&\n        (res = tryResolveFile(fsPath, '', options, false, targetWeb, options.tryPrefix, options.skipPackageJson))) {\n        return res;\n    }\n    if ((res = tryResolveFile(file, postfix, options, false, targetWeb, options.tryPrefix, options.skipPackageJson))) {\n        return res;\n    }\n    for (const ext of options.extensions) {\n        if (postfix &&\n            (res = tryResolveFile(fsPath + ext, '', options, false, targetWeb, options.tryPrefix, options.skipPackageJson, false))) {\n            return res;\n        }\n        if ((res = tryResolveFile(file + ext, postfix, options, false, targetWeb, options.tryPrefix, options.skipPackageJson, false))) {\n            return res;\n        }\n    }\n    // if `tryIndex` false, skip as we've already tested above\n    if (!tryIndex)\n        return;\n    if (postfix &&\n        (res = tryResolveFile(fsPath, '', options, tryIndex, targetWeb, options.tryPrefix, options.skipPackageJson))) {\n        return res;\n    }\n    if ((res = tryResolveFile(file, postfix, options, tryIndex, targetWeb, options.tryPrefix, options.skipPackageJson))) {\n        return res;\n    }\n}\nfunction tryResolveFile(file, postfix, options, tryIndex, targetWeb, tryPrefix, skipPackageJson, skipTsExtension) {\n    let stat;\n    try {\n        stat = fs$l.statSync(file, { throwIfNoEntry: false });\n    }\n    catch {\n        return;\n    }\n    if (stat) {\n        if (!stat.isDirectory()) {\n            return getRealPath(file, options.preserveSymlinks) + postfix;\n        }\n        else if (tryIndex) {\n            if (!skipPackageJson) {\n                const pkgPath = file + '/package.json';\n                try {\n                    // path points to a node package\n                    const pkg = loadPackageData(pkgPath, options.preserveSymlinks);\n                    const resolved = resolvePackageEntry(file, pkg, targetWeb, options);\n                    return resolved;\n                }\n                catch (e) {\n                    if (e.code !== 'ENOENT') {\n                        throw e;\n                    }\n                }\n            }\n            const index = tryFsResolve(file + '/index', options);\n            if (index)\n                return index + postfix;\n        }\n    }\n    // try resolve .js import to typescript file\n    if (!skipTsExtension &&\n        options.isFromTsImporter &&\n        isPossibleTsOutput(file)) {\n        const tsSrcPaths = getPotentialTsSrcPaths(file);\n        for (const srcPath of tsSrcPaths) {\n            const res = tryResolveFile(srcPath, postfix, options, tryIndex, targetWeb, tryPrefix, skipPackageJson, true);\n            if (res)\n                return res;\n        }\n        return;\n    }\n    if (tryPrefix) {\n        const prefixed = `${path$o.dirname(file)}/${tryPrefix}${path$o.basename(file)}`;\n        return tryResolveFile(prefixed, postfix, options, tryIndex, targetWeb);\n    }\n}\nconst idToPkgMap = new Map();\nfunction tryNodeResolve(id, importer, options, targetWeb, depsOptimizer, ssr, externalize, allowLinkedExternal = true) {\n    const { root, dedupe, isBuild, preserveSymlinks, packageCache } = options;\n    ssr ?? (ssr = false);\n    // split id by last '>' for nested selected packages, for example:\n    // 'foo > bar > baz' => 'foo > bar' & 'baz'\n    // 'foo'             => ''          & 'foo'\n    const lastArrowIndex = id.lastIndexOf('>');\n    const nestedRoot = id.substring(0, lastArrowIndex).trim();\n    const nestedPath = id.substring(lastArrowIndex + 1).trim();\n    const possiblePkgIds = [];\n    for (let prevSlashIndex = -1;;) {\n        let slashIndex = nestedPath.indexOf('/', prevSlashIndex + 1);\n        if (slashIndex < 0) {\n            slashIndex = nestedPath.length;\n        }\n        const part = nestedPath.slice(prevSlashIndex + 1, (prevSlashIndex = slashIndex));\n        if (!part) {\n            break;\n        }\n        // Assume path parts with an extension are not package roots, except for the\n        // first path part (since periods are sadly allowed in package names).\n        // At the same time, skip the first path part if it begins with \"@\"\n        // (since \"@foo/bar\" should be treated as the top-level path).\n        if (possiblePkgIds.length ? path$o.extname(part) : part[0] === '@') {\n            continue;\n        }\n        const possiblePkgId = nestedPath.slice(0, slashIndex);\n        possiblePkgIds.push(possiblePkgId);\n    }\n    let basedir;\n    if (dedupe?.some((id) => possiblePkgIds.includes(id))) {\n        basedir = root;\n    }\n    else if (importer &&\n        path$o.isAbsolute(importer) &&\n        fs$l.existsSync(cleanUrl(importer))) {\n        basedir = path$o.dirname(importer);\n    }\n    else {\n        basedir = root;\n    }\n    // nested node module, step-by-step resolve to the basedir of the nestedPath\n    if (nestedRoot) {\n        basedir = nestedResolveFrom(nestedRoot, basedir, preserveSymlinks);\n    }\n    let pkg;\n    let pkgId;\n    // nearest package.json\n    let nearestPkg;\n    const rootPkgId = possiblePkgIds[0];\n    const rootPkg = resolvePackageData(rootPkgId, basedir, preserveSymlinks, packageCache);\n    const nearestPkgId = [...possiblePkgIds].reverse().find((pkgId) => {\n        nearestPkg = resolvePackageData(pkgId, basedir, preserveSymlinks, packageCache);\n        return nearestPkg;\n    });\n    if (rootPkg?.data?.exports) {\n        pkgId = rootPkgId;\n        pkg = rootPkg;\n    }\n    else {\n        pkgId = nearestPkgId;\n        pkg = nearestPkg;\n    }\n    if (!pkg || !nearestPkg) {\n        // if import can't be found, check if it's an optional peer dep.\n        // if so, we can resolve to a special id that errors only when imported.\n        if (basedir !== root && // root has no peer dep\n            !isBuiltin(nestedPath) &&\n            !nestedPath.includes('\\0') &&\n            bareImportRE.test(nestedPath)) {\n            // find package.json with `name` as main\n            const mainPackageJson = lookupFile(basedir, ['package.json'], {\n                predicate: (content) => !!JSON.parse(content).name,\n            });\n            if (mainPackageJson) {\n                const mainPkg = JSON.parse(mainPackageJson);\n                if (mainPkg.peerDependencies?.[nestedPath] &&\n                    mainPkg.peerDependenciesMeta?.[nestedPath]?.optional) {\n                    return {\n                        id: `${optionalPeerDepId}:${nestedPath}:${mainPkg.name}`,\n                    };\n                }\n            }\n        }\n        return;\n    }\n    let resolveId = resolvePackageEntry;\n    let unresolvedId = pkgId;\n    const isDeepImport = unresolvedId !== nestedPath;\n    if (isDeepImport) {\n        resolveId = resolveDeepImport;\n        unresolvedId = '.' + nestedPath.slice(pkgId.length);\n    }\n    let resolved;\n    try {\n        resolved = resolveId(unresolvedId, pkg, targetWeb, options);\n    }\n    catch (err) {\n        if (!options.tryEsmOnly) {\n            throw err;\n        }\n    }\n    if (!resolved && options.tryEsmOnly) {\n        resolved = resolveId(unresolvedId, pkg, targetWeb, {\n            ...options,\n            isRequire: false,\n            mainFields: DEFAULT_MAIN_FIELDS,\n            extensions: DEFAULT_EXTENSIONS$1,\n        });\n    }\n    if (!resolved) {\n        return;\n    }\n    const processResult = (resolved) => {\n        if (!externalize) {\n            return resolved;\n        }\n        // don't external symlink packages\n        if (!allowLinkedExternal && !resolved.id.includes('node_modules')) {\n            return resolved;\n        }\n        const resolvedExt = path$o.extname(resolved.id);\n        // don't external non-js imports\n        if (resolvedExt &&\n            resolvedExt !== '.js' &&\n            resolvedExt !== '.mjs' &&\n            resolvedExt !== '.cjs') {\n            return resolved;\n        }\n        let resolvedId = id;\n        if (isDeepImport) {\n            if (!pkg?.data.exports && path$o.extname(id) !== resolvedExt) {\n                resolvedId = resolved.id.slice(resolved.id.indexOf(id));\n                isDebug$4 &&\n                    debug$c(`[processResult] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(resolvedId)}`);\n            }\n        }\n        return { ...resolved, id: resolvedId, external: true };\n    };\n    // link id to pkg for browser field mapping check\n    idToPkgMap.set(resolved, pkg);\n    if ((isBuild && !depsOptimizer) || externalize) {\n        // Resolve package side effects for build so that rollup can better\n        // perform tree-shaking\n        return processResult({\n            id: resolved,\n            moduleSideEffects: pkg.hasSideEffects(resolved),\n        });\n    }\n    const ext = path$o.extname(resolved);\n    const isCJS = ext === '.cjs' || (ext === '.js' && nearestPkg.data.type !== 'module');\n    if (!options.ssrOptimizeCheck &&\n        (!resolved.includes('node_modules') || // linked\n            !depsOptimizer || // resolving before listening to the server\n            options.scan) // initial esbuild scan phase\n    ) {\n        return { id: resolved };\n    }\n    // if we reach here, it's a valid dep import that hasn't been optimized.\n    const isJsType = depsOptimizer\n        ? isOptimizable(resolved, depsOptimizer.options)\n        : OPTIMIZABLE_ENTRY_RE.test(resolved);\n    let exclude = depsOptimizer?.options.exclude;\n    let include = depsOptimizer?.options.include;\n    if (options.ssrOptimizeCheck) {\n        // we don't have the depsOptimizer\n        exclude = options.ssrConfig?.optimizeDeps?.exclude;\n        include = options.ssrConfig?.optimizeDeps?.include;\n    }\n    const skipOptimization = !isJsType ||\n        importer?.includes('node_modules') ||\n        exclude?.includes(pkgId) ||\n        exclude?.includes(nestedPath) ||\n        SPECIAL_QUERY_RE.test(resolved) ||\n        // During dev SSR, we don't have a way to reload the module graph if\n        // a non-optimized dep is found. So we need to skip optimization here.\n        // The only optimized deps are the ones explicitly listed in the config.\n        (!options.ssrOptimizeCheck && !isBuild && ssr) ||\n        // Only optimize non-external CJS deps during SSR by default\n        (ssr &&\n            !isCJS &&\n            !(include?.includes(pkgId) || include?.includes(nestedPath)));\n    if (options.ssrOptimizeCheck) {\n        return {\n            id: skipOptimization\n                ? injectQuery(resolved, `__vite_skip_optimization`)\n                : resolved,\n        };\n    }\n    if (skipOptimization) {\n        // excluded from optimization\n        // Inject a version query to npm deps so that the browser\n        // can cache it without re-validation, but only do so for known js types.\n        // otherwise we may introduce duplicated modules for externalized files\n        // from pre-bundled deps.\n        if (!isBuild) {\n            const versionHash = depsOptimizer.metadata.browserHash;\n            if (versionHash && isJsType) {\n                resolved = injectQuery(resolved, `v=${versionHash}`);\n            }\n        }\n    }\n    else {\n        // this is a missing import, queue optimize-deps re-run and\n        // get a resolved its optimized info\n        const optimizedInfo = depsOptimizer.registerMissingImport(id, resolved);\n        resolved = depsOptimizer.getOptimizedDepId(optimizedInfo);\n    }\n    if (isBuild) {\n        // Resolve package side effects for build so that rollup can better\n        // perform tree-shaking\n        return {\n            id: resolved,\n            moduleSideEffects: pkg.hasSideEffects(resolved),\n        };\n    }\n    else {\n        return { id: resolved };\n    }\n}\nasync function tryOptimizedResolve(depsOptimizer, id, importer) {\n    // TODO: we need to wait until scanning is done here as this function\n    // is used in the preAliasPlugin to decide if an aliased dep is optimized,\n    // and avoid replacing the bare import with the resolved path.\n    // We should be able to remove this in the future\n    await depsOptimizer.scanProcessing;\n    const metadata = depsOptimizer.metadata;\n    const depInfo = optimizedDepInfoFromId(metadata, id);\n    if (depInfo) {\n        return depsOptimizer.getOptimizedDepId(depInfo);\n    }\n    if (!importer)\n        return;\n    // further check if id is imported by nested dependency\n    let resolvedSrc;\n    for (const optimizedData of metadata.depInfoList) {\n        if (!optimizedData.src)\n            continue; // Ignore chunks\n        const pkgPath = optimizedData.id;\n        // check for scenarios, e.g.\n        //   pkgPath  => \"my-lib > foo\"\n        //   id       => \"foo\"\n        // this narrows the need to do a full resolve\n        if (!pkgPath.endsWith(id))\n            continue;\n        // lazily initialize resolvedSrc\n        if (resolvedSrc == null) {\n            try {\n                // this may throw errors if unable to resolve, e.g. aliased id\n                resolvedSrc = normalizePath$3(resolveFrom(id, path$o.dirname(importer)));\n            }\n            catch {\n                // this is best-effort only so swallow errors\n                break;\n            }\n        }\n        // match by src to correctly identify if id belongs to nested dependency\n        if (optimizedData.src === resolvedSrc) {\n            return depsOptimizer.getOptimizedDepId(optimizedData);\n        }\n    }\n}\nfunction resolvePackageEntry(id, { dir, data, setResolvedCache, getResolvedCache }, targetWeb, options) {\n    const cached = getResolvedCache('.', targetWeb);\n    if (cached) {\n        return cached;\n    }\n    try {\n        let entryPoint;\n        // resolve exports field with highest priority\n        // using https://github.com/lukeed/resolve.exports\n        if (data.exports) {\n            entryPoint = resolveExports(data, '.', options, targetWeb);\n        }\n        const resolvedFromExports = !!entryPoint;\n        // if exports resolved to .mjs, still resolve other fields.\n        // This is because .mjs files can technically import .cjs files which would\n        // make them invalid for pure ESM environments - so if other module/browser\n        // fields are present, prioritize those instead.\n        if (targetWeb &&\n            options.browserField &&\n            (!entryPoint || entryPoint.endsWith('.mjs'))) {\n            // check browser field\n            // https://github.com/defunctzombie/package-browser-field-spec\n            const browserEntry = typeof data.browser === 'string'\n                ? data.browser\n                : isObject$1(data.browser) && data.browser['.'];\n            if (browserEntry) {\n                // check if the package also has a \"module\" field.\n                if (!options.isRequire &&\n                    options.mainFields.includes('module') &&\n                    typeof data.module === 'string' &&\n                    data.module !== browserEntry) {\n                    // if both are present, we may have a problem: some package points both\n                    // to ESM, with \"module\" targeting Node.js, while some packages points\n                    // \"module\" to browser ESM and \"browser\" to UMD/IIFE.\n                    // the heuristics here is to actually read the browser entry when\n                    // possible and check for hints of ESM. If it is not ESM, prefer \"module\"\n                    // instead; Otherwise, assume it's ESM and use it.\n                    const resolvedBrowserEntry = tryFsResolve(path$o.join(dir, browserEntry), options);\n                    if (resolvedBrowserEntry) {\n                        const content = fs$l.readFileSync(resolvedBrowserEntry, 'utf-8');\n                        if (hasESMSyntax(content)) {\n                            // likely ESM, prefer browser\n                            entryPoint = browserEntry;\n                        }\n                        else {\n                            // non-ESM, UMD or IIFE or CJS(!!! e.g. firebase 7.x), prefer module\n                            entryPoint = data.module;\n                        }\n                    }\n                }\n                else {\n                    entryPoint = browserEntry;\n                }\n            }\n        }\n        // fallback to mainFields if still not resolved\n        // TODO: review if `.mjs` check is still needed\n        if (!resolvedFromExports && (!entryPoint || entryPoint.endsWith('.mjs'))) {\n            for (const field of options.mainFields) {\n                if (field === 'browser')\n                    continue; // already checked above\n                if (typeof data[field] === 'string') {\n                    entryPoint = data[field];\n                    break;\n                }\n            }\n        }\n        entryPoint || (entryPoint = data.main);\n        // try default entry when entry is not define\n        // https://nodejs.org/api/modules.html#all-together\n        const entryPoints = entryPoint\n            ? [entryPoint]\n            : ['index.js', 'index.json', 'index.node'];\n        for (let entry of entryPoints) {\n            // make sure we don't get scripts when looking for sass\n            if (options.mainFields[0] === 'sass' &&\n                !options.extensions.includes(path$o.extname(entry))) {\n                entry = '';\n                options.skipPackageJson = true;\n            }\n            // resolve object browser field in package.json\n            const { browser: browserField } = data;\n            if (targetWeb && options.browserField && isObject$1(browserField)) {\n                entry = mapWithBrowserField(entry, browserField) || entry;\n            }\n            const entryPointPath = path$o.join(dir, entry);\n            const resolvedEntryPoint = tryFsResolve(entryPointPath, options);\n            if (resolvedEntryPoint) {\n                isDebug$4 &&\n                    debug$c(`[package entry] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(resolvedEntryPoint)}`);\n                setResolvedCache('.', resolvedEntryPoint, targetWeb);\n                return resolvedEntryPoint;\n            }\n        }\n    }\n    catch (e) {\n        packageEntryFailure(id, e.message);\n    }\n    packageEntryFailure(id);\n}\nfunction packageEntryFailure(id, details) {\n    throw new Error(`Failed to resolve entry for package \"${id}\". ` +\n        `The package may have incorrect main/module/exports specified in its package.json` +\n        (details ? ': ' + details : '.'));\n}\nconst conditionalConditions = new Set(['production', 'development', 'module']);\nfunction resolveExports(pkg, key, options, targetWeb) {\n    const overrideConditions = options.overrideConditions\n        ? new Set(options.overrideConditions)\n        : undefined;\n    const conditions = [];\n    if ((!overrideConditions || overrideConditions.has('production')) &&\n        options.isProduction) {\n        conditions.push('production');\n    }\n    if ((!overrideConditions || overrideConditions.has('development')) &&\n        !options.isProduction) {\n        conditions.push('development');\n    }\n    if ((!overrideConditions || overrideConditions.has('module')) &&\n        !options.isRequire) {\n        conditions.push('module');\n    }\n    if (options.overrideConditions) {\n        conditions.push(...options.overrideConditions.filter((condition) => conditionalConditions.has(condition)));\n    }\n    else if (options.conditions.length > 0) {\n        conditions.push(...options.conditions);\n    }\n    const result = o(pkg, key, {\n        browser: targetWeb && !conditions.includes('node'),\n        require: options.isRequire && !conditions.includes('import'),\n        conditions,\n    });\n    return result ? result[0] : undefined;\n}\nfunction resolveDeepImport(id, { webResolvedImports, setResolvedCache, getResolvedCache, dir, data, }, targetWeb, options) {\n    const cache = getResolvedCache(id, targetWeb);\n    if (cache) {\n        return cache;\n    }\n    let relativeId = id;\n    const { exports: exportsField, browser: browserField } = data;\n    // map relative based on exports data\n    if (exportsField) {\n        if (isObject$1(exportsField) && !Array.isArray(exportsField)) {\n            // resolve without postfix (see #7098)\n            const { file, postfix } = splitFileAndPostfix(relativeId);\n            const exportsId = resolveExports(data, file, options, targetWeb);\n            if (exportsId !== undefined) {\n                relativeId = exportsId + postfix;\n            }\n            else {\n                relativeId = undefined;\n            }\n        }\n        else {\n            // not exposed\n            relativeId = undefined;\n        }\n        if (!relativeId) {\n            throw new Error(`Package subpath '${relativeId}' is not defined by \"exports\" in ` +\n                `${path$o.join(dir, 'package.json')}.`);\n        }\n    }\n    else if (targetWeb && options.browserField && isObject$1(browserField)) {\n        // resolve without postfix (see #7098)\n        const { file, postfix } = splitFileAndPostfix(relativeId);\n        const mapped = mapWithBrowserField(file, browserField);\n        if (mapped) {\n            relativeId = mapped + postfix;\n        }\n        else if (mapped === false) {\n            return (webResolvedImports[id] = browserExternalId);\n        }\n    }\n    if (relativeId) {\n        const resolved = tryFsResolve(path$o.join(dir, relativeId), options, !exportsField, // try index only if no exports field\n        targetWeb);\n        if (resolved) {\n            isDebug$4 &&\n                debug$c(`[node/deep-import] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(resolved)}`);\n            setResolvedCache(id, resolved, targetWeb);\n            return resolved;\n        }\n    }\n}\nfunction tryResolveBrowserMapping(id, importer, options, isFilePath, externalize) {\n    let res;\n    const pkg = importer && (idToPkgMap.get(importer) || resolvePkg(importer, options));\n    if (pkg && isObject$1(pkg.data.browser)) {\n        const mapId = isFilePath ? './' + slash$1(path$o.relative(pkg.dir, id)) : id;\n        const browserMappedPath = mapWithBrowserField(mapId, pkg.data.browser);\n        if (browserMappedPath) {\n            const fsPath = path$o.join(pkg.dir, browserMappedPath);\n            if ((res = tryFsResolve(fsPath, options))) {\n                isDebug$4 &&\n                    debug$c(`[browser mapped] ${picocolorsExports.cyan(id)} -> ${picocolorsExports.dim(res)}`);\n                idToPkgMap.set(res, pkg);\n                const result = {\n                    id: res,\n                    moduleSideEffects: pkg.hasSideEffects(res),\n                };\n                return externalize ? { ...result, external: true } : result;\n            }\n        }\n        else if (browserMappedPath === false) {\n            return browserExternalId;\n        }\n    }\n}\n/**\n * given a relative path in pkg dir,\n * return a relative path in pkg dir,\n * mapped with the \"map\" object\n *\n * - Returning `undefined` means there is no browser mapping for this id\n * - Returning `false` means this id is explicitly externalized for browser\n */\nfunction mapWithBrowserField(relativePathInPkgDir, map) {\n    const normalizedPath = path$o.posix.normalize(relativePathInPkgDir);\n    for (const key in map) {\n        const normalizedKey = path$o.posix.normalize(key);\n        if (normalizedPath === normalizedKey ||\n            equalWithoutSuffix(normalizedPath, normalizedKey, '.js') ||\n            equalWithoutSuffix(normalizedPath, normalizedKey, '/index.js')) {\n            return map[key];\n        }\n    }\n}\nfunction equalWithoutSuffix(path, key, suffix) {\n    return key.endsWith(suffix) && key.slice(0, -suffix.length) === path;\n}\nfunction getRealPath(resolved, preserveSymlinks) {\n    resolved = ensureVolumeInPath(resolved);\n    if (!preserveSymlinks && browserExternalId !== resolved) {\n        resolved = fs$l.realpathSync(resolved);\n    }\n    return normalizePath$3(resolved);\n}\n/**\n * if importer was not resolved by vite's resolver previously\n * (when esbuild resolved it)\n * resolve importer's pkg and add to idToPkgMap\n */\nfunction resolvePkg(importer, options) {\n    const { root, preserveSymlinks, packageCache } = options;\n    if (importer.includes('\\x00')) {\n        return null;\n    }\n    const possiblePkgIds = [];\n    for (let prevSlashIndex = -1;;) {\n        const slashIndex = importer.indexOf(isWindows$4 ? '\\\\' : '/', prevSlashIndex);\n        if (slashIndex < 0) {\n            break;\n        }\n        prevSlashIndex = slashIndex + 1;\n        const possiblePkgId = importer.slice(0, slashIndex);\n        possiblePkgIds.push(possiblePkgId);\n    }\n    let pkg;\n    possiblePkgIds.reverse().find((pkgId) => {\n        pkg = resolvePackageData(pkgId, root, preserveSymlinks, packageCache);\n        return pkg;\n    });\n    if (pkg) {\n        idToPkgMap.set(importer, pkg);\n    }\n    return pkg;\n}\n\nconst externalWithConversionNamespace = 'vite:dep-pre-bundle:external-conversion';\nconst convertedExternalPrefix = 'vite-dep-pre-bundle-external:';\nconst cjsExternalFacadeNamespace = 'vite:cjs-external-facade';\nconst nonFacadePrefix = 'vite-cjs-external-facade:';\nconst externalTypes = [\n    'css',\n    // supported pre-processor types\n    'less',\n    'sass',\n    'scss',\n    'styl',\n    'stylus',\n    'pcss',\n    'postcss',\n    // wasm\n    'wasm',\n    // known SFC types\n    'vue',\n    'svelte',\n    'marko',\n    'astro',\n    'imba',\n    // JSX/TSX may be configured to be compiled differently from how esbuild\n    // handles it by default, so exclude them as well\n    'jsx',\n    'tsx',\n    ...KNOWN_ASSET_TYPES,\n];\nfunction esbuildDepPlugin(qualified, external, config, ssr) {\n    const { extensions } = getDepOptimizationConfig(config, ssr);\n    // remove optimizable extensions from `externalTypes` list\n    const allExternalTypes = extensions\n        ? externalTypes.filter((type) => !extensions?.includes('.' + type))\n        : externalTypes;\n    // default resolver which prefers ESM\n    const _resolve = config.createResolver({ asSrc: false, scan: true });\n    // cjs resolver that prefers Node\n    const _resolveRequire = config.createResolver({\n        asSrc: false,\n        isRequire: true,\n        scan: true,\n    });\n    const resolve = (id, importer, kind, resolveDir) => {\n        let _importer;\n        // explicit resolveDir - this is passed only during yarn pnp resolve for\n        // entries\n        if (resolveDir) {\n            _importer = normalizePath$3(path$o.join(resolveDir, '*'));\n        }\n        else {\n            // map importer ids to file paths for correct resolution\n            _importer = importer in qualified ? qualified[importer] : importer;\n        }\n        const resolver = kind.startsWith('require') ? _resolveRequire : _resolve;\n        return resolver(id, _importer, undefined, ssr);\n    };\n    const resolveResult = (id, resolved) => {\n        if (resolved.startsWith(browserExternalId)) {\n            return {\n                path: id,\n                namespace: 'browser-external',\n            };\n        }\n        if (resolved.startsWith(optionalPeerDepId)) {\n            return {\n                path: resolved,\n                namespace: 'optional-peer-dep',\n            };\n        }\n        if (ssr && isBuiltin(resolved)) {\n            return;\n        }\n        if (isExternalUrl(resolved)) {\n            return {\n                path: resolved,\n                external: true,\n            };\n        }\n        return {\n            path: path$o.resolve(resolved),\n        };\n    };\n    return {\n        name: 'vite:dep-pre-bundle',\n        setup(build) {\n            // externalize assets and commonly known non-js file types\n            // See #8459 for more details about this require-import conversion\n            build.onResolve({\n                filter: new RegExp(`\\\\.(` + allExternalTypes.join('|') + `)(\\\\?.*)?$`),\n            }, async ({ path: id, importer, kind }) => {\n                // if the prefix exist, it is already converted to `import`, so set `external: true`\n                if (id.startsWith(convertedExternalPrefix)) {\n                    return {\n                        path: id.slice(convertedExternalPrefix.length),\n                        external: true,\n                    };\n                }\n                const resolved = await resolve(id, importer, kind);\n                if (resolved) {\n                    if (kind === 'require-call') {\n                        // here it is not set to `external: true` to convert `require` to `import`\n                        return {\n                            path: resolved,\n                            namespace: externalWithConversionNamespace,\n                        };\n                    }\n                    return {\n                        path: resolved,\n                        external: true,\n                    };\n                }\n            });\n            build.onLoad({ filter: /./, namespace: externalWithConversionNamespace }, (args) => {\n                // import itself with prefix (this is the actual part of require-import conversion)\n                return {\n                    contents: `export { default } from \"${convertedExternalPrefix}${args.path}\";` +\n                        `export * from \"${convertedExternalPrefix}${args.path}\";`,\n                    loader: 'js',\n                };\n            });\n            function resolveEntry(id) {\n                const flatId = flattenId(id);\n                if (flatId in qualified) {\n                    return {\n                        path: qualified[flatId],\n                    };\n                }\n            }\n            build.onResolve({ filter: /^[\\w@][^:]/ }, async ({ path: id, importer, kind }) => {\n                if (moduleListContains(external, id)) {\n                    return {\n                        path: id,\n                        external: true,\n                    };\n                }\n                // ensure esbuild uses our resolved entries\n                let entry;\n                // if this is an entry, return entry namespace resolve result\n                if (!importer) {\n                    if ((entry = resolveEntry(id)))\n                        return entry;\n                    // check if this is aliased to an entry - also return entry namespace\n                    const aliased = await _resolve(id, undefined, true);\n                    if (aliased && (entry = resolveEntry(aliased))) {\n                        return entry;\n                    }\n                }\n                // use vite's own resolver\n                const resolved = await resolve(id, importer, kind);\n                if (resolved) {\n                    return resolveResult(id, resolved);\n                }\n            });\n            build.onLoad({ filter: /.*/, namespace: 'browser-external' }, ({ path }) => {\n                if (config.isProduction) {\n                    return {\n                        contents: 'module.exports = {}',\n                    };\n                }\n                else {\n                    return {\n                        // Return in CJS to intercept named imports. Use `Object.create` to\n                        // create the Proxy in the prototype to workaround esbuild issue. Why?\n                        //\n                        // In short, esbuild cjs->esm flow:\n                        // 1. Create empty object using `Object.create(Object.getPrototypeOf(module.exports))`.\n                        // 2. Assign props of `module.exports` to the object.\n                        // 3. Return object for ESM use.\n                        //\n                        // If we do `module.exports = new Proxy({}, {})`, step 1 returns empty object,\n                        // step 2 does nothing as there's no props for `module.exports`. The final object\n                        // is just an empty object.\n                        //\n                        // Creating the Proxy in the prototype satisfies step 1 immediately, which means\n                        // the returned object is a Proxy that we can intercept.\n                        //\n                        // Note: Skip keys that are accessed by esbuild and browser devtools.\n                        contents: `\\\nmodule.exports = Object.create(new Proxy({}, {\n  get(_, key) {\n    if (\n      key !== '__esModule' &&\n      key !== '__proto__' &&\n      key !== 'constructor' &&\n      key !== 'splice'\n    ) {\n      console.warn(\\`Module \"${path}\" has been externalized for browser compatibility. Cannot access \"${path}.\\${key}\" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.\\`)\n    }\n  }\n}))`,\n                    };\n                }\n            });\n            build.onLoad({ filter: /.*/, namespace: 'optional-peer-dep' }, ({ path }) => {\n                if (config.isProduction) {\n                    return {\n                        contents: 'module.exports = {}',\n                    };\n                }\n                else {\n                    const [, peerDep, parentDep] = path.split(':');\n                    return {\n                        contents: `throw new Error(\\`Could not resolve \"${peerDep}\" imported by \"${parentDep}\". Is it installed?\\`)`,\n                    };\n                }\n            });\n        },\n    };\n}\n// esbuild doesn't transpile `require('foo')` into `import` statements if 'foo' is externalized\n// https://github.com/evanw/esbuild/issues/566#issuecomment-735551834\nfunction esbuildCjsExternalPlugin(externals, platform) {\n    return {\n        name: 'cjs-external',\n        setup(build) {\n            const escape = (text) => `^${text.replace(/[-/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&')}$`;\n            const filter = new RegExp(externals.map(escape).join('|'));\n            build.onResolve({ filter: new RegExp(`^${nonFacadePrefix}`) }, (args) => {\n                return {\n                    path: args.path.slice(nonFacadePrefix.length),\n                    external: true,\n                };\n            });\n            build.onResolve({ filter }, (args) => {\n                // preserve `require` for node because it's more accurate than converting it to import\n                if (args.kind === 'require-call' && platform !== 'node') {\n                    return {\n                        path: args.path,\n                        namespace: cjsExternalFacadeNamespace,\n                    };\n                }\n                return {\n                    path: args.path,\n                    external: true,\n                };\n            });\n            build.onLoad({ filter: /.*/, namespace: cjsExternalFacadeNamespace }, (args) => ({\n                contents: `import * as m from ${JSON.stringify(nonFacadePrefix + args.path)};` + `module.exports = m;`,\n            }));\n        },\n    };\n}\n\nvar tasks = {};\n\nvar utils$g = {};\n\nvar array$1 = {};\n\nObject.defineProperty(array$1, \"__esModule\", { value: true });\r\narray$1.splitWhen = array$1.flatten = void 0;\r\nfunction flatten$1(items) {\r\n    return items.reduce((collection, item) => [].concat(collection, item), []);\r\n}\r\narray$1.flatten = flatten$1;\r\nfunction splitWhen(items, predicate) {\r\n    const result = [[]];\r\n    let groupIndex = 0;\r\n    for (const item of items) {\r\n        if (predicate(item)) {\r\n            groupIndex++;\r\n            result[groupIndex] = [];\r\n        }\r\n        else {\r\n            result[groupIndex].push(item);\r\n        }\r\n    }\r\n    return result;\r\n}\r\narray$1.splitWhen = splitWhen;\n\nvar errno$1 = {};\n\nObject.defineProperty(errno$1, \"__esModule\", { value: true });\r\nerrno$1.isEnoentCodeError = void 0;\r\nfunction isEnoentCodeError(error) {\r\n    return error.code === 'ENOENT';\r\n}\r\nerrno$1.isEnoentCodeError = isEnoentCodeError;\n\nvar fs$h = {};\n\nObject.defineProperty(fs$h, \"__esModule\", { value: true });\r\nfs$h.createDirentFromStats = void 0;\r\nlet DirentFromStats$1 = class DirentFromStats {\r\n    constructor(name, stats) {\r\n        this.name = name;\r\n        this.isBlockDevice = stats.isBlockDevice.bind(stats);\r\n        this.isCharacterDevice = stats.isCharacterDevice.bind(stats);\r\n        this.isDirectory = stats.isDirectory.bind(stats);\r\n        this.isFIFO = stats.isFIFO.bind(stats);\r\n        this.isFile = stats.isFile.bind(stats);\r\n        this.isSocket = stats.isSocket.bind(stats);\r\n        this.isSymbolicLink = stats.isSymbolicLink.bind(stats);\r\n    }\r\n};\r\nfunction createDirentFromStats$1(name, stats) {\r\n    return new DirentFromStats$1(name, stats);\r\n}\r\nfs$h.createDirentFromStats = createDirentFromStats$1;\n\nvar path$h = {};\n\nObject.defineProperty(path$h, \"__esModule\", { value: true });\r\npath$h.removeLeadingDotSegment = path$h.escape = path$h.makeAbsolute = path$h.unixify = void 0;\r\nconst path$g = require$$0$4;\r\nconst LEADING_DOT_SEGMENT_CHARACTERS_COUNT = 2; // ./ or .\\\\\r\nconst UNESCAPED_GLOB_SYMBOLS_RE = /(\\\\?)([()*?[\\]{|}]|^!|[!+@](?=\\())/g;\r\n/**\r\n * Designed to work only with simple paths: `dir\\\\file`.\r\n */\r\nfunction unixify(filepath) {\r\n    return filepath.replace(/\\\\/g, '/');\r\n}\r\npath$h.unixify = unixify;\r\nfunction makeAbsolute(cwd, filepath) {\r\n    return path$g.resolve(cwd, filepath);\r\n}\r\npath$h.makeAbsolute = makeAbsolute;\r\nfunction escape$2(pattern) {\r\n    return pattern.replace(UNESCAPED_GLOB_SYMBOLS_RE, '\\\\$2');\r\n}\r\npath$h.escape = escape$2;\r\nfunction removeLeadingDotSegment(entry) {\r\n    // We do not use `startsWith` because this is 10x slower than current implementation for some cases.\r\n    // eslint-disable-next-line @typescript-eslint/prefer-string-starts-ends-with\r\n    if (entry.charAt(0) === '.') {\r\n        const secondCharactery = entry.charAt(1);\r\n        if (secondCharactery === '/' || secondCharactery === '\\\\') {\r\n            return entry.slice(LEADING_DOT_SEGMENT_CHARACTERS_COUNT);\r\n        }\r\n    }\r\n    return entry;\r\n}\r\npath$h.removeLeadingDotSegment = removeLeadingDotSegment;\n\nvar pattern$1 = {};\n\n/*!\n * is-extglob <https://github.com/jonschlinkert/is-extglob>\n *\n * Copyright (c) 2014-2016, Jon Schlinkert.\n * Licensed under the MIT License.\n */\n\nvar isExtglob$1 = function isExtglob(str) {\n  if (typeof str !== 'string' || str === '') {\n    return false;\n  }\n\n  var match;\n  while ((match = /(\\\\).|([@?!+*]\\(.*\\))/g.exec(str))) {\n    if (match[2]) return true;\n    str = str.slice(match.index + match[0].length);\n  }\n\n  return false;\n};\n\n/*!\n * is-glob <https://github.com/jonschlinkert/is-glob>\n *\n * Copyright (c) 2014-2017, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nvar isExtglob = isExtglob$1;\nvar chars = { '{': '}', '(': ')', '[': ']'};\nvar strictCheck = function(str) {\n  if (str[0] === '!') {\n    return true;\n  }\n  var index = 0;\n  var pipeIndex = -2;\n  var closeSquareIndex = -2;\n  var closeCurlyIndex = -2;\n  var closeParenIndex = -2;\n  var backSlashIndex = -2;\n  while (index < str.length) {\n    if (str[index] === '*') {\n      return true;\n    }\n\n    if (str[index + 1] === '?' && /[\\].+)]/.test(str[index])) {\n      return true;\n    }\n\n    if (closeSquareIndex !== -1 && str[index] === '[' && str[index + 1] !== ']') {\n      if (closeSquareIndex < index) {\n        closeSquareIndex = str.indexOf(']', index);\n      }\n      if (closeSquareIndex > index) {\n        if (backSlashIndex === -1 || backSlashIndex > closeSquareIndex) {\n          return true;\n        }\n        backSlashIndex = str.indexOf('\\\\', index);\n        if (backSlashIndex === -1 || backSlashIndex > closeSquareIndex) {\n          return true;\n        }\n      }\n    }\n\n    if (closeCurlyIndex !== -1 && str[index] === '{' && str[index + 1] !== '}') {\n      closeCurlyIndex = str.indexOf('}', index);\n      if (closeCurlyIndex > index) {\n        backSlashIndex = str.indexOf('\\\\', index);\n        if (backSlashIndex === -1 || backSlashIndex > closeCurlyIndex) {\n          return true;\n        }\n      }\n    }\n\n    if (closeParenIndex !== -1 && str[index] === '(' && str[index + 1] === '?' && /[:!=]/.test(str[index + 2]) && str[index + 3] !== ')') {\n      closeParenIndex = str.indexOf(')', index);\n      if (closeParenIndex > index) {\n        backSlashIndex = str.indexOf('\\\\', index);\n        if (backSlashIndex === -1 || backSlashIndex > closeParenIndex) {\n          return true;\n        }\n      }\n    }\n\n    if (pipeIndex !== -1 && str[index] === '(' && str[index + 1] !== '|') {\n      if (pipeIndex < index) {\n        pipeIndex = str.indexOf('|', index);\n      }\n      if (pipeIndex !== -1 && str[pipeIndex + 1] !== ')') {\n        closeParenIndex = str.indexOf(')', pipeIndex);\n        if (closeParenIndex > pipeIndex) {\n          backSlashIndex = str.indexOf('\\\\', pipeIndex);\n          if (backSlashIndex === -1 || backSlashIndex > closeParenIndex) {\n            return true;\n          }\n        }\n      }\n    }\n\n    if (str[index] === '\\\\') {\n      var open = str[index + 1];\n      index += 2;\n      var close = chars[open];\n\n      if (close) {\n        var n = str.indexOf(close, index);\n        if (n !== -1) {\n          index = n + 1;\n        }\n      }\n\n      if (str[index] === '!') {\n        return true;\n      }\n    } else {\n      index++;\n    }\n  }\n  return false;\n};\n\nvar relaxedCheck = function(str) {\n  if (str[0] === '!') {\n    return true;\n  }\n  var index = 0;\n  while (index < str.length) {\n    if (/[*?{}()[\\]]/.test(str[index])) {\n      return true;\n    }\n\n    if (str[index] === '\\\\') {\n      var open = str[index + 1];\n      index += 2;\n      var close = chars[open];\n\n      if (close) {\n        var n = str.indexOf(close, index);\n        if (n !== -1) {\n          index = n + 1;\n        }\n      }\n\n      if (str[index] === '!') {\n        return true;\n      }\n    } else {\n      index++;\n    }\n  }\n  return false;\n};\n\nvar isGlob$2 = function isGlob(str, options) {\n  if (typeof str !== 'string' || str === '') {\n    return false;\n  }\n\n  if (isExtglob(str)) {\n    return true;\n  }\n\n  var check = strictCheck;\n\n  // optionally relax check\n  if (options && options.strict === false) {\n    check = relaxedCheck;\n  }\n\n  return check(str);\n};\n\nvar isGlob$1 = isGlob$2;\nvar pathPosixDirname = require$$0$4.posix.dirname;\nvar isWin32 = require$$2.platform() === 'win32';\n\nvar slash = '/';\nvar backslash = /\\\\/g;\nvar enclosure = /[\\{\\[].*[\\}\\]]$/;\nvar globby = /(^|[^\\\\])([\\{\\[]|\\([^\\)]+$)/;\nvar escaped = /\\\\([\\!\\*\\?\\|\\[\\]\\(\\)\\{\\}])/g;\n\n/**\n * @param {string} str\n * @param {Object} opts\n * @param {boolean} [opts.flipBackslashes=true]\n * @returns {string}\n */\nvar globParent$2 = function globParent(str, opts) {\n  var options = Object.assign({ flipBackslashes: true }, opts);\n\n  // flip windows path separators\n  if (options.flipBackslashes && isWin32 && str.indexOf(slash) < 0) {\n    str = str.replace(backslash, slash);\n  }\n\n  // special case for strings ending in enclosure containing path separator\n  if (enclosure.test(str)) {\n    str += slash;\n  }\n\n  // preserves full path in case of trailing path separator\n  str += 'a';\n\n  // remove path parts that are globby\n  do {\n    str = pathPosixDirname(str);\n  } while (isGlob$1(str) || globby.test(str));\n\n  // remove escape chars and return result\n  return str.replace(escaped, '$1');\n};\n\nvar utils$f = {};\n\n(function (exports) {\n\n\texports.isInteger = num => {\n\t  if (typeof num === 'number') {\n\t    return Number.isInteger(num);\n\t  }\n\t  if (typeof num === 'string' && num.trim() !== '') {\n\t    return Number.isInteger(Number(num));\n\t  }\n\t  return false;\n\t};\n\n\t/**\n\t * Find a node of the given type\n\t */\n\n\texports.find = (node, type) => node.nodes.find(node => node.type === type);\n\n\t/**\n\t * Find a node of the given type\n\t */\n\n\texports.exceedsLimit = (min, max, step = 1, limit) => {\n\t  if (limit === false) return false;\n\t  if (!exports.isInteger(min) || !exports.isInteger(max)) return false;\n\t  return ((Number(max) - Number(min)) / Number(step)) >= limit;\n\t};\n\n\t/**\n\t * Escape the given node with '\\\\' before node.value\n\t */\n\n\texports.escapeNode = (block, n = 0, type) => {\n\t  let node = block.nodes[n];\n\t  if (!node) return;\n\n\t  if ((type && node.type === type) || node.type === 'open' || node.type === 'close') {\n\t    if (node.escaped !== true) {\n\t      node.value = '\\\\' + node.value;\n\t      node.escaped = true;\n\t    }\n\t  }\n\t};\n\n\t/**\n\t * Returns true if the given brace node should be enclosed in literal braces\n\t */\n\n\texports.encloseBrace = node => {\n\t  if (node.type !== 'brace') return false;\n\t  if ((node.commas >> 0 + node.ranges >> 0) === 0) {\n\t    node.invalid = true;\n\t    return true;\n\t  }\n\t  return false;\n\t};\n\n\t/**\n\t * Returns true if a brace node is invalid.\n\t */\n\n\texports.isInvalidBrace = block => {\n\t  if (block.type !== 'brace') return false;\n\t  if (block.invalid === true || block.dollar) return true;\n\t  if ((block.commas >> 0 + block.ranges >> 0) === 0) {\n\t    block.invalid = true;\n\t    return true;\n\t  }\n\t  if (block.open !== true || block.close !== true) {\n\t    block.invalid = true;\n\t    return true;\n\t  }\n\t  return false;\n\t};\n\n\t/**\n\t * Returns true if a node is an open or close node\n\t */\n\n\texports.isOpenOrClose = node => {\n\t  if (node.type === 'open' || node.type === 'close') {\n\t    return true;\n\t  }\n\t  return node.open === true || node.close === true;\n\t};\n\n\t/**\n\t * Reduce an array of text nodes.\n\t */\n\n\texports.reduce = nodes => nodes.reduce((acc, node) => {\n\t  if (node.type === 'text') acc.push(node.value);\n\t  if (node.type === 'range') node.type = 'text';\n\t  return acc;\n\t}, []);\n\n\t/**\n\t * Flatten an array\n\t */\n\n\texports.flatten = (...args) => {\n\t  const result = [];\n\t  const flat = arr => {\n\t    for (let i = 0; i < arr.length; i++) {\n\t      let ele = arr[i];\n\t      Array.isArray(ele) ? flat(ele) : ele !== void 0 && result.push(ele);\n\t    }\n\t    return result;\n\t  };\n\t  flat(args);\n\t  return result;\n\t};\n} (utils$f));\n\nconst utils$e = utils$f;\n\nvar stringify$7 = (ast, options = {}) => {\n  let stringify = (node, parent = {}) => {\n    let invalidBlock = options.escapeInvalid && utils$e.isInvalidBrace(parent);\n    let invalidNode = node.invalid === true && options.escapeInvalid === true;\n    let output = '';\n\n    if (node.value) {\n      if ((invalidBlock || invalidNode) && utils$e.isOpenOrClose(node)) {\n        return '\\\\' + node.value;\n      }\n      return node.value;\n    }\n\n    if (node.value) {\n      return node.value;\n    }\n\n    if (node.nodes) {\n      for (let child of node.nodes) {\n        output += stringify(child);\n      }\n    }\n    return output;\n  };\n\n  return stringify(ast);\n};\n\n/*!\n * is-number <https://github.com/jonschlinkert/is-number>\n *\n * Copyright (c) 2014-present, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nvar isNumber$2 = function(num) {\n  if (typeof num === 'number') {\n    return num - num === 0;\n  }\n  if (typeof num === 'string' && num.trim() !== '') {\n    return Number.isFinite ? Number.isFinite(+num) : isFinite(+num);\n  }\n  return false;\n};\n\n/*!\n * to-regex-range <https://github.com/micromatch/to-regex-range>\n *\n * Copyright (c) 2015-present, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nconst isNumber$1 = isNumber$2;\n\nconst toRegexRange$1 = (min, max, options) => {\n  if (isNumber$1(min) === false) {\n    throw new TypeError('toRegexRange: expected the first argument to be a number');\n  }\n\n  if (max === void 0 || min === max) {\n    return String(min);\n  }\n\n  if (isNumber$1(max) === false) {\n    throw new TypeError('toRegexRange: expected the second argument to be a number.');\n  }\n\n  let opts = { relaxZeros: true, ...options };\n  if (typeof opts.strictZeros === 'boolean') {\n    opts.relaxZeros = opts.strictZeros === false;\n  }\n\n  let relax = String(opts.relaxZeros);\n  let shorthand = String(opts.shorthand);\n  let capture = String(opts.capture);\n  let wrap = String(opts.wrap);\n  let cacheKey = min + ':' + max + '=' + relax + shorthand + capture + wrap;\n\n  if (toRegexRange$1.cache.hasOwnProperty(cacheKey)) {\n    return toRegexRange$1.cache[cacheKey].result;\n  }\n\n  let a = Math.min(min, max);\n  let b = Math.max(min, max);\n\n  if (Math.abs(a - b) === 1) {\n    let result = min + '|' + max;\n    if (opts.capture) {\n      return `(${result})`;\n    }\n    if (opts.wrap === false) {\n      return result;\n    }\n    return `(?:${result})`;\n  }\n\n  let isPadded = hasPadding(min) || hasPadding(max);\n  let state = { min, max, a, b };\n  let positives = [];\n  let negatives = [];\n\n  if (isPadded) {\n    state.isPadded = isPadded;\n    state.maxLen = String(state.max).length;\n  }\n\n  if (a < 0) {\n    let newMin = b < 0 ? Math.abs(b) : 1;\n    negatives = splitToPatterns(newMin, Math.abs(a), state, opts);\n    a = state.a = 0;\n  }\n\n  if (b >= 0) {\n    positives = splitToPatterns(a, b, state, opts);\n  }\n\n  state.negatives = negatives;\n  state.positives = positives;\n  state.result = collatePatterns(negatives, positives);\n\n  if (opts.capture === true) {\n    state.result = `(${state.result})`;\n  } else if (opts.wrap !== false && (positives.length + negatives.length) > 1) {\n    state.result = `(?:${state.result})`;\n  }\n\n  toRegexRange$1.cache[cacheKey] = state;\n  return state.result;\n};\n\nfunction collatePatterns(neg, pos, options) {\n  let onlyNegative = filterPatterns(neg, pos, '-', false) || [];\n  let onlyPositive = filterPatterns(pos, neg, '', false) || [];\n  let intersected = filterPatterns(neg, pos, '-?', true) || [];\n  let subpatterns = onlyNegative.concat(intersected).concat(onlyPositive);\n  return subpatterns.join('|');\n}\n\nfunction splitToRanges(min, max) {\n  let nines = 1;\n  let zeros = 1;\n\n  let stop = countNines(min, nines);\n  let stops = new Set([max]);\n\n  while (min <= stop && stop <= max) {\n    stops.add(stop);\n    nines += 1;\n    stop = countNines(min, nines);\n  }\n\n  stop = countZeros(max + 1, zeros) - 1;\n\n  while (min < stop && stop <= max) {\n    stops.add(stop);\n    zeros += 1;\n    stop = countZeros(max + 1, zeros) - 1;\n  }\n\n  stops = [...stops];\n  stops.sort(compare);\n  return stops;\n}\n\n/**\n * Convert a range to a regex pattern\n * @param {Number} `start`\n * @param {Number} `stop`\n * @return {String}\n */\n\nfunction rangeToPattern(start, stop, options) {\n  if (start === stop) {\n    return { pattern: start, count: [], digits: 0 };\n  }\n\n  let zipped = zip(start, stop);\n  let digits = zipped.length;\n  let pattern = '';\n  let count = 0;\n\n  for (let i = 0; i < digits; i++) {\n    let [startDigit, stopDigit] = zipped[i];\n\n    if (startDigit === stopDigit) {\n      pattern += startDigit;\n\n    } else if (startDigit !== '0' || stopDigit !== '9') {\n      pattern += toCharacterClass(startDigit, stopDigit);\n\n    } else {\n      count++;\n    }\n  }\n\n  if (count) {\n    pattern += options.shorthand === true ? '\\\\d' : '[0-9]';\n  }\n\n  return { pattern, count: [count], digits };\n}\n\nfunction splitToPatterns(min, max, tok, options) {\n  let ranges = splitToRanges(min, max);\n  let tokens = [];\n  let start = min;\n  let prev;\n\n  for (let i = 0; i < ranges.length; i++) {\n    let max = ranges[i];\n    let obj = rangeToPattern(String(start), String(max), options);\n    let zeros = '';\n\n    if (!tok.isPadded && prev && prev.pattern === obj.pattern) {\n      if (prev.count.length > 1) {\n        prev.count.pop();\n      }\n\n      prev.count.push(obj.count[0]);\n      prev.string = prev.pattern + toQuantifier(prev.count);\n      start = max + 1;\n      continue;\n    }\n\n    if (tok.isPadded) {\n      zeros = padZeros(max, tok, options);\n    }\n\n    obj.string = zeros + obj.pattern + toQuantifier(obj.count);\n    tokens.push(obj);\n    start = max + 1;\n    prev = obj;\n  }\n\n  return tokens;\n}\n\nfunction filterPatterns(arr, comparison, prefix, intersection, options) {\n  let result = [];\n\n  for (let ele of arr) {\n    let { string } = ele;\n\n    // only push if _both_ are negative...\n    if (!intersection && !contains(comparison, 'string', string)) {\n      result.push(prefix + string);\n    }\n\n    // or _both_ are positive\n    if (intersection && contains(comparison, 'string', string)) {\n      result.push(prefix + string);\n    }\n  }\n  return result;\n}\n\n/**\n * Zip strings\n */\n\nfunction zip(a, b) {\n  let arr = [];\n  for (let i = 0; i < a.length; i++) arr.push([a[i], b[i]]);\n  return arr;\n}\n\nfunction compare(a, b) {\n  return a > b ? 1 : b > a ? -1 : 0;\n}\n\nfunction contains(arr, key, val) {\n  return arr.some(ele => ele[key] === val);\n}\n\nfunction countNines(min, len) {\n  return Number(String(min).slice(0, -len) + '9'.repeat(len));\n}\n\nfunction countZeros(integer, zeros) {\n  return integer - (integer % Math.pow(10, zeros));\n}\n\nfunction toQuantifier(digits) {\n  let [start = 0, stop = ''] = digits;\n  if (stop || start > 1) {\n    return `{${start + (stop ? ',' + stop : '')}}`;\n  }\n  return '';\n}\n\nfunction toCharacterClass(a, b, options) {\n  return `[${a}${(b - a === 1) ? '' : '-'}${b}]`;\n}\n\nfunction hasPadding(str) {\n  return /^-?(0+)\\d/.test(str);\n}\n\nfunction padZeros(value, tok, options) {\n  if (!tok.isPadded) {\n    return value;\n  }\n\n  let diff = Math.abs(tok.maxLen - String(value).length);\n  let relax = options.relaxZeros !== false;\n\n  switch (diff) {\n    case 0:\n      return '';\n    case 1:\n      return relax ? '0?' : '0';\n    case 2:\n      return relax ? '0{0,2}' : '00';\n    default: {\n      return relax ? `0{0,${diff}}` : `0{${diff}}`;\n    }\n  }\n}\n\n/**\n * Cache\n */\n\ntoRegexRange$1.cache = {};\ntoRegexRange$1.clearCache = () => (toRegexRange$1.cache = {});\n\n/**\n * Expose `toRegexRange`\n */\n\nvar toRegexRange_1 = toRegexRange$1;\n\n/*!\n * fill-range <https://github.com/jonschlinkert/fill-range>\n *\n * Copyright (c) 2014-present, Jon Schlinkert.\n * Licensed under the MIT License.\n */\n\nconst util$1 = require$$0$6;\nconst toRegexRange = toRegexRange_1;\n\nconst isObject = val => val !== null && typeof val === 'object' && !Array.isArray(val);\n\nconst transform$1 = toNumber => {\n  return value => toNumber === true ? Number(value) : String(value);\n};\n\nconst isValidValue = value => {\n  return typeof value === 'number' || (typeof value === 'string' && value !== '');\n};\n\nconst isNumber = num => Number.isInteger(+num);\n\nconst zeros = input => {\n  let value = `${input}`;\n  let index = -1;\n  if (value[0] === '-') value = value.slice(1);\n  if (value === '0') return false;\n  while (value[++index] === '0');\n  return index > 0;\n};\n\nconst stringify$6 = (start, end, options) => {\n  if (typeof start === 'string' || typeof end === 'string') {\n    return true;\n  }\n  return options.stringify === true;\n};\n\nconst pad = (input, maxLength, toNumber) => {\n  if (maxLength > 0) {\n    let dash = input[0] === '-' ? '-' : '';\n    if (dash) input = input.slice(1);\n    input = (dash + input.padStart(dash ? maxLength - 1 : maxLength, '0'));\n  }\n  if (toNumber === false) {\n    return String(input);\n  }\n  return input;\n};\n\nconst toMaxLen = (input, maxLength) => {\n  let negative = input[0] === '-' ? '-' : '';\n  if (negative) {\n    input = input.slice(1);\n    maxLength--;\n  }\n  while (input.length < maxLength) input = '0' + input;\n  return negative ? ('-' + input) : input;\n};\n\nconst toSequence = (parts, options) => {\n  parts.negatives.sort((a, b) => a < b ? -1 : a > b ? 1 : 0);\n  parts.positives.sort((a, b) => a < b ? -1 : a > b ? 1 : 0);\n\n  let prefix = options.capture ? '' : '?:';\n  let positives = '';\n  let negatives = '';\n  let result;\n\n  if (parts.positives.length) {\n    positives = parts.positives.join('|');\n  }\n\n  if (parts.negatives.length) {\n    negatives = `-(${prefix}${parts.negatives.join('|')})`;\n  }\n\n  if (positives && negatives) {\n    result = `${positives}|${negatives}`;\n  } else {\n    result = positives || negatives;\n  }\n\n  if (options.wrap) {\n    return `(${prefix}${result})`;\n  }\n\n  return result;\n};\n\nconst toRange = (a, b, isNumbers, options) => {\n  if (isNumbers) {\n    return toRegexRange(a, b, { wrap: false, ...options });\n  }\n\n  let start = String.fromCharCode(a);\n  if (a === b) return start;\n\n  let stop = String.fromCharCode(b);\n  return `[${start}-${stop}]`;\n};\n\nconst toRegex = (start, end, options) => {\n  if (Array.isArray(start)) {\n    let wrap = options.wrap === true;\n    let prefix = options.capture ? '' : '?:';\n    return wrap ? `(${prefix}${start.join('|')})` : start.join('|');\n  }\n  return toRegexRange(start, end, options);\n};\n\nconst rangeError = (...args) => {\n  return new RangeError('Invalid range arguments: ' + util$1.inspect(...args));\n};\n\nconst invalidRange = (start, end, options) => {\n  if (options.strictRanges === true) throw rangeError([start, end]);\n  return [];\n};\n\nconst invalidStep = (step, options) => {\n  if (options.strictRanges === true) {\n    throw new TypeError(`Expected step \"${step}\" to be a number`);\n  }\n  return [];\n};\n\nconst fillNumbers = (start, end, step = 1, options = {}) => {\n  let a = Number(start);\n  let b = Number(end);\n\n  if (!Number.isInteger(a) || !Number.isInteger(b)) {\n    if (options.strictRanges === true) throw rangeError([start, end]);\n    return [];\n  }\n\n  // fix negative zero\n  if (a === 0) a = 0;\n  if (b === 0) b = 0;\n\n  let descending = a > b;\n  let startString = String(start);\n  let endString = String(end);\n  let stepString = String(step);\n  step = Math.max(Math.abs(step), 1);\n\n  let padded = zeros(startString) || zeros(endString) || zeros(stepString);\n  let maxLen = padded ? Math.max(startString.length, endString.length, stepString.length) : 0;\n  let toNumber = padded === false && stringify$6(start, end, options) === false;\n  let format = options.transform || transform$1(toNumber);\n\n  if (options.toRegex && step === 1) {\n    return toRange(toMaxLen(start, maxLen), toMaxLen(end, maxLen), true, options);\n  }\n\n  let parts = { negatives: [], positives: [] };\n  let push = num => parts[num < 0 ? 'negatives' : 'positives'].push(Math.abs(num));\n  let range = [];\n  let index = 0;\n\n  while (descending ? a >= b : a <= b) {\n    if (options.toRegex === true && step > 1) {\n      push(a);\n    } else {\n      range.push(pad(format(a, index), maxLen, toNumber));\n    }\n    a = descending ? a - step : a + step;\n    index++;\n  }\n\n  if (options.toRegex === true) {\n    return step > 1\n      ? toSequence(parts, options)\n      : toRegex(range, null, { wrap: false, ...options });\n  }\n\n  return range;\n};\n\nconst fillLetters = (start, end, step = 1, options = {}) => {\n  if ((!isNumber(start) && start.length > 1) || (!isNumber(end) && end.length > 1)) {\n    return invalidRange(start, end, options);\n  }\n\n\n  let format = options.transform || (val => String.fromCharCode(val));\n  let a = `${start}`.charCodeAt(0);\n  let b = `${end}`.charCodeAt(0);\n\n  let descending = a > b;\n  let min = Math.min(a, b);\n  let max = Math.max(a, b);\n\n  if (options.toRegex && step === 1) {\n    return toRange(min, max, false, options);\n  }\n\n  let range = [];\n  let index = 0;\n\n  while (descending ? a >= b : a <= b) {\n    range.push(format(a, index));\n    a = descending ? a - step : a + step;\n    index++;\n  }\n\n  if (options.toRegex === true) {\n    return toRegex(range, null, { wrap: false, options });\n  }\n\n  return range;\n};\n\nconst fill$2 = (start, end, step, options = {}) => {\n  if (end == null && isValidValue(start)) {\n    return [start];\n  }\n\n  if (!isValidValue(start) || !isValidValue(end)) {\n    return invalidRange(start, end, options);\n  }\n\n  if (typeof step === 'function') {\n    return fill$2(start, end, 1, { transform: step });\n  }\n\n  if (isObject(step)) {\n    return fill$2(start, end, 0, step);\n  }\n\n  let opts = { ...options };\n  if (opts.capture === true) opts.wrap = true;\n  step = step || opts.step || 1;\n\n  if (!isNumber(step)) {\n    if (step != null && !isObject(step)) return invalidStep(step, opts);\n    return fill$2(start, end, 1, step);\n  }\n\n  if (isNumber(start) && isNumber(end)) {\n    return fillNumbers(start, end, step, opts);\n  }\n\n  return fillLetters(start, end, Math.max(Math.abs(step), 1), opts);\n};\n\nvar fillRange = fill$2;\n\nconst fill$1 = fillRange;\nconst utils$d = utils$f;\n\nconst compile$1 = (ast, options = {}) => {\n  let walk = (node, parent = {}) => {\n    let invalidBlock = utils$d.isInvalidBrace(parent);\n    let invalidNode = node.invalid === true && options.escapeInvalid === true;\n    let invalid = invalidBlock === true || invalidNode === true;\n    let prefix = options.escapeInvalid === true ? '\\\\' : '';\n    let output = '';\n\n    if (node.isOpen === true) {\n      return prefix + node.value;\n    }\n    if (node.isClose === true) {\n      return prefix + node.value;\n    }\n\n    if (node.type === 'open') {\n      return invalid ? (prefix + node.value) : '(';\n    }\n\n    if (node.type === 'close') {\n      return invalid ? (prefix + node.value) : ')';\n    }\n\n    if (node.type === 'comma') {\n      return node.prev.type === 'comma' ? '' : (invalid ? node.value : '|');\n    }\n\n    if (node.value) {\n      return node.value;\n    }\n\n    if (node.nodes && node.ranges > 0) {\n      let args = utils$d.reduce(node.nodes);\n      let range = fill$1(...args, { ...options, wrap: false, toRegex: true });\n\n      if (range.length !== 0) {\n        return args.length > 1 && range.length > 1 ? `(${range})` : range;\n      }\n    }\n\n    if (node.nodes) {\n      for (let child of node.nodes) {\n        output += walk(child, node);\n      }\n    }\n    return output;\n  };\n\n  return walk(ast);\n};\n\nvar compile_1 = compile$1;\n\nconst fill = fillRange;\nconst stringify$5 = stringify$7;\nconst utils$c = utils$f;\n\nconst append$1 = (queue = '', stash = '', enclose = false) => {\n  let result = [];\n\n  queue = [].concat(queue);\n  stash = [].concat(stash);\n\n  if (!stash.length) return queue;\n  if (!queue.length) {\n    return enclose ? utils$c.flatten(stash).map(ele => `{${ele}}`) : stash;\n  }\n\n  for (let item of queue) {\n    if (Array.isArray(item)) {\n      for (let value of item) {\n        result.push(append$1(value, stash, enclose));\n      }\n    } else {\n      for (let ele of stash) {\n        if (enclose === true && typeof ele === 'string') ele = `{${ele}}`;\n        result.push(Array.isArray(ele) ? append$1(item, ele, enclose) : (item + ele));\n      }\n    }\n  }\n  return utils$c.flatten(result);\n};\n\nconst expand$2 = (ast, options = {}) => {\n  let rangeLimit = options.rangeLimit === void 0 ? 1000 : options.rangeLimit;\n\n  let walk = (node, parent = {}) => {\n    node.queue = [];\n\n    let p = parent;\n    let q = parent.queue;\n\n    while (p.type !== 'brace' && p.type !== 'root' && p.parent) {\n      p = p.parent;\n      q = p.queue;\n    }\n\n    if (node.invalid || node.dollar) {\n      q.push(append$1(q.pop(), stringify$5(node, options)));\n      return;\n    }\n\n    if (node.type === 'brace' && node.invalid !== true && node.nodes.length === 2) {\n      q.push(append$1(q.pop(), ['{}']));\n      return;\n    }\n\n    if (node.nodes && node.ranges > 0) {\n      let args = utils$c.reduce(node.nodes);\n\n      if (utils$c.exceedsLimit(...args, options.step, rangeLimit)) {\n        throw new RangeError('expanded array length exceeds range limit. Use options.rangeLimit to increase or disable the limit.');\n      }\n\n      let range = fill(...args, options);\n      if (range.length === 0) {\n        range = stringify$5(node, options);\n      }\n\n      q.push(append$1(q.pop(), range));\n      node.nodes = [];\n      return;\n    }\n\n    let enclose = utils$c.encloseBrace(node);\n    let queue = node.queue;\n    let block = node;\n\n    while (block.type !== 'brace' && block.type !== 'root' && block.parent) {\n      block = block.parent;\n      queue = block.queue;\n    }\n\n    for (let i = 0; i < node.nodes.length; i++) {\n      let child = node.nodes[i];\n\n      if (child.type === 'comma' && node.type === 'brace') {\n        if (i === 1) queue.push('');\n        queue.push('');\n        continue;\n      }\n\n      if (child.type === 'close') {\n        q.push(append$1(q.pop(), queue, enclose));\n        continue;\n      }\n\n      if (child.value && child.type !== 'open') {\n        queue.push(append$1(queue.pop(), child.value));\n        continue;\n      }\n\n      if (child.nodes) {\n        walk(child, node);\n      }\n    }\n\n    return queue;\n  };\n\n  return utils$c.flatten(walk(ast));\n};\n\nvar expand_1$1 = expand$2;\n\nvar constants$3 = {\n  MAX_LENGTH: 1024 * 64,\n\n  // Digits\n  CHAR_0: '0', /* 0 */\n  CHAR_9: '9', /* 9 */\n\n  // Alphabet chars.\n  CHAR_UPPERCASE_A: 'A', /* A */\n  CHAR_LOWERCASE_A: 'a', /* a */\n  CHAR_UPPERCASE_Z: 'Z', /* Z */\n  CHAR_LOWERCASE_Z: 'z', /* z */\n\n  CHAR_LEFT_PARENTHESES: '(', /* ( */\n  CHAR_RIGHT_PARENTHESES: ')', /* ) */\n\n  CHAR_ASTERISK: '*', /* * */\n\n  // Non-alphabetic chars.\n  CHAR_AMPERSAND: '&', /* & */\n  CHAR_AT: '@', /* @ */\n  CHAR_BACKSLASH: '\\\\', /* \\ */\n  CHAR_BACKTICK: '`', /* ` */\n  CHAR_CARRIAGE_RETURN: '\\r', /* \\r */\n  CHAR_CIRCUMFLEX_ACCENT: '^', /* ^ */\n  CHAR_COLON: ':', /* : */\n  CHAR_COMMA: ',', /* , */\n  CHAR_DOLLAR: '$', /* . */\n  CHAR_DOT: '.', /* . */\n  CHAR_DOUBLE_QUOTE: '\"', /* \" */\n  CHAR_EQUAL: '=', /* = */\n  CHAR_EXCLAMATION_MARK: '!', /* ! */\n  CHAR_FORM_FEED: '\\f', /* \\f */\n  CHAR_FORWARD_SLASH: '/', /* / */\n  CHAR_HASH: '#', /* # */\n  CHAR_HYPHEN_MINUS: '-', /* - */\n  CHAR_LEFT_ANGLE_BRACKET: '<', /* < */\n  CHAR_LEFT_CURLY_BRACE: '{', /* { */\n  CHAR_LEFT_SQUARE_BRACKET: '[', /* [ */\n  CHAR_LINE_FEED: '\\n', /* \\n */\n  CHAR_NO_BREAK_SPACE: '\\u00A0', /* \\u00A0 */\n  CHAR_PERCENT: '%', /* % */\n  CHAR_PLUS: '+', /* + */\n  CHAR_QUESTION_MARK: '?', /* ? */\n  CHAR_RIGHT_ANGLE_BRACKET: '>', /* > */\n  CHAR_RIGHT_CURLY_BRACE: '}', /* } */\n  CHAR_RIGHT_SQUARE_BRACKET: ']', /* ] */\n  CHAR_SEMICOLON: ';', /* ; */\n  CHAR_SINGLE_QUOTE: '\\'', /* ' */\n  CHAR_SPACE: ' ', /*   */\n  CHAR_TAB: '\\t', /* \\t */\n  CHAR_UNDERSCORE: '_', /* _ */\n  CHAR_VERTICAL_LINE: '|', /* | */\n  CHAR_ZERO_WIDTH_NOBREAK_SPACE: '\\uFEFF' /* \\uFEFF */\n};\n\nconst stringify$4 = stringify$7;\n\n/**\n * Constants\n */\n\nconst {\n  MAX_LENGTH,\n  CHAR_BACKSLASH, /* \\ */\n  CHAR_BACKTICK, /* ` */\n  CHAR_COMMA, /* , */\n  CHAR_DOT, /* . */\n  CHAR_LEFT_PARENTHESES, /* ( */\n  CHAR_RIGHT_PARENTHESES, /* ) */\n  CHAR_LEFT_CURLY_BRACE, /* { */\n  CHAR_RIGHT_CURLY_BRACE, /* } */\n  CHAR_LEFT_SQUARE_BRACKET, /* [ */\n  CHAR_RIGHT_SQUARE_BRACKET, /* ] */\n  CHAR_DOUBLE_QUOTE, /* \" */\n  CHAR_SINGLE_QUOTE, /* ' */\n  CHAR_NO_BREAK_SPACE,\n  CHAR_ZERO_WIDTH_NOBREAK_SPACE\n} = constants$3;\n\n/**\n * parse\n */\n\nconst parse$c = (input, options = {}) => {\n  if (typeof input !== 'string') {\n    throw new TypeError('Expected a string');\n  }\n\n  let opts = options || {};\n  let max = typeof opts.maxLength === 'number' ? Math.min(MAX_LENGTH, opts.maxLength) : MAX_LENGTH;\n  if (input.length > max) {\n    throw new SyntaxError(`Input length (${input.length}), exceeds max characters (${max})`);\n  }\n\n  let ast = { type: 'root', input, nodes: [] };\n  let stack = [ast];\n  let block = ast;\n  let prev = ast;\n  let brackets = 0;\n  let length = input.length;\n  let index = 0;\n  let depth = 0;\n  let value;\n\n  /**\n   * Helpers\n   */\n\n  const advance = () => input[index++];\n  const push = node => {\n    if (node.type === 'text' && prev.type === 'dot') {\n      prev.type = 'text';\n    }\n\n    if (prev && prev.type === 'text' && node.type === 'text') {\n      prev.value += node.value;\n      return;\n    }\n\n    block.nodes.push(node);\n    node.parent = block;\n    node.prev = prev;\n    prev = node;\n    return node;\n  };\n\n  push({ type: 'bos' });\n\n  while (index < length) {\n    block = stack[stack.length - 1];\n    value = advance();\n\n    /**\n     * Invalid chars\n     */\n\n    if (value === CHAR_ZERO_WIDTH_NOBREAK_SPACE || value === CHAR_NO_BREAK_SPACE) {\n      continue;\n    }\n\n    /**\n     * Escaped chars\n     */\n\n    if (value === CHAR_BACKSLASH) {\n      push({ type: 'text', value: (options.keepEscaping ? value : '') + advance() });\n      continue;\n    }\n\n    /**\n     * Right square bracket (literal): ']'\n     */\n\n    if (value === CHAR_RIGHT_SQUARE_BRACKET) {\n      push({ type: 'text', value: '\\\\' + value });\n      continue;\n    }\n\n    /**\n     * Left square bracket: '['\n     */\n\n    if (value === CHAR_LEFT_SQUARE_BRACKET) {\n      brackets++;\n      let next;\n\n      while (index < length && (next = advance())) {\n        value += next;\n\n        if (next === CHAR_LEFT_SQUARE_BRACKET) {\n          brackets++;\n          continue;\n        }\n\n        if (next === CHAR_BACKSLASH) {\n          value += advance();\n          continue;\n        }\n\n        if (next === CHAR_RIGHT_SQUARE_BRACKET) {\n          brackets--;\n\n          if (brackets === 0) {\n            break;\n          }\n        }\n      }\n\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Parentheses\n     */\n\n    if (value === CHAR_LEFT_PARENTHESES) {\n      block = push({ type: 'paren', nodes: [] });\n      stack.push(block);\n      push({ type: 'text', value });\n      continue;\n    }\n\n    if (value === CHAR_RIGHT_PARENTHESES) {\n      if (block.type !== 'paren') {\n        push({ type: 'text', value });\n        continue;\n      }\n      block = stack.pop();\n      push({ type: 'text', value });\n      block = stack[stack.length - 1];\n      continue;\n    }\n\n    /**\n     * Quotes: '|\"|`\n     */\n\n    if (value === CHAR_DOUBLE_QUOTE || value === CHAR_SINGLE_QUOTE || value === CHAR_BACKTICK) {\n      let open = value;\n      let next;\n\n      if (options.keepQuotes !== true) {\n        value = '';\n      }\n\n      while (index < length && (next = advance())) {\n        if (next === CHAR_BACKSLASH) {\n          value += next + advance();\n          continue;\n        }\n\n        if (next === open) {\n          if (options.keepQuotes === true) value += next;\n          break;\n        }\n\n        value += next;\n      }\n\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Left curly brace: '{'\n     */\n\n    if (value === CHAR_LEFT_CURLY_BRACE) {\n      depth++;\n\n      let dollar = prev.value && prev.value.slice(-1) === '$' || block.dollar === true;\n      let brace = {\n        type: 'brace',\n        open: true,\n        close: false,\n        dollar,\n        depth,\n        commas: 0,\n        ranges: 0,\n        nodes: []\n      };\n\n      block = push(brace);\n      stack.push(block);\n      push({ type: 'open', value });\n      continue;\n    }\n\n    /**\n     * Right curly brace: '}'\n     */\n\n    if (value === CHAR_RIGHT_CURLY_BRACE) {\n      if (block.type !== 'brace') {\n        push({ type: 'text', value });\n        continue;\n      }\n\n      let type = 'close';\n      block = stack.pop();\n      block.close = true;\n\n      push({ type, value });\n      depth--;\n\n      block = stack[stack.length - 1];\n      continue;\n    }\n\n    /**\n     * Comma: ','\n     */\n\n    if (value === CHAR_COMMA && depth > 0) {\n      if (block.ranges > 0) {\n        block.ranges = 0;\n        let open = block.nodes.shift();\n        block.nodes = [open, { type: 'text', value: stringify$4(block) }];\n      }\n\n      push({ type: 'comma', value });\n      block.commas++;\n      continue;\n    }\n\n    /**\n     * Dot: '.'\n     */\n\n    if (value === CHAR_DOT && depth > 0 && block.commas === 0) {\n      let siblings = block.nodes;\n\n      if (depth === 0 || siblings.length === 0) {\n        push({ type: 'text', value });\n        continue;\n      }\n\n      if (prev.type === 'dot') {\n        block.range = [];\n        prev.value += value;\n        prev.type = 'range';\n\n        if (block.nodes.length !== 3 && block.nodes.length !== 5) {\n          block.invalid = true;\n          block.ranges = 0;\n          prev.type = 'text';\n          continue;\n        }\n\n        block.ranges++;\n        block.args = [];\n        continue;\n      }\n\n      if (prev.type === 'range') {\n        siblings.pop();\n\n        let before = siblings[siblings.length - 1];\n        before.value += prev.value + value;\n        prev = before;\n        block.ranges--;\n        continue;\n      }\n\n      push({ type: 'dot', value });\n      continue;\n    }\n\n    /**\n     * Text\n     */\n\n    push({ type: 'text', value });\n  }\n\n  // Mark imbalanced braces and brackets as invalid\n  do {\n    block = stack.pop();\n\n    if (block.type !== 'root') {\n      block.nodes.forEach(node => {\n        if (!node.nodes) {\n          if (node.type === 'open') node.isOpen = true;\n          if (node.type === 'close') node.isClose = true;\n          if (!node.nodes) node.type = 'text';\n          node.invalid = true;\n        }\n      });\n\n      // get the location of the block on parent.nodes (block's siblings)\n      let parent = stack[stack.length - 1];\n      let index = parent.nodes.indexOf(block);\n      // replace the (invalid) block with it's nodes\n      parent.nodes.splice(index, 1, ...block.nodes);\n    }\n  } while (stack.length > 0);\n\n  push({ type: 'eos' });\n  return ast;\n};\n\nvar parse_1$2 = parse$c;\n\nconst stringify$3 = stringify$7;\nconst compile = compile_1;\nconst expand$1 = expand_1$1;\nconst parse$b = parse_1$2;\n\n/**\n * Expand the given pattern or create a regex-compatible string.\n *\n * ```js\n * const braces = require('braces');\n * console.log(braces('{a,b,c}', { compile: true })); //=> ['(a|b|c)']\n * console.log(braces('{a,b,c}')); //=> ['a', 'b', 'c']\n * ```\n * @param {String} `str`\n * @param {Object} `options`\n * @return {String}\n * @api public\n */\n\nconst braces$2 = (input, options = {}) => {\n  let output = [];\n\n  if (Array.isArray(input)) {\n    for (let pattern of input) {\n      let result = braces$2.create(pattern, options);\n      if (Array.isArray(result)) {\n        output.push(...result);\n      } else {\n        output.push(result);\n      }\n    }\n  } else {\n    output = [].concat(braces$2.create(input, options));\n  }\n\n  if (options && options.expand === true && options.nodupes === true) {\n    output = [...new Set(output)];\n  }\n  return output;\n};\n\n/**\n * Parse the given `str` with the given `options`.\n *\n * ```js\n * // braces.parse(pattern, [, options]);\n * const ast = braces.parse('a/{b,c}/d');\n * console.log(ast);\n * ```\n * @param {String} pattern Brace pattern to parse\n * @param {Object} options\n * @return {Object} Returns an AST\n * @api public\n */\n\nbraces$2.parse = (input, options = {}) => parse$b(input, options);\n\n/**\n * Creates a braces string from an AST, or an AST node.\n *\n * ```js\n * const braces = require('braces');\n * let ast = braces.parse('foo/{a,b}/bar');\n * console.log(stringify(ast.nodes[2])); //=> '{a,b}'\n * ```\n * @param {String} `input` Brace pattern or AST.\n * @param {Object} `options`\n * @return {Array} Returns an array of expanded values.\n * @api public\n */\n\nbraces$2.stringify = (input, options = {}) => {\n  if (typeof input === 'string') {\n    return stringify$3(braces$2.parse(input, options), options);\n  }\n  return stringify$3(input, options);\n};\n\n/**\n * Compiles a brace pattern into a regex-compatible, optimized string.\n * This method is called by the main [braces](#braces) function by default.\n *\n * ```js\n * const braces = require('braces');\n * console.log(braces.compile('a/{b,c}/d'));\n * //=> ['a/(b|c)/d']\n * ```\n * @param {String} `input` Brace pattern or AST.\n * @param {Object} `options`\n * @return {Array} Returns an array of expanded values.\n * @api public\n */\n\nbraces$2.compile = (input, options = {}) => {\n  if (typeof input === 'string') {\n    input = braces$2.parse(input, options);\n  }\n  return compile(input, options);\n};\n\n/**\n * Expands a brace pattern into an array. This method is called by the\n * main [braces](#braces) function when `options.expand` is true. Before\n * using this method it's recommended that you read the [performance notes](#performance))\n * and advantages of using [.compile](#compile) instead.\n *\n * ```js\n * const braces = require('braces');\n * console.log(braces.expand('a/{b,c}/d'));\n * //=> ['a/b/d', 'a/c/d'];\n * ```\n * @param {String} `pattern` Brace pattern\n * @param {Object} `options`\n * @return {Array} Returns an array of expanded values.\n * @api public\n */\n\nbraces$2.expand = (input, options = {}) => {\n  if (typeof input === 'string') {\n    input = braces$2.parse(input, options);\n  }\n\n  let result = expand$1(input, options);\n\n  // filter out empty strings if specified\n  if (options.noempty === true) {\n    result = result.filter(Boolean);\n  }\n\n  // filter out duplicates if specified\n  if (options.nodupes === true) {\n    result = [...new Set(result)];\n  }\n\n  return result;\n};\n\n/**\n * Processes a brace pattern and returns either an expanded array\n * (if `options.expand` is true), a highly optimized regex-compatible string.\n * This method is called by the main [braces](#braces) function.\n *\n * ```js\n * const braces = require('braces');\n * console.log(braces.create('user-{200..300}/project-{a,b,c}-{1..10}'))\n * //=> 'user-(20[0-9]|2[1-9][0-9]|300)/project-(a|b|c)-([1-9]|10)'\n * ```\n * @param {String} `pattern` Brace pattern\n * @param {Object} `options`\n * @return {Array} Returns an array of expanded values.\n * @api public\n */\n\nbraces$2.create = (input, options = {}) => {\n  if (input === '' || input.length < 3) {\n    return [input];\n  }\n\n return options.expand !== true\n    ? braces$2.compile(input, options)\n    : braces$2.expand(input, options);\n};\n\n/**\n * Expose \"braces\"\n */\n\nvar braces_1 = braces$2;\n\nconst util = require$$0$6;\nconst braces$1 = braces_1;\nconst picomatch$2 = picomatchExports;\nconst utils$b = utils$k;\nconst isEmptyString = val => val === '' || val === './';\n\n/**\n * Returns an array of strings that match one or more glob patterns.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm(list, patterns[, options]);\n *\n * console.log(mm(['a.js', 'a.txt'], ['*.js']));\n * //=> [ 'a.js' ]\n * ```\n * @param {String|Array<string>} `list` List of strings to match.\n * @param {String|Array<string>} `patterns` One or more glob patterns to use for matching.\n * @param {Object} `options` See available [options](#options)\n * @return {Array} Returns an array of matches\n * @summary false\n * @api public\n */\n\nconst micromatch$1 = (list, patterns, options) => {\n  patterns = [].concat(patterns);\n  list = [].concat(list);\n\n  let omit = new Set();\n  let keep = new Set();\n  let items = new Set();\n  let negatives = 0;\n\n  let onResult = state => {\n    items.add(state.output);\n    if (options && options.onResult) {\n      options.onResult(state);\n    }\n  };\n\n  for (let i = 0; i < patterns.length; i++) {\n    let isMatch = picomatch$2(String(patterns[i]), { ...options, onResult }, true);\n    let negated = isMatch.state.negated || isMatch.state.negatedExtglob;\n    if (negated) negatives++;\n\n    for (let item of list) {\n      let matched = isMatch(item, true);\n\n      let match = negated ? !matched.isMatch : matched.isMatch;\n      if (!match) continue;\n\n      if (negated) {\n        omit.add(matched.output);\n      } else {\n        omit.delete(matched.output);\n        keep.add(matched.output);\n      }\n    }\n  }\n\n  let result = negatives === patterns.length ? [...items] : [...keep];\n  let matches = result.filter(item => !omit.has(item));\n\n  if (options && matches.length === 0) {\n    if (options.failglob === true) {\n      throw new Error(`No matches found for \"${patterns.join(', ')}\"`);\n    }\n\n    if (options.nonull === true || options.nullglob === true) {\n      return options.unescape ? patterns.map(p => p.replace(/\\\\/g, '')) : patterns;\n    }\n  }\n\n  return matches;\n};\n\n/**\n * Backwards compatibility\n */\n\nmicromatch$1.match = micromatch$1;\n\n/**\n * Returns a matcher function from the given glob `pattern` and `options`.\n * The returned function takes a string to match as its only argument and returns\n * true if the string is a match.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.matcher(pattern[, options]);\n *\n * const isMatch = mm.matcher('*.!(*a)');\n * console.log(isMatch('a.a')); //=> false\n * console.log(isMatch('a.b')); //=> true\n * ```\n * @param {String} `pattern` Glob pattern\n * @param {Object} `options`\n * @return {Function} Returns a matcher function.\n * @api public\n */\n\nmicromatch$1.matcher = (pattern, options) => picomatch$2(pattern, options);\n\n/**\n * Returns true if **any** of the given glob `patterns` match the specified `string`.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.isMatch(string, patterns[, options]);\n *\n * console.log(mm.isMatch('a.a', ['b.*', '*.a'])); //=> true\n * console.log(mm.isMatch('a.a', 'b.*')); //=> false\n * ```\n * @param {String} `str` The string to test.\n * @param {String|Array} `patterns` One or more glob patterns to use for matching.\n * @param {Object} `[options]` See available [options](#options).\n * @return {Boolean} Returns true if any patterns match `str`\n * @api public\n */\n\nmicromatch$1.isMatch = (str, patterns, options) => picomatch$2(patterns, options)(str);\n\n/**\n * Backwards compatibility\n */\n\nmicromatch$1.any = micromatch$1.isMatch;\n\n/**\n * Returns a list of strings that _**do not match any**_ of the given `patterns`.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.not(list, patterns[, options]);\n *\n * console.log(mm.not(['a.a', 'b.b', 'c.c'], '*.a'));\n * //=> ['b.b', 'c.c']\n * ```\n * @param {Array} `list` Array of strings to match.\n * @param {String|Array} `patterns` One or more glob pattern to use for matching.\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Array} Returns an array of strings that **do not match** the given patterns.\n * @api public\n */\n\nmicromatch$1.not = (list, patterns, options = {}) => {\n  patterns = [].concat(patterns).map(String);\n  let result = new Set();\n  let items = [];\n\n  let onResult = state => {\n    if (options.onResult) options.onResult(state);\n    items.push(state.output);\n  };\n\n  let matches = new Set(micromatch$1(list, patterns, { ...options, onResult }));\n\n  for (let item of items) {\n    if (!matches.has(item)) {\n      result.add(item);\n    }\n  }\n  return [...result];\n};\n\n/**\n * Returns true if the given `string` contains the given pattern. Similar\n * to [.isMatch](#isMatch) but the pattern can match any part of the string.\n *\n * ```js\n * var mm = require('micromatch');\n * // mm.contains(string, pattern[, options]);\n *\n * console.log(mm.contains('aa/bb/cc', '*b'));\n * //=> true\n * console.log(mm.contains('aa/bb/cc', '*d'));\n * //=> false\n * ```\n * @param {String} `str` The string to match.\n * @param {String|Array} `patterns` Glob pattern to use for matching.\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Boolean} Returns true if any of the patterns matches any part of `str`.\n * @api public\n */\n\nmicromatch$1.contains = (str, pattern, options) => {\n  if (typeof str !== 'string') {\n    throw new TypeError(`Expected a string: \"${util.inspect(str)}\"`);\n  }\n\n  if (Array.isArray(pattern)) {\n    return pattern.some(p => micromatch$1.contains(str, p, options));\n  }\n\n  if (typeof pattern === 'string') {\n    if (isEmptyString(str) || isEmptyString(pattern)) {\n      return false;\n    }\n\n    if (str.includes(pattern) || (str.startsWith('./') && str.slice(2).includes(pattern))) {\n      return true;\n    }\n  }\n\n  return micromatch$1.isMatch(str, pattern, { ...options, contains: true });\n};\n\n/**\n * Filter the keys of the given object with the given `glob` pattern\n * and `options`. Does not attempt to match nested keys. If you need this feature,\n * use [glob-object][] instead.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.matchKeys(object, patterns[, options]);\n *\n * const obj = { aa: 'a', ab: 'b', ac: 'c' };\n * console.log(mm.matchKeys(obj, '*b'));\n * //=> { ab: 'b' }\n * ```\n * @param {Object} `object` The object with keys to filter.\n * @param {String|Array} `patterns` One or more glob patterns to use for matching.\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Object} Returns an object with only keys that match the given patterns.\n * @api public\n */\n\nmicromatch$1.matchKeys = (obj, patterns, options) => {\n  if (!utils$b.isObject(obj)) {\n    throw new TypeError('Expected the first argument to be an object');\n  }\n  let keys = micromatch$1(Object.keys(obj), patterns, options);\n  let res = {};\n  for (let key of keys) res[key] = obj[key];\n  return res;\n};\n\n/**\n * Returns true if some of the strings in the given `list` match any of the given glob `patterns`.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.some(list, patterns[, options]);\n *\n * console.log(mm.some(['foo.js', 'bar.js'], ['*.js', '!foo.js']));\n * // true\n * console.log(mm.some(['foo.js'], ['*.js', '!foo.js']));\n * // false\n * ```\n * @param {String|Array} `list` The string or array of strings to test. Returns as soon as the first match is found.\n * @param {String|Array} `patterns` One or more glob patterns to use for matching.\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Boolean} Returns true if any `patterns` matches any of the strings in `list`\n * @api public\n */\n\nmicromatch$1.some = (list, patterns, options) => {\n  let items = [].concat(list);\n\n  for (let pattern of [].concat(patterns)) {\n    let isMatch = picomatch$2(String(pattern), options);\n    if (items.some(item => isMatch(item))) {\n      return true;\n    }\n  }\n  return false;\n};\n\n/**\n * Returns true if every string in the given `list` matches\n * any of the given glob `patterns`.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.every(list, patterns[, options]);\n *\n * console.log(mm.every('foo.js', ['foo.js']));\n * // true\n * console.log(mm.every(['foo.js', 'bar.js'], ['*.js']));\n * // true\n * console.log(mm.every(['foo.js', 'bar.js'], ['*.js', '!foo.js']));\n * // false\n * console.log(mm.every(['foo.js'], ['*.js', '!foo.js']));\n * // false\n * ```\n * @param {String|Array} `list` The string or array of strings to test.\n * @param {String|Array} `patterns` One or more glob patterns to use for matching.\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Boolean} Returns true if all `patterns` matches all of the strings in `list`\n * @api public\n */\n\nmicromatch$1.every = (list, patterns, options) => {\n  let items = [].concat(list);\n\n  for (let pattern of [].concat(patterns)) {\n    let isMatch = picomatch$2(String(pattern), options);\n    if (!items.every(item => isMatch(item))) {\n      return false;\n    }\n  }\n  return true;\n};\n\n/**\n * Returns true if **all** of the given `patterns` match\n * the specified string.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.all(string, patterns[, options]);\n *\n * console.log(mm.all('foo.js', ['foo.js']));\n * // true\n *\n * console.log(mm.all('foo.js', ['*.js', '!foo.js']));\n * // false\n *\n * console.log(mm.all('foo.js', ['*.js', 'foo.js']));\n * // true\n *\n * console.log(mm.all('foo.js', ['*.js', 'f*', '*o*', '*o.js']));\n * // true\n * ```\n * @param {String|Array} `str` The string to test.\n * @param {String|Array} `patterns` One or more glob patterns to use for matching.\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Boolean} Returns true if any patterns match `str`\n * @api public\n */\n\nmicromatch$1.all = (str, patterns, options) => {\n  if (typeof str !== 'string') {\n    throw new TypeError(`Expected a string: \"${util.inspect(str)}\"`);\n  }\n\n  return [].concat(patterns).every(p => picomatch$2(p, options)(str));\n};\n\n/**\n * Returns an array of matches captured by `pattern` in `string, or `null` if the pattern did not match.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.capture(pattern, string[, options]);\n *\n * console.log(mm.capture('test/*.js', 'test/foo.js'));\n * //=> ['foo']\n * console.log(mm.capture('test/*.js', 'foo/bar.css'));\n * //=> null\n * ```\n * @param {String} `glob` Glob pattern to use for matching.\n * @param {String} `input` String to match\n * @param {Object} `options` See available [options](#options) for changing how matches are performed\n * @return {Array|null} Returns an array of captures if the input matches the glob pattern, otherwise `null`.\n * @api public\n */\n\nmicromatch$1.capture = (glob, input, options) => {\n  let posix = utils$b.isWindows(options);\n  let regex = picomatch$2.makeRe(String(glob), { ...options, capture: true });\n  let match = regex.exec(posix ? utils$b.toPosixSlashes(input) : input);\n\n  if (match) {\n    return match.slice(1).map(v => v === void 0 ? '' : v);\n  }\n};\n\n/**\n * Create a regular expression from the given glob `pattern`.\n *\n * ```js\n * const mm = require('micromatch');\n * // mm.makeRe(pattern[, options]);\n *\n * console.log(mm.makeRe('*.js'));\n * //=> /^(?:(\\.[\\\\\\/])?(?!\\.)(?=.)[^\\/]*?\\.js)$/\n * ```\n * @param {String} `pattern` A glob pattern to convert to regex.\n * @param {Object} `options`\n * @return {RegExp} Returns a regex created from the given pattern.\n * @api public\n */\n\nmicromatch$1.makeRe = (...args) => picomatch$2.makeRe(...args);\n\n/**\n * Scan a glob pattern to separate the pattern into segments. Used\n * by the [split](#split) method.\n *\n * ```js\n * const mm = require('micromatch');\n * const state = mm.scan(pattern[, options]);\n * ```\n * @param {String} `pattern`\n * @param {Object} `options`\n * @return {Object} Returns an object with\n * @api public\n */\n\nmicromatch$1.scan = (...args) => picomatch$2.scan(...args);\n\n/**\n * Parse a glob pattern to create the source string for a regular\n * expression.\n *\n * ```js\n * const mm = require('micromatch');\n * const state = mm.parse(pattern[, options]);\n * ```\n * @param {String} `glob`\n * @param {Object} `options`\n * @return {Object} Returns an object with useful properties and output to be used as regex source string.\n * @api public\n */\n\nmicromatch$1.parse = (patterns, options) => {\n  let res = [];\n  for (let pattern of [].concat(patterns || [])) {\n    for (let str of braces$1(String(pattern), options)) {\n      res.push(picomatch$2.parse(str, options));\n    }\n  }\n  return res;\n};\n\n/**\n * Process the given brace `pattern`.\n *\n * ```js\n * const { braces } = require('micromatch');\n * console.log(braces('foo/{a,b,c}/bar'));\n * //=> [ 'foo/(a|b|c)/bar' ]\n *\n * console.log(braces('foo/{a,b,c}/bar', { expand: true }));\n * //=> [ 'foo/a/bar', 'foo/b/bar', 'foo/c/bar' ]\n * ```\n * @param {String} `pattern` String with brace pattern to process.\n * @param {Object} `options` Any [options](#options) to change how expansion is performed. See the [braces][] library for all available options.\n * @return {Array}\n * @api public\n */\n\nmicromatch$1.braces = (pattern, options) => {\n  if (typeof pattern !== 'string') throw new TypeError('Expected a string');\n  if ((options && options.nobrace === true) || !/\\{.*\\}/.test(pattern)) {\n    return [pattern];\n  }\n  return braces$1(pattern, options);\n};\n\n/**\n * Expand braces\n */\n\nmicromatch$1.braceExpand = (pattern, options) => {\n  if (typeof pattern !== 'string') throw new TypeError('Expected a string');\n  return micromatch$1.braces(pattern, { ...options, expand: true });\n};\n\n/**\n * Expose micromatch\n */\n\nvar micromatch_1 = micromatch$1;\n\nObject.defineProperty(pattern$1, \"__esModule\", { value: true });\r\npattern$1.matchAny = pattern$1.convertPatternsToRe = pattern$1.makeRe = pattern$1.getPatternParts = pattern$1.expandBraceExpansion = pattern$1.expandPatternsWithBraceExpansion = pattern$1.isAffectDepthOfReadingPattern = pattern$1.endsWithSlashGlobStar = pattern$1.hasGlobStar = pattern$1.getBaseDirectory = pattern$1.isPatternRelatedToParentDirectory = pattern$1.getPatternsOutsideCurrentDirectory = pattern$1.getPatternsInsideCurrentDirectory = pattern$1.getPositivePatterns = pattern$1.getNegativePatterns = pattern$1.isPositivePattern = pattern$1.isNegativePattern = pattern$1.convertToNegativePattern = pattern$1.convertToPositivePattern = pattern$1.isDynamicPattern = pattern$1.isStaticPattern = void 0;\r\nconst path$f = require$$0$4;\r\nconst globParent$1 = globParent$2;\r\nconst micromatch = micromatch_1;\r\nconst GLOBSTAR$1 = '**';\r\nconst ESCAPE_SYMBOL = '\\\\';\r\nconst COMMON_GLOB_SYMBOLS_RE = /[*?]|^!/;\r\nconst REGEX_CHARACTER_CLASS_SYMBOLS_RE = /\\[[^[]*]/;\r\nconst REGEX_GROUP_SYMBOLS_RE = /(?:^|[^!*+?@])\\([^(]*\\|[^|]*\\)/;\r\nconst GLOB_EXTENSION_SYMBOLS_RE = /[!*+?@]\\([^(]*\\)/;\r\nconst BRACE_EXPANSION_SEPARATORS_RE = /,|\\.\\./;\r\nfunction isStaticPattern(pattern, options = {}) {\r\n    return !isDynamicPattern(pattern, options);\r\n}\r\npattern$1.isStaticPattern = isStaticPattern;\r\nfunction isDynamicPattern(pattern, options = {}) {\r\n    /**\r\n     * A special case with an empty string is necessary for matching patterns that start with a forward slash.\r\n     * An empty string cannot be a dynamic pattern.\r\n     * For example, the pattern `/lib/*` will be spread into parts: '', 'lib', '*'.\r\n     */\r\n    if (pattern === '') {\r\n        return false;\r\n    }\r\n    /**\r\n     * When the `caseSensitiveMatch` option is disabled, all patterns must be marked as dynamic, because we cannot check\r\n     * filepath directly (without read directory).\r\n     */\r\n    if (options.caseSensitiveMatch === false || pattern.includes(ESCAPE_SYMBOL)) {\r\n        return true;\r\n    }\r\n    if (COMMON_GLOB_SYMBOLS_RE.test(pattern) || REGEX_CHARACTER_CLASS_SYMBOLS_RE.test(pattern) || REGEX_GROUP_SYMBOLS_RE.test(pattern)) {\r\n        return true;\r\n    }\r\n    if (options.extglob !== false && GLOB_EXTENSION_SYMBOLS_RE.test(pattern)) {\r\n        return true;\r\n    }\r\n    if (options.braceExpansion !== false && hasBraceExpansion(pattern)) {\r\n        return true;\r\n    }\r\n    return false;\r\n}\r\npattern$1.isDynamicPattern = isDynamicPattern;\r\nfunction hasBraceExpansion(pattern) {\r\n    const openingBraceIndex = pattern.indexOf('{');\r\n    if (openingBraceIndex === -1) {\r\n        return false;\r\n    }\r\n    const closingBraceIndex = pattern.indexOf('}', openingBraceIndex + 1);\r\n    if (closingBraceIndex === -1) {\r\n        return false;\r\n    }\r\n    const braceContent = pattern.slice(openingBraceIndex, closingBraceIndex);\r\n    return BRACE_EXPANSION_SEPARATORS_RE.test(braceContent);\r\n}\r\nfunction convertToPositivePattern(pattern) {\r\n    return isNegativePattern(pattern) ? pattern.slice(1) : pattern;\r\n}\r\npattern$1.convertToPositivePattern = convertToPositivePattern;\r\nfunction convertToNegativePattern(pattern) {\r\n    return '!' + pattern;\r\n}\r\npattern$1.convertToNegativePattern = convertToNegativePattern;\r\nfunction isNegativePattern(pattern) {\r\n    return pattern.startsWith('!') && pattern[1] !== '(';\r\n}\r\npattern$1.isNegativePattern = isNegativePattern;\r\nfunction isPositivePattern(pattern) {\r\n    return !isNegativePattern(pattern);\r\n}\r\npattern$1.isPositivePattern = isPositivePattern;\r\nfunction getNegativePatterns(patterns) {\r\n    return patterns.filter(isNegativePattern);\r\n}\r\npattern$1.getNegativePatterns = getNegativePatterns;\r\nfunction getPositivePatterns$1(patterns) {\r\n    return patterns.filter(isPositivePattern);\r\n}\r\npattern$1.getPositivePatterns = getPositivePatterns$1;\r\n/**\r\n * Returns patterns that can be applied inside the current directory.\r\n *\r\n * @example\r\n * // ['./*', '*', 'a/*']\r\n * getPatternsInsideCurrentDirectory(['./*', '*', 'a/*', '../*', './../*'])\r\n */\r\nfunction getPatternsInsideCurrentDirectory(patterns) {\r\n    return patterns.filter((pattern) => !isPatternRelatedToParentDirectory(pattern));\r\n}\r\npattern$1.getPatternsInsideCurrentDirectory = getPatternsInsideCurrentDirectory;\r\n/**\r\n * Returns patterns to be expanded relative to (outside) the current directory.\r\n *\r\n * @example\r\n * // ['../*', './../*']\r\n * getPatternsInsideCurrentDirectory(['./*', '*', 'a/*', '../*', './../*'])\r\n */\r\nfunction getPatternsOutsideCurrentDirectory(patterns) {\r\n    return patterns.filter(isPatternRelatedToParentDirectory);\r\n}\r\npattern$1.getPatternsOutsideCurrentDirectory = getPatternsOutsideCurrentDirectory;\r\nfunction isPatternRelatedToParentDirectory(pattern) {\r\n    return pattern.startsWith('..') || pattern.startsWith('./..');\r\n}\r\npattern$1.isPatternRelatedToParentDirectory = isPatternRelatedToParentDirectory;\r\nfunction getBaseDirectory(pattern) {\r\n    return globParent$1(pattern, { flipBackslashes: false });\r\n}\r\npattern$1.getBaseDirectory = getBaseDirectory;\r\nfunction hasGlobStar(pattern) {\r\n    return pattern.includes(GLOBSTAR$1);\r\n}\r\npattern$1.hasGlobStar = hasGlobStar;\r\nfunction endsWithSlashGlobStar(pattern) {\r\n    return pattern.endsWith('/' + GLOBSTAR$1);\r\n}\r\npattern$1.endsWithSlashGlobStar = endsWithSlashGlobStar;\r\nfunction isAffectDepthOfReadingPattern(pattern) {\r\n    const basename = path$f.basename(pattern);\r\n    return endsWithSlashGlobStar(pattern) || isStaticPattern(basename);\r\n}\r\npattern$1.isAffectDepthOfReadingPattern = isAffectDepthOfReadingPattern;\r\nfunction expandPatternsWithBraceExpansion(patterns) {\r\n    return patterns.reduce((collection, pattern) => {\r\n        return collection.concat(expandBraceExpansion(pattern));\r\n    }, []);\r\n}\r\npattern$1.expandPatternsWithBraceExpansion = expandPatternsWithBraceExpansion;\r\nfunction expandBraceExpansion(pattern) {\r\n    return micromatch.braces(pattern, {\r\n        expand: true,\r\n        nodupes: true\r\n    });\r\n}\r\npattern$1.expandBraceExpansion = expandBraceExpansion;\r\nfunction getPatternParts(pattern, options) {\r\n    let { parts } = micromatch.scan(pattern, Object.assign(Object.assign({}, options), { parts: true }));\r\n    /**\r\n     * The scan method returns an empty array in some cases.\r\n     * See micromatch/picomatch#58 for more details.\r\n     */\r\n    if (parts.length === 0) {\r\n        parts = [pattern];\r\n    }\r\n    /**\r\n     * The scan method does not return an empty part for the pattern with a forward slash.\r\n     * This is another part of micromatch/picomatch#58.\r\n     */\r\n    if (parts[0].startsWith('/')) {\r\n        parts[0] = parts[0].slice(1);\r\n        parts.unshift('');\r\n    }\r\n    return parts;\r\n}\r\npattern$1.getPatternParts = getPatternParts;\r\nfunction makeRe(pattern, options) {\r\n    return micromatch.makeRe(pattern, options);\r\n}\r\npattern$1.makeRe = makeRe;\r\nfunction convertPatternsToRe(patterns, options) {\r\n    return patterns.map((pattern) => makeRe(pattern, options));\r\n}\r\npattern$1.convertPatternsToRe = convertPatternsToRe;\r\nfunction matchAny(entry, patternsRe) {\r\n    return patternsRe.some((patternRe) => patternRe.test(entry));\r\n}\r\npattern$1.matchAny = matchAny;\n\nvar stream$4 = {};\n\n/*\n * merge2\n * https://github.com/teambition/merge2\n *\n * Copyright (c) 2014-2020 Teambition\n * Licensed under the MIT license.\n */\nconst Stream = require$$0$7;\nconst PassThrough = Stream.PassThrough;\nconst slice = Array.prototype.slice;\n\nvar merge2_1 = merge2$1;\n\nfunction merge2$1 () {\n  const streamsQueue = [];\n  const args = slice.call(arguments);\n  let merging = false;\n  let options = args[args.length - 1];\n\n  if (options && !Array.isArray(options) && options.pipe == null) {\n    args.pop();\n  } else {\n    options = {};\n  }\n\n  const doEnd = options.end !== false;\n  const doPipeError = options.pipeError === true;\n  if (options.objectMode == null) {\n    options.objectMode = true;\n  }\n  if (options.highWaterMark == null) {\n    options.highWaterMark = 64 * 1024;\n  }\n  const mergedStream = PassThrough(options);\n\n  function addStream () {\n    for (let i = 0, len = arguments.length; i < len; i++) {\n      streamsQueue.push(pauseStreams(arguments[i], options));\n    }\n    mergeStream();\n    return this\n  }\n\n  function mergeStream () {\n    if (merging) {\n      return\n    }\n    merging = true;\n\n    let streams = streamsQueue.shift();\n    if (!streams) {\n      process.nextTick(endStream);\n      return\n    }\n    if (!Array.isArray(streams)) {\n      streams = [streams];\n    }\n\n    let pipesCount = streams.length + 1;\n\n    function next () {\n      if (--pipesCount > 0) {\n        return\n      }\n      merging = false;\n      mergeStream();\n    }\n\n    function pipe (stream) {\n      function onend () {\n        stream.removeListener('merge2UnpipeEnd', onend);\n        stream.removeListener('end', onend);\n        if (doPipeError) {\n          stream.removeListener('error', onerror);\n        }\n        next();\n      }\n      function onerror (err) {\n        mergedStream.emit('error', err);\n      }\n      // skip ended stream\n      if (stream._readableState.endEmitted) {\n        return next()\n      }\n\n      stream.on('merge2UnpipeEnd', onend);\n      stream.on('end', onend);\n\n      if (doPipeError) {\n        stream.on('error', onerror);\n      }\n\n      stream.pipe(mergedStream, { end: false });\n      // compatible for old stream\n      stream.resume();\n    }\n\n    for (let i = 0; i < streams.length; i++) {\n      pipe(streams[i]);\n    }\n\n    next();\n  }\n\n  function endStream () {\n    merging = false;\n    // emit 'queueDrain' when all streams merged.\n    mergedStream.emit('queueDrain');\n    if (doEnd) {\n      mergedStream.end();\n    }\n  }\n\n  mergedStream.setMaxListeners(0);\n  mergedStream.add = addStream;\n  mergedStream.on('unpipe', function (stream) {\n    stream.emit('merge2UnpipeEnd');\n  });\n\n  if (args.length) {\n    addStream.apply(null, args);\n  }\n  return mergedStream\n}\n\n// check and pause streams for pipe.\nfunction pauseStreams (streams, options) {\n  if (!Array.isArray(streams)) {\n    // Backwards-compat with old-style streams\n    if (!streams._readableState && streams.pipe) {\n      streams = streams.pipe(PassThrough(options));\n    }\n    if (!streams._readableState || !streams.pause || !streams.pipe) {\n      throw new Error('Only readable stream can be merged.')\n    }\n    streams.pause();\n  } else {\n    for (let i = 0, len = streams.length; i < len; i++) {\n      streams[i] = pauseStreams(streams[i], options);\n    }\n  }\n  return streams\n}\n\nObject.defineProperty(stream$4, \"__esModule\", { value: true });\r\nstream$4.merge = void 0;\r\nconst merge2 = merge2_1;\r\nfunction merge$1(streams) {\r\n    const mergedStream = merge2(streams);\r\n    streams.forEach((stream) => {\r\n        stream.once('error', (error) => mergedStream.emit('error', error));\r\n    });\r\n    mergedStream.once('close', () => propagateCloseEventToSources(streams));\r\n    mergedStream.once('end', () => propagateCloseEventToSources(streams));\r\n    return mergedStream;\r\n}\r\nstream$4.merge = merge$1;\r\nfunction propagateCloseEventToSources(streams) {\r\n    streams.forEach((stream) => stream.emit('close'));\r\n}\n\nvar string$2 = {};\n\nObject.defineProperty(string$2, \"__esModule\", { value: true });\r\nstring$2.isEmpty = string$2.isString = void 0;\r\nfunction isString(input) {\r\n    return typeof input === 'string';\r\n}\r\nstring$2.isString = isString;\r\nfunction isEmpty$1(input) {\r\n    return input === '';\r\n}\r\nstring$2.isEmpty = isEmpty$1;\n\nObject.defineProperty(utils$g, \"__esModule\", { value: true });\r\nutils$g.string = utils$g.stream = utils$g.pattern = utils$g.path = utils$g.fs = utils$g.errno = utils$g.array = void 0;\r\nconst array = array$1;\r\nutils$g.array = array;\r\nconst errno = errno$1;\r\nutils$g.errno = errno;\r\nconst fs$g = fs$h;\r\nutils$g.fs = fs$g;\r\nconst path$e = path$h;\r\nutils$g.path = path$e;\r\nconst pattern = pattern$1;\r\nutils$g.pattern = pattern;\r\nconst stream$3 = stream$4;\r\nutils$g.stream = stream$3;\r\nconst string$1 = string$2;\r\nutils$g.string = string$1;\n\nObject.defineProperty(tasks, \"__esModule\", { value: true });\r\ntasks.convertPatternGroupToTask = tasks.convertPatternGroupsToTasks = tasks.groupPatternsByBaseDirectory = tasks.getNegativePatternsAsPositive = tasks.getPositivePatterns = tasks.convertPatternsToTasks = tasks.generate = void 0;\r\nconst utils$a = utils$g;\r\nfunction generate(patterns, settings) {\r\n    const positivePatterns = getPositivePatterns(patterns);\r\n    const negativePatterns = getNegativePatternsAsPositive(patterns, settings.ignore);\r\n    const staticPatterns = positivePatterns.filter((pattern) => utils$a.pattern.isStaticPattern(pattern, settings));\r\n    const dynamicPatterns = positivePatterns.filter((pattern) => utils$a.pattern.isDynamicPattern(pattern, settings));\r\n    const staticTasks = convertPatternsToTasks(staticPatterns, negativePatterns, /* dynamic */ false);\r\n    const dynamicTasks = convertPatternsToTasks(dynamicPatterns, negativePatterns, /* dynamic */ true);\r\n    return staticTasks.concat(dynamicTasks);\r\n}\r\ntasks.generate = generate;\r\n/**\r\n * Returns tasks grouped by basic pattern directories.\r\n *\r\n * Patterns that can be found inside (`./`) and outside (`../`) the current directory are handled separately.\r\n * This is necessary because directory traversal starts at the base directory and goes deeper.\r\n */\r\nfunction convertPatternsToTasks(positive, negative, dynamic) {\r\n    const tasks = [];\r\n    const patternsOutsideCurrentDirectory = utils$a.pattern.getPatternsOutsideCurrentDirectory(positive);\r\n    const patternsInsideCurrentDirectory = utils$a.pattern.getPatternsInsideCurrentDirectory(positive);\r\n    const outsideCurrentDirectoryGroup = groupPatternsByBaseDirectory(patternsOutsideCurrentDirectory);\r\n    const insideCurrentDirectoryGroup = groupPatternsByBaseDirectory(patternsInsideCurrentDirectory);\r\n    tasks.push(...convertPatternGroupsToTasks(outsideCurrentDirectoryGroup, negative, dynamic));\r\n    /*\r\n     * For the sake of reducing future accesses to the file system, we merge all tasks within the current directory\r\n     * into a global task, if at least one pattern refers to the root (`.`). In this case, the global task covers the rest.\r\n     */\r\n    if ('.' in insideCurrentDirectoryGroup) {\r\n        tasks.push(convertPatternGroupToTask('.', patternsInsideCurrentDirectory, negative, dynamic));\r\n    }\r\n    else {\r\n        tasks.push(...convertPatternGroupsToTasks(insideCurrentDirectoryGroup, negative, dynamic));\r\n    }\r\n    return tasks;\r\n}\r\ntasks.convertPatternsToTasks = convertPatternsToTasks;\r\nfunction getPositivePatterns(patterns) {\r\n    return utils$a.pattern.getPositivePatterns(patterns);\r\n}\r\ntasks.getPositivePatterns = getPositivePatterns;\r\nfunction getNegativePatternsAsPositive(patterns, ignore) {\r\n    const negative = utils$a.pattern.getNegativePatterns(patterns).concat(ignore);\r\n    const positive = negative.map(utils$a.pattern.convertToPositivePattern);\r\n    return positive;\r\n}\r\ntasks.getNegativePatternsAsPositive = getNegativePatternsAsPositive;\r\nfunction groupPatternsByBaseDirectory(patterns) {\r\n    const group = {};\r\n    return patterns.reduce((collection, pattern) => {\r\n        const base = utils$a.pattern.getBaseDirectory(pattern);\r\n        if (base in collection) {\r\n            collection[base].push(pattern);\r\n        }\r\n        else {\r\n            collection[base] = [pattern];\r\n        }\r\n        return collection;\r\n    }, group);\r\n}\r\ntasks.groupPatternsByBaseDirectory = groupPatternsByBaseDirectory;\r\nfunction convertPatternGroupsToTasks(positive, negative, dynamic) {\r\n    return Object.keys(positive).map((base) => {\r\n        return convertPatternGroupToTask(base, positive[base], negative, dynamic);\r\n    });\r\n}\r\ntasks.convertPatternGroupsToTasks = convertPatternGroupsToTasks;\r\nfunction convertPatternGroupToTask(base, positive, negative, dynamic) {\r\n    return {\r\n        dynamic,\r\n        positive,\r\n        negative,\r\n        base,\r\n        patterns: [].concat(positive, negative.map(utils$a.pattern.convertToNegativePattern))\r\n    };\r\n}\r\ntasks.convertPatternGroupToTask = convertPatternGroupToTask;\n\nvar patterns = {};\n\nObject.defineProperty(patterns, \"__esModule\", { value: true });\r\npatterns.removeDuplicateSlashes = patterns.transform = void 0;\r\n/**\r\n * Matches a sequence of two or more consecutive slashes, excluding the first two slashes at the beginning of the string.\r\n * The latter is due to the presence of the device path at the beginning of the UNC path.\r\n * @todo rewrite to negative lookbehind with the next major release.\r\n */\r\nconst DOUBLE_SLASH_RE$1 = /(?!^)\\/{2,}/g;\r\nfunction transform(patterns) {\r\n    return patterns.map((pattern) => removeDuplicateSlashes(pattern));\r\n}\r\npatterns.transform = transform;\r\n/**\r\n * This package only works with forward slashes as a path separator.\r\n * Because of this, we cannot use the standard `path.normalize` method, because on Windows platform it will use of backslashes.\r\n */\r\nfunction removeDuplicateSlashes(pattern) {\r\n    return pattern.replace(DOUBLE_SLASH_RE$1, '/');\r\n}\r\npatterns.removeDuplicateSlashes = removeDuplicateSlashes;\n\nvar async$7 = {};\n\nvar async$6 = {};\n\nvar out$3 = {};\n\nvar async$5 = {};\n\nvar async$4 = {};\n\nvar out$2 = {};\n\nvar async$3 = {};\n\nvar out$1 = {};\n\nvar async$2 = {};\n\nObject.defineProperty(async$2, \"__esModule\", { value: true });\nasync$2.read = void 0;\nfunction read$3(path, settings, callback) {\n    settings.fs.lstat(path, (lstatError, lstat) => {\n        if (lstatError !== null) {\n            callFailureCallback$2(callback, lstatError);\n            return;\n        }\n        if (!lstat.isSymbolicLink() || !settings.followSymbolicLink) {\n            callSuccessCallback$2(callback, lstat);\n            return;\n        }\n        settings.fs.stat(path, (statError, stat) => {\n            if (statError !== null) {\n                if (settings.throwErrorOnBrokenSymbolicLink) {\n                    callFailureCallback$2(callback, statError);\n                    return;\n                }\n                callSuccessCallback$2(callback, lstat);\n                return;\n            }\n            if (settings.markSymbolicLink) {\n                stat.isSymbolicLink = () => true;\n            }\n            callSuccessCallback$2(callback, stat);\n        });\n    });\n}\nasync$2.read = read$3;\nfunction callFailureCallback$2(callback, error) {\n    callback(error);\n}\nfunction callSuccessCallback$2(callback, result) {\n    callback(null, result);\n}\n\nvar sync$8 = {};\n\nObject.defineProperty(sync$8, \"__esModule\", { value: true });\nsync$8.read = void 0;\nfunction read$2(path, settings) {\n    const lstat = settings.fs.lstatSync(path);\n    if (!lstat.isSymbolicLink() || !settings.followSymbolicLink) {\n        return lstat;\n    }\n    try {\n        const stat = settings.fs.statSync(path);\n        if (settings.markSymbolicLink) {\n            stat.isSymbolicLink = () => true;\n        }\n        return stat;\n    }\n    catch (error) {\n        if (!settings.throwErrorOnBrokenSymbolicLink) {\n            return lstat;\n        }\n        throw error;\n    }\n}\nsync$8.read = read$2;\n\nvar settings$3 = {};\n\nvar fs$f = {};\n\n(function (exports) {\n\tObject.defineProperty(exports, \"__esModule\", { value: true });\n\texports.createFileSystemAdapter = exports.FILE_SYSTEM_ADAPTER = void 0;\n\tconst fs = require$$0__default;\n\texports.FILE_SYSTEM_ADAPTER = {\n\t    lstat: fs.lstat,\n\t    stat: fs.stat,\n\t    lstatSync: fs.lstatSync,\n\t    statSync: fs.statSync\n\t};\n\tfunction createFileSystemAdapter(fsMethods) {\n\t    if (fsMethods === undefined) {\n\t        return exports.FILE_SYSTEM_ADAPTER;\n\t    }\n\t    return Object.assign(Object.assign({}, exports.FILE_SYSTEM_ADAPTER), fsMethods);\n\t}\n\texports.createFileSystemAdapter = createFileSystemAdapter;\n} (fs$f));\n\nObject.defineProperty(settings$3, \"__esModule\", { value: true });\nconst fs$e = fs$f;\nlet Settings$2 = class Settings {\n    constructor(_options = {}) {\n        this._options = _options;\n        this.followSymbolicLink = this._getValue(this._options.followSymbolicLink, true);\n        this.fs = fs$e.createFileSystemAdapter(this._options.fs);\n        this.markSymbolicLink = this._getValue(this._options.markSymbolicLink, false);\n        this.throwErrorOnBrokenSymbolicLink = this._getValue(this._options.throwErrorOnBrokenSymbolicLink, true);\n    }\n    _getValue(option, value) {\n        return option !== null && option !== void 0 ? option : value;\n    }\n};\nsettings$3.default = Settings$2;\n\nObject.defineProperty(out$1, \"__esModule\", { value: true });\nout$1.statSync = out$1.stat = out$1.Settings = void 0;\nconst async$1 = async$2;\nconst sync$7 = sync$8;\nconst settings_1$3 = settings$3;\nout$1.Settings = settings_1$3.default;\nfunction stat$4(path, optionsOrSettingsOrCallback, callback) {\n    if (typeof optionsOrSettingsOrCallback === 'function') {\n        async$1.read(path, getSettings$2(), optionsOrSettingsOrCallback);\n        return;\n    }\n    async$1.read(path, getSettings$2(optionsOrSettingsOrCallback), callback);\n}\nout$1.stat = stat$4;\nfunction statSync(path, optionsOrSettings) {\n    const settings = getSettings$2(optionsOrSettings);\n    return sync$7.read(path, settings);\n}\nout$1.statSync = statSync;\nfunction getSettings$2(settingsOrOptions = {}) {\n    if (settingsOrOptions instanceof settings_1$3.default) {\n        return settingsOrOptions;\n    }\n    return new settings_1$3.default(settingsOrOptions);\n}\n\n/*! queue-microtask. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n\nlet promise;\n\nvar queueMicrotask_1 = typeof queueMicrotask === 'function'\n  ? queueMicrotask.bind(typeof window !== 'undefined' ? window : commonjsGlobal)\n  // reuse resolved promise, and allocate it lazily\n  : cb => (promise || (promise = Promise.resolve()))\n    .then(cb)\n    .catch(err => setTimeout(() => { throw err }, 0));\n\n/*! run-parallel. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n\nvar runParallel_1 = runParallel;\n\nconst queueMicrotask$1 = queueMicrotask_1;\n\nfunction runParallel (tasks, cb) {\n  let results, pending, keys;\n  let isSync = true;\n\n  if (Array.isArray(tasks)) {\n    results = [];\n    pending = tasks.length;\n  } else {\n    keys = Object.keys(tasks);\n    results = {};\n    pending = keys.length;\n  }\n\n  function done (err) {\n    function end () {\n      if (cb) cb(err, results);\n      cb = null;\n    }\n    if (isSync) queueMicrotask$1(end);\n    else end();\n  }\n\n  function each (i, err, result) {\n    results[i] = result;\n    if (--pending === 0 || err) {\n      done(err);\n    }\n  }\n\n  if (!pending) {\n    // empty\n    done(null);\n  } else if (keys) {\n    // object\n    keys.forEach(function (key) {\n      tasks[key](function (err, result) { each(key, err, result); });\n    });\n  } else {\n    // array\n    tasks.forEach(function (task, i) {\n      task(function (err, result) { each(i, err, result); });\n    });\n  }\n\n  isSync = false;\n}\n\nvar constants$2 = {};\n\nObject.defineProperty(constants$2, \"__esModule\", { value: true });\nconstants$2.IS_SUPPORT_READDIR_WITH_FILE_TYPES = void 0;\nconst NODE_PROCESS_VERSION_PARTS = process.versions.node.split('.');\nif (NODE_PROCESS_VERSION_PARTS[0] === undefined || NODE_PROCESS_VERSION_PARTS[1] === undefined) {\n    throw new Error(`Unexpected behavior. The 'process.versions.node' variable has invalid value: ${process.versions.node}`);\n}\nconst MAJOR_VERSION = Number.parseInt(NODE_PROCESS_VERSION_PARTS[0], 10);\nconst MINOR_VERSION = Number.parseInt(NODE_PROCESS_VERSION_PARTS[1], 10);\nconst SUPPORTED_MAJOR_VERSION = 10;\nconst SUPPORTED_MINOR_VERSION = 10;\nconst IS_MATCHED_BY_MAJOR = MAJOR_VERSION > SUPPORTED_MAJOR_VERSION;\nconst IS_MATCHED_BY_MAJOR_AND_MINOR = MAJOR_VERSION === SUPPORTED_MAJOR_VERSION && MINOR_VERSION >= SUPPORTED_MINOR_VERSION;\n/**\n * IS `true` for Node.js 10.10 and greater.\n */\nconstants$2.IS_SUPPORT_READDIR_WITH_FILE_TYPES = IS_MATCHED_BY_MAJOR || IS_MATCHED_BY_MAJOR_AND_MINOR;\n\nvar utils$9 = {};\n\nvar fs$d = {};\n\nObject.defineProperty(fs$d, \"__esModule\", { value: true });\nfs$d.createDirentFromStats = void 0;\nclass DirentFromStats {\n    constructor(name, stats) {\n        this.name = name;\n        this.isBlockDevice = stats.isBlockDevice.bind(stats);\n        this.isCharacterDevice = stats.isCharacterDevice.bind(stats);\n        this.isDirectory = stats.isDirectory.bind(stats);\n        this.isFIFO = stats.isFIFO.bind(stats);\n        this.isFile = stats.isFile.bind(stats);\n        this.isSocket = stats.isSocket.bind(stats);\n        this.isSymbolicLink = stats.isSymbolicLink.bind(stats);\n    }\n}\nfunction createDirentFromStats(name, stats) {\n    return new DirentFromStats(name, stats);\n}\nfs$d.createDirentFromStats = createDirentFromStats;\n\nObject.defineProperty(utils$9, \"__esModule\", { value: true });\nutils$9.fs = void 0;\nconst fs$c = fs$d;\nutils$9.fs = fs$c;\n\nvar common$a = {};\n\nObject.defineProperty(common$a, \"__esModule\", { value: true });\ncommon$a.joinPathSegments = void 0;\nfunction joinPathSegments$1(a, b, separator) {\n    /**\n     * The correct handling of cases when the first segment is a root (`/`, `C:/`) or UNC path (`//?/C:/`).\n     */\n    if (a.endsWith(separator)) {\n        return a + b;\n    }\n    return a + separator + b;\n}\ncommon$a.joinPathSegments = joinPathSegments$1;\n\nObject.defineProperty(async$3, \"__esModule\", { value: true });\nasync$3.readdir = async$3.readdirWithFileTypes = async$3.read = void 0;\nconst fsStat$5 = out$1;\nconst rpl = runParallel_1;\nconst constants_1$1 = constants$2;\nconst utils$8 = utils$9;\nconst common$9 = common$a;\nfunction read$1(directory, settings, callback) {\n    if (!settings.stats && constants_1$1.IS_SUPPORT_READDIR_WITH_FILE_TYPES) {\n        readdirWithFileTypes$1(directory, settings, callback);\n        return;\n    }\n    readdir$3(directory, settings, callback);\n}\nasync$3.read = read$1;\nfunction readdirWithFileTypes$1(directory, settings, callback) {\n    settings.fs.readdir(directory, { withFileTypes: true }, (readdirError, dirents) => {\n        if (readdirError !== null) {\n            callFailureCallback$1(callback, readdirError);\n            return;\n        }\n        const entries = dirents.map((dirent) => ({\n            dirent,\n            name: dirent.name,\n            path: common$9.joinPathSegments(directory, dirent.name, settings.pathSegmentSeparator)\n        }));\n        if (!settings.followSymbolicLinks) {\n            callSuccessCallback$1(callback, entries);\n            return;\n        }\n        const tasks = entries.map((entry) => makeRplTaskEntry(entry, settings));\n        rpl(tasks, (rplError, rplEntries) => {\n            if (rplError !== null) {\n                callFailureCallback$1(callback, rplError);\n                return;\n            }\n            callSuccessCallback$1(callback, rplEntries);\n        });\n    });\n}\nasync$3.readdirWithFileTypes = readdirWithFileTypes$1;\nfunction makeRplTaskEntry(entry, settings) {\n    return (done) => {\n        if (!entry.dirent.isSymbolicLink()) {\n            done(null, entry);\n            return;\n        }\n        settings.fs.stat(entry.path, (statError, stats) => {\n            if (statError !== null) {\n                if (settings.throwErrorOnBrokenSymbolicLink) {\n                    done(statError);\n                    return;\n                }\n                done(null, entry);\n                return;\n            }\n            entry.dirent = utils$8.fs.createDirentFromStats(entry.name, stats);\n            done(null, entry);\n        });\n    };\n}\nfunction readdir$3(directory, settings, callback) {\n    settings.fs.readdir(directory, (readdirError, names) => {\n        if (readdirError !== null) {\n            callFailureCallback$1(callback, readdirError);\n            return;\n        }\n        const tasks = names.map((name) => {\n            const path = common$9.joinPathSegments(directory, name, settings.pathSegmentSeparator);\n            return (done) => {\n                fsStat$5.stat(path, settings.fsStatSettings, (error, stats) => {\n                    if (error !== null) {\n                        done(error);\n                        return;\n                    }\n                    const entry = {\n                        name,\n                        path,\n                        dirent: utils$8.fs.createDirentFromStats(name, stats)\n                    };\n                    if (settings.stats) {\n                        entry.stats = stats;\n                    }\n                    done(null, entry);\n                });\n            };\n        });\n        rpl(tasks, (rplError, entries) => {\n            if (rplError !== null) {\n                callFailureCallback$1(callback, rplError);\n                return;\n            }\n            callSuccessCallback$1(callback, entries);\n        });\n    });\n}\nasync$3.readdir = readdir$3;\nfunction callFailureCallback$1(callback, error) {\n    callback(error);\n}\nfunction callSuccessCallback$1(callback, result) {\n    callback(null, result);\n}\n\nvar sync$6 = {};\n\nObject.defineProperty(sync$6, \"__esModule\", { value: true });\nsync$6.readdir = sync$6.readdirWithFileTypes = sync$6.read = void 0;\nconst fsStat$4 = out$1;\nconst constants_1 = constants$2;\nconst utils$7 = utils$9;\nconst common$8 = common$a;\nfunction read(directory, settings) {\n    if (!settings.stats && constants_1.IS_SUPPORT_READDIR_WITH_FILE_TYPES) {\n        return readdirWithFileTypes(directory, settings);\n    }\n    return readdir$2(directory, settings);\n}\nsync$6.read = read;\nfunction readdirWithFileTypes(directory, settings) {\n    const dirents = settings.fs.readdirSync(directory, { withFileTypes: true });\n    return dirents.map((dirent) => {\n        const entry = {\n            dirent,\n            name: dirent.name,\n            path: common$8.joinPathSegments(directory, dirent.name, settings.pathSegmentSeparator)\n        };\n        if (entry.dirent.isSymbolicLink() && settings.followSymbolicLinks) {\n            try {\n                const stats = settings.fs.statSync(entry.path);\n                entry.dirent = utils$7.fs.createDirentFromStats(entry.name, stats);\n            }\n            catch (error) {\n                if (settings.throwErrorOnBrokenSymbolicLink) {\n                    throw error;\n                }\n            }\n        }\n        return entry;\n    });\n}\nsync$6.readdirWithFileTypes = readdirWithFileTypes;\nfunction readdir$2(directory, settings) {\n    const names = settings.fs.readdirSync(directory);\n    return names.map((name) => {\n        const entryPath = common$8.joinPathSegments(directory, name, settings.pathSegmentSeparator);\n        const stats = fsStat$4.statSync(entryPath, settings.fsStatSettings);\n        const entry = {\n            name,\n            path: entryPath,\n            dirent: utils$7.fs.createDirentFromStats(name, stats)\n        };\n        if (settings.stats) {\n            entry.stats = stats;\n        }\n        return entry;\n    });\n}\nsync$6.readdir = readdir$2;\n\nvar settings$2 = {};\n\nvar fs$b = {};\n\n(function (exports) {\n\tObject.defineProperty(exports, \"__esModule\", { value: true });\n\texports.createFileSystemAdapter = exports.FILE_SYSTEM_ADAPTER = void 0;\n\tconst fs = require$$0__default;\n\texports.FILE_SYSTEM_ADAPTER = {\n\t    lstat: fs.lstat,\n\t    stat: fs.stat,\n\t    lstatSync: fs.lstatSync,\n\t    statSync: fs.statSync,\n\t    readdir: fs.readdir,\n\t    readdirSync: fs.readdirSync\n\t};\n\tfunction createFileSystemAdapter(fsMethods) {\n\t    if (fsMethods === undefined) {\n\t        return exports.FILE_SYSTEM_ADAPTER;\n\t    }\n\t    return Object.assign(Object.assign({}, exports.FILE_SYSTEM_ADAPTER), fsMethods);\n\t}\n\texports.createFileSystemAdapter = createFileSystemAdapter;\n} (fs$b));\n\nObject.defineProperty(settings$2, \"__esModule\", { value: true });\nconst path$d = require$$0$4;\nconst fsStat$3 = out$1;\nconst fs$a = fs$b;\nlet Settings$1 = class Settings {\n    constructor(_options = {}) {\n        this._options = _options;\n        this.followSymbolicLinks = this._getValue(this._options.followSymbolicLinks, false);\n        this.fs = fs$a.createFileSystemAdapter(this._options.fs);\n        this.pathSegmentSeparator = this._getValue(this._options.pathSegmentSeparator, path$d.sep);\n        this.stats = this._getValue(this._options.stats, false);\n        this.throwErrorOnBrokenSymbolicLink = this._getValue(this._options.throwErrorOnBrokenSymbolicLink, true);\n        this.fsStatSettings = new fsStat$3.Settings({\n            followSymbolicLink: this.followSymbolicLinks,\n            fs: this.fs,\n            throwErrorOnBrokenSymbolicLink: this.throwErrorOnBrokenSymbolicLink\n        });\n    }\n    _getValue(option, value) {\n        return option !== null && option !== void 0 ? option : value;\n    }\n};\nsettings$2.default = Settings$1;\n\nObject.defineProperty(out$2, \"__esModule\", { value: true });\nout$2.Settings = out$2.scandirSync = out$2.scandir = void 0;\nconst async = async$3;\nconst sync$5 = sync$6;\nconst settings_1$2 = settings$2;\nout$2.Settings = settings_1$2.default;\nfunction scandir(path, optionsOrSettingsOrCallback, callback) {\n    if (typeof optionsOrSettingsOrCallback === 'function') {\n        async.read(path, getSettings$1(), optionsOrSettingsOrCallback);\n        return;\n    }\n    async.read(path, getSettings$1(optionsOrSettingsOrCallback), callback);\n}\nout$2.scandir = scandir;\nfunction scandirSync(path, optionsOrSettings) {\n    const settings = getSettings$1(optionsOrSettings);\n    return sync$5.read(path, settings);\n}\nout$2.scandirSync = scandirSync;\nfunction getSettings$1(settingsOrOptions = {}) {\n    if (settingsOrOptions instanceof settings_1$2.default) {\n        return settingsOrOptions;\n    }\n    return new settings_1$2.default(settingsOrOptions);\n}\n\nvar queueExports = {};\nvar queue = {\n  get exports(){ return queueExports; },\n  set exports(v){ queueExports = v; },\n};\n\nfunction reusify$1 (Constructor) {\n  var head = new Constructor();\n  var tail = head;\n\n  function get () {\n    var current = head;\n\n    if (current.next) {\n      head = current.next;\n    } else {\n      head = new Constructor();\n      tail = head;\n    }\n\n    current.next = null;\n\n    return current\n  }\n\n  function release (obj) {\n    tail.next = obj;\n    tail = obj;\n  }\n\n  return {\n    get: get,\n    release: release\n  }\n}\n\nvar reusify_1 = reusify$1;\n\n/* eslint-disable no-var */\n\nvar reusify = reusify_1;\n\nfunction fastqueue (context, worker, concurrency) {\n  if (typeof context === 'function') {\n    concurrency = worker;\n    worker = context;\n    context = null;\n  }\n\n  if (concurrency < 1) {\n    throw new Error('fastqueue concurrency must be greater than 1')\n  }\n\n  var cache = reusify(Task);\n  var queueHead = null;\n  var queueTail = null;\n  var _running = 0;\n  var errorHandler = null;\n\n  var self = {\n    push: push,\n    drain: noop$3,\n    saturated: noop$3,\n    pause: pause,\n    paused: false,\n    concurrency: concurrency,\n    running: running,\n    resume: resume,\n    idle: idle,\n    length: length,\n    getQueue: getQueue,\n    unshift: unshift,\n    empty: noop$3,\n    kill: kill,\n    killAndDrain: killAndDrain,\n    error: error\n  };\n\n  return self\n\n  function running () {\n    return _running\n  }\n\n  function pause () {\n    self.paused = true;\n  }\n\n  function length () {\n    var current = queueHead;\n    var counter = 0;\n\n    while (current) {\n      current = current.next;\n      counter++;\n    }\n\n    return counter\n  }\n\n  function getQueue () {\n    var current = queueHead;\n    var tasks = [];\n\n    while (current) {\n      tasks.push(current.value);\n      current = current.next;\n    }\n\n    return tasks\n  }\n\n  function resume () {\n    if (!self.paused) return\n    self.paused = false;\n    for (var i = 0; i < self.concurrency; i++) {\n      _running++;\n      release();\n    }\n  }\n\n  function idle () {\n    return _running === 0 && self.length() === 0\n  }\n\n  function push (value, done) {\n    var current = cache.get();\n\n    current.context = context;\n    current.release = release;\n    current.value = value;\n    current.callback = done || noop$3;\n    current.errorHandler = errorHandler;\n\n    if (_running === self.concurrency || self.paused) {\n      if (queueTail) {\n        queueTail.next = current;\n        queueTail = current;\n      } else {\n        queueHead = current;\n        queueTail = current;\n        self.saturated();\n      }\n    } else {\n      _running++;\n      worker.call(context, current.value, current.worked);\n    }\n  }\n\n  function unshift (value, done) {\n    var current = cache.get();\n\n    current.context = context;\n    current.release = release;\n    current.value = value;\n    current.callback = done || noop$3;\n\n    if (_running === self.concurrency || self.paused) {\n      if (queueHead) {\n        current.next = queueHead;\n        queueHead = current;\n      } else {\n        queueHead = current;\n        queueTail = current;\n        self.saturated();\n      }\n    } else {\n      _running++;\n      worker.call(context, current.value, current.worked);\n    }\n  }\n\n  function release (holder) {\n    if (holder) {\n      cache.release(holder);\n    }\n    var next = queueHead;\n    if (next) {\n      if (!self.paused) {\n        if (queueTail === queueHead) {\n          queueTail = null;\n        }\n        queueHead = next.next;\n        next.next = null;\n        worker.call(context, next.value, next.worked);\n        if (queueTail === null) {\n          self.empty();\n        }\n      } else {\n        _running--;\n      }\n    } else if (--_running === 0) {\n      self.drain();\n    }\n  }\n\n  function kill () {\n    queueHead = null;\n    queueTail = null;\n    self.drain = noop$3;\n  }\n\n  function killAndDrain () {\n    queueHead = null;\n    queueTail = null;\n    self.drain();\n    self.drain = noop$3;\n  }\n\n  function error (handler) {\n    errorHandler = handler;\n  }\n}\n\nfunction noop$3 () {}\n\nfunction Task () {\n  this.value = null;\n  this.callback = noop$3;\n  this.next = null;\n  this.release = noop$3;\n  this.context = null;\n  this.errorHandler = null;\n\n  var self = this;\n\n  this.worked = function worked (err, result) {\n    var callback = self.callback;\n    var errorHandler = self.errorHandler;\n    var val = self.value;\n    self.value = null;\n    self.callback = noop$3;\n    if (self.errorHandler) {\n      errorHandler(err, val);\n    }\n    callback.call(self.context, err, result);\n    self.release(self);\n  };\n}\n\nfunction queueAsPromised (context, worker, concurrency) {\n  if (typeof context === 'function') {\n    concurrency = worker;\n    worker = context;\n    context = null;\n  }\n\n  function asyncWrapper (arg, cb) {\n    worker.call(this, arg)\n      .then(function (res) {\n        cb(null, res);\n      }, cb);\n  }\n\n  var queue = fastqueue(context, asyncWrapper, concurrency);\n\n  var pushCb = queue.push;\n  var unshiftCb = queue.unshift;\n\n  queue.push = push;\n  queue.unshift = unshift;\n  queue.drained = drained;\n\n  return queue\n\n  function push (value) {\n    var p = new Promise(function (resolve, reject) {\n      pushCb(value, function (err, result) {\n        if (err) {\n          reject(err);\n          return\n        }\n        resolve(result);\n      });\n    });\n\n    // Let's fork the promise chain to\n    // make the error bubble up to the user but\n    // not lead to a unhandledRejection\n    p.catch(noop$3);\n\n    return p\n  }\n\n  function unshift (value) {\n    var p = new Promise(function (resolve, reject) {\n      unshiftCb(value, function (err, result) {\n        if (err) {\n          reject(err);\n          return\n        }\n        resolve(result);\n      });\n    });\n\n    // Let's fork the promise chain to\n    // make the error bubble up to the user but\n    // not lead to a unhandledRejection\n    p.catch(noop$3);\n\n    return p\n  }\n\n  function drained () {\n    var previousDrain = queue.drain;\n\n    var p = new Promise(function (resolve) {\n      queue.drain = function () {\n        previousDrain();\n        resolve();\n      };\n    });\n\n    return p\n  }\n}\n\nqueue.exports = fastqueue;\nqueueExports.promise = queueAsPromised;\n\nvar common$7 = {};\n\nObject.defineProperty(common$7, \"__esModule\", { value: true });\ncommon$7.joinPathSegments = common$7.replacePathSegmentSeparator = common$7.isAppliedFilter = common$7.isFatalError = void 0;\nfunction isFatalError(settings, error) {\n    if (settings.errorFilter === null) {\n        return true;\n    }\n    return !settings.errorFilter(error);\n}\ncommon$7.isFatalError = isFatalError;\nfunction isAppliedFilter(filter, value) {\n    return filter === null || filter(value);\n}\ncommon$7.isAppliedFilter = isAppliedFilter;\nfunction replacePathSegmentSeparator(filepath, separator) {\n    return filepath.split(/[/\\\\]/).join(separator);\n}\ncommon$7.replacePathSegmentSeparator = replacePathSegmentSeparator;\nfunction joinPathSegments(a, b, separator) {\n    if (a === '') {\n        return b;\n    }\n    /**\n     * The correct handling of cases when the first segment is a root (`/`, `C:/`) or UNC path (`//?/C:/`).\n     */\n    if (a.endsWith(separator)) {\n        return a + b;\n    }\n    return a + separator + b;\n}\ncommon$7.joinPathSegments = joinPathSegments;\n\nvar reader$1 = {};\n\nObject.defineProperty(reader$1, \"__esModule\", { value: true });\nconst common$6 = common$7;\nlet Reader$1 = class Reader {\n    constructor(_root, _settings) {\n        this._root = _root;\n        this._settings = _settings;\n        this._root = common$6.replacePathSegmentSeparator(_root, _settings.pathSegmentSeparator);\n    }\n};\nreader$1.default = Reader$1;\n\nObject.defineProperty(async$4, \"__esModule\", { value: true });\nconst events_1 = require$$0$5;\nconst fsScandir$2 = out$2;\nconst fastq = queueExports;\nconst common$5 = common$7;\nconst reader_1$4 = reader$1;\nclass AsyncReader extends reader_1$4.default {\n    constructor(_root, _settings) {\n        super(_root, _settings);\n        this._settings = _settings;\n        this._scandir = fsScandir$2.scandir;\n        this._emitter = new events_1.EventEmitter();\n        this._queue = fastq(this._worker.bind(this), this._settings.concurrency);\n        this._isFatalError = false;\n        this._isDestroyed = false;\n        this._queue.drain = () => {\n            if (!this._isFatalError) {\n                this._emitter.emit('end');\n            }\n        };\n    }\n    read() {\n        this._isFatalError = false;\n        this._isDestroyed = false;\n        setImmediate(() => {\n            this._pushToQueue(this._root, this._settings.basePath);\n        });\n        return this._emitter;\n    }\n    get isDestroyed() {\n        return this._isDestroyed;\n    }\n    destroy() {\n        if (this._isDestroyed) {\n            throw new Error('The reader is already destroyed');\n        }\n        this._isDestroyed = true;\n        this._queue.killAndDrain();\n    }\n    onEntry(callback) {\n        this._emitter.on('entry', callback);\n    }\n    onError(callback) {\n        this._emitter.once('error', callback);\n    }\n    onEnd(callback) {\n        this._emitter.once('end', callback);\n    }\n    _pushToQueue(directory, base) {\n        const queueItem = { directory, base };\n        this._queue.push(queueItem, (error) => {\n            if (error !== null) {\n                this._handleError(error);\n            }\n        });\n    }\n    _worker(item, done) {\n        this._scandir(item.directory, this._settings.fsScandirSettings, (error, entries) => {\n            if (error !== null) {\n                done(error, undefined);\n                return;\n            }\n            for (const entry of entries) {\n                this._handleEntry(entry, item.base);\n            }\n            done(null, undefined);\n        });\n    }\n    _handleError(error) {\n        if (this._isDestroyed || !common$5.isFatalError(this._settings, error)) {\n            return;\n        }\n        this._isFatalError = true;\n        this._isDestroyed = true;\n        this._emitter.emit('error', error);\n    }\n    _handleEntry(entry, base) {\n        if (this._isDestroyed || this._isFatalError) {\n            return;\n        }\n        const fullpath = entry.path;\n        if (base !== undefined) {\n            entry.path = common$5.joinPathSegments(base, entry.name, this._settings.pathSegmentSeparator);\n        }\n        if (common$5.isAppliedFilter(this._settings.entryFilter, entry)) {\n            this._emitEntry(entry);\n        }\n        if (entry.dirent.isDirectory() && common$5.isAppliedFilter(this._settings.deepFilter, entry)) {\n            this._pushToQueue(fullpath, base === undefined ? undefined : entry.path);\n        }\n    }\n    _emitEntry(entry) {\n        this._emitter.emit('entry', entry);\n    }\n}\nasync$4.default = AsyncReader;\n\nObject.defineProperty(async$5, \"__esModule\", { value: true });\nconst async_1$4 = async$4;\nclass AsyncProvider {\n    constructor(_root, _settings) {\n        this._root = _root;\n        this._settings = _settings;\n        this._reader = new async_1$4.default(this._root, this._settings);\n        this._storage = [];\n    }\n    read(callback) {\n        this._reader.onError((error) => {\n            callFailureCallback(callback, error);\n        });\n        this._reader.onEntry((entry) => {\n            this._storage.push(entry);\n        });\n        this._reader.onEnd(() => {\n            callSuccessCallback(callback, this._storage);\n        });\n        this._reader.read();\n    }\n}\nasync$5.default = AsyncProvider;\nfunction callFailureCallback(callback, error) {\n    callback(error);\n}\nfunction callSuccessCallback(callback, entries) {\n    callback(null, entries);\n}\n\nvar stream$2 = {};\n\nObject.defineProperty(stream$2, \"__esModule\", { value: true });\nconst stream_1$5 = require$$0$7;\nconst async_1$3 = async$4;\nclass StreamProvider {\n    constructor(_root, _settings) {\n        this._root = _root;\n        this._settings = _settings;\n        this._reader = new async_1$3.default(this._root, this._settings);\n        this._stream = new stream_1$5.Readable({\n            objectMode: true,\n            read: () => { },\n            destroy: () => {\n                if (!this._reader.isDestroyed) {\n                    this._reader.destroy();\n                }\n            }\n        });\n    }\n    read() {\n        this._reader.onError((error) => {\n            this._stream.emit('error', error);\n        });\n        this._reader.onEntry((entry) => {\n            this._stream.push(entry);\n        });\n        this._reader.onEnd(() => {\n            this._stream.push(null);\n        });\n        this._reader.read();\n        return this._stream;\n    }\n}\nstream$2.default = StreamProvider;\n\nvar sync$4 = {};\n\nvar sync$3 = {};\n\nObject.defineProperty(sync$3, \"__esModule\", { value: true });\nconst fsScandir$1 = out$2;\nconst common$4 = common$7;\nconst reader_1$3 = reader$1;\nclass SyncReader extends reader_1$3.default {\n    constructor() {\n        super(...arguments);\n        this._scandir = fsScandir$1.scandirSync;\n        this._storage = [];\n        this._queue = new Set();\n    }\n    read() {\n        this._pushToQueue(this._root, this._settings.basePath);\n        this._handleQueue();\n        return this._storage;\n    }\n    _pushToQueue(directory, base) {\n        this._queue.add({ directory, base });\n    }\n    _handleQueue() {\n        for (const item of this._queue.values()) {\n            this._handleDirectory(item.directory, item.base);\n        }\n    }\n    _handleDirectory(directory, base) {\n        try {\n            const entries = this._scandir(directory, this._settings.fsScandirSettings);\n            for (const entry of entries) {\n                this._handleEntry(entry, base);\n            }\n        }\n        catch (error) {\n            this._handleError(error);\n        }\n    }\n    _handleError(error) {\n        if (!common$4.isFatalError(this._settings, error)) {\n            return;\n        }\n        throw error;\n    }\n    _handleEntry(entry, base) {\n        const fullpath = entry.path;\n        if (base !== undefined) {\n            entry.path = common$4.joinPathSegments(base, entry.name, this._settings.pathSegmentSeparator);\n        }\n        if (common$4.isAppliedFilter(this._settings.entryFilter, entry)) {\n            this._pushToStorage(entry);\n        }\n        if (entry.dirent.isDirectory() && common$4.isAppliedFilter(this._settings.deepFilter, entry)) {\n            this._pushToQueue(fullpath, base === undefined ? undefined : entry.path);\n        }\n    }\n    _pushToStorage(entry) {\n        this._storage.push(entry);\n    }\n}\nsync$3.default = SyncReader;\n\nObject.defineProperty(sync$4, \"__esModule\", { value: true });\nconst sync_1$3 = sync$3;\nclass SyncProvider {\n    constructor(_root, _settings) {\n        this._root = _root;\n        this._settings = _settings;\n        this._reader = new sync_1$3.default(this._root, this._settings);\n    }\n    read() {\n        return this._reader.read();\n    }\n}\nsync$4.default = SyncProvider;\n\nvar settings$1 = {};\n\nObject.defineProperty(settings$1, \"__esModule\", { value: true });\nconst path$c = require$$0$4;\nconst fsScandir = out$2;\nclass Settings {\n    constructor(_options = {}) {\n        this._options = _options;\n        this.basePath = this._getValue(this._options.basePath, undefined);\n        this.concurrency = this._getValue(this._options.concurrency, Number.POSITIVE_INFINITY);\n        this.deepFilter = this._getValue(this._options.deepFilter, null);\n        this.entryFilter = this._getValue(this._options.entryFilter, null);\n        this.errorFilter = this._getValue(this._options.errorFilter, null);\n        this.pathSegmentSeparator = this._getValue(this._options.pathSegmentSeparator, path$c.sep);\n        this.fsScandirSettings = new fsScandir.Settings({\n            followSymbolicLinks: this._options.followSymbolicLinks,\n            fs: this._options.fs,\n            pathSegmentSeparator: this._options.pathSegmentSeparator,\n            stats: this._options.stats,\n            throwErrorOnBrokenSymbolicLink: this._options.throwErrorOnBrokenSymbolicLink\n        });\n    }\n    _getValue(option, value) {\n        return option !== null && option !== void 0 ? option : value;\n    }\n}\nsettings$1.default = Settings;\n\nObject.defineProperty(out$3, \"__esModule\", { value: true });\nout$3.Settings = out$3.walkStream = out$3.walkSync = out$3.walk = void 0;\nconst async_1$2 = async$5;\nconst stream_1$4 = stream$2;\nconst sync_1$2 = sync$4;\nconst settings_1$1 = settings$1;\nout$3.Settings = settings_1$1.default;\nfunction walk$2(directory, optionsOrSettingsOrCallback, callback) {\n    if (typeof optionsOrSettingsOrCallback === 'function') {\n        new async_1$2.default(directory, getSettings()).read(optionsOrSettingsOrCallback);\n        return;\n    }\n    new async_1$2.default(directory, getSettings(optionsOrSettingsOrCallback)).read(callback);\n}\nout$3.walk = walk$2;\nfunction walkSync(directory, optionsOrSettings) {\n    const settings = getSettings(optionsOrSettings);\n    const provider = new sync_1$2.default(directory, settings);\n    return provider.read();\n}\nout$3.walkSync = walkSync;\nfunction walkStream(directory, optionsOrSettings) {\n    const settings = getSettings(optionsOrSettings);\n    const provider = new stream_1$4.default(directory, settings);\n    return provider.read();\n}\nout$3.walkStream = walkStream;\nfunction getSettings(settingsOrOptions = {}) {\n    if (settingsOrOptions instanceof settings_1$1.default) {\n        return settingsOrOptions;\n    }\n    return new settings_1$1.default(settingsOrOptions);\n}\n\nvar reader = {};\n\nObject.defineProperty(reader, \"__esModule\", { value: true });\r\nconst path$b = require$$0$4;\r\nconst fsStat$2 = out$1;\r\nconst utils$6 = utils$g;\r\nclass Reader {\r\n    constructor(_settings) {\r\n        this._settings = _settings;\r\n        this._fsStatSettings = new fsStat$2.Settings({\r\n            followSymbolicLink: this._settings.followSymbolicLinks,\r\n            fs: this._settings.fs,\r\n            throwErrorOnBrokenSymbolicLink: this._settings.followSymbolicLinks\r\n        });\r\n    }\r\n    _getFullEntryPath(filepath) {\r\n        return path$b.resolve(this._settings.cwd, filepath);\r\n    }\r\n    _makeEntry(stats, pattern) {\r\n        const entry = {\r\n            name: pattern,\r\n            path: pattern,\r\n            dirent: utils$6.fs.createDirentFromStats(pattern, stats)\r\n        };\r\n        if (this._settings.stats) {\r\n            entry.stats = stats;\r\n        }\r\n        return entry;\r\n    }\r\n    _isFatalError(error) {\r\n        return !utils$6.errno.isEnoentCodeError(error) && !this._settings.suppressErrors;\r\n    }\r\n}\r\nreader.default = Reader;\n\nvar stream$1 = {};\n\nObject.defineProperty(stream$1, \"__esModule\", { value: true });\r\nconst stream_1$3 = require$$0$7;\r\nconst fsStat$1 = out$1;\r\nconst fsWalk$2 = out$3;\r\nconst reader_1$2 = reader;\r\nclass ReaderStream extends reader_1$2.default {\r\n    constructor() {\r\n        super(...arguments);\r\n        this._walkStream = fsWalk$2.walkStream;\r\n        this._stat = fsStat$1.stat;\r\n    }\r\n    dynamic(root, options) {\r\n        return this._walkStream(root, options);\r\n    }\r\n    static(patterns, options) {\r\n        const filepaths = patterns.map(this._getFullEntryPath, this);\r\n        const stream = new stream_1$3.PassThrough({ objectMode: true });\r\n        stream._write = (index, _enc, done) => {\r\n            return this._getEntry(filepaths[index], patterns[index], options)\r\n                .then((entry) => {\r\n                if (entry !== null && options.entryFilter(entry)) {\r\n                    stream.push(entry);\r\n                }\r\n                if (index === filepaths.length - 1) {\r\n                    stream.end();\r\n                }\r\n                done();\r\n            })\r\n                .catch(done);\r\n        };\r\n        for (let i = 0; i < filepaths.length; i++) {\r\n            stream.write(i);\r\n        }\r\n        return stream;\r\n    }\r\n    _getEntry(filepath, pattern, options) {\r\n        return this._getStat(filepath)\r\n            .then((stats) => this._makeEntry(stats, pattern))\r\n            .catch((error) => {\r\n            if (options.errorFilter(error)) {\r\n                return null;\r\n            }\r\n            throw error;\r\n        });\r\n    }\r\n    _getStat(filepath) {\r\n        return new Promise((resolve, reject) => {\r\n            this._stat(filepath, this._fsStatSettings, (error, stats) => {\r\n                return error === null ? resolve(stats) : reject(error);\r\n            });\r\n        });\r\n    }\r\n}\r\nstream$1.default = ReaderStream;\n\nObject.defineProperty(async$6, \"__esModule\", { value: true });\r\nconst fsWalk$1 = out$3;\r\nconst reader_1$1 = reader;\r\nconst stream_1$2 = stream$1;\r\nclass ReaderAsync extends reader_1$1.default {\r\n    constructor() {\r\n        super(...arguments);\r\n        this._walkAsync = fsWalk$1.walk;\r\n        this._readerStream = new stream_1$2.default(this._settings);\r\n    }\r\n    dynamic(root, options) {\r\n        return new Promise((resolve, reject) => {\r\n            this._walkAsync(root, options, (error, entries) => {\r\n                if (error === null) {\r\n                    resolve(entries);\r\n                }\r\n                else {\r\n                    reject(error);\r\n                }\r\n            });\r\n        });\r\n    }\r\n    async static(patterns, options) {\r\n        const entries = [];\r\n        const stream = this._readerStream.static(patterns, options);\r\n        // After #235, replace it with an asynchronous iterator.\r\n        return new Promise((resolve, reject) => {\r\n            stream.once('error', reject);\r\n            stream.on('data', (entry) => entries.push(entry));\r\n            stream.once('end', () => resolve(entries));\r\n        });\r\n    }\r\n}\r\nasync$6.default = ReaderAsync;\n\nvar provider = {};\n\nvar deep = {};\n\nvar partial = {};\n\nvar matcher = {};\n\nObject.defineProperty(matcher, \"__esModule\", { value: true });\r\nconst utils$5 = utils$g;\r\nclass Matcher {\r\n    constructor(_patterns, _settings, _micromatchOptions) {\r\n        this._patterns = _patterns;\r\n        this._settings = _settings;\r\n        this._micromatchOptions = _micromatchOptions;\r\n        this._storage = [];\r\n        this._fillStorage();\r\n    }\r\n    _fillStorage() {\r\n        /**\r\n         * The original pattern may include `{,*,**,a/*}`, which will lead to problems with matching (unresolved level).\r\n         * So, before expand patterns with brace expansion into separated patterns.\r\n         */\r\n        const patterns = utils$5.pattern.expandPatternsWithBraceExpansion(this._patterns);\r\n        for (const pattern of patterns) {\r\n            const segments = this._getPatternSegments(pattern);\r\n            const sections = this._splitSegmentsIntoSections(segments);\r\n            this._storage.push({\r\n                complete: sections.length <= 1,\r\n                pattern,\r\n                segments,\r\n                sections\r\n            });\r\n        }\r\n    }\r\n    _getPatternSegments(pattern) {\r\n        const parts = utils$5.pattern.getPatternParts(pattern, this._micromatchOptions);\r\n        return parts.map((part) => {\r\n            const dynamic = utils$5.pattern.isDynamicPattern(part, this._settings);\r\n            if (!dynamic) {\r\n                return {\r\n                    dynamic: false,\r\n                    pattern: part\r\n                };\r\n            }\r\n            return {\r\n                dynamic: true,\r\n                pattern: part,\r\n                patternRe: utils$5.pattern.makeRe(part, this._micromatchOptions)\r\n            };\r\n        });\r\n    }\r\n    _splitSegmentsIntoSections(segments) {\r\n        return utils$5.array.splitWhen(segments, (segment) => segment.dynamic && utils$5.pattern.hasGlobStar(segment.pattern));\r\n    }\r\n}\r\nmatcher.default = Matcher;\n\nObject.defineProperty(partial, \"__esModule\", { value: true });\r\nconst matcher_1 = matcher;\r\nclass PartialMatcher extends matcher_1.default {\r\n    match(filepath) {\r\n        const parts = filepath.split('/');\r\n        const levels = parts.length;\r\n        const patterns = this._storage.filter((info) => !info.complete || info.segments.length > levels);\r\n        for (const pattern of patterns) {\r\n            const section = pattern.sections[0];\r\n            /**\r\n             * In this case, the pattern has a globstar and we must read all directories unconditionally,\r\n             * but only if the level has reached the end of the first group.\r\n             *\r\n             * fixtures/{a,b}/**\r\n             *  ^ true/false  ^ always true\r\n            */\r\n            if (!pattern.complete && levels > section.length) {\r\n                return true;\r\n            }\r\n            const match = parts.every((part, index) => {\r\n                const segment = pattern.segments[index];\r\n                if (segment.dynamic && segment.patternRe.test(part)) {\r\n                    return true;\r\n                }\r\n                if (!segment.dynamic && segment.pattern === part) {\r\n                    return true;\r\n                }\r\n                return false;\r\n            });\r\n            if (match) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n}\r\npartial.default = PartialMatcher;\n\nObject.defineProperty(deep, \"__esModule\", { value: true });\r\nconst utils$4 = utils$g;\r\nconst partial_1 = partial;\r\nclass DeepFilter {\r\n    constructor(_settings, _micromatchOptions) {\r\n        this._settings = _settings;\r\n        this._micromatchOptions = _micromatchOptions;\r\n    }\r\n    getFilter(basePath, positive, negative) {\r\n        const matcher = this._getMatcher(positive);\r\n        const negativeRe = this._getNegativePatternsRe(negative);\r\n        return (entry) => this._filter(basePath, entry, matcher, negativeRe);\r\n    }\r\n    _getMatcher(patterns) {\r\n        return new partial_1.default(patterns, this._settings, this._micromatchOptions);\r\n    }\r\n    _getNegativePatternsRe(patterns) {\r\n        const affectDepthOfReadingPatterns = patterns.filter(utils$4.pattern.isAffectDepthOfReadingPattern);\r\n        return utils$4.pattern.convertPatternsToRe(affectDepthOfReadingPatterns, this._micromatchOptions);\r\n    }\r\n    _filter(basePath, entry, matcher, negativeRe) {\r\n        if (this._isSkippedByDeep(basePath, entry.path)) {\r\n            return false;\r\n        }\r\n        if (this._isSkippedSymbolicLink(entry)) {\r\n            return false;\r\n        }\r\n        const filepath = utils$4.path.removeLeadingDotSegment(entry.path);\r\n        if (this._isSkippedByPositivePatterns(filepath, matcher)) {\r\n            return false;\r\n        }\r\n        return this._isSkippedByNegativePatterns(filepath, negativeRe);\r\n    }\r\n    _isSkippedByDeep(basePath, entryPath) {\r\n        /**\r\n         * Avoid unnecessary depth calculations when it doesn't matter.\r\n         */\r\n        if (this._settings.deep === Infinity) {\r\n            return false;\r\n        }\r\n        return this._getEntryLevel(basePath, entryPath) >= this._settings.deep;\r\n    }\r\n    _getEntryLevel(basePath, entryPath) {\r\n        const entryPathDepth = entryPath.split('/').length;\r\n        if (basePath === '') {\r\n            return entryPathDepth;\r\n        }\r\n        const basePathDepth = basePath.split('/').length;\r\n        return entryPathDepth - basePathDepth;\r\n    }\r\n    _isSkippedSymbolicLink(entry) {\r\n        return !this._settings.followSymbolicLinks && entry.dirent.isSymbolicLink();\r\n    }\r\n    _isSkippedByPositivePatterns(entryPath, matcher) {\r\n        return !this._settings.baseNameMatch && !matcher.match(entryPath);\r\n    }\r\n    _isSkippedByNegativePatterns(entryPath, patternsRe) {\r\n        return !utils$4.pattern.matchAny(entryPath, patternsRe);\r\n    }\r\n}\r\ndeep.default = DeepFilter;\n\nvar entry$1 = {};\n\nObject.defineProperty(entry$1, \"__esModule\", { value: true });\r\nconst utils$3 = utils$g;\r\nclass EntryFilter {\r\n    constructor(_settings, _micromatchOptions) {\r\n        this._settings = _settings;\r\n        this._micromatchOptions = _micromatchOptions;\r\n        this.index = new Map();\r\n    }\r\n    getFilter(positive, negative) {\r\n        const positiveRe = utils$3.pattern.convertPatternsToRe(positive, this._micromatchOptions);\r\n        const negativeRe = utils$3.pattern.convertPatternsToRe(negative, this._micromatchOptions);\r\n        return (entry) => this._filter(entry, positiveRe, negativeRe);\r\n    }\r\n    _filter(entry, positiveRe, negativeRe) {\r\n        if (this._settings.unique && this._isDuplicateEntry(entry)) {\r\n            return false;\r\n        }\r\n        if (this._onlyFileFilter(entry) || this._onlyDirectoryFilter(entry)) {\r\n            return false;\r\n        }\r\n        if (this._isSkippedByAbsoluteNegativePatterns(entry.path, negativeRe)) {\r\n            return false;\r\n        }\r\n        const filepath = this._settings.baseNameMatch ? entry.name : entry.path;\r\n        const isDirectory = entry.dirent.isDirectory();\r\n        const isMatched = this._isMatchToPatterns(filepath, positiveRe, isDirectory) && !this._isMatchToPatterns(entry.path, negativeRe, isDirectory);\r\n        if (this._settings.unique && isMatched) {\r\n            this._createIndexRecord(entry);\r\n        }\r\n        return isMatched;\r\n    }\r\n    _isDuplicateEntry(entry) {\r\n        return this.index.has(entry.path);\r\n    }\r\n    _createIndexRecord(entry) {\r\n        this.index.set(entry.path, undefined);\r\n    }\r\n    _onlyFileFilter(entry) {\r\n        return this._settings.onlyFiles && !entry.dirent.isFile();\r\n    }\r\n    _onlyDirectoryFilter(entry) {\r\n        return this._settings.onlyDirectories && !entry.dirent.isDirectory();\r\n    }\r\n    _isSkippedByAbsoluteNegativePatterns(entryPath, patternsRe) {\r\n        if (!this._settings.absolute) {\r\n            return false;\r\n        }\r\n        const fullpath = utils$3.path.makeAbsolute(this._settings.cwd, entryPath);\r\n        return utils$3.pattern.matchAny(fullpath, patternsRe);\r\n    }\r\n    _isMatchToPatterns(entryPath, patternsRe, isDirectory) {\r\n        const filepath = utils$3.path.removeLeadingDotSegment(entryPath);\r\n        // Trying to match files and directories by patterns.\r\n        const isMatched = utils$3.pattern.matchAny(filepath, patternsRe);\r\n        // A pattern with a trailling slash can be used for directory matching.\r\n        // To apply such pattern, we need to add a tralling slash to the path.\r\n        if (!isMatched && isDirectory) {\r\n            return utils$3.pattern.matchAny(filepath + '/', patternsRe);\r\n        }\r\n        return isMatched;\r\n    }\r\n}\r\nentry$1.default = EntryFilter;\n\nvar error$2 = {};\n\nObject.defineProperty(error$2, \"__esModule\", { value: true });\r\nconst utils$2 = utils$g;\r\nclass ErrorFilter {\r\n    constructor(_settings) {\r\n        this._settings = _settings;\r\n    }\r\n    getFilter() {\r\n        return (error) => this._isNonFatalError(error);\r\n    }\r\n    _isNonFatalError(error) {\r\n        return utils$2.errno.isEnoentCodeError(error) || this._settings.suppressErrors;\r\n    }\r\n}\r\nerror$2.default = ErrorFilter;\n\nvar entry = {};\n\nObject.defineProperty(entry, \"__esModule\", { value: true });\r\nconst utils$1 = utils$g;\r\nclass EntryTransformer {\r\n    constructor(_settings) {\r\n        this._settings = _settings;\r\n    }\r\n    getTransformer() {\r\n        return (entry) => this._transform(entry);\r\n    }\r\n    _transform(entry) {\r\n        let filepath = entry.path;\r\n        if (this._settings.absolute) {\r\n            filepath = utils$1.path.makeAbsolute(this._settings.cwd, filepath);\r\n            filepath = utils$1.path.unixify(filepath);\r\n        }\r\n        if (this._settings.markDirectories && entry.dirent.isDirectory()) {\r\n            filepath += '/';\r\n        }\r\n        if (!this._settings.objectMode) {\r\n            return filepath;\r\n        }\r\n        return Object.assign(Object.assign({}, entry), { path: filepath });\r\n    }\r\n}\r\nentry.default = EntryTransformer;\n\nObject.defineProperty(provider, \"__esModule\", { value: true });\r\nconst path$a = require$$0$4;\r\nconst deep_1 = deep;\r\nconst entry_1 = entry$1;\r\nconst error_1 = error$2;\r\nconst entry_2 = entry;\r\nclass Provider {\r\n    constructor(_settings) {\r\n        this._settings = _settings;\r\n        this.errorFilter = new error_1.default(this._settings);\r\n        this.entryFilter = new entry_1.default(this._settings, this._getMicromatchOptions());\r\n        this.deepFilter = new deep_1.default(this._settings, this._getMicromatchOptions());\r\n        this.entryTransformer = new entry_2.default(this._settings);\r\n    }\r\n    _getRootDirectory(task) {\r\n        return path$a.resolve(this._settings.cwd, task.base);\r\n    }\r\n    _getReaderOptions(task) {\r\n        const basePath = task.base === '.' ? '' : task.base;\r\n        return {\r\n            basePath,\r\n            pathSegmentSeparator: '/',\r\n            concurrency: this._settings.concurrency,\r\n            deepFilter: this.deepFilter.getFilter(basePath, task.positive, task.negative),\r\n            entryFilter: this.entryFilter.getFilter(task.positive, task.negative),\r\n            errorFilter: this.errorFilter.getFilter(),\r\n            followSymbolicLinks: this._settings.followSymbolicLinks,\r\n            fs: this._settings.fs,\r\n            stats: this._settings.stats,\r\n            throwErrorOnBrokenSymbolicLink: this._settings.throwErrorOnBrokenSymbolicLink,\r\n            transform: this.entryTransformer.getTransformer()\r\n        };\r\n    }\r\n    _getMicromatchOptions() {\r\n        return {\r\n            dot: this._settings.dot,\r\n            matchBase: this._settings.baseNameMatch,\r\n            nobrace: !this._settings.braceExpansion,\r\n            nocase: !this._settings.caseSensitiveMatch,\r\n            noext: !this._settings.extglob,\r\n            noglobstar: !this._settings.globstar,\r\n            posix: true,\r\n            strictSlashes: false\r\n        };\r\n    }\r\n}\r\nprovider.default = Provider;\n\nObject.defineProperty(async$7, \"__esModule\", { value: true });\r\nconst async_1$1 = async$6;\r\nconst provider_1$2 = provider;\r\nclass ProviderAsync extends provider_1$2.default {\r\n    constructor() {\r\n        super(...arguments);\r\n        this._reader = new async_1$1.default(this._settings);\r\n    }\r\n    async read(task) {\r\n        const root = this._getRootDirectory(task);\r\n        const options = this._getReaderOptions(task);\r\n        const entries = await this.api(root, task, options);\r\n        return entries.map((entry) => options.transform(entry));\r\n    }\r\n    api(root, task, options) {\r\n        if (task.dynamic) {\r\n            return this._reader.dynamic(root, options);\r\n        }\r\n        return this._reader.static(task.patterns, options);\r\n    }\r\n}\r\nasync$7.default = ProviderAsync;\n\nvar stream = {};\n\nObject.defineProperty(stream, \"__esModule\", { value: true });\r\nconst stream_1$1 = require$$0$7;\r\nconst stream_2 = stream$1;\r\nconst provider_1$1 = provider;\r\nclass ProviderStream extends provider_1$1.default {\r\n    constructor() {\r\n        super(...arguments);\r\n        this._reader = new stream_2.default(this._settings);\r\n    }\r\n    read(task) {\r\n        const root = this._getRootDirectory(task);\r\n        const options = this._getReaderOptions(task);\r\n        const source = this.api(root, task, options);\r\n        const destination = new stream_1$1.Readable({ objectMode: true, read: () => { } });\r\n        source\r\n            .once('error', (error) => destination.emit('error', error))\r\n            .on('data', (entry) => destination.emit('data', options.transform(entry)))\r\n            .once('end', () => destination.emit('end'));\r\n        destination\r\n            .once('close', () => source.destroy());\r\n        return destination;\r\n    }\r\n    api(root, task, options) {\r\n        if (task.dynamic) {\r\n            return this._reader.dynamic(root, options);\r\n        }\r\n        return this._reader.static(task.patterns, options);\r\n    }\r\n}\r\nstream.default = ProviderStream;\n\nvar sync$2 = {};\n\nvar sync$1 = {};\n\nObject.defineProperty(sync$1, \"__esModule\", { value: true });\r\nconst fsStat = out$1;\r\nconst fsWalk = out$3;\r\nconst reader_1 = reader;\r\nclass ReaderSync extends reader_1.default {\r\n    constructor() {\r\n        super(...arguments);\r\n        this._walkSync = fsWalk.walkSync;\r\n        this._statSync = fsStat.statSync;\r\n    }\r\n    dynamic(root, options) {\r\n        return this._walkSync(root, options);\r\n    }\r\n    static(patterns, options) {\r\n        const entries = [];\r\n        for (const pattern of patterns) {\r\n            const filepath = this._getFullEntryPath(pattern);\r\n            const entry = this._getEntry(filepath, pattern, options);\r\n            if (entry === null || !options.entryFilter(entry)) {\r\n                continue;\r\n            }\r\n            entries.push(entry);\r\n        }\r\n        return entries;\r\n    }\r\n    _getEntry(filepath, pattern, options) {\r\n        try {\r\n            const stats = this._getStat(filepath);\r\n            return this._makeEntry(stats, pattern);\r\n        }\r\n        catch (error) {\r\n            if (options.errorFilter(error)) {\r\n                return null;\r\n            }\r\n            throw error;\r\n        }\r\n    }\r\n    _getStat(filepath) {\r\n        return this._statSync(filepath, this._fsStatSettings);\r\n    }\r\n}\r\nsync$1.default = ReaderSync;\n\nObject.defineProperty(sync$2, \"__esModule\", { value: true });\r\nconst sync_1$1 = sync$1;\r\nconst provider_1 = provider;\r\nclass ProviderSync extends provider_1.default {\r\n    constructor() {\r\n        super(...arguments);\r\n        this._reader = new sync_1$1.default(this._settings);\r\n    }\r\n    read(task) {\r\n        const root = this._getRootDirectory(task);\r\n        const options = this._getReaderOptions(task);\r\n        const entries = this.api(root, task, options);\r\n        return entries.map(options.transform);\r\n    }\r\n    api(root, task, options) {\r\n        if (task.dynamic) {\r\n            return this._reader.dynamic(root, options);\r\n        }\r\n        return this._reader.static(task.patterns, options);\r\n    }\r\n}\r\nsync$2.default = ProviderSync;\n\nvar settings = {};\n\n(function (exports) {\n\tObject.defineProperty(exports, \"__esModule\", { value: true });\r\n\texports.DEFAULT_FILE_SYSTEM_ADAPTER = void 0;\r\n\tconst fs = require$$0__default;\r\n\tconst os = require$$2;\r\n\t/**\r\n\t * The `os.cpus` method can return zero. We expect the number of cores to be greater than zero.\r\n\t * https://github.com/nodejs/node/blob/7faeddf23a98c53896f8b574a6e66589e8fb1eb8/lib/os.js#L106-L107\r\n\t */\r\n\tconst CPU_COUNT = Math.max(os.cpus().length, 1);\r\n\texports.DEFAULT_FILE_SYSTEM_ADAPTER = {\r\n\t    lstat: fs.lstat,\r\n\t    lstatSync: fs.lstatSync,\r\n\t    stat: fs.stat,\r\n\t    statSync: fs.statSync,\r\n\t    readdir: fs.readdir,\r\n\t    readdirSync: fs.readdirSync\r\n\t};\r\n\tclass Settings {\r\n\t    constructor(_options = {}) {\r\n\t        this._options = _options;\r\n\t        this.absolute = this._getValue(this._options.absolute, false);\r\n\t        this.baseNameMatch = this._getValue(this._options.baseNameMatch, false);\r\n\t        this.braceExpansion = this._getValue(this._options.braceExpansion, true);\r\n\t        this.caseSensitiveMatch = this._getValue(this._options.caseSensitiveMatch, true);\r\n\t        this.concurrency = this._getValue(this._options.concurrency, CPU_COUNT);\r\n\t        this.cwd = this._getValue(this._options.cwd, process.cwd());\r\n\t        this.deep = this._getValue(this._options.deep, Infinity);\r\n\t        this.dot = this._getValue(this._options.dot, false);\r\n\t        this.extglob = this._getValue(this._options.extglob, true);\r\n\t        this.followSymbolicLinks = this._getValue(this._options.followSymbolicLinks, true);\r\n\t        this.fs = this._getFileSystemMethods(this._options.fs);\r\n\t        this.globstar = this._getValue(this._options.globstar, true);\r\n\t        this.ignore = this._getValue(this._options.ignore, []);\r\n\t        this.markDirectories = this._getValue(this._options.markDirectories, false);\r\n\t        this.objectMode = this._getValue(this._options.objectMode, false);\r\n\t        this.onlyDirectories = this._getValue(this._options.onlyDirectories, false);\r\n\t        this.onlyFiles = this._getValue(this._options.onlyFiles, true);\r\n\t        this.stats = this._getValue(this._options.stats, false);\r\n\t        this.suppressErrors = this._getValue(this._options.suppressErrors, false);\r\n\t        this.throwErrorOnBrokenSymbolicLink = this._getValue(this._options.throwErrorOnBrokenSymbolicLink, false);\r\n\t        this.unique = this._getValue(this._options.unique, true);\r\n\t        if (this.onlyDirectories) {\r\n\t            this.onlyFiles = false;\r\n\t        }\r\n\t        if (this.stats) {\r\n\t            this.objectMode = true;\r\n\t        }\r\n\t    }\r\n\t    _getValue(option, value) {\r\n\t        return option === undefined ? value : option;\r\n\t    }\r\n\t    _getFileSystemMethods(methods = {}) {\r\n\t        return Object.assign(Object.assign({}, exports.DEFAULT_FILE_SYSTEM_ADAPTER), methods);\r\n\t    }\r\n\t}\r\n\texports.default = Settings;\n} (settings));\n\nconst taskManager = tasks;\r\nconst patternManager = patterns;\r\nconst async_1 = async$7;\r\nconst stream_1 = stream;\r\nconst sync_1 = sync$2;\r\nconst settings_1 = settings;\r\nconst utils = utils$g;\r\nasync function FastGlob(source, options) {\r\n    assertPatternsInput(source);\r\n    const works = getWorks(source, async_1.default, options);\r\n    const result = await Promise.all(works);\r\n    return utils.array.flatten(result);\r\n}\r\n// https://github.com/typescript-eslint/typescript-eslint/issues/60\r\n// eslint-disable-next-line no-redeclare\r\n(function (FastGlob) {\r\n    function sync(source, options) {\r\n        assertPatternsInput(source);\r\n        const works = getWorks(source, sync_1.default, options);\r\n        return utils.array.flatten(works);\r\n    }\r\n    FastGlob.sync = sync;\r\n    function stream(source, options) {\r\n        assertPatternsInput(source);\r\n        const works = getWorks(source, stream_1.default, options);\r\n        /**\r\n         * The stream returned by the provider cannot work with an asynchronous iterator.\r\n         * To support asynchronous iterators, regardless of the number of tasks, we always multiplex streams.\r\n         * This affects performance (+25%). I don't see best solution right now.\r\n         */\r\n        return utils.stream.merge(works);\r\n    }\r\n    FastGlob.stream = stream;\r\n    function generateTasks(source, options) {\r\n        assertPatternsInput(source);\r\n        const patterns = patternManager.transform([].concat(source));\r\n        const settings = new settings_1.default(options);\r\n        return taskManager.generate(patterns, settings);\r\n    }\r\n    FastGlob.generateTasks = generateTasks;\r\n    function isDynamicPattern(source, options) {\r\n        assertPatternsInput(source);\r\n        const settings = new settings_1.default(options);\r\n        return utils.pattern.isDynamicPattern(source, settings);\r\n    }\r\n    FastGlob.isDynamicPattern = isDynamicPattern;\r\n    function escapePath(source) {\r\n        assertPatternsInput(source);\r\n        return utils.path.escape(source);\r\n    }\r\n    FastGlob.escapePath = escapePath;\r\n})(FastGlob || (FastGlob = {}));\r\nfunction getWorks(source, _Provider, options) {\r\n    const patterns = patternManager.transform([].concat(source));\r\n    const settings = new settings_1.default(options);\r\n    const tasks = taskManager.generate(patterns, settings);\r\n    const provider = new _Provider(settings);\r\n    return tasks.map(provider.read, provider);\r\n}\r\nfunction assertPatternsInput(input) {\r\n    const source = [].concat(input);\r\n    const isValidSource = source.every((item) => utils.string.isString(item) && !utils.string.isEmpty(item));\r\n    if (!isValidSource) {\r\n        throw new TypeError('Patterns must be a string (non empty) or an array of strings');\r\n    }\r\n}\r\nvar out = FastGlob;\n\nconst debug$b = createDebugger('vite:ssr-external');\n/**\n * Converts \"parent > child\" syntax to just \"child\"\n */\nfunction stripNesting(packages) {\n    return packages.map((s) => {\n        const arr = s.split('>');\n        return arr[arr.length - 1].trim();\n    });\n}\n/**\n * Heuristics for determining whether a dependency should be externalized for\n * server-side rendering.\n */\nfunction cjsSsrResolveExternals(config, knownImports) {\n    // strip nesting since knownImports may be passed in from optimizeDeps which\n    // supports a \"parent > child\" syntax\n    knownImports = stripNesting(knownImports);\n    const ssrConfig = config.ssr;\n    if (ssrConfig?.noExternal === true) {\n        return [];\n    }\n    const ssrExternals = new Set();\n    const seen = new Set();\n    ssrConfig?.external?.forEach((id) => {\n        ssrExternals.add(id);\n        seen.add(id);\n    });\n    cjsSsrCollectExternals(config.root, config.resolve, ssrExternals, seen, config.logger);\n    const importedDeps = knownImports.map(getNpmPackageName).filter(isDefined);\n    for (const dep of importedDeps) {\n        // Assume external if not yet seen\n        // At this point, the project root and any linked packages have had their dependencies checked,\n        // so we can safely mark any knownImports not yet seen as external. They are guaranteed to be\n        // dependencies of packages in node_modules.\n        if (!seen.has(dep)) {\n            ssrExternals.add(dep);\n        }\n    }\n    // ensure `vite/dynamic-import-polyfill` is bundled (issue #1865)\n    ssrExternals.delete('vite');\n    let externals = [...ssrExternals];\n    if (ssrConfig?.noExternal) {\n        externals = externals.filter(createFilter(undefined, ssrConfig.noExternal, { resolve: false }));\n    }\n    return externals;\n}\nconst CJS_CONTENT_RE = /\\bmodule\\.exports\\b|\\bexports[.[]|\\brequire\\s*\\(|\\bObject\\.(?:defineProperty|defineProperties|assign)\\s*\\(\\s*exports\\b/;\n// TODO: use import()\nconst _require$2 = createRequire$1(import.meta.url);\nconst isSsrExternalCache = new WeakMap();\nfunction shouldExternalizeForSSR(id, config) {\n    let isSsrExternal = isSsrExternalCache.get(config);\n    if (!isSsrExternal) {\n        isSsrExternal = createIsSsrExternal(config);\n        isSsrExternalCache.set(config, isSsrExternal);\n    }\n    return isSsrExternal(id);\n}\nfunction createIsConfiguredAsSsrExternal(config) {\n    const { ssr, root } = config;\n    const noExternal = ssr?.noExternal;\n    const noExternalFilter = noExternal !== 'undefined' &&\n        typeof noExternal !== 'boolean' &&\n        createFilter(undefined, noExternal, { resolve: false });\n    const resolveOptions = {\n        ...config.resolve,\n        root,\n        isProduction: false,\n        isBuild: true,\n    };\n    const isExternalizable = (id, configuredAsExternal) => {\n        if (!bareImportRE.test(id) || id.includes('\\0')) {\n            return false;\n        }\n        try {\n            return !!tryNodeResolve(id, undefined, resolveOptions, ssr?.target === 'webworker', undefined, true, \n            // try to externalize, will return undefined or an object without\n            // a external flag if it isn't externalizable\n            true, \n            // Allow linked packages to be externalized if they are explicitly\n            // configured as external\n            !!configuredAsExternal)?.external;\n        }\n        catch (e) {\n            debug$b(`Failed to node resolve \"${id}\". Skipping externalizing it by default.`);\n            // may be an invalid import that's resolved by a plugin\n            return false;\n        }\n    };\n    // Returns true if it is configured as external, false if it is filtered\n    // by noExternal and undefined if it isn't affected by the explicit config\n    return (id) => {\n        const { ssr } = config;\n        if (ssr) {\n            if (\n            // If this id is defined as external, force it as external\n            // Note that individual package entries are allowed in ssr.external\n            ssr.external?.includes(id)) {\n                return true;\n            }\n            const pkgName = getNpmPackageName(id);\n            if (!pkgName) {\n                return isExternalizable(id);\n            }\n            if (\n            // A package name in ssr.external externalizes every\n            // externalizable package entry\n            ssr.external?.includes(pkgName)) {\n                return isExternalizable(id, true);\n            }\n            if (typeof noExternal === 'boolean') {\n                return !noExternal;\n            }\n            if (noExternalFilter && !noExternalFilter(pkgName)) {\n                return false;\n            }\n        }\n        return isExternalizable(id);\n    };\n}\nfunction createIsSsrExternal(config) {\n    const processedIds = new Map();\n    const isConfiguredAsExternal = createIsConfiguredAsSsrExternal(config);\n    return (id) => {\n        if (processedIds.has(id)) {\n            return processedIds.get(id);\n        }\n        let external = false;\n        if (!id.startsWith('.') && !path$o.isAbsolute(id)) {\n            external = isBuiltin(id) || isConfiguredAsExternal(id);\n        }\n        processedIds.set(id, external);\n        return external;\n    };\n}\n// When config.experimental.buildSsrCjsExternalHeuristics is enabled, this function\n// is used reverting to the Vite 2.9 SSR externalization heuristics\nfunction cjsSsrCollectExternals(root, resolveOptions, ssrExternals, seen, logger) {\n    const rootPkgContent = lookupFile(root, ['package.json']);\n    if (!rootPkgContent) {\n        return;\n    }\n    const rootPkg = JSON.parse(rootPkgContent);\n    const deps = {\n        ...rootPkg.devDependencies,\n        ...rootPkg.dependencies,\n    };\n    const internalResolveOptions = {\n        ...resolveOptions,\n        root,\n        isProduction: false,\n        isBuild: true,\n    };\n    const depsToTrace = new Set();\n    for (const id in deps) {\n        if (seen.has(id))\n            continue;\n        seen.add(id);\n        let esmEntry;\n        let requireEntry;\n        try {\n            esmEntry = tryNodeResolve(id, undefined, internalResolveOptions, true, // we set `targetWeb` to `true` to get the ESM entry\n            undefined, true)?.id;\n            // normalizePath required for windows. tryNodeResolve uses normalizePath\n            // which returns with '/', require.resolve returns with '\\\\'\n            requireEntry = normalizePath$3(_require$2.resolve(id, { paths: [root] }));\n        }\n        catch (e) {\n            try {\n                // no main entry, but deep imports may be allowed\n                const pkgPath = resolveFrom(`${id}/package.json`, root);\n                if (pkgPath.includes('node_modules')) {\n                    ssrExternals.add(id);\n                }\n                else {\n                    depsToTrace.add(path$o.dirname(pkgPath));\n                }\n                continue;\n            }\n            catch { }\n            // resolve failed, assume include\n            debug$b(`Failed to resolve entries for package \"${id}\"\\n`, e);\n            continue;\n        }\n        // no esm entry but has require entry\n        if (!esmEntry) {\n            ssrExternals.add(id);\n        }\n        // trace the dependencies of linked packages\n        else if (!esmEntry.includes('node_modules')) {\n            const pkgPath = resolveFrom(`${id}/package.json`, root);\n            depsToTrace.add(path$o.dirname(pkgPath));\n        }\n        // has separate esm/require entry, assume require entry is cjs\n        else if (esmEntry !== requireEntry) {\n            ssrExternals.add(id);\n        }\n        // if we're externalizing ESM and CJS should basically just always do it?\n        // or are there others like SystemJS / AMD that we'd need to handle?\n        // for now, we'll just leave this as is\n        else if (/\\.m?js$/.test(esmEntry)) {\n            const pkgPath = resolveFrom(`${id}/package.json`, root);\n            const pkgContent = fs$l.readFileSync(pkgPath, 'utf-8');\n            if (!pkgContent) {\n                continue;\n            }\n            const pkg = JSON.parse(pkgContent);\n            if (pkg.type === 'module' || esmEntry.endsWith('.mjs')) {\n                ssrExternals.add(id);\n                continue;\n            }\n            // check if the entry is cjs\n            const content = fs$l.readFileSync(esmEntry, 'utf-8');\n            if (CJS_CONTENT_RE.test(content)) {\n                ssrExternals.add(id);\n                continue;\n            }\n            logger.warn(`${id} doesn't appear to be written in CJS, but also doesn't appear to be a valid ES module (i.e. it doesn't have \"type\": \"module\" or an .mjs extension for the entry point). Please contact the package author to fix.`);\n        }\n    }\n    for (const depRoot of depsToTrace) {\n        cjsSsrCollectExternals(depRoot, resolveOptions, ssrExternals, seen, logger);\n    }\n}\nfunction cjsShouldExternalizeForSSR(id, externals) {\n    if (!externals) {\n        return false;\n    }\n    const should = externals.some((e) => {\n        if (id === e) {\n            return true;\n        }\n        // deep imports, check ext before externalizing - only externalize\n        // extension-less imports and explicit .js imports\n        if (id.startsWith(e + '/') && (!path$o.extname(id) || id.endsWith('.js'))) {\n            return true;\n        }\n    });\n    return should;\n}\nfunction getNpmPackageName(importPath) {\n    const parts = importPath.split('/');\n    if (parts[0].startsWith('@')) {\n        if (!parts[1])\n            return null;\n        return `${parts[0]}/${parts[1]}`;\n    }\n    else {\n        return parts[0];\n    }\n}\n\n/**\n * https://github.com/rollup/plugins/blob/master/packages/json/src/index.js\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file at\n * https://github.com/rollup/plugins/blob/master/LICENSE\n */\n// Custom json filter for vite\nconst jsonExtRE = /\\.json(?:$|\\?)(?!commonjs-(?:proxy|external))/;\nconst jsonLangs = `\\\\.(?:json|json5)(?:$|\\\\?)`;\nconst jsonLangRE = new RegExp(jsonLangs);\nconst isJSONRequest = (request) => jsonLangRE.test(request);\nfunction jsonPlugin(options = {}, isBuild) {\n    return {\n        name: 'vite:json',\n        transform(json, id) {\n            if (!jsonExtRE.test(id))\n                return null;\n            if (SPECIAL_QUERY_RE.test(id))\n                return null;\n            json = stripBomTag(json);\n            try {\n                if (options.stringify) {\n                    if (isBuild) {\n                        return {\n                            // during build, parse then double-stringify to remove all\n                            // unnecessary whitespaces to reduce bundle size.\n                            code: `export default JSON.parse(${JSON.stringify(JSON.stringify(JSON.parse(json)))})`,\n                            map: { mappings: '' },\n                        };\n                    }\n                    else {\n                        return `export default JSON.parse(${JSON.stringify(json)})`;\n                    }\n                }\n                const parsed = JSON.parse(json);\n                return {\n                    code: dataToEsm(parsed, {\n                        preferConst: true,\n                        namedExports: options.namedExports,\n                    }),\n                    map: { mappings: '' },\n                };\n            }\n            catch (e) {\n                const errorMessageList = /\\d+/.exec(e.message);\n                const position = errorMessageList && parseInt(errorMessageList[0], 10);\n                const msg = position\n                    ? `, invalid JSON syntax found at line ${position}`\n                    : `.`;\n                this.error(`Failed to parse JSON file` + msg, e.idx);\n            }\n        },\n    };\n}\n\nconst ERR_OPTIMIZE_DEPS_PROCESSING_ERROR = 'ERR_OPTIMIZE_DEPS_PROCESSING_ERROR';\nconst ERR_OUTDATED_OPTIMIZED_DEP = 'ERR_OUTDATED_OPTIMIZED_DEP';\nconst isDebug$3 = process.env.DEBUG;\nconst debug$a = createDebugger('vite:optimize-deps');\nfunction optimizedDepsPlugin(config) {\n    return {\n        name: 'vite:optimized-deps',\n        async resolveId(id, source, { ssr }) {\n            if (getDepsOptimizer(config, ssr)?.isOptimizedDepFile(id)) {\n                return id;\n            }\n        },\n        // this.load({ id }) isn't implemented in PluginContainer\n        // The logic to register an id to wait until it is processed\n        // is in importAnalysis, see call to delayDepsOptimizerUntil\n        async load(id, options) {\n            const ssr = options?.ssr === true;\n            const depsOptimizer = getDepsOptimizer(config, ssr);\n            if (depsOptimizer?.isOptimizedDepFile(id)) {\n                const metadata = depsOptimizer.metadata;\n                const file = cleanUrl(id);\n                const versionMatch = id.match(DEP_VERSION_RE);\n                const browserHash = versionMatch\n                    ? versionMatch[1].split('=')[1]\n                    : undefined;\n                // Search in both the currently optimized and newly discovered deps\n                const info = optimizedDepInfoFromFile(metadata, file);\n                if (info) {\n                    if (browserHash && info.browserHash !== browserHash) {\n                        throwOutdatedRequest(id);\n                    }\n                    try {\n                        // This is an entry point, it may still not be bundled\n                        await info.processing;\n                    }\n                    catch {\n                        // If the refresh has not happened after timeout, Vite considers\n                        // something unexpected has happened. In this case, Vite\n                        // returns an empty response that will error.\n                        throwProcessingError(id);\n                        return;\n                    }\n                    const newMetadata = depsOptimizer.metadata;\n                    if (metadata !== newMetadata) {\n                        const currentInfo = optimizedDepInfoFromFile(newMetadata, file);\n                        if (info.browserHash !== currentInfo?.browserHash) {\n                            throwOutdatedRequest(id);\n                        }\n                    }\n                }\n                isDebug$3 && debug$a(`load ${picocolorsExports.cyan(file)}`);\n                // Load the file from the cache instead of waiting for other plugin\n                // load hooks to avoid race conditions, once processing is resolved,\n                // we are sure that the file has been properly save to disk\n                try {\n                    return await promises$2.readFile(file, 'utf-8');\n                }\n                catch (e) {\n                    // Outdated non-entry points (CHUNK), loaded after a rerun\n                    throwOutdatedRequest(id);\n                }\n            }\n        },\n    };\n}\nfunction optimizedDepsBuildPlugin(config) {\n    return {\n        name: 'vite:optimized-deps-build',\n        buildStart() {\n            if (!config.isWorker) {\n                // This will be run for the current active optimizer, during build\n                // it will be the SSR optimizer if config.build.ssr is defined\n                getDepsOptimizer(config)?.resetRegisteredIds();\n            }\n        },\n        async resolveId(id, importer, { ssr }) {\n            if (getDepsOptimizer(config, ssr)?.isOptimizedDepFile(id)) {\n                return id;\n            }\n        },\n        transform(_code, id, options) {\n            const ssr = options?.ssr === true;\n            getDepsOptimizer(config, ssr)?.delayDepsOptimizerUntil(id, async () => {\n                await this.load({ id });\n            });\n        },\n        async load(id, options) {\n            const ssr = options?.ssr === true;\n            const depsOptimizer = getDepsOptimizer(config, ssr);\n            if (!depsOptimizer?.isOptimizedDepFile(id)) {\n                return;\n            }\n            depsOptimizer?.ensureFirstRun();\n            const file = cleanUrl(id);\n            // Search in both the currently optimized and newly discovered deps\n            // If all the inputs are dependencies, we aren't going to get any\n            const info = optimizedDepInfoFromFile(depsOptimizer.metadata, file);\n            if (info) {\n                try {\n                    // This is an entry point, it may still not be bundled\n                    await info.processing;\n                }\n                catch {\n                    // If the refresh has not happened after timeout, Vite considers\n                    // something unexpected has happened. In this case, Vite\n                    // returns an empty response that will error.\n                    // throwProcessingError(id)\n                    return;\n                }\n                isDebug$3 && debug$a(`load ${picocolorsExports.cyan(file)}`);\n            }\n            else {\n                // TODO: error\n                return;\n            }\n            // Load the file from the cache instead of waiting for other plugin\n            // load hooks to avoid race conditions, once processing is resolved,\n            // we are sure that the file has been properly save to disk\n            try {\n                return await promises$2.readFile(file, 'utf-8');\n            }\n            catch (e) {\n                // Outdated non-entry points (CHUNK), loaded after a rerun\n                return '';\n            }\n        },\n    };\n}\nfunction throwProcessingError(id) {\n    const err = new Error(`Something unexpected happened while optimizing \"${id}\". ` +\n        `The current page should have reloaded by now`);\n    err.code = ERR_OPTIMIZE_DEPS_PROCESSING_ERROR;\n    // This error will be caught by the transform middleware that will\n    // send a 504 status code request timeout\n    throw err;\n}\nfunction throwOutdatedRequest(id) {\n    const err = new Error(`There is a new version of the pre-bundle for \"${id}\", ` +\n        `a page reload is going to ask for it.`);\n    err.code = ERR_OUTDATED_OPTIMIZED_DEP;\n    // This error will be caught by the transform middleware that will\n    // send a 504 status code request timeout\n    throw err;\n}\n\nvar dist = {};\n\n(function (exports) {\n\tObject.defineProperty(exports, \"__esModule\", { value: true });\n\texports.lilconfigSync = exports.lilconfig = exports.defaultLoaders = void 0;\n\tconst path = require$$0$4;\n\tconst fs = require$$0__default;\n\tconst os = require$$2;\n\tconst fsReadFileAsync = fs.promises.readFile;\n\tfunction getDefaultSearchPlaces(name) {\n\t    return [\n\t        'package.json',\n\t        `.${name}rc.json`,\n\t        `.${name}rc.js`,\n\t        `${name}.config.js`,\n\t        `.${name}rc.cjs`,\n\t        `${name}.config.cjs`,\n\t    ];\n\t}\n\tfunction getSearchPaths(startDir, stopDir) {\n\t    return startDir\n\t        .split(path.sep)\n\t        .reduceRight((acc, _, ind, arr) => {\n\t        const currentPath = arr.slice(0, ind + 1).join(path.sep);\n\t        if (!acc.passedStopDir)\n\t            acc.searchPlaces.push(currentPath || path.sep);\n\t        if (currentPath === stopDir)\n\t            acc.passedStopDir = true;\n\t        return acc;\n\t    }, { searchPlaces: [], passedStopDir: false }).searchPlaces;\n\t}\n\texports.defaultLoaders = Object.freeze({\n\t    '.js': __require,\n\t    '.json': __require,\n\t    '.cjs': __require,\n\t    noExt(_, content) {\n\t        return JSON.parse(content);\n\t    },\n\t});\n\tfunction getExtDesc(ext) {\n\t    return ext === 'noExt' ? 'files without extensions' : `extension \"${ext}\"`;\n\t}\n\tfunction getOptions(name, options = {}) {\n\t    const conf = {\n\t        stopDir: os.homedir(),\n\t        searchPlaces: getDefaultSearchPlaces(name),\n\t        ignoreEmptySearchPlaces: true,\n\t        transform: (x) => x,\n\t        packageProp: [name],\n\t        ...options,\n\t        loaders: { ...exports.defaultLoaders, ...options.loaders },\n\t    };\n\t    conf.searchPlaces.forEach(place => {\n\t        const key = path.extname(place) || 'noExt';\n\t        const loader = conf.loaders[key];\n\t        if (!loader) {\n\t            throw new Error(`No loader specified for ${getExtDesc(key)}, so searchPlaces item \"${place}\" is invalid`);\n\t        }\n\t        if (typeof loader !== 'function') {\n\t            throw new Error(`loader for ${getExtDesc(key)} is not a function (type provided: \"${typeof loader}\"), so searchPlaces item \"${place}\" is invalid`);\n\t        }\n\t    });\n\t    return conf;\n\t}\n\tfunction getPackageProp(props, obj) {\n\t    if (typeof props === 'string' && props in obj)\n\t        return obj[props];\n\t    return ((Array.isArray(props) ? props : props.split('.')).reduce((acc, prop) => (acc === undefined ? acc : acc[prop]), obj) || null);\n\t}\n\tfunction getSearchItems(searchPlaces, searchPaths) {\n\t    return searchPaths.reduce((acc, searchPath) => {\n\t        searchPlaces.forEach(fileName => acc.push({\n\t            fileName,\n\t            filepath: path.join(searchPath, fileName),\n\t            loaderKey: path.extname(fileName) || 'noExt',\n\t        }));\n\t        return acc;\n\t    }, []);\n\t}\n\tfunction validateFilePath(filepath) {\n\t    if (!filepath)\n\t        throw new Error('load must pass a non-empty string');\n\t}\n\tfunction validateLoader(loader, ext) {\n\t    if (!loader)\n\t        throw new Error(`No loader specified for extension \"${ext}\"`);\n\t    if (typeof loader !== 'function')\n\t        throw new Error('loader is not a function');\n\t}\n\tfunction lilconfig(name, options) {\n\t    const { ignoreEmptySearchPlaces, loaders, packageProp, searchPlaces, stopDir, transform, } = getOptions(name, options);\n\t    return {\n\t        async search(searchFrom = process.cwd()) {\n\t            const searchPaths = getSearchPaths(searchFrom, stopDir);\n\t            const result = {\n\t                config: null,\n\t                filepath: '',\n\t            };\n\t            const searchItems = getSearchItems(searchPlaces, searchPaths);\n\t            for (const { fileName, filepath, loaderKey } of searchItems) {\n\t                try {\n\t                    await fs.promises.access(filepath);\n\t                }\n\t                catch (_a) {\n\t                    continue;\n\t                }\n\t                const content = String(await fsReadFileAsync(filepath));\n\t                const loader = loaders[loaderKey];\n\t                if (fileName === 'package.json') {\n\t                    const pkg = await loader(filepath, content);\n\t                    const maybeConfig = getPackageProp(packageProp, pkg);\n\t                    if (maybeConfig != null) {\n\t                        result.config = maybeConfig;\n\t                        result.filepath = filepath;\n\t                        break;\n\t                    }\n\t                    continue;\n\t                }\n\t                const isEmpty = content.trim() === '';\n\t                if (isEmpty && ignoreEmptySearchPlaces)\n\t                    continue;\n\t                if (isEmpty) {\n\t                    result.isEmpty = true;\n\t                    result.config = undefined;\n\t                }\n\t                else {\n\t                    validateLoader(loader, loaderKey);\n\t                    result.config = await loader(filepath, content);\n\t                }\n\t                result.filepath = filepath;\n\t                break;\n\t            }\n\t            if (result.filepath === '' && result.config === null)\n\t                return transform(null);\n\t            return transform(result);\n\t        },\n\t        async load(filepath) {\n\t            validateFilePath(filepath);\n\t            const absPath = path.resolve(process.cwd(), filepath);\n\t            const { base, ext } = path.parse(absPath);\n\t            const loaderKey = ext || 'noExt';\n\t            const loader = loaders[loaderKey];\n\t            validateLoader(loader, loaderKey);\n\t            const content = String(await fsReadFileAsync(absPath));\n\t            if (base === 'package.json') {\n\t                const pkg = await loader(absPath, content);\n\t                return transform({\n\t                    config: getPackageProp(packageProp, pkg),\n\t                    filepath: absPath,\n\t                });\n\t            }\n\t            const result = {\n\t                config: null,\n\t                filepath: absPath,\n\t            };\n\t            const isEmpty = content.trim() === '';\n\t            if (isEmpty && ignoreEmptySearchPlaces)\n\t                return transform({\n\t                    config: undefined,\n\t                    filepath: absPath,\n\t                    isEmpty: true,\n\t                });\n\t            result.config = isEmpty\n\t                ? undefined\n\t                : await loader(absPath, content);\n\t            return transform(isEmpty ? { ...result, isEmpty, config: undefined } : result);\n\t        },\n\t    };\n\t}\n\texports.lilconfig = lilconfig;\n\tfunction lilconfigSync(name, options) {\n\t    const { ignoreEmptySearchPlaces, loaders, packageProp, searchPlaces, stopDir, transform, } = getOptions(name, options);\n\t    return {\n\t        search(searchFrom = process.cwd()) {\n\t            const searchPaths = getSearchPaths(searchFrom, stopDir);\n\t            const result = {\n\t                config: null,\n\t                filepath: '',\n\t            };\n\t            const searchItems = getSearchItems(searchPlaces, searchPaths);\n\t            for (const { fileName, filepath, loaderKey } of searchItems) {\n\t                try {\n\t                    fs.accessSync(filepath);\n\t                }\n\t                catch (_a) {\n\t                    continue;\n\t                }\n\t                const loader = loaders[loaderKey];\n\t                const content = String(fs.readFileSync(filepath));\n\t                if (fileName === 'package.json') {\n\t                    const pkg = loader(filepath, content);\n\t                    const maybeConfig = getPackageProp(packageProp, pkg);\n\t                    if (maybeConfig != null) {\n\t                        result.config = maybeConfig;\n\t                        result.filepath = filepath;\n\t                        break;\n\t                    }\n\t                    continue;\n\t                }\n\t                const isEmpty = content.trim() === '';\n\t                if (isEmpty && ignoreEmptySearchPlaces)\n\t                    continue;\n\t                if (isEmpty) {\n\t                    result.isEmpty = true;\n\t                    result.config = undefined;\n\t                }\n\t                else {\n\t                    validateLoader(loader, loaderKey);\n\t                    result.config = loader(filepath, content);\n\t                }\n\t                result.filepath = filepath;\n\t                break;\n\t            }\n\t            if (result.filepath === '' && result.config === null)\n\t                return transform(null);\n\t            return transform(result);\n\t        },\n\t        load(filepath) {\n\t            validateFilePath(filepath);\n\t            const absPath = path.resolve(process.cwd(), filepath);\n\t            const { base, ext } = path.parse(absPath);\n\t            const loaderKey = ext || 'noExt';\n\t            const loader = loaders[loaderKey];\n\t            validateLoader(loader, loaderKey);\n\t            const content = String(fs.readFileSync(absPath));\n\t            if (base === 'package.json') {\n\t                const pkg = loader(absPath, content);\n\t                return transform({\n\t                    config: getPackageProp(packageProp, pkg),\n\t                    filepath: absPath,\n\t                });\n\t            }\n\t            const result = {\n\t                config: null,\n\t                filepath: absPath,\n\t            };\n\t            const isEmpty = content.trim() === '';\n\t            if (isEmpty && ignoreEmptySearchPlaces)\n\t                return transform({\n\t                    filepath: absPath,\n\t                    config: undefined,\n\t                    isEmpty: true,\n\t                });\n\t            result.config = isEmpty ? undefined : loader(absPath, content);\n\t            return transform(isEmpty ? { ...result, isEmpty, config: undefined } : result);\n\t        },\n\t    };\n\t}\n\texports.lilconfigSync = lilconfigSync;\n} (dist));\n\nconst ALIAS = Symbol.for('yaml.alias');\nconst DOC = Symbol.for('yaml.document');\nconst MAP = Symbol.for('yaml.map');\nconst PAIR = Symbol.for('yaml.pair');\nconst SCALAR$1 = Symbol.for('yaml.scalar');\nconst SEQ = Symbol.for('yaml.seq');\nconst NODE_TYPE = Symbol.for('yaml.node.type');\nconst isAlias = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === ALIAS;\nconst isDocument = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === DOC;\nconst isMap = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === MAP;\nconst isPair = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === PAIR;\nconst isScalar$1 = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SCALAR$1;\nconst isSeq = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SEQ;\nfunction isCollection$1(node) {\n    if (node && typeof node === 'object')\n        switch (node[NODE_TYPE]) {\n            case MAP:\n            case SEQ:\n                return true;\n        }\n    return false;\n}\nfunction isNode$1(node) {\n    if (node && typeof node === 'object')\n        switch (node[NODE_TYPE]) {\n            case ALIAS:\n            case MAP:\n            case SCALAR$1:\n            case SEQ:\n                return true;\n        }\n    return false;\n}\nconst hasAnchor = (node) => (isScalar$1(node) || isCollection$1(node)) && !!node.anchor;\nclass NodeBase {\n    constructor(type) {\n        Object.defineProperty(this, NODE_TYPE, { value: type });\n    }\n    /** Create a copy of this node.  */\n    clone() {\n        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n}\n\nconst BREAK$1 = Symbol('break visit');\nconst SKIP$1 = Symbol('skip children');\nconst REMOVE$1 = Symbol('remove node');\n/**\n * Apply a visitor to an AST node or document.\n *\n * Walks through the tree (depth-first) starting from `node`, calling a\n * `visitor` function with three arguments:\n *   - `key`: For sequence values and map `Pair`, the node's index in the\n *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.\n *     `null` for the root node.\n *   - `node`: The current node.\n *   - `path`: The ancestry of the current node.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this node, continue with next\n *     sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current node, then continue with the next one\n *   - `Node`: Replace the current node, then continue by visiting it\n *   - `number`: While iterating the items of a sequence or map, set the index\n *     of the next step. This is useful especially if the index of the current\n *     node has changed.\n *\n * If `visitor` is a single function, it will be called with all values\n * encountered in the tree, including e.g. `null` values. Alternatively,\n * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,\n * `Alias` and `Scalar` node. To define the same visitor function for more than\n * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)\n * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most\n * specific defined one will be used for each node.\n */\nfunction visit$1(node, visitor) {\n    const visitor_ = initVisitor(visitor);\n    if (isDocument(node)) {\n        const cd = visit_(null, node.contents, visitor_, Object.freeze([node]));\n        if (cd === REMOVE$1)\n            node.contents = null;\n    }\n    else\n        visit_(null, node, visitor_, Object.freeze([]));\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisit$1.BREAK = BREAK$1;\n/** Do not visit the children of the current node */\nvisit$1.SKIP = SKIP$1;\n/** Remove the current node */\nvisit$1.REMOVE = REMOVE$1;\nfunction visit_(key, node, visitor, path) {\n    const ctrl = callVisitor(key, node, visitor, path);\n    if (isNode$1(ctrl) || isPair(ctrl)) {\n        replaceNode(key, path, ctrl);\n        return visit_(key, ctrl, visitor, path);\n    }\n    if (typeof ctrl !== 'symbol') {\n        if (isCollection$1(node)) {\n            path = Object.freeze(path.concat(node));\n            for (let i = 0; i < node.items.length; ++i) {\n                const ci = visit_(i, node.items[i], visitor, path);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK$1)\n                    return BREAK$1;\n                else if (ci === REMOVE$1) {\n                    node.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n        }\n        else if (isPair(node)) {\n            path = Object.freeze(path.concat(node));\n            const ck = visit_('key', node.key, visitor, path);\n            if (ck === BREAK$1)\n                return BREAK$1;\n            else if (ck === REMOVE$1)\n                node.key = null;\n            const cv = visit_('value', node.value, visitor, path);\n            if (cv === BREAK$1)\n                return BREAK$1;\n            else if (cv === REMOVE$1)\n                node.value = null;\n        }\n    }\n    return ctrl;\n}\n/**\n * Apply an async visitor to an AST node or document.\n *\n * Walks through the tree (depth-first) starting from `node`, calling a\n * `visitor` function with three arguments:\n *   - `key`: For sequence values and map `Pair`, the node's index in the\n *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.\n *     `null` for the root node.\n *   - `node`: The current node.\n *   - `path`: The ancestry of the current node.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `Promise`: Must resolve to one of the following values\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this node, continue with next\n *     sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current node, then continue with the next one\n *   - `Node`: Replace the current node, then continue by visiting it\n *   - `number`: While iterating the items of a sequence or map, set the index\n *     of the next step. This is useful especially if the index of the current\n *     node has changed.\n *\n * If `visitor` is a single function, it will be called with all values\n * encountered in the tree, including e.g. `null` values. Alternatively,\n * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,\n * `Alias` and `Scalar` node. To define the same visitor function for more than\n * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)\n * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most\n * specific defined one will be used for each node.\n */\nasync function visitAsync(node, visitor) {\n    const visitor_ = initVisitor(visitor);\n    if (isDocument(node)) {\n        const cd = await visitAsync_(null, node.contents, visitor_, Object.freeze([node]));\n        if (cd === REMOVE$1)\n            node.contents = null;\n    }\n    else\n        await visitAsync_(null, node, visitor_, Object.freeze([]));\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisitAsync.BREAK = BREAK$1;\n/** Do not visit the children of the current node */\nvisitAsync.SKIP = SKIP$1;\n/** Remove the current node */\nvisitAsync.REMOVE = REMOVE$1;\nasync function visitAsync_(key, node, visitor, path) {\n    const ctrl = await callVisitor(key, node, visitor, path);\n    if (isNode$1(ctrl) || isPair(ctrl)) {\n        replaceNode(key, path, ctrl);\n        return visitAsync_(key, ctrl, visitor, path);\n    }\n    if (typeof ctrl !== 'symbol') {\n        if (isCollection$1(node)) {\n            path = Object.freeze(path.concat(node));\n            for (let i = 0; i < node.items.length; ++i) {\n                const ci = await visitAsync_(i, node.items[i], visitor, path);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK$1)\n                    return BREAK$1;\n                else if (ci === REMOVE$1) {\n                    node.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n        }\n        else if (isPair(node)) {\n            path = Object.freeze(path.concat(node));\n            const ck = await visitAsync_('key', node.key, visitor, path);\n            if (ck === BREAK$1)\n                return BREAK$1;\n            else if (ck === REMOVE$1)\n                node.key = null;\n            const cv = await visitAsync_('value', node.value, visitor, path);\n            if (cv === BREAK$1)\n                return BREAK$1;\n            else if (cv === REMOVE$1)\n                node.value = null;\n        }\n    }\n    return ctrl;\n}\nfunction initVisitor(visitor) {\n    if (typeof visitor === 'object' &&\n        (visitor.Collection || visitor.Node || visitor.Value)) {\n        return Object.assign({\n            Alias: visitor.Node,\n            Map: visitor.Node,\n            Scalar: visitor.Node,\n            Seq: visitor.Node\n        }, visitor.Value && {\n            Map: visitor.Value,\n            Scalar: visitor.Value,\n            Seq: visitor.Value\n        }, visitor.Collection && {\n            Map: visitor.Collection,\n            Seq: visitor.Collection\n        }, visitor);\n    }\n    return visitor;\n}\nfunction callVisitor(key, node, visitor, path) {\n    if (typeof visitor === 'function')\n        return visitor(key, node, path);\n    if (isMap(node))\n        return visitor.Map?.(key, node, path);\n    if (isSeq(node))\n        return visitor.Seq?.(key, node, path);\n    if (isPair(node))\n        return visitor.Pair?.(key, node, path);\n    if (isScalar$1(node))\n        return visitor.Scalar?.(key, node, path);\n    if (isAlias(node))\n        return visitor.Alias?.(key, node, path);\n    return undefined;\n}\nfunction replaceNode(key, path, node) {\n    const parent = path[path.length - 1];\n    if (isCollection$1(parent)) {\n        parent.items[key] = node;\n    }\n    else if (isPair(parent)) {\n        if (key === 'key')\n            parent.key = node;\n        else\n            parent.value = node;\n    }\n    else if (isDocument(parent)) {\n        parent.contents = node;\n    }\n    else {\n        const pt = isAlias(parent) ? 'alias' : 'scalar';\n        throw new Error(`Cannot replace node with ${pt} parent`);\n    }\n}\n\nconst escapeChars = {\n    '!': '%21',\n    ',': '%2C',\n    '[': '%5B',\n    ']': '%5D',\n    '{': '%7B',\n    '}': '%7D'\n};\nconst escapeTagName = (tn) => tn.replace(/[!,[\\]{}]/g, ch => escapeChars[ch]);\nclass Directives {\n    constructor(yaml, tags) {\n        /**\n         * The directives-end/doc-start marker `---`. If `null`, a marker may still be\n         * included in the document's stringified representation.\n         */\n        this.docStart = null;\n        /** The doc-end marker `...`.  */\n        this.docEnd = false;\n        this.yaml = Object.assign({}, Directives.defaultYaml, yaml);\n        this.tags = Object.assign({}, Directives.defaultTags, tags);\n    }\n    clone() {\n        const copy = new Directives(this.yaml, this.tags);\n        copy.docStart = this.docStart;\n        return copy;\n    }\n    /**\n     * During parsing, get a Directives instance for the current document and\n     * update the stream state according to the current version's spec.\n     */\n    atDocument() {\n        const res = new Directives(this.yaml, this.tags);\n        switch (this.yaml.version) {\n            case '1.1':\n                this.atNextDocument = true;\n                break;\n            case '1.2':\n                this.atNextDocument = false;\n                this.yaml = {\n                    explicit: Directives.defaultYaml.explicit,\n                    version: '1.2'\n                };\n                this.tags = Object.assign({}, Directives.defaultTags);\n                break;\n        }\n        return res;\n    }\n    /**\n     * @param onError - May be called even if the action was successful\n     * @returns `true` on success\n     */\n    add(line, onError) {\n        if (this.atNextDocument) {\n            this.yaml = { explicit: Directives.defaultYaml.explicit, version: '1.1' };\n            this.tags = Object.assign({}, Directives.defaultTags);\n            this.atNextDocument = false;\n        }\n        const parts = line.trim().split(/[ \\t]+/);\n        const name = parts.shift();\n        switch (name) {\n            case '%TAG': {\n                if (parts.length !== 2) {\n                    onError(0, '%TAG directive should contain exactly two parts');\n                    if (parts.length < 2)\n                        return false;\n                }\n                const [handle, prefix] = parts;\n                this.tags[handle] = prefix;\n                return true;\n            }\n            case '%YAML': {\n                this.yaml.explicit = true;\n                if (parts.length !== 1) {\n                    onError(0, '%YAML directive should contain exactly one part');\n                    return false;\n                }\n                const [version] = parts;\n                if (version === '1.1' || version === '1.2') {\n                    this.yaml.version = version;\n                    return true;\n                }\n                else {\n                    const isValid = /^\\d+\\.\\d+$/.test(version);\n                    onError(6, `Unsupported YAML version ${version}`, isValid);\n                    return false;\n                }\n            }\n            default:\n                onError(0, `Unknown directive ${name}`, true);\n                return false;\n        }\n    }\n    /**\n     * Resolves a tag, matching handles to those defined in %TAG directives.\n     *\n     * @returns Resolved tag, which may also be the non-specific tag `'!'` or a\n     *   `'!local'` tag, or `null` if unresolvable.\n     */\n    tagName(source, onError) {\n        if (source === '!')\n            return '!'; // non-specific tag\n        if (source[0] !== '!') {\n            onError(`Not a valid tag: ${source}`);\n            return null;\n        }\n        if (source[1] === '<') {\n            const verbatim = source.slice(2, -1);\n            if (verbatim === '!' || verbatim === '!!') {\n                onError(`Verbatim tags aren't resolved, so ${source} is invalid.`);\n                return null;\n            }\n            if (source[source.length - 1] !== '>')\n                onError('Verbatim tags must end with a >');\n            return verbatim;\n        }\n        const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/);\n        if (!suffix)\n            onError(`The ${source} tag has no suffix`);\n        const prefix = this.tags[handle];\n        if (prefix)\n            return prefix + decodeURIComponent(suffix);\n        if (handle === '!')\n            return source; // local tag\n        onError(`Could not resolve tag: ${source}`);\n        return null;\n    }\n    /**\n     * Given a fully resolved tag, returns its printable string form,\n     * taking into account current tag prefixes and defaults.\n     */\n    tagString(tag) {\n        for (const [handle, prefix] of Object.entries(this.tags)) {\n            if (tag.startsWith(prefix))\n                return handle + escapeTagName(tag.substring(prefix.length));\n        }\n        return tag[0] === '!' ? tag : `!<${tag}>`;\n    }\n    toString(doc) {\n        const lines = this.yaml.explicit\n            ? [`%YAML ${this.yaml.version || '1.2'}`]\n            : [];\n        const tagEntries = Object.entries(this.tags);\n        let tagNames;\n        if (doc && tagEntries.length > 0 && isNode$1(doc.contents)) {\n            const tags = {};\n            visit$1(doc.contents, (_key, node) => {\n                if (isNode$1(node) && node.tag)\n                    tags[node.tag] = true;\n            });\n            tagNames = Object.keys(tags);\n        }\n        else\n            tagNames = [];\n        for (const [handle, prefix] of tagEntries) {\n            if (handle === '!!' && prefix === 'tag:yaml.org,2002:')\n                continue;\n            if (!doc || tagNames.some(tn => tn.startsWith(prefix)))\n                lines.push(`%TAG ${handle} ${prefix}`);\n        }\n        return lines.join('\\n');\n    }\n}\nDirectives.defaultYaml = { explicit: false, version: '1.2' };\nDirectives.defaultTags = { '!!': 'tag:yaml.org,2002:' };\n\n/**\n * Verify that the input string is a valid anchor.\n *\n * Will throw on errors.\n */\nfunction anchorIsValid(anchor) {\n    if (/[\\x00-\\x19\\s,[\\]{}]/.test(anchor)) {\n        const sa = JSON.stringify(anchor);\n        const msg = `Anchor must not contain whitespace or control characters: ${sa}`;\n        throw new Error(msg);\n    }\n    return true;\n}\nfunction anchorNames(root) {\n    const anchors = new Set();\n    visit$1(root, {\n        Value(_key, node) {\n            if (node.anchor)\n                anchors.add(node.anchor);\n        }\n    });\n    return anchors;\n}\n/** Find a new anchor name with the given `prefix` and a one-indexed suffix. */\nfunction findNewAnchor(prefix, exclude) {\n    for (let i = 1; true; ++i) {\n        const name = `${prefix}${i}`;\n        if (!exclude.has(name))\n            return name;\n    }\n}\nfunction createNodeAnchors(doc, prefix) {\n    const aliasObjects = [];\n    const sourceObjects = new Map();\n    let prevAnchors = null;\n    return {\n        onAnchor: (source) => {\n            aliasObjects.push(source);\n            if (!prevAnchors)\n                prevAnchors = anchorNames(doc);\n            const anchor = findNewAnchor(prefix, prevAnchors);\n            prevAnchors.add(anchor);\n            return anchor;\n        },\n        /**\n         * With circular references, the source node is only resolved after all\n         * of its child nodes are. This is why anchors are set only after all of\n         * the nodes have been created.\n         */\n        setAnchors: () => {\n            for (const source of aliasObjects) {\n                const ref = sourceObjects.get(source);\n                if (typeof ref === 'object' &&\n                    ref.anchor &&\n                    (isScalar$1(ref.node) || isCollection$1(ref.node))) {\n                    ref.node.anchor = ref.anchor;\n                }\n                else {\n                    const error = new Error('Failed to resolve repeated object (this should not happen)');\n                    error.source = source;\n                    throw error;\n                }\n            }\n        },\n        sourceObjects\n    };\n}\n\nclass Alias extends NodeBase {\n    constructor(source) {\n        super(ALIAS);\n        this.source = source;\n        Object.defineProperty(this, 'tag', {\n            set() {\n                throw new Error('Alias nodes cannot have tags');\n            }\n        });\n    }\n    /**\n     * Resolve the value of this alias within `doc`, finding the last\n     * instance of the `source` anchor before this node.\n     */\n    resolve(doc) {\n        let found = undefined;\n        visit$1(doc, {\n            Node: (_key, node) => {\n                if (node === this)\n                    return visit$1.BREAK;\n                if (node.anchor === this.source)\n                    found = node;\n            }\n        });\n        return found;\n    }\n    toJSON(_arg, ctx) {\n        if (!ctx)\n            return { source: this.source };\n        const { anchors, doc, maxAliasCount } = ctx;\n        const source = this.resolve(doc);\n        if (!source) {\n            const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;\n            throw new ReferenceError(msg);\n        }\n        const data = anchors.get(source);\n        /* istanbul ignore if */\n        if (!data || data.res === undefined) {\n            const msg = 'This should not happen: Alias anchor was not resolved?';\n            throw new ReferenceError(msg);\n        }\n        if (maxAliasCount >= 0) {\n            data.count += 1;\n            if (data.aliasCount === 0)\n                data.aliasCount = getAliasCount(doc, source, anchors);\n            if (data.count * data.aliasCount > maxAliasCount) {\n                const msg = 'Excessive alias count indicates a resource exhaustion attack';\n                throw new ReferenceError(msg);\n            }\n        }\n        return data.res;\n    }\n    toString(ctx, _onComment, _onChompKeep) {\n        const src = `*${this.source}`;\n        if (ctx) {\n            anchorIsValid(this.source);\n            if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {\n                const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;\n                throw new Error(msg);\n            }\n            if (ctx.implicitKey)\n                return `${src} `;\n        }\n        return src;\n    }\n}\nfunction getAliasCount(doc, node, anchors) {\n    if (isAlias(node)) {\n        const source = node.resolve(doc);\n        const anchor = anchors && source && anchors.get(source);\n        return anchor ? anchor.count * anchor.aliasCount : 0;\n    }\n    else if (isCollection$1(node)) {\n        let count = 0;\n        for (const item of node.items) {\n            const c = getAliasCount(doc, item, anchors);\n            if (c > count)\n                count = c;\n        }\n        return count;\n    }\n    else if (isPair(node)) {\n        const kc = getAliasCount(doc, node.key, anchors);\n        const vc = getAliasCount(doc, node.value, anchors);\n        return Math.max(kc, vc);\n    }\n    return 1;\n}\n\n/**\n * Recursively convert any node or its contents to native JavaScript\n *\n * @param value - The input value\n * @param arg - If `value` defines a `toJSON()` method, use this\n *   as its first argument\n * @param ctx - Conversion context, originally set in Document#toJS(). If\n *   `{ keep: true }` is not set, output should be suitable for JSON\n *   stringification.\n */\nfunction toJS(value, arg, ctx) {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n    if (Array.isArray(value))\n        return value.map((v, i) => toJS(v, String(i), ctx));\n    if (value && typeof value.toJSON === 'function') {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n        if (!ctx || !hasAnchor(value))\n            return value.toJSON(arg, ctx);\n        const data = { aliasCount: 0, count: 1, res: undefined };\n        ctx.anchors.set(value, data);\n        ctx.onCreate = res => {\n            data.res = res;\n            delete ctx.onCreate;\n        };\n        const res = value.toJSON(arg, ctx);\n        if (ctx.onCreate)\n            ctx.onCreate(res);\n        return res;\n    }\n    if (typeof value === 'bigint' && !ctx?.keep)\n        return Number(value);\n    return value;\n}\n\nconst isScalarValue = (value) => !value || (typeof value !== 'function' && typeof value !== 'object');\nclass Scalar extends NodeBase {\n    constructor(value) {\n        super(SCALAR$1);\n        this.value = value;\n    }\n    toJSON(arg, ctx) {\n        return ctx?.keep ? this.value : toJS(this.value, arg, ctx);\n    }\n    toString() {\n        return String(this.value);\n    }\n}\nScalar.BLOCK_FOLDED = 'BLOCK_FOLDED';\nScalar.BLOCK_LITERAL = 'BLOCK_LITERAL';\nScalar.PLAIN = 'PLAIN';\nScalar.QUOTE_DOUBLE = 'QUOTE_DOUBLE';\nScalar.QUOTE_SINGLE = 'QUOTE_SINGLE';\n\nconst defaultTagPrefix = 'tag:yaml.org,2002:';\nfunction findTagObject(value, tagName, tags) {\n    if (tagName) {\n        const match = tags.filter(t => t.tag === tagName);\n        const tagObj = match.find(t => !t.format) ?? match[0];\n        if (!tagObj)\n            throw new Error(`Tag ${tagName} not found`);\n        return tagObj;\n    }\n    return tags.find(t => t.identify?.(value) && !t.format);\n}\nfunction createNode(value, tagName, ctx) {\n    if (isDocument(value))\n        value = value.contents;\n    if (isNode$1(value))\n        return value;\n    if (isPair(value)) {\n        const map = ctx.schema[MAP].createNode?.(ctx.schema, null, ctx);\n        map.items.push(value);\n        return map;\n    }\n    if (value instanceof String ||\n        value instanceof Number ||\n        value instanceof Boolean ||\n        (typeof BigInt === 'function' && value instanceof BigInt) // not supported everywhere\n    ) {\n        // https://tc39.es/ecma262/#sec-serializejsonproperty\n        value = value.valueOf();\n    }\n    const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } = ctx;\n    // Detect duplicate references to the same object & use Alias nodes for all\n    // after first. The `ref` wrapper allows for circular references to resolve.\n    let ref = undefined;\n    if (aliasDuplicateObjects && value && typeof value === 'object') {\n        ref = sourceObjects.get(value);\n        if (ref) {\n            if (!ref.anchor)\n                ref.anchor = onAnchor(value);\n            return new Alias(ref.anchor);\n        }\n        else {\n            ref = { anchor: null, node: null };\n            sourceObjects.set(value, ref);\n        }\n    }\n    if (tagName?.startsWith('!!'))\n        tagName = defaultTagPrefix + tagName.slice(2);\n    let tagObj = findTagObject(value, tagName, schema.tags);\n    if (!tagObj) {\n        if (value && typeof value.toJSON === 'function') {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n            value = value.toJSON();\n        }\n        if (!value || typeof value !== 'object') {\n            const node = new Scalar(value);\n            if (ref)\n                ref.node = node;\n            return node;\n        }\n        tagObj =\n            value instanceof Map\n                ? schema[MAP]\n                : Symbol.iterator in Object(value)\n                    ? schema[SEQ]\n                    : schema[MAP];\n    }\n    if (onTagObj) {\n        onTagObj(tagObj);\n        delete ctx.onTagObj;\n    }\n    const node = tagObj?.createNode\n        ? tagObj.createNode(ctx.schema, value, ctx)\n        : new Scalar(value);\n    if (tagName)\n        node.tag = tagName;\n    if (ref)\n        ref.node = node;\n    return node;\n}\n\nfunction collectionFromPath(schema, path, value) {\n    let v = value;\n    for (let i = path.length - 1; i >= 0; --i) {\n        const k = path[i];\n        if (typeof k === 'number' && Number.isInteger(k) && k >= 0) {\n            const a = [];\n            a[k] = v;\n            v = a;\n        }\n        else {\n            v = new Map([[k, v]]);\n        }\n    }\n    return createNode(v, undefined, {\n        aliasDuplicateObjects: false,\n        keepUndefined: false,\n        onAnchor: () => {\n            throw new Error('This should not happen, please report a bug.');\n        },\n        schema,\n        sourceObjects: new Map()\n    });\n}\n// Type guard is intentionally a little wrong so as to be more useful,\n// as it does not cover untypable empty non-string iterables (e.g. []).\nconst isEmptyPath = (path) => path == null ||\n    (typeof path === 'object' && !!path[Symbol.iterator]().next().done);\nclass Collection extends NodeBase {\n    constructor(type, schema) {\n        super(type);\n        Object.defineProperty(this, 'schema', {\n            value: schema,\n            configurable: true,\n            enumerable: false,\n            writable: true\n        });\n    }\n    /**\n     * Create a copy of this collection.\n     *\n     * @param schema - If defined, overwrites the original's schema\n     */\n    clone(schema) {\n        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));\n        if (schema)\n            copy.schema = schema;\n        copy.items = copy.items.map(it => isNode$1(it) || isPair(it) ? it.clone(schema) : it);\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /**\n     * Adds a value to the collection. For `!!map` and `!!omap` the value must\n     * be a Pair instance or a `{ key, value }` object, which may not have a key\n     * that already exists in the map.\n     */\n    addIn(path, value) {\n        if (isEmptyPath(path))\n            this.add(value);\n        else {\n            const [key, ...rest] = path;\n            const node = this.get(key, true);\n            if (isCollection$1(node))\n                node.addIn(rest, value);\n            else if (node === undefined && this.schema)\n                this.set(key, collectionFromPath(this.schema, rest, value));\n            else\n                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n        }\n    }\n    /**\n     * Removes a value from the collection.\n     * @returns `true` if the item was found and removed.\n     */\n    deleteIn(path) {\n        const [key, ...rest] = path;\n        if (rest.length === 0)\n            return this.delete(key);\n        const node = this.get(key, true);\n        if (isCollection$1(node))\n            return node.deleteIn(rest);\n        else\n            throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n    }\n    /**\n     * Returns item at `key`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    getIn(path, keepScalar) {\n        const [key, ...rest] = path;\n        const node = this.get(key, true);\n        if (rest.length === 0)\n            return !keepScalar && isScalar$1(node) ? node.value : node;\n        else\n            return isCollection$1(node) ? node.getIn(rest, keepScalar) : undefined;\n    }\n    hasAllNullValues(allowScalar) {\n        return this.items.every(node => {\n            if (!isPair(node))\n                return false;\n            const n = node.value;\n            return (n == null ||\n                (allowScalar &&\n                    isScalar$1(n) &&\n                    n.value == null &&\n                    !n.commentBefore &&\n                    !n.comment &&\n                    !n.tag));\n        });\n    }\n    /**\n     * Checks if the collection includes a value with the key `key`.\n     */\n    hasIn(path) {\n        const [key, ...rest] = path;\n        if (rest.length === 0)\n            return this.has(key);\n        const node = this.get(key, true);\n        return isCollection$1(node) ? node.hasIn(rest) : false;\n    }\n    /**\n     * Sets a value in this collection. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    setIn(path, value) {\n        const [key, ...rest] = path;\n        if (rest.length === 0) {\n            this.set(key, value);\n        }\n        else {\n            const node = this.get(key, true);\n            if (isCollection$1(node))\n                node.setIn(rest, value);\n            else if (node === undefined && this.schema)\n                this.set(key, collectionFromPath(this.schema, rest, value));\n            else\n                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n        }\n    }\n}\nCollection.maxFlowStringSingleLineLength = 60;\n\n/**\n * Stringifies a comment.\n *\n * Empty comment lines are left empty,\n * lines consisting of a single space are replaced by `#`,\n * and all other lines are prefixed with a `#`.\n */\nconst stringifyComment = (str) => str.replace(/^(?!$)(?: $)?/gm, '#');\nfunction indentComment(comment, indent) {\n    if (/^\\n+$/.test(comment))\n        return comment.substring(1);\n    return indent ? comment.replace(/^(?! *$)/gm, indent) : comment;\n}\nconst lineComment = (str, indent, comment) => str.endsWith('\\n')\n    ? indentComment(comment, indent)\n    : comment.includes('\\n')\n        ? '\\n' + indentComment(comment, indent)\n        : (str.endsWith(' ') ? '' : ' ') + comment;\n\nconst FOLD_FLOW = 'flow';\nconst FOLD_BLOCK = 'block';\nconst FOLD_QUOTED = 'quoted';\n/**\n * Tries to keep input at up to `lineWidth` characters, splitting only on spaces\n * not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are\n * terminated with `\\n` and started with `indent`.\n */\nfunction foldFlowLines(text, indent, mode = 'flow', { indentAtStart, lineWidth = 80, minContentWidth = 20, onFold, onOverflow } = {}) {\n    if (!lineWidth || lineWidth < 0)\n        return text;\n    const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);\n    if (text.length <= endStep)\n        return text;\n    const folds = [];\n    const escapedFolds = {};\n    let end = lineWidth - indent.length;\n    if (typeof indentAtStart === 'number') {\n        if (indentAtStart > lineWidth - Math.max(2, minContentWidth))\n            folds.push(0);\n        else\n            end = lineWidth - indentAtStart;\n    }\n    let split = undefined;\n    let prev = undefined;\n    let overflow = false;\n    let i = -1;\n    let escStart = -1;\n    let escEnd = -1;\n    if (mode === FOLD_BLOCK) {\n        i = consumeMoreIndentedLines(text, i);\n        if (i !== -1)\n            end = i + endStep;\n    }\n    for (let ch; (ch = text[(i += 1)]);) {\n        if (mode === FOLD_QUOTED && ch === '\\\\') {\n            escStart = i;\n            switch (text[i + 1]) {\n                case 'x':\n                    i += 3;\n                    break;\n                case 'u':\n                    i += 5;\n                    break;\n                case 'U':\n                    i += 9;\n                    break;\n                default:\n                    i += 1;\n            }\n            escEnd = i;\n        }\n        if (ch === '\\n') {\n            if (mode === FOLD_BLOCK)\n                i = consumeMoreIndentedLines(text, i);\n            end = i + endStep;\n            split = undefined;\n        }\n        else {\n            if (ch === ' ' &&\n                prev &&\n                prev !== ' ' &&\n                prev !== '\\n' &&\n                prev !== '\\t') {\n                // space surrounded by non-space can be replaced with newline + indent\n                const next = text[i + 1];\n                if (next && next !== ' ' && next !== '\\n' && next !== '\\t')\n                    split = i;\n            }\n            if (i >= end) {\n                if (split) {\n                    folds.push(split);\n                    end = split + endStep;\n                    split = undefined;\n                }\n                else if (mode === FOLD_QUOTED) {\n                    // white-space collected at end may stretch past lineWidth\n                    while (prev === ' ' || prev === '\\t') {\n                        prev = ch;\n                        ch = text[(i += 1)];\n                        overflow = true;\n                    }\n                    // Account for newline escape, but don't break preceding escape\n                    const j = i > escEnd + 1 ? i - 2 : escStart - 1;\n                    // Bail out if lineWidth & minContentWidth are shorter than an escape string\n                    if (escapedFolds[j])\n                        return text;\n                    folds.push(j);\n                    escapedFolds[j] = true;\n                    end = j + endStep;\n                    split = undefined;\n                }\n                else {\n                    overflow = true;\n                }\n            }\n        }\n        prev = ch;\n    }\n    if (overflow && onOverflow)\n        onOverflow();\n    if (folds.length === 0)\n        return text;\n    if (onFold)\n        onFold();\n    let res = text.slice(0, folds[0]);\n    for (let i = 0; i < folds.length; ++i) {\n        const fold = folds[i];\n        const end = folds[i + 1] || text.length;\n        if (fold === 0)\n            res = `\\n${indent}${text.slice(0, end)}`;\n        else {\n            if (mode === FOLD_QUOTED && escapedFolds[fold])\n                res += `${text[fold]}\\\\`;\n            res += `\\n${indent}${text.slice(fold + 1, end)}`;\n        }\n    }\n    return res;\n}\n/**\n * Presumes `i + 1` is at the start of a line\n * @returns index of last newline in more-indented block\n */\nfunction consumeMoreIndentedLines(text, i) {\n    let ch = text[i + 1];\n    while (ch === ' ' || ch === '\\t') {\n        do {\n            ch = text[(i += 1)];\n        } while (ch && ch !== '\\n');\n        ch = text[i + 1];\n    }\n    return i;\n}\n\nconst getFoldOptions = (ctx) => ({\n    indentAtStart: ctx.indentAtStart,\n    lineWidth: ctx.options.lineWidth,\n    minContentWidth: ctx.options.minContentWidth\n});\n// Also checks for lines starting with %, as parsing the output as YAML 1.1 will\n// presume that's starting a new document.\nconst containsDocumentMarker = (str) => /^(%|---|\\.\\.\\.)/m.test(str);\nfunction lineLengthOverLimit(str, lineWidth, indentLength) {\n    if (!lineWidth || lineWidth < 0)\n        return false;\n    const limit = lineWidth - indentLength;\n    const strLen = str.length;\n    if (strLen <= limit)\n        return false;\n    for (let i = 0, start = 0; i < strLen; ++i) {\n        if (str[i] === '\\n') {\n            if (i - start > limit)\n                return true;\n            start = i + 1;\n            if (strLen - start <= limit)\n                return false;\n        }\n    }\n    return true;\n}\nfunction doubleQuotedString(value, ctx) {\n    const json = JSON.stringify(value);\n    if (ctx.options.doubleQuotedAsJSON)\n        return json;\n    const { implicitKey } = ctx;\n    const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength;\n    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n    let str = '';\n    let start = 0;\n    for (let i = 0, ch = json[i]; ch; ch = json[++i]) {\n        if (ch === ' ' && json[i + 1] === '\\\\' && json[i + 2] === 'n') {\n            // space before newline needs to be escaped to not be folded\n            str += json.slice(start, i) + '\\\\ ';\n            i += 1;\n            start = i;\n            ch = '\\\\';\n        }\n        if (ch === '\\\\')\n            switch (json[i + 1]) {\n                case 'u':\n                    {\n                        str += json.slice(start, i);\n                        const code = json.substr(i + 2, 4);\n                        switch (code) {\n                            case '0000':\n                                str += '\\\\0';\n                                break;\n                            case '0007':\n                                str += '\\\\a';\n                                break;\n                            case '000b':\n                                str += '\\\\v';\n                                break;\n                            case '001b':\n                                str += '\\\\e';\n                                break;\n                            case '0085':\n                                str += '\\\\N';\n                                break;\n                            case '00a0':\n                                str += '\\\\_';\n                                break;\n                            case '2028':\n                                str += '\\\\L';\n                                break;\n                            case '2029':\n                                str += '\\\\P';\n                                break;\n                            default:\n                                if (code.substr(0, 2) === '00')\n                                    str += '\\\\x' + code.substr(2);\n                                else\n                                    str += json.substr(i, 6);\n                        }\n                        i += 5;\n                        start = i + 1;\n                    }\n                    break;\n                case 'n':\n                    if (implicitKey ||\n                        json[i + 2] === '\"' ||\n                        json.length < minMultiLineLength) {\n                        i += 1;\n                    }\n                    else {\n                        // folding will eat first newline\n                        str += json.slice(start, i) + '\\n\\n';\n                        while (json[i + 2] === '\\\\' &&\n                            json[i + 3] === 'n' &&\n                            json[i + 4] !== '\"') {\n                            str += '\\n';\n                            i += 2;\n                        }\n                        str += indent;\n                        // space after newline needs to be escaped to not be folded\n                        if (json[i + 2] === ' ')\n                            str += '\\\\';\n                        i += 1;\n                        start = i + 1;\n                    }\n                    break;\n                default:\n                    i += 1;\n            }\n    }\n    str = start ? str + json.slice(start) : json;\n    return implicitKey\n        ? str\n        : foldFlowLines(str, indent, FOLD_QUOTED, getFoldOptions(ctx));\n}\nfunction singleQuotedString(value, ctx) {\n    if (ctx.options.singleQuote === false ||\n        (ctx.implicitKey && value.includes('\\n')) ||\n        /[ \\t]\\n|\\n[ \\t]/.test(value) // single quoted string can't have leading or trailing whitespace around newline\n    )\n        return doubleQuotedString(value, ctx);\n    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n    const res = \"'\" + value.replace(/'/g, \"''\").replace(/\\n+/g, `$&\\n${indent}`) + \"'\";\n    return ctx.implicitKey\n        ? res\n        : foldFlowLines(res, indent, FOLD_FLOW, getFoldOptions(ctx));\n}\nfunction quotedString(value, ctx) {\n    const { singleQuote } = ctx.options;\n    let qs;\n    if (singleQuote === false)\n        qs = doubleQuotedString;\n    else {\n        const hasDouble = value.includes('\"');\n        const hasSingle = value.includes(\"'\");\n        if (hasDouble && !hasSingle)\n            qs = singleQuotedString;\n        else if (hasSingle && !hasDouble)\n            qs = doubleQuotedString;\n        else\n            qs = singleQuote ? singleQuotedString : doubleQuotedString;\n    }\n    return qs(value, ctx);\n}\nfunction blockString({ comment, type, value }, ctx, onComment, onChompKeep) {\n    const { blockQuote, commentString, lineWidth } = ctx.options;\n    // 1. Block can't end in whitespace unless the last line is non-empty.\n    // 2. Strings consisting of only whitespace are best rendered explicitly.\n    if (!blockQuote || /\\n[\\t ]+$/.test(value) || /^\\s*$/.test(value)) {\n        return quotedString(value, ctx);\n    }\n    const indent = ctx.indent ||\n        (ctx.forceBlockIndent || containsDocumentMarker(value) ? '  ' : '');\n    const literal = blockQuote === 'literal'\n        ? true\n        : blockQuote === 'folded' || type === Scalar.BLOCK_FOLDED\n            ? false\n            : type === Scalar.BLOCK_LITERAL\n                ? true\n                : !lineLengthOverLimit(value, lineWidth, indent.length);\n    if (!value)\n        return literal ? '|\\n' : '>\\n';\n    // determine chomping from whitespace at value end\n    let chomp;\n    let endStart;\n    for (endStart = value.length; endStart > 0; --endStart) {\n        const ch = value[endStart - 1];\n        if (ch !== '\\n' && ch !== '\\t' && ch !== ' ')\n            break;\n    }\n    let end = value.substring(endStart);\n    const endNlPos = end.indexOf('\\n');\n    if (endNlPos === -1) {\n        chomp = '-'; // strip\n    }\n    else if (value === end || endNlPos !== end.length - 1) {\n        chomp = '+'; // keep\n        if (onChompKeep)\n            onChompKeep();\n    }\n    else {\n        chomp = ''; // clip\n    }\n    if (end) {\n        value = value.slice(0, -end.length);\n        if (end[end.length - 1] === '\\n')\n            end = end.slice(0, -1);\n        end = end.replace(/\\n+(?!\\n|$)/g, `$&${indent}`);\n    }\n    // determine indent indicator from whitespace at value start\n    let startWithSpace = false;\n    let startEnd;\n    let startNlPos = -1;\n    for (startEnd = 0; startEnd < value.length; ++startEnd) {\n        const ch = value[startEnd];\n        if (ch === ' ')\n            startWithSpace = true;\n        else if (ch === '\\n')\n            startNlPos = startEnd;\n        else\n            break;\n    }\n    let start = value.substring(0, startNlPos < startEnd ? startNlPos + 1 : startEnd);\n    if (start) {\n        value = value.substring(start.length);\n        start = start.replace(/\\n+/g, `$&${indent}`);\n    }\n    const indentSize = indent ? '2' : '1'; // root is at -1\n    let header = (literal ? '|' : '>') + (startWithSpace ? indentSize : '') + chomp;\n    if (comment) {\n        header += ' ' + commentString(comment.replace(/ ?[\\r\\n]+/g, ' '));\n        if (onComment)\n            onComment();\n    }\n    if (literal) {\n        value = value.replace(/\\n+/g, `$&${indent}`);\n        return `${header}\\n${indent}${start}${value}${end}`;\n    }\n    value = value\n        .replace(/\\n+/g, '\\n$&')\n        .replace(/(?:^|\\n)([\\t ].*)(?:([\\n\\t ]*)\\n(?![\\n\\t ]))?/g, '$1$2') // more-indented lines aren't folded\n        //                ^ more-ind. ^ empty     ^ capture next empty lines only at end of indent\n        .replace(/\\n+/g, `$&${indent}`);\n    const body = foldFlowLines(`${start}${value}${end}`, indent, FOLD_BLOCK, getFoldOptions(ctx));\n    return `${header}\\n${indent}${body}`;\n}\nfunction plainString(item, ctx, onComment, onChompKeep) {\n    const { type, value } = item;\n    const { actualString, implicitKey, indent, inFlow } = ctx;\n    if ((implicitKey && /[\\n[\\]{},]/.test(value)) ||\n        (inFlow && /[[\\]{},]/.test(value))) {\n        return quotedString(value, ctx);\n    }\n    if (!value ||\n        /^[\\n\\t ,[\\]{}#&*!|>'\"%@`]|^[?-]$|^[?-][ \\t]|[\\n:][ \\t]|[ \\t]\\n|[\\n\\t ]#|[\\n\\t :]$/.test(value)) {\n        // not allowed:\n        // - empty string, '-' or '?'\n        // - start with an indicator character (except [?:-]) or /[?-] /\n        // - '\\n ', ': ' or ' \\n' anywhere\n        // - '#' not preceded by a non-space char\n        // - end with ' ' or ':'\n        return implicitKey || inFlow || !value.includes('\\n')\n            ? quotedString(value, ctx)\n            : blockString(item, ctx, onComment, onChompKeep);\n    }\n    if (!implicitKey &&\n        !inFlow &&\n        type !== Scalar.PLAIN &&\n        value.includes('\\n')) {\n        // Where allowed & type not set explicitly, prefer block style for multiline strings\n        return blockString(item, ctx, onComment, onChompKeep);\n    }\n    if (indent === '' && containsDocumentMarker(value)) {\n        ctx.forceBlockIndent = true;\n        return blockString(item, ctx, onComment, onChompKeep);\n    }\n    const str = value.replace(/\\n+/g, `$&\\n${indent}`);\n    // Verify that output will be parsed as a string, as e.g. plain numbers and\n    // booleans get parsed with those types in v1.2 (e.g. '42', 'true' & '0.9e-3'),\n    // and others in v1.1.\n    if (actualString) {\n        const test = (tag) => tag.default && tag.tag !== 'tag:yaml.org,2002:str' && tag.test?.test(str);\n        const { compat, tags } = ctx.doc.schema;\n        if (tags.some(test) || compat?.some(test))\n            return quotedString(value, ctx);\n    }\n    return implicitKey\n        ? str\n        : foldFlowLines(str, indent, FOLD_FLOW, getFoldOptions(ctx));\n}\nfunction stringifyString(item, ctx, onComment, onChompKeep) {\n    const { implicitKey, inFlow } = ctx;\n    const ss = typeof item.value === 'string'\n        ? item\n        : Object.assign({}, item, { value: String(item.value) });\n    let { type } = item;\n    if (type !== Scalar.QUOTE_DOUBLE) {\n        // force double quotes on control characters & unpaired surrogates\n        if (/[\\x00-\\x08\\x0b-\\x1f\\x7f-\\x9f\\u{D800}-\\u{DFFF}]/u.test(ss.value))\n            type = Scalar.QUOTE_DOUBLE;\n    }\n    const _stringify = (_type) => {\n        switch (_type) {\n            case Scalar.BLOCK_FOLDED:\n            case Scalar.BLOCK_LITERAL:\n                return implicitKey || inFlow\n                    ? quotedString(ss.value, ctx) // blocks are not valid inside flow containers\n                    : blockString(ss, ctx, onComment, onChompKeep);\n            case Scalar.QUOTE_DOUBLE:\n                return doubleQuotedString(ss.value, ctx);\n            case Scalar.QUOTE_SINGLE:\n                return singleQuotedString(ss.value, ctx);\n            case Scalar.PLAIN:\n                return plainString(ss, ctx, onComment, onChompKeep);\n            default:\n                return null;\n        }\n    };\n    let res = _stringify(type);\n    if (res === null) {\n        const { defaultKeyType, defaultStringType } = ctx.options;\n        const t = (implicitKey && defaultKeyType) || defaultStringType;\n        res = _stringify(t);\n        if (res === null)\n            throw new Error(`Unsupported default string type ${t}`);\n    }\n    return res;\n}\n\nfunction createStringifyContext(doc, options) {\n    const opt = Object.assign({\n        blockQuote: true,\n        commentString: stringifyComment,\n        defaultKeyType: null,\n        defaultStringType: 'PLAIN',\n        directives: null,\n        doubleQuotedAsJSON: false,\n        doubleQuotedMinMultiLineLength: 40,\n        falseStr: 'false',\n        indentSeq: true,\n        lineWidth: 80,\n        minContentWidth: 20,\n        nullStr: 'null',\n        simpleKeys: false,\n        singleQuote: null,\n        trueStr: 'true',\n        verifyAliasOrder: true\n    }, doc.schema.toStringOptions, options);\n    let inFlow;\n    switch (opt.collectionStyle) {\n        case 'block':\n            inFlow = false;\n            break;\n        case 'flow':\n            inFlow = true;\n            break;\n        default:\n            inFlow = null;\n    }\n    return {\n        anchors: new Set(),\n        doc,\n        indent: '',\n        indentStep: typeof opt.indent === 'number' ? ' '.repeat(opt.indent) : '  ',\n        inFlow,\n        options: opt\n    };\n}\nfunction getTagObject(tags, item) {\n    if (item.tag) {\n        const match = tags.filter(t => t.tag === item.tag);\n        if (match.length > 0)\n            return match.find(t => t.format === item.format) ?? match[0];\n    }\n    let tagObj = undefined;\n    let obj;\n    if (isScalar$1(item)) {\n        obj = item.value;\n        const match = tags.filter(t => t.identify?.(obj));\n        tagObj =\n            match.find(t => t.format === item.format) ?? match.find(t => !t.format);\n    }\n    else {\n        obj = item;\n        tagObj = tags.find(t => t.nodeClass && obj instanceof t.nodeClass);\n    }\n    if (!tagObj) {\n        const name = obj?.constructor?.name ?? typeof obj;\n        throw new Error(`Tag not resolved for ${name} value`);\n    }\n    return tagObj;\n}\n// needs to be called before value stringifier to allow for circular anchor refs\nfunction stringifyProps(node, tagObj, { anchors, doc }) {\n    if (!doc.directives)\n        return '';\n    const props = [];\n    const anchor = (isScalar$1(node) || isCollection$1(node)) && node.anchor;\n    if (anchor && anchorIsValid(anchor)) {\n        anchors.add(anchor);\n        props.push(`&${anchor}`);\n    }\n    const tag = node.tag ? node.tag : tagObj.default ? null : tagObj.tag;\n    if (tag)\n        props.push(doc.directives.tagString(tag));\n    return props.join(' ');\n}\nfunction stringify$2(item, ctx, onComment, onChompKeep) {\n    if (isPair(item))\n        return item.toString(ctx, onComment, onChompKeep);\n    if (isAlias(item)) {\n        if (ctx.doc.directives)\n            return item.toString(ctx);\n        if (ctx.resolvedAliases?.has(item)) {\n            throw new TypeError(`Cannot stringify circular structure without alias nodes`);\n        }\n        else {\n            if (ctx.resolvedAliases)\n                ctx.resolvedAliases.add(item);\n            else\n                ctx.resolvedAliases = new Set([item]);\n            item = item.resolve(ctx.doc);\n        }\n    }\n    let tagObj = undefined;\n    const node = isNode$1(item)\n        ? item\n        : ctx.doc.createNode(item, { onTagObj: o => (tagObj = o) });\n    if (!tagObj)\n        tagObj = getTagObject(ctx.doc.schema.tags, node);\n    const props = stringifyProps(node, tagObj, ctx);\n    if (props.length > 0)\n        ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1;\n    const str = typeof tagObj.stringify === 'function'\n        ? tagObj.stringify(node, ctx, onComment, onChompKeep)\n        : isScalar$1(node)\n            ? stringifyString(node, ctx, onComment, onChompKeep)\n            : node.toString(ctx, onComment, onChompKeep);\n    if (!props)\n        return str;\n    return isScalar$1(node) || str[0] === '{' || str[0] === '['\n        ? `${props} ${str}`\n        : `${props}\\n${ctx.indent}${str}`;\n}\n\nfunction stringifyPair({ key, value }, ctx, onComment, onChompKeep) {\n    const { allNullValues, doc, indent, indentStep, options: { commentString, indentSeq, simpleKeys } } = ctx;\n    let keyComment = (isNode$1(key) && key.comment) || null;\n    if (simpleKeys) {\n        if (keyComment) {\n            throw new Error('With simple keys, key nodes cannot have comments');\n        }\n        if (isCollection$1(key)) {\n            const msg = 'With simple keys, collection cannot be used as a key value';\n            throw new Error(msg);\n        }\n    }\n    let explicitKey = !simpleKeys &&\n        (!key ||\n            (keyComment && value == null && !ctx.inFlow) ||\n            isCollection$1(key) ||\n            (isScalar$1(key)\n                ? key.type === Scalar.BLOCK_FOLDED || key.type === Scalar.BLOCK_LITERAL\n                : typeof key === 'object'));\n    ctx = Object.assign({}, ctx, {\n        allNullValues: false,\n        implicitKey: !explicitKey && (simpleKeys || !allNullValues),\n        indent: indent + indentStep\n    });\n    let keyCommentDone = false;\n    let chompKeep = false;\n    let str = stringify$2(key, ctx, () => (keyCommentDone = true), () => (chompKeep = true));\n    if (!explicitKey && !ctx.inFlow && str.length > 1024) {\n        if (simpleKeys)\n            throw new Error('With simple keys, single line scalar must not span more than 1024 characters');\n        explicitKey = true;\n    }\n    if (ctx.inFlow) {\n        if (allNullValues || value == null) {\n            if (keyCommentDone && onComment)\n                onComment();\n            return str === '' ? '?' : explicitKey ? `? ${str}` : str;\n        }\n    }\n    else if ((allNullValues && !simpleKeys) || (value == null && explicitKey)) {\n        str = `? ${str}`;\n        if (keyComment && !keyCommentDone) {\n            str += lineComment(str, ctx.indent, commentString(keyComment));\n        }\n        else if (chompKeep && onChompKeep)\n            onChompKeep();\n        return str;\n    }\n    if (keyCommentDone)\n        keyComment = null;\n    if (explicitKey) {\n        if (keyComment)\n            str += lineComment(str, ctx.indent, commentString(keyComment));\n        str = `? ${str}\\n${indent}:`;\n    }\n    else {\n        str = `${str}:`;\n        if (keyComment)\n            str += lineComment(str, ctx.indent, commentString(keyComment));\n    }\n    let vcb = '';\n    let valueComment = null;\n    if (isNode$1(value)) {\n        if (value.spaceBefore)\n            vcb = '\\n';\n        if (value.commentBefore) {\n            const cs = commentString(value.commentBefore);\n            vcb += `\\n${indentComment(cs, ctx.indent)}`;\n        }\n        valueComment = value.comment;\n    }\n    else if (value && typeof value === 'object') {\n        value = doc.createNode(value);\n    }\n    ctx.implicitKey = false;\n    if (!explicitKey && !keyComment && isScalar$1(value))\n        ctx.indentAtStart = str.length + 1;\n    chompKeep = false;\n    if (!indentSeq &&\n        indentStep.length >= 2 &&\n        !ctx.inFlow &&\n        !explicitKey &&\n        isSeq(value) &&\n        !value.flow &&\n        !value.tag &&\n        !value.anchor) {\n        // If indentSeq === false, consider '- ' as part of indentation where possible\n        ctx.indent = ctx.indent.substr(2);\n    }\n    let valueCommentDone = false;\n    const valueStr = stringify$2(value, ctx, () => (valueCommentDone = true), () => (chompKeep = true));\n    let ws = ' ';\n    if (vcb || keyComment) {\n        if (valueStr === '' && !ctx.inFlow)\n            ws = vcb === '\\n' ? '\\n\\n' : vcb;\n        else\n            ws = `${vcb}\\n${ctx.indent}`;\n    }\n    else if (!explicitKey && isCollection$1(value)) {\n        const flow = valueStr[0] === '[' || valueStr[0] === '{';\n        if (!flow || valueStr.includes('\\n'))\n            ws = `\\n${ctx.indent}`;\n    }\n    else if (valueStr === '' || valueStr[0] === '\\n')\n        ws = '';\n    str += ws + valueStr;\n    if (ctx.inFlow) {\n        if (valueCommentDone && onComment)\n            onComment();\n    }\n    else if (valueComment && !valueCommentDone) {\n        str += lineComment(str, ctx.indent, commentString(valueComment));\n    }\n    else if (chompKeep && onChompKeep) {\n        onChompKeep();\n    }\n    return str;\n}\n\nfunction warn(logLevel, warning) {\n    if (logLevel === 'debug' || logLevel === 'warn') {\n        if (typeof process !== 'undefined' && process.emitWarning)\n            process.emitWarning(warning);\n        else\n            console.warn(warning);\n    }\n}\n\nconst MERGE_KEY = '<<';\nfunction addPairToJSMap(ctx, map, { key, value }) {\n    if (ctx?.doc.schema.merge && isMergeKey(key)) {\n        value = isAlias(value) ? value.resolve(ctx.doc) : value;\n        if (isSeq(value))\n            for (const it of value.items)\n                mergeToJSMap(ctx, map, it);\n        else if (Array.isArray(value))\n            for (const it of value)\n                mergeToJSMap(ctx, map, it);\n        else\n            mergeToJSMap(ctx, map, value);\n    }\n    else {\n        const jsKey = toJS(key, '', ctx);\n        if (map instanceof Map) {\n            map.set(jsKey, toJS(value, jsKey, ctx));\n        }\n        else if (map instanceof Set) {\n            map.add(jsKey);\n        }\n        else {\n            const stringKey = stringifyKey(key, jsKey, ctx);\n            const jsValue = toJS(value, stringKey, ctx);\n            if (stringKey in map)\n                Object.defineProperty(map, stringKey, {\n                    value: jsValue,\n                    writable: true,\n                    enumerable: true,\n                    configurable: true\n                });\n            else\n                map[stringKey] = jsValue;\n        }\n    }\n    return map;\n}\nconst isMergeKey = (key) => key === MERGE_KEY ||\n    (isScalar$1(key) &&\n        key.value === MERGE_KEY &&\n        (!key.type || key.type === Scalar.PLAIN));\n// If the value associated with a merge key is a single mapping node, each of\n// its key/value pairs is inserted into the current mapping, unless the key\n// already exists in it. If the value associated with the merge key is a\n// sequence, then this sequence is expected to contain mapping nodes and each\n// of these nodes is merged in turn according to its order in the sequence.\n// Keys in mapping nodes earlier in the sequence override keys specified in\n// later mapping nodes. -- http://yaml.org/type/merge.html\nfunction mergeToJSMap(ctx, map, value) {\n    const source = ctx && isAlias(value) ? value.resolve(ctx.doc) : value;\n    if (!isMap(source))\n        throw new Error('Merge sources must be maps or map aliases');\n    const srcMap = source.toJSON(null, ctx, Map);\n    for (const [key, value] of srcMap) {\n        if (map instanceof Map) {\n            if (!map.has(key))\n                map.set(key, value);\n        }\n        else if (map instanceof Set) {\n            map.add(key);\n        }\n        else if (!Object.prototype.hasOwnProperty.call(map, key)) {\n            Object.defineProperty(map, key, {\n                value,\n                writable: true,\n                enumerable: true,\n                configurable: true\n            });\n        }\n    }\n    return map;\n}\nfunction stringifyKey(key, jsKey, ctx) {\n    if (jsKey === null)\n        return '';\n    if (typeof jsKey !== 'object')\n        return String(jsKey);\n    if (isNode$1(key) && ctx && ctx.doc) {\n        const strCtx = createStringifyContext(ctx.doc, {});\n        strCtx.anchors = new Set();\n        for (const node of ctx.anchors.keys())\n            strCtx.anchors.add(node.anchor);\n        strCtx.inFlow = true;\n        strCtx.inStringifyKey = true;\n        const strKey = key.toString(strCtx);\n        if (!ctx.mapKeyWarned) {\n            let jsonStr = JSON.stringify(strKey);\n            if (jsonStr.length > 40)\n                jsonStr = jsonStr.substring(0, 36) + '...\"';\n            warn(ctx.doc.options.logLevel, `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`);\n            ctx.mapKeyWarned = true;\n        }\n        return strKey;\n    }\n    return JSON.stringify(jsKey);\n}\n\nfunction createPair(key, value, ctx) {\n    const k = createNode(key, undefined, ctx);\n    const v = createNode(value, undefined, ctx);\n    return new Pair(k, v);\n}\nclass Pair {\n    constructor(key, value = null) {\n        Object.defineProperty(this, NODE_TYPE, { value: PAIR });\n        this.key = key;\n        this.value = value;\n    }\n    clone(schema) {\n        let { key, value } = this;\n        if (isNode$1(key))\n            key = key.clone(schema);\n        if (isNode$1(value))\n            value = value.clone(schema);\n        return new Pair(key, value);\n    }\n    toJSON(_, ctx) {\n        const pair = ctx?.mapAsMap ? new Map() : {};\n        return addPairToJSMap(ctx, pair, this);\n    }\n    toString(ctx, onComment, onChompKeep) {\n        return ctx?.doc\n            ? stringifyPair(this, ctx, onComment, onChompKeep)\n            : JSON.stringify(this);\n    }\n}\n\nfunction stringifyCollection(collection, ctx, options) {\n    const flow = ctx.inFlow ?? collection.flow;\n    const stringify = flow ? stringifyFlowCollection : stringifyBlockCollection;\n    return stringify(collection, ctx, options);\n}\nfunction stringifyBlockCollection({ comment, items }, ctx, { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }) {\n    const { indent, options: { commentString } } = ctx;\n    const itemCtx = Object.assign({}, ctx, { indent: itemIndent, type: null });\n    let chompKeep = false; // flag for the preceding node's status\n    const lines = [];\n    for (let i = 0; i < items.length; ++i) {\n        const item = items[i];\n        let comment = null;\n        if (isNode$1(item)) {\n            if (!chompKeep && item.spaceBefore)\n                lines.push('');\n            addCommentBefore(ctx, lines, item.commentBefore, chompKeep);\n            if (item.comment)\n                comment = item.comment;\n        }\n        else if (isPair(item)) {\n            const ik = isNode$1(item.key) ? item.key : null;\n            if (ik) {\n                if (!chompKeep && ik.spaceBefore)\n                    lines.push('');\n                addCommentBefore(ctx, lines, ik.commentBefore, chompKeep);\n            }\n        }\n        chompKeep = false;\n        let str = stringify$2(item, itemCtx, () => (comment = null), () => (chompKeep = true));\n        if (comment)\n            str += lineComment(str, itemIndent, commentString(comment));\n        if (chompKeep && comment)\n            chompKeep = false;\n        lines.push(blockItemPrefix + str);\n    }\n    let str;\n    if (lines.length === 0) {\n        str = flowChars.start + flowChars.end;\n    }\n    else {\n        str = lines[0];\n        for (let i = 1; i < lines.length; ++i) {\n            const line = lines[i];\n            str += line ? `\\n${indent}${line}` : '\\n';\n        }\n    }\n    if (comment) {\n        str += '\\n' + indentComment(commentString(comment), indent);\n        if (onComment)\n            onComment();\n    }\n    else if (chompKeep && onChompKeep)\n        onChompKeep();\n    return str;\n}\nfunction stringifyFlowCollection({ comment, items }, ctx, { flowChars, itemIndent, onComment }) {\n    const { indent, indentStep, options: { commentString } } = ctx;\n    itemIndent += indentStep;\n    const itemCtx = Object.assign({}, ctx, {\n        indent: itemIndent,\n        inFlow: true,\n        type: null\n    });\n    let reqNewline = false;\n    let linesAtValue = 0;\n    const lines = [];\n    for (let i = 0; i < items.length; ++i) {\n        const item = items[i];\n        let comment = null;\n        if (isNode$1(item)) {\n            if (item.spaceBefore)\n                lines.push('');\n            addCommentBefore(ctx, lines, item.commentBefore, false);\n            if (item.comment)\n                comment = item.comment;\n        }\n        else if (isPair(item)) {\n            const ik = isNode$1(item.key) ? item.key : null;\n            if (ik) {\n                if (ik.spaceBefore)\n                    lines.push('');\n                addCommentBefore(ctx, lines, ik.commentBefore, false);\n                if (ik.comment)\n                    reqNewline = true;\n            }\n            const iv = isNode$1(item.value) ? item.value : null;\n            if (iv) {\n                if (iv.comment)\n                    comment = iv.comment;\n                if (iv.commentBefore)\n                    reqNewline = true;\n            }\n            else if (item.value == null && ik && ik.comment) {\n                comment = ik.comment;\n            }\n        }\n        if (comment)\n            reqNewline = true;\n        let str = stringify$2(item, itemCtx, () => (comment = null));\n        if (i < items.length - 1)\n            str += ',';\n        if (comment)\n            str += lineComment(str, itemIndent, commentString(comment));\n        if (!reqNewline && (lines.length > linesAtValue || str.includes('\\n')))\n            reqNewline = true;\n        lines.push(str);\n        linesAtValue = lines.length;\n    }\n    let str;\n    const { start, end } = flowChars;\n    if (lines.length === 0) {\n        str = start + end;\n    }\n    else {\n        if (!reqNewline) {\n            const len = lines.reduce((sum, line) => sum + line.length + 2, 2);\n            reqNewline = len > Collection.maxFlowStringSingleLineLength;\n        }\n        if (reqNewline) {\n            str = start;\n            for (const line of lines)\n                str += line ? `\\n${indentStep}${indent}${line}` : '\\n';\n            str += `\\n${indent}${end}`;\n        }\n        else {\n            str = `${start} ${lines.join(' ')} ${end}`;\n        }\n    }\n    if (comment) {\n        str += lineComment(str, commentString(comment), indent);\n        if (onComment)\n            onComment();\n    }\n    return str;\n}\nfunction addCommentBefore({ indent, options: { commentString } }, lines, comment, chompKeep) {\n    if (comment && chompKeep)\n        comment = comment.replace(/^\\n+/, '');\n    if (comment) {\n        const ic = indentComment(commentString(comment), indent);\n        lines.push(ic.trimStart()); // Avoid double indent on first line\n    }\n}\n\nfunction findPair(items, key) {\n    const k = isScalar$1(key) ? key.value : key;\n    for (const it of items) {\n        if (isPair(it)) {\n            if (it.key === key || it.key === k)\n                return it;\n            if (isScalar$1(it.key) && it.key.value === k)\n                return it;\n        }\n    }\n    return undefined;\n}\nclass YAMLMap extends Collection {\n    constructor(schema) {\n        super(MAP, schema);\n        this.items = [];\n    }\n    static get tagName() {\n        return 'tag:yaml.org,2002:map';\n    }\n    /**\n     * Adds a value to the collection.\n     *\n     * @param overwrite - If not set `true`, using a key that is already in the\n     *   collection will throw. Otherwise, overwrites the previous value.\n     */\n    add(pair, overwrite) {\n        let _pair;\n        if (isPair(pair))\n            _pair = pair;\n        else if (!pair || typeof pair !== 'object' || !('key' in pair)) {\n            // In TypeScript, this never happens.\n            _pair = new Pair(pair, pair?.value);\n        }\n        else\n            _pair = new Pair(pair.key, pair.value);\n        const prev = findPair(this.items, _pair.key);\n        const sortEntries = this.schema?.sortMapEntries;\n        if (prev) {\n            if (!overwrite)\n                throw new Error(`Key ${_pair.key} already set`);\n            // For scalars, keep the old node & its comments and anchors\n            if (isScalar$1(prev.value) && isScalarValue(_pair.value))\n                prev.value.value = _pair.value;\n            else\n                prev.value = _pair.value;\n        }\n        else if (sortEntries) {\n            const i = this.items.findIndex(item => sortEntries(_pair, item) < 0);\n            if (i === -1)\n                this.items.push(_pair);\n            else\n                this.items.splice(i, 0, _pair);\n        }\n        else {\n            this.items.push(_pair);\n        }\n    }\n    delete(key) {\n        const it = findPair(this.items, key);\n        if (!it)\n            return false;\n        const del = this.items.splice(this.items.indexOf(it), 1);\n        return del.length > 0;\n    }\n    get(key, keepScalar) {\n        const it = findPair(this.items, key);\n        const node = it?.value;\n        return (!keepScalar && isScalar$1(node) ? node.value : node) ?? undefined;\n    }\n    has(key) {\n        return !!findPair(this.items, key);\n    }\n    set(key, value) {\n        this.add(new Pair(key, value), true);\n    }\n    /**\n     * @param ctx - Conversion context, originally set in Document#toJS()\n     * @param {Class} Type - If set, forces the returned collection type\n     * @returns Instance of Type, Map, or Object\n     */\n    toJSON(_, ctx, Type) {\n        const map = Type ? new Type() : ctx?.mapAsMap ? new Map() : {};\n        if (ctx?.onCreate)\n            ctx.onCreate(map);\n        for (const item of this.items)\n            addPairToJSMap(ctx, map, item);\n        return map;\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        for (const item of this.items) {\n            if (!isPair(item))\n                throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);\n        }\n        if (!ctx.allNullValues && this.hasAllNullValues(false))\n            ctx = Object.assign({}, ctx, { allNullValues: true });\n        return stringifyCollection(this, ctx, {\n            blockItemPrefix: '',\n            flowChars: { start: '{', end: '}' },\n            itemIndent: ctx.indent || '',\n            onChompKeep,\n            onComment\n        });\n    }\n}\n\nfunction createMap(schema, obj, ctx) {\n    const { keepUndefined, replacer } = ctx;\n    const map = new YAMLMap(schema);\n    const add = (key, value) => {\n        if (typeof replacer === 'function')\n            value = replacer.call(obj, key, value);\n        else if (Array.isArray(replacer) && !replacer.includes(key))\n            return;\n        if (value !== undefined || keepUndefined)\n            map.items.push(createPair(key, value, ctx));\n    };\n    if (obj instanceof Map) {\n        for (const [key, value] of obj)\n            add(key, value);\n    }\n    else if (obj && typeof obj === 'object') {\n        for (const key of Object.keys(obj))\n            add(key, obj[key]);\n    }\n    if (typeof schema.sortMapEntries === 'function') {\n        map.items.sort(schema.sortMapEntries);\n    }\n    return map;\n}\nconst map = {\n    collection: 'map',\n    createNode: createMap,\n    default: true,\n    nodeClass: YAMLMap,\n    tag: 'tag:yaml.org,2002:map',\n    resolve(map, onError) {\n        if (!isMap(map))\n            onError('Expected a mapping for this tag');\n        return map;\n    }\n};\n\nclass YAMLSeq extends Collection {\n    constructor(schema) {\n        super(SEQ, schema);\n        this.items = [];\n    }\n    static get tagName() {\n        return 'tag:yaml.org,2002:seq';\n    }\n    add(value) {\n        this.items.push(value);\n    }\n    /**\n     * Removes a value from the collection.\n     *\n     * `key` must contain a representation of an integer for this to succeed.\n     * It may be wrapped in a `Scalar`.\n     *\n     * @returns `true` if the item was found and removed.\n     */\n    delete(key) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            return false;\n        const del = this.items.splice(idx, 1);\n        return del.length > 0;\n    }\n    get(key, keepScalar) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            return undefined;\n        const it = this.items[idx];\n        return !keepScalar && isScalar$1(it) ? it.value : it;\n    }\n    /**\n     * Checks if the collection includes a value with the key `key`.\n     *\n     * `key` must contain a representation of an integer for this to succeed.\n     * It may be wrapped in a `Scalar`.\n     */\n    has(key) {\n        const idx = asItemIndex(key);\n        return typeof idx === 'number' && idx < this.items.length;\n    }\n    /**\n     * Sets a value in this collection. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     *\n     * If `key` does not contain a representation of an integer, this will throw.\n     * It may be wrapped in a `Scalar`.\n     */\n    set(key, value) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            throw new Error(`Expected a valid index, not ${key}.`);\n        const prev = this.items[idx];\n        if (isScalar$1(prev) && isScalarValue(value))\n            prev.value = value;\n        else\n            this.items[idx] = value;\n    }\n    toJSON(_, ctx) {\n        const seq = [];\n        if (ctx?.onCreate)\n            ctx.onCreate(seq);\n        let i = 0;\n        for (const item of this.items)\n            seq.push(toJS(item, String(i++), ctx));\n        return seq;\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        return stringifyCollection(this, ctx, {\n            blockItemPrefix: '- ',\n            flowChars: { start: '[', end: ']' },\n            itemIndent: (ctx.indent || '') + '  ',\n            onChompKeep,\n            onComment\n        });\n    }\n}\nfunction asItemIndex(key) {\n    let idx = isScalar$1(key) ? key.value : key;\n    if (idx && typeof idx === 'string')\n        idx = Number(idx);\n    return typeof idx === 'number' && Number.isInteger(idx) && idx >= 0\n        ? idx\n        : null;\n}\n\nfunction createSeq(schema, obj, ctx) {\n    const { replacer } = ctx;\n    const seq = new YAMLSeq(schema);\n    if (obj && Symbol.iterator in Object(obj)) {\n        let i = 0;\n        for (let it of obj) {\n            if (typeof replacer === 'function') {\n                const key = obj instanceof Set ? it : String(i++);\n                it = replacer.call(obj, key, it);\n            }\n            seq.items.push(createNode(it, undefined, ctx));\n        }\n    }\n    return seq;\n}\nconst seq = {\n    collection: 'seq',\n    createNode: createSeq,\n    default: true,\n    nodeClass: YAMLSeq,\n    tag: 'tag:yaml.org,2002:seq',\n    resolve(seq, onError) {\n        if (!isSeq(seq))\n            onError('Expected a sequence for this tag');\n        return seq;\n    }\n};\n\nconst string = {\n    identify: value => typeof value === 'string',\n    default: true,\n    tag: 'tag:yaml.org,2002:str',\n    resolve: str => str,\n    stringify(item, ctx, onComment, onChompKeep) {\n        ctx = Object.assign({ actualString: true }, ctx);\n        return stringifyString(item, ctx, onComment, onChompKeep);\n    }\n};\n\nconst nullTag = {\n    identify: value => value == null,\n    createNode: () => new Scalar(null),\n    default: true,\n    tag: 'tag:yaml.org,2002:null',\n    test: /^(?:~|[Nn]ull|NULL)?$/,\n    resolve: () => new Scalar(null),\n    stringify: ({ source }, ctx) => typeof source === 'string' && nullTag.test.test(source)\n        ? source\n        : ctx.options.nullStr\n};\n\nconst boolTag = {\n    identify: value => typeof value === 'boolean',\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,\n    resolve: str => new Scalar(str[0] === 't' || str[0] === 'T'),\n    stringify({ source, value }, ctx) {\n        if (source && boolTag.test.test(source)) {\n            const sv = source[0] === 't' || source[0] === 'T';\n            if (value === sv)\n                return source;\n        }\n        return value ? ctx.options.trueStr : ctx.options.falseStr;\n    }\n};\n\nfunction stringifyNumber({ format, minFractionDigits, tag, value }) {\n    if (typeof value === 'bigint')\n        return String(value);\n    const num = typeof value === 'number' ? value : Number(value);\n    if (!isFinite(num))\n        return isNaN(num) ? '.nan' : num < 0 ? '-.inf' : '.inf';\n    let n = JSON.stringify(value);\n    if (!format &&\n        minFractionDigits &&\n        (!tag || tag === 'tag:yaml.org,2002:float') &&\n        /^\\d/.test(n)) {\n        let i = n.indexOf('.');\n        if (i < 0) {\n            i = n.length;\n            n += '.';\n        }\n        let d = minFractionDigits - (n.length - i - 1);\n        while (d-- > 0)\n            n += '0';\n    }\n    return n;\n}\n\nconst floatNaN$1 = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^(?:[-+]?\\.(?:inf|Inf|INF|nan|NaN|NAN))$/,\n    resolve: str => str.slice(-3).toLowerCase() === 'nan'\n        ? NaN\n        : str[0] === '-'\n            ? Number.NEGATIVE_INFINITY\n            : Number.POSITIVE_INFINITY,\n    stringify: stringifyNumber\n};\nconst floatExp$1 = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'EXP',\n    test: /^[-+]?(?:\\.[0-9]+|[0-9]+(?:\\.[0-9]*)?)[eE][-+]?[0-9]+$/,\n    resolve: str => parseFloat(str),\n    stringify(node) {\n        const num = Number(node.value);\n        return isFinite(num) ? num.toExponential() : stringifyNumber(node);\n    }\n};\nconst float$1 = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?(?:\\.[0-9]+|[0-9]+\\.[0-9]*)$/,\n    resolve(str) {\n        const node = new Scalar(parseFloat(str));\n        const dot = str.indexOf('.');\n        if (dot !== -1 && str[str.length - 1] === '0')\n            node.minFractionDigits = str.length - dot - 1;\n        return node;\n    },\n    stringify: stringifyNumber\n};\n\nconst intIdentify$2 = (value) => typeof value === 'bigint' || Number.isInteger(value);\nconst intResolve$1 = (str, offset, radix, { intAsBigInt }) => (intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix));\nfunction intStringify$1(node, radix, prefix) {\n    const { value } = node;\n    if (intIdentify$2(value) && value >= 0)\n        return prefix + value.toString(radix);\n    return stringifyNumber(node);\n}\nconst intOct$1 = {\n    identify: value => intIdentify$2(value) && value >= 0,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'OCT',\n    test: /^0o[0-7]+$/,\n    resolve: (str, _onError, opt) => intResolve$1(str, 2, 8, opt),\n    stringify: node => intStringify$1(node, 8, '0o')\n};\nconst int$1 = {\n    identify: intIdentify$2,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    test: /^[-+]?[0-9]+$/,\n    resolve: (str, _onError, opt) => intResolve$1(str, 0, 10, opt),\n    stringify: stringifyNumber\n};\nconst intHex$1 = {\n    identify: value => intIdentify$2(value) && value >= 0,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'HEX',\n    test: /^0x[0-9a-fA-F]+$/,\n    resolve: (str, _onError, opt) => intResolve$1(str, 2, 16, opt),\n    stringify: node => intStringify$1(node, 16, '0x')\n};\n\nconst schema$2 = [\n    map,\n    seq,\n    string,\n    nullTag,\n    boolTag,\n    intOct$1,\n    int$1,\n    intHex$1,\n    floatNaN$1,\n    floatExp$1,\n    float$1\n];\n\nfunction intIdentify$1(value) {\n    return typeof value === 'bigint' || Number.isInteger(value);\n}\nconst stringifyJSON = ({ value }) => JSON.stringify(value);\nconst jsonScalars = [\n    {\n        identify: value => typeof value === 'string',\n        default: true,\n        tag: 'tag:yaml.org,2002:str',\n        resolve: str => str,\n        stringify: stringifyJSON\n    },\n    {\n        identify: value => value == null,\n        createNode: () => new Scalar(null),\n        default: true,\n        tag: 'tag:yaml.org,2002:null',\n        test: /^null$/,\n        resolve: () => null,\n        stringify: stringifyJSON\n    },\n    {\n        identify: value => typeof value === 'boolean',\n        default: true,\n        tag: 'tag:yaml.org,2002:bool',\n        test: /^true|false$/,\n        resolve: str => str === 'true',\n        stringify: stringifyJSON\n    },\n    {\n        identify: intIdentify$1,\n        default: true,\n        tag: 'tag:yaml.org,2002:int',\n        test: /^-?(?:0|[1-9][0-9]*)$/,\n        resolve: (str, _onError, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str, 10),\n        stringify: ({ value }) => intIdentify$1(value) ? value.toString() : JSON.stringify(value)\n    },\n    {\n        identify: value => typeof value === 'number',\n        default: true,\n        tag: 'tag:yaml.org,2002:float',\n        test: /^-?(?:0|[1-9][0-9]*)(?:\\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,\n        resolve: str => parseFloat(str),\n        stringify: stringifyJSON\n    }\n];\nconst jsonError = {\n    default: true,\n    tag: '',\n    test: /^/,\n    resolve(str, onError) {\n        onError(`Unresolved plain scalar ${JSON.stringify(str)}`);\n        return str;\n    }\n};\nconst schema$1 = [map, seq].concat(jsonScalars, jsonError);\n\nconst binary = {\n    identify: value => value instanceof Uint8Array,\n    default: false,\n    tag: 'tag:yaml.org,2002:binary',\n    /**\n     * Returns a Buffer in node and an Uint8Array in browsers\n     *\n     * To use the resulting buffer as an image, you'll want to do something like:\n     *\n     *   const blob = new Blob([buffer], { type: 'image/jpeg' })\n     *   document.querySelector('#photo').src = URL.createObjectURL(blob)\n     */\n    resolve(src, onError) {\n        if (typeof Buffer === 'function') {\n            return Buffer.from(src, 'base64');\n        }\n        else if (typeof atob === 'function') {\n            // On IE 11, atob() can't handle newlines\n            const str = atob(src.replace(/[\\n\\r]/g, ''));\n            const buffer = new Uint8Array(str.length);\n            for (let i = 0; i < str.length; ++i)\n                buffer[i] = str.charCodeAt(i);\n            return buffer;\n        }\n        else {\n            onError('This environment does not support reading binary tags; either Buffer or atob is required');\n            return src;\n        }\n    },\n    stringify({ comment, type, value }, ctx, onComment, onChompKeep) {\n        const buf = value; // checked earlier by binary.identify()\n        let str;\n        if (typeof Buffer === 'function') {\n            str =\n                buf instanceof Buffer\n                    ? buf.toString('base64')\n                    : Buffer.from(buf.buffer).toString('base64');\n        }\n        else if (typeof btoa === 'function') {\n            let s = '';\n            for (let i = 0; i < buf.length; ++i)\n                s += String.fromCharCode(buf[i]);\n            str = btoa(s);\n        }\n        else {\n            throw new Error('This environment does not support writing binary tags; either Buffer or btoa is required');\n        }\n        if (!type)\n            type = Scalar.BLOCK_LITERAL;\n        if (type !== Scalar.QUOTE_DOUBLE) {\n            const lineWidth = Math.max(ctx.options.lineWidth - ctx.indent.length, ctx.options.minContentWidth);\n            const n = Math.ceil(str.length / lineWidth);\n            const lines = new Array(n);\n            for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {\n                lines[i] = str.substr(o, lineWidth);\n            }\n            str = lines.join(type === Scalar.BLOCK_LITERAL ? '\\n' : ' ');\n        }\n        return stringifyString({ comment, type, value: str }, ctx, onComment, onChompKeep);\n    }\n};\n\nfunction resolvePairs(seq, onError) {\n    if (isSeq(seq)) {\n        for (let i = 0; i < seq.items.length; ++i) {\n            let item = seq.items[i];\n            if (isPair(item))\n                continue;\n            else if (isMap(item)) {\n                if (item.items.length > 1)\n                    onError('Each pair must have its own sequence indicator');\n                const pair = item.items[0] || new Pair(new Scalar(null));\n                if (item.commentBefore)\n                    pair.key.commentBefore = pair.key.commentBefore\n                        ? `${item.commentBefore}\\n${pair.key.commentBefore}`\n                        : item.commentBefore;\n                if (item.comment) {\n                    const cn = pair.value ?? pair.key;\n                    cn.comment = cn.comment\n                        ? `${item.comment}\\n${cn.comment}`\n                        : item.comment;\n                }\n                item = pair;\n            }\n            seq.items[i] = isPair(item) ? item : new Pair(item);\n        }\n    }\n    else\n        onError('Expected a sequence for this tag');\n    return seq;\n}\nfunction createPairs(schema, iterable, ctx) {\n    const { replacer } = ctx;\n    const pairs = new YAMLSeq(schema);\n    pairs.tag = 'tag:yaml.org,2002:pairs';\n    let i = 0;\n    if (iterable && Symbol.iterator in Object(iterable))\n        for (let it of iterable) {\n            if (typeof replacer === 'function')\n                it = replacer.call(iterable, String(i++), it);\n            let key, value;\n            if (Array.isArray(it)) {\n                if (it.length === 2) {\n                    key = it[0];\n                    value = it[1];\n                }\n                else\n                    throw new TypeError(`Expected [key, value] tuple: ${it}`);\n            }\n            else if (it && it instanceof Object) {\n                const keys = Object.keys(it);\n                if (keys.length === 1) {\n                    key = keys[0];\n                    value = it[key];\n                }\n                else\n                    throw new TypeError(`Expected { key: value } tuple: ${it}`);\n            }\n            else {\n                key = it;\n            }\n            pairs.items.push(createPair(key, value, ctx));\n        }\n    return pairs;\n}\nconst pairs = {\n    collection: 'seq',\n    default: false,\n    tag: 'tag:yaml.org,2002:pairs',\n    resolve: resolvePairs,\n    createNode: createPairs\n};\n\nclass YAMLOMap extends YAMLSeq {\n    constructor() {\n        super();\n        this.add = YAMLMap.prototype.add.bind(this);\n        this.delete = YAMLMap.prototype.delete.bind(this);\n        this.get = YAMLMap.prototype.get.bind(this);\n        this.has = YAMLMap.prototype.has.bind(this);\n        this.set = YAMLMap.prototype.set.bind(this);\n        this.tag = YAMLOMap.tag;\n    }\n    /**\n     * If `ctx` is given, the return type is actually `Map<unknown, unknown>`,\n     * but TypeScript won't allow widening the signature of a child method.\n     */\n    toJSON(_, ctx) {\n        if (!ctx)\n            return super.toJSON(_);\n        const map = new Map();\n        if (ctx?.onCreate)\n            ctx.onCreate(map);\n        for (const pair of this.items) {\n            let key, value;\n            if (isPair(pair)) {\n                key = toJS(pair.key, '', ctx);\n                value = toJS(pair.value, key, ctx);\n            }\n            else {\n                key = toJS(pair, '', ctx);\n            }\n            if (map.has(key))\n                throw new Error('Ordered maps must not include duplicate keys');\n            map.set(key, value);\n        }\n        return map;\n    }\n}\nYAMLOMap.tag = 'tag:yaml.org,2002:omap';\nconst omap = {\n    collection: 'seq',\n    identify: value => value instanceof Map,\n    nodeClass: YAMLOMap,\n    default: false,\n    tag: 'tag:yaml.org,2002:omap',\n    resolve(seq, onError) {\n        const pairs = resolvePairs(seq, onError);\n        const seenKeys = [];\n        for (const { key } of pairs.items) {\n            if (isScalar$1(key)) {\n                if (seenKeys.includes(key.value)) {\n                    onError(`Ordered maps must not include duplicate keys: ${key.value}`);\n                }\n                else {\n                    seenKeys.push(key.value);\n                }\n            }\n        }\n        return Object.assign(new YAMLOMap(), pairs);\n    },\n    createNode(schema, iterable, ctx) {\n        const pairs = createPairs(schema, iterable, ctx);\n        const omap = new YAMLOMap();\n        omap.items = pairs.items;\n        return omap;\n    }\n};\n\nfunction boolStringify({ value, source }, ctx) {\n    const boolObj = value ? trueTag : falseTag;\n    if (source && boolObj.test.test(source))\n        return source;\n    return value ? ctx.options.trueStr : ctx.options.falseStr;\n}\nconst trueTag = {\n    identify: value => value === true,\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,\n    resolve: () => new Scalar(true),\n    stringify: boolStringify\n};\nconst falseTag = {\n    identify: value => value === false,\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/i,\n    resolve: () => new Scalar(false),\n    stringify: boolStringify\n};\n\nconst floatNaN = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?\\.(?:inf|Inf|INF|nan|NaN|NAN)$/,\n    resolve: (str) => str.slice(-3).toLowerCase() === 'nan'\n        ? NaN\n        : str[0] === '-'\n            ? Number.NEGATIVE_INFINITY\n            : Number.POSITIVE_INFINITY,\n    stringify: stringifyNumber\n};\nconst floatExp = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'EXP',\n    test: /^[-+]?(?:[0-9][0-9_]*)?(?:\\.[0-9_]*)?[eE][-+]?[0-9]+$/,\n    resolve: (str) => parseFloat(str.replace(/_/g, '')),\n    stringify(node) {\n        const num = Number(node.value);\n        return isFinite(num) ? num.toExponential() : stringifyNumber(node);\n    }\n};\nconst float = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?(?:[0-9][0-9_]*)?\\.[0-9_]*$/,\n    resolve(str) {\n        const node = new Scalar(parseFloat(str.replace(/_/g, '')));\n        const dot = str.indexOf('.');\n        if (dot !== -1) {\n            const f = str.substring(dot + 1).replace(/_/g, '');\n            if (f[f.length - 1] === '0')\n                node.minFractionDigits = f.length;\n        }\n        return node;\n    },\n    stringify: stringifyNumber\n};\n\nconst intIdentify = (value) => typeof value === 'bigint' || Number.isInteger(value);\nfunction intResolve(str, offset, radix, { intAsBigInt }) {\n    const sign = str[0];\n    if (sign === '-' || sign === '+')\n        offset += 1;\n    str = str.substring(offset).replace(/_/g, '');\n    if (intAsBigInt) {\n        switch (radix) {\n            case 2:\n                str = `0b${str}`;\n                break;\n            case 8:\n                str = `0o${str}`;\n                break;\n            case 16:\n                str = `0x${str}`;\n                break;\n        }\n        const n = BigInt(str);\n        return sign === '-' ? BigInt(-1) * n : n;\n    }\n    const n = parseInt(str, radix);\n    return sign === '-' ? -1 * n : n;\n}\nfunction intStringify(node, radix, prefix) {\n    const { value } = node;\n    if (intIdentify(value)) {\n        const str = value.toString(radix);\n        return value < 0 ? '-' + prefix + str.substr(1) : prefix + str;\n    }\n    return stringifyNumber(node);\n}\nconst intBin = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'BIN',\n    test: /^[-+]?0b[0-1_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),\n    stringify: node => intStringify(node, 2, '0b')\n};\nconst intOct = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'OCT',\n    test: /^[-+]?0[0-7_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),\n    stringify: node => intStringify(node, 8, '0')\n};\nconst int = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    test: /^[-+]?[0-9][0-9_]*$/,\n    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),\n    stringify: stringifyNumber\n};\nconst intHex = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'HEX',\n    test: /^[-+]?0x[0-9a-fA-F_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),\n    stringify: node => intStringify(node, 16, '0x')\n};\n\nclass YAMLSet extends YAMLMap {\n    constructor(schema) {\n        super(schema);\n        this.tag = YAMLSet.tag;\n    }\n    add(key) {\n        let pair;\n        if (isPair(key))\n            pair = key;\n        else if (typeof key === 'object' &&\n            'key' in key &&\n            'value' in key &&\n            key.value === null)\n            pair = new Pair(key.key, null);\n        else\n            pair = new Pair(key, null);\n        const prev = findPair(this.items, pair.key);\n        if (!prev)\n            this.items.push(pair);\n    }\n    /**\n     * If `keepPair` is `true`, returns the Pair matching `key`.\n     * Otherwise, returns the value of that Pair's key.\n     */\n    get(key, keepPair) {\n        const pair = findPair(this.items, key);\n        return !keepPair && isPair(pair)\n            ? isScalar$1(pair.key)\n                ? pair.key.value\n                : pair.key\n            : pair;\n    }\n    set(key, value) {\n        if (typeof value !== 'boolean')\n            throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`);\n        const prev = findPair(this.items, key);\n        if (prev && !value) {\n            this.items.splice(this.items.indexOf(prev), 1);\n        }\n        else if (!prev && value) {\n            this.items.push(new Pair(key));\n        }\n    }\n    toJSON(_, ctx) {\n        return super.toJSON(_, ctx, Set);\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        if (this.hasAllNullValues(true))\n            return super.toString(Object.assign({}, ctx, { allNullValues: true }), onComment, onChompKeep);\n        else\n            throw new Error('Set items must all have null values');\n    }\n}\nYAMLSet.tag = 'tag:yaml.org,2002:set';\nconst set = {\n    collection: 'map',\n    identify: value => value instanceof Set,\n    nodeClass: YAMLSet,\n    default: false,\n    tag: 'tag:yaml.org,2002:set',\n    resolve(map, onError) {\n        if (isMap(map)) {\n            if (map.hasAllNullValues(true))\n                return Object.assign(new YAMLSet(), map);\n            else\n                onError('Set items must all have null values');\n        }\n        else\n            onError('Expected a mapping for this tag');\n        return map;\n    },\n    createNode(schema, iterable, ctx) {\n        const { replacer } = ctx;\n        const set = new YAMLSet(schema);\n        if (iterable && Symbol.iterator in Object(iterable))\n            for (let value of iterable) {\n                if (typeof replacer === 'function')\n                    value = replacer.call(iterable, value, value);\n                set.items.push(createPair(value, null, ctx));\n            }\n        return set;\n    }\n};\n\n/** Internal types handle bigint as number, because TS can't figure it out. */\nfunction parseSexagesimal(str, asBigInt) {\n    const sign = str[0];\n    const parts = sign === '-' || sign === '+' ? str.substring(1) : str;\n    const num = (n) => asBigInt ? BigInt(n) : Number(n);\n    const res = parts\n        .replace(/_/g, '')\n        .split(':')\n        .reduce((res, p) => res * num(60) + num(p), num(0));\n    return (sign === '-' ? num(-1) * res : res);\n}\n/**\n * hhhh:mm:ss.sss\n *\n * Internal types handle bigint as number, because TS can't figure it out.\n */\nfunction stringifySexagesimal(node) {\n    let { value } = node;\n    let num = (n) => n;\n    if (typeof value === 'bigint')\n        num = n => BigInt(n);\n    else if (isNaN(value) || !isFinite(value))\n        return stringifyNumber(node);\n    let sign = '';\n    if (value < 0) {\n        sign = '-';\n        value *= num(-1);\n    }\n    const _60 = num(60);\n    const parts = [value % _60]; // seconds, including ms\n    if (value < 60) {\n        parts.unshift(0); // at least one : is required\n    }\n    else {\n        value = (value - parts[0]) / _60;\n        parts.unshift(value % _60); // minutes\n        if (value >= 60) {\n            value = (value - parts[0]) / _60;\n            parts.unshift(value); // hours\n        }\n    }\n    return (sign +\n        parts\n            .map(n => (n < 10 ? '0' + String(n) : String(n)))\n            .join(':')\n            .replace(/000000\\d*$/, '') // % 60 may introduce error\n    );\n}\nconst intTime = {\n    identify: value => typeof value === 'bigint' || Number.isInteger(value),\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'TIME',\n    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,\n    resolve: (str, _onError, { intAsBigInt }) => parseSexagesimal(str, intAsBigInt),\n    stringify: stringifySexagesimal\n};\nconst floatTime = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'TIME',\n    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*$/,\n    resolve: str => parseSexagesimal(str, false),\n    stringify: stringifySexagesimal\n};\nconst timestamp = {\n    identify: value => value instanceof Date,\n    default: true,\n    tag: 'tag:yaml.org,2002:timestamp',\n    // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part\n    // may be omitted altogether, resulting in a date format. In such a case, the time part is\n    // assumed to be 00:00:00Z (start of day, UTC).\n    test: RegExp('^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})' + // YYYY-Mm-Dd\n        '(?:' + // time is optional\n        '(?:t|T|[ \\\\t]+)' + // t | T | whitespace\n        '([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\\\.[0-9]+)?)' + // Hh:Mm:Ss(.ss)?\n        '(?:[ \\\\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?' + // Z | +5 | -03:30\n        ')?$'),\n    resolve(str) {\n        const match = str.match(timestamp.test);\n        if (!match)\n            throw new Error('!!timestamp expects a date, starting with yyyy-mm-dd');\n        const [, year, month, day, hour, minute, second] = match.map(Number);\n        const millisec = match[7] ? Number((match[7] + '00').substr(1, 3)) : 0;\n        let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec);\n        const tz = match[8];\n        if (tz && tz !== 'Z') {\n            let d = parseSexagesimal(tz, false);\n            if (Math.abs(d) < 30)\n                d *= 60;\n            date -= 60000 * d;\n        }\n        return new Date(date);\n    },\n    stringify: ({ value }) => value.toISOString().replace(/((T00:00)?:00)?\\.000Z$/, '')\n};\n\nconst schema = [\n    map,\n    seq,\n    string,\n    nullTag,\n    trueTag,\n    falseTag,\n    intBin,\n    intOct,\n    int,\n    intHex,\n    floatNaN,\n    floatExp,\n    float,\n    binary,\n    omap,\n    pairs,\n    set,\n    intTime,\n    floatTime,\n    timestamp\n];\n\nconst schemas = new Map([\n    ['core', schema$2],\n    ['failsafe', [map, seq, string]],\n    ['json', schema$1],\n    ['yaml11', schema],\n    ['yaml-1.1', schema]\n]);\nconst tagsByName = {\n    binary,\n    bool: boolTag,\n    float: float$1,\n    floatExp: floatExp$1,\n    floatNaN: floatNaN$1,\n    floatTime,\n    int: int$1,\n    intHex: intHex$1,\n    intOct: intOct$1,\n    intTime,\n    map,\n    null: nullTag,\n    omap,\n    pairs,\n    seq,\n    set,\n    timestamp\n};\nconst coreKnownTags = {\n    'tag:yaml.org,2002:binary': binary,\n    'tag:yaml.org,2002:omap': omap,\n    'tag:yaml.org,2002:pairs': pairs,\n    'tag:yaml.org,2002:set': set,\n    'tag:yaml.org,2002:timestamp': timestamp\n};\nfunction getTags(customTags, schemaName) {\n    let tags = schemas.get(schemaName);\n    if (!tags) {\n        if (Array.isArray(customTags))\n            tags = [];\n        else {\n            const keys = Array.from(schemas.keys())\n                .filter(key => key !== 'yaml11')\n                .map(key => JSON.stringify(key))\n                .join(', ');\n            throw new Error(`Unknown schema \"${schemaName}\"; use one of ${keys} or define customTags array`);\n        }\n    }\n    if (Array.isArray(customTags)) {\n        for (const tag of customTags)\n            tags = tags.concat(tag);\n    }\n    else if (typeof customTags === 'function') {\n        tags = customTags(tags.slice());\n    }\n    return tags.map(tag => {\n        if (typeof tag !== 'string')\n            return tag;\n        const tagObj = tagsByName[tag];\n        if (tagObj)\n            return tagObj;\n        const keys = Object.keys(tagsByName)\n            .map(key => JSON.stringify(key))\n            .join(', ');\n        throw new Error(`Unknown custom tag \"${tag}\"; use one of ${keys}`);\n    });\n}\n\nconst sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;\nclass Schema {\n    constructor({ compat, customTags, merge, resolveKnownTags, schema, sortMapEntries, toStringDefaults }) {\n        this.compat = Array.isArray(compat)\n            ? getTags(compat, 'compat')\n            : compat\n                ? getTags(null, compat)\n                : null;\n        this.merge = !!merge;\n        this.name = (typeof schema === 'string' && schema) || 'core';\n        this.knownTags = resolveKnownTags ? coreKnownTags : {};\n        this.tags = getTags(customTags, this.name);\n        this.toStringOptions = toStringDefaults ?? null;\n        Object.defineProperty(this, MAP, { value: map });\n        Object.defineProperty(this, SCALAR$1, { value: string });\n        Object.defineProperty(this, SEQ, { value: seq });\n        // Used by createMap()\n        this.sortMapEntries =\n            typeof sortMapEntries === 'function'\n                ? sortMapEntries\n                : sortMapEntries === true\n                    ? sortMapEntriesByKey\n                    : null;\n    }\n    clone() {\n        const copy = Object.create(Schema.prototype, Object.getOwnPropertyDescriptors(this));\n        copy.tags = this.tags.slice();\n        return copy;\n    }\n}\n\nfunction stringifyDocument(doc, options) {\n    const lines = [];\n    let hasDirectives = options.directives === true;\n    if (options.directives !== false && doc.directives) {\n        const dir = doc.directives.toString(doc);\n        if (dir) {\n            lines.push(dir);\n            hasDirectives = true;\n        }\n        else if (doc.directives.docStart)\n            hasDirectives = true;\n    }\n    if (hasDirectives)\n        lines.push('---');\n    const ctx = createStringifyContext(doc, options);\n    const { commentString } = ctx.options;\n    if (doc.commentBefore) {\n        if (lines.length !== 1)\n            lines.unshift('');\n        const cs = commentString(doc.commentBefore);\n        lines.unshift(indentComment(cs, ''));\n    }\n    let chompKeep = false;\n    let contentComment = null;\n    if (doc.contents) {\n        if (isNode$1(doc.contents)) {\n            if (doc.contents.spaceBefore && hasDirectives)\n                lines.push('');\n            if (doc.contents.commentBefore) {\n                const cs = commentString(doc.contents.commentBefore);\n                lines.push(indentComment(cs, ''));\n            }\n            // top-level block scalars need to be indented if followed by a comment\n            ctx.forceBlockIndent = !!doc.comment;\n            contentComment = doc.contents.comment;\n        }\n        const onChompKeep = contentComment ? undefined : () => (chompKeep = true);\n        let body = stringify$2(doc.contents, ctx, () => (contentComment = null), onChompKeep);\n        if (contentComment)\n            body += lineComment(body, '', commentString(contentComment));\n        if ((body[0] === '|' || body[0] === '>') &&\n            lines[lines.length - 1] === '---') {\n            // Top-level block scalars with a preceding doc marker ought to use the\n            // same line for their header.\n            lines[lines.length - 1] = `--- ${body}`;\n        }\n        else\n            lines.push(body);\n    }\n    else {\n        lines.push(stringify$2(doc.contents, ctx));\n    }\n    if (doc.directives?.docEnd) {\n        if (doc.comment) {\n            const cs = commentString(doc.comment);\n            if (cs.includes('\\n')) {\n                lines.push('...');\n                lines.push(indentComment(cs, ''));\n            }\n            else {\n                lines.push(`... ${cs}`);\n            }\n        }\n        else {\n            lines.push('...');\n        }\n    }\n    else {\n        let dc = doc.comment;\n        if (dc && chompKeep)\n            dc = dc.replace(/^\\n+/, '');\n        if (dc) {\n            if ((!chompKeep || contentComment) && lines[lines.length - 1] !== '')\n                lines.push('');\n            lines.push(indentComment(commentString(dc), ''));\n        }\n    }\n    return lines.join('\\n') + '\\n';\n}\n\n/**\n * Applies the JSON.parse reviver algorithm as defined in the ECMA-262 spec,\n * in section 24.5.1.1 \"Runtime Semantics: InternalizeJSONProperty\" of the\n * 2021 edition: https://tc39.es/ecma262/#sec-json.parse\n *\n * Includes extensions for handling Map and Set objects.\n */\nfunction applyReviver(reviver, obj, key, val) {\n    if (val && typeof val === 'object') {\n        if (Array.isArray(val)) {\n            for (let i = 0, len = val.length; i < len; ++i) {\n                const v0 = val[i];\n                const v1 = applyReviver(reviver, val, String(i), v0);\n                if (v1 === undefined)\n                    delete val[i];\n                else if (v1 !== v0)\n                    val[i] = v1;\n            }\n        }\n        else if (val instanceof Map) {\n            for (const k of Array.from(val.keys())) {\n                const v0 = val.get(k);\n                const v1 = applyReviver(reviver, val, k, v0);\n                if (v1 === undefined)\n                    val.delete(k);\n                else if (v1 !== v0)\n                    val.set(k, v1);\n            }\n        }\n        else if (val instanceof Set) {\n            for (const v0 of Array.from(val)) {\n                const v1 = applyReviver(reviver, val, v0, v0);\n                if (v1 === undefined)\n                    val.delete(v0);\n                else if (v1 !== v0) {\n                    val.delete(v0);\n                    val.add(v1);\n                }\n            }\n        }\n        else {\n            for (const [k, v0] of Object.entries(val)) {\n                const v1 = applyReviver(reviver, val, k, v0);\n                if (v1 === undefined)\n                    delete val[k];\n                else if (v1 !== v0)\n                    val[k] = v1;\n            }\n        }\n    }\n    return reviver.call(obj, key, val);\n}\n\nclass Document {\n    constructor(value, replacer, options) {\n        /** A comment before this Document */\n        this.commentBefore = null;\n        /** A comment immediately after this Document */\n        this.comment = null;\n        /** Errors encountered during parsing. */\n        this.errors = [];\n        /** Warnings encountered during parsing. */\n        this.warnings = [];\n        Object.defineProperty(this, NODE_TYPE, { value: DOC });\n        let _replacer = null;\n        if (typeof replacer === 'function' || Array.isArray(replacer)) {\n            _replacer = replacer;\n        }\n        else if (options === undefined && replacer) {\n            options = replacer;\n            replacer = undefined;\n        }\n        const opt = Object.assign({\n            intAsBigInt: false,\n            keepSourceTokens: false,\n            logLevel: 'warn',\n            prettyErrors: true,\n            strict: true,\n            uniqueKeys: true,\n            version: '1.2'\n        }, options);\n        this.options = opt;\n        let { version } = opt;\n        if (options?._directives) {\n            this.directives = options._directives.atDocument();\n            if (this.directives.yaml.explicit)\n                version = this.directives.yaml.version;\n        }\n        else\n            this.directives = new Directives({ version });\n        this.setSchema(version, options);\n        if (value === undefined)\n            this.contents = null;\n        else {\n            this.contents = this.createNode(value, _replacer, options);\n        }\n    }\n    /**\n     * Create a deep copy of this Document and its contents.\n     *\n     * Custom Node values that inherit from `Object` still refer to their original instances.\n     */\n    clone() {\n        const copy = Object.create(Document.prototype, {\n            [NODE_TYPE]: { value: DOC }\n        });\n        copy.commentBefore = this.commentBefore;\n        copy.comment = this.comment;\n        copy.errors = this.errors.slice();\n        copy.warnings = this.warnings.slice();\n        copy.options = Object.assign({}, this.options);\n        if (this.directives)\n            copy.directives = this.directives.clone();\n        copy.schema = this.schema.clone();\n        copy.contents = isNode$1(this.contents)\n            ? this.contents.clone(copy.schema)\n            : this.contents;\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /** Adds a value to the document. */\n    add(value) {\n        if (assertCollection(this.contents))\n            this.contents.add(value);\n    }\n    /** Adds a value to the document. */\n    addIn(path, value) {\n        if (assertCollection(this.contents))\n            this.contents.addIn(path, value);\n    }\n    /**\n     * Create a new `Alias` node, ensuring that the target `node` has the required anchor.\n     *\n     * If `node` already has an anchor, `name` is ignored.\n     * Otherwise, the `node.anchor` value will be set to `name`,\n     * or if an anchor with that name is already present in the document,\n     * `name` will be used as a prefix for a new unique anchor.\n     * If `name` is undefined, the generated anchor will use 'a' as a prefix.\n     */\n    createAlias(node, name) {\n        if (!node.anchor) {\n            const prev = anchorNames(this);\n            node.anchor =\n                // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n                !name || prev.has(name) ? findNewAnchor(name || 'a', prev) : name;\n        }\n        return new Alias(node.anchor);\n    }\n    createNode(value, replacer, options) {\n        let _replacer = undefined;\n        if (typeof replacer === 'function') {\n            value = replacer.call({ '': value }, '', value);\n            _replacer = replacer;\n        }\n        else if (Array.isArray(replacer)) {\n            const keyToStr = (v) => typeof v === 'number' || v instanceof String || v instanceof Number;\n            const asStr = replacer.filter(keyToStr).map(String);\n            if (asStr.length > 0)\n                replacer = replacer.concat(asStr);\n            _replacer = replacer;\n        }\n        else if (options === undefined && replacer) {\n            options = replacer;\n            replacer = undefined;\n        }\n        const { aliasDuplicateObjects, anchorPrefix, flow, keepUndefined, onTagObj, tag } = options ?? {};\n        const { onAnchor, setAnchors, sourceObjects } = createNodeAnchors(this, \n        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n        anchorPrefix || 'a');\n        const ctx = {\n            aliasDuplicateObjects: aliasDuplicateObjects ?? true,\n            keepUndefined: keepUndefined ?? false,\n            onAnchor,\n            onTagObj,\n            replacer: _replacer,\n            schema: this.schema,\n            sourceObjects\n        };\n        const node = createNode(value, tag, ctx);\n        if (flow && isCollection$1(node))\n            node.flow = true;\n        setAnchors();\n        return node;\n    }\n    /**\n     * Convert a key and a value into a `Pair` using the current schema,\n     * recursively wrapping all values as `Scalar` or `Collection` nodes.\n     */\n    createPair(key, value, options = {}) {\n        const k = this.createNode(key, null, options);\n        const v = this.createNode(value, null, options);\n        return new Pair(k, v);\n    }\n    /**\n     * Removes a value from the document.\n     * @returns `true` if the item was found and removed.\n     */\n    delete(key) {\n        return assertCollection(this.contents) ? this.contents.delete(key) : false;\n    }\n    /**\n     * Removes a value from the document.\n     * @returns `true` if the item was found and removed.\n     */\n    deleteIn(path) {\n        if (isEmptyPath(path)) {\n            if (this.contents == null)\n                return false;\n            this.contents = null;\n            return true;\n        }\n        return assertCollection(this.contents)\n            ? this.contents.deleteIn(path)\n            : false;\n    }\n    /**\n     * Returns item at `key`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    get(key, keepScalar) {\n        return isCollection$1(this.contents)\n            ? this.contents.get(key, keepScalar)\n            : undefined;\n    }\n    /**\n     * Returns item at `path`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    getIn(path, keepScalar) {\n        if (isEmptyPath(path))\n            return !keepScalar && isScalar$1(this.contents)\n                ? this.contents.value\n                : this.contents;\n        return isCollection$1(this.contents)\n            ? this.contents.getIn(path, keepScalar)\n            : undefined;\n    }\n    /**\n     * Checks if the document includes a value with the key `key`.\n     */\n    has(key) {\n        return isCollection$1(this.contents) ? this.contents.has(key) : false;\n    }\n    /**\n     * Checks if the document includes a value at `path`.\n     */\n    hasIn(path) {\n        if (isEmptyPath(path))\n            return this.contents !== undefined;\n        return isCollection$1(this.contents) ? this.contents.hasIn(path) : false;\n    }\n    /**\n     * Sets a value in this document. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    set(key, value) {\n        if (this.contents == null) {\n            this.contents = collectionFromPath(this.schema, [key], value);\n        }\n        else if (assertCollection(this.contents)) {\n            this.contents.set(key, value);\n        }\n    }\n    /**\n     * Sets a value in this document. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    setIn(path, value) {\n        if (isEmptyPath(path))\n            this.contents = value;\n        else if (this.contents == null) {\n            this.contents = collectionFromPath(this.schema, Array.from(path), value);\n        }\n        else if (assertCollection(this.contents)) {\n            this.contents.setIn(path, value);\n        }\n    }\n    /**\n     * Change the YAML version and schema used by the document.\n     * A `null` version disables support for directives, explicit tags, anchors, and aliases.\n     * It also requires the `schema` option to be given as a `Schema` instance value.\n     *\n     * Overrides all previously set schema options.\n     */\n    setSchema(version, options = {}) {\n        if (typeof version === 'number')\n            version = String(version);\n        let opt;\n        switch (version) {\n            case '1.1':\n                if (this.directives)\n                    this.directives.yaml.version = '1.1';\n                else\n                    this.directives = new Directives({ version: '1.1' });\n                opt = { merge: true, resolveKnownTags: false, schema: 'yaml-1.1' };\n                break;\n            case '1.2':\n            case 'next':\n                if (this.directives)\n                    this.directives.yaml.version = version;\n                else\n                    this.directives = new Directives({ version });\n                opt = { merge: false, resolveKnownTags: true, schema: 'core' };\n                break;\n            case null:\n                if (this.directives)\n                    delete this.directives;\n                opt = null;\n                break;\n            default: {\n                const sv = JSON.stringify(version);\n                throw new Error(`Expected '1.1', '1.2' or null as first argument, but found: ${sv}`);\n            }\n        }\n        // Not using `instanceof Schema` to allow for duck typing\n        if (options.schema instanceof Object)\n            this.schema = options.schema;\n        else if (opt)\n            this.schema = new Schema(Object.assign(opt, options));\n        else\n            throw new Error(`With a null YAML version, the { schema: Schema } option is required`);\n    }\n    // json & jsonArg are only used from toJSON()\n    toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {\n        const ctx = {\n            anchors: new Map(),\n            doc: this,\n            keep: !json,\n            mapAsMap: mapAsMap === true,\n            mapKeyWarned: false,\n            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100,\n            stringify: stringify$2\n        };\n        const res = toJS(this.contents, jsonArg ?? '', ctx);\n        if (typeof onAnchor === 'function')\n            for (const { count, res } of ctx.anchors.values())\n                onAnchor(res, count);\n        return typeof reviver === 'function'\n            ? applyReviver(reviver, { '': res }, '', res)\n            : res;\n    }\n    /**\n     * A JSON representation of the document `contents`.\n     *\n     * @param jsonArg Used by `JSON.stringify` to indicate the array index or\n     *   property name.\n     */\n    toJSON(jsonArg, onAnchor) {\n        return this.toJS({ json: true, jsonArg, mapAsMap: false, onAnchor });\n    }\n    /** A YAML representation of the document. */\n    toString(options = {}) {\n        if (this.errors.length > 0)\n            throw new Error('Document with errors cannot be stringified');\n        if ('indent' in options &&\n            (!Number.isInteger(options.indent) || Number(options.indent) <= 0)) {\n            const s = JSON.stringify(options.indent);\n            throw new Error(`\"indent\" option must be a positive integer, not ${s}`);\n        }\n        return stringifyDocument(this, options);\n    }\n}\nfunction assertCollection(contents) {\n    if (isCollection$1(contents))\n        return true;\n    throw new Error('Expected a YAML collection as document contents');\n}\n\nclass YAMLError extends Error {\n    constructor(name, pos, code, message) {\n        super();\n        this.name = name;\n        this.code = code;\n        this.message = message;\n        this.pos = pos;\n    }\n}\nclass YAMLParseError extends YAMLError {\n    constructor(pos, code, message) {\n        super('YAMLParseError', pos, code, message);\n    }\n}\nclass YAMLWarning extends YAMLError {\n    constructor(pos, code, message) {\n        super('YAMLWarning', pos, code, message);\n    }\n}\nconst prettifyError = (src, lc) => (error) => {\n    if (error.pos[0] === -1)\n        return;\n    error.linePos = error.pos.map(pos => lc.linePos(pos));\n    const { line, col } = error.linePos[0];\n    error.message += ` at line ${line}, column ${col}`;\n    let ci = col - 1;\n    let lineStr = src\n        .substring(lc.lineStarts[line - 1], lc.lineStarts[line])\n        .replace(/[\\n\\r]+$/, '');\n    // Trim to max 80 chars, keeping col position near the middle\n    if (ci >= 60 && lineStr.length > 80) {\n        const trimStart = Math.min(ci - 39, lineStr.length - 79);\n        lineStr = '…' + lineStr.substring(trimStart);\n        ci -= trimStart - 1;\n    }\n    if (lineStr.length > 80)\n        lineStr = lineStr.substring(0, 79) + '…';\n    // Include previous line in context if pointing at line start\n    if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {\n        // Regexp won't match if start is trimmed\n        let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1]);\n        if (prev.length > 80)\n            prev = prev.substring(0, 79) + '…\\n';\n        lineStr = prev + lineStr;\n    }\n    if (/[^ ]/.test(lineStr)) {\n        let count = 1;\n        const end = error.linePos[1];\n        if (end && end.line === line && end.col > col) {\n            count = Math.min(end.col - col, 80 - ci);\n        }\n        const pointer = ' '.repeat(ci) + '^'.repeat(count);\n        error.message += `:\\n\\n${lineStr}\\n${pointer}\\n`;\n    }\n};\n\nfunction resolveProps(tokens, { flow, indicator, next, offset, onError, startOnNewline }) {\n    let spaceBefore = false;\n    let atNewline = startOnNewline;\n    let hasSpace = startOnNewline;\n    let comment = '';\n    let commentSep = '';\n    let hasNewline = false;\n    let hasNewlineAfterProp = false;\n    let reqSpace = false;\n    let anchor = null;\n    let tag = null;\n    let comma = null;\n    let found = null;\n    let start = null;\n    for (const token of tokens) {\n        if (reqSpace) {\n            if (token.type !== 'space' &&\n                token.type !== 'newline' &&\n                token.type !== 'comma')\n                onError(token.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');\n            reqSpace = false;\n        }\n        switch (token.type) {\n            case 'space':\n                // At the doc level, tabs at line start may be parsed\n                // as leading white space rather than indentation.\n                // In a flow collection, only the parser handles indent.\n                if (!flow &&\n                    atNewline &&\n                    indicator !== 'doc-start' &&\n                    token.source[0] === '\\t')\n                    onError(token, 'TAB_AS_INDENT', 'Tabs are not allowed as indentation');\n                hasSpace = true;\n                break;\n            case 'comment': {\n                if (!hasSpace)\n                    onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');\n                const cb = token.source.substring(1) || ' ';\n                if (!comment)\n                    comment = cb;\n                else\n                    comment += commentSep + cb;\n                commentSep = '';\n                atNewline = false;\n                break;\n            }\n            case 'newline':\n                if (atNewline) {\n                    if (comment)\n                        comment += token.source;\n                    else\n                        spaceBefore = true;\n                }\n                else\n                    commentSep += token.source;\n                atNewline = true;\n                hasNewline = true;\n                if (anchor || tag)\n                    hasNewlineAfterProp = true;\n                hasSpace = true;\n                break;\n            case 'anchor':\n                if (anchor)\n                    onError(token, 'MULTIPLE_ANCHORS', 'A node can have at most one anchor');\n                if (token.source.endsWith(':'))\n                    onError(token.offset + token.source.length - 1, 'BAD_ALIAS', 'Anchor ending in : is ambiguous', true);\n                anchor = token;\n                if (start === null)\n                    start = token.offset;\n                atNewline = false;\n                hasSpace = false;\n                reqSpace = true;\n                break;\n            case 'tag': {\n                if (tag)\n                    onError(token, 'MULTIPLE_TAGS', 'A node can have at most one tag');\n                tag = token;\n                if (start === null)\n                    start = token.offset;\n                atNewline = false;\n                hasSpace = false;\n                reqSpace = true;\n                break;\n            }\n            case indicator:\n                // Could here handle preceding comments differently\n                if (anchor || tag)\n                    onError(token, 'BAD_PROP_ORDER', `Anchors and tags must be after the ${token.source} indicator`);\n                if (found)\n                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.source} in ${flow ?? 'collection'}`);\n                found = token;\n                atNewline = false;\n                hasSpace = false;\n                break;\n            case 'comma':\n                if (flow) {\n                    if (comma)\n                        onError(token, 'UNEXPECTED_TOKEN', `Unexpected , in ${flow}`);\n                    comma = token;\n                    atNewline = false;\n                    hasSpace = false;\n                    break;\n                }\n            // else fallthrough\n            default:\n                onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.type} token`);\n                atNewline = false;\n                hasSpace = false;\n        }\n    }\n    const last = tokens[tokens.length - 1];\n    const end = last ? last.offset + last.source.length : offset;\n    if (reqSpace &&\n        next &&\n        next.type !== 'space' &&\n        next.type !== 'newline' &&\n        next.type !== 'comma' &&\n        (next.type !== 'scalar' || next.source !== ''))\n        onError(next.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');\n    return {\n        comma,\n        found,\n        spaceBefore,\n        comment,\n        hasNewline,\n        hasNewlineAfterProp,\n        anchor,\n        tag,\n        end,\n        start: start ?? end\n    };\n}\n\nfunction containsNewline(key) {\n    if (!key)\n        return null;\n    switch (key.type) {\n        case 'alias':\n        case 'scalar':\n        case 'double-quoted-scalar':\n        case 'single-quoted-scalar':\n            if (key.source.includes('\\n'))\n                return true;\n            if (key.end)\n                for (const st of key.end)\n                    if (st.type === 'newline')\n                        return true;\n            return false;\n        case 'flow-collection':\n            for (const it of key.items) {\n                for (const st of it.start)\n                    if (st.type === 'newline')\n                        return true;\n                if (it.sep)\n                    for (const st of it.sep)\n                        if (st.type === 'newline')\n                            return true;\n                if (containsNewline(it.key) || containsNewline(it.value))\n                    return true;\n            }\n            return false;\n        default:\n            return true;\n    }\n}\n\nfunction flowIndentCheck(indent, fc, onError) {\n    if (fc?.type === 'flow-collection') {\n        const end = fc.end[0];\n        if (end.indent === indent &&\n            (end.source === ']' || end.source === '}') &&\n            containsNewline(fc)) {\n            const msg = 'Flow end indicator should be more indented than parent';\n            onError(end, 'BAD_INDENT', msg, true);\n        }\n    }\n}\n\nfunction mapIncludes(ctx, items, search) {\n    const { uniqueKeys } = ctx.options;\n    if (uniqueKeys === false)\n        return false;\n    const isEqual = typeof uniqueKeys === 'function'\n        ? uniqueKeys\n        : (a, b) => a === b ||\n            (isScalar$1(a) &&\n                isScalar$1(b) &&\n                a.value === b.value &&\n                !(a.value === '<<' && ctx.schema.merge));\n    return items.some(pair => isEqual(pair.key, search));\n}\n\nconst startColMsg = 'All mapping items must start at the same column';\nfunction resolveBlockMap({ composeNode, composeEmptyNode }, ctx, bm, onError) {\n    const map = new YAMLMap(ctx.schema);\n    if (ctx.atRoot)\n        ctx.atRoot = false;\n    let offset = bm.offset;\n    for (const collItem of bm.items) {\n        const { start, key, sep, value } = collItem;\n        // key properties\n        const keyProps = resolveProps(start, {\n            indicator: 'explicit-key-ind',\n            next: key ?? sep?.[0],\n            offset,\n            onError,\n            startOnNewline: true\n        });\n        const implicitKey = !keyProps.found;\n        if (implicitKey) {\n            if (key) {\n                if (key.type === 'block-seq')\n                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'A block sequence may not be used as an implicit map key');\n                else if ('indent' in key && key.indent !== bm.indent)\n                    onError(offset, 'BAD_INDENT', startColMsg);\n            }\n            if (!keyProps.anchor && !keyProps.tag && !sep) {\n                // TODO: assert being at last item?\n                if (keyProps.comment) {\n                    if (map.comment)\n                        map.comment += '\\n' + keyProps.comment;\n                    else\n                        map.comment = keyProps.comment;\n                }\n                continue;\n            }\n            if (keyProps.hasNewlineAfterProp || containsNewline(key)) {\n                onError(key ?? start[start.length - 1], 'MULTILINE_IMPLICIT_KEY', 'Implicit keys need to be on a single line');\n            }\n        }\n        else if (keyProps.found?.indent !== bm.indent) {\n            onError(offset, 'BAD_INDENT', startColMsg);\n        }\n        // key value\n        const keyStart = keyProps.end;\n        const keyNode = key\n            ? composeNode(ctx, key, keyProps, onError)\n            : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError);\n        if (ctx.schema.compat)\n            flowIndentCheck(bm.indent, key, onError);\n        if (mapIncludes(ctx, map.items, keyNode))\n            onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');\n        // value properties\n        const valueProps = resolveProps(sep ?? [], {\n            indicator: 'map-value-ind',\n            next: value,\n            offset: keyNode.range[2],\n            onError,\n            startOnNewline: !key || key.type === 'block-scalar'\n        });\n        offset = valueProps.end;\n        if (valueProps.found) {\n            if (implicitKey) {\n                if (value?.type === 'block-map' && !valueProps.hasNewline)\n                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'Nested mappings are not allowed in compact mappings');\n                if (ctx.options.strict &&\n                    keyProps.start < valueProps.found.offset - 1024)\n                    onError(keyNode.range, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit block mapping key');\n            }\n            // value value\n            const valueNode = value\n                ? composeNode(ctx, value, valueProps, onError)\n                : composeEmptyNode(ctx, offset, sep, null, valueProps, onError);\n            if (ctx.schema.compat)\n                flowIndentCheck(bm.indent, value, onError);\n            offset = valueNode.range[2];\n            const pair = new Pair(keyNode, valueNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            map.items.push(pair);\n        }\n        else {\n            // key with no value\n            if (implicitKey)\n                onError(keyNode.range, 'MISSING_CHAR', 'Implicit map keys need to be followed by map values');\n            if (valueProps.comment) {\n                if (keyNode.comment)\n                    keyNode.comment += '\\n' + valueProps.comment;\n                else\n                    keyNode.comment = valueProps.comment;\n            }\n            const pair = new Pair(keyNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            map.items.push(pair);\n        }\n    }\n    map.range = [bm.offset, offset, offset];\n    return map;\n}\n\nfunction resolveBlockSeq({ composeNode, composeEmptyNode }, ctx, bs, onError) {\n    const seq = new YAMLSeq(ctx.schema);\n    if (ctx.atRoot)\n        ctx.atRoot = false;\n    let offset = bs.offset;\n    for (const { start, value } of bs.items) {\n        const props = resolveProps(start, {\n            indicator: 'seq-item-ind',\n            next: value,\n            offset,\n            onError,\n            startOnNewline: true\n        });\n        offset = props.end;\n        if (!props.found) {\n            if (props.anchor || props.tag || value) {\n                if (value && value.type === 'block-seq')\n                    onError(offset, 'BAD_INDENT', 'All sequence items must start at the same column');\n                else\n                    onError(offset, 'MISSING_CHAR', 'Sequence item without - indicator');\n            }\n            else {\n                // TODO: assert being at last item?\n                if (props.comment)\n                    seq.comment = props.comment;\n                continue;\n            }\n        }\n        const node = value\n            ? composeNode(ctx, value, props, onError)\n            : composeEmptyNode(ctx, offset, start, null, props, onError);\n        if (ctx.schema.compat)\n            flowIndentCheck(bs.indent, value, onError);\n        offset = node.range[2];\n        seq.items.push(node);\n    }\n    seq.range = [bs.offset, offset, offset];\n    return seq;\n}\n\nfunction resolveEnd(end, offset, reqSpace, onError) {\n    let comment = '';\n    if (end) {\n        let hasSpace = false;\n        let sep = '';\n        for (const token of end) {\n            const { source, type } = token;\n            switch (type) {\n                case 'space':\n                    hasSpace = true;\n                    break;\n                case 'comment': {\n                    if (reqSpace && !hasSpace)\n                        onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');\n                    const cb = source.substring(1) || ' ';\n                    if (!comment)\n                        comment = cb;\n                    else\n                        comment += sep + cb;\n                    sep = '';\n                    break;\n                }\n                case 'newline':\n                    if (comment)\n                        sep += source;\n                    hasSpace = true;\n                    break;\n                default:\n                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${type} at node end`);\n            }\n            offset += source.length;\n        }\n    }\n    return { comment, offset };\n}\n\nconst blockMsg = 'Block collections are not allowed within flow collections';\nconst isBlock = (token) => token && (token.type === 'block-map' || token.type === 'block-seq');\nfunction resolveFlowCollection({ composeNode, composeEmptyNode }, ctx, fc, onError) {\n    const isMap = fc.start.source === '{';\n    const fcName = isMap ? 'flow map' : 'flow sequence';\n    const coll = isMap\n        ? new YAMLMap(ctx.schema)\n        : new YAMLSeq(ctx.schema);\n    coll.flow = true;\n    const atRoot = ctx.atRoot;\n    if (atRoot)\n        ctx.atRoot = false;\n    let offset = fc.offset + fc.start.source.length;\n    for (let i = 0; i < fc.items.length; ++i) {\n        const collItem = fc.items[i];\n        const { start, key, sep, value } = collItem;\n        const props = resolveProps(start, {\n            flow: fcName,\n            indicator: 'explicit-key-ind',\n            next: key ?? sep?.[0],\n            offset,\n            onError,\n            startOnNewline: false\n        });\n        if (!props.found) {\n            if (!props.anchor && !props.tag && !sep && !value) {\n                if (i === 0 && props.comma)\n                    onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);\n                else if (i < fc.items.length - 1)\n                    onError(props.start, 'UNEXPECTED_TOKEN', `Unexpected empty item in ${fcName}`);\n                if (props.comment) {\n                    if (coll.comment)\n                        coll.comment += '\\n' + props.comment;\n                    else\n                        coll.comment = props.comment;\n                }\n                offset = props.end;\n                continue;\n            }\n            if (!isMap && ctx.options.strict && containsNewline(key))\n                onError(key, // checked by containsNewline()\n                'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');\n        }\n        if (i === 0) {\n            if (props.comma)\n                onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);\n        }\n        else {\n            if (!props.comma)\n                onError(props.start, 'MISSING_CHAR', `Missing , between ${fcName} items`);\n            if (props.comment) {\n                let prevItemComment = '';\n                loop: for (const st of start) {\n                    switch (st.type) {\n                        case 'comma':\n                        case 'space':\n                            break;\n                        case 'comment':\n                            prevItemComment = st.source.substring(1);\n                            break loop;\n                        default:\n                            break loop;\n                    }\n                }\n                if (prevItemComment) {\n                    let prev = coll.items[coll.items.length - 1];\n                    if (isPair(prev))\n                        prev = prev.value ?? prev.key;\n                    if (prev.comment)\n                        prev.comment += '\\n' + prevItemComment;\n                    else\n                        prev.comment = prevItemComment;\n                    props.comment = props.comment.substring(prevItemComment.length + 1);\n                }\n            }\n        }\n        if (!isMap && !sep && !props.found) {\n            // item is a value in a seq\n            // → key & sep are empty, start does not include ? or :\n            const valueNode = value\n                ? composeNode(ctx, value, props, onError)\n                : composeEmptyNode(ctx, props.end, sep, null, props, onError);\n            coll.items.push(valueNode);\n            offset = valueNode.range[2];\n            if (isBlock(value))\n                onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);\n        }\n        else {\n            // item is a key+value pair\n            // key value\n            const keyStart = props.end;\n            const keyNode = key\n                ? composeNode(ctx, key, props, onError)\n                : composeEmptyNode(ctx, keyStart, start, null, props, onError);\n            if (isBlock(key))\n                onError(keyNode.range, 'BLOCK_IN_FLOW', blockMsg);\n            // value properties\n            const valueProps = resolveProps(sep ?? [], {\n                flow: fcName,\n                indicator: 'map-value-ind',\n                next: value,\n                offset: keyNode.range[2],\n                onError,\n                startOnNewline: false\n            });\n            if (valueProps.found) {\n                if (!isMap && !props.found && ctx.options.strict) {\n                    if (sep)\n                        for (const st of sep) {\n                            if (st === valueProps.found)\n                                break;\n                            if (st.type === 'newline') {\n                                onError(st, 'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');\n                                break;\n                            }\n                        }\n                    if (props.start < valueProps.found.offset - 1024)\n                        onError(valueProps.found, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit flow sequence key');\n                }\n            }\n            else if (value) {\n                if ('source' in value && value.source && value.source[0] === ':')\n                    onError(value, 'MISSING_CHAR', `Missing space after : in ${fcName}`);\n                else\n                    onError(valueProps.start, 'MISSING_CHAR', `Missing , or : between ${fcName} items`);\n            }\n            // value value\n            const valueNode = value\n                ? composeNode(ctx, value, valueProps, onError)\n                : valueProps.found\n                    ? composeEmptyNode(ctx, valueProps.end, sep, null, valueProps, onError)\n                    : null;\n            if (valueNode) {\n                if (isBlock(value))\n                    onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);\n            }\n            else if (valueProps.comment) {\n                if (keyNode.comment)\n                    keyNode.comment += '\\n' + valueProps.comment;\n                else\n                    keyNode.comment = valueProps.comment;\n            }\n            const pair = new Pair(keyNode, valueNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            if (isMap) {\n                const map = coll;\n                if (mapIncludes(ctx, map.items, keyNode))\n                    onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');\n                map.items.push(pair);\n            }\n            else {\n                const map = new YAMLMap(ctx.schema);\n                map.flow = true;\n                map.items.push(pair);\n                coll.items.push(map);\n            }\n            offset = valueNode ? valueNode.range[2] : valueProps.end;\n        }\n    }\n    const expectedEnd = isMap ? '}' : ']';\n    const [ce, ...ee] = fc.end;\n    let cePos = offset;\n    if (ce && ce.source === expectedEnd)\n        cePos = ce.offset + ce.source.length;\n    else {\n        const name = fcName[0].toUpperCase() + fcName.substring(1);\n        const msg = atRoot\n            ? `${name} must end with a ${expectedEnd}`\n            : `${name} in block collection must be sufficiently indented and end with a ${expectedEnd}`;\n        onError(offset, atRoot ? 'MISSING_CHAR' : 'BAD_INDENT', msg);\n        if (ce && ce.source.length !== 1)\n            ee.unshift(ce);\n    }\n    if (ee.length > 0) {\n        const end = resolveEnd(ee, cePos, ctx.options.strict, onError);\n        if (end.comment) {\n            if (coll.comment)\n                coll.comment += '\\n' + end.comment;\n            else\n                coll.comment = end.comment;\n        }\n        coll.range = [fc.offset, cePos, end.offset];\n    }\n    else {\n        coll.range = [fc.offset, cePos, cePos];\n    }\n    return coll;\n}\n\nfunction composeCollection(CN, ctx, token, tagToken, onError) {\n    let coll;\n    switch (token.type) {\n        case 'block-map': {\n            coll = resolveBlockMap(CN, ctx, token, onError);\n            break;\n        }\n        case 'block-seq': {\n            coll = resolveBlockSeq(CN, ctx, token, onError);\n            break;\n        }\n        case 'flow-collection': {\n            coll = resolveFlowCollection(CN, ctx, token, onError);\n            break;\n        }\n    }\n    if (!tagToken)\n        return coll;\n    const tagName = ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg));\n    if (!tagName)\n        return coll;\n    // Cast needed due to: https://github.com/Microsoft/TypeScript/issues/3841\n    const Coll = coll.constructor;\n    if (tagName === '!' || tagName === Coll.tagName) {\n        coll.tag = Coll.tagName;\n        return coll;\n    }\n    const expType = isMap(coll) ? 'map' : 'seq';\n    let tag = ctx.schema.tags.find(t => t.collection === expType && t.tag === tagName);\n    if (!tag) {\n        const kt = ctx.schema.knownTags[tagName];\n        if (kt && kt.collection === expType) {\n            ctx.schema.tags.push(Object.assign({}, kt, { default: false }));\n            tag = kt;\n        }\n        else {\n            onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, true);\n            coll.tag = tagName;\n            return coll;\n        }\n    }\n    const res = tag.resolve(coll, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg), ctx.options);\n    const node = isNode$1(res)\n        ? res\n        : new Scalar(res);\n    node.range = coll.range;\n    node.tag = tagName;\n    if (tag?.format)\n        node.format = tag.format;\n    return node;\n}\n\nfunction resolveBlockScalar(scalar, strict, onError) {\n    const start = scalar.offset;\n    const header = parseBlockScalarHeader(scalar, strict, onError);\n    if (!header)\n        return { value: '', type: null, comment: '', range: [start, start, start] };\n    const type = header.mode === '>' ? Scalar.BLOCK_FOLDED : Scalar.BLOCK_LITERAL;\n    const lines = scalar.source ? splitLines(scalar.source) : [];\n    // determine the end of content & start of chomping\n    let chompStart = lines.length;\n    for (let i = lines.length - 1; i >= 0; --i) {\n        const content = lines[i][1];\n        if (content === '' || content === '\\r')\n            chompStart = i;\n        else\n            break;\n    }\n    // shortcut for empty contents\n    if (chompStart === 0) {\n        const value = header.chomp === '+' && lines.length > 0\n            ? '\\n'.repeat(Math.max(1, lines.length - 1))\n            : '';\n        let end = start + header.length;\n        if (scalar.source)\n            end += scalar.source.length;\n        return { value, type, comment: header.comment, range: [start, end, end] };\n    }\n    // find the indentation level to trim from start\n    let trimIndent = scalar.indent + header.indent;\n    let offset = scalar.offset + header.length;\n    let contentStart = 0;\n    for (let i = 0; i < chompStart; ++i) {\n        const [indent, content] = lines[i];\n        if (content === '' || content === '\\r') {\n            if (header.indent === 0 && indent.length > trimIndent)\n                trimIndent = indent.length;\n        }\n        else {\n            if (indent.length < trimIndent) {\n                const message = 'Block scalars with more-indented leading empty lines must use an explicit indentation indicator';\n                onError(offset + indent.length, 'MISSING_CHAR', message);\n            }\n            if (header.indent === 0)\n                trimIndent = indent.length;\n            contentStart = i;\n            break;\n        }\n        offset += indent.length + content.length + 1;\n    }\n    // include trailing more-indented empty lines in content\n    for (let i = lines.length - 1; i >= chompStart; --i) {\n        if (lines[i][0].length > trimIndent)\n            chompStart = i + 1;\n    }\n    let value = '';\n    let sep = '';\n    let prevMoreIndented = false;\n    // leading whitespace is kept intact\n    for (let i = 0; i < contentStart; ++i)\n        value += lines[i][0].slice(trimIndent) + '\\n';\n    for (let i = contentStart; i < chompStart; ++i) {\n        let [indent, content] = lines[i];\n        offset += indent.length + content.length + 1;\n        const crlf = content[content.length - 1] === '\\r';\n        if (crlf)\n            content = content.slice(0, -1);\n        /* istanbul ignore if already caught in lexer */\n        if (content && indent.length < trimIndent) {\n            const src = header.indent\n                ? 'explicit indentation indicator'\n                : 'first line';\n            const message = `Block scalar lines must not be less indented than their ${src}`;\n            onError(offset - content.length - (crlf ? 2 : 1), 'BAD_INDENT', message);\n            indent = '';\n        }\n        if (type === Scalar.BLOCK_LITERAL) {\n            value += sep + indent.slice(trimIndent) + content;\n            sep = '\\n';\n        }\n        else if (indent.length > trimIndent || content[0] === '\\t') {\n            // more-indented content within a folded block\n            if (sep === ' ')\n                sep = '\\n';\n            else if (!prevMoreIndented && sep === '\\n')\n                sep = '\\n\\n';\n            value += sep + indent.slice(trimIndent) + content;\n            sep = '\\n';\n            prevMoreIndented = true;\n        }\n        else if (content === '') {\n            // empty line\n            if (sep === '\\n')\n                value += '\\n';\n            else\n                sep = '\\n';\n        }\n        else {\n            value += sep + content;\n            sep = ' ';\n            prevMoreIndented = false;\n        }\n    }\n    switch (header.chomp) {\n        case '-':\n            break;\n        case '+':\n            for (let i = chompStart; i < lines.length; ++i)\n                value += '\\n' + lines[i][0].slice(trimIndent);\n            if (value[value.length - 1] !== '\\n')\n                value += '\\n';\n            break;\n        default:\n            value += '\\n';\n    }\n    const end = start + header.length + scalar.source.length;\n    return { value, type, comment: header.comment, range: [start, end, end] };\n}\nfunction parseBlockScalarHeader({ offset, props }, strict, onError) {\n    /* istanbul ignore if should not happen */\n    if (props[0].type !== 'block-scalar-header') {\n        onError(props[0], 'IMPOSSIBLE', 'Block scalar header not found');\n        return null;\n    }\n    const { source } = props[0];\n    const mode = source[0];\n    let indent = 0;\n    let chomp = '';\n    let error = -1;\n    for (let i = 1; i < source.length; ++i) {\n        const ch = source[i];\n        if (!chomp && (ch === '-' || ch === '+'))\n            chomp = ch;\n        else {\n            const n = Number(ch);\n            if (!indent && n)\n                indent = n;\n            else if (error === -1)\n                error = offset + i;\n        }\n    }\n    if (error !== -1)\n        onError(error, 'UNEXPECTED_TOKEN', `Block scalar header includes extra characters: ${source}`);\n    let hasSpace = false;\n    let comment = '';\n    let length = source.length;\n    for (let i = 1; i < props.length; ++i) {\n        const token = props[i];\n        switch (token.type) {\n            case 'space':\n                hasSpace = true;\n            // fallthrough\n            case 'newline':\n                length += token.source.length;\n                break;\n            case 'comment':\n                if (strict && !hasSpace) {\n                    const message = 'Comments must be separated from other tokens by white space characters';\n                    onError(token, 'MISSING_CHAR', message);\n                }\n                length += token.source.length;\n                comment = token.source.substring(1);\n                break;\n            case 'error':\n                onError(token, 'UNEXPECTED_TOKEN', token.message);\n                length += token.source.length;\n                break;\n            /* istanbul ignore next should not happen */\n            default: {\n                const message = `Unexpected token in block scalar header: ${token.type}`;\n                onError(token, 'UNEXPECTED_TOKEN', message);\n                const ts = token.source;\n                if (ts && typeof ts === 'string')\n                    length += ts.length;\n            }\n        }\n    }\n    return { mode, indent, chomp, comment, length };\n}\n/** @returns Array of lines split up as `[indent, content]` */\nfunction splitLines(source) {\n    const split = source.split(/\\n( *)/);\n    const first = split[0];\n    const m = first.match(/^( *)/);\n    const line0 = m?.[1]\n        ? [m[1], first.slice(m[1].length)]\n        : ['', first];\n    const lines = [line0];\n    for (let i = 1; i < split.length; i += 2)\n        lines.push([split[i], split[i + 1]]);\n    return lines;\n}\n\nfunction resolveFlowScalar(scalar, strict, onError) {\n    const { offset, type, source, end } = scalar;\n    let _type;\n    let value;\n    const _onError = (rel, code, msg) => onError(offset + rel, code, msg);\n    switch (type) {\n        case 'scalar':\n            _type = Scalar.PLAIN;\n            value = plainValue(source, _onError);\n            break;\n        case 'single-quoted-scalar':\n            _type = Scalar.QUOTE_SINGLE;\n            value = singleQuotedValue(source, _onError);\n            break;\n        case 'double-quoted-scalar':\n            _type = Scalar.QUOTE_DOUBLE;\n            value = doubleQuotedValue(source, _onError);\n            break;\n        /* istanbul ignore next should not happen */\n        default:\n            onError(scalar, 'UNEXPECTED_TOKEN', `Expected a flow scalar value, but found: ${type}`);\n            return {\n                value: '',\n                type: null,\n                comment: '',\n                range: [offset, offset + source.length, offset + source.length]\n            };\n    }\n    const valueEnd = offset + source.length;\n    const re = resolveEnd(end, valueEnd, strict, onError);\n    return {\n        value,\n        type: _type,\n        comment: re.comment,\n        range: [offset, valueEnd, re.offset]\n    };\n}\nfunction plainValue(source, onError) {\n    let badChar = '';\n    switch (source[0]) {\n        /* istanbul ignore next should not happen */\n        case '\\t':\n            badChar = 'a tab character';\n            break;\n        case ',':\n            badChar = 'flow indicator character ,';\n            break;\n        case '%':\n            badChar = 'directive indicator character %';\n            break;\n        case '|':\n        case '>': {\n            badChar = `block scalar indicator ${source[0]}`;\n            break;\n        }\n        case '@':\n        case '`': {\n            badChar = `reserved character ${source[0]}`;\n            break;\n        }\n    }\n    if (badChar)\n        onError(0, 'BAD_SCALAR_START', `Plain value cannot start with ${badChar}`);\n    return foldLines(source);\n}\nfunction singleQuotedValue(source, onError) {\n    if (source[source.length - 1] !== \"'\" || source.length === 1)\n        onError(source.length, 'MISSING_CHAR', \"Missing closing 'quote\");\n    return foldLines(source.slice(1, -1)).replace(/''/g, \"'\");\n}\nfunction foldLines(source) {\n    /**\n     * The negative lookbehind here and in the `re` RegExp is to\n     * prevent causing a polynomial search time in certain cases.\n     *\n     * The try-catch is for Safari, which doesn't support this yet:\n     * https://caniuse.com/js-regexp-lookbehind\n     */\n    let first, line;\n    try {\n        first = new RegExp('(.*?)(?<![ \\t])[ \\t]*\\r?\\n', 'sy');\n        line = new RegExp('[ \\t]*(.*?)(?:(?<![ \\t])[ \\t]*)?\\r?\\n', 'sy');\n    }\n    catch (_) {\n        first = /(.*?)[ \\t]*\\r?\\n/sy;\n        line = /[ \\t]*(.*?)[ \\t]*\\r?\\n/sy;\n    }\n    let match = first.exec(source);\n    if (!match)\n        return source;\n    let res = match[1];\n    let sep = ' ';\n    let pos = first.lastIndex;\n    line.lastIndex = pos;\n    while ((match = line.exec(source))) {\n        if (match[1] === '') {\n            if (sep === '\\n')\n                res += sep;\n            else\n                sep = '\\n';\n        }\n        else {\n            res += sep + match[1];\n            sep = ' ';\n        }\n        pos = line.lastIndex;\n    }\n    const last = /[ \\t]*(.*)/sy;\n    last.lastIndex = pos;\n    match = last.exec(source);\n    return res + sep + (match?.[1] ?? '');\n}\nfunction doubleQuotedValue(source, onError) {\n    let res = '';\n    for (let i = 1; i < source.length - 1; ++i) {\n        const ch = source[i];\n        if (ch === '\\r' && source[i + 1] === '\\n')\n            continue;\n        if (ch === '\\n') {\n            const { fold, offset } = foldNewline(source, i);\n            res += fold;\n            i = offset;\n        }\n        else if (ch === '\\\\') {\n            let next = source[++i];\n            const cc = escapeCodes[next];\n            if (cc)\n                res += cc;\n            else if (next === '\\n') {\n                // skip escaped newlines, but still trim the following line\n                next = source[i + 1];\n                while (next === ' ' || next === '\\t')\n                    next = source[++i + 1];\n            }\n            else if (next === '\\r' && source[i + 1] === '\\n') {\n                // skip escaped CRLF newlines, but still trim the following line\n                next = source[++i + 1];\n                while (next === ' ' || next === '\\t')\n                    next = source[++i + 1];\n            }\n            else if (next === 'x' || next === 'u' || next === 'U') {\n                const length = { x: 2, u: 4, U: 8 }[next];\n                res += parseCharCode(source, i + 1, length, onError);\n                i += length;\n            }\n            else {\n                const raw = source.substr(i - 1, 2);\n                onError(i - 1, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);\n                res += raw;\n            }\n        }\n        else if (ch === ' ' || ch === '\\t') {\n            // trim trailing whitespace\n            const wsStart = i;\n            let next = source[i + 1];\n            while (next === ' ' || next === '\\t')\n                next = source[++i + 1];\n            if (next !== '\\n' && !(next === '\\r' && source[i + 2] === '\\n'))\n                res += i > wsStart ? source.slice(wsStart, i + 1) : ch;\n        }\n        else {\n            res += ch;\n        }\n    }\n    if (source[source.length - 1] !== '\"' || source.length === 1)\n        onError(source.length, 'MISSING_CHAR', 'Missing closing \"quote');\n    return res;\n}\n/**\n * Fold a single newline into a space, multiple newlines to N - 1 newlines.\n * Presumes `source[offset] === '\\n'`\n */\nfunction foldNewline(source, offset) {\n    let fold = '';\n    let ch = source[offset + 1];\n    while (ch === ' ' || ch === '\\t' || ch === '\\n' || ch === '\\r') {\n        if (ch === '\\r' && source[offset + 2] !== '\\n')\n            break;\n        if (ch === '\\n')\n            fold += '\\n';\n        offset += 1;\n        ch = source[offset + 1];\n    }\n    if (!fold)\n        fold = ' ';\n    return { fold, offset };\n}\nconst escapeCodes = {\n    '0': '\\0',\n    a: '\\x07',\n    b: '\\b',\n    e: '\\x1b',\n    f: '\\f',\n    n: '\\n',\n    r: '\\r',\n    t: '\\t',\n    v: '\\v',\n    N: '\\u0085',\n    _: '\\u00a0',\n    L: '\\u2028',\n    P: '\\u2029',\n    ' ': ' ',\n    '\"': '\"',\n    '/': '/',\n    '\\\\': '\\\\',\n    '\\t': '\\t'\n};\nfunction parseCharCode(source, offset, length, onError) {\n    const cc = source.substr(offset, length);\n    const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc);\n    const code = ok ? parseInt(cc, 16) : NaN;\n    if (isNaN(code)) {\n        const raw = source.substr(offset - 2, length + 2);\n        onError(offset - 2, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);\n        return raw;\n    }\n    return String.fromCodePoint(code);\n}\n\nfunction composeScalar(ctx, token, tagToken, onError) {\n    const { value, type, comment, range } = token.type === 'block-scalar'\n        ? resolveBlockScalar(token, ctx.options.strict, onError)\n        : resolveFlowScalar(token, ctx.options.strict, onError);\n    const tagName = tagToken\n        ? ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg))\n        : null;\n    const tag = tagToken && tagName\n        ? findScalarTagByName(ctx.schema, value, tagName, tagToken, onError)\n        : token.type === 'scalar'\n            ? findScalarTagByTest(ctx, value, token, onError)\n            : ctx.schema[SCALAR$1];\n    let scalar;\n    try {\n        const res = tag.resolve(value, msg => onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg), ctx.options);\n        scalar = isScalar$1(res) ? res : new Scalar(res);\n    }\n    catch (error) {\n        const msg = error instanceof Error ? error.message : String(error);\n        onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg);\n        scalar = new Scalar(value);\n    }\n    scalar.range = range;\n    scalar.source = value;\n    if (type)\n        scalar.type = type;\n    if (tagName)\n        scalar.tag = tagName;\n    if (tag.format)\n        scalar.format = tag.format;\n    if (comment)\n        scalar.comment = comment;\n    return scalar;\n}\nfunction findScalarTagByName(schema, value, tagName, tagToken, onError) {\n    if (tagName === '!')\n        return schema[SCALAR$1]; // non-specific tag\n    const matchWithTest = [];\n    for (const tag of schema.tags) {\n        if (!tag.collection && tag.tag === tagName) {\n            if (tag.default && tag.test)\n                matchWithTest.push(tag);\n            else\n                return tag;\n        }\n    }\n    for (const tag of matchWithTest)\n        if (tag.test?.test(value))\n            return tag;\n    const kt = schema.knownTags[tagName];\n    if (kt && !kt.collection) {\n        // Ensure that the known tag is available for stringifying,\n        // but does not get used by default.\n        schema.tags.push(Object.assign({}, kt, { default: false, test: undefined }));\n        return kt;\n    }\n    onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, tagName !== 'tag:yaml.org,2002:str');\n    return schema[SCALAR$1];\n}\nfunction findScalarTagByTest({ directives, schema }, value, token, onError) {\n    const tag = schema.tags.find(tag => tag.default && tag.test?.test(value)) || schema[SCALAR$1];\n    if (schema.compat) {\n        const compat = schema.compat.find(tag => tag.default && tag.test?.test(value)) ??\n            schema[SCALAR$1];\n        if (tag.tag !== compat.tag) {\n            const ts = directives.tagString(tag.tag);\n            const cs = directives.tagString(compat.tag);\n            const msg = `Value may be parsed as either ${ts} or ${cs}`;\n            onError(token, 'TAG_RESOLVE_FAILED', msg, true);\n        }\n    }\n    return tag;\n}\n\nfunction emptyScalarPosition(offset, before, pos) {\n    if (before) {\n        if (pos === null)\n            pos = before.length;\n        for (let i = pos - 1; i >= 0; --i) {\n            let st = before[i];\n            switch (st.type) {\n                case 'space':\n                case 'comment':\n                case 'newline':\n                    offset -= st.source.length;\n                    continue;\n            }\n            // Technically, an empty scalar is immediately after the last non-empty\n            // node, but it's more useful to place it after any whitespace.\n            st = before[++i];\n            while (st?.type === 'space') {\n                offset += st.source.length;\n                st = before[++i];\n            }\n            break;\n        }\n    }\n    return offset;\n}\n\nconst CN = { composeNode, composeEmptyNode };\nfunction composeNode(ctx, token, props, onError) {\n    const { spaceBefore, comment, anchor, tag } = props;\n    let node;\n    let isSrcToken = true;\n    switch (token.type) {\n        case 'alias':\n            node = composeAlias(ctx, token, onError);\n            if (anchor || tag)\n                onError(token, 'ALIAS_PROPS', 'An alias node must not specify any properties');\n            break;\n        case 'scalar':\n        case 'single-quoted-scalar':\n        case 'double-quoted-scalar':\n        case 'block-scalar':\n            node = composeScalar(ctx, token, tag, onError);\n            if (anchor)\n                node.anchor = anchor.source.substring(1);\n            break;\n        case 'block-map':\n        case 'block-seq':\n        case 'flow-collection':\n            node = composeCollection(CN, ctx, token, tag, onError);\n            if (anchor)\n                node.anchor = anchor.source.substring(1);\n            break;\n        default: {\n            const message = token.type === 'error'\n                ? token.message\n                : `Unsupported token (type: ${token.type})`;\n            onError(token, 'UNEXPECTED_TOKEN', message);\n            node = composeEmptyNode(ctx, token.offset, undefined, null, props, onError);\n            isSrcToken = false;\n        }\n    }\n    if (anchor && node.anchor === '')\n        onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');\n    if (spaceBefore)\n        node.spaceBefore = true;\n    if (comment) {\n        if (token.type === 'scalar' && token.source === '')\n            node.comment = comment;\n        else\n            node.commentBefore = comment;\n    }\n    // @ts-expect-error Type checking misses meaning of isSrcToken\n    if (ctx.options.keepSourceTokens && isSrcToken)\n        node.srcToken = token;\n    return node;\n}\nfunction composeEmptyNode(ctx, offset, before, pos, { spaceBefore, comment, anchor, tag }, onError) {\n    const token = {\n        type: 'scalar',\n        offset: emptyScalarPosition(offset, before, pos),\n        indent: -1,\n        source: ''\n    };\n    const node = composeScalar(ctx, token, tag, onError);\n    if (anchor) {\n        node.anchor = anchor.source.substring(1);\n        if (node.anchor === '')\n            onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');\n    }\n    if (spaceBefore)\n        node.spaceBefore = true;\n    if (comment)\n        node.comment = comment;\n    return node;\n}\nfunction composeAlias({ options }, { offset, source, end }, onError) {\n    const alias = new Alias(source.substring(1));\n    if (alias.source === '')\n        onError(offset, 'BAD_ALIAS', 'Alias cannot be an empty string');\n    if (alias.source.endsWith(':'))\n        onError(offset + source.length - 1, 'BAD_ALIAS', 'Alias ending in : is ambiguous', true);\n    const valueEnd = offset + source.length;\n    const re = resolveEnd(end, valueEnd, options.strict, onError);\n    alias.range = [offset, valueEnd, re.offset];\n    if (re.comment)\n        alias.comment = re.comment;\n    return alias;\n}\n\nfunction composeDoc(options, directives, { offset, start, value, end }, onError) {\n    const opts = Object.assign({ _directives: directives }, options);\n    const doc = new Document(undefined, opts);\n    const ctx = {\n        atRoot: true,\n        directives: doc.directives,\n        options: doc.options,\n        schema: doc.schema\n    };\n    const props = resolveProps(start, {\n        indicator: 'doc-start',\n        next: value ?? end?.[0],\n        offset,\n        onError,\n        startOnNewline: true\n    });\n    if (props.found) {\n        doc.directives.docStart = true;\n        if (value &&\n            (value.type === 'block-map' || value.type === 'block-seq') &&\n            !props.hasNewline)\n            onError(props.end, 'MISSING_CHAR', 'Block collection cannot start on same line with directives-end marker');\n    }\n    doc.contents = value\n        ? composeNode(ctx, value, props, onError)\n        : composeEmptyNode(ctx, props.end, start, null, props, onError);\n    const contentEnd = doc.contents.range[2];\n    const re = resolveEnd(end, contentEnd, false, onError);\n    if (re.comment)\n        doc.comment = re.comment;\n    doc.range = [offset, contentEnd, re.offset];\n    return doc;\n}\n\nfunction getErrorPos(src) {\n    if (typeof src === 'number')\n        return [src, src + 1];\n    if (Array.isArray(src))\n        return src.length === 2 ? src : [src[0], src[1]];\n    const { offset, source } = src;\n    return [offset, offset + (typeof source === 'string' ? source.length : 1)];\n}\nfunction parsePrelude(prelude) {\n    let comment = '';\n    let atComment = false;\n    let afterEmptyLine = false;\n    for (let i = 0; i < prelude.length; ++i) {\n        const source = prelude[i];\n        switch (source[0]) {\n            case '#':\n                comment +=\n                    (comment === '' ? '' : afterEmptyLine ? '\\n\\n' : '\\n') +\n                        (source.substring(1) || ' ');\n                atComment = true;\n                afterEmptyLine = false;\n                break;\n            case '%':\n                if (prelude[i + 1]?.[0] !== '#')\n                    i += 1;\n                atComment = false;\n                break;\n            default:\n                // This may be wrong after doc-end, but in that case it doesn't matter\n                if (!atComment)\n                    afterEmptyLine = true;\n                atComment = false;\n        }\n    }\n    return { comment, afterEmptyLine };\n}\n/**\n * Compose a stream of CST nodes into a stream of YAML Documents.\n *\n * ```ts\n * import { Composer, Parser } from 'yaml'\n *\n * const src: string = ...\n * const tokens = new Parser().parse(src)\n * const docs = new Composer().compose(tokens)\n * ```\n */\nclass Composer {\n    constructor(options = {}) {\n        this.doc = null;\n        this.atDirectives = false;\n        this.prelude = [];\n        this.errors = [];\n        this.warnings = [];\n        this.onError = (source, code, message, warning) => {\n            const pos = getErrorPos(source);\n            if (warning)\n                this.warnings.push(new YAMLWarning(pos, code, message));\n            else\n                this.errors.push(new YAMLParseError(pos, code, message));\n        };\n        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n        this.directives = new Directives({ version: options.version || '1.2' });\n        this.options = options;\n    }\n    decorate(doc, afterDoc) {\n        const { comment, afterEmptyLine } = parsePrelude(this.prelude);\n        //console.log({ dc: doc.comment, prelude, comment })\n        if (comment) {\n            const dc = doc.contents;\n            if (afterDoc) {\n                doc.comment = doc.comment ? `${doc.comment}\\n${comment}` : comment;\n            }\n            else if (afterEmptyLine || doc.directives.docStart || !dc) {\n                doc.commentBefore = comment;\n            }\n            else if (isCollection$1(dc) && !dc.flow && dc.items.length > 0) {\n                let it = dc.items[0];\n                if (isPair(it))\n                    it = it.key;\n                const cb = it.commentBefore;\n                it.commentBefore = cb ? `${comment}\\n${cb}` : comment;\n            }\n            else {\n                const cb = dc.commentBefore;\n                dc.commentBefore = cb ? `${comment}\\n${cb}` : comment;\n            }\n        }\n        if (afterDoc) {\n            Array.prototype.push.apply(doc.errors, this.errors);\n            Array.prototype.push.apply(doc.warnings, this.warnings);\n        }\n        else {\n            doc.errors = this.errors;\n            doc.warnings = this.warnings;\n        }\n        this.prelude = [];\n        this.errors = [];\n        this.warnings = [];\n    }\n    /**\n     * Current stream status information.\n     *\n     * Mostly useful at the end of input for an empty stream.\n     */\n    streamInfo() {\n        return {\n            comment: parsePrelude(this.prelude).comment,\n            directives: this.directives,\n            errors: this.errors,\n            warnings: this.warnings\n        };\n    }\n    /**\n     * Compose tokens into documents.\n     *\n     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.\n     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n     */\n    *compose(tokens, forceDoc = false, endOffset = -1) {\n        for (const token of tokens)\n            yield* this.next(token);\n        yield* this.end(forceDoc, endOffset);\n    }\n    /** Advance the composer by one CST token. */\n    *next(token) {\n        switch (token.type) {\n            case 'directive':\n                this.directives.add(token.source, (offset, message, warning) => {\n                    const pos = getErrorPos(token);\n                    pos[0] += offset;\n                    this.onError(pos, 'BAD_DIRECTIVE', message, warning);\n                });\n                this.prelude.push(token.source);\n                this.atDirectives = true;\n                break;\n            case 'document': {\n                const doc = composeDoc(this.options, this.directives, token, this.onError);\n                if (this.atDirectives && !doc.directives.docStart)\n                    this.onError(token, 'MISSING_CHAR', 'Missing directives-end/doc-start indicator line');\n                this.decorate(doc, false);\n                if (this.doc)\n                    yield this.doc;\n                this.doc = doc;\n                this.atDirectives = false;\n                break;\n            }\n            case 'byte-order-mark':\n            case 'space':\n                break;\n            case 'comment':\n            case 'newline':\n                this.prelude.push(token.source);\n                break;\n            case 'error': {\n                const msg = token.source\n                    ? `${token.message}: ${JSON.stringify(token.source)}`\n                    : token.message;\n                const error = new YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg);\n                if (this.atDirectives || !this.doc)\n                    this.errors.push(error);\n                else\n                    this.doc.errors.push(error);\n                break;\n            }\n            case 'doc-end': {\n                if (!this.doc) {\n                    const msg = 'Unexpected doc-end without preceding document';\n                    this.errors.push(new YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg));\n                    break;\n                }\n                this.doc.directives.docEnd = true;\n                const end = resolveEnd(token.end, token.offset + token.source.length, this.doc.options.strict, this.onError);\n                this.decorate(this.doc, true);\n                if (end.comment) {\n                    const dc = this.doc.comment;\n                    this.doc.comment = dc ? `${dc}\\n${end.comment}` : end.comment;\n                }\n                this.doc.range[2] = end.offset;\n                break;\n            }\n            default:\n                this.errors.push(new YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', `Unsupported token ${token.type}`));\n        }\n    }\n    /**\n     * Call at end of input to yield any remaining document.\n     *\n     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.\n     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n     */\n    *end(forceDoc = false, endOffset = -1) {\n        if (this.doc) {\n            this.decorate(this.doc, true);\n            yield this.doc;\n            this.doc = null;\n        }\n        else if (forceDoc) {\n            const opts = Object.assign({ _directives: this.directives }, this.options);\n            const doc = new Document(undefined, opts);\n            if (this.atDirectives)\n                this.onError(endOffset, 'MISSING_CHAR', 'Missing directives-end indicator line');\n            doc.range = [0, endOffset, endOffset];\n            this.decorate(doc, false);\n            yield doc;\n        }\n    }\n}\n\nfunction resolveAsScalar(token, strict = true, onError) {\n    if (token) {\n        const _onError = (pos, code, message) => {\n            const offset = typeof pos === 'number' ? pos : Array.isArray(pos) ? pos[0] : pos.offset;\n            if (onError)\n                onError(offset, code, message);\n            else\n                throw new YAMLParseError([offset, offset + 1], code, message);\n        };\n        switch (token.type) {\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return resolveFlowScalar(token, strict, _onError);\n            case 'block-scalar':\n                return resolveBlockScalar(token, strict, _onError);\n        }\n    }\n    return null;\n}\n/**\n * Create a new scalar token with `value`\n *\n * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,\n * as this function does not support any schema operations and won't check for such conflicts.\n *\n * @param value The string representation of the value, which will have its content properly indented.\n * @param context.end Comments and whitespace after the end of the value, or after the block scalar header. If undefined, a newline will be added.\n * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.\n * @param context.indent The indent level of the token.\n * @param context.inFlow Is this scalar within a flow collection? This may affect the resolved type of the token's value.\n * @param context.offset The offset position of the token.\n * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.\n */\nfunction createScalarToken(value, context) {\n    const { implicitKey = false, indent, inFlow = false, offset = -1, type = 'PLAIN' } = context;\n    const source = stringifyString({ type, value }, {\n        implicitKey,\n        indent: indent > 0 ? ' '.repeat(indent) : '',\n        inFlow,\n        options: { blockQuote: true, lineWidth: -1 }\n    });\n    const end = context.end ?? [\n        { type: 'newline', offset: -1, indent, source: '\\n' }\n    ];\n    switch (source[0]) {\n        case '|':\n        case '>': {\n            const he = source.indexOf('\\n');\n            const head = source.substring(0, he);\n            const body = source.substring(he + 1) + '\\n';\n            const props = [\n                { type: 'block-scalar-header', offset, indent, source: head }\n            ];\n            if (!addEndtoBlockProps(props, end))\n                props.push({ type: 'newline', offset: -1, indent, source: '\\n' });\n            return { type: 'block-scalar', offset, indent, props, source: body };\n        }\n        case '\"':\n            return { type: 'double-quoted-scalar', offset, indent, source, end };\n        case \"'\":\n            return { type: 'single-quoted-scalar', offset, indent, source, end };\n        default:\n            return { type: 'scalar', offset, indent, source, end };\n    }\n}\n/**\n * Set the value of `token` to the given string `value`, overwriting any previous contents and type that it may have.\n *\n * Best efforts are made to retain any comments previously associated with the `token`,\n * though all contents within a collection's `items` will be overwritten.\n *\n * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,\n * as this function does not support any schema operations and won't check for such conflicts.\n *\n * @param token Any token. If it does not include an `indent` value, the value will be stringified as if it were an implicit key.\n * @param value The string representation of the value, which will have its content properly indented.\n * @param context.afterKey In most cases, values after a key should have an additional level of indentation.\n * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.\n * @param context.inFlow Being within a flow collection may affect the resolved type of the token's value.\n * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.\n */\nfunction setScalarValue(token, value, context = {}) {\n    let { afterKey = false, implicitKey = false, inFlow = false, type } = context;\n    let indent = 'indent' in token ? token.indent : null;\n    if (afterKey && typeof indent === 'number')\n        indent += 2;\n    if (!type)\n        switch (token.type) {\n            case 'single-quoted-scalar':\n                type = 'QUOTE_SINGLE';\n                break;\n            case 'double-quoted-scalar':\n                type = 'QUOTE_DOUBLE';\n                break;\n            case 'block-scalar': {\n                const header = token.props[0];\n                if (header.type !== 'block-scalar-header')\n                    throw new Error('Invalid block scalar header');\n                type = header.source[0] === '>' ? 'BLOCK_FOLDED' : 'BLOCK_LITERAL';\n                break;\n            }\n            default:\n                type = 'PLAIN';\n        }\n    const source = stringifyString({ type, value }, {\n        implicitKey: implicitKey || indent === null,\n        indent: indent !== null && indent > 0 ? ' '.repeat(indent) : '',\n        inFlow,\n        options: { blockQuote: true, lineWidth: -1 }\n    });\n    switch (source[0]) {\n        case '|':\n        case '>':\n            setBlockScalarValue(token, source);\n            break;\n        case '\"':\n            setFlowScalarValue(token, source, 'double-quoted-scalar');\n            break;\n        case \"'\":\n            setFlowScalarValue(token, source, 'single-quoted-scalar');\n            break;\n        default:\n            setFlowScalarValue(token, source, 'scalar');\n    }\n}\nfunction setBlockScalarValue(token, source) {\n    const he = source.indexOf('\\n');\n    const head = source.substring(0, he);\n    const body = source.substring(he + 1) + '\\n';\n    if (token.type === 'block-scalar') {\n        const header = token.props[0];\n        if (header.type !== 'block-scalar-header')\n            throw new Error('Invalid block scalar header');\n        header.source = head;\n        token.source = body;\n    }\n    else {\n        const { offset } = token;\n        const indent = 'indent' in token ? token.indent : -1;\n        const props = [\n            { type: 'block-scalar-header', offset, indent, source: head }\n        ];\n        if (!addEndtoBlockProps(props, 'end' in token ? token.end : undefined))\n            props.push({ type: 'newline', offset: -1, indent, source: '\\n' });\n        for (const key of Object.keys(token))\n            if (key !== 'type' && key !== 'offset')\n                delete token[key];\n        Object.assign(token, { type: 'block-scalar', indent, props, source: body });\n    }\n}\n/** @returns `true` if last token is a newline */\nfunction addEndtoBlockProps(props, end) {\n    if (end)\n        for (const st of end)\n            switch (st.type) {\n                case 'space':\n                case 'comment':\n                    props.push(st);\n                    break;\n                case 'newline':\n                    props.push(st);\n                    return true;\n            }\n    return false;\n}\nfunction setFlowScalarValue(token, source, type) {\n    switch (token.type) {\n        case 'scalar':\n        case 'double-quoted-scalar':\n        case 'single-quoted-scalar':\n            token.type = type;\n            token.source = source;\n            break;\n        case 'block-scalar': {\n            const end = token.props.slice(1);\n            let oa = source.length;\n            if (token.props[0].type === 'block-scalar-header')\n                oa -= token.props[0].source.length;\n            for (const tok of end)\n                tok.offset += oa;\n            delete token.props;\n            Object.assign(token, { type, source, end });\n            break;\n        }\n        case 'block-map':\n        case 'block-seq': {\n            const offset = token.offset + source.length;\n            const nl = { type: 'newline', offset, indent: token.indent, source: '\\n' };\n            delete token.items;\n            Object.assign(token, { type, source, end: [nl] });\n            break;\n        }\n        default: {\n            const indent = 'indent' in token ? token.indent : -1;\n            const end = 'end' in token && Array.isArray(token.end)\n                ? token.end.filter(st => st.type === 'space' ||\n                    st.type === 'comment' ||\n                    st.type === 'newline')\n                : [];\n            for (const key of Object.keys(token))\n                if (key !== 'type' && key !== 'offset')\n                    delete token[key];\n            Object.assign(token, { type, indent, source, end });\n        }\n    }\n}\n\n/**\n * Stringify a CST document, token, or collection item\n *\n * Fair warning: This applies no validation whatsoever, and\n * simply concatenates the sources in their logical order.\n */\nconst stringify$1 = (cst) => 'type' in cst ? stringifyToken(cst) : stringifyItem(cst);\nfunction stringifyToken(token) {\n    switch (token.type) {\n        case 'block-scalar': {\n            let res = '';\n            for (const tok of token.props)\n                res += stringifyToken(tok);\n            return res + token.source;\n        }\n        case 'block-map':\n        case 'block-seq': {\n            let res = '';\n            for (const item of token.items)\n                res += stringifyItem(item);\n            return res;\n        }\n        case 'flow-collection': {\n            let res = token.start.source;\n            for (const item of token.items)\n                res += stringifyItem(item);\n            for (const st of token.end)\n                res += st.source;\n            return res;\n        }\n        case 'document': {\n            let res = stringifyItem(token);\n            if (token.end)\n                for (const st of token.end)\n                    res += st.source;\n            return res;\n        }\n        default: {\n            let res = token.source;\n            if ('end' in token && token.end)\n                for (const st of token.end)\n                    res += st.source;\n            return res;\n        }\n    }\n}\nfunction stringifyItem({ start, key, sep, value }) {\n    let res = '';\n    for (const st of start)\n        res += st.source;\n    if (key)\n        res += stringifyToken(key);\n    if (sep)\n        for (const st of sep)\n            res += st.source;\n    if (value)\n        res += stringifyToken(value);\n    return res;\n}\n\nconst BREAK = Symbol('break visit');\nconst SKIP = Symbol('skip children');\nconst REMOVE = Symbol('remove item');\n/**\n * Apply a visitor to a CST document or item.\n *\n * Walks through the tree (depth-first) starting from the root, calling a\n * `visitor` function with two arguments when entering each item:\n *   - `item`: The current item, which included the following members:\n *     - `start: SourceToken[]` – Source tokens before the key or value,\n *       possibly including its anchor or tag.\n *     - `key?: Token | null` – Set for pair values. May then be `null`, if\n *       the key before the `:` separator is empty.\n *     - `sep?: SourceToken[]` – Source tokens between the key and the value,\n *       which should include the `:` map value indicator if `value` is set.\n *     - `value?: Token` – The value of a sequence item, or of a map pair.\n *   - `path`: The steps from the root to the current node, as an array of\n *     `['key' | 'value', number]` tuples.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this token, continue with\n *      next sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current item, then continue with the next one\n *   - `number`: Set the index of the next step. This is useful especially if\n *     the index of the current token has changed.\n *   - `function`: Define the next visitor for this item. After the original\n *     visitor is called on item entry, next visitors are called after handling\n *     a non-empty `key` and when exiting the item.\n */\nfunction visit(cst, visitor) {\n    if ('type' in cst && cst.type === 'document')\n        cst = { start: cst.start, value: cst.value };\n    _visit(Object.freeze([]), cst, visitor);\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisit.BREAK = BREAK;\n/** Do not visit the children of the current item */\nvisit.SKIP = SKIP;\n/** Remove the current item */\nvisit.REMOVE = REMOVE;\n/** Find the item at `path` from `cst` as the root */\nvisit.itemAtPath = (cst, path) => {\n    let item = cst;\n    for (const [field, index] of path) {\n        const tok = item?.[field];\n        if (tok && 'items' in tok) {\n            item = tok.items[index];\n        }\n        else\n            return undefined;\n    }\n    return item;\n};\n/**\n * Get the immediate parent collection of the item at `path` from `cst` as the root.\n *\n * Throws an error if the collection is not found, which should never happen if the item itself exists.\n */\nvisit.parentCollection = (cst, path) => {\n    const parent = visit.itemAtPath(cst, path.slice(0, -1));\n    const field = path[path.length - 1][0];\n    const coll = parent?.[field];\n    if (coll && 'items' in coll)\n        return coll;\n    throw new Error('Parent collection not found');\n};\nfunction _visit(path, item, visitor) {\n    let ctrl = visitor(item, path);\n    if (typeof ctrl === 'symbol')\n        return ctrl;\n    for (const field of ['key', 'value']) {\n        const token = item[field];\n        if (token && 'items' in token) {\n            for (let i = 0; i < token.items.length; ++i) {\n                const ci = _visit(Object.freeze(path.concat([[field, i]])), token.items[i], visitor);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    token.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n            if (typeof ctrl === 'function' && field === 'key')\n                ctrl = ctrl(item, path);\n        }\n    }\n    return typeof ctrl === 'function' ? ctrl(item, path) : ctrl;\n}\n\n/** The byte order mark */\nconst BOM = '\\u{FEFF}';\n/** Start of doc-mode */\nconst DOCUMENT = '\\x02'; // C0: Start of Text\n/** Unexpected end of flow-mode */\nconst FLOW_END = '\\x18'; // C0: Cancel\n/** Next token is a scalar value */\nconst SCALAR = '\\x1f'; // C0: Unit Separator\n/** @returns `true` if `token` is a flow or block collection */\nconst isCollection = (token) => !!token && 'items' in token;\n/** @returns `true` if `token` is a flow or block scalar; not an alias */\nconst isScalar = (token) => !!token &&\n    (token.type === 'scalar' ||\n        token.type === 'single-quoted-scalar' ||\n        token.type === 'double-quoted-scalar' ||\n        token.type === 'block-scalar');\n/* istanbul ignore next */\n/** Get a printable representation of a lexer token */\nfunction prettyToken(token) {\n    switch (token) {\n        case BOM:\n            return '<BOM>';\n        case DOCUMENT:\n            return '<DOC>';\n        case FLOW_END:\n            return '<FLOW_END>';\n        case SCALAR:\n            return '<SCALAR>';\n        default:\n            return JSON.stringify(token);\n    }\n}\n/** Identify the type of a lexer token. May return `null` for unknown tokens. */\nfunction tokenType(source) {\n    switch (source) {\n        case BOM:\n            return 'byte-order-mark';\n        case DOCUMENT:\n            return 'doc-mode';\n        case FLOW_END:\n            return 'flow-error-end';\n        case SCALAR:\n            return 'scalar';\n        case '---':\n            return 'doc-start';\n        case '...':\n            return 'doc-end';\n        case '':\n        case '\\n':\n        case '\\r\\n':\n            return 'newline';\n        case '-':\n            return 'seq-item-ind';\n        case '?':\n            return 'explicit-key-ind';\n        case ':':\n            return 'map-value-ind';\n        case '{':\n            return 'flow-map-start';\n        case '}':\n            return 'flow-map-end';\n        case '[':\n            return 'flow-seq-start';\n        case ']':\n            return 'flow-seq-end';\n        case ',':\n            return 'comma';\n    }\n    switch (source[0]) {\n        case ' ':\n        case '\\t':\n            return 'space';\n        case '#':\n            return 'comment';\n        case '%':\n            return 'directive-line';\n        case '*':\n            return 'alias';\n        case '&':\n            return 'anchor';\n        case '!':\n            return 'tag';\n        case \"'\":\n            return 'single-quoted-scalar';\n        case '\"':\n            return 'double-quoted-scalar';\n        case '|':\n        case '>':\n            return 'block-scalar-header';\n    }\n    return null;\n}\n\nvar cst = {\n  __proto__: null,\n  BOM: BOM,\n  DOCUMENT: DOCUMENT,\n  FLOW_END: FLOW_END,\n  SCALAR: SCALAR,\n  createScalarToken: createScalarToken,\n  isCollection: isCollection,\n  isScalar: isScalar,\n  prettyToken: prettyToken,\n  resolveAsScalar: resolveAsScalar,\n  setScalarValue: setScalarValue,\n  stringify: stringify$1,\n  tokenType: tokenType,\n  visit: visit\n};\n\n/*\nSTART -> stream\n\nstream\n  directive -> line-end -> stream\n  indent + line-end -> stream\n  [else] -> line-start\n\nline-end\n  comment -> line-end\n  newline -> .\n  input-end -> END\n\nline-start\n  doc-start -> doc\n  doc-end -> stream\n  [else] -> indent -> block-start\n\nblock-start\n  seq-item-start -> block-start\n  explicit-key-start -> block-start\n  map-value-start -> block-start\n  [else] -> doc\n\ndoc\n  line-end -> line-start\n  spaces -> doc\n  anchor -> doc\n  tag -> doc\n  flow-start -> flow -> doc\n  flow-end -> error -> doc\n  seq-item-start -> error -> doc\n  explicit-key-start -> error -> doc\n  map-value-start -> doc\n  alias -> doc\n  quote-start -> quoted-scalar -> doc\n  block-scalar-header -> line-end -> block-scalar(min) -> line-start\n  [else] -> plain-scalar(false, min) -> doc\n\nflow\n  line-end -> flow\n  spaces -> flow\n  anchor -> flow\n  tag -> flow\n  flow-start -> flow -> flow\n  flow-end -> .\n  seq-item-start -> error -> flow\n  explicit-key-start -> flow\n  map-value-start -> flow\n  alias -> flow\n  quote-start -> quoted-scalar -> flow\n  comma -> flow\n  [else] -> plain-scalar(true, 0) -> flow\n\nquoted-scalar\n  quote-end -> .\n  [else] -> quoted-scalar\n\nblock-scalar(min)\n  newline + peek(indent < min) -> .\n  [else] -> block-scalar(min)\n\nplain-scalar(is-flow, min)\n  scalar-end(is-flow) -> .\n  peek(newline + (indent < min)) -> .\n  [else] -> plain-scalar(min)\n*/\nfunction isEmpty(ch) {\n    switch (ch) {\n        case undefined:\n        case ' ':\n        case '\\n':\n        case '\\r':\n        case '\\t':\n            return true;\n        default:\n            return false;\n    }\n}\nconst hexDigits = '0123456789ABCDEFabcdef'.split('');\nconst tagChars = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()\".split('');\nconst invalidFlowScalarChars = ',[]{}'.split('');\nconst invalidAnchorChars = ' ,[]{}\\n\\r\\t'.split('');\nconst isNotAnchorChar = (ch) => !ch || invalidAnchorChars.includes(ch);\n/**\n * Splits an input string into lexical tokens, i.e. smaller strings that are\n * easily identifiable by `tokens.tokenType()`.\n *\n * Lexing starts always in a \"stream\" context. Incomplete input may be buffered\n * until a complete token can be emitted.\n *\n * In addition to slices of the original input, the following control characters\n * may also be emitted:\n *\n * - `\\x02` (Start of Text): A document starts with the next token\n * - `\\x18` (Cancel): Unexpected end of flow-mode (indicates an error)\n * - `\\x1f` (Unit Separator): Next token is a scalar value\n * - `\\u{FEFF}` (Byte order mark): Emitted separately outside documents\n */\nclass Lexer {\n    constructor() {\n        /**\n         * Flag indicating whether the end of the current buffer marks the end of\n         * all input\n         */\n        this.atEnd = false;\n        /**\n         * Explicit indent set in block scalar header, as an offset from the current\n         * minimum indent, so e.g. set to 1 from a header `|2+`. Set to -1 if not\n         * explicitly set.\n         */\n        this.blockScalarIndent = -1;\n        /**\n         * Block scalars that include a + (keep) chomping indicator in their header\n         * include trailing empty lines, which are otherwise excluded from the\n         * scalar's contents.\n         */\n        this.blockScalarKeep = false;\n        /** Current input */\n        this.buffer = '';\n        /**\n         * Flag noting whether the map value indicator : can immediately follow this\n         * node within a flow context.\n         */\n        this.flowKey = false;\n        /** Count of surrounding flow collection levels. */\n        this.flowLevel = 0;\n        /**\n         * Minimum level of indentation required for next lines to be parsed as a\n         * part of the current scalar value.\n         */\n        this.indentNext = 0;\n        /** Indentation level of the current line. */\n        this.indentValue = 0;\n        /** Position of the next \\n character. */\n        this.lineEndPos = null;\n        /** Stores the state of the lexer if reaching the end of incpomplete input */\n        this.next = null;\n        /** A pointer to `buffer`; the current position of the lexer. */\n        this.pos = 0;\n    }\n    /**\n     * Generate YAML tokens from the `source` string. If `incomplete`,\n     * a part of the last line may be left as a buffer for the next call.\n     *\n     * @returns A generator of lexical tokens\n     */\n    *lex(source, incomplete = false) {\n        if (source) {\n            this.buffer = this.buffer ? this.buffer + source : source;\n            this.lineEndPos = null;\n        }\n        this.atEnd = !incomplete;\n        let next = this.next ?? 'stream';\n        while (next && (incomplete || this.hasChars(1)))\n            next = yield* this.parseNext(next);\n    }\n    atLineEnd() {\n        let i = this.pos;\n        let ch = this.buffer[i];\n        while (ch === ' ' || ch === '\\t')\n            ch = this.buffer[++i];\n        if (!ch || ch === '#' || ch === '\\n')\n            return true;\n        if (ch === '\\r')\n            return this.buffer[i + 1] === '\\n';\n        return false;\n    }\n    charAt(n) {\n        return this.buffer[this.pos + n];\n    }\n    continueScalar(offset) {\n        let ch = this.buffer[offset];\n        if (this.indentNext > 0) {\n            let indent = 0;\n            while (ch === ' ')\n                ch = this.buffer[++indent + offset];\n            if (ch === '\\r') {\n                const next = this.buffer[indent + offset + 1];\n                if (next === '\\n' || (!next && !this.atEnd))\n                    return offset + indent + 1;\n            }\n            return ch === '\\n' || indent >= this.indentNext || (!ch && !this.atEnd)\n                ? offset + indent\n                : -1;\n        }\n        if (ch === '-' || ch === '.') {\n            const dt = this.buffer.substr(offset, 3);\n            if ((dt === '---' || dt === '...') && isEmpty(this.buffer[offset + 3]))\n                return -1;\n        }\n        return offset;\n    }\n    getLine() {\n        let end = this.lineEndPos;\n        if (typeof end !== 'number' || (end !== -1 && end < this.pos)) {\n            end = this.buffer.indexOf('\\n', this.pos);\n            this.lineEndPos = end;\n        }\n        if (end === -1)\n            return this.atEnd ? this.buffer.substring(this.pos) : null;\n        if (this.buffer[end - 1] === '\\r')\n            end -= 1;\n        return this.buffer.substring(this.pos, end);\n    }\n    hasChars(n) {\n        return this.pos + n <= this.buffer.length;\n    }\n    setNext(state) {\n        this.buffer = this.buffer.substring(this.pos);\n        this.pos = 0;\n        this.lineEndPos = null;\n        this.next = state;\n        return null;\n    }\n    peek(n) {\n        return this.buffer.substr(this.pos, n);\n    }\n    *parseNext(next) {\n        switch (next) {\n            case 'stream':\n                return yield* this.parseStream();\n            case 'line-start':\n                return yield* this.parseLineStart();\n            case 'block-start':\n                return yield* this.parseBlockStart();\n            case 'doc':\n                return yield* this.parseDocument();\n            case 'flow':\n                return yield* this.parseFlowCollection();\n            case 'quoted-scalar':\n                return yield* this.parseQuotedScalar();\n            case 'block-scalar':\n                return yield* this.parseBlockScalar();\n            case 'plain-scalar':\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseStream() {\n        let line = this.getLine();\n        if (line === null)\n            return this.setNext('stream');\n        if (line[0] === BOM) {\n            yield* this.pushCount(1);\n            line = line.substring(1);\n        }\n        if (line[0] === '%') {\n            let dirEnd = line.length;\n            const cs = line.indexOf('#');\n            if (cs !== -1) {\n                const ch = line[cs - 1];\n                if (ch === ' ' || ch === '\\t')\n                    dirEnd = cs - 1;\n            }\n            while (true) {\n                const ch = line[dirEnd - 1];\n                if (ch === ' ' || ch === '\\t')\n                    dirEnd -= 1;\n                else\n                    break;\n            }\n            const n = (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true));\n            yield* this.pushCount(line.length - n); // possible comment\n            this.pushNewline();\n            return 'stream';\n        }\n        if (this.atLineEnd()) {\n            const sp = yield* this.pushSpaces(true);\n            yield* this.pushCount(line.length - sp);\n            yield* this.pushNewline();\n            return 'stream';\n        }\n        yield DOCUMENT;\n        return yield* this.parseLineStart();\n    }\n    *parseLineStart() {\n        const ch = this.charAt(0);\n        if (!ch && !this.atEnd)\n            return this.setNext('line-start');\n        if (ch === '-' || ch === '.') {\n            if (!this.atEnd && !this.hasChars(4))\n                return this.setNext('line-start');\n            const s = this.peek(3);\n            if (s === '---' && isEmpty(this.charAt(3))) {\n                yield* this.pushCount(3);\n                this.indentValue = 0;\n                this.indentNext = 0;\n                return 'doc';\n            }\n            else if (s === '...' && isEmpty(this.charAt(3))) {\n                yield* this.pushCount(3);\n                return 'stream';\n            }\n        }\n        this.indentValue = yield* this.pushSpaces(false);\n        if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1)))\n            this.indentNext = this.indentValue;\n        return yield* this.parseBlockStart();\n    }\n    *parseBlockStart() {\n        const [ch0, ch1] = this.peek(2);\n        if (!ch1 && !this.atEnd)\n            return this.setNext('block-start');\n        if ((ch0 === '-' || ch0 === '?' || ch0 === ':') && isEmpty(ch1)) {\n            const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true));\n            this.indentNext = this.indentValue + 1;\n            this.indentValue += n;\n            return yield* this.parseBlockStart();\n        }\n        return 'doc';\n    }\n    *parseDocument() {\n        yield* this.pushSpaces(true);\n        const line = this.getLine();\n        if (line === null)\n            return this.setNext('doc');\n        let n = yield* this.pushIndicators();\n        switch (line[n]) {\n            case '#':\n                yield* this.pushCount(line.length - n);\n            // fallthrough\n            case undefined:\n                yield* this.pushNewline();\n                return yield* this.parseLineStart();\n            case '{':\n            case '[':\n                yield* this.pushCount(1);\n                this.flowKey = false;\n                this.flowLevel = 1;\n                return 'flow';\n            case '}':\n            case ']':\n                // this is an error\n                yield* this.pushCount(1);\n                return 'doc';\n            case '*':\n                yield* this.pushUntil(isNotAnchorChar);\n                return 'doc';\n            case '\"':\n            case \"'\":\n                return yield* this.parseQuotedScalar();\n            case '|':\n            case '>':\n                n += yield* this.parseBlockScalarHeader();\n                n += yield* this.pushSpaces(true);\n                yield* this.pushCount(line.length - n);\n                yield* this.pushNewline();\n                return yield* this.parseBlockScalar();\n            default:\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseFlowCollection() {\n        let nl, sp;\n        let indent = -1;\n        do {\n            nl = yield* this.pushNewline();\n            if (nl > 0) {\n                sp = yield* this.pushSpaces(false);\n                this.indentValue = indent = sp;\n            }\n            else {\n                sp = 0;\n            }\n            sp += yield* this.pushSpaces(true);\n        } while (nl + sp > 0);\n        const line = this.getLine();\n        if (line === null)\n            return this.setNext('flow');\n        if ((indent !== -1 && indent < this.indentNext && line[0] !== '#') ||\n            (indent === 0 &&\n                (line.startsWith('---') || line.startsWith('...')) &&\n                isEmpty(line[3]))) {\n            // Allowing for the terminal ] or } at the same (rather than greater)\n            // indent level as the initial [ or { is technically invalid, but\n            // failing here would be surprising to users.\n            const atFlowEndMarker = indent === this.indentNext - 1 &&\n                this.flowLevel === 1 &&\n                (line[0] === ']' || line[0] === '}');\n            if (!atFlowEndMarker) {\n                // this is an error\n                this.flowLevel = 0;\n                yield FLOW_END;\n                return yield* this.parseLineStart();\n            }\n        }\n        let n = 0;\n        while (line[n] === ',') {\n            n += yield* this.pushCount(1);\n            n += yield* this.pushSpaces(true);\n            this.flowKey = false;\n        }\n        n += yield* this.pushIndicators();\n        switch (line[n]) {\n            case undefined:\n                return 'flow';\n            case '#':\n                yield* this.pushCount(line.length - n);\n                return 'flow';\n            case '{':\n            case '[':\n                yield* this.pushCount(1);\n                this.flowKey = false;\n                this.flowLevel += 1;\n                return 'flow';\n            case '}':\n            case ']':\n                yield* this.pushCount(1);\n                this.flowKey = true;\n                this.flowLevel -= 1;\n                return this.flowLevel ? 'flow' : 'doc';\n            case '*':\n                yield* this.pushUntil(isNotAnchorChar);\n                return 'flow';\n            case '\"':\n            case \"'\":\n                this.flowKey = true;\n                return yield* this.parseQuotedScalar();\n            case ':': {\n                const next = this.charAt(1);\n                if (this.flowKey || isEmpty(next) || next === ',') {\n                    this.flowKey = false;\n                    yield* this.pushCount(1);\n                    yield* this.pushSpaces(true);\n                    return 'flow';\n                }\n            }\n            // fallthrough\n            default:\n                this.flowKey = false;\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseQuotedScalar() {\n        const quote = this.charAt(0);\n        let end = this.buffer.indexOf(quote, this.pos + 1);\n        if (quote === \"'\") {\n            while (end !== -1 && this.buffer[end + 1] === \"'\")\n                end = this.buffer.indexOf(\"'\", end + 2);\n        }\n        else {\n            // double-quote\n            while (end !== -1) {\n                let n = 0;\n                while (this.buffer[end - 1 - n] === '\\\\')\n                    n += 1;\n                if (n % 2 === 0)\n                    break;\n                end = this.buffer.indexOf('\"', end + 1);\n            }\n        }\n        // Only looking for newlines within the quotes\n        const qb = this.buffer.substring(0, end);\n        let nl = qb.indexOf('\\n', this.pos);\n        if (nl !== -1) {\n            while (nl !== -1) {\n                const cs = this.continueScalar(nl + 1);\n                if (cs === -1)\n                    break;\n                nl = qb.indexOf('\\n', cs);\n            }\n            if (nl !== -1) {\n                // this is an error caused by an unexpected unindent\n                end = nl - (qb[nl - 1] === '\\r' ? 2 : 1);\n            }\n        }\n        if (end === -1) {\n            if (!this.atEnd)\n                return this.setNext('quoted-scalar');\n            end = this.buffer.length;\n        }\n        yield* this.pushToIndex(end + 1, false);\n        return this.flowLevel ? 'flow' : 'doc';\n    }\n    *parseBlockScalarHeader() {\n        this.blockScalarIndent = -1;\n        this.blockScalarKeep = false;\n        let i = this.pos;\n        while (true) {\n            const ch = this.buffer[++i];\n            if (ch === '+')\n                this.blockScalarKeep = true;\n            else if (ch > '0' && ch <= '9')\n                this.blockScalarIndent = Number(ch) - 1;\n            else if (ch !== '-')\n                break;\n        }\n        return yield* this.pushUntil(ch => isEmpty(ch) || ch === '#');\n    }\n    *parseBlockScalar() {\n        let nl = this.pos - 1; // may be -1 if this.pos === 0\n        let indent = 0;\n        let ch;\n        loop: for (let i = this.pos; (ch = this.buffer[i]); ++i) {\n            switch (ch) {\n                case ' ':\n                    indent += 1;\n                    break;\n                case '\\n':\n                    nl = i;\n                    indent = 0;\n                    break;\n                case '\\r': {\n                    const next = this.buffer[i + 1];\n                    if (!next && !this.atEnd)\n                        return this.setNext('block-scalar');\n                    if (next === '\\n')\n                        break;\n                } // fallthrough\n                default:\n                    break loop;\n            }\n        }\n        if (!ch && !this.atEnd)\n            return this.setNext('block-scalar');\n        if (indent >= this.indentNext) {\n            if (this.blockScalarIndent === -1)\n                this.indentNext = indent;\n            else\n                this.indentNext += this.blockScalarIndent;\n            do {\n                const cs = this.continueScalar(nl + 1);\n                if (cs === -1)\n                    break;\n                nl = this.buffer.indexOf('\\n', cs);\n            } while (nl !== -1);\n            if (nl === -1) {\n                if (!this.atEnd)\n                    return this.setNext('block-scalar');\n                nl = this.buffer.length;\n            }\n        }\n        if (!this.blockScalarKeep) {\n            do {\n                let i = nl - 1;\n                let ch = this.buffer[i];\n                if (ch === '\\r')\n                    ch = this.buffer[--i];\n                const lastChar = i; // Drop the line if last char not more indented\n                while (ch === ' ' || ch === '\\t')\n                    ch = this.buffer[--i];\n                if (ch === '\\n' && i >= this.pos && i + 1 + indent > lastChar)\n                    nl = i;\n                else\n                    break;\n            } while (true);\n        }\n        yield SCALAR;\n        yield* this.pushToIndex(nl + 1, true);\n        return yield* this.parseLineStart();\n    }\n    *parsePlainScalar() {\n        const inFlow = this.flowLevel > 0;\n        let end = this.pos - 1;\n        let i = this.pos - 1;\n        let ch;\n        while ((ch = this.buffer[++i])) {\n            if (ch === ':') {\n                const next = this.buffer[i + 1];\n                if (isEmpty(next) || (inFlow && next === ','))\n                    break;\n                end = i;\n            }\n            else if (isEmpty(ch)) {\n                let next = this.buffer[i + 1];\n                if (ch === '\\r') {\n                    if (next === '\\n') {\n                        i += 1;\n                        ch = '\\n';\n                        next = this.buffer[i + 1];\n                    }\n                    else\n                        end = i;\n                }\n                if (next === '#' || (inFlow && invalidFlowScalarChars.includes(next)))\n                    break;\n                if (ch === '\\n') {\n                    const cs = this.continueScalar(i + 1);\n                    if (cs === -1)\n                        break;\n                    i = Math.max(i, cs - 2); // to advance, but still account for ' #'\n                }\n            }\n            else {\n                if (inFlow && invalidFlowScalarChars.includes(ch))\n                    break;\n                end = i;\n            }\n        }\n        if (!ch && !this.atEnd)\n            return this.setNext('plain-scalar');\n        yield SCALAR;\n        yield* this.pushToIndex(end + 1, true);\n        return inFlow ? 'flow' : 'doc';\n    }\n    *pushCount(n) {\n        if (n > 0) {\n            yield this.buffer.substr(this.pos, n);\n            this.pos += n;\n            return n;\n        }\n        return 0;\n    }\n    *pushToIndex(i, allowEmpty) {\n        const s = this.buffer.slice(this.pos, i);\n        if (s) {\n            yield s;\n            this.pos += s.length;\n            return s.length;\n        }\n        else if (allowEmpty)\n            yield '';\n        return 0;\n    }\n    *pushIndicators() {\n        switch (this.charAt(0)) {\n            case '!':\n                return ((yield* this.pushTag()) +\n                    (yield* this.pushSpaces(true)) +\n                    (yield* this.pushIndicators()));\n            case '&':\n                return ((yield* this.pushUntil(isNotAnchorChar)) +\n                    (yield* this.pushSpaces(true)) +\n                    (yield* this.pushIndicators()));\n            case '-': // this is an error\n            case '?': // this is an error outside flow collections\n            case ':': {\n                const inFlow = this.flowLevel > 0;\n                const ch1 = this.charAt(1);\n                if (isEmpty(ch1) || (inFlow && invalidFlowScalarChars.includes(ch1))) {\n                    if (!inFlow)\n                        this.indentNext = this.indentValue + 1;\n                    else if (this.flowKey)\n                        this.flowKey = false;\n                    return ((yield* this.pushCount(1)) +\n                        (yield* this.pushSpaces(true)) +\n                        (yield* this.pushIndicators()));\n                }\n            }\n        }\n        return 0;\n    }\n    *pushTag() {\n        if (this.charAt(1) === '<') {\n            let i = this.pos + 2;\n            let ch = this.buffer[i];\n            while (!isEmpty(ch) && ch !== '>')\n                ch = this.buffer[++i];\n            return yield* this.pushToIndex(ch === '>' ? i + 1 : i, false);\n        }\n        else {\n            let i = this.pos + 1;\n            let ch = this.buffer[i];\n            while (ch) {\n                if (tagChars.includes(ch))\n                    ch = this.buffer[++i];\n                else if (ch === '%' &&\n                    hexDigits.includes(this.buffer[i + 1]) &&\n                    hexDigits.includes(this.buffer[i + 2])) {\n                    ch = this.buffer[(i += 3)];\n                }\n                else\n                    break;\n            }\n            return yield* this.pushToIndex(i, false);\n        }\n    }\n    *pushNewline() {\n        const ch = this.buffer[this.pos];\n        if (ch === '\\n')\n            return yield* this.pushCount(1);\n        else if (ch === '\\r' && this.charAt(1) === '\\n')\n            return yield* this.pushCount(2);\n        else\n            return 0;\n    }\n    *pushSpaces(allowTabs) {\n        let i = this.pos - 1;\n        let ch;\n        do {\n            ch = this.buffer[++i];\n        } while (ch === ' ' || (allowTabs && ch === '\\t'));\n        const n = i - this.pos;\n        if (n > 0) {\n            yield this.buffer.substr(this.pos, n);\n            this.pos = i;\n        }\n        return n;\n    }\n    *pushUntil(test) {\n        let i = this.pos;\n        let ch = this.buffer[i];\n        while (!test(ch))\n            ch = this.buffer[++i];\n        return yield* this.pushToIndex(i, false);\n    }\n}\n\n/**\n * Tracks newlines during parsing in order to provide an efficient API for\n * determining the one-indexed `{ line, col }` position for any offset\n * within the input.\n */\nclass LineCounter {\n    constructor() {\n        this.lineStarts = [];\n        /**\n         * Should be called in ascending order. Otherwise, call\n         * `lineCounter.lineStarts.sort()` before calling `linePos()`.\n         */\n        this.addNewLine = (offset) => this.lineStarts.push(offset);\n        /**\n         * Performs a binary search and returns the 1-indexed { line, col }\n         * position of `offset`. If `line === 0`, `addNewLine` has never been\n         * called or `offset` is before the first known newline.\n         */\n        this.linePos = (offset) => {\n            let low = 0;\n            let high = this.lineStarts.length;\n            while (low < high) {\n                const mid = (low + high) >> 1; // Math.floor((low + high) / 2)\n                if (this.lineStarts[mid] < offset)\n                    low = mid + 1;\n                else\n                    high = mid;\n            }\n            if (this.lineStarts[low] === offset)\n                return { line: low + 1, col: 1 };\n            if (low === 0)\n                return { line: 0, col: offset };\n            const start = this.lineStarts[low - 1];\n            return { line: low, col: offset - start + 1 };\n        };\n    }\n}\n\nfunction includesToken(list, type) {\n    for (let i = 0; i < list.length; ++i)\n        if (list[i].type === type)\n            return true;\n    return false;\n}\nfunction findNonEmptyIndex(list) {\n    for (let i = 0; i < list.length; ++i) {\n        switch (list[i].type) {\n            case 'space':\n            case 'comment':\n            case 'newline':\n                break;\n            default:\n                return i;\n        }\n    }\n    return -1;\n}\nfunction isFlowToken(token) {\n    switch (token?.type) {\n        case 'alias':\n        case 'scalar':\n        case 'single-quoted-scalar':\n        case 'double-quoted-scalar':\n        case 'flow-collection':\n            return true;\n        default:\n            return false;\n    }\n}\nfunction getPrevProps(parent) {\n    switch (parent.type) {\n        case 'document':\n            return parent.start;\n        case 'block-map': {\n            const it = parent.items[parent.items.length - 1];\n            return it.sep ?? it.start;\n        }\n        case 'block-seq':\n            return parent.items[parent.items.length - 1].start;\n        /* istanbul ignore next should not happen */\n        default:\n            return [];\n    }\n}\n/** Note: May modify input array */\nfunction getFirstKeyStartProps(prev) {\n    if (prev.length === 0)\n        return [];\n    let i = prev.length;\n    loop: while (--i >= 0) {\n        switch (prev[i].type) {\n            case 'doc-start':\n            case 'explicit-key-ind':\n            case 'map-value-ind':\n            case 'seq-item-ind':\n            case 'newline':\n                break loop;\n        }\n    }\n    while (prev[++i]?.type === 'space') {\n        /* loop */\n    }\n    return prev.splice(i, prev.length);\n}\nfunction fixFlowSeqItems(fc) {\n    if (fc.start.type === 'flow-seq-start') {\n        for (const it of fc.items) {\n            if (it.sep &&\n                !it.value &&\n                !includesToken(it.start, 'explicit-key-ind') &&\n                !includesToken(it.sep, 'map-value-ind')) {\n                if (it.key)\n                    it.value = it.key;\n                delete it.key;\n                if (isFlowToken(it.value)) {\n                    if (it.value.end)\n                        Array.prototype.push.apply(it.value.end, it.sep);\n                    else\n                        it.value.end = it.sep;\n                }\n                else\n                    Array.prototype.push.apply(it.start, it.sep);\n                delete it.sep;\n            }\n        }\n    }\n}\n/**\n * A YAML concrete syntax tree (CST) parser\n *\n * ```ts\n * const src: string = ...\n * for (const token of new Parser().parse(src)) {\n *   // token: Token\n * }\n * ```\n *\n * To use the parser with a user-provided lexer:\n *\n * ```ts\n * function* parse(source: string, lexer: Lexer) {\n *   const parser = new Parser()\n *   for (const lexeme of lexer.lex(source))\n *     yield* parser.next(lexeme)\n *   yield* parser.end()\n * }\n *\n * const src: string = ...\n * const lexer = new Lexer()\n * for (const token of parse(src, lexer)) {\n *   // token: Token\n * }\n * ```\n */\nclass Parser {\n    /**\n     * @param onNewLine - If defined, called separately with the start position of\n     *   each new line (in `parse()`, including the start of input).\n     */\n    constructor(onNewLine) {\n        /** If true, space and sequence indicators count as indentation */\n        this.atNewLine = true;\n        /** If true, next token is a scalar value */\n        this.atScalar = false;\n        /** Current indentation level */\n        this.indent = 0;\n        /** Current offset since the start of parsing */\n        this.offset = 0;\n        /** On the same line with a block map key */\n        this.onKeyLine = false;\n        /** Top indicates the node that's currently being built */\n        this.stack = [];\n        /** The source of the current token, set in parse() */\n        this.source = '';\n        /** The type of the current token, set in parse() */\n        this.type = '';\n        // Must be defined after `next()`\n        this.lexer = new Lexer();\n        this.onNewLine = onNewLine;\n    }\n    /**\n     * Parse `source` as a YAML stream.\n     * If `incomplete`, a part of the last line may be left as a buffer for the next call.\n     *\n     * Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.\n     *\n     * @returns A generator of tokens representing each directive, document, and other structure.\n     */\n    *parse(source, incomplete = false) {\n        if (this.onNewLine && this.offset === 0)\n            this.onNewLine(0);\n        for (const lexeme of this.lexer.lex(source, incomplete))\n            yield* this.next(lexeme);\n        if (!incomplete)\n            yield* this.end();\n    }\n    /**\n     * Advance the parser by the `source` of one lexical token.\n     */\n    *next(source) {\n        this.source = source;\n        if (this.atScalar) {\n            this.atScalar = false;\n            yield* this.step();\n            this.offset += source.length;\n            return;\n        }\n        const type = tokenType(source);\n        if (!type) {\n            const message = `Not a YAML token: ${source}`;\n            yield* this.pop({ type: 'error', offset: this.offset, message, source });\n            this.offset += source.length;\n        }\n        else if (type === 'scalar') {\n            this.atNewLine = false;\n            this.atScalar = true;\n            this.type = 'scalar';\n        }\n        else {\n            this.type = type;\n            yield* this.step();\n            switch (type) {\n                case 'newline':\n                    this.atNewLine = true;\n                    this.indent = 0;\n                    if (this.onNewLine)\n                        this.onNewLine(this.offset + source.length);\n                    break;\n                case 'space':\n                    if (this.atNewLine && source[0] === ' ')\n                        this.indent += source.length;\n                    break;\n                case 'explicit-key-ind':\n                case 'map-value-ind':\n                case 'seq-item-ind':\n                    if (this.atNewLine)\n                        this.indent += source.length;\n                    break;\n                case 'doc-mode':\n                case 'flow-error-end':\n                    return;\n                default:\n                    this.atNewLine = false;\n            }\n            this.offset += source.length;\n        }\n    }\n    /** Call at end of input to push out any remaining constructions */\n    *end() {\n        while (this.stack.length > 0)\n            yield* this.pop();\n    }\n    get sourceToken() {\n        const st = {\n            type: this.type,\n            offset: this.offset,\n            indent: this.indent,\n            source: this.source\n        };\n        return st;\n    }\n    *step() {\n        const top = this.peek(1);\n        if (this.type === 'doc-end' && (!top || top.type !== 'doc-end')) {\n            while (this.stack.length > 0)\n                yield* this.pop();\n            this.stack.push({\n                type: 'doc-end',\n                offset: this.offset,\n                source: this.source\n            });\n            return;\n        }\n        if (!top)\n            return yield* this.stream();\n        switch (top.type) {\n            case 'document':\n                return yield* this.document(top);\n            case 'alias':\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return yield* this.scalar(top);\n            case 'block-scalar':\n                return yield* this.blockScalar(top);\n            case 'block-map':\n                return yield* this.blockMap(top);\n            case 'block-seq':\n                return yield* this.blockSequence(top);\n            case 'flow-collection':\n                return yield* this.flowCollection(top);\n            case 'doc-end':\n                return yield* this.documentEnd(top);\n        }\n        /* istanbul ignore next should not happen */\n        yield* this.pop();\n    }\n    peek(n) {\n        return this.stack[this.stack.length - n];\n    }\n    *pop(error) {\n        const token = error ?? this.stack.pop();\n        /* istanbul ignore if should not happen */\n        if (!token) {\n            const message = 'Tried to pop an empty stack';\n            yield { type: 'error', offset: this.offset, source: '', message };\n        }\n        else if (this.stack.length === 0) {\n            yield token;\n        }\n        else {\n            const top = this.peek(1);\n            if (token.type === 'block-scalar') {\n                // Block scalars use their parent rather than header indent\n                token.indent = 'indent' in top ? top.indent : 0;\n            }\n            else if (token.type === 'flow-collection' && top.type === 'document') {\n                // Ignore all indent for top-level flow collections\n                token.indent = 0;\n            }\n            if (token.type === 'flow-collection')\n                fixFlowSeqItems(token);\n            switch (top.type) {\n                case 'document':\n                    top.value = token;\n                    break;\n                case 'block-scalar':\n                    top.props.push(token); // error\n                    break;\n                case 'block-map': {\n                    const it = top.items[top.items.length - 1];\n                    if (it.value) {\n                        top.items.push({ start: [], key: token, sep: [] });\n                        this.onKeyLine = true;\n                        return;\n                    }\n                    else if (it.sep) {\n                        it.value = token;\n                    }\n                    else {\n                        Object.assign(it, { key: token, sep: [] });\n                        this.onKeyLine = !includesToken(it.start, 'explicit-key-ind');\n                        return;\n                    }\n                    break;\n                }\n                case 'block-seq': {\n                    const it = top.items[top.items.length - 1];\n                    if (it.value)\n                        top.items.push({ start: [], value: token });\n                    else\n                        it.value = token;\n                    break;\n                }\n                case 'flow-collection': {\n                    const it = top.items[top.items.length - 1];\n                    if (!it || it.value)\n                        top.items.push({ start: [], key: token, sep: [] });\n                    else if (it.sep)\n                        it.value = token;\n                    else\n                        Object.assign(it, { key: token, sep: [] });\n                    return;\n                }\n                /* istanbul ignore next should not happen */\n                default:\n                    yield* this.pop();\n                    yield* this.pop(token);\n            }\n            if ((top.type === 'document' ||\n                top.type === 'block-map' ||\n                top.type === 'block-seq') &&\n                (token.type === 'block-map' || token.type === 'block-seq')) {\n                const last = token.items[token.items.length - 1];\n                if (last &&\n                    !last.sep &&\n                    !last.value &&\n                    last.start.length > 0 &&\n                    findNonEmptyIndex(last.start) === -1 &&\n                    (token.indent === 0 ||\n                        last.start.every(st => st.type !== 'comment' || st.indent < token.indent))) {\n                    if (top.type === 'document')\n                        top.end = last.start;\n                    else\n                        top.items.push({ start: last.start });\n                    token.items.splice(-1, 1);\n                }\n            }\n        }\n    }\n    *stream() {\n        switch (this.type) {\n            case 'directive-line':\n                yield { type: 'directive', offset: this.offset, source: this.source };\n                return;\n            case 'byte-order-mark':\n            case 'space':\n            case 'comment':\n            case 'newline':\n                yield this.sourceToken;\n                return;\n            case 'doc-mode':\n            case 'doc-start': {\n                const doc = {\n                    type: 'document',\n                    offset: this.offset,\n                    start: []\n                };\n                if (this.type === 'doc-start')\n                    doc.start.push(this.sourceToken);\n                this.stack.push(doc);\n                return;\n            }\n        }\n        yield {\n            type: 'error',\n            offset: this.offset,\n            message: `Unexpected ${this.type} token in YAML stream`,\n            source: this.source\n        };\n    }\n    *document(doc) {\n        if (doc.value)\n            return yield* this.lineEnd(doc);\n        switch (this.type) {\n            case 'doc-start': {\n                if (findNonEmptyIndex(doc.start) !== -1) {\n                    yield* this.pop();\n                    yield* this.step();\n                }\n                else\n                    doc.start.push(this.sourceToken);\n                return;\n            }\n            case 'anchor':\n            case 'tag':\n            case 'space':\n            case 'comment':\n            case 'newline':\n                doc.start.push(this.sourceToken);\n                return;\n        }\n        const bv = this.startBlockValue(doc);\n        if (bv)\n            this.stack.push(bv);\n        else {\n            yield {\n                type: 'error',\n                offset: this.offset,\n                message: `Unexpected ${this.type} token in YAML document`,\n                source: this.source\n            };\n        }\n    }\n    *scalar(scalar) {\n        if (this.type === 'map-value-ind') {\n            const prev = getPrevProps(this.peek(2));\n            const start = getFirstKeyStartProps(prev);\n            let sep;\n            if (scalar.end) {\n                sep = scalar.end;\n                sep.push(this.sourceToken);\n                delete scalar.end;\n            }\n            else\n                sep = [this.sourceToken];\n            const map = {\n                type: 'block-map',\n                offset: scalar.offset,\n                indent: scalar.indent,\n                items: [{ start, key: scalar, sep }]\n            };\n            this.onKeyLine = true;\n            this.stack[this.stack.length - 1] = map;\n        }\n        else\n            yield* this.lineEnd(scalar);\n    }\n    *blockScalar(scalar) {\n        switch (this.type) {\n            case 'space':\n            case 'comment':\n            case 'newline':\n                scalar.props.push(this.sourceToken);\n                return;\n            case 'scalar':\n                scalar.source = this.source;\n                // block-scalar source includes trailing newline\n                this.atNewLine = true;\n                this.indent = 0;\n                if (this.onNewLine) {\n                    let nl = this.source.indexOf('\\n') + 1;\n                    while (nl !== 0) {\n                        this.onNewLine(this.offset + nl);\n                        nl = this.source.indexOf('\\n', nl) + 1;\n                    }\n                }\n                yield* this.pop();\n                break;\n            /* istanbul ignore next should not happen */\n            default:\n                yield* this.pop();\n                yield* this.step();\n        }\n    }\n    *blockMap(map) {\n        const it = map.items[map.items.length - 1];\n        // it.sep is true-ish if pair already has key or : separator\n        switch (this.type) {\n            case 'newline':\n                this.onKeyLine = false;\n                if (it.value) {\n                    const end = 'end' in it.value ? it.value.end : undefined;\n                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;\n                    if (last?.type === 'comment')\n                        end?.push(this.sourceToken);\n                    else\n                        map.items.push({ start: [this.sourceToken] });\n                }\n                else if (it.sep) {\n                    it.sep.push(this.sourceToken);\n                }\n                else {\n                    it.start.push(this.sourceToken);\n                }\n                return;\n            case 'space':\n            case 'comment':\n                if (it.value) {\n                    map.items.push({ start: [this.sourceToken] });\n                }\n                else if (it.sep) {\n                    it.sep.push(this.sourceToken);\n                }\n                else {\n                    if (this.atIndentedComment(it.start, map.indent)) {\n                        const prev = map.items[map.items.length - 2];\n                        const end = prev?.value?.end;\n                        if (Array.isArray(end)) {\n                            Array.prototype.push.apply(end, it.start);\n                            end.push(this.sourceToken);\n                            map.items.pop();\n                            return;\n                        }\n                    }\n                    it.start.push(this.sourceToken);\n                }\n                return;\n        }\n        if (this.indent >= map.indent) {\n            const atNextItem = !this.onKeyLine && this.indent === map.indent && it.sep;\n            // For empty nodes, assign newline-separated not indented empty tokens to following node\n            let start = [];\n            if (atNextItem && it.sep && !it.value) {\n                const nl = [];\n                for (let i = 0; i < it.sep.length; ++i) {\n                    const st = it.sep[i];\n                    switch (st.type) {\n                        case 'newline':\n                            nl.push(i);\n                            break;\n                        case 'space':\n                            break;\n                        case 'comment':\n                            if (st.indent > map.indent)\n                                nl.length = 0;\n                            break;\n                        default:\n                            nl.length = 0;\n                    }\n                }\n                if (nl.length >= 2)\n                    start = it.sep.splice(nl[1]);\n            }\n            switch (this.type) {\n                case 'anchor':\n                case 'tag':\n                    if (atNextItem || it.value) {\n                        start.push(this.sourceToken);\n                        map.items.push({ start });\n                        this.onKeyLine = true;\n                    }\n                    else if (it.sep) {\n                        it.sep.push(this.sourceToken);\n                    }\n                    else {\n                        it.start.push(this.sourceToken);\n                    }\n                    return;\n                case 'explicit-key-ind':\n                    if (!it.sep && !includesToken(it.start, 'explicit-key-ind')) {\n                        it.start.push(this.sourceToken);\n                    }\n                    else if (atNextItem || it.value) {\n                        start.push(this.sourceToken);\n                        map.items.push({ start });\n                    }\n                    else {\n                        this.stack.push({\n                            type: 'block-map',\n                            offset: this.offset,\n                            indent: this.indent,\n                            items: [{ start: [this.sourceToken] }]\n                        });\n                    }\n                    this.onKeyLine = true;\n                    return;\n                case 'map-value-ind':\n                    if (includesToken(it.start, 'explicit-key-ind')) {\n                        if (!it.sep) {\n                            if (includesToken(it.start, 'newline')) {\n                                Object.assign(it, { key: null, sep: [this.sourceToken] });\n                            }\n                            else {\n                                const start = getFirstKeyStartProps(it.start);\n                                this.stack.push({\n                                    type: 'block-map',\n                                    offset: this.offset,\n                                    indent: this.indent,\n                                    items: [{ start, key: null, sep: [this.sourceToken] }]\n                                });\n                            }\n                        }\n                        else if (it.value) {\n                            map.items.push({ start: [], key: null, sep: [this.sourceToken] });\n                        }\n                        else if (includesToken(it.sep, 'map-value-ind')) {\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start, key: null, sep: [this.sourceToken] }]\n                            });\n                        }\n                        else if (isFlowToken(it.key) &&\n                            !includesToken(it.sep, 'newline')) {\n                            const start = getFirstKeyStartProps(it.start);\n                            const key = it.key;\n                            const sep = it.sep;\n                            sep.push(this.sourceToken);\n                            // @ts-expect-error type guard is wrong here\n                            delete it.key, delete it.sep;\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start, key, sep }]\n                            });\n                        }\n                        else if (start.length > 0) {\n                            // Not actually at next item\n                            it.sep = it.sep.concat(start, this.sourceToken);\n                        }\n                        else {\n                            it.sep.push(this.sourceToken);\n                        }\n                    }\n                    else {\n                        if (!it.sep) {\n                            Object.assign(it, { key: null, sep: [this.sourceToken] });\n                        }\n                        else if (it.value || atNextItem) {\n                            map.items.push({ start, key: null, sep: [this.sourceToken] });\n                        }\n                        else if (includesToken(it.sep, 'map-value-ind')) {\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start: [], key: null, sep: [this.sourceToken] }]\n                            });\n                        }\n                        else {\n                            it.sep.push(this.sourceToken);\n                        }\n                    }\n                    this.onKeyLine = true;\n                    return;\n                case 'alias':\n                case 'scalar':\n                case 'single-quoted-scalar':\n                case 'double-quoted-scalar': {\n                    const fs = this.flowScalar(this.type);\n                    if (atNextItem || it.value) {\n                        map.items.push({ start, key: fs, sep: [] });\n                        this.onKeyLine = true;\n                    }\n                    else if (it.sep) {\n                        this.stack.push(fs);\n                    }\n                    else {\n                        Object.assign(it, { key: fs, sep: [] });\n                        this.onKeyLine = true;\n                    }\n                    return;\n                }\n                default: {\n                    const bv = this.startBlockValue(map);\n                    if (bv) {\n                        if (atNextItem &&\n                            bv.type !== 'block-seq' &&\n                            includesToken(it.start, 'explicit-key-ind')) {\n                            map.items.push({ start });\n                        }\n                        this.stack.push(bv);\n                        return;\n                    }\n                }\n            }\n        }\n        yield* this.pop();\n        yield* this.step();\n    }\n    *blockSequence(seq) {\n        const it = seq.items[seq.items.length - 1];\n        switch (this.type) {\n            case 'newline':\n                if (it.value) {\n                    const end = 'end' in it.value ? it.value.end : undefined;\n                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;\n                    if (last?.type === 'comment')\n                        end?.push(this.sourceToken);\n                    else\n                        seq.items.push({ start: [this.sourceToken] });\n                }\n                else\n                    it.start.push(this.sourceToken);\n                return;\n            case 'space':\n            case 'comment':\n                if (it.value)\n                    seq.items.push({ start: [this.sourceToken] });\n                else {\n                    if (this.atIndentedComment(it.start, seq.indent)) {\n                        const prev = seq.items[seq.items.length - 2];\n                        const end = prev?.value?.end;\n                        if (Array.isArray(end)) {\n                            Array.prototype.push.apply(end, it.start);\n                            end.push(this.sourceToken);\n                            seq.items.pop();\n                            return;\n                        }\n                    }\n                    it.start.push(this.sourceToken);\n                }\n                return;\n            case 'anchor':\n            case 'tag':\n                if (it.value || this.indent <= seq.indent)\n                    break;\n                it.start.push(this.sourceToken);\n                return;\n            case 'seq-item-ind':\n                if (this.indent !== seq.indent)\n                    break;\n                if (it.value || includesToken(it.start, 'seq-item-ind'))\n                    seq.items.push({ start: [this.sourceToken] });\n                else\n                    it.start.push(this.sourceToken);\n                return;\n        }\n        if (this.indent > seq.indent) {\n            const bv = this.startBlockValue(seq);\n            if (bv) {\n                this.stack.push(bv);\n                return;\n            }\n        }\n        yield* this.pop();\n        yield* this.step();\n    }\n    *flowCollection(fc) {\n        const it = fc.items[fc.items.length - 1];\n        if (this.type === 'flow-error-end') {\n            let top;\n            do {\n                yield* this.pop();\n                top = this.peek(1);\n            } while (top && top.type === 'flow-collection');\n        }\n        else if (fc.end.length === 0) {\n            switch (this.type) {\n                case 'comma':\n                case 'explicit-key-ind':\n                    if (!it || it.sep)\n                        fc.items.push({ start: [this.sourceToken] });\n                    else\n                        it.start.push(this.sourceToken);\n                    return;\n                case 'map-value-ind':\n                    if (!it || it.value)\n                        fc.items.push({ start: [], key: null, sep: [this.sourceToken] });\n                    else if (it.sep)\n                        it.sep.push(this.sourceToken);\n                    else\n                        Object.assign(it, { key: null, sep: [this.sourceToken] });\n                    return;\n                case 'space':\n                case 'comment':\n                case 'newline':\n                case 'anchor':\n                case 'tag':\n                    if (!it || it.value)\n                        fc.items.push({ start: [this.sourceToken] });\n                    else if (it.sep)\n                        it.sep.push(this.sourceToken);\n                    else\n                        it.start.push(this.sourceToken);\n                    return;\n                case 'alias':\n                case 'scalar':\n                case 'single-quoted-scalar':\n                case 'double-quoted-scalar': {\n                    const fs = this.flowScalar(this.type);\n                    if (!it || it.value)\n                        fc.items.push({ start: [], key: fs, sep: [] });\n                    else if (it.sep)\n                        this.stack.push(fs);\n                    else\n                        Object.assign(it, { key: fs, sep: [] });\n                    return;\n                }\n                case 'flow-map-end':\n                case 'flow-seq-end':\n                    fc.end.push(this.sourceToken);\n                    return;\n            }\n            const bv = this.startBlockValue(fc);\n            /* istanbul ignore else should not happen */\n            if (bv)\n                this.stack.push(bv);\n            else {\n                yield* this.pop();\n                yield* this.step();\n            }\n        }\n        else {\n            const parent = this.peek(2);\n            if (parent.type === 'block-map' &&\n                ((this.type === 'map-value-ind' && parent.indent === fc.indent) ||\n                    (this.type === 'newline' &&\n                        !parent.items[parent.items.length - 1].sep))) {\n                yield* this.pop();\n                yield* this.step();\n            }\n            else if (this.type === 'map-value-ind' &&\n                parent.type !== 'flow-collection') {\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                fixFlowSeqItems(fc);\n                const sep = fc.end.splice(1, fc.end.length);\n                sep.push(this.sourceToken);\n                const map = {\n                    type: 'block-map',\n                    offset: fc.offset,\n                    indent: fc.indent,\n                    items: [{ start, key: fc, sep }]\n                };\n                this.onKeyLine = true;\n                this.stack[this.stack.length - 1] = map;\n            }\n            else {\n                yield* this.lineEnd(fc);\n            }\n        }\n    }\n    flowScalar(type) {\n        if (this.onNewLine) {\n            let nl = this.source.indexOf('\\n') + 1;\n            while (nl !== 0) {\n                this.onNewLine(this.offset + nl);\n                nl = this.source.indexOf('\\n', nl) + 1;\n            }\n        }\n        return {\n            type,\n            offset: this.offset,\n            indent: this.indent,\n            source: this.source\n        };\n    }\n    startBlockValue(parent) {\n        switch (this.type) {\n            case 'alias':\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return this.flowScalar(this.type);\n            case 'block-scalar-header':\n                return {\n                    type: 'block-scalar',\n                    offset: this.offset,\n                    indent: this.indent,\n                    props: [this.sourceToken],\n                    source: ''\n                };\n            case 'flow-map-start':\n            case 'flow-seq-start':\n                return {\n                    type: 'flow-collection',\n                    offset: this.offset,\n                    indent: this.indent,\n                    start: this.sourceToken,\n                    items: [],\n                    end: []\n                };\n            case 'seq-item-ind':\n                return {\n                    type: 'block-seq',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start: [this.sourceToken] }]\n                };\n            case 'explicit-key-ind': {\n                this.onKeyLine = true;\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                start.push(this.sourceToken);\n                return {\n                    type: 'block-map',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start }]\n                };\n            }\n            case 'map-value-ind': {\n                this.onKeyLine = true;\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                return {\n                    type: 'block-map',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start, key: null, sep: [this.sourceToken] }]\n                };\n            }\n        }\n        return null;\n    }\n    atIndentedComment(start, indent) {\n        if (this.type !== 'comment')\n            return false;\n        if (this.indent <= indent)\n            return false;\n        return start.every(st => st.type === 'newline' || st.type === 'space');\n    }\n    *documentEnd(docEnd) {\n        if (this.type !== 'doc-mode') {\n            if (docEnd.end)\n                docEnd.end.push(this.sourceToken);\n            else\n                docEnd.end = [this.sourceToken];\n            if (this.type === 'newline')\n                yield* this.pop();\n        }\n    }\n    *lineEnd(token) {\n        switch (this.type) {\n            case 'comma':\n            case 'doc-start':\n            case 'doc-end':\n            case 'flow-seq-end':\n            case 'flow-map-end':\n            case 'map-value-ind':\n                yield* this.pop();\n                yield* this.step();\n                break;\n            case 'newline':\n                this.onKeyLine = false;\n            // fallthrough\n            case 'space':\n            case 'comment':\n            default:\n                // all other values are errors\n                if (token.end)\n                    token.end.push(this.sourceToken);\n                else\n                    token.end = [this.sourceToken];\n                if (this.type === 'newline')\n                    yield* this.pop();\n        }\n    }\n}\n\nfunction parseOptions(options) {\n    const prettyErrors = options.prettyErrors !== false;\n    const lineCounter = options.lineCounter || (prettyErrors && new LineCounter()) || null;\n    return { lineCounter, prettyErrors };\n}\n/**\n * Parse the input as a stream of YAML documents.\n *\n * Documents should be separated from each other by `...` or `---` marker lines.\n *\n * @returns If an empty `docs` array is returned, it will be of type\n *   EmptyStream and contain additional stream information. In\n *   TypeScript, you should use `'empty' in docs` as a type guard for it.\n */\nfunction parseAllDocuments(source, options = {}) {\n    const { lineCounter, prettyErrors } = parseOptions(options);\n    const parser = new Parser(lineCounter?.addNewLine);\n    const composer = new Composer(options);\n    const docs = Array.from(composer.compose(parser.parse(source)));\n    if (prettyErrors && lineCounter)\n        for (const doc of docs) {\n            doc.errors.forEach(prettifyError(source, lineCounter));\n            doc.warnings.forEach(prettifyError(source, lineCounter));\n        }\n    if (docs.length > 0)\n        return docs;\n    return Object.assign([], { empty: true }, composer.streamInfo());\n}\n/** Parse an input string into a single YAML.Document */\nfunction parseDocument(source, options = {}) {\n    const { lineCounter, prettyErrors } = parseOptions(options);\n    const parser = new Parser(lineCounter?.addNewLine);\n    const composer = new Composer(options);\n    // `doc` is always set by compose.end(true) at the very latest\n    let doc = null;\n    for (const _doc of composer.compose(parser.parse(source), true, source.length)) {\n        if (!doc)\n            doc = _doc;\n        else if (doc.options.logLevel !== 'silent') {\n            doc.errors.push(new YAMLParseError(_doc.range.slice(0, 2), 'MULTIPLE_DOCS', 'Source contains multiple documents; please use YAML.parseAllDocuments()'));\n            break;\n        }\n    }\n    if (prettyErrors && lineCounter) {\n        doc.errors.forEach(prettifyError(source, lineCounter));\n        doc.warnings.forEach(prettifyError(source, lineCounter));\n    }\n    return doc;\n}\nfunction parse$a(src, reviver, options) {\n    let _reviver = undefined;\n    if (typeof reviver === 'function') {\n        _reviver = reviver;\n    }\n    else if (options === undefined && reviver && typeof reviver === 'object') {\n        options = reviver;\n    }\n    const doc = parseDocument(src, options);\n    if (!doc)\n        return null;\n    doc.warnings.forEach(warning => warn(doc.options.logLevel, warning));\n    if (doc.errors.length > 0) {\n        if (doc.options.logLevel !== 'silent')\n            throw doc.errors[0];\n        else\n            doc.errors = [];\n    }\n    return doc.toJS(Object.assign({ reviver: _reviver }, options));\n}\nfunction stringify(value, replacer, options) {\n    let _replacer = null;\n    if (typeof replacer === 'function' || Array.isArray(replacer)) {\n        _replacer = replacer;\n    }\n    else if (options === undefined && replacer) {\n        options = replacer;\n    }\n    if (typeof options === 'string')\n        options = options.length;\n    if (typeof options === 'number') {\n        const indent = Math.round(options);\n        options = indent < 1 ? undefined : indent > 8 ? { indent: 8 } : { indent };\n    }\n    if (value === undefined) {\n        const { keepUndefined } = options ?? replacer ?? {};\n        if (!keepUndefined)\n            return undefined;\n    }\n    return new Document(value, _replacer, options).toString(options);\n}\n\nvar YAML = {\n  __proto__: null,\n  Alias: Alias,\n  CST: cst,\n  Composer: Composer,\n  Document: Document,\n  Lexer: Lexer,\n  LineCounter: LineCounter,\n  Pair: Pair,\n  Parser: Parser,\n  Scalar: Scalar,\n  Schema: Schema,\n  YAMLError: YAMLError,\n  YAMLMap: YAMLMap,\n  YAMLParseError: YAMLParseError,\n  YAMLSeq: YAMLSeq,\n  YAMLWarning: YAMLWarning,\n  isAlias: isAlias,\n  isCollection: isCollection$1,\n  isDocument: isDocument,\n  isMap: isMap,\n  isNode: isNode$1,\n  isPair: isPair,\n  isScalar: isScalar$1,\n  isSeq: isSeq,\n  parse: parse$a,\n  parseAllDocuments: parseAllDocuments,\n  parseDocument: parseDocument,\n  stringify: stringify,\n  visit: visit$1,\n  visitAsync: visitAsync\n};\n\n// `export * as default from ...` fails on Webpack v4\n\nvar browser$1 = {\n  __proto__: null,\n  Alias: Alias,\n  CST: cst,\n  Composer: Composer,\n  Document: Document,\n  Lexer: Lexer,\n  LineCounter: LineCounter,\n  Pair: Pair,\n  Parser: Parser,\n  Scalar: Scalar,\n  Schema: Schema,\n  YAMLError: YAMLError,\n  YAMLMap: YAMLMap,\n  YAMLParseError: YAMLParseError,\n  YAMLSeq: YAMLSeq,\n  YAMLWarning: YAMLWarning,\n  default: YAML,\n  isAlias: isAlias,\n  isCollection: isCollection$1,\n  isDocument: isDocument,\n  isMap: isMap,\n  isNode: isNode$1,\n  isPair: isPair,\n  isScalar: isScalar$1,\n  isSeq: isSeq,\n  parse: parse$a,\n  parseAllDocuments: parseAllDocuments,\n  parseDocument: parseDocument,\n  stringify: stringify,\n  visit: visit$1,\n  visitAsync: visitAsync\n};\n\nvar require$$3$1 = /*@__PURE__*/getAugmentedNamespace(browser$1);\n\n// eslint-disable-next-line n/no-deprecated-api\nconst { createRequire, createRequireFromPath } = require$$0$8;\n\nfunction req$2 (name, rootFile) {\n  const create = createRequire || createRequireFromPath;\n  const require = create(rootFile);\n  return require(name)\n}\n\nvar req_1 = req$2;\n\nconst req$1 = req_1;\n\n/**\n * Load Options\n *\n * @private\n * @method options\n *\n * @param  {Object} config  PostCSS Config\n *\n * @return {Object} options PostCSS Options\n */\nconst options = (config, file) => {\n  if (config.parser && typeof config.parser === 'string') {\n    try {\n      config.parser = req$1(config.parser, file);\n    } catch (err) {\n      throw new Error(`Loading PostCSS Parser failed: ${err.message}\\n\\n(@${file})`)\n    }\n  }\n\n  if (config.syntax && typeof config.syntax === 'string') {\n    try {\n      config.syntax = req$1(config.syntax, file);\n    } catch (err) {\n      throw new Error(`Loading PostCSS Syntax failed: ${err.message}\\n\\n(@${file})`)\n    }\n  }\n\n  if (config.stringifier && typeof config.stringifier === 'string') {\n    try {\n      config.stringifier = req$1(config.stringifier, file);\n    } catch (err) {\n      throw new Error(`Loading PostCSS Stringifier failed: ${err.message}\\n\\n(@${file})`)\n    }\n  }\n\n  if (config.plugins) {\n    delete config.plugins;\n  }\n\n  return config\n};\n\nvar options_1 = options;\n\nconst req = req_1;\n\n/**\n * Plugin Loader\n *\n * @private\n * @method load\n *\n * @param  {String} plugin PostCSS Plugin Name\n * @param  {Object} options PostCSS Plugin Options\n *\n * @return {Function} PostCSS Plugin\n */\nconst load = (plugin, options, file) => {\n  try {\n    if (\n      options === null ||\n      options === undefined ||\n      Object.keys(options).length === 0\n    ) {\n      return req(plugin, file)\n    } else {\n      return req(plugin, file)(options)\n    }\n  } catch (err) {\n    throw new Error(`Loading PostCSS Plugin failed: ${err.message}\\n\\n(@${file})`)\n  }\n};\n\n/**\n * Load Plugins\n *\n * @private\n * @method plugins\n *\n * @param {Object} config PostCSS Config Plugins\n *\n * @return {Array} plugins PostCSS Plugins\n */\nconst plugins = (config, file) => {\n  let plugins = [];\n\n  if (Array.isArray(config.plugins)) {\n    plugins = config.plugins.filter(Boolean);\n  } else {\n    plugins = Object.keys(config.plugins)\n      .filter((plugin) => {\n        return config.plugins[plugin] !== false ? plugin : ''\n      })\n      .map((plugin) => {\n        return load(plugin, config.plugins[plugin], file)\n      });\n  }\n\n  if (plugins.length && plugins.length > 0) {\n    plugins.forEach((plugin, i) => {\n      if (plugin.default) {\n        plugin = plugin.default;\n      }\n\n      if (plugin.postcss === true) {\n        plugin = plugin();\n      } else if (plugin.postcss) {\n        plugin = plugin.postcss;\n      }\n\n      if (\n        // eslint-disable-next-line\n        !(\n          (typeof plugin === 'object' && Array.isArray(plugin.plugins)) ||\n          (typeof plugin === 'object' && plugin.postcssPlugin) ||\n          (typeof plugin === 'function')\n        )\n      ) {\n        throw new TypeError(`Invalid PostCSS Plugin found at: plugins[${i}]\\n\\n(@${file})`)\n      }\n    });\n  }\n\n  return plugins\n};\n\nvar plugins_1 = plugins;\n\nconst resolve = require$$0$4.resolve;\nconst url$4 = require$$0$9;\n\nconst config$1 = dist;\nconst yaml = require$$3$1;\n\nconst loadOptions = options_1;\nconst loadPlugins = plugins_1;\n\n/* istanbul ignore next */\nconst interopRequireDefault = (obj) => obj && obj.__esModule ? obj : { default: obj };\n\n/**\n * Process the result from cosmiconfig\n *\n * @param  {Object} ctx Config Context\n * @param  {Object} result Cosmiconfig result\n *\n * @return {Object} PostCSS Config\n */\nconst processResult = (ctx, result) => {\n  const file = result.filepath || '';\n  let config = interopRequireDefault(result.config).default || {};\n\n  if (typeof config === 'function') {\n    config = config(ctx);\n  } else {\n    config = Object.assign({}, config, ctx);\n  }\n\n  if (!config.plugins) {\n    config.plugins = [];\n  }\n\n  return {\n    plugins: loadPlugins(config, file),\n    options: loadOptions(config, file),\n    file\n  }\n};\n\n/**\n * Builds the Config Context\n *\n * @param  {Object} ctx Config Context\n *\n * @return {Object} Config Context\n */\nconst createContext = (ctx) => {\n  /**\n   * @type {Object}\n   *\n   * @prop {String} cwd=process.cwd() Config search start location\n   * @prop {String} env=process.env.NODE_ENV Config Enviroment, will be set to `development` by `postcss-load-config` if `process.env.NODE_ENV` is `undefined`\n   */\n  ctx = Object.assign({\n    cwd: process.cwd(),\n    env: process.env.NODE_ENV\n  }, ctx);\n\n  if (!ctx.env) {\n    process.env.NODE_ENV = 'development';\n  }\n\n  return ctx\n};\n\nconst importDefault = async filepath => {\n  const module = await import(url$4.pathToFileURL(filepath).href);\n  return module.default\n};\n\nconst addTypeScriptLoader = (options = {}, loader) => {\n  const moduleName = 'postcss';\n\n  return {\n    ...options,\n    searchPlaces: [\n      ...(options.searchPlaces || []),\n      'package.json',\n      `.${moduleName}rc`,\n      `.${moduleName}rc.json`,\n      `.${moduleName}rc.yaml`,\n      `.${moduleName}rc.yml`,\n      `.${moduleName}rc.ts`,\n      `.${moduleName}rc.js`,\n      `.${moduleName}rc.cjs`,\n      `.${moduleName}rc.mjs`,\n      `${moduleName}.config.ts`,\n      `${moduleName}.config.js`,\n      `${moduleName}.config.cjs`,\n      `${moduleName}.config.mjs`\n    ],\n    loaders: {\n      ...options.loaders,\n      '.yaml': (filepath, content) => yaml.parse(content),\n      '.yml': (filepath, content) => yaml.parse(content),\n      '.js': importDefault,\n      '.cjs': importDefault,\n      '.mjs': importDefault,\n      '.ts': loader\n    }\n  }\n};\n\nconst withTypeScriptLoader = (rcFunc) => {\n  return (ctx, path, options) => {\n    return rcFunc(ctx, path, addTypeScriptLoader(options, (configFile) => {\n      let registerer = { enabled () {} };\n\n      try {\n        // Register TypeScript compiler instance\n        registerer = eval('require')('ts-node').register();\n\n        return eval('require')(configFile)\n      } catch (err) {\n        if (err.code === 'MODULE_NOT_FOUND') {\n          throw new Error(\n            `'ts-node' is required for the TypeScript configuration files. Make sure it is installed\\nError: ${err.message}`\n          )\n        }\n\n        throw err\n      } finally {\n        registerer.enabled(false);\n      }\n    }))\n  }\n};\n\n/**\n * Load Config\n *\n * @method rc\n *\n * @param  {Object} ctx Config Context\n * @param  {String} path Config Path\n * @param  {Object} options Config Options\n *\n * @return {Promise} config PostCSS Config\n */\nconst rc = withTypeScriptLoader((ctx, path, options) => {\n  /**\n   * @type {Object} The full Config Context\n   */\n  ctx = createContext(ctx);\n\n  /**\n   * @type {String} `process.cwd()`\n   */\n  path = path ? resolve(path) : process.cwd();\n\n  return config$1.lilconfig('postcss', options)\n    .search(path)\n    .then((result) => {\n      if (!result) {\n        throw new Error(`No PostCSS Config found in: ${path}`)\n      }\n\n      return processResult(ctx, result)\n    })\n});\n\n/**\n * Autoload Config for PostCSS\n *\n * @author Michael Ciniawsky @michael-ciniawsky <michael.ciniawsky@gmail.com>\n * @license MIT\n *\n * @module postcss-load-config\n * @version 2.1.0\n *\n * @requires comsiconfig\n * @requires ./options\n * @requires ./plugins\n */\nvar src$1 = rc;\n\nfunction stripLiteralAcorn(code) {\n  const FILL = \" \";\n  let result = \"\";\n  function fulfill(index) {\n    if (index > result.length)\n      result += code.slice(result.length, index).replace(/[^\\n]/g, FILL);\n  }\n  const tokens = tokenizer(code, {\n    ecmaVersion: \"latest\",\n    sourceType: \"module\",\n    allowHashBang: true,\n    allowAwaitOutsideFunction: true,\n    allowImportExportEverywhere: true\n  });\n  const inter = tokens[Symbol.iterator]();\n  while (true) {\n    const { done, value: token } = inter.next();\n    if (done)\n      break;\n    fulfill(token.start);\n    if (token.type.label === \"string\")\n      result += code[token.start] + FILL.repeat(token.end - token.start - 2) + code[token.end - 1];\n    else if (token.type.label === \"template\")\n      result += FILL.repeat(token.end - token.start);\n    else\n      result += code.slice(token.start, token.end);\n  }\n  fulfill(code.length);\n  return result;\n}\n\nconst multilineCommentsRE = /\\/\\*([^*\\/])*?\\*\\//gms;\nconst singlelineCommentsRE = /(?:^|\\n|\\r)\\s*\\/\\/.*(?:\\r|\\n|$)/gm;\nconst templateLiteralRE = /\\$\\{(\\s*(?:(?!\\$\\{).|\\n|\\r)*?\\s*)\\}/g;\nconst quotesRE = [\n  /([\"'`])((?:\\\\\\1|(?!\\1)|.|\\r)*?)\\1/gm,\n  /([`])((?:\\\\\\1|(?!\\1)|.|\\n|\\r)*?)\\1/gm\n  // multi-line strings (i.e. template literals only)\n];\nfunction stripLiteralRegex(code) {\n  code = code.replace(multilineCommentsRE, (s) => \" \".repeat(s.length)).replace(singlelineCommentsRE, (s) => \" \".repeat(s.length));\n  let expanded = code;\n  for (let i = 0; i < 16; i++) {\n    const before = expanded;\n    expanded = expanded.replace(templateLiteralRE, \"` $1`\");\n    if (expanded === before)\n      break;\n  }\n  quotesRE.forEach((re) => {\n    expanded = expanded.replace(re, (s, quote, body, index) => {\n      code = code.slice(0, index + 1) + \" \".repeat(s.length - 2) + code.slice(index + s.length - 1);\n      return quote + \" \".repeat(s.length - 2) + quote;\n    });\n  });\n  return code;\n}\n\nfunction stripLiteral(code) {\n  try {\n    return stripLiteralAcorn(code);\n  } catch (e) {\n    return stripLiteralRegex(code);\n  }\n}\n\nconst modulePreloadPolyfillId = 'vite/modulepreload-polyfill';\nconst resolvedModulePreloadPolyfillId = '\\0' + modulePreloadPolyfillId;\nfunction modulePreloadPolyfillPlugin(config) {\n    // `isModernFlag` is only available during build since it is resolved by `vite:build-import-analysis`\n    const skip = config.command !== 'build' || config.build.ssr;\n    let polyfillString;\n    return {\n        name: 'vite:modulepreload-polyfill',\n        resolveId(id) {\n            if (id === modulePreloadPolyfillId) {\n                return resolvedModulePreloadPolyfillId;\n            }\n        },\n        load(id) {\n            if (id === resolvedModulePreloadPolyfillId) {\n                if (skip) {\n                    return '';\n                }\n                if (!polyfillString) {\n                    polyfillString = `${isModernFlag}&&(${polyfill.toString()}());`;\n                }\n                return polyfillString;\n            }\n        },\n    };\n}\nfunction polyfill() {\n    const relList = document.createElement('link').relList;\n    if (relList && relList.supports && relList.supports('modulepreload')) {\n        return;\n    }\n    for (const link of document.querySelectorAll('link[rel=\"modulepreload\"]')) {\n        processPreload(link);\n    }\n    new MutationObserver((mutations) => {\n        for (const mutation of mutations) {\n            if (mutation.type !== 'childList') {\n                continue;\n            }\n            for (const node of mutation.addedNodes) {\n                if (node.tagName === 'LINK' && node.rel === 'modulepreload')\n                    processPreload(node);\n            }\n        }\n    }).observe(document, { childList: true, subtree: true });\n    function getFetchOpts(link) {\n        const fetchOpts = {};\n        if (link.integrity)\n            fetchOpts.integrity = link.integrity;\n        if (link.referrerPolicy)\n            fetchOpts.referrerPolicy = link.referrerPolicy;\n        if (link.crossOrigin === 'use-credentials')\n            fetchOpts.credentials = 'include';\n        else if (link.crossOrigin === 'anonymous')\n            fetchOpts.credentials = 'omit';\n        else\n            fetchOpts.credentials = 'same-origin';\n        return fetchOpts;\n    }\n    function processPreload(link) {\n        if (link.ep)\n            // ep marker = processed\n            return;\n        link.ep = true;\n        // prepopulate the load record\n        const fetchOpts = getFetchOpts(link);\n        fetch(link.href, fetchOpts);\n    }\n}\n\nconst htmlProxyRE$1 = /\\?html-proxy=?(?:&inline-css)?&index=(\\d+)\\.(js|css)$/;\nconst inlineCSSRE$1 = /__VITE_INLINE_CSS__([a-z\\d]{8}_\\d+)__/g;\n// Do not allow preceding '.', but do allow preceding '...' for spread operations\nconst inlineImportRE = /(?<!(?<!\\.\\.)\\.)\\bimport\\s*\\((\"(?:[^\"]|(?<=\\\\)\")*\"|'(?:[^']|(?<=\\\\)')*')\\)/g;\nconst htmlLangRE = /\\.(?:html|htm)$/;\nconst importMapRE = /[ \\t]*<script[^>]*type\\s*=\\s*(?:\"importmap\"|'importmap'|importmap)[^>]*>.*?<\\/script>/is;\nconst moduleScriptRE = /[ \\t]*<script[^>]*type\\s*=\\s*(?:\"module\"|'module'|module)[^>]*>/i;\nconst modulePreloadLinkRE = /[ \\t]*<link[^>]*rel\\s*=\\s*(?:\"modulepreload\"|'modulepreload'|modulepreload)[\\s\\S]*?\\/>/i;\nconst importMapAppendRE = new RegExp([moduleScriptRE, modulePreloadLinkRE].map((r) => r.source).join('|'), 'i');\nconst isHTMLProxy = (id) => htmlProxyRE$1.test(id);\nconst isHTMLRequest = (request) => htmlLangRE.test(request);\n// HTML Proxy Caches are stored by config -> filePath -> index\nconst htmlProxyMap = new WeakMap();\n// HTML Proxy Transform result are stored by config\n// `${hash(importer)}_${query.index}` -> transformed css code\n// PS: key like `hash(/vite/playground/assets/index.html)_1`)\nconst htmlProxyResult = new Map();\nfunction htmlInlineProxyPlugin(config) {\n    // Should do this when `constructor` rather than when `buildStart`,\n    // `buildStart` will be triggered multiple times then the cached result will be emptied.\n    // https://github.com/vitejs/vite/issues/6372\n    htmlProxyMap.set(config, new Map());\n    return {\n        name: 'vite:html-inline-proxy',\n        resolveId(id) {\n            if (htmlProxyRE$1.test(id)) {\n                return id;\n            }\n        },\n        load(id) {\n            const proxyMatch = id.match(htmlProxyRE$1);\n            if (proxyMatch) {\n                const index = Number(proxyMatch[1]);\n                const file = cleanUrl(id);\n                const url = file.replace(normalizePath$3(config.root), '');\n                const result = htmlProxyMap.get(config).get(url)[index];\n                if (result) {\n                    return result;\n                }\n                else {\n                    throw new Error(`No matching HTML proxy module found from ${id}`);\n                }\n            }\n        },\n    };\n}\nfunction addToHTMLProxyCache(config, filePath, index, result) {\n    if (!htmlProxyMap.get(config)) {\n        htmlProxyMap.set(config, new Map());\n    }\n    if (!htmlProxyMap.get(config).get(filePath)) {\n        htmlProxyMap.get(config).set(filePath, []);\n    }\n    htmlProxyMap.get(config).get(filePath)[index] = result;\n}\nfunction addToHTMLProxyTransformResult(hash, code) {\n    htmlProxyResult.set(hash, code);\n}\n// this extends the config in @vue/compiler-sfc with <link href>\nconst assetAttrsConfig = {\n    link: ['href'],\n    video: ['src', 'poster'],\n    source: ['src', 'srcset'],\n    img: ['src', 'srcset'],\n    image: ['xlink:href', 'href'],\n    use: ['xlink:href', 'href'],\n};\nconst isAsyncScriptMap = new WeakMap();\nfunction nodeIsElement(node) {\n    return node.nodeName[0] !== '#';\n}\nfunction traverseNodes(node, visitor) {\n    visitor(node);\n    if (nodeIsElement(node) ||\n        node.nodeName === '#document' ||\n        node.nodeName === '#document-fragment') {\n        node.childNodes.forEach((childNode) => traverseNodes(childNode, visitor));\n    }\n}\nasync function traverseHtml(html, filePath, visitor) {\n    // lazy load compiler\n    const { parse } = await import('./dep-98d07f71.js');\n    const ast = parse(html, {\n        scriptingEnabled: false,\n        sourceCodeLocationInfo: true,\n        onParseError: (e) => {\n            handleParseError(e, html, filePath);\n        },\n    });\n    traverseNodes(ast, visitor);\n}\nfunction getScriptInfo(node) {\n    let src;\n    let sourceCodeLocation;\n    let isModule = false;\n    let isAsync = false;\n    for (const p of node.attrs) {\n        if (p.prefix !== undefined)\n            continue;\n        if (p.name === 'src') {\n            if (!src) {\n                src = p;\n                sourceCodeLocation = node.sourceCodeLocation?.attrs['src'];\n            }\n        }\n        else if (p.name === 'type' && p.value && p.value === 'module') {\n            isModule = true;\n        }\n        else if (p.name === 'async') {\n            isAsync = true;\n        }\n    }\n    return { src, sourceCodeLocation, isModule, isAsync };\n}\nconst attrValueStartRE = /=\\s*(.)/;\nfunction overwriteAttrValue(s, sourceCodeLocation, newValue) {\n    const srcString = s.slice(sourceCodeLocation.startOffset, sourceCodeLocation.endOffset);\n    const valueStart = srcString.match(attrValueStartRE);\n    if (!valueStart) {\n        // overwrite attr value can only be called for a well-defined value\n        throw new Error(`[vite:html] internal error, failed to overwrite attribute value`);\n    }\n    const wrapOffset = valueStart[1] === '\"' || valueStart[1] === \"'\" ? 1 : 0;\n    const valueOffset = valueStart.index + valueStart[0].length - 1;\n    s.update(sourceCodeLocation.startOffset + valueOffset + wrapOffset, sourceCodeLocation.endOffset - wrapOffset, newValue);\n    return s;\n}\n/**\n * Format parse5 @type {ParserError} to @type {RollupError}\n */\nfunction formatParseError(parserError, id, html) {\n    const formattedError = {\n        code: parserError.code,\n        message: `parse5 error code ${parserError.code}`,\n        frame: generateCodeFrame(html, parserError.startOffset),\n        loc: {\n            file: id,\n            line: parserError.startLine,\n            column: parserError.startCol,\n        },\n    };\n    return formattedError;\n}\nfunction handleParseError(parserError, html, filePath) {\n    switch (parserError.code) {\n        case 'missing-doctype':\n            // ignore missing DOCTYPE\n            return;\n        case 'abandoned-head-element-child':\n            // Accept elements without closing tag in <head>\n            return;\n        case 'duplicate-attribute':\n            // Accept duplicate attributes #9566\n            // The first attribute is used, browsers silently ignore duplicates\n            return;\n        case 'non-void-html-element-start-tag-with-trailing-solidus':\n            // Allow self closing on non-void elements #10439\n            return;\n    }\n    const parseError = formatParseError(parserError, filePath, html);\n    throw new Error(`Unable to parse HTML; ${parseError.message}\\n` +\n        ` at ${parseError.loc.file}:${parseError.loc.line}:${parseError.loc.column}\\n` +\n        `${parseError.frame}`);\n}\n/**\n * Compiles index.html into an entry js module\n */\nfunction buildHtmlPlugin(config) {\n    const [preHooks, normalHooks, postHooks] = resolveHtmlTransforms(config.plugins);\n    preHooks.unshift(preImportMapHook(config));\n    postHooks.push(postImportMapHook());\n    const processedHtml = new Map();\n    const isExcludedUrl = (url) => url.startsWith('#') ||\n        isExternalUrl(url) ||\n        isDataUrl(url) ||\n        checkPublicFile(url, config);\n    // Same reason with `htmlInlineProxyPlugin`\n    isAsyncScriptMap.set(config, new Map());\n    return {\n        name: 'vite:build-html',\n        async transform(html, id) {\n            if (id.endsWith('.html')) {\n                const relativeUrlPath = path$o.posix.relative(config.root, normalizePath$3(id));\n                const publicPath = `/${relativeUrlPath}`;\n                const publicBase = getBaseInHTML(relativeUrlPath, config);\n                const publicToRelative = (filename, importer) => publicBase + filename;\n                const toOutputPublicFilePath = (url) => toOutputFilePathInHtml(url.slice(1), 'public', relativeUrlPath, 'html', config, publicToRelative);\n                // pre-transform\n                html = await applyHtmlTransforms(html, preHooks, {\n                    path: publicPath,\n                    filename: id,\n                });\n                let js = '';\n                const s = new MagicString(html);\n                const assetUrls = [];\n                const scriptUrls = [];\n                const styleUrls = [];\n                let inlineModuleIndex = -1;\n                let everyScriptIsAsync = true;\n                let someScriptsAreAsync = false;\n                let someScriptsAreDefer = false;\n                await traverseHtml(html, id, (node) => {\n                    if (!nodeIsElement(node)) {\n                        return;\n                    }\n                    let shouldRemove = false;\n                    // script tags\n                    if (node.nodeName === 'script') {\n                        const { src, sourceCodeLocation, isModule, isAsync } = getScriptInfo(node);\n                        const url = src && src.value;\n                        const isPublicFile = !!(url && checkPublicFile(url, config));\n                        if (isPublicFile) {\n                            // referencing public dir url, prefix with base\n                            overwriteAttrValue(s, sourceCodeLocation, toOutputPublicFilePath(url));\n                        }\n                        if (isModule) {\n                            inlineModuleIndex++;\n                            if (url && !isExcludedUrl(url)) {\n                                // <script type=\"module\" src=\"...\"/>\n                                // add it as an import\n                                js += `\\nimport ${JSON.stringify(url)}`;\n                                shouldRemove = true;\n                            }\n                            else if (node.childNodes.length) {\n                                const scriptNode = node.childNodes.pop();\n                                const contents = scriptNode.value;\n                                // <script type=\"module\">...</script>\n                                const filePath = id.replace(normalizePath$3(config.root), '');\n                                addToHTMLProxyCache(config, filePath, inlineModuleIndex, {\n                                    code: contents,\n                                });\n                                js += `\\nimport \"${id}?html-proxy&index=${inlineModuleIndex}.js\"`;\n                                shouldRemove = true;\n                            }\n                            everyScriptIsAsync && (everyScriptIsAsync = isAsync);\n                            someScriptsAreAsync || (someScriptsAreAsync = isAsync);\n                            someScriptsAreDefer || (someScriptsAreDefer = !isAsync);\n                        }\n                        else if (url && !isPublicFile) {\n                            if (!isExcludedUrl(url)) {\n                                config.logger.warn(`<script src=\"${url}\"> in \"${publicPath}\" can't be bundled without type=\"module\" attribute`);\n                            }\n                        }\n                        else if (node.childNodes.length) {\n                            const scriptNode = node.childNodes.pop();\n                            const cleanCode = stripLiteral(scriptNode.value);\n                            let match;\n                            inlineImportRE.lastIndex = 0;\n                            while ((match = inlineImportRE.exec(cleanCode))) {\n                                const { 1: url, index } = match;\n                                const startUrl = cleanCode.indexOf(url, index);\n                                const start = startUrl + 1;\n                                const end = start + url.length - 2;\n                                const startOffset = scriptNode.sourceCodeLocation.startOffset;\n                                scriptUrls.push({\n                                    start: start + startOffset,\n                                    end: end + startOffset,\n                                    url: scriptNode.value.slice(start, end),\n                                });\n                            }\n                        }\n                    }\n                    // For asset references in index.html, also generate an import\n                    // statement for each - this will be handled by the asset plugin\n                    const assetAttrs = assetAttrsConfig[node.nodeName];\n                    if (assetAttrs) {\n                        for (const p of node.attrs) {\n                            const attrKey = getAttrKey(p);\n                            if (p.value && assetAttrs.includes(attrKey)) {\n                                const attrSourceCodeLocation = node.sourceCodeLocation.attrs[attrKey];\n                                // assetsUrl may be encodeURI\n                                const url = decodeURI(p.value);\n                                if (!isExcludedUrl(url)) {\n                                    if (node.nodeName === 'link' &&\n                                        isCSSRequest(url) &&\n                                        // should not be converted if following attributes are present (#6748)\n                                        !node.attrs.some((p) => p.prefix === undefined &&\n                                            (p.name === 'media' || p.name === 'disabled'))) {\n                                        // CSS references, convert to import\n                                        const importExpression = `\\nimport ${JSON.stringify(url)}`;\n                                        styleUrls.push({\n                                            url,\n                                            start: node.sourceCodeLocation.startOffset,\n                                            end: node.sourceCodeLocation.endOffset,\n                                        });\n                                        js += importExpression;\n                                    }\n                                    else {\n                                        assetUrls.push({\n                                            attr: p,\n                                            sourceCodeLocation: attrSourceCodeLocation,\n                                        });\n                                    }\n                                }\n                                else if (checkPublicFile(url, config)) {\n                                    overwriteAttrValue(s, attrSourceCodeLocation, toOutputPublicFilePath(url));\n                                }\n                            }\n                        }\n                    }\n                    // <tag style=\"... url(...) ...\"></tag>\n                    // extract inline styles as virtual css and add class attribute to tag for selecting\n                    const inlineStyle = node.attrs.find((prop) => prop.prefix === undefined &&\n                        prop.name === 'style' &&\n                        prop.value.includes('url('));\n                    if (inlineStyle) {\n                        inlineModuleIndex++;\n                        // replace `inline style` to class\n                        // and import css in js code\n                        const code = inlineStyle.value;\n                        const filePath = id.replace(normalizePath$3(config.root), '');\n                        addToHTMLProxyCache(config, filePath, inlineModuleIndex, { code });\n                        // will transform with css plugin and cache result with css-post plugin\n                        js += `\\nimport \"${id}?html-proxy&inline-css&index=${inlineModuleIndex}.css\"`;\n                        const hash = getHash(cleanUrl(id));\n                        // will transform in `applyHtmlTransforms`\n                        const sourceCodeLocation = node.sourceCodeLocation.attrs['style'];\n                        overwriteAttrValue(s, sourceCodeLocation, `__VITE_INLINE_CSS__${hash}_${inlineModuleIndex}__`);\n                    }\n                    // <style>...</style>\n                    if (node.nodeName === 'style' && node.childNodes.length) {\n                        const styleNode = node.childNodes.pop();\n                        const filePath = id.replace(normalizePath$3(config.root), '');\n                        inlineModuleIndex++;\n                        addToHTMLProxyCache(config, filePath, inlineModuleIndex, {\n                            code: styleNode.value,\n                        });\n                        js += `\\nimport \"${id}?html-proxy&inline-css&index=${inlineModuleIndex}.css\"`;\n                        const hash = getHash(cleanUrl(id));\n                        // will transform in `applyHtmlTransforms`\n                        s.update(styleNode.sourceCodeLocation.startOffset, styleNode.sourceCodeLocation.endOffset, `__VITE_INLINE_CSS__${hash}_${inlineModuleIndex}__`);\n                    }\n                    if (shouldRemove) {\n                        // remove the script tag from the html. we are going to inject new\n                        // ones in the end.\n                        s.remove(node.sourceCodeLocation.startOffset, node.sourceCodeLocation.endOffset);\n                    }\n                });\n                isAsyncScriptMap.get(config).set(id, everyScriptIsAsync);\n                if (someScriptsAreAsync && someScriptsAreDefer) {\n                    config.logger.warn(`\\nMixed async and defer script modules in ${id}, output script will fallback to defer. Every script, including inline ones, need to be marked as async for your output script to be async.`);\n                }\n                // for each encountered asset url, rewrite original html so that it\n                // references the post-build location, ignoring empty attributes and\n                // attributes that directly reference named output.\n                const namedOutput = Object.keys(config?.build?.rollupOptions?.input || {});\n                for (const { attr, sourceCodeLocation } of assetUrls) {\n                    // assetsUrl may be encodeURI\n                    const content = decodeURI(attr.value);\n                    if (content !== '' && // Empty attribute\n                        !namedOutput.includes(content) && // Direct reference to named output\n                        !namedOutput.includes(content.replace(/^\\//, '')) // Allow for absolute references as named output can't be an absolute path\n                    ) {\n                        try {\n                            const url = attr.prefix === undefined && attr.name === 'srcset'\n                                ? await processSrcSet(content, ({ url }) => urlToBuiltUrl(url, id, config, this))\n                                : await urlToBuiltUrl(content, id, config, this);\n                            overwriteAttrValue(s, sourceCodeLocation, url);\n                        }\n                        catch (e) {\n                            if (e.code !== 'ENOENT') {\n                                throw e;\n                            }\n                        }\n                    }\n                }\n                // emit <script>import(\"./aaa\")</script> asset\n                for (const { start, end, url } of scriptUrls) {\n                    if (!isExcludedUrl(url)) {\n                        s.update(start, end, await urlToBuiltUrl(url, id, config, this));\n                    }\n                    else if (checkPublicFile(url, config)) {\n                        s.update(start, end, toOutputPublicFilePath(url));\n                    }\n                }\n                // ignore <link rel=\"stylesheet\"> if its url can't be resolved\n                const resolvedStyleUrls = await Promise.all(styleUrls.map(async (styleUrl) => ({\n                    ...styleUrl,\n                    resolved: await this.resolve(styleUrl.url, id),\n                })));\n                for (const { start, end, url, resolved } of resolvedStyleUrls) {\n                    if (resolved == null) {\n                        config.logger.warnOnce(`\\n${url} doesn't exist at build time, it will remain unchanged to be resolved at runtime`);\n                        const importExpression = `\\nimport ${JSON.stringify(url)}`;\n                        js = js.replace(importExpression, '');\n                    }\n                    else {\n                        s.remove(start, end);\n                    }\n                }\n                processedHtml.set(id, s.toString());\n                // inject module preload polyfill only when configured and needed\n                const { modulePreload } = config.build;\n                if ((modulePreload === true ||\n                    (typeof modulePreload === 'object' && modulePreload.polyfill)) &&\n                    (someScriptsAreAsync || someScriptsAreDefer)) {\n                    js = `import \"${modulePreloadPolyfillId}\";\\n${js}`;\n                }\n                return js;\n            }\n        },\n        async generateBundle(options, bundle) {\n            const analyzedChunk = new Map();\n            const getImportedChunks = (chunk, seen = new Set()) => {\n                const chunks = [];\n                chunk.imports.forEach((file) => {\n                    const importee = bundle[file];\n                    if (importee?.type === 'chunk' && !seen.has(file)) {\n                        seen.add(file);\n                        // post-order traversal\n                        chunks.push(...getImportedChunks(importee, seen));\n                        chunks.push(importee);\n                    }\n                });\n                return chunks;\n            };\n            const toScriptTag = (chunk, toOutputPath, isAsync) => ({\n                tag: 'script',\n                attrs: {\n                    ...(isAsync ? { async: true } : {}),\n                    type: 'module',\n                    crossorigin: true,\n                    src: toOutputPath(chunk.fileName),\n                },\n            });\n            const toPreloadTag = (filename, toOutputPath) => ({\n                tag: 'link',\n                attrs: {\n                    rel: 'modulepreload',\n                    crossorigin: true,\n                    href: toOutputPath(filename),\n                },\n            });\n            const getCssTagsForChunk = (chunk, toOutputPath, seen = new Set()) => {\n                const tags = [];\n                if (!analyzedChunk.has(chunk)) {\n                    analyzedChunk.set(chunk, 1);\n                    chunk.imports.forEach((file) => {\n                        const importee = bundle[file];\n                        if (importee?.type === 'chunk') {\n                            tags.push(...getCssTagsForChunk(importee, toOutputPath, seen));\n                        }\n                    });\n                }\n                chunk.viteMetadata.importedCss.forEach((file) => {\n                    if (!seen.has(file)) {\n                        seen.add(file);\n                        tags.push({\n                            tag: 'link',\n                            attrs: {\n                                rel: 'stylesheet',\n                                href: toOutputPath(file),\n                            },\n                        });\n                    }\n                });\n                return tags;\n            };\n            for (const [id, html] of processedHtml) {\n                const relativeUrlPath = path$o.posix.relative(config.root, normalizePath$3(id));\n                const assetsBase = getBaseInHTML(relativeUrlPath, config);\n                const toOutputFilePath = (filename, type) => {\n                    if (isExternalUrl(filename)) {\n                        return filename;\n                    }\n                    else {\n                        return toOutputFilePathInHtml(filename, type, relativeUrlPath, 'html', config, (filename, importer) => assetsBase + filename);\n                    }\n                };\n                const toOutputAssetFilePath = (filename) => toOutputFilePath(filename, 'asset');\n                const toOutputPublicAssetFilePath = (filename) => toOutputFilePath(filename, 'public');\n                const isAsync = isAsyncScriptMap.get(config).get(id);\n                let result = html;\n                // find corresponding entry chunk\n                const chunk = Object.values(bundle).find((chunk) => chunk.type === 'chunk' &&\n                    chunk.isEntry &&\n                    chunk.facadeModuleId === id);\n                let canInlineEntry = false;\n                // inject chunk asset links\n                if (chunk) {\n                    // an entry chunk can be inlined if\n                    //  - it's an ES module (e.g. not generated by the legacy plugin)\n                    //  - it contains no meaningful code other than import statements\n                    if (options.format === 'es' && isEntirelyImport(chunk.code)) {\n                        canInlineEntry = true;\n                    }\n                    // when not inlined, inject <script> for entry and modulepreload its dependencies\n                    // when inlined, discard entry chunk and inject <script> for everything in post-order\n                    const imports = getImportedChunks(chunk);\n                    let assetTags;\n                    if (canInlineEntry) {\n                        assetTags = imports.map((chunk) => toScriptTag(chunk, toOutputAssetFilePath, isAsync));\n                    }\n                    else {\n                        assetTags = [toScriptTag(chunk, toOutputAssetFilePath, isAsync)];\n                        const { modulePreload } = config.build;\n                        if (modulePreload !== false) {\n                            const resolveDependencies = typeof modulePreload === 'object' &&\n                                modulePreload.resolveDependencies;\n                            const importsFileNames = imports.map((chunk) => chunk.fileName);\n                            const resolvedDeps = resolveDependencies\n                                ? resolveDependencies(chunk.fileName, importsFileNames, {\n                                    hostId: relativeUrlPath,\n                                    hostType: 'html',\n                                })\n                                : importsFileNames;\n                            assetTags.push(...resolvedDeps.map((i) => toPreloadTag(i, toOutputAssetFilePath)));\n                        }\n                    }\n                    assetTags.push(...getCssTagsForChunk(chunk, toOutputAssetFilePath));\n                    result = injectToHead(result, assetTags);\n                }\n                // inject css link when cssCodeSplit is false\n                if (!config.build.cssCodeSplit) {\n                    const cssChunk = Object.values(bundle).find((chunk) => chunk.type === 'asset' && chunk.name === 'style.css');\n                    if (cssChunk) {\n                        result = injectToHead(result, [\n                            {\n                                tag: 'link',\n                                attrs: {\n                                    rel: 'stylesheet',\n                                    href: toOutputAssetFilePath(cssChunk.fileName),\n                                },\n                            },\n                        ]);\n                    }\n                }\n                // no use assets plugin because it will emit file\n                let match;\n                let s;\n                inlineCSSRE$1.lastIndex = 0;\n                while ((match = inlineCSSRE$1.exec(result))) {\n                    s || (s = new MagicString(result));\n                    const { 0: full, 1: scopedName } = match;\n                    const cssTransformedCode = htmlProxyResult.get(scopedName);\n                    s.update(match.index, match.index + full.length, cssTransformedCode);\n                }\n                if (s) {\n                    result = s.toString();\n                }\n                result = await applyHtmlTransforms(result, [...normalHooks, ...postHooks], {\n                    path: '/' + relativeUrlPath,\n                    filename: id,\n                    bundle,\n                    chunk,\n                });\n                // resolve asset url references\n                result = result.replace(assetUrlRE, (_, fileHash, postfix = '') => {\n                    return toOutputAssetFilePath(this.getFileName(fileHash)) + postfix;\n                });\n                result = result.replace(publicAssetUrlRE, (_, fileHash) => {\n                    return normalizePath$3(toOutputPublicAssetFilePath(getPublicAssetFilename(fileHash, config)));\n                });\n                if (chunk && canInlineEntry) {\n                    // all imports from entry have been inlined to html, prevent rollup from outputting it\n                    delete bundle[chunk.fileName];\n                }\n                const shortEmitName = normalizePath$3(path$o.relative(config.root, id));\n                this.emitFile({\n                    type: 'asset',\n                    fileName: shortEmitName,\n                    source: result,\n                });\n            }\n        },\n    };\n}\nfunction preImportMapHook(config) {\n    return (html, ctx) => {\n        const importMapIndex = html.match(importMapRE)?.index;\n        if (importMapIndex === undefined)\n            return;\n        const importMapAppendIndex = html.match(importMapAppendRE)?.index;\n        if (importMapAppendIndex === undefined)\n            return;\n        if (importMapAppendIndex < importMapIndex) {\n            const relativeHtml = normalizePath$3(path$o.relative(config.root, ctx.filename));\n            config.logger.warnOnce(picocolorsExports.yellow(picocolorsExports.bold(`(!) <script type=\"importmap\"> should come before <script type=\"module\"> and <link rel=\"modulepreload\"> in /${relativeHtml}`)));\n        }\n    };\n}\n/**\n * Move importmap before the first module script and modulepreload link\n */\nfunction postImportMapHook() {\n    return (html) => {\n        if (!importMapAppendRE.test(html))\n            return;\n        let importMap;\n        html = html.replace(importMapRE, (match) => {\n            importMap = match;\n            return '';\n        });\n        if (importMap) {\n            html = html.replace(importMapAppendRE, (match) => `${importMap}\\n${match}`);\n        }\n        return html;\n    };\n}\nfunction resolveHtmlTransforms(plugins) {\n    const preHooks = [];\n    const normalHooks = [];\n    const postHooks = [];\n    for (const plugin of plugins) {\n        const hook = plugin.transformIndexHtml;\n        if (!hook)\n            continue;\n        if (typeof hook === 'function') {\n            normalHooks.push(hook);\n        }\n        else {\n            // `enforce` had only two possible values for the `transformIndexHtml` hook\n            // `'pre'` and `'post'` (the default). `order` now works with three values\n            // to align with other hooks (`'pre'`, normal, and `'post'`). We map\n            // both `enforce: 'post'` to `order: undefined` to avoid a breaking change\n            const order = hook.order ?? (hook.enforce === 'pre' ? 'pre' : undefined);\n            // @ts-expect-error union type\n            const handler = hook.handler ?? hook.transform;\n            if (order === 'pre') {\n                preHooks.push(handler);\n            }\n            else if (order === 'post') {\n                postHooks.push(handler);\n            }\n            else {\n                normalHooks.push(handler);\n            }\n        }\n    }\n    return [preHooks, normalHooks, postHooks];\n}\nasync function applyHtmlTransforms(html, hooks, ctx) {\n    for (const hook of hooks) {\n        const res = await hook(html, ctx);\n        if (!res) {\n            continue;\n        }\n        if (typeof res === 'string') {\n            html = res;\n        }\n        else {\n            let tags;\n            if (Array.isArray(res)) {\n                tags = res;\n            }\n            else {\n                html = res.html || html;\n                tags = res.tags;\n            }\n            const headTags = [];\n            const headPrependTags = [];\n            const bodyTags = [];\n            const bodyPrependTags = [];\n            for (const tag of tags) {\n                if (tag.injectTo === 'body') {\n                    bodyTags.push(tag);\n                }\n                else if (tag.injectTo === 'body-prepend') {\n                    bodyPrependTags.push(tag);\n                }\n                else if (tag.injectTo === 'head') {\n                    headTags.push(tag);\n                }\n                else {\n                    headPrependTags.push(tag);\n                }\n            }\n            html = injectToHead(html, headPrependTags, true);\n            html = injectToHead(html, headTags);\n            html = injectToBody(html, bodyPrependTags, true);\n            html = injectToBody(html, bodyTags);\n        }\n    }\n    return html;\n}\nconst importRE = /\\bimport\\s*(\"[^\"]*[^\\\\]\"|'[^']*[^\\\\]');*/g;\nconst commentRE$1 = /\\/\\*[\\s\\S]*?\\*\\/|\\/\\/.*$/gm;\nfunction isEntirelyImport(code) {\n    // only consider \"side-effect\" imports, which match <script type=module> semantics exactly\n    // the regexes will remove too little in some exotic cases, but false-negatives are alright\n    return !code.replace(importRE, '').replace(commentRE$1, '').trim().length;\n}\nfunction getBaseInHTML(urlRelativePath, config) {\n    // Prefer explicit URL if defined for linking to assets and public files from HTML,\n    // even when base relative is specified\n    return config.base === './' || config.base === ''\n        ? path$o.posix.join(path$o.posix.relative(urlRelativePath, '').slice(0, -2), './')\n        : config.base;\n}\nconst headInjectRE = /([ \\t]*)<\\/head>/i;\nconst headPrependInjectRE = /([ \\t]*)<head[^>]*>/i;\nconst htmlInjectRE = /<\\/html>/i;\nconst htmlPrependInjectRE = /([ \\t]*)<html[^>]*>/i;\nconst bodyInjectRE = /([ \\t]*)<\\/body>/i;\nconst bodyPrependInjectRE = /([ \\t]*)<body[^>]*>/i;\nconst doctypePrependInjectRE = /<!doctype html>/i;\nfunction injectToHead(html, tags, prepend = false) {\n    if (tags.length === 0)\n        return html;\n    if (prepend) {\n        // inject as the first element of head\n        if (headPrependInjectRE.test(html)) {\n            return html.replace(headPrependInjectRE, (match, p1) => `${match}\\n${serializeTags(tags, incrementIndent(p1))}`);\n        }\n    }\n    else {\n        // inject before head close\n        if (headInjectRE.test(html)) {\n            // respect indentation of head tag\n            return html.replace(headInjectRE, (match, p1) => `${serializeTags(tags, incrementIndent(p1))}${match}`);\n        }\n        // try to inject before the body tag\n        if (bodyPrependInjectRE.test(html)) {\n            return html.replace(bodyPrependInjectRE, (match, p1) => `${serializeTags(tags, p1)}\\n${match}`);\n        }\n    }\n    // if no head tag is present, we prepend the tag for both prepend and append\n    return prependInjectFallback(html, tags);\n}\nfunction injectToBody(html, tags, prepend = false) {\n    if (tags.length === 0)\n        return html;\n    if (prepend) {\n        // inject after body open\n        if (bodyPrependInjectRE.test(html)) {\n            return html.replace(bodyPrependInjectRE, (match, p1) => `${match}\\n${serializeTags(tags, incrementIndent(p1))}`);\n        }\n        // if no there is no body tag, inject after head or fallback to prepend in html\n        if (headInjectRE.test(html)) {\n            return html.replace(headInjectRE, (match, p1) => `${match}\\n${serializeTags(tags, p1)}`);\n        }\n        return prependInjectFallback(html, tags);\n    }\n    else {\n        // inject before body close\n        if (bodyInjectRE.test(html)) {\n            return html.replace(bodyInjectRE, (match, p1) => `${serializeTags(tags, incrementIndent(p1))}${match}`);\n        }\n        // if no body tag is present, append to the html tag, or at the end of the file\n        if (htmlInjectRE.test(html)) {\n            return html.replace(htmlInjectRE, `${serializeTags(tags)}\\n$&`);\n        }\n        return html + `\\n` + serializeTags(tags);\n    }\n}\nfunction prependInjectFallback(html, tags) {\n    // prepend to the html tag, append after doctype, or the document start\n    if (htmlPrependInjectRE.test(html)) {\n        return html.replace(htmlPrependInjectRE, `$&\\n${serializeTags(tags)}`);\n    }\n    if (doctypePrependInjectRE.test(html)) {\n        return html.replace(doctypePrependInjectRE, `$&\\n${serializeTags(tags)}`);\n    }\n    return serializeTags(tags) + html;\n}\nconst unaryTags = new Set(['link', 'meta', 'base']);\nfunction serializeTag({ tag, attrs, children }, indent = '') {\n    if (unaryTags.has(tag)) {\n        return `<${tag}${serializeAttrs(attrs)}>`;\n    }\n    else {\n        return `<${tag}${serializeAttrs(attrs)}>${serializeTags(children, incrementIndent(indent))}</${tag}>`;\n    }\n}\nfunction serializeTags(tags, indent = '') {\n    if (typeof tags === 'string') {\n        return tags;\n    }\n    else if (tags && tags.length) {\n        return tags.map((tag) => `${indent}${serializeTag(tag, indent)}\\n`).join('');\n    }\n    return '';\n}\nfunction serializeAttrs(attrs) {\n    let res = '';\n    for (const key in attrs) {\n        if (typeof attrs[key] === 'boolean') {\n            res += attrs[key] ? ` ${key}` : ``;\n        }\n        else {\n            res += ` ${key}=${JSON.stringify(attrs[key])}`;\n        }\n    }\n    return res;\n}\nfunction incrementIndent(indent = '') {\n    return `${indent}${indent[0] === '\\t' ? '\\t' : '  '}`;\n}\nfunction getAttrKey(attr) {\n    return attr.prefix === undefined ? attr.name : `${attr.prefix}:${attr.name}`;\n}\n\nconst cssModuleRE = new RegExp(`\\\\.module${CSS_LANGS_RE.source}`);\nconst directRequestRE = /(?:\\?|&)direct\\b/;\nconst htmlProxyRE = /(?:\\?|&)html-proxy\\b/;\nconst commonjsProxyRE = /\\?commonjs-proxy/;\nconst inlineRE = /(?:\\?|&)inline\\b/;\nconst inlineCSSRE = /(?:\\?|&)inline-css\\b/;\nconst usedRE = /(?:\\?|&)used\\b/;\nconst varRE = /^var\\(/i;\nconst cssBundleName = 'style.css';\nconst isCSSRequest = (request) => CSS_LANGS_RE.test(request);\nconst isModuleCSSRequest = (request) => cssModuleRE.test(request);\nconst isDirectCSSRequest = (request) => CSS_LANGS_RE.test(request) && directRequestRE.test(request);\nconst isDirectRequest = (request) => directRequestRE.test(request);\nconst cssModulesCache = new WeakMap();\nconst removedPureCssFilesCache = new WeakMap();\nconst postcssConfigCache = {};\nfunction encodePublicUrlsInCSS(config) {\n    return config.command === 'build';\n}\n/**\n * Plugin applied before user plugins\n */\nfunction cssPlugin(config) {\n    let server;\n    let moduleCache;\n    const resolveUrl = config.createResolver({\n        preferRelative: true,\n        tryIndex: false,\n        extensions: [],\n    });\n    return {\n        name: 'vite:css',\n        configureServer(_server) {\n            server = _server;\n        },\n        buildStart() {\n            // Ensure a new cache for every build (i.e. rebuilding in watch mode)\n            moduleCache = new Map();\n            cssModulesCache.set(config, moduleCache);\n            removedPureCssFilesCache.set(config, new Map());\n        },\n        async transform(raw, id, options) {\n            if (!isCSSRequest(id) ||\n                commonjsProxyRE.test(id) ||\n                SPECIAL_QUERY_RE.test(id)) {\n                return;\n            }\n            const ssr = options?.ssr === true;\n            const urlReplacer = async (url, importer) => {\n                if (checkPublicFile(url, config)) {\n                    if (encodePublicUrlsInCSS(config)) {\n                        return publicFileToBuiltUrl(url, config);\n                    }\n                    else {\n                        return joinUrlSegments(config.base, url);\n                    }\n                }\n                const resolved = await resolveUrl(url, importer);\n                if (resolved) {\n                    return fileToUrl(resolved, config, this);\n                }\n                if (config.command === 'build') {\n                    // #9800 If we cannot resolve the css url, leave a warning.\n                    config.logger.warnOnce(`\\n${url} referenced in ${id} didn't resolve at build time, it will remain unchanged to be resolved at runtime`);\n                }\n                return url;\n            };\n            const { code: css, modules, deps, map, } = await compileCSS(id, raw, config, urlReplacer);\n            if (modules) {\n                moduleCache.set(id, modules);\n            }\n            // track deps for build watch mode\n            if (config.command === 'build' && config.build.watch && deps) {\n                for (const file of deps) {\n                    this.addWatchFile(file);\n                }\n            }\n            // dev\n            if (server) {\n                // server only logic for handling CSS @import dependency hmr\n                const { moduleGraph } = server;\n                const thisModule = moduleGraph.getModuleById(id);\n                if (thisModule) {\n                    // CSS modules cannot self-accept since it exports values\n                    const isSelfAccepting = !modules && !inlineRE.test(id) && !htmlProxyRE.test(id);\n                    if (deps) {\n                        // record deps in the module graph so edits to @import css can trigger\n                        // main import to hot update\n                        const depModules = new Set();\n                        const devBase = config.base;\n                        for (const file of deps) {\n                            depModules.add(isCSSRequest(file)\n                                ? moduleGraph.createFileOnlyEntry(file)\n                                : await moduleGraph.ensureEntryFromUrl(stripBase(await fileToUrl(file, config, this), (config.server?.origin ?? '') + devBase), ssr));\n                        }\n                        moduleGraph.updateModuleInfo(thisModule, depModules, null, \n                        // The root CSS proxy module is self-accepting and should not\n                        // have an explicit accept list\n                        new Set(), null, isSelfAccepting, ssr);\n                        for (const file of deps) {\n                            this.addWatchFile(file);\n                        }\n                    }\n                    else {\n                        thisModule.isSelfAccepting = isSelfAccepting;\n                    }\n                }\n            }\n            return {\n                code: css,\n                map,\n            };\n        },\n    };\n}\n/**\n * Plugin applied after user plugins\n */\nfunction cssPostPlugin(config) {\n    // styles initialization in buildStart causes a styling loss in watch\n    const styles = new Map();\n    let pureCssChunks;\n    // when there are multiple rollup outputs and extracting CSS, only emit once,\n    // since output formats have no effect on the generated CSS.\n    let outputToExtractedCSSMap;\n    let hasEmitted = false;\n    const rollupOptionsOutput = config.build.rollupOptions.output;\n    const assetFileNames = (Array.isArray(rollupOptionsOutput)\n        ? rollupOptionsOutput[0]\n        : rollupOptionsOutput)?.assetFileNames;\n    const getCssAssetDirname = (cssAssetName) => {\n        if (!assetFileNames) {\n            return config.build.assetsDir;\n        }\n        else if (typeof assetFileNames === 'string') {\n            return path$o.dirname(assetFileNames);\n        }\n        else {\n            return path$o.dirname(assetFileNames({\n                name: cssAssetName,\n                type: 'asset',\n                source: '/* vite internal call, ignore */',\n            }));\n        }\n    };\n    return {\n        name: 'vite:css-post',\n        buildStart() {\n            // Ensure new caches for every build (i.e. rebuilding in watch mode)\n            pureCssChunks = new Set();\n            outputToExtractedCSSMap = new Map();\n            hasEmitted = false;\n        },\n        async transform(css, id, options) {\n            if (!isCSSRequest(id) ||\n                commonjsProxyRE.test(id) ||\n                SPECIAL_QUERY_RE.test(id)) {\n                return;\n            }\n            css = stripBomTag(css);\n            const inlined = inlineRE.test(id);\n            const modules = cssModulesCache.get(config).get(id);\n            // #6984, #7552\n            // `foo.module.css` => modulesCode\n            // `foo.module.css?inline` => cssContent\n            const modulesCode = modules &&\n                !inlined &&\n                dataToEsm(modules, { namedExports: true, preferConst: true });\n            if (config.command === 'serve') {\n                const getContentWithSourcemap = async (content) => {\n                    if (config.css?.devSourcemap) {\n                        const sourcemap = this.getCombinedSourcemap();\n                        await injectSourcesContent(sourcemap, cleanUrl(id), config.logger);\n                        return getCodeWithSourcemap('css', content, sourcemap);\n                    }\n                    return content;\n                };\n                if (isDirectCSSRequest(id)) {\n                    return await getContentWithSourcemap(css);\n                }\n                // server only\n                if (options?.ssr) {\n                    return modulesCode || `export default ${JSON.stringify(css)}`;\n                }\n                if (inlined) {\n                    return `export default ${JSON.stringify(css)}`;\n                }\n                const cssContent = await getContentWithSourcemap(css);\n                const code = [\n                    `import { updateStyle as __vite__updateStyle, removeStyle as __vite__removeStyle } from ${JSON.stringify(path$o.posix.join(config.base, CLIENT_PUBLIC_PATH))}`,\n                    `const __vite__id = ${JSON.stringify(id)}`,\n                    `const __vite__css = ${JSON.stringify(cssContent)}`,\n                    `__vite__updateStyle(__vite__id, __vite__css)`,\n                    // css modules exports change on edit so it can't self accept\n                    `${modulesCode ||\n                        `import.meta.hot.accept()\\nexport default __vite__css`}`,\n                    `import.meta.hot.prune(() => __vite__removeStyle(__vite__id))`,\n                ].join('\\n');\n                return { code, map: { mappings: '' } };\n            }\n            // build CSS handling ----------------------------------------------------\n            // record css\n            // cache css compile result to map\n            // and then use the cache replace inline-style-flag when `generateBundle` in vite:build-html plugin\n            const inlineCSS = inlineCSSRE.test(id);\n            const isHTMLProxy = htmlProxyRE.test(id);\n            const query = parseRequest(id);\n            if (inlineCSS && isHTMLProxy) {\n                addToHTMLProxyTransformResult(`${getHash(cleanUrl(id))}_${Number.parseInt(query.index)}`, css);\n                return `export default ''`;\n            }\n            if (!inlined) {\n                styles.set(id, css);\n            }\n            let code;\n            if (usedRE.test(id)) {\n                if (modulesCode) {\n                    code = modulesCode;\n                }\n                else {\n                    let content = css;\n                    if (config.build.minify) {\n                        content = await minifyCSS(content, config);\n                    }\n                    code = `export default ${JSON.stringify(content)}`;\n                }\n            }\n            else {\n                // if moduleCode exists return it **even if** it does not have `?used`\n                // this will disable tree-shake to work with `import './foo.module.css'` but this usually does not happen\n                // this is a limitation of the current approach by `?used` to make tree-shake work\n                // See #8936 for more details\n                code = modulesCode || `export default ''`;\n            }\n            return {\n                code,\n                map: { mappings: '' },\n                // avoid the css module from being tree-shaken so that we can retrieve\n                // it in renderChunk()\n                moduleSideEffects: inlined ? false : 'no-treeshake',\n            };\n        },\n        async renderChunk(code, chunk, opts) {\n            let chunkCSS = '';\n            let isPureCssChunk = true;\n            const ids = Object.keys(chunk.modules);\n            for (const id of ids) {\n                if (styles.has(id)) {\n                    chunkCSS += styles.get(id);\n                    // a css module contains JS, so it makes this not a pure css chunk\n                    if (cssModuleRE.test(id)) {\n                        isPureCssChunk = false;\n                    }\n                }\n                else {\n                    // if the module does not have a style, then it's not a pure css chunk.\n                    // this is true because in the `transform` hook above, only modules\n                    // that are css gets added to the `styles` map.\n                    isPureCssChunk = false;\n                }\n            }\n            if (!chunkCSS) {\n                return null;\n            }\n            const publicAssetUrlMap = publicAssetUrlCache.get(config);\n            // resolve asset URL placeholders to their built file URLs\n            const resolveAssetUrlsInCss = (chunkCSS, cssAssetName) => {\n                const encodedPublicUrls = encodePublicUrlsInCSS(config);\n                const relative = config.base === './' || config.base === '';\n                const cssAssetDirname = encodedPublicUrls || relative\n                    ? getCssAssetDirname(cssAssetName)\n                    : undefined;\n                const toRelative = (filename, importer) => {\n                    // relative base + extracted CSS\n                    const relativePath = path$o.posix.relative(cssAssetDirname, filename);\n                    return relativePath.startsWith('.')\n                        ? relativePath\n                        : './' + relativePath;\n                };\n                // replace asset url references with resolved url.\n                chunkCSS = chunkCSS.replace(assetUrlRE, (_, fileHash, postfix = '') => {\n                    const filename = this.getFileName(fileHash) + postfix;\n                    chunk.viteMetadata.importedAssets.add(cleanUrl(filename));\n                    return toOutputFilePathInCss(filename, 'asset', cssAssetName, 'css', config, toRelative);\n                });\n                // resolve public URL from CSS paths\n                if (encodedPublicUrls) {\n                    const relativePathToPublicFromCSS = path$o.posix.relative(cssAssetDirname, '');\n                    chunkCSS = chunkCSS.replace(publicAssetUrlRE, (_, hash) => {\n                        const publicUrl = publicAssetUrlMap.get(hash).slice(1);\n                        return toOutputFilePathInCss(publicUrl, 'public', cssAssetName, 'css', config, () => `${relativePathToPublicFromCSS}/${publicUrl}`);\n                    });\n                }\n                return chunkCSS;\n            };\n            function ensureFileExt(name, ext) {\n                return normalizePath$3(path$o.format({ ...path$o.parse(name), base: undefined, ext }));\n            }\n            if (config.build.cssCodeSplit) {\n                if (isPureCssChunk) {\n                    // this is a shared CSS-only chunk that is empty.\n                    pureCssChunks.add(chunk);\n                }\n                if (opts.format === 'es' || opts.format === 'cjs') {\n                    const cssAssetName = chunk.facadeModuleId\n                        ? normalizePath$3(path$o.relative(config.root, chunk.facadeModuleId))\n                        : chunk.name;\n                    const lang = path$o.extname(cssAssetName).slice(1);\n                    const cssFileName = ensureFileExt(cssAssetName, '.css');\n                    chunkCSS = resolveAssetUrlsInCss(chunkCSS, cssAssetName);\n                    chunkCSS = await finalizeCss(chunkCSS, true, config);\n                    // emit corresponding css file\n                    const referenceId = this.emitFile({\n                        name: path$o.basename(cssFileName),\n                        type: 'asset',\n                        source: chunkCSS,\n                    });\n                    const originalName = isPreProcessor(lang) ? cssAssetName : cssFileName;\n                    const isEntry = chunk.isEntry && isPureCssChunk;\n                    generatedAssets\n                        .get(config)\n                        .set(referenceId, { originalName, isEntry });\n                    chunk.viteMetadata.importedCss.add(this.getFileName(referenceId));\n                }\n                else if (!config.build.ssr) {\n                    // legacy build and inline css\n                    // Entry chunk CSS will be collected into `chunk.viteMetadata.importedCss`\n                    // and injected later by the `'vite:build-html'` plugin into the `index.html`\n                    // so it will be duplicated. (https://github.com/vitejs/vite/issues/2062#issuecomment-782388010)\n                    // But because entry chunk can be imported by dynamic import,\n                    // we shouldn't remove the inlined CSS. (#10285)\n                    chunkCSS = await finalizeCss(chunkCSS, true, config);\n                    let cssString = JSON.stringify(chunkCSS);\n                    cssString =\n                        renderAssetUrlInJS(this, config, chunk, opts, cssString)?.toString() || cssString;\n                    const style = `__vite_style__`;\n                    const injectCode = `var ${style} = document.createElement('style');` +\n                        `${style}.textContent = ${cssString};` +\n                        `document.head.appendChild(${style});`;\n                    const wrapIdx = code.indexOf('System.register');\n                    const insertMark = \"'use strict';\";\n                    const insertIdx = code.indexOf(insertMark, wrapIdx);\n                    const s = new MagicString(code);\n                    s.appendLeft(insertIdx + insertMark.length, injectCode);\n                    if (config.build.sourcemap) {\n                        // resolve public URL from CSS paths, we need to use absolute paths\n                        return {\n                            code: s.toString(),\n                            map: s.generateMap({ hires: true }),\n                        };\n                    }\n                    else {\n                        return { code: s.toString() };\n                    }\n                }\n            }\n            else {\n                chunkCSS = resolveAssetUrlsInCss(chunkCSS, cssBundleName);\n                // finalizeCss is called for the aggregated chunk in generateBundle\n                outputToExtractedCSSMap.set(opts, (outputToExtractedCSSMap.get(opts) || '') + chunkCSS);\n            }\n            return null;\n        },\n        augmentChunkHash(chunk) {\n            if (chunk.viteMetadata?.importedCss.size) {\n                let hash = '';\n                for (const id of chunk.viteMetadata.importedCss) {\n                    hash += id;\n                }\n                return hash;\n            }\n        },\n        async generateBundle(opts, bundle) {\n            // @ts-expect-error asset emits are skipped in legacy bundle\n            if (opts.__vite_skip_asset_emit__) {\n                return;\n            }\n            // remove empty css chunks and their imports\n            if (pureCssChunks.size) {\n                // map each pure css chunk (rendered chunk) to it's corresponding bundle\n                // chunk. we check that by comparing the `moduleIds` as they have different\n                // filenames (rendered chunk has the !~{XXX}~ placeholder)\n                const pureCssChunkNames = [];\n                for (const pureCssChunk of pureCssChunks) {\n                    for (const key in bundle) {\n                        const bundleChunk = bundle[key];\n                        if (bundleChunk.type === 'chunk' &&\n                            arrayEqual(bundleChunk.moduleIds, pureCssChunk.moduleIds)) {\n                            pureCssChunkNames.push(key);\n                            break;\n                        }\n                    }\n                }\n                const emptyChunkFiles = pureCssChunkNames\n                    .map((file) => path$o.basename(file))\n                    .join('|')\n                    .replace(/\\./g, '\\\\.');\n                const emptyChunkRE = new RegExp(opts.format === 'es'\n                    ? `\\\\bimport\\\\s*[\"'][^\"']*(?:${emptyChunkFiles})[\"'];\\n?`\n                    : `\\\\brequire\\\\(\\\\s*[\"'][^\"']*(?:${emptyChunkFiles})[\"']\\\\);\\n?`, 'g');\n                for (const file in bundle) {\n                    const chunk = bundle[file];\n                    if (chunk.type === 'chunk') {\n                        // remove pure css chunk from other chunk's imports,\n                        // and also register the emitted CSS files under the importer\n                        // chunks instead.\n                        chunk.imports = chunk.imports.filter((file) => {\n                            if (pureCssChunkNames.includes(file)) {\n                                const { importedCss } = bundle[file]\n                                    .viteMetadata;\n                                importedCss.forEach((file) => chunk.viteMetadata.importedCss.add(file));\n                                return false;\n                            }\n                            return true;\n                        });\n                        chunk.code = chunk.code.replace(emptyChunkRE, \n                        // remove css import while preserving source map location\n                        (m) => `/* empty css ${''.padEnd(m.length - 15)}*/`);\n                    }\n                }\n                const removedPureCssFiles = removedPureCssFilesCache.get(config);\n                pureCssChunkNames.forEach((fileName) => {\n                    removedPureCssFiles.set(fileName, bundle[fileName]);\n                    delete bundle[fileName];\n                });\n            }\n            let extractedCss = outputToExtractedCSSMap.get(opts);\n            if (extractedCss && !hasEmitted) {\n                hasEmitted = true;\n                extractedCss = await finalizeCss(extractedCss, true, config);\n                this.emitFile({\n                    name: cssBundleName,\n                    type: 'asset',\n                    source: extractedCss,\n                });\n            }\n        },\n    };\n}\nfunction createCSSResolvers(config) {\n    let cssResolve;\n    let sassResolve;\n    let lessResolve;\n    return {\n        get css() {\n            return (cssResolve ||\n                (cssResolve = config.createResolver({\n                    extensions: ['.css'],\n                    mainFields: ['style'],\n                    tryIndex: false,\n                    preferRelative: true,\n                })));\n        },\n        get sass() {\n            return (sassResolve ||\n                (sassResolve = config.createResolver({\n                    extensions: ['.scss', '.sass', '.css'],\n                    mainFields: ['sass', 'style'],\n                    tryIndex: true,\n                    tryPrefix: '_',\n                    preferRelative: true,\n                })));\n        },\n        get less() {\n            return (lessResolve ||\n                (lessResolve = config.createResolver({\n                    extensions: ['.less', '.css'],\n                    mainFields: ['less', 'style'],\n                    tryIndex: false,\n                    preferRelative: true,\n                })));\n        },\n    };\n}\nfunction getCssResolversKeys(resolvers) {\n    return Object.keys(resolvers);\n}\nconst configToAtImportResolvers = new WeakMap();\nasync function compileCSS(id, code, config, urlReplacer) {\n    const { modules: modulesOptions, preprocessorOptions, devSourcemap, } = config.css || {};\n    const isModule = modulesOptions !== false && cssModuleRE.test(id);\n    // although at serve time it can work without processing, we do need to\n    // crawl them in order to register watch dependencies.\n    const needInlineImport = code.includes('@import');\n    const hasUrl = cssUrlRE.test(code) || cssImageSetRE.test(code);\n    const lang = id.match(CSS_LANGS_RE)?.[1];\n    const postcssConfig = await resolvePostcssConfig(config, getCssDialect(lang));\n    // 1. plain css that needs no processing\n    if (lang === 'css' &&\n        !postcssConfig &&\n        !isModule &&\n        !needInlineImport &&\n        !hasUrl) {\n        return { code, map: null };\n    }\n    let preprocessorMap;\n    let modules;\n    const deps = new Set();\n    let atImportResolvers = configToAtImportResolvers.get(config);\n    if (!atImportResolvers) {\n        atImportResolvers = createCSSResolvers(config);\n        configToAtImportResolvers.set(config, atImportResolvers);\n    }\n    // 2. pre-processors: sass etc.\n    if (isPreProcessor(lang)) {\n        const preProcessor = preProcessors[lang];\n        let opts = (preprocessorOptions && preprocessorOptions[lang]) || {};\n        // support @import from node dependencies by default\n        switch (lang) {\n            case \"scss\" /* PreprocessLang.scss */:\n            case \"sass\" /* PreprocessLang.sass */:\n                opts = {\n                    includePaths: ['node_modules'],\n                    alias: config.resolve.alias,\n                    ...opts,\n                };\n                break;\n            case \"less\" /* PreprocessLang.less */:\n            case \"styl\" /* PreprocessLang.styl */:\n            case \"stylus\" /* PreprocessLang.stylus */:\n                opts = {\n                    paths: ['node_modules'],\n                    alias: config.resolve.alias,\n                    ...opts,\n                };\n        }\n        // important: set this for relative import resolving\n        opts.filename = cleanUrl(id);\n        opts.enableSourcemap = devSourcemap ?? false;\n        const preprocessResult = await preProcessor(code, config.root, opts, atImportResolvers);\n        if (preprocessResult.error) {\n            throw preprocessResult.error;\n        }\n        code = preprocessResult.code;\n        preprocessorMap = combineSourcemapsIfExists(opts.filename, preprocessResult.map, preprocessResult.additionalMap);\n        if (preprocessResult.deps) {\n            preprocessResult.deps.forEach((dep) => {\n                // sometimes sass registers the file itself as a dep\n                if (normalizePath$3(dep) !== normalizePath$3(opts.filename)) {\n                    deps.add(dep);\n                }\n            });\n        }\n    }\n    // 3. postcss\n    const postcssOptions = (postcssConfig && postcssConfig.options) || {};\n    // for sugarss change parser\n    if (lang === 'sss') {\n        postcssOptions.parser = loadPreprocessor(\"sugarss\" /* PostCssDialectLang.sss */, config.root);\n    }\n    const postcssPlugins = postcssConfig && postcssConfig.plugins ? postcssConfig.plugins.slice() : [];\n    if (needInlineImport) {\n        postcssPlugins.unshift((await import('./dep-53dc1ef4.js').then(function (n) { return n.i; })).default({\n            async resolve(id, basedir) {\n                const publicFile = checkPublicFile(id, config);\n                if (publicFile) {\n                    return publicFile;\n                }\n                const resolved = await atImportResolvers.css(id, path$o.join(basedir, '*'));\n                if (resolved) {\n                    return path$o.resolve(resolved);\n                }\n                return id;\n            },\n            nameLayer(index) {\n                return `vite--anon-layer-${getHash(id)}-${index}`;\n            },\n        }));\n    }\n    if (urlReplacer) {\n        postcssPlugins.push(UrlRewritePostcssPlugin({\n            replacer: urlReplacer,\n            logger: config.logger,\n        }));\n    }\n    if (isModule) {\n        postcssPlugins.unshift((await import('./dep-f597f42f.js').then(function (n) { return n.i; })).default({\n            ...modulesOptions,\n            localsConvention: modulesOptions?.localsConvention,\n            getJSON(cssFileName, _modules, outputFileName) {\n                modules = _modules;\n                if (modulesOptions && typeof modulesOptions.getJSON === 'function') {\n                    modulesOptions.getJSON(cssFileName, _modules, outputFileName);\n                }\n            },\n            async resolve(id, importer) {\n                for (const key of getCssResolversKeys(atImportResolvers)) {\n                    const resolved = await atImportResolvers[key](id, importer);\n                    if (resolved) {\n                        return path$o.resolve(resolved);\n                    }\n                }\n                return id;\n            },\n        }));\n    }\n    if (!postcssPlugins.length) {\n        return {\n            code,\n            map: preprocessorMap,\n        };\n    }\n    let postcssResult;\n    try {\n        const source = removeDirectQuery(id);\n        // postcss is an unbundled dep and should be lazy imported\n        postcssResult = await (await import('postcss'))\n            .default(postcssPlugins)\n            .process(code, {\n            ...postcssOptions,\n            to: source,\n            from: source,\n            ...(devSourcemap\n                ? {\n                    map: {\n                        inline: false,\n                        annotation: false,\n                        // postcss may return virtual files\n                        // we cannot obtain content of them, so this needs to be enabled\n                        sourcesContent: true,\n                        // when \"prev: preprocessorMap\", the result map may include duplicate filename in `postcssResult.map.sources`\n                        // prev: preprocessorMap,\n                    },\n                }\n                : {}),\n        });\n        // record CSS dependencies from @imports\n        for (const message of postcssResult.messages) {\n            if (message.type === 'dependency') {\n                deps.add(normalizePath$3(message.file));\n            }\n            else if (message.type === 'dir-dependency') {\n                // https://github.com/postcss/postcss/blob/main/docs/guidelines/plugin.md#3-dependencies\n                const { dir, glob: globPattern = '**' } = message;\n                const pattern = out.escapePath(normalizePath$3(path$o.resolve(path$o.dirname(id), dir))) +\n                    `/` +\n                    globPattern;\n                const files = out.sync(pattern, {\n                    ignore: ['**/node_modules/**'],\n                });\n                for (let i = 0; i < files.length; i++) {\n                    deps.add(files[i]);\n                }\n            }\n            else if (message.type === 'warning') {\n                let msg = `[vite:css] ${message.text}`;\n                if (message.line && message.column) {\n                    msg += `\\n${generateCodeFrame(code, {\n                        line: message.line,\n                        column: message.column,\n                    })}`;\n                }\n                config.logger.warn(picocolorsExports.yellow(msg));\n            }\n        }\n    }\n    catch (e) {\n        e.message = `[postcss] ${e.message}`;\n        e.code = code;\n        e.loc = {\n            column: e.column,\n            line: e.line,\n        };\n        throw e;\n    }\n    if (!devSourcemap) {\n        return {\n            ast: postcssResult,\n            code: postcssResult.css,\n            map: { mappings: '' },\n            modules,\n            deps,\n        };\n    }\n    const rawPostcssMap = postcssResult.map.toJSON();\n    const postcssMap = await formatPostcssSourceMap(\n    // version property of rawPostcssMap is declared as string\n    // but actually it is a number\n    rawPostcssMap, cleanUrl(id));\n    return {\n        ast: postcssResult,\n        code: postcssResult.css,\n        map: combineSourcemapsIfExists(cleanUrl(id), postcssMap, preprocessorMap),\n        modules,\n        deps,\n    };\n}\n/**\n * @experimental\n */\nasync function preprocessCSS(code, filename, config) {\n    return await compileCSS(filename, code, config);\n}\nasync function formatPostcssSourceMap(rawMap, file) {\n    const inputFileDir = path$o.dirname(file);\n    const sources = rawMap.sources.map((source) => {\n        const cleanSource = cleanUrl(decodeURIComponent(source));\n        // postcss returns virtual files\n        if (/^<.+>$/.test(cleanSource)) {\n            return `\\0${cleanSource}`;\n        }\n        return normalizePath$3(path$o.resolve(inputFileDir, cleanSource));\n    });\n    return {\n        file,\n        mappings: rawMap.mappings,\n        names: rawMap.names,\n        sources,\n        sourcesContent: rawMap.sourcesContent,\n        version: rawMap.version,\n    };\n}\nfunction combineSourcemapsIfExists(filename, map1, map2) {\n    return map1 && map2\n        ? combineSourcemaps(filename, [\n            // type of version property of ExistingRawSourceMap is number\n            // but it is always 3\n            map1,\n            map2,\n        ])\n        : map1;\n}\nasync function finalizeCss(css, minify, config) {\n    // hoist external @imports and @charset to the top of the CSS chunk per spec (#1845 and #6333)\n    if (css.includes('@import') || css.includes('@charset')) {\n        css = await hoistAtRules(css);\n    }\n    if (minify && config.build.minify) {\n        css = await minifyCSS(css, config);\n    }\n    return css;\n}\nasync function resolvePostcssConfig(config, dialect = 'css') {\n    postcssConfigCache[dialect] ?? (postcssConfigCache[dialect] = new WeakMap());\n    let result = postcssConfigCache[dialect].get(config);\n    if (result !== undefined) {\n        return result;\n    }\n    // inline postcss config via vite config\n    const inlineOptions = config.css?.postcss;\n    if (isObject$1(inlineOptions)) {\n        const options = { ...inlineOptions };\n        delete options.plugins;\n        result = {\n            options,\n            plugins: inlineOptions.plugins || [],\n        };\n    }\n    else {\n        const searchPath = typeof inlineOptions === 'string' ? inlineOptions : config.root;\n        try {\n            result = await src$1({}, searchPath);\n        }\n        catch (e) {\n            if (!/No PostCSS Config found/.test(e.message)) {\n                if (e instanceof Error) {\n                    const { name, message, stack } = e;\n                    e.name = 'Failed to load PostCSS config';\n                    e.message = `Failed to load PostCSS config (searchPath: ${searchPath}): [${name}] ${message}\\n${stack}`;\n                    e.stack = ''; // add stack to message to retain stack\n                    throw e;\n                }\n                else {\n                    throw new Error(`Failed to load PostCSS config: ${e}`);\n                }\n            }\n            result = null;\n        }\n    }\n    postcssConfigCache[dialect].set(config, result);\n    return result;\n}\n// https://drafts.csswg.org/css-syntax-3/#identifier-code-point\nconst cssUrlRE = /(?<=^|[^\\w\\-\\u0080-\\uffff])url\\((\\s*('[^']+'|\"[^\"]+\")\\s*|[^'\")]+)\\)/;\nconst cssDataUriRE = /(?<=^|[^\\w\\-\\u0080-\\uffff])data-uri\\((\\s*('[^']+'|\"[^\"]+\")\\s*|[^'\")]+)\\)/;\nconst importCssRE = /@import ('[^']+\\.css'|\"[^\"]+\\.css\"|[^'\")]+\\.css)/;\n// Assuming a function name won't be longer than 256 chars\n// eslint-disable-next-line regexp/no-unused-capturing-group -- doesn't detect asyncReplace usage\nconst cssImageSetRE = /(?<=image-set\\()((?:[\\w\\-]{1,256}\\([^)]*\\)|[^)])*)(?=\\))/;\nconst UrlRewritePostcssPlugin = (opts) => {\n    if (!opts) {\n        throw new Error('base or replace is required');\n    }\n    return {\n        postcssPlugin: 'vite-url-rewrite',\n        Once(root) {\n            const promises = [];\n            root.walkDecls((declaration) => {\n                const importer = declaration.source?.input.file;\n                if (!importer) {\n                    opts.logger.warnOnce('\\nA PostCSS plugin did not pass the `from` option to `postcss.parse`. ' +\n                        'This may cause imported assets to be incorrectly transformed. ' +\n                        \"If you've recently added a PostCSS plugin that raised this warning, \" +\n                        'please contact the package author to fix the issue.');\n                }\n                const isCssUrl = cssUrlRE.test(declaration.value);\n                const isCssImageSet = cssImageSetRE.test(declaration.value);\n                if (isCssUrl || isCssImageSet) {\n                    const replacerForDeclaration = (rawUrl) => {\n                        return opts.replacer(rawUrl, importer);\n                    };\n                    const rewriterToUse = isCssImageSet\n                        ? rewriteCssImageSet\n                        : rewriteCssUrls;\n                    promises.push(rewriterToUse(declaration.value, replacerForDeclaration).then((url) => {\n                        declaration.value = url;\n                    }));\n                }\n            });\n            if (promises.length) {\n                return Promise.all(promises);\n            }\n        },\n    };\n};\nUrlRewritePostcssPlugin.postcss = true;\nfunction rewriteCssUrls(css, replacer) {\n    return asyncReplace(css, cssUrlRE, async (match) => {\n        const [matched, rawUrl] = match;\n        return await doUrlReplace(rawUrl.trim(), matched, replacer);\n    });\n}\nfunction rewriteCssDataUris(css, replacer) {\n    return asyncReplace(css, cssDataUriRE, async (match) => {\n        const [matched, rawUrl] = match;\n        return await doUrlReplace(rawUrl.trim(), matched, replacer, 'data-uri');\n    });\n}\nfunction rewriteImportCss(css, replacer) {\n    return asyncReplace(css, importCssRE, async (match) => {\n        const [matched, rawUrl] = match;\n        return await doImportCSSReplace(rawUrl, matched, replacer);\n    });\n}\n// TODO: image and cross-fade could contain a \"url\" that needs to be processed\n// https://drafts.csswg.org/css-images-4/#image-notation\n// https://drafts.csswg.org/css-images-4/#cross-fade-function\nconst cssNotProcessedRE = /(?:gradient|element|cross-fade|image)\\(/;\nasync function rewriteCssImageSet(css, replacer) {\n    return await asyncReplace(css, cssImageSetRE, async (match) => {\n        const [, rawUrl] = match;\n        const url = await processSrcSet(rawUrl, async ({ url }) => {\n            // the url maybe url(...)\n            if (cssUrlRE.test(url)) {\n                return await rewriteCssUrls(url, replacer);\n            }\n            if (!cssNotProcessedRE.test(url)) {\n                return await doUrlReplace(url, url, replacer);\n            }\n            return url;\n        });\n        return url;\n    });\n}\nasync function doUrlReplace(rawUrl, matched, replacer, funcName = 'url') {\n    let wrap = '';\n    const first = rawUrl[0];\n    if (first === `\"` || first === `'`) {\n        wrap = first;\n        rawUrl = rawUrl.slice(1, -1);\n    }\n    if (isExternalUrl(rawUrl) ||\n        isDataUrl(rawUrl) ||\n        rawUrl.startsWith('#') ||\n        varRE.test(rawUrl)) {\n        return matched;\n    }\n    const newUrl = await replacer(rawUrl);\n    if (wrap === '' && newUrl !== encodeURI(newUrl)) {\n        // The new url might need wrapping even if the original did not have it, e.g. if a space was added during replacement\n        wrap = \"'\";\n    }\n    return `${funcName}(${wrap}${newUrl}${wrap})`;\n}\nasync function doImportCSSReplace(rawUrl, matched, replacer) {\n    let wrap = '';\n    const first = rawUrl[0];\n    if (first === `\"` || first === `'`) {\n        wrap = first;\n        rawUrl = rawUrl.slice(1, -1);\n    }\n    if (isExternalUrl(rawUrl) || isDataUrl(rawUrl) || rawUrl.startsWith('#')) {\n        return matched;\n    }\n    return `@import ${wrap}${await replacer(rawUrl)}${wrap}`;\n}\nasync function minifyCSS(css, config) {\n    try {\n        const { code, warnings } = await transform$2(css, {\n            loader: 'css',\n            target: config.build.cssTarget || undefined,\n            ...resolveEsbuildMinifyOptions(config.esbuild || {}),\n        });\n        if (warnings.length) {\n            const msgs = await formatMessages(warnings, { kind: 'warning' });\n            config.logger.warn(picocolorsExports.yellow(`warnings when minifying css:\\n${msgs.join('\\n')}`));\n        }\n        return code;\n    }\n    catch (e) {\n        if (e.errors) {\n            e.message = '[esbuild css minify] ' + e.message;\n            const msgs = await formatMessages(e.errors, { kind: 'error' });\n            e.frame = '\\n' + msgs.join('\\n');\n            e.loc = e.errors[0].location;\n        }\n        throw e;\n    }\n}\nfunction resolveEsbuildMinifyOptions(options) {\n    const base = {\n        logLevel: options.logLevel,\n        logLimit: options.logLimit,\n        logOverride: options.logOverride,\n    };\n    if (options.minifyIdentifiers != null ||\n        options.minifySyntax != null ||\n        options.minifyWhitespace != null) {\n        return {\n            ...base,\n            minifyIdentifiers: options.minifyIdentifiers ?? true,\n            minifySyntax: options.minifySyntax ?? true,\n            minifyWhitespace: options.minifyWhitespace ?? true,\n        };\n    }\n    else {\n        return { ...base, minify: true };\n    }\n}\nasync function hoistAtRules(css) {\n    const s = new MagicString(css);\n    const cleanCss = emptyCssComments(css);\n    let match;\n    // #1845\n    // CSS @import can only appear at top of the file. We need to hoist all @import\n    // to top when multiple files are concatenated.\n    // match until semicolon that's not in quotes\n    const atImportRE = /@import(?:\\s*(?:url\\([^)]*\\)|\"(?:[^\"]|(?<=\\\\)\")*\"|'(?:[^']|(?<=\\\\)')*').*?|[^;]*);/g;\n    while ((match = atImportRE.exec(cleanCss))) {\n        s.remove(match.index, match.index + match[0].length);\n        // Use `appendLeft` instead of `prepend` to preserve original @import order\n        s.appendLeft(0, match[0]);\n    }\n    // #6333\n    // CSS @charset must be the top-first in the file, hoist the first to top\n    const atCharsetRE = /@charset(?:\\s*(?:\"(?:[^\"]|(?<=\\\\)\")*\"|'(?:[^']|(?<=\\\\)')*').*?|[^;]*);/g;\n    let foundCharset = false;\n    while ((match = atCharsetRE.exec(cleanCss))) {\n        s.remove(match.index, match.index + match[0].length);\n        if (!foundCharset) {\n            s.prepend(match[0]);\n            foundCharset = true;\n        }\n    }\n    return s.toString();\n}\nconst loadedPreprocessors = {};\n// TODO: use dynamic import\nconst _require$1 = createRequire$1(import.meta.url);\nfunction loadPreprocessor(lang, root) {\n    if (lang in loadedPreprocessors) {\n        return loadedPreprocessors[lang];\n    }\n    try {\n        const resolved = requireResolveFromRootWithFallback(root, lang);\n        return (loadedPreprocessors[lang] = _require$1(resolved));\n    }\n    catch (e) {\n        if (e.code === 'MODULE_NOT_FOUND') {\n            throw new Error(`Preprocessor dependency \"${lang}\" not found. Did you install it?`);\n        }\n        else {\n            const message = new Error(`Preprocessor dependency \"${lang}\" failed to load:\\n${e.message}`);\n            message.stack = e.stack + '\\n' + message.stack;\n            throw message;\n        }\n    }\n}\n// in unix, scss might append `location.href` in environments that shim `location`\n// see https://github.com/sass/dart-sass/issues/710\nfunction cleanScssBugUrl(url) {\n    if (\n    // check bug via `window` and `location` global\n    typeof window !== 'undefined' &&\n        typeof location !== 'undefined') {\n        const prefix = location.href.replace(/\\/$/, '');\n        return url.replace(prefix, '');\n    }\n    else {\n        return url;\n    }\n}\nfunction fixScssBugImportValue(data) {\n    // the scss bug doesn't load files properly so we have to load it ourselves\n    // to prevent internal error when it loads itself\n    if (\n    // check bug via `window` and `location` global\n    typeof window !== 'undefined' &&\n        typeof location !== 'undefined' &&\n        data &&\n        'file' in data &&\n        (!('contents' in data) || data.contents == null)) {\n        // @ts-expect-error we need to preserve file property for HMR\n        data.contents = fs$l.readFileSync(data.file, 'utf-8');\n    }\n    return data;\n}\n// .scss/.sass processor\nconst scss = async (source, root, options, resolvers) => {\n    const render = loadPreprocessor(\"sass\" /* PreprocessLang.sass */, root).render;\n    // NOTE: `sass` always runs it's own importer first, and only falls back to\n    // the `importer` option when it can't resolve a path\n    const internalImporter = (url, importer, done) => {\n        importer = cleanScssBugUrl(importer);\n        resolvers.sass(url, importer).then((resolved) => {\n            if (resolved) {\n                rebaseUrls(resolved, options.filename, options.alias, '$')\n                    .then((data) => done?.(fixScssBugImportValue(data)))\n                    .catch((data) => done?.(data));\n            }\n            else {\n                done?.(null);\n            }\n        });\n    };\n    const importer = [internalImporter];\n    if (options.importer) {\n        Array.isArray(options.importer)\n            ? importer.unshift(...options.importer)\n            : importer.unshift(options.importer);\n    }\n    const { content: data, map: additionalMap } = await getSource(source, options.filename, options.additionalData, options.enableSourcemap);\n    const finalOptions = {\n        ...options,\n        data,\n        file: options.filename,\n        outFile: options.filename,\n        importer,\n        ...(options.enableSourcemap\n            ? {\n                sourceMap: true,\n                omitSourceMapUrl: true,\n                sourceMapRoot: path$o.dirname(options.filename),\n            }\n            : {}),\n    };\n    try {\n        const result = await new Promise((resolve, reject) => {\n            render(finalOptions, (err, res) => {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve(res);\n                }\n            });\n        });\n        const deps = result.stats.includedFiles.map((f) => cleanScssBugUrl(f));\n        const map = result.map\n            ? JSON.parse(result.map.toString())\n            : undefined;\n        return {\n            code: result.css.toString(),\n            map,\n            additionalMap,\n            deps,\n        };\n    }\n    catch (e) {\n        // normalize SASS error\n        e.message = `[sass] ${e.message}`;\n        e.id = e.file;\n        e.frame = e.formatted;\n        return { code: '', error: e, deps: [] };\n    }\n};\nconst sass = (source, root, options, aliasResolver) => scss(source, root, {\n    ...options,\n    indentedSyntax: true,\n}, aliasResolver);\n/**\n * relative url() inside \\@imported sass and less files must be rebased to use\n * root file as base.\n */\nasync function rebaseUrls(file, rootFile, alias, variablePrefix) {\n    file = path$o.resolve(file); // ensure os-specific flashes\n    // in the same dir, no need to rebase\n    const fileDir = path$o.dirname(file);\n    const rootDir = path$o.dirname(rootFile);\n    if (fileDir === rootDir) {\n        return { file };\n    }\n    const content = fs$l.readFileSync(file, 'utf-8');\n    // no url()\n    const hasUrls = cssUrlRE.test(content);\n    // data-uri() calls\n    const hasDataUris = cssDataUriRE.test(content);\n    // no @import xxx.css\n    const hasImportCss = importCssRE.test(content);\n    if (!hasUrls && !hasDataUris && !hasImportCss) {\n        return { file };\n    }\n    let rebased;\n    const rebaseFn = (url) => {\n        if (url.startsWith('/'))\n            return url;\n        // ignore url's starting with variable\n        if (url.startsWith(variablePrefix))\n            return url;\n        // match alias, no need to rewrite\n        for (const { find } of alias) {\n            const matches = typeof find === 'string' ? url.startsWith(find) : find.test(url);\n            if (matches) {\n                return url;\n            }\n        }\n        const absolute = path$o.resolve(fileDir, url);\n        const relative = path$o.relative(rootDir, absolute);\n        return normalizePath$3(relative);\n    };\n    // fix css imports in less such as `@import \"foo.css\"`\n    if (hasImportCss) {\n        rebased = await rewriteImportCss(content, rebaseFn);\n    }\n    if (hasUrls) {\n        rebased = await rewriteCssUrls(rebased || content, rebaseFn);\n    }\n    if (hasDataUris) {\n        rebased = await rewriteCssDataUris(rebased || content, rebaseFn);\n    }\n    return {\n        file,\n        contents: rebased,\n    };\n}\n// .less\nconst less = async (source, root, options, resolvers) => {\n    const nodeLess = loadPreprocessor(\"less\" /* PreprocessLang.less */, root);\n    const viteResolverPlugin = createViteLessPlugin(nodeLess, options.filename, options.alias, resolvers);\n    const { content, map: additionalMap } = await getSource(source, options.filename, options.additionalData, options.enableSourcemap);\n    let result;\n    try {\n        result = await nodeLess.render(content, {\n            ...options,\n            plugins: [viteResolverPlugin, ...(options.plugins || [])],\n            ...(options.enableSourcemap\n                ? {\n                    sourceMap: {\n                        outputSourceFiles: true,\n                        sourceMapFileInline: false,\n                    },\n                }\n                : {}),\n        });\n    }\n    catch (e) {\n        const error = e;\n        // normalize error info\n        const normalizedError = new Error(`[less] ${error.message || error.type}`);\n        normalizedError.loc = {\n            file: error.filename || options.filename,\n            line: error.line,\n            column: error.column,\n        };\n        return { code: '', error: normalizedError, deps: [] };\n    }\n    const map = result.map && JSON.parse(result.map);\n    if (map) {\n        delete map.sourcesContent;\n    }\n    return {\n        code: result.css.toString(),\n        map,\n        additionalMap,\n        deps: result.imports,\n    };\n};\n/**\n * Less manager, lazy initialized\n */\nlet ViteLessManager;\nfunction createViteLessPlugin(less, rootFile, alias, resolvers) {\n    if (!ViteLessManager) {\n        ViteLessManager = class ViteManager extends less.FileManager {\n            constructor(rootFile, resolvers, alias) {\n                super();\n                this.rootFile = rootFile;\n                this.resolvers = resolvers;\n                this.alias = alias;\n            }\n            supports() {\n                return true;\n            }\n            supportsSync() {\n                return false;\n            }\n            async loadFile(filename, dir, opts, env) {\n                const resolved = await this.resolvers.less(filename, path$o.join(dir, '*'));\n                if (resolved) {\n                    const result = await rebaseUrls(resolved, this.rootFile, this.alias, '@');\n                    let contents;\n                    if (result && 'contents' in result) {\n                        contents = result.contents;\n                    }\n                    else {\n                        contents = fs$l.readFileSync(resolved, 'utf-8');\n                    }\n                    return {\n                        filename: path$o.resolve(resolved),\n                        contents,\n                    };\n                }\n                else {\n                    return super.loadFile(filename, dir, opts, env);\n                }\n            }\n        };\n    }\n    return {\n        install(_, pluginManager) {\n            pluginManager.addFileManager(new ViteLessManager(rootFile, resolvers, alias));\n        },\n        minVersion: [3, 0, 0],\n    };\n}\n// .styl\nconst styl = async (source, root, options) => {\n    const nodeStylus = loadPreprocessor(\"stylus\" /* PreprocessLang.stylus */, root);\n    // Get source with preprocessor options.additionalData. Make sure a new line separator\n    // is added to avoid any render error, as added stylus content may not have semi-colon separators\n    const { content, map: additionalMap } = await getSource(source, options.filename, options.additionalData, options.enableSourcemap, '\\n');\n    // Get preprocessor options.imports dependencies as stylus\n    // does not return them with its builtin `.deps()` method\n    const importsDeps = (options.imports ?? []).map((dep) => path$o.resolve(dep));\n    try {\n        const ref = nodeStylus(content, options);\n        if (options.enableSourcemap) {\n            ref.set('sourcemap', {\n                comment: false,\n                inline: false,\n                basePath: root,\n            });\n        }\n        const result = ref.render();\n        // Concat imports deps with computed deps\n        const deps = [...ref.deps(), ...importsDeps];\n        // @ts-expect-error sourcemap exists\n        const map = ref.sourcemap;\n        return {\n            code: result,\n            map: formatStylusSourceMap(map, root),\n            additionalMap,\n            deps,\n        };\n    }\n    catch (e) {\n        e.message = `[stylus] ${e.message}`;\n        return { code: '', error: e, deps: [] };\n    }\n};\nfunction formatStylusSourceMap(mapBefore, root) {\n    if (!mapBefore)\n        return undefined;\n    const map = { ...mapBefore };\n    const resolveFromRoot = (p) => normalizePath$3(path$o.resolve(root, p));\n    if (map.file) {\n        map.file = resolveFromRoot(map.file);\n    }\n    map.sources = map.sources.map(resolveFromRoot);\n    return map;\n}\nasync function getSource(source, filename, additionalData, enableSourcemap, sep = '') {\n    if (!additionalData)\n        return { content: source };\n    if (typeof additionalData === 'function') {\n        const newContent = await additionalData(source, filename);\n        if (typeof newContent === 'string') {\n            return { content: newContent };\n        }\n        return newContent;\n    }\n    if (!enableSourcemap) {\n        return { content: additionalData + sep + source };\n    }\n    const ms = new MagicString(source);\n    ms.appendLeft(0, sep);\n    ms.appendLeft(0, additionalData);\n    const map = ms.generateMap({ hires: true });\n    map.file = filename;\n    map.sources = [filename];\n    return {\n        content: ms.toString(),\n        map,\n    };\n}\nconst preProcessors = Object.freeze({\n    [\"less\" /* PreprocessLang.less */]: less,\n    [\"sass\" /* PreprocessLang.sass */]: sass,\n    [\"scss\" /* PreprocessLang.scss */]: scss,\n    [\"styl\" /* PreprocessLang.styl */]: styl,\n    [\"stylus\" /* PreprocessLang.stylus */]: styl,\n});\nfunction isPreProcessor(lang) {\n    return lang && lang in preProcessors;\n}\nfunction getCssDialect(lang) {\n    return lang === 'sss' ? 'sss' : 'css';\n}\n\n// AST walker module for Mozilla Parser API compatible trees\n\nfunction makeTest(test) {\n  if (typeof test === \"string\")\n    { return function (type) { return type === test; } }\n  else if (!test)\n    { return function () { return true; } }\n  else\n    { return test }\n}\n\nvar Found = function Found(node, state) { this.node = node; this.state = state; };\n\n// Find a node with a given start, end, and type (all are optional,\n// null can be used as wildcard). Returns a {node, state} object, or\n// undefined when it doesn't find a matching node.\nfunction findNodeAt(node, start, end, test, baseVisitor, state) {\n  if (!baseVisitor) { baseVisitor = base; }\n  test = makeTest(test);\n  try {\n    (function c(node, st, override) {\n      var type = override || node.type;\n      if ((start == null || node.start <= start) &&\n          (end == null || node.end >= end))\n        { baseVisitor[type](node, st, c); }\n      if ((start == null || node.start === start) &&\n          (end == null || node.end === end) &&\n          test(type, node))\n        { throw new Found(node, st) }\n    })(node, state);\n  } catch (e) {\n    if (e instanceof Found) { return e }\n    throw e\n  }\n}\n\nfunction skipThrough(node, st, c) { c(node, st); }\nfunction ignore(_node, _st, _c) {}\n\n// Node walkers.\n\nvar base = {};\n\nbase.Program = base.BlockStatement = base.StaticBlock = function (node, st, c) {\n  for (var i = 0, list = node.body; i < list.length; i += 1)\n    {\n    var stmt = list[i];\n\n    c(stmt, st, \"Statement\");\n  }\n};\nbase.Statement = skipThrough;\nbase.EmptyStatement = ignore;\nbase.ExpressionStatement = base.ParenthesizedExpression = base.ChainExpression =\n  function (node, st, c) { return c(node.expression, st, \"Expression\"); };\nbase.IfStatement = function (node, st, c) {\n  c(node.test, st, \"Expression\");\n  c(node.consequent, st, \"Statement\");\n  if (node.alternate) { c(node.alternate, st, \"Statement\"); }\n};\nbase.LabeledStatement = function (node, st, c) { return c(node.body, st, \"Statement\"); };\nbase.BreakStatement = base.ContinueStatement = ignore;\nbase.WithStatement = function (node, st, c) {\n  c(node.object, st, \"Expression\");\n  c(node.body, st, \"Statement\");\n};\nbase.SwitchStatement = function (node, st, c) {\n  c(node.discriminant, st, \"Expression\");\n  for (var i$1 = 0, list$1 = node.cases; i$1 < list$1.length; i$1 += 1) {\n    var cs = list$1[i$1];\n\n    if (cs.test) { c(cs.test, st, \"Expression\"); }\n    for (var i = 0, list = cs.consequent; i < list.length; i += 1)\n      {\n      var cons = list[i];\n\n      c(cons, st, \"Statement\");\n    }\n  }\n};\nbase.SwitchCase = function (node, st, c) {\n  if (node.test) { c(node.test, st, \"Expression\"); }\n  for (var i = 0, list = node.consequent; i < list.length; i += 1)\n    {\n    var cons = list[i];\n\n    c(cons, st, \"Statement\");\n  }\n};\nbase.ReturnStatement = base.YieldExpression = base.AwaitExpression = function (node, st, c) {\n  if (node.argument) { c(node.argument, st, \"Expression\"); }\n};\nbase.ThrowStatement = base.SpreadElement =\n  function (node, st, c) { return c(node.argument, st, \"Expression\"); };\nbase.TryStatement = function (node, st, c) {\n  c(node.block, st, \"Statement\");\n  if (node.handler) { c(node.handler, st); }\n  if (node.finalizer) { c(node.finalizer, st, \"Statement\"); }\n};\nbase.CatchClause = function (node, st, c) {\n  if (node.param) { c(node.param, st, \"Pattern\"); }\n  c(node.body, st, \"Statement\");\n};\nbase.WhileStatement = base.DoWhileStatement = function (node, st, c) {\n  c(node.test, st, \"Expression\");\n  c(node.body, st, \"Statement\");\n};\nbase.ForStatement = function (node, st, c) {\n  if (node.init) { c(node.init, st, \"ForInit\"); }\n  if (node.test) { c(node.test, st, \"Expression\"); }\n  if (node.update) { c(node.update, st, \"Expression\"); }\n  c(node.body, st, \"Statement\");\n};\nbase.ForInStatement = base.ForOfStatement = function (node, st, c) {\n  c(node.left, st, \"ForInit\");\n  c(node.right, st, \"Expression\");\n  c(node.body, st, \"Statement\");\n};\nbase.ForInit = function (node, st, c) {\n  if (node.type === \"VariableDeclaration\") { c(node, st); }\n  else { c(node, st, \"Expression\"); }\n};\nbase.DebuggerStatement = ignore;\n\nbase.FunctionDeclaration = function (node, st, c) { return c(node, st, \"Function\"); };\nbase.VariableDeclaration = function (node, st, c) {\n  for (var i = 0, list = node.declarations; i < list.length; i += 1)\n    {\n    var decl = list[i];\n\n    c(decl, st);\n  }\n};\nbase.VariableDeclarator = function (node, st, c) {\n  c(node.id, st, \"Pattern\");\n  if (node.init) { c(node.init, st, \"Expression\"); }\n};\n\nbase.Function = function (node, st, c) {\n  if (node.id) { c(node.id, st, \"Pattern\"); }\n  for (var i = 0, list = node.params; i < list.length; i += 1)\n    {\n    var param = list[i];\n\n    c(param, st, \"Pattern\");\n  }\n  c(node.body, st, node.expression ? \"Expression\" : \"Statement\");\n};\n\nbase.Pattern = function (node, st, c) {\n  if (node.type === \"Identifier\")\n    { c(node, st, \"VariablePattern\"); }\n  else if (node.type === \"MemberExpression\")\n    { c(node, st, \"MemberPattern\"); }\n  else\n    { c(node, st); }\n};\nbase.VariablePattern = ignore;\nbase.MemberPattern = skipThrough;\nbase.RestElement = function (node, st, c) { return c(node.argument, st, \"Pattern\"); };\nbase.ArrayPattern = function (node, st, c) {\n  for (var i = 0, list = node.elements; i < list.length; i += 1) {\n    var elt = list[i];\n\n    if (elt) { c(elt, st, \"Pattern\"); }\n  }\n};\nbase.ObjectPattern = function (node, st, c) {\n  for (var i = 0, list = node.properties; i < list.length; i += 1) {\n    var prop = list[i];\n\n    if (prop.type === \"Property\") {\n      if (prop.computed) { c(prop.key, st, \"Expression\"); }\n      c(prop.value, st, \"Pattern\");\n    } else if (prop.type === \"RestElement\") {\n      c(prop.argument, st, \"Pattern\");\n    }\n  }\n};\n\nbase.Expression = skipThrough;\nbase.ThisExpression = base.Super = base.MetaProperty = ignore;\nbase.ArrayExpression = function (node, st, c) {\n  for (var i = 0, list = node.elements; i < list.length; i += 1) {\n    var elt = list[i];\n\n    if (elt) { c(elt, st, \"Expression\"); }\n  }\n};\nbase.ObjectExpression = function (node, st, c) {\n  for (var i = 0, list = node.properties; i < list.length; i += 1)\n    {\n    var prop = list[i];\n\n    c(prop, st);\n  }\n};\nbase.FunctionExpression = base.ArrowFunctionExpression = base.FunctionDeclaration;\nbase.SequenceExpression = function (node, st, c) {\n  for (var i = 0, list = node.expressions; i < list.length; i += 1)\n    {\n    var expr = list[i];\n\n    c(expr, st, \"Expression\");\n  }\n};\nbase.TemplateLiteral = function (node, st, c) {\n  for (var i = 0, list = node.quasis; i < list.length; i += 1)\n    {\n    var quasi = list[i];\n\n    c(quasi, st);\n  }\n\n  for (var i$1 = 0, list$1 = node.expressions; i$1 < list$1.length; i$1 += 1)\n    {\n    var expr = list$1[i$1];\n\n    c(expr, st, \"Expression\");\n  }\n};\nbase.TemplateElement = ignore;\nbase.UnaryExpression = base.UpdateExpression = function (node, st, c) {\n  c(node.argument, st, \"Expression\");\n};\nbase.BinaryExpression = base.LogicalExpression = function (node, st, c) {\n  c(node.left, st, \"Expression\");\n  c(node.right, st, \"Expression\");\n};\nbase.AssignmentExpression = base.AssignmentPattern = function (node, st, c) {\n  c(node.left, st, \"Pattern\");\n  c(node.right, st, \"Expression\");\n};\nbase.ConditionalExpression = function (node, st, c) {\n  c(node.test, st, \"Expression\");\n  c(node.consequent, st, \"Expression\");\n  c(node.alternate, st, \"Expression\");\n};\nbase.NewExpression = base.CallExpression = function (node, st, c) {\n  c(node.callee, st, \"Expression\");\n  if (node.arguments)\n    { for (var i = 0, list = node.arguments; i < list.length; i += 1)\n      {\n        var arg = list[i];\n\n        c(arg, st, \"Expression\");\n      } }\n};\nbase.MemberExpression = function (node, st, c) {\n  c(node.object, st, \"Expression\");\n  if (node.computed) { c(node.property, st, \"Expression\"); }\n};\nbase.ExportNamedDeclaration = base.ExportDefaultDeclaration = function (node, st, c) {\n  if (node.declaration)\n    { c(node.declaration, st, node.type === \"ExportNamedDeclaration\" || node.declaration.id ? \"Statement\" : \"Expression\"); }\n  if (node.source) { c(node.source, st, \"Expression\"); }\n};\nbase.ExportAllDeclaration = function (node, st, c) {\n  if (node.exported)\n    { c(node.exported, st); }\n  c(node.source, st, \"Expression\");\n};\nbase.ImportDeclaration = function (node, st, c) {\n  for (var i = 0, list = node.specifiers; i < list.length; i += 1)\n    {\n    var spec = list[i];\n\n    c(spec, st);\n  }\n  c(node.source, st, \"Expression\");\n};\nbase.ImportExpression = function (node, st, c) {\n  c(node.source, st, \"Expression\");\n};\nbase.ImportSpecifier = base.ImportDefaultSpecifier = base.ImportNamespaceSpecifier = base.Identifier = base.PrivateIdentifier = base.Literal = ignore;\n\nbase.TaggedTemplateExpression = function (node, st, c) {\n  c(node.tag, st, \"Expression\");\n  c(node.quasi, st, \"Expression\");\n};\nbase.ClassDeclaration = base.ClassExpression = function (node, st, c) { return c(node, st, \"Class\"); };\nbase.Class = function (node, st, c) {\n  if (node.id) { c(node.id, st, \"Pattern\"); }\n  if (node.superClass) { c(node.superClass, st, \"Expression\"); }\n  c(node.body, st);\n};\nbase.ClassBody = function (node, st, c) {\n  for (var i = 0, list = node.body; i < list.length; i += 1)\n    {\n    var elt = list[i];\n\n    c(elt, st);\n  }\n};\nbase.MethodDefinition = base.PropertyDefinition = base.Property = function (node, st, c) {\n  if (node.computed) { c(node.key, st, \"Expression\"); }\n  if (node.value) { c(node.value, st, \"Expression\"); }\n};\n\nconst { isMatch: isMatch$1, scan } = micromatch_1;\nfunction getAffectedGlobModules(file, server) {\n    const modules = [];\n    for (const [id, allGlobs] of server._importGlobMap) {\n        if (allGlobs.some((glob) => isMatch$1(file, glob)))\n            modules.push(...(server.moduleGraph.getModulesByFile(id) || []));\n    }\n    modules.forEach((i) => {\n        if (i?.file)\n            server.moduleGraph.onFileChange(i.file);\n    });\n    return modules;\n}\nfunction importGlobPlugin(config) {\n    let server;\n    return {\n        name: 'vite:import-glob',\n        configureServer(_server) {\n            server = _server;\n            server._importGlobMap.clear();\n        },\n        async transform(code, id) {\n            if (!code.includes('import.meta.glob'))\n                return;\n            const result = await transformGlobImport(code, id, config.root, (im) => this.resolve(im, id).then((i) => i?.id || im), config.isProduction, config.experimental.importGlobRestoreExtension);\n            if (result) {\n                if (server) {\n                    const allGlobs = result.matches.map((i) => i.globsResolved);\n                    server._importGlobMap.set(id, allGlobs);\n                }\n                return transformStableResult(result.s, id, config);\n            }\n        },\n    };\n}\nconst importGlobRE = /\\bimport\\.meta\\.(glob|globEager|globEagerDefault)(?:<\\w+>)?\\s*\\(/g;\nconst knownOptions = {\n    as: ['string'],\n    eager: ['boolean'],\n    import: ['string'],\n    exhaustive: ['boolean'],\n    query: ['object', 'string'],\n};\nconst forceDefaultAs = ['raw', 'url'];\nfunction err$1(e, pos) {\n    const error = new Error(e);\n    error.pos = pos;\n    return error;\n}\nfunction parseGlobOptions(rawOpts, optsStartIndex) {\n    let opts = {};\n    try {\n        opts = evalValue(rawOpts);\n    }\n    catch {\n        throw err$1('Vite is unable to parse the glob options as the value is not static', optsStartIndex);\n    }\n    if (opts == null) {\n        return {};\n    }\n    for (const key in opts) {\n        if (!(key in knownOptions)) {\n            throw err$1(`Unknown glob option \"${key}\"`, optsStartIndex);\n        }\n        const allowedTypes = knownOptions[key];\n        const valueType = typeof opts[key];\n        if (!allowedTypes.includes(valueType)) {\n            throw err$1(`Expected glob option \"${key}\" to be of type ${allowedTypes.join(' or ')}, but got ${valueType}`, optsStartIndex);\n        }\n    }\n    if (typeof opts.query === 'object') {\n        for (const key in opts.query) {\n            const value = opts.query[key];\n            if (!['string', 'number', 'boolean'].includes(typeof value)) {\n                throw err$1(`Expected glob option \"query.${key}\" to be of type string, number, or boolean, but got ${typeof value}`, optsStartIndex);\n            }\n        }\n    }\n    if (opts.as && forceDefaultAs.includes(opts.as)) {\n        if (opts.import && opts.import !== 'default' && opts.import !== '*')\n            throw err$1(`Option \"import\" can only be \"default\" or \"*\" when \"as\" is \"${opts.as}\", but got \"${opts.import}\"`, optsStartIndex);\n        opts.import = opts.import || 'default';\n    }\n    if (opts.as && opts.query)\n        throw err$1('Options \"as\" and \"query\" cannot be used together', optsStartIndex);\n    if (opts.as)\n        opts.query = opts.as;\n    return opts;\n}\nasync function parseImportGlob(code, importer, root, resolveId) {\n    let cleanCode;\n    try {\n        cleanCode = stripLiteral(code);\n    }\n    catch (e) {\n        // skip invalid js code\n        return [];\n    }\n    const matches = Array.from(cleanCode.matchAll(importGlobRE));\n    const tasks = matches.map(async (match, index) => {\n        const type = match[1];\n        const start = match.index;\n        const err = (msg) => {\n            const e = new Error(`Invalid glob import syntax: ${msg}`);\n            e.pos = start;\n            return e;\n        };\n        let ast;\n        let lastTokenPos;\n        try {\n            ast = parseExpressionAt(code, start, {\n                ecmaVersion: 'latest',\n                sourceType: 'module',\n                ranges: true,\n                onToken: (token) => {\n                    lastTokenPos = token.end;\n                },\n            });\n        }\n        catch (e) {\n            const _e = e;\n            if (_e.message && _e.message.startsWith('Unterminated string constant'))\n                return undefined;\n            if (lastTokenPos == null || lastTokenPos <= start)\n                throw _e;\n            // tailing comma in object or array will make the parser think it's a comma operation\n            // we try to parse again removing the comma\n            try {\n                const statement = code.slice(start, lastTokenPos).replace(/[,\\s]*$/, '');\n                ast = parseExpressionAt(' '.repeat(start) + statement, // to keep the ast position\n                start, {\n                    ecmaVersion: 'latest',\n                    sourceType: 'module',\n                    ranges: true,\n                });\n            }\n            catch {\n                throw _e;\n            }\n        }\n        const found = findNodeAt(ast, start, undefined, 'CallExpression');\n        if (!found)\n            throw err(`Expect CallExpression, got ${ast.type}`);\n        ast = found.node;\n        if (ast.arguments.length < 1 || ast.arguments.length > 2)\n            throw err(`Expected 1-2 arguments, but got ${ast.arguments.length}`);\n        const arg1 = ast.arguments[0];\n        const arg2 = ast.arguments[1];\n        const globs = [];\n        const validateLiteral = (element) => {\n            if (!element)\n                return;\n            if (element.type === 'Literal') {\n                if (typeof element.value !== 'string')\n                    throw err(`Expected glob to be a string, but got \"${typeof element.value}\"`);\n                globs.push(element.value);\n            }\n            else if (element.type === 'TemplateLiteral') {\n                if (element.expressions.length !== 0) {\n                    throw err(`Expected glob to be a string, but got dynamic template literal`);\n                }\n                globs.push(element.quasis[0].value.raw);\n            }\n            else {\n                throw err('Could only use literals');\n            }\n        };\n        if (arg1.type === 'ArrayExpression') {\n            for (const element of arg1.elements) {\n                validateLiteral(element);\n            }\n        }\n        else {\n            validateLiteral(arg1);\n        }\n        // arg2\n        let options = {};\n        if (arg2) {\n            if (arg2.type !== 'ObjectExpression')\n                throw err(`Expected the second argument to be an object literal, but got \"${arg2.type}\"`);\n            options = parseGlobOptions(code.slice(arg2.range[0], arg2.range[1]), arg2.range[0]);\n        }\n        const end = ast.range[1];\n        const globsResolved = await Promise.all(globs.map((glob) => toAbsoluteGlob(glob, root, importer, resolveId)));\n        const isRelative = globs.every((i) => '.!'.includes(i[0]));\n        return {\n            match,\n            index,\n            globs,\n            globsResolved,\n            isRelative,\n            options,\n            type,\n            start,\n            end,\n        };\n    });\n    return (await Promise.all(tasks)).filter(Boolean);\n}\nconst importPrefix = '__vite_glob_';\nconst { basename, dirname, relative, join } = posix$1;\nconst warnedCSSDefaultImportVarName = '__vite_warned_css_default_import';\nconst jsonStringifyInOneline = (input) => JSON.stringify(input).replace(/[{,:]/g, '$& ').replace(/\\}/g, ' }');\nconst createCssDefaultImportWarning = (globs, options) => `if (!${warnedCSSDefaultImportVarName}) {` +\n    `${warnedCSSDefaultImportVarName} = true;` +\n    `console.warn(${JSON.stringify('Default import of CSS without `?inline` is deprecated. ' +\n        \"Add the `{ query: '?inline' }` glob option to fix this.\\n\" +\n        `For example: \\`import.meta.glob(${jsonStringifyInOneline(globs.length === 1 ? globs[0] : globs)}, ${jsonStringifyInOneline({ ...options, query: '?inline' })})\\``)});` +\n    `}`;\n/**\n * @param optimizeExport for dynamicImportVar plugin don't need to optimize export.\n */\nasync function transformGlobImport(code, id, root, resolveId, isProduction, restoreQueryExtension = false) {\n    id = slash$1(id);\n    root = slash$1(root);\n    const isVirtual = isVirtualModule(id);\n    const dir = isVirtual ? undefined : dirname(id);\n    const matches = await parseImportGlob(code, isVirtual ? undefined : id, root, resolveId);\n    const matchedFiles = new Set();\n    // TODO: backwards compatibility\n    matches.forEach((i) => {\n        if (i.type === 'globEager')\n            i.options.eager = true;\n        if (i.type === 'globEagerDefault') {\n            i.options.eager = true;\n            i.options.import = 'default';\n        }\n    });\n    if (!matches.length)\n        return null;\n    const s = new MagicString(code);\n    const staticImports = (await Promise.all(matches.map(async ({ globs, globsResolved, isRelative, options, index, start, end, }) => {\n        const cwd = getCommonBase(globsResolved) ?? root;\n        const files = (await out(globsResolved, {\n            cwd,\n            absolute: true,\n            dot: !!options.exhaustive,\n            ignore: options.exhaustive\n                ? []\n                : [join(cwd, '**/node_modules/**')],\n        }))\n            .filter((file) => file !== id)\n            .sort();\n        const objectProps = [];\n        const staticImports = [];\n        let query = !options.query\n            ? ''\n            : typeof options.query === 'string'\n                ? options.query\n                : stringifyQuery(options.query);\n        if (query && !query.startsWith('?'))\n            query = `?${query}`;\n        const resolvePaths = (file) => {\n            if (!dir) {\n                if (isRelative)\n                    throw new Error(\"In virtual modules, all globs must start with '/'\");\n                const filePath = `/${relative(root, file)}`;\n                return { filePath, importPath: filePath };\n            }\n            let importPath = relative(dir, file);\n            if (!importPath.startsWith('.'))\n                importPath = `./${importPath}`;\n            let filePath;\n            if (isRelative) {\n                filePath = importPath;\n            }\n            else {\n                filePath = relative(root, file);\n                if (!filePath.startsWith('.'))\n                    filePath = `/${filePath}`;\n            }\n            return { filePath, importPath };\n        };\n        let includesCSS = false;\n        files.forEach((file, i) => {\n            const paths = resolvePaths(file);\n            const filePath = paths.filePath;\n            let importPath = paths.importPath;\n            let importQuery = query;\n            if (importQuery && importQuery !== '?raw') {\n                const fileExtension = basename(file).split('.').slice(-1)[0];\n                if (fileExtension && restoreQueryExtension)\n                    importQuery = `${importQuery}&lang.${fileExtension}`;\n            }\n            importPath = `${importPath}${importQuery}`;\n            const isCSS = !query && isCSSRequest(file) && !isModuleCSSRequest(file);\n            includesCSS || (includesCSS = isCSS);\n            const importKey = options.import && options.import !== '*'\n                ? options.import\n                : undefined;\n            if (options.eager) {\n                const variableName = `${importPrefix}${index}_${i}`;\n                const expression = importKey\n                    ? `{ ${importKey} as ${variableName} }`\n                    : `* as ${variableName}`;\n                staticImports.push(`import ${expression} from ${JSON.stringify(importPath)}`);\n                if (!isProduction && isCSS) {\n                    objectProps.push(`get ${JSON.stringify(filePath)}() { ${createCssDefaultImportWarning(globs, options)} return ${variableName} }`);\n                }\n                else {\n                    objectProps.push(`${JSON.stringify(filePath)}: ${variableName}`);\n                }\n            }\n            else {\n                let importStatement = `import(${JSON.stringify(importPath)})`;\n                if (importKey)\n                    importStatement += `.then(m => m[${JSON.stringify(importKey)}])`;\n                if (!isProduction && isCSS) {\n                    objectProps.push(`${JSON.stringify(filePath)}: () => { ${createCssDefaultImportWarning(globs, options)} return ${importStatement}}`);\n                }\n                else {\n                    objectProps.push(`${JSON.stringify(filePath)}: () => ${importStatement}`);\n                }\n            }\n        });\n        files.forEach((i) => matchedFiles.add(i));\n        const originalLineBreakCount = code.slice(start, end).match(/\\n/g)?.length ?? 0;\n        const lineBreaks = originalLineBreakCount > 0\n            ? '\\n'.repeat(originalLineBreakCount)\n            : '';\n        let replacement;\n        if (!isProduction && includesCSS) {\n            replacement =\n                '/* #__PURE__ */ Object.assign(' +\n                    '(() => {' +\n                    `let ${warnedCSSDefaultImportVarName} = false;` +\n                    `return {${objectProps.join(',')}${lineBreaks}};` +\n                    '})()' +\n                    ')';\n        }\n        else {\n            replacement = `/* #__PURE__ */ Object.assign({${objectProps.join(',')}${lineBreaks}})`;\n        }\n        s.overwrite(start, end, replacement);\n        return staticImports;\n    }))).flat();\n    if (staticImports.length)\n        s.prepend(`${staticImports.join(';')};`);\n    return {\n        s,\n        matches,\n        files: matchedFiles,\n    };\n}\nfunction globSafePath(path) {\n    // slash path to ensure \\ is converted to / as \\ could lead to a double escape scenario\n    // see https://github.com/mrmlnc/fast-glob#advanced-syntax\n    return out.escapePath(normalizePath$3(path));\n}\nfunction lastNthChar(str, n) {\n    return str.charAt(str.length - 1 - n);\n}\nfunction globSafeResolvedPath(resolved, glob) {\n    // we have to escape special glob characters in the resolved path, but keep the user specified globby suffix\n    // walk back both strings until a character difference is found\n    // then slice up the resolved path at that pos and escape the first part\n    let numEqual = 0;\n    const maxEqual = Math.min(resolved.length, glob.length);\n    while (numEqual < maxEqual &&\n        lastNthChar(resolved, numEqual) === lastNthChar(glob, numEqual)) {\n        numEqual += 1;\n    }\n    const staticPartEnd = resolved.length - numEqual;\n    const staticPart = resolved.slice(0, staticPartEnd);\n    const dynamicPart = resolved.slice(staticPartEnd);\n    return globSafePath(staticPart) + dynamicPart;\n}\nasync function toAbsoluteGlob(glob, root, importer, resolveId) {\n    let pre = '';\n    if (glob.startsWith('!')) {\n        pre = '!';\n        glob = glob.slice(1);\n    }\n    root = globSafePath(root);\n    const dir = importer ? globSafePath(dirname(importer)) : root;\n    if (glob.startsWith('/'))\n        return pre + posix$1.join(root, glob.slice(1));\n    if (glob.startsWith('./'))\n        return pre + posix$1.join(dir, glob.slice(2));\n    if (glob.startsWith('../'))\n        return pre + posix$1.join(dir, glob);\n    if (glob.startsWith('**'))\n        return pre + glob;\n    const resolved = normalizePath$3((await resolveId(glob, importer)) || glob);\n    if (isAbsolute$2(resolved)) {\n        return pre + globSafeResolvedPath(resolved, glob);\n    }\n    throw new Error(`Invalid glob: \"${glob}\" (resolved: \"${resolved}\"). It must start with '/' or './'`);\n}\nfunction getCommonBase(globsResolved) {\n    const bases = globsResolved\n        .filter((g) => !g.startsWith('!'))\n        .map((glob) => {\n        let { base } = scan(glob);\n        // `scan('a/foo.js')` returns `base: 'a/foo.js'`\n        if (posix$1.basename(base).includes('.'))\n            base = posix$1.dirname(base);\n        return base;\n    });\n    if (!bases.length)\n        return null;\n    let commonAncestor = '';\n    const dirS = bases[0].split('/');\n    for (let i = 0; i < dirS.length; i++) {\n        const candidate = dirS.slice(0, i + 1).join('/');\n        if (bases.every((base) => base.startsWith(candidate)))\n            commonAncestor = candidate;\n        else\n            break;\n    }\n    if (!commonAncestor)\n        commonAncestor = '/';\n    return commonAncestor;\n}\nfunction isVirtualModule(id) {\n    // https://vitejs.dev/guide/api-plugin.html#virtual-modules-convention\n    return id.startsWith('virtual:') || id.startsWith('\\0') || !id.includes('/');\n}\n\nconst debugHmr = createDebugger('vite:hmr');\nconst normalizedClientDir = normalizePath$3(CLIENT_DIR);\nfunction getShortName(file, root) {\n    return file.startsWith(root + '/') ? path$o.posix.relative(root, file) : file;\n}\nasync function handleHMRUpdate(file, server) {\n    const { ws, config, moduleGraph } = server;\n    const shortFile = getShortName(file, config.root);\n    const fileName = path$o.basename(file);\n    const isConfig = file === config.configFile;\n    const isConfigDependency = config.configFileDependencies.some((name) => file === name);\n    const isEnv = config.inlineConfig.envFile !== false &&\n        (fileName === '.env' || fileName.startsWith('.env.'));\n    if (isConfig || isConfigDependency || isEnv) {\n        // auto restart server\n        debugHmr(`[config change] ${picocolorsExports.dim(shortFile)}`);\n        config.logger.info(picocolorsExports.green(`${path$o.relative(process.cwd(), file)} changed, restarting server...`), { clear: true, timestamp: true });\n        try {\n            await server.restart();\n        }\n        catch (e) {\n            config.logger.error(picocolorsExports.red(e));\n        }\n        return;\n    }\n    debugHmr(`[file change] ${picocolorsExports.dim(shortFile)}`);\n    // (dev only) the client itself cannot be hot updated.\n    if (file.startsWith(normalizedClientDir)) {\n        ws.send({\n            type: 'full-reload',\n            path: '*',\n        });\n        return;\n    }\n    const mods = moduleGraph.getModulesByFile(file);\n    // check if any plugin wants to perform custom HMR handling\n    const timestamp = Date.now();\n    const hmrContext = {\n        file,\n        timestamp,\n        modules: mods ? [...mods] : [],\n        read: () => readModifiedFile(file),\n        server,\n    };\n    for (const hook of config.getSortedPluginHooks('handleHotUpdate')) {\n        const filteredModules = await hook(hmrContext);\n        if (filteredModules) {\n            hmrContext.modules = filteredModules;\n        }\n    }\n    if (!hmrContext.modules.length) {\n        // html file cannot be hot updated\n        if (file.endsWith('.html')) {\n            config.logger.info(picocolorsExports.green(`page reload `) + picocolorsExports.dim(shortFile), {\n                clear: true,\n                timestamp: true,\n            });\n            ws.send({\n                type: 'full-reload',\n                path: config.server.middlewareMode\n                    ? '*'\n                    : '/' + normalizePath$3(path$o.relative(config.root, file)),\n            });\n        }\n        else {\n            // loaded but not in the module graph, probably not js\n            debugHmr(`[no modules matched] ${picocolorsExports.dim(shortFile)}`);\n        }\n        return;\n    }\n    updateModules(shortFile, hmrContext.modules, timestamp, server);\n}\nfunction updateModules(file, modules, timestamp, { config, ws, moduleGraph }, afterInvalidation) {\n    const updates = [];\n    const invalidatedModules = new Set();\n    let needFullReload = false;\n    for (const mod of modules) {\n        moduleGraph.invalidateModule(mod, invalidatedModules, timestamp, true);\n        if (needFullReload) {\n            continue;\n        }\n        const boundaries = new Set();\n        const hasDeadEnd = propagateUpdate(mod, boundaries);\n        if (hasDeadEnd) {\n            needFullReload = true;\n            continue;\n        }\n        updates.push(...[...boundaries].map(({ boundary, acceptedVia }) => ({\n            type: `${boundary.type}-update`,\n            timestamp,\n            path: normalizeHmrUrl(boundary.url),\n            explicitImportRequired: boundary.type === 'js'\n                ? isExplicitImportRequired(acceptedVia.url)\n                : undefined,\n            acceptedPath: normalizeHmrUrl(acceptedVia.url),\n        })));\n    }\n    if (needFullReload) {\n        config.logger.info(picocolorsExports.green(`page reload `) + picocolorsExports.dim(file), {\n            clear: !afterInvalidation,\n            timestamp: true,\n        });\n        ws.send({\n            type: 'full-reload',\n        });\n        return;\n    }\n    if (updates.length === 0) {\n        debugHmr(picocolorsExports.yellow(`no update happened `) + picocolorsExports.dim(file));\n        return;\n    }\n    config.logger.info(picocolorsExports.green(`hmr update `) +\n        picocolorsExports.dim([...new Set(updates.map((u) => u.path))].join(', ')), { clear: !afterInvalidation, timestamp: true });\n    ws.send({\n        type: 'update',\n        updates,\n    });\n}\nasync function handleFileAddUnlink(file, server) {\n    const modules = [...(server.moduleGraph.getModulesByFile(file) || [])];\n    modules.push(...getAffectedGlobModules(file, server));\n    if (modules.length > 0) {\n        updateModules(getShortName(file, server.config.root), unique(modules), Date.now(), server);\n    }\n}\nfunction areAllImportsAccepted(importedBindings, acceptedExports) {\n    for (const binding of importedBindings) {\n        if (!acceptedExports.has(binding)) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction propagateUpdate(node, boundaries, currentChain = [node]) {\n    // #7561\n    // if the imports of `node` have not been analyzed, then `node` has not\n    // been loaded in the browser and we should stop propagation.\n    if (node.id && node.isSelfAccepting === undefined) {\n        debugHmr(`[propagate update] stop propagation because not analyzed: ${picocolorsExports.dim(node.id)}`);\n        return false;\n    }\n    if (node.isSelfAccepting) {\n        boundaries.add({\n            boundary: node,\n            acceptedVia: node,\n        });\n        // additionally check for CSS importers, since a PostCSS plugin like\n        // Tailwind JIT may register any file as a dependency to a CSS file.\n        for (const importer of node.importers) {\n            if (isCSSRequest(importer.url) && !currentChain.includes(importer)) {\n                propagateUpdate(importer, boundaries, currentChain.concat(importer));\n            }\n        }\n        return false;\n    }\n    // A partially accepted module with no importers is considered self accepting,\n    // because the deal is \"there are parts of myself I can't self accept if they\n    // are used outside of me\".\n    // Also, the imported module (this one) must be updated before the importers,\n    // so that they do get the fresh imported module when/if they are reloaded.\n    if (node.acceptedHmrExports) {\n        boundaries.add({\n            boundary: node,\n            acceptedVia: node,\n        });\n    }\n    else {\n        if (!node.importers.size) {\n            return true;\n        }\n        // #3716, #3913\n        // For a non-CSS file, if all of its importers are CSS files (registered via\n        // PostCSS plugins) it should be considered a dead end and force full reload.\n        if (!isCSSRequest(node.url) &&\n            [...node.importers].every((i) => isCSSRequest(i.url))) {\n            return true;\n        }\n    }\n    for (const importer of node.importers) {\n        const subChain = currentChain.concat(importer);\n        if (importer.acceptedHmrDeps.has(node)) {\n            boundaries.add({\n                boundary: importer,\n                acceptedVia: node,\n            });\n            continue;\n        }\n        if (node.id && node.acceptedHmrExports && importer.importedBindings) {\n            const importedBindingsFromNode = importer.importedBindings.get(node.id);\n            if (importedBindingsFromNode &&\n                areAllImportsAccepted(importedBindingsFromNode, node.acceptedHmrExports)) {\n                continue;\n            }\n        }\n        if (currentChain.includes(importer)) {\n            // circular deps is considered dead end\n            return true;\n        }\n        if (propagateUpdate(importer, boundaries, subChain)) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction handlePrunedModules(mods, { ws }) {\n    // update the disposed modules' hmr timestamp\n    // since if it's re-imported, it should re-apply side effects\n    // and without the timestamp the browser will not re-import it!\n    const t = Date.now();\n    mods.forEach((mod) => {\n        mod.lastHMRTimestamp = t;\n        debugHmr(`[dispose] ${picocolorsExports.dim(mod.file)}`);\n    });\n    ws.send({\n        type: 'prune',\n        paths: [...mods].map((m) => m.url),\n    });\n}\n/**\n * Lex import.meta.hot.accept() for accepted deps.\n * Since hot.accept() can only accept string literals or array of string\n * literals, we don't really need a heavy @babel/parse call on the entire source.\n *\n * @returns selfAccepts\n */\nfunction lexAcceptedHmrDeps(code, start, urls) {\n    let state = 0 /* LexerState.inCall */;\n    // the state can only be 2 levels deep so no need for a stack\n    let prevState = 0 /* LexerState.inCall */;\n    let currentDep = '';\n    function addDep(index) {\n        urls.add({\n            url: currentDep,\n            start: index - currentDep.length - 1,\n            end: index + 1,\n        });\n        currentDep = '';\n    }\n    for (let i = start; i < code.length; i++) {\n        const char = code.charAt(i);\n        switch (state) {\n            case 0 /* LexerState.inCall */:\n            case 4 /* LexerState.inArray */:\n                if (char === `'`) {\n                    prevState = state;\n                    state = 1 /* LexerState.inSingleQuoteString */;\n                }\n                else if (char === `\"`) {\n                    prevState = state;\n                    state = 2 /* LexerState.inDoubleQuoteString */;\n                }\n                else if (char === '`') {\n                    prevState = state;\n                    state = 3 /* LexerState.inTemplateString */;\n                }\n                else if (/\\s/.test(char)) {\n                    continue;\n                }\n                else {\n                    if (state === 0 /* LexerState.inCall */) {\n                        if (char === `[`) {\n                            state = 4 /* LexerState.inArray */;\n                        }\n                        else {\n                            // reaching here means the first arg is neither a string literal\n                            // nor an Array literal (direct callback) or there is no arg\n                            // in both case this indicates a self-accepting module\n                            return true; // done\n                        }\n                    }\n                    else if (state === 4 /* LexerState.inArray */) {\n                        if (char === `]`) {\n                            return false; // done\n                        }\n                        else if (char === ',') {\n                            continue;\n                        }\n                        else {\n                            error$1(i);\n                        }\n                    }\n                }\n                break;\n            case 1 /* LexerState.inSingleQuoteString */:\n                if (char === `'`) {\n                    addDep(i);\n                    if (prevState === 0 /* LexerState.inCall */) {\n                        // accept('foo', ...)\n                        return false;\n                    }\n                    else {\n                        state = prevState;\n                    }\n                }\n                else {\n                    currentDep += char;\n                }\n                break;\n            case 2 /* LexerState.inDoubleQuoteString */:\n                if (char === `\"`) {\n                    addDep(i);\n                    if (prevState === 0 /* LexerState.inCall */) {\n                        // accept('foo', ...)\n                        return false;\n                    }\n                    else {\n                        state = prevState;\n                    }\n                }\n                else {\n                    currentDep += char;\n                }\n                break;\n            case 3 /* LexerState.inTemplateString */:\n                if (char === '`') {\n                    addDep(i);\n                    if (prevState === 0 /* LexerState.inCall */) {\n                        // accept('foo', ...)\n                        return false;\n                    }\n                    else {\n                        state = prevState;\n                    }\n                }\n                else if (char === '$' && code.charAt(i + 1) === '{') {\n                    error$1(i);\n                }\n                else {\n                    currentDep += char;\n                }\n                break;\n            default:\n                throw new Error('unknown import.meta.hot lexer state');\n        }\n    }\n    return false;\n}\nfunction lexAcceptedHmrExports(code, start, exportNames) {\n    const urls = new Set();\n    lexAcceptedHmrDeps(code, start, urls);\n    for (const { url } of urls) {\n        exportNames.add(url);\n    }\n    return urls.size > 0;\n}\nfunction normalizeHmrUrl(url) {\n    if (!url.startsWith('.') && !url.startsWith('/')) {\n        url = wrapId(url);\n    }\n    return url;\n}\nfunction error$1(pos) {\n    const err = new Error(`import.meta.hot.accept() can only accept string literals or an ` +\n        `Array of string literals.`);\n    err.pos = pos;\n    throw err;\n}\n// vitejs/vite#610 when hot-reloading Vue files, we read immediately on file\n// change event and sometimes this can be too early and get an empty buffer.\n// Poll until the file's modified time has changed before reading again.\nasync function readModifiedFile(file) {\n    const content = fs$l.readFileSync(file, 'utf-8');\n    if (!content) {\n        const mtime = fs$l.statSync(file).mtimeMs;\n        await new Promise((r) => {\n            let n = 0;\n            const poll = async () => {\n                n++;\n                const newMtime = fs$l.statSync(file).mtimeMs;\n                if (newMtime !== mtime || n > 10) {\n                    r(0);\n                }\n                else {\n                    setTimeout(poll, 10);\n                }\n            };\n            setTimeout(poll, 10);\n        });\n        return fs$l.readFileSync(file, 'utf-8');\n    }\n    else {\n        return content;\n    }\n}\n\n/*!\n * etag\n * Copyright(c) 2014-2016 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module exports.\n * @public\n */\n\nvar etag_1 = etag;\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar crypto = require$$5$1;\nvar Stats = require$$0__default.Stats;\n\n/**\n * Module variables.\n * @private\n */\n\nvar toString = Object.prototype.toString;\n\n/**\n * Generate an entity tag.\n *\n * @param {Buffer|string} entity\n * @return {string}\n * @private\n */\n\nfunction entitytag (entity) {\n  if (entity.length === 0) {\n    // fast-path empty\n    return '\"0-2jmj7l5rSw0yVb/vlWAYkK/YBwk\"'\n  }\n\n  // compute hash of entity\n  var hash = crypto\n    .createHash('sha1')\n    .update(entity, 'utf8')\n    .digest('base64')\n    .substring(0, 27);\n\n  // compute length of entity\n  var len = typeof entity === 'string'\n    ? Buffer.byteLength(entity, 'utf8')\n    : entity.length;\n\n  return '\"' + len.toString(16) + '-' + hash + '\"'\n}\n\n/**\n * Create a simple ETag.\n *\n * @param {string|Buffer|Stats} entity\n * @param {object} [options]\n * @param {boolean} [options.weak]\n * @return {String}\n * @public\n */\n\nfunction etag (entity, options) {\n  if (entity == null) {\n    throw new TypeError('argument entity is required')\n  }\n\n  // support fs.Stats object\n  var isStats = isstats(entity);\n  var weak = options && typeof options.weak === 'boolean'\n    ? options.weak\n    : isStats;\n\n  // validate argument\n  if (!isStats && typeof entity !== 'string' && !Buffer.isBuffer(entity)) {\n    throw new TypeError('argument entity must be string, Buffer, or fs.Stats')\n  }\n\n  // generate entity tag\n  var tag = isStats\n    ? stattag(entity)\n    : entitytag(entity);\n\n  return weak\n    ? 'W/' + tag\n    : tag\n}\n\n/**\n * Determine if object is a Stats object.\n *\n * @param {object} obj\n * @return {boolean}\n * @api private\n */\n\nfunction isstats (obj) {\n  // genuine fs.Stats\n  if (typeof Stats === 'function' && obj instanceof Stats) {\n    return true\n  }\n\n  // quack quack\n  return obj && typeof obj === 'object' &&\n    'ctime' in obj && toString.call(obj.ctime) === '[object Date]' &&\n    'mtime' in obj && toString.call(obj.mtime) === '[object Date]' &&\n    'ino' in obj && typeof obj.ino === 'number' &&\n    'size' in obj && typeof obj.size === 'number'\n}\n\n/**\n * Generate a tag for a stat.\n *\n * @param {object} stat\n * @return {string}\n * @private\n */\n\nfunction stattag (stat) {\n  var mtime = stat.mtime.getTime().toString(16);\n  var size = stat.size.toString(16);\n\n  return '\"' + size + '-' + mtime + '\"'\n}\n\nvar convertSourceMap = {};\n\n(function (exports) {\n\n\tObject.defineProperty(exports, 'commentRegex', {\n\t  get: function getCommentRegex () {\n\t    // Groups: 1: media type, 2: MIME type, 3: charset, 4: encoding, 5: data.\n\t    return /^\\s*?\\/[\\/\\*][@#]\\s+?sourceMappingURL=data:(((?:application|text)\\/json)(?:;charset=([^;,]+?)?)?)?(?:;(base64))?,(.*?)$/mg;\n\t  }\n\t});\n\n\n\tObject.defineProperty(exports, 'mapFileCommentRegex', {\n\t  get: function getMapFileCommentRegex () {\n\t    // Matches sourceMappingURL in either // or /* comment styles.\n\t    return /(?:\\/\\/[@#][ \\t]+?sourceMappingURL=([^\\s'\"`]+?)[ \\t]*?$)|(?:\\/\\*[@#][ \\t]+sourceMappingURL=([^*]+?)[ \\t]*?(?:\\*\\/){1}[ \\t]*?$)/mg;\n\t  }\n\t});\n\n\tvar decodeBase64;\n\tif (typeof Buffer !== 'undefined') {\n\t  if (typeof Buffer.from === 'function') {\n\t    decodeBase64 = decodeBase64WithBufferFrom;\n\t  } else {\n\t    decodeBase64 = decodeBase64WithNewBuffer;\n\t  }\n\t} else {\n\t  decodeBase64 = decodeBase64WithAtob;\n\t}\n\n\tfunction decodeBase64WithBufferFrom(base64) {\n\t  return Buffer.from(base64, 'base64').toString();\n\t}\n\n\tfunction decodeBase64WithNewBuffer(base64) {\n\t  if (typeof value === 'number') {\n\t    throw new TypeError('The value to decode must not be of type number.');\n\t  }\n\t  return new Buffer(base64, 'base64').toString();\n\t}\n\n\tfunction decodeBase64WithAtob(base64) {\n\t  return decodeURIComponent(escape(atob(base64)));\n\t}\n\n\tfunction stripComment(sm) {\n\t  return sm.split(',').pop();\n\t}\n\n\tfunction readFromFileMap(sm, read) {\n\t  var r = exports.mapFileCommentRegex.exec(sm);\n\t  // for some odd reason //# .. captures in 1 and /* .. */ in 2\n\t  var filename = r[1] || r[2];\n\n\t  try {\n\t    var sm = read(filename);\n\t    if (sm != null && typeof sm.catch === 'function') {\n\t      return sm.catch(throwError);\n\t    } else {\n\t      return sm;\n\t    }\n\t  } catch (e) {\n\t    throwError(e);\n\t  }\n\n\t  function throwError(e) {\n\t    throw new Error('An error occurred while trying to read the map file at ' + filename + '\\n' + e.stack);\n\t  }\n\t}\n\n\tfunction Converter (sm, opts) {\n\t  opts = opts || {};\n\n\t  if (opts.hasComment) {\n\t    sm = stripComment(sm);\n\t  }\n\n\t  if (opts.encoding === 'base64') {\n\t    sm = decodeBase64(sm);\n\t  } else if (opts.encoding === 'uri') {\n\t    sm = decodeURIComponent(sm);\n\t  }\n\n\t  if (opts.isJSON || opts.encoding) {\n\t    sm = JSON.parse(sm);\n\t  }\n\n\t  this.sourcemap = sm;\n\t}\n\n\tConverter.prototype.toJSON = function (space) {\n\t  return JSON.stringify(this.sourcemap, null, space);\n\t};\n\n\tif (typeof Buffer !== 'undefined') {\n\t  if (typeof Buffer.from === 'function') {\n\t    Converter.prototype.toBase64 = encodeBase64WithBufferFrom;\n\t  } else {\n\t    Converter.prototype.toBase64 = encodeBase64WithNewBuffer;\n\t  }\n\t} else {\n\t  Converter.prototype.toBase64 = encodeBase64WithBtoa;\n\t}\n\n\tfunction encodeBase64WithBufferFrom() {\n\t  var json = this.toJSON();\n\t  return Buffer.from(json, 'utf8').toString('base64');\n\t}\n\n\tfunction encodeBase64WithNewBuffer() {\n\t  var json = this.toJSON();\n\t  if (typeof json === 'number') {\n\t    throw new TypeError('The json to encode must not be of type number.');\n\t  }\n\t  return new Buffer(json, 'utf8').toString('base64');\n\t}\n\n\tfunction encodeBase64WithBtoa() {\n\t  var json = this.toJSON();\n\t  return btoa(unescape(encodeURIComponent(json)));\n\t}\n\n\tConverter.prototype.toURI = function () {\n\t  var json = this.toJSON();\n\t  return encodeURIComponent(json);\n\t};\n\n\tConverter.prototype.toComment = function (options) {\n\t  var encoding, content, data;\n\t  if (options != null && options.encoding === 'uri') {\n\t    encoding = '';\n\t    content = this.toURI();\n\t  } else {\n\t    encoding = ';base64';\n\t    content = this.toBase64();\n\t  }\n\t  data = 'sourceMappingURL=data:application/json;charset=utf-8' + encoding + ',' + content;\n\t  return options != null && options.multiline ? '/*# ' + data + ' */' : '//# ' + data;\n\t};\n\n\t// returns copy instead of original\n\tConverter.prototype.toObject = function () {\n\t  return JSON.parse(this.toJSON());\n\t};\n\n\tConverter.prototype.addProperty = function (key, value) {\n\t  if (this.sourcemap.hasOwnProperty(key)) throw new Error('property \"' + key + '\" already exists on the sourcemap, use set property instead');\n\t  return this.setProperty(key, value);\n\t};\n\n\tConverter.prototype.setProperty = function (key, value) {\n\t  this.sourcemap[key] = value;\n\t  return this;\n\t};\n\n\tConverter.prototype.getProperty = function (key) {\n\t  return this.sourcemap[key];\n\t};\n\n\texports.fromObject = function (obj) {\n\t  return new Converter(obj);\n\t};\n\n\texports.fromJSON = function (json) {\n\t  return new Converter(json, { isJSON: true });\n\t};\n\n\texports.fromURI = function (uri) {\n\t  return new Converter(uri, { encoding: 'uri' });\n\t};\n\n\texports.fromBase64 = function (base64) {\n\t  return new Converter(base64, { encoding: 'base64' });\n\t};\n\n\texports.fromComment = function (comment) {\n\t  var m, encoding;\n\t  comment = comment\n\t    .replace(/^\\/\\*/g, '//')\n\t    .replace(/\\*\\/$/g, '');\n\t  m = exports.commentRegex.exec(comment);\n\t  encoding = m && m[4] || 'uri';\n\t  return new Converter(comment, { encoding: encoding, hasComment: true });\n\t};\n\n\tfunction makeConverter(sm) {\n\t  return new Converter(sm, { isJSON: true });\n\t}\n\n\texports.fromMapFileComment = function (comment, read) {\n\t  if (typeof read === 'string') {\n\t    throw new Error(\n\t      'String directory paths are no longer supported with `fromMapFileComment`\\n' +\n\t      'Please review the Upgrading documentation at https://github.com/thlorenz/convert-source-map#upgrading'\n\t    )\n\t  }\n\n\t  var sm = readFromFileMap(comment, read);\n\t  if (sm != null && typeof sm.then === 'function') {\n\t    return sm.then(makeConverter);\n\t  } else {\n\t    return makeConverter(sm);\n\t  }\n\t};\n\n\t// Finds last sourcemap comment in file or returns null if none was found\n\texports.fromSource = function (content) {\n\t  var m = content.match(exports.commentRegex);\n\t  return m ? exports.fromComment(m.pop()) : null;\n\t};\n\n\t// Finds last sourcemap comment in file or returns null if none was found\n\texports.fromMapFileSource = function (content, read) {\n\t  if (typeof read === 'string') {\n\t    throw new Error(\n\t      'String directory paths are no longer supported with `fromMapFileSource`\\n' +\n\t      'Please review the Upgrading documentation at https://github.com/thlorenz/convert-source-map#upgrading'\n\t    )\n\t  }\n\t  var m = content.match(exports.mapFileCommentRegex);\n\t  return m ? exports.fromMapFileComment(m.pop(), read) : null;\n\t};\n\n\texports.removeComments = function (src) {\n\t  return src.replace(exports.commentRegex, '');\n\t};\n\n\texports.removeMapFileComments = function (src) {\n\t  return src.replace(exports.mapFileCommentRegex, '');\n\t};\n\n\texports.generateMapFileComment = function (file, options) {\n\t  var data = 'sourceMappingURL=' + file;\n\t  return options && options.multiline ? '/*# ' + data + ' */' : '//# ' + data;\n\t};\n} (convertSourceMap));\n\nfunction totalist(dir, callback, pre='') {\n\tdir = resolve$3('.', dir);\n\tlet arr = readdirSync(dir);\n\tlet i=0, abs, stats;\n\tfor (; i < arr.length; i++) {\n\t\tabs = join$1(dir, arr[i]);\n\t\tstats = statSync$1(abs);\n\t\tstats.isDirectory()\n\t\t\t? totalist(abs, callback, join$1(pre, arr[i]))\n\t\t\t: callback(join$1(pre, arr[i]), abs, stats);\n\t}\n}\n\n/**\n * @typedef ParsedURL\n * @type {import('.').ParsedURL}\n */\n\n/**\n * @typedef Request\n * @property {string} url\n * @property {ParsedURL} _parsedUrl\n */\n\n/**\n * @param {Request} req\n * @returns {ParsedURL|void}\n */\nfunction parse$9(req) {\n\tlet raw = req.url;\n\tif (raw == null) return;\n\n\tlet prev = req._parsedUrl;\n\tif (prev && prev.raw === raw) return prev;\n\n\tlet pathname=raw, search='', query;\n\n\tif (raw.length > 1) {\n\t\tlet idx = raw.indexOf('?', 1);\n\n\t\tif (idx !== -1) {\n\t\t\tsearch = raw.substring(idx);\n\t\t\tpathname = raw.substring(0, idx);\n\t\t\tif (search.length > 1) {\n\t\t\t\tquery = qs.parse(search.substring(1));\n\t\t\t}\n\t\t}\n\t}\n\n\treturn req._parsedUrl = { pathname, search, query, raw };\n}\n\nconst noop$2 = () => {};\n\nfunction isMatch(uri, arr) {\n\tfor (let i=0; i < arr.length; i++) {\n\t\tif (arr[i].test(uri)) return true;\n\t}\n}\n\nfunction toAssume(uri, extns) {\n\tlet i=0, x, len=uri.length - 1;\n\tif (uri.charCodeAt(len) === 47) {\n\t\turi = uri.substring(0, len);\n\t}\n\n\tlet arr=[], tmp=`${uri}/index`;\n\tfor (; i < extns.length; i++) {\n\t\tx = extns[i] ? `.${extns[i]}` : '';\n\t\tif (uri) arr.push(uri + x);\n\t\tarr.push(tmp + x);\n\t}\n\n\treturn arr;\n}\n\nfunction viaCache(cache, uri, extns) {\n\tlet i=0, data, arr=toAssume(uri, extns);\n\tfor (; i < arr.length; i++) {\n\t\tif (data = cache[arr[i]]) return data;\n\t}\n}\n\nfunction viaLocal(dir, isEtag, uri, extns, shouldServe) {\n\tlet i=0, arr=toAssume(uri, extns);\n\tlet abs, stats, name, headers;\n\tfor (; i < arr.length; i++) {\n\t\tabs = normalize(join$1(dir, name=arr[i]));\n\t\tif (abs.startsWith(dir) && require$$0$2.existsSync(abs)) {\n\t\t\tstats = require$$0$2.statSync(abs);\n\t\t\tif (stats.isDirectory()) continue;\n\t\t\tif (shouldServe && !shouldServe(abs)) continue;\n\t\t\theaders = toHeaders(name, stats, isEtag);\n\t\t\theaders['Cache-Control'] = isEtag ? 'no-cache' : 'no-store';\n\t\t\treturn { abs, stats, headers };\n\t\t}\n\t}\n}\n\nfunction is404(req, res) {\n\treturn (res.statusCode=404,res.end());\n}\n\nfunction send$2(req, res, file, stats, headers) {\n\tlet code=200, tmp, opts={};\n\theaders = { ...headers };\n\n\tfor (let key in headers) {\n\t\ttmp = res.getHeader(key);\n\t\tif (tmp) headers[key] = tmp;\n\t}\n\n\tif (tmp = res.getHeader('content-type')) {\n\t\theaders['Content-Type'] = tmp;\n\t}\n\n\tif (req.headers.range) {\n\t\tcode = 206;\n\t\tlet [x, y] = req.headers.range.replace('bytes=', '').split('-');\n\t\tlet end = opts.end = parseInt(y, 10) || stats.size - 1;\n\t\tlet start = opts.start = parseInt(x, 10) || 0;\n\n\t\tif (start >= stats.size || end >= stats.size) {\n\t\t\tres.setHeader('Content-Range', `bytes */${stats.size}`);\n\t\t\tres.statusCode = 416;\n\t\t\treturn res.end();\n\t\t}\n\n\t\theaders['Content-Range'] = `bytes ${start}-${end}/${stats.size}`;\n\t\theaders['Content-Length'] = (end - start + 1);\n\t\theaders['Accept-Ranges'] = 'bytes';\n\t}\n\n\tres.writeHead(code, headers);\n\trequire$$0$2.createReadStream(file, opts).pipe(res);\n}\n\nconst ENCODING = {\n\t'.br': 'br',\n\t'.gz': 'gzip',\n};\n\nfunction toHeaders(name, stats, isEtag) {\n\tlet enc = ENCODING[name.slice(-3)];\n\n\tlet ctype = lookup(name.slice(0, enc && -3)) || '';\n\tif (ctype === 'text/html') ctype += ';charset=utf-8';\n\n\tlet headers = {\n\t\t'Content-Length': stats.size,\n\t\t'Content-Type': ctype,\n\t\t'Last-Modified': stats.mtime.toUTCString(),\n\t};\n\n\tif (enc) headers['Content-Encoding'] = enc;\n\tif (isEtag) headers['ETag'] = `W/\"${stats.size}-${stats.mtime.getTime()}\"`;\n\n\treturn headers;\n}\n\nfunction sirv (dir, opts={}) {\n\tdir = resolve$3(dir || '.');\n\n\tlet isNotFound = opts.onNoMatch || is404;\n\tlet setHeaders = opts.setHeaders || noop$2;\n\n\tlet extensions = opts.extensions || ['html', 'htm'];\n\tlet gzips = opts.gzip && extensions.map(x => `${x}.gz`).concat('gz');\n\tlet brots = opts.brotli && extensions.map(x => `${x}.br`).concat('br');\n\n\tconst FILES = {};\n\n\tlet fallback = '/';\n\tlet isEtag = !!opts.etag;\n\tlet isSPA = !!opts.single;\n\tif (typeof opts.single === 'string') {\n\t\tlet idx = opts.single.lastIndexOf('.');\n\t\tfallback += !!~idx ? opts.single.substring(0, idx) : opts.single;\n\t}\n\n\tlet ignores = [];\n\tif (opts.ignores !== false) {\n\t\tignores.push(/[/]([A-Za-z\\s\\d~$._-]+\\.\\w+){1,}$/); // any extn\n\t\tif (opts.dotfiles) ignores.push(/\\/\\.\\w/);\n\t\telse ignores.push(/\\/\\.well-known/);\n\t\t[].concat(opts.ignores || []).forEach(x => {\n\t\t\tignores.push(new RegExp(x, 'i'));\n\t\t});\n\t}\n\n\tlet cc = opts.maxAge != null && `public,max-age=${opts.maxAge}`;\n\tif (cc && opts.immutable) cc += ',immutable';\n\telse if (cc && opts.maxAge === 0) cc += ',must-revalidate';\n\n\tif (!opts.dev) {\n\t\ttotalist(dir, (name, abs, stats) => {\n\t\t\tif (/\\.well-known[\\\\+\\/]/.test(name)) ; // keep\n\t\t\telse if (!opts.dotfiles && /(^\\.|[\\\\+|\\/+]\\.)/.test(name)) return;\n\n\t\t\tlet headers = toHeaders(name, stats, isEtag);\n\t\t\tif (cc) headers['Cache-Control'] = cc;\n\n\t\t\tFILES['/' + name.normalize().replace(/\\\\+/g, '/')] = { abs, stats, headers };\n\t\t});\n\t}\n\n\tlet lookup = opts.dev ? viaLocal.bind(0, dir, isEtag) : viaCache.bind(0, FILES);\n\n\treturn function (req, res, next) {\n\t\tlet extns = [''];\n\t\tlet pathname = parse$9(req).pathname;\n\t\tlet val = req.headers['accept-encoding'] || '';\n\t\tif (gzips && val.includes('gzip')) extns.unshift(...gzips);\n\t\tif (brots && /(br|brotli)/i.test(val)) extns.unshift(...brots);\n\t\textns.push(...extensions); // [...br, ...gz, orig, ...exts]\n\n\t\tif (pathname.indexOf('%') !== -1) {\n\t\t\ttry { pathname = decodeURIComponent(pathname); }\n\t\t\tcatch (err) { /* malform uri */ }\n\t\t}\n\n\t\tlet data = lookup(pathname, extns, opts.shouldServe) || isSPA && !isMatch(pathname, ignores) && lookup(fallback, extns, opts.shouldServe);\n\t\tif (!data) return next ? next() : isNotFound(req, res);\n\n\t\tif (isEtag && req.headers['if-none-match'] === data.headers['ETag']) {\n\t\t\tres.writeHead(304);\n\t\t\treturn res.end();\n\t\t}\n\n\t\tif (gzips || brots) {\n\t\t\tres.setHeader('Vary', 'Accept-Encoding');\n\t\t}\n\n\t\tsetHeaders(res, pathname, data.stats);\n\t\tsend$2(req, res, data.abs, data.stats, data.headers);\n\t};\n}\n\nconst sirvOptions = ({ headers, shouldServe, }) => {\n    return {\n        dev: true,\n        etag: true,\n        extensions: [],\n        setHeaders(res, pathname) {\n            // Matches js, jsx, ts, tsx.\n            // The reason this is done, is that the .ts file extension is reserved\n            // for the MIME type video/mp2t. In almost all cases, we can expect\n            // these files to be TypeScript files, and for Vite to serve them with\n            // this Content-Type.\n            if (/\\.[tj]sx?$/.test(pathname)) {\n                res.setHeader('Content-Type', 'application/javascript');\n            }\n            if (headers) {\n                for (const name in headers) {\n                    res.setHeader(name, headers[name]);\n                }\n            }\n        },\n        shouldServe,\n    };\n};\nfunction servePublicMiddleware(dir, headers) {\n    const serve = sirv(dir, sirvOptions({\n        headers,\n        shouldServe: (filePath) => shouldServeFile(filePath, dir),\n    }));\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteServePublicMiddleware(req, res, next) {\n        // skip import request and internal requests `/@fs/ /@vite-client` etc...\n        if (isImportRequest(req.url) || isInternalRequest(req.url)) {\n            return next();\n        }\n        serve(req, res, next);\n    };\n}\nfunction serveStaticMiddleware(dir, server) {\n    const serve = sirv(dir, sirvOptions({\n        headers: server.config.server.headers,\n    }));\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteServeStaticMiddleware(req, res, next) {\n        // only serve the file if it's not an html request or ends with `/`\n        // so that html requests can fallthrough to our html middleware for\n        // special processing\n        // also skip internal requests `/@fs/ /@vite-client` etc...\n        const cleanedUrl = cleanUrl(req.url);\n        if (cleanedUrl.endsWith('/') ||\n            path$o.extname(cleanedUrl) === '.html' ||\n            isInternalRequest(req.url)) {\n            return next();\n        }\n        const url = new URL(req.url, 'http://example.com');\n        const pathname = decodeURIComponent(url.pathname);\n        // apply aliases to static requests as well\n        let redirectedPathname;\n        for (const { find, replacement } of server.config.resolve.alias) {\n            const matches = typeof find === 'string'\n                ? pathname.startsWith(find)\n                : find.test(pathname);\n            if (matches) {\n                redirectedPathname = pathname.replace(find, replacement);\n                break;\n            }\n        }\n        if (redirectedPathname) {\n            // dir is pre-normalized to posix style\n            if (redirectedPathname.startsWith(dir)) {\n                redirectedPathname = redirectedPathname.slice(dir.length);\n            }\n        }\n        const resolvedPathname = redirectedPathname || pathname;\n        let fileUrl = path$o.resolve(dir, resolvedPathname.replace(/^\\//, ''));\n        if (resolvedPathname.endsWith('/') && !fileUrl.endsWith('/')) {\n            fileUrl = fileUrl + '/';\n        }\n        if (!ensureServingAccess(fileUrl, server, res, next)) {\n            return;\n        }\n        if (redirectedPathname) {\n            url.pathname = encodeURIComponent(redirectedPathname);\n            req.url = url.href.slice(url.origin.length);\n        }\n        serve(req, res, next);\n    };\n}\nfunction serveRawFsMiddleware(server) {\n    const serveFromRoot = sirv('/', sirvOptions({ headers: server.config.server.headers }));\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteServeRawFsMiddleware(req, res, next) {\n        const url = new URL(req.url, 'http://example.com');\n        // In some cases (e.g. linked monorepos) files outside of root will\n        // reference assets that are also out of served root. In such cases\n        // the paths are rewritten to `/@fs/` prefixed paths and must be served by\n        // searching based from fs root.\n        if (url.pathname.startsWith(FS_PREFIX)) {\n            const pathname = decodeURIComponent(url.pathname);\n            // restrict files outside of `fs.allow`\n            if (!ensureServingAccess(slash$1(path$o.resolve(fsPathFromId(pathname))), server, res, next)) {\n                return;\n            }\n            let newPathname = pathname.slice(FS_PREFIX.length);\n            if (isWindows$4)\n                newPathname = newPathname.replace(/^[A-Z]:/i, '');\n            url.pathname = encodeURIComponent(newPathname);\n            req.url = url.href.slice(url.origin.length);\n            serveFromRoot(req, res, next);\n        }\n        else {\n            next();\n        }\n    };\n}\nfunction isFileServingAllowed(url, server) {\n    if (!server.config.server.fs.strict)\n        return true;\n    const file = fsPathFromUrl(url);\n    if (server._fsDenyGlob(file))\n        return false;\n    if (server.moduleGraph.safeModulesPath.has(file))\n        return true;\n    if (server.config.server.fs.allow.some((dir) => isParentDirectory(dir, file)))\n        return true;\n    return false;\n}\nfunction ensureServingAccess(url, server, res, next) {\n    if (isFileServingAllowed(url, server)) {\n        return true;\n    }\n    if (isFileReadable(cleanUrl(url))) {\n        const urlMessage = `The request url \"${url}\" is outside of Vite serving allow list.`;\n        const hintMessage = `\n${server.config.server.fs.allow.map((i) => `- ${i}`).join('\\n')}\n\nRefer to docs https://vitejs.dev/config/server-options.html#server-fs-allow for configurations and more details.`;\n        server.config.logger.error(urlMessage);\n        server.config.logger.warnOnce(hintMessage + '\\n');\n        res.statusCode = 403;\n        res.write(renderRestrictedErrorHTML(urlMessage + '\\n' + hintMessage));\n        res.end();\n    }\n    else {\n        // if the file doesn't exist, we shouldn't restrict this path as it can\n        // be an API call. Middlewares would issue a 404 if the file isn't handled\n        next();\n    }\n    return false;\n}\nfunction renderRestrictedErrorHTML(msg) {\n    // to have syntax highlighting and autocompletion in IDE\n    const html = String.raw;\n    return html `\n    <body>\n      <h1>403 Restricted</h1>\n      <p>${msg.replace(/\\n/g, '<br/>')}</p>\n      <style>\n        body {\n          padding: 1em 2em;\n        }\n      </style>\n    </body>\n  `;\n}\n\nconst ERR_LOAD_URL = 'ERR_LOAD_URL';\nconst ERR_LOAD_PUBLIC_URL = 'ERR_LOAD_PUBLIC_URL';\nconst debugLoad = createDebugger('vite:load');\nconst debugTransform = createDebugger('vite:transform');\nconst debugCache$1 = createDebugger('vite:cache');\nconst isDebug$2 = !!process.env.DEBUG;\nfunction transformRequest(url, server, options = {}) {\n    const cacheKey = (options.ssr ? 'ssr:' : options.html ? 'html:' : '') + url;\n    // This module may get invalidated while we are processing it. For example\n    // when a full page reload is needed after the re-processing of pre-bundled\n    // dependencies when a missing dep is discovered. We save the current time\n    // to compare it to the last invalidation performed to know if we should\n    // cache the result of the transformation or we should discard it as stale.\n    //\n    // A module can be invalidated due to:\n    // 1. A full reload because of pre-bundling newly discovered deps\n    // 2. A full reload after a config change\n    // 3. The file that generated the module changed\n    // 4. Invalidation for a virtual module\n    //\n    // For 1 and 2, a new request for this module will be issued after\n    // the invalidation as part of the browser reloading the page. For 3 and 4\n    // there may not be a new request right away because of HMR handling.\n    // In all cases, the next time this module is requested, it should be\n    // re-processed.\n    //\n    // We save the timestamp when we start processing and compare it with the\n    // last time this module is invalidated\n    const timestamp = Date.now();\n    const pending = server._pendingRequests.get(cacheKey);\n    if (pending) {\n        return server.moduleGraph\n            .getModuleByUrl(removeTimestampQuery(url), options.ssr)\n            .then((module) => {\n            if (!module || pending.timestamp > module.lastInvalidationTimestamp) {\n                // The pending request is still valid, we can safely reuse its result\n                return pending.request;\n            }\n            else {\n                // Request 1 for module A     (pending.timestamp)\n                // Invalidate module A        (module.lastInvalidationTimestamp)\n                // Request 2 for module A     (timestamp)\n                // First request has been invalidated, abort it to clear the cache,\n                // then perform a new doTransform.\n                pending.abort();\n                return transformRequest(url, server, options);\n            }\n        });\n    }\n    const request = doTransform(url, server, options, timestamp);\n    // Avoid clearing the cache of future requests if aborted\n    let cleared = false;\n    const clearCache = () => {\n        if (!cleared) {\n            server._pendingRequests.delete(cacheKey);\n            cleared = true;\n        }\n    };\n    // Cache the request and clear it once processing is done\n    server._pendingRequests.set(cacheKey, {\n        request,\n        timestamp,\n        abort: clearCache,\n    });\n    request.then(clearCache, clearCache);\n    return request;\n}\nasync function doTransform(url, server, options, timestamp) {\n    url = removeTimestampQuery(url);\n    const { config, pluginContainer } = server;\n    const prettyUrl = isDebug$2 ? prettifyUrl(url, config.root) : '';\n    const ssr = !!options.ssr;\n    const module = await server.moduleGraph.getModuleByUrl(url, ssr);\n    // check if we have a fresh cache\n    const cached = module && (ssr ? module.ssrTransformResult : module.transformResult);\n    if (cached) {\n        // TODO: check if the module is \"partially invalidated\" - i.e. an import\n        // down the chain has been fully invalidated, but this current module's\n        // content has not changed.\n        // in this case, we can reuse its previous cached result and only update\n        // its import timestamps.\n        isDebug$2 && debugCache$1(`[memory] ${prettyUrl}`);\n        return cached;\n    }\n    // resolve\n    const id = (await pluginContainer.resolveId(url, undefined, { ssr }))?.id || url;\n    const result = loadAndTransform(id, url, server, options, timestamp);\n    getDepsOptimizer(config, ssr)?.delayDepsOptimizerUntil(id, () => result);\n    return result;\n}\nasync function loadAndTransform(id, url, server, options, timestamp) {\n    const { config, pluginContainer, moduleGraph, watcher } = server;\n    const { root, logger } = config;\n    const prettyUrl = isDebug$2 ? prettifyUrl(url, config.root) : '';\n    const ssr = !!options.ssr;\n    const file = cleanUrl(id);\n    let code = null;\n    let map = null;\n    // load\n    const loadStart = isDebug$2 ? performance.now() : 0;\n    const loadResult = await pluginContainer.load(id, { ssr });\n    if (loadResult == null) {\n        // if this is an html request and there is no load result, skip ahead to\n        // SPA fallback.\n        if (options.html && !id.endsWith('.html')) {\n            return null;\n        }\n        // try fallback loading it from fs as string\n        // if the file is a binary, there should be a plugin that already loaded it\n        // as string\n        // only try the fallback if access is allowed, skip for out of root url\n        // like /service-worker.js or /api/users\n        if (options.ssr || isFileServingAllowed(file, server)) {\n            try {\n                code = await promises$2.readFile(file, 'utf-8');\n                isDebug$2 && debugLoad(`${timeFrom(loadStart)} [fs] ${prettyUrl}`);\n            }\n            catch (e) {\n                if (e.code !== 'ENOENT') {\n                    throw e;\n                }\n            }\n        }\n        if (code) {\n            try {\n                map = (convertSourceMap.fromSource(code) ||\n                    (await convertSourceMap.fromMapFileSource(code, createConvertSourceMapReadMap(file))))?.toObject();\n                code = code.replace(convertSourceMap.mapFileCommentRegex, blankReplacer);\n            }\n            catch (e) {\n                logger.warn(`Failed to load source map for ${url}.`, {\n                    timestamp: true,\n                });\n            }\n        }\n    }\n    else {\n        isDebug$2 && debugLoad(`${timeFrom(loadStart)} [plugin] ${prettyUrl}`);\n        if (isObject$1(loadResult)) {\n            code = loadResult.code;\n            map = loadResult.map;\n        }\n        else {\n            code = loadResult;\n        }\n    }\n    if (code == null) {\n        const isPublicFile = checkPublicFile(url, config);\n        const msg = isPublicFile\n            ? `This file is in /public and will be copied as-is during build without ` +\n                `going through the plugin transforms, and therefore should not be ` +\n                `imported from source code. It can only be referenced via HTML tags.`\n            : `Does the file exist?`;\n        const importerMod = server.moduleGraph.idToModuleMap\n            .get(id)\n            ?.importers.values()\n            .next().value;\n        const importer = importerMod?.file || importerMod?.url;\n        const err = new Error(`Failed to load url ${url} (resolved id: ${id})${importer ? ` in ${importer}` : ''}. ${msg}`);\n        err.code = isPublicFile ? ERR_LOAD_PUBLIC_URL : ERR_LOAD_URL;\n        throw err;\n    }\n    // ensure module in graph after successful load\n    const mod = await moduleGraph.ensureEntryFromUrl(url, ssr);\n    ensureWatchedFile(watcher, mod.file, root);\n    // transform\n    const transformStart = isDebug$2 ? performance.now() : 0;\n    const transformResult = await pluginContainer.transform(code, id, {\n        inMap: map,\n        ssr,\n    });\n    const originalCode = code;\n    if (transformResult == null ||\n        (isObject$1(transformResult) && transformResult.code == null)) {\n        // no transform applied, keep code as-is\n        isDebug$2 &&\n            debugTransform(timeFrom(transformStart) + picocolorsExports.dim(` [skipped] ${prettyUrl}`));\n    }\n    else {\n        isDebug$2 && debugTransform(`${timeFrom(transformStart)} ${prettyUrl}`);\n        code = transformResult.code;\n        map = transformResult.map;\n    }\n    if (map && mod.file) {\n        map = (typeof map === 'string' ? JSON.parse(map) : map);\n        if (map.mappings && !map.sourcesContent) {\n            await injectSourcesContent(map, mod.file, logger);\n        }\n    }\n    const result = ssr && !server.config.experimental.skipSsrTransform\n        ? await server.ssrTransform(code, map, url, originalCode)\n        : {\n            code,\n            map,\n            etag: etag_1(code, { weak: true }),\n        };\n    // Only cache the result if the module wasn't invalidated while it was\n    // being processed, so it is re-processed next time if it is stale\n    if (timestamp > mod.lastInvalidationTimestamp) {\n        if (ssr)\n            mod.ssrTransformResult = result;\n        else\n            mod.transformResult = result;\n    }\n    return result;\n}\nfunction createConvertSourceMapReadMap(originalFileName) {\n    return (filename) => {\n        return promises$2.readFile(path$o.resolve(path$o.dirname(originalFileName), filename), 'utf-8');\n    };\n}\n\nconst isDebug$1 = !!process.env.DEBUG;\nconst debug$9 = createDebugger('vite:import-analysis');\nconst clientDir = normalizePath$3(CLIENT_DIR);\nconst skipRE = /\\.(?:map|json)(?:$|\\?)/;\nconst canSkipImportAnalysis = (id) => skipRE.test(id) || isDirectCSSRequest(id);\nconst optimizedDepChunkRE$1 = /\\/chunk-[A-Z\\d]{8}\\.js/;\nconst optimizedDepDynamicRE$1 = /-[A-Z\\d]{8}\\.js/;\nfunction isExplicitImportRequired(url) {\n    return !isJSRequest(cleanUrl(url)) && !isCSSRequest(url);\n}\nfunction markExplicitImport(url) {\n    if (isExplicitImportRequired(url)) {\n        return injectQuery(url, 'import');\n    }\n    return url;\n}\nfunction extractImportedBindings(id, source, importSpec, importedBindings) {\n    let bindings = importedBindings.get(id);\n    if (!bindings) {\n        bindings = new Set();\n        importedBindings.set(id, bindings);\n    }\n    const isDynamic = importSpec.d > -1;\n    const isMeta = importSpec.d === -2;\n    if (isDynamic || isMeta) {\n        // this basically means the module will be impacted by any change in its dep\n        bindings.add('*');\n        return;\n    }\n    const exp = source.slice(importSpec.ss, importSpec.se);\n    const [match0] = findStaticImports(exp);\n    if (!match0) {\n        return;\n    }\n    const parsed = parseStaticImport(match0);\n    if (!parsed) {\n        return;\n    }\n    if (parsed.namespacedImport) {\n        bindings.add('*');\n    }\n    if (parsed.defaultImport) {\n        bindings.add('default');\n    }\n    if (parsed.namedImports) {\n        for (const name of Object.keys(parsed.namedImports)) {\n            bindings.add(name);\n        }\n    }\n}\n/**\n * Server-only plugin that lexes, resolves, rewrites and analyzes url imports.\n *\n * - Imports are resolved to ensure they exist on disk\n *\n * - Lexes HMR accept calls and updates import relationships in the module graph\n *\n * - Bare module imports are resolved (by @rollup-plugin/node-resolve) to\n * absolute file paths, e.g.\n *\n *     ```js\n *     import 'foo'\n *     ```\n *     is rewritten to\n *     ```js\n *     import '/@fs//project/node_modules/foo/dist/foo.js'\n *     ```\n *\n * - CSS imports are appended with `.js` since both the js module and the actual\n * css (referenced via `<link>`) may go through the transform pipeline:\n *\n *     ```js\n *     import './style.css'\n *     ```\n *     is rewritten to\n *     ```js\n *     import './style.css.js'\n *     ```\n */\nfunction importAnalysisPlugin(config) {\n    const { root, base } = config;\n    const clientPublicPath = path$o.posix.join(base, CLIENT_PUBLIC_PATH);\n    const enablePartialAccept = config.experimental?.hmrPartialAccept;\n    let server;\n    return {\n        name: 'vite:import-analysis',\n        configureServer(_server) {\n            server = _server;\n        },\n        async transform(source, importer, options) {\n            // In a real app `server` is always defined, but it is undefined when\n            // running src/node/server/__tests__/pluginContainer.spec.ts\n            if (!server) {\n                return null;\n            }\n            const ssr = options?.ssr === true;\n            const prettyImporter = prettifyUrl(importer, root);\n            if (canSkipImportAnalysis(importer)) {\n                isDebug$1 && debug$9(picocolorsExports.dim(`[skipped] ${prettyImporter}`));\n                return null;\n            }\n            const start = performance.now();\n            await init;\n            let imports;\n            let exports;\n            source = stripBomTag(source);\n            try {\n                [imports, exports] = parse$e(source);\n            }\n            catch (e) {\n                const isVue = importer.endsWith('.vue');\n                const maybeJSX = !isVue && isJSRequest(importer);\n                const msg = isVue\n                    ? `Install @vitejs/plugin-vue to handle .vue files.`\n                    : maybeJSX\n                        ? `If you are using JSX, make sure to name the file with the .jsx or .tsx extension.`\n                        : `You may need to install appropriate plugins to handle the ${path$o.extname(importer)} file format, or if it's an asset, add \"**/*${path$o.extname(importer)}\" to \\`assetsInclude\\` in your configuration.`;\n                this.error(`Failed to parse source for import analysis because the content ` +\n                    `contains invalid JS syntax. ` +\n                    msg, e.idx);\n            }\n            const depsOptimizer = getDepsOptimizer(config, ssr);\n            const { moduleGraph } = server;\n            // since we are already in the transform phase of the importer, it must\n            // have been loaded so its entry is guaranteed in the module graph.\n            const importerModule = moduleGraph.getModuleById(importer);\n            if (!importerModule && depsOptimizer?.isOptimizedDepFile(importer)) {\n                // Ids of optimized deps could be invalidated and removed from the graph\n                // Return without transforming, this request is no longer valid, a full reload\n                // is going to request this id again. Throwing an outdated error so we\n                // properly finish the request with a 504 sent to the browser.\n                throwOutdatedRequest(importer);\n            }\n            if (!imports.length && !this._addedImports) {\n                importerModule.isSelfAccepting = false;\n                isDebug$1 &&\n                    debug$9(`${timeFrom(start)} ${picocolorsExports.dim(`[no imports] ${prettyImporter}`)}`);\n                return source;\n            }\n            let hasHMR = false;\n            let isSelfAccepting = false;\n            let hasEnv = false;\n            let needQueryInjectHelper = false;\n            let s;\n            const str = () => s || (s = new MagicString(source));\n            const importedUrls = new Set();\n            const staticImportedUrls = new Set();\n            const acceptedUrls = new Set();\n            let isPartiallySelfAccepting = false;\n            const acceptedExports = new Set();\n            const importedBindings = enablePartialAccept\n                ? new Map()\n                : null;\n            const toAbsoluteUrl = (url) => path$o.posix.resolve(path$o.posix.dirname(importerModule.url), url);\n            const normalizeUrl = async (url, pos, forceSkipImportAnalysis = false) => {\n                url = stripBase(url, base);\n                let importerFile = importer;\n                const optimizeDeps = getDepOptimizationConfig(config, ssr);\n                if (moduleListContains(optimizeDeps?.exclude, url)) {\n                    if (depsOptimizer) {\n                        await depsOptimizer.scanProcessing;\n                        // if the dependency encountered in the optimized file was excluded from the optimization\n                        // the dependency needs to be resolved starting from the original source location of the optimized file\n                        // because starting from node_modules/.vite will not find the dependency if it was not hoisted\n                        // (that is, if it is under node_modules directory in the package source of the optimized file)\n                        for (const optimizedModule of depsOptimizer.metadata.depInfoList) {\n                            if (!optimizedModule.src)\n                                continue; // Ignore chunks\n                            if (optimizedModule.file === importerModule.file) {\n                                importerFile = optimizedModule.src;\n                            }\n                        }\n                    }\n                }\n                const resolved = await this.resolve(url, importerFile);\n                if (!resolved) {\n                    // in ssr, we should let node handle the missing modules\n                    if (ssr) {\n                        return [url, url];\n                    }\n                    // fix#9534, prevent the importerModuleNode being stopped from propagating updates\n                    importerModule.isSelfAccepting = false;\n                    return this.error(`Failed to resolve import \"${url}\" from \"${path$o.relative(process.cwd(), importerFile)}\". Does the file exist?`, pos);\n                }\n                const isRelative = url.startsWith('.');\n                const isSelfImport = !isRelative && cleanUrl(url) === cleanUrl(importer);\n                // normalize all imports into resolved URLs\n                // e.g. `import 'foo'` -> `import '/@fs/.../node_modules/foo/index.js'`\n                if (resolved.id.startsWith(root + '/')) {\n                    // in root: infer short absolute path from root\n                    url = resolved.id.slice(root.length);\n                }\n                else if (resolved.id.startsWith(getDepsCacheDirPrefix(config)) ||\n                    fs$l.existsSync(cleanUrl(resolved.id))) {\n                    // an optimized deps may not yet exists in the filesystem, or\n                    // a regular file exists but is out of root: rewrite to absolute /@fs/ paths\n                    url = path$o.posix.join(FS_PREFIX, resolved.id);\n                }\n                else {\n                    url = resolved.id;\n                }\n                if (isExternalUrl(url)) {\n                    return [url, url];\n                }\n                // if the resolved id is not a valid browser import specifier,\n                // prefix it to make it valid. We will strip this before feeding it\n                // back into the transform pipeline\n                if (!url.startsWith('.') && !url.startsWith('/')) {\n                    url = wrapId(resolved.id);\n                }\n                // make the URL browser-valid if not SSR\n                if (!ssr) {\n                    // mark non-js/css imports with `?import`\n                    url = markExplicitImport(url);\n                    // If the url isn't a request for a pre-bundled common chunk,\n                    // for relative js/css imports, or self-module virtual imports\n                    // (e.g. vue blocks), inherit importer's version query\n                    // do not do this for unknown type imports, otherwise the appended\n                    // query can break 3rd party plugin's extension checks.\n                    if ((isRelative || isSelfImport) &&\n                        !/[?&]import=?\\b/.test(url) &&\n                        !url.match(DEP_VERSION_RE)) {\n                        const versionMatch = importer.match(DEP_VERSION_RE);\n                        if (versionMatch) {\n                            url = injectQuery(url, versionMatch[1]);\n                        }\n                    }\n                    // check if the dep has been hmr updated. If yes, we need to attach\n                    // its last updated timestamp to force the browser to fetch the most\n                    // up-to-date version of this module.\n                    try {\n                        // delay setting `isSelfAccepting` until the file is actually used (#7870)\n                        const depModule = await moduleGraph.ensureEntryFromUrl(unwrapId(url), ssr, canSkipImportAnalysis(url) || forceSkipImportAnalysis);\n                        if (depModule.lastHMRTimestamp > 0) {\n                            url = injectQuery(url, `t=${depModule.lastHMRTimestamp}`);\n                        }\n                    }\n                    catch (e) {\n                        // it's possible that the dep fails to resolve (non-existent import)\n                        // attach location to the missing import\n                        e.pos = pos;\n                        throw e;\n                    }\n                    // prepend base\n                    url = joinUrlSegments(base, url);\n                }\n                return [url, resolved.id];\n            };\n            for (let index = 0; index < imports.length; index++) {\n                const { s: start, e: end, ss: expStart, se: expEnd, d: dynamicIndex, \n                // #2083 User may use escape path,\n                // so use imports[index].n to get the unescaped string\n                n: specifier, a: assertIndex, } = imports[index];\n                const rawUrl = source.slice(start, end);\n                // check import.meta usage\n                if (rawUrl === 'import.meta') {\n                    const prop = source.slice(end, end + 4);\n                    if (prop === '.hot') {\n                        hasHMR = true;\n                        const endHot = end + 4 + (source[end + 4] === '?' ? 1 : 0);\n                        if (source.slice(endHot, endHot + 7) === '.accept') {\n                            // further analyze accepted modules\n                            if (source.slice(endHot, endHot + 14) === '.acceptExports') {\n                                lexAcceptedHmrExports(source, source.indexOf('(', endHot + 14) + 1, acceptedExports);\n                                isPartiallySelfAccepting = true;\n                            }\n                            else if (lexAcceptedHmrDeps(source, source.indexOf('(', endHot + 7) + 1, acceptedUrls)) {\n                                isSelfAccepting = true;\n                            }\n                        }\n                    }\n                    else if (prop === '.env') {\n                        hasEnv = true;\n                    }\n                    continue;\n                }\n                const isDynamicImport = dynamicIndex > -1;\n                // strip import assertions as we can process them ourselves\n                if (!isDynamicImport && assertIndex > -1) {\n                    str().remove(end + 1, expEnd);\n                }\n                // static import or valid string in dynamic import\n                // If resolvable, let's resolve it\n                if (specifier) {\n                    // skip external / data uri\n                    if (isExternalUrl(specifier) || isDataUrl(specifier)) {\n                        continue;\n                    }\n                    // skip ssr external\n                    if (ssr) {\n                        if (config.legacy?.buildSsrCjsExternalHeuristics) {\n                            if (cjsShouldExternalizeForSSR(specifier, server._ssrExternals)) {\n                                continue;\n                            }\n                        }\n                        else if (shouldExternalizeForSSR(specifier, config)) {\n                            continue;\n                        }\n                        if (isBuiltin(specifier)) {\n                            continue;\n                        }\n                    }\n                    // skip client\n                    if (specifier === clientPublicPath) {\n                        continue;\n                    }\n                    // warn imports to non-asset /public files\n                    if (specifier.startsWith('/') &&\n                        !config.assetsInclude(cleanUrl(specifier)) &&\n                        !specifier.endsWith('.json') &&\n                        checkPublicFile(specifier, config)) {\n                        throw new Error(`Cannot import non-asset file ${specifier} which is inside /public.` +\n                            `JS/CSS files inside /public are copied as-is on build and ` +\n                            `can only be referenced via <script src> or <link href> in html.`);\n                    }\n                    // normalize\n                    const [url, resolvedId] = await normalizeUrl(specifier, start);\n                    if (!isDynamicImport &&\n                        specifier &&\n                        !specifier.includes('?') && // ignore custom queries\n                        isCSSRequest(resolvedId) &&\n                        !isModuleCSSRequest(resolvedId)) {\n                        const sourceExp = source.slice(expStart, start);\n                        if (sourceExp.includes('from') && // check default and named imports\n                            !sourceExp.includes('__vite_glob_') // glob handles deprecation message itself\n                        ) {\n                            const newImport = sourceExp + specifier + `?inline` + source.slice(end, expEnd);\n                            this.warn(`\\n` +\n                                picocolorsExports.cyan(importerModule.file) +\n                                `\\n` +\n                                picocolorsExports.reset(generateCodeFrame(source, start)) +\n                                `\\n` +\n                                picocolorsExports.yellow(`Default and named imports from CSS files are deprecated. ` +\n                                    `Use the ?inline query instead. ` +\n                                    `For example: ${newImport}`));\n                        }\n                    }\n                    // record as safe modules\n                    server?.moduleGraph.safeModulesPath.add(fsPathFromUrl(url));\n                    if (url !== specifier) {\n                        let rewriteDone = false;\n                        if (depsOptimizer?.isOptimizedDepFile(resolvedId) &&\n                            !resolvedId.match(optimizedDepChunkRE$1)) {\n                            // for optimized cjs deps, support named imports by rewriting named imports to const assignments.\n                            // internal optimized chunks don't need es interop and are excluded\n                            // The browserHash in resolvedId could be stale in which case there will be a full\n                            // page reload. We could return a 404 in that case but it is safe to return the request\n                            const file = cleanUrl(resolvedId); // Remove ?v={hash}\n                            const needsInterop = await optimizedDepNeedsInterop(depsOptimizer.metadata, file, config, ssr);\n                            if (needsInterop === undefined) {\n                                // Non-entry dynamic imports from dependencies will reach here as there isn't\n                                // optimize info for them, but they don't need es interop. If the request isn't\n                                // a dynamic import, then it is an internal Vite error\n                                if (!file.match(optimizedDepDynamicRE$1)) {\n                                    config.logger.error(picocolorsExports.red(`Vite Error, ${url} optimized info should be defined`));\n                                }\n                            }\n                            else if (needsInterop) {\n                                debug$9(`${url} needs interop`);\n                                interopNamedImports(str(), imports[index], url, index);\n                                rewriteDone = true;\n                            }\n                        }\n                        // If source code imports builtin modules via named imports, the stub proxy export\n                        // would fail as it's `export default` only. Apply interop for builtin modules to\n                        // correctly throw the error message.\n                        else if (url.includes(browserExternalId) &&\n                            source.slice(expStart, start).includes('{')) {\n                            interopNamedImports(str(), imports[index], url, index);\n                            rewriteDone = true;\n                        }\n                        if (!rewriteDone) {\n                            let rewrittenUrl = JSON.stringify(url);\n                            if (!isDynamicImport)\n                                rewrittenUrl = rewrittenUrl.slice(1, -1);\n                            str().overwrite(start, end, rewrittenUrl, {\n                                contentOnly: true,\n                            });\n                        }\n                    }\n                    // record for HMR import chain analysis\n                    // make sure to unwrap and normalize away base\n                    const hmrUrl = unwrapId(stripBase(url, base));\n                    importedUrls.add(hmrUrl);\n                    if (enablePartialAccept && importedBindings) {\n                        extractImportedBindings(resolvedId, source, imports[index], importedBindings);\n                    }\n                    if (!isDynamicImport) {\n                        // for pre-transforming\n                        staticImportedUrls.add({ url: hmrUrl, id: resolvedId });\n                    }\n                }\n                else if (!importer.startsWith(clientDir)) {\n                    if (!importer.includes('node_modules')) {\n                        // check @vite-ignore which suppresses dynamic import warning\n                        const hasViteIgnore = /\\/\\*\\s*@vite-ignore\\s*\\*\\//.test(\n                        // complete expression inside parens\n                        source.slice(dynamicIndex + 1, end));\n                        if (!hasViteIgnore) {\n                            this.warn(`\\n` +\n                                picocolorsExports.cyan(importerModule.file) +\n                                `\\n` +\n                                picocolorsExports.reset(generateCodeFrame(source, start)) +\n                                picocolorsExports.yellow(`\\nThe above dynamic import cannot be analyzed by Vite.\\n` +\n                                    `See ${picocolorsExports.blue(`https://github.com/rollup/plugins/tree/master/packages/dynamic-import-vars#limitations`)} ` +\n                                    `for supported dynamic import formats. ` +\n                                    `If this is intended to be left as-is, you can use the ` +\n                                    `/* @vite-ignore */ comment inside the import() call to suppress this warning.\\n`));\n                        }\n                    }\n                    if (!ssr) {\n                        const url = rawUrl\n                            .replace(/\\/\\*[\\s\\S]*?\\*\\/|([^\\\\:]|^)\\/\\/.*$/gm, '')\n                            .trim();\n                        if (!/^(?:'.*'|\".*\"|`.*`)$/.test(url) ||\n                            isExplicitImportRequired(url.slice(1, -1))) {\n                            needQueryInjectHelper = true;\n                            str().overwrite(start, end, `__vite__injectQuery(${url}, 'import')`, { contentOnly: true });\n                        }\n                    }\n                }\n            }\n            if (hasEnv) {\n                // inject import.meta.env\n                let env = `import.meta.env = ${JSON.stringify({\n                    ...config.env,\n                    SSR: !!ssr,\n                })};`;\n                // account for user env defines\n                for (const key in config.define) {\n                    if (key.startsWith(`import.meta.env.`)) {\n                        const val = config.define[key];\n                        env += `${key} = ${typeof val === 'string' ? val : JSON.stringify(val)};`;\n                    }\n                }\n                str().prepend(env);\n            }\n            if (hasHMR && !ssr) {\n                debugHmr(`${isSelfAccepting\n                    ? `[self-accepts]`\n                    : isPartiallySelfAccepting\n                        ? `[accepts-exports]`\n                        : acceptedUrls.size\n                            ? `[accepts-deps]`\n                            : `[detected api usage]`} ${prettyImporter}`);\n                // inject hot context\n                str().prepend(`import { createHotContext as __vite__createHotContext } from \"${clientPublicPath}\";` +\n                    `import.meta.hot = __vite__createHotContext(${JSON.stringify(normalizeHmrUrl(importerModule.url))});`);\n            }\n            if (needQueryInjectHelper) {\n                str().prepend(`import { injectQuery as __vite__injectQuery } from \"${clientPublicPath}\";`);\n            }\n            // normalize and rewrite accepted urls\n            const normalizedAcceptedUrls = new Set();\n            for (const { url, start, end } of acceptedUrls) {\n                const [normalized] = await moduleGraph.resolveUrl(toAbsoluteUrl(markExplicitImport(url)), ssr);\n                normalizedAcceptedUrls.add(normalized);\n                str().overwrite(start, end, JSON.stringify(normalized), {\n                    contentOnly: true,\n                });\n            }\n            // update the module graph for HMR analysis.\n            // node CSS imports does its own graph update in the css plugin so we\n            // only handle js graph updates here.\n            if (!isCSSRequest(importer)) {\n                // attached by pluginContainer.addWatchFile\n                const pluginImports = this._addedImports;\n                if (pluginImports) {\n                    (await Promise.all([...pluginImports].map((id) => normalizeUrl(id, 0, true)))).forEach(([url]) => importedUrls.add(url));\n                }\n                // HMR transforms are no-ops in SSR, so an `accept` call will\n                // never be injected. Avoid updating the `isSelfAccepting`\n                // property for our module node in that case.\n                if (ssr && importerModule.isSelfAccepting) {\n                    isSelfAccepting = true;\n                }\n                // a partially accepted module that accepts all its exports\n                // behaves like a self-accepted module in practice\n                if (!isSelfAccepting &&\n                    isPartiallySelfAccepting &&\n                    acceptedExports.size >= exports.length &&\n                    exports.every((e) => acceptedExports.has(e.n))) {\n                    isSelfAccepting = true;\n                }\n                const prunedImports = await moduleGraph.updateModuleInfo(importerModule, importedUrls, importedBindings, normalizedAcceptedUrls, isPartiallySelfAccepting ? acceptedExports : null, isSelfAccepting, ssr);\n                if (hasHMR && prunedImports) {\n                    handlePrunedModules(prunedImports, server);\n                }\n            }\n            isDebug$1 &&\n                debug$9(`${timeFrom(start)} ${picocolorsExports.dim(`[${importedUrls.size} imports rewritten] ${prettyImporter}`)}`);\n            // pre-transform known direct imports\n            // These requests will also be registered in transformRequest to be awaited\n            // by the deps optimizer\n            if (config.server.preTransformRequests && staticImportedUrls.size) {\n                staticImportedUrls.forEach(({ url }) => {\n                    url = removeImportQuery(url);\n                    transformRequest(url, server, { ssr }).catch((e) => {\n                        if (e?.code === ERR_OUTDATED_OPTIMIZED_DEP) {\n                            // This are expected errors\n                            return;\n                        }\n                        // Unexpected error, log the issue but avoid an unhandled exception\n                        config.logger.error(e.message);\n                    });\n                });\n            }\n            if (s) {\n                return transformStableResult(s, importer, config);\n            }\n            else {\n                return source;\n            }\n        },\n    };\n}\nfunction interopNamedImports(str, importSpecifier, rewrittenUrl, importIndex) {\n    const source = str.original;\n    const { s: start, e: end, ss: expStart, se: expEnd, d: dynamicIndex, } = importSpecifier;\n    if (dynamicIndex > -1) {\n        // rewrite `import('package')` to expose the default directly\n        str.overwrite(expStart, expEnd, `import('${rewrittenUrl}').then(m => m.default && m.default.__esModule ? m.default : ({ ...m.default, default: m.default }))`, { contentOnly: true });\n    }\n    else {\n        const exp = source.slice(expStart, expEnd);\n        const rawUrl = source.slice(start, end);\n        const rewritten = transformCjsImport(exp, rewrittenUrl, rawUrl, importIndex);\n        if (rewritten) {\n            str.overwrite(expStart, expEnd, rewritten, { contentOnly: true });\n        }\n        else {\n            // #1439 export * from '...'\n            str.overwrite(start, end, rewrittenUrl, { contentOnly: true });\n        }\n    }\n}\n/**\n * Detect import statements to a known optimized CJS dependency and provide\n * ES named imports interop. We do this by rewriting named imports to a variable\n * assignment to the corresponding property on the `module.exports` of the cjs\n * module. Note this doesn't support dynamic re-assignments from within the cjs\n * module.\n *\n * Note that es-module-lexer treats `export * from '...'` as an import as well,\n * so, we may encounter ExportAllDeclaration here, in which case `undefined`\n * will be returned.\n *\n * Credits \\@csr632 via #837\n */\nfunction transformCjsImport(importExp, url, rawUrl, importIndex) {\n    const node = parse$d(importExp, {\n        ecmaVersion: 'latest',\n        sourceType: 'module',\n    }).body[0];\n    if (node.type === 'ImportDeclaration' ||\n        node.type === 'ExportNamedDeclaration') {\n        if (!node.specifiers.length) {\n            return `import \"${url}\"`;\n        }\n        const importNames = [];\n        const exportNames = [];\n        let defaultExports = '';\n        for (const spec of node.specifiers) {\n            if (spec.type === 'ImportSpecifier' &&\n                spec.imported.type === 'Identifier') {\n                const importedName = spec.imported.name;\n                const localName = spec.local.name;\n                importNames.push({ importedName, localName });\n            }\n            else if (spec.type === 'ImportDefaultSpecifier') {\n                importNames.push({\n                    importedName: 'default',\n                    localName: spec.local.name,\n                });\n            }\n            else if (spec.type === 'ImportNamespaceSpecifier') {\n                importNames.push({ importedName: '*', localName: spec.local.name });\n            }\n            else if (spec.type === 'ExportSpecifier' &&\n                spec.exported.type === 'Identifier') {\n                // for ExportSpecifier, local name is same as imported name\n                // prefix the variable name to avoid clashing with other local variables\n                const importedName = spec.local.name;\n                // we want to specify exported name as variable and re-export it\n                const exportedName = spec.exported.name;\n                if (exportedName === 'default') {\n                    defaultExports = makeLegalIdentifier(`__vite__cjsExportDefault_${importIndex}`);\n                    importNames.push({ importedName, localName: defaultExports });\n                }\n                else {\n                    const localName = makeLegalIdentifier(`__vite__cjsExport_${exportedName}`);\n                    importNames.push({ importedName, localName });\n                    exportNames.push(`${localName} as ${exportedName}`);\n                }\n            }\n        }\n        // If there is multiple import for same id in one file,\n        // importIndex will prevent the cjsModuleName to be duplicate\n        const cjsModuleName = makeLegalIdentifier(`__vite__cjsImport${importIndex}_${rawUrl}`);\n        const lines = [`import ${cjsModuleName} from \"${url}\"`];\n        importNames.forEach(({ importedName, localName }) => {\n            if (importedName === '*') {\n                lines.push(`const ${localName} = ${cjsModuleName}`);\n            }\n            else if (importedName === 'default') {\n                lines.push(`const ${localName} = ${cjsModuleName}.__esModule ? ${cjsModuleName}.default : ${cjsModuleName}`);\n            }\n            else {\n                lines.push(`const ${localName} = ${cjsModuleName}[\"${importedName}\"]`);\n            }\n        });\n        if (defaultExports) {\n            lines.push(`export default ${defaultExports}`);\n        }\n        if (exportNames.length) {\n            lines.push(`export { ${exportNames.join(', ')} }`);\n        }\n        return lines.join('; ');\n    }\n}\n\n// ids in transform are normalized to unix style\nconst normalizedClientEntry = normalizePath$3(CLIENT_ENTRY);\nconst normalizedEnvEntry = normalizePath$3(ENV_ENTRY);\n/**\n * some values used by the client needs to be dynamically injected by the server\n * @server-only\n */\nfunction clientInjectionsPlugin(config) {\n    return {\n        name: 'vite:client-inject',\n        async transform(code, id, options) {\n            if (id === normalizedClientEntry || id === normalizedEnvEntry) {\n                const resolvedServerHostname = (await resolveHostname(config.server.host)).name;\n                const resolvedServerPort = config.server.port;\n                const devBase = config.base;\n                const serverHost = `${resolvedServerHostname}:${resolvedServerPort}${devBase}`;\n                let hmrConfig = config.server.hmr;\n                hmrConfig = isObject$1(hmrConfig) ? hmrConfig : undefined;\n                const host = hmrConfig?.host || null;\n                const protocol = hmrConfig?.protocol || null;\n                const timeout = hmrConfig?.timeout || 30000;\n                const overlay = hmrConfig?.overlay !== false;\n                const isHmrServerSpecified = !!hmrConfig?.server;\n                // hmr.clientPort -> hmr.port\n                // -> (24678 if middleware mode and HMR server is not specified) -> new URL(import.meta.url).port\n                let port = hmrConfig?.clientPort || hmrConfig?.port || null;\n                if (config.server.middlewareMode && !isHmrServerSpecified) {\n                    port || (port = 24678);\n                }\n                let directTarget = hmrConfig?.host || resolvedServerHostname;\n                directTarget += `:${hmrConfig?.port || resolvedServerPort}`;\n                directTarget += devBase;\n                let hmrBase = devBase;\n                if (hmrConfig?.path) {\n                    hmrBase = path$o.posix.join(hmrBase, hmrConfig.path);\n                }\n                return code\n                    .replace(`__MODE__`, JSON.stringify(config.mode))\n                    .replace(/__BASE__/g, JSON.stringify(devBase))\n                    .replace(`__DEFINES__`, serializeDefine(config.define || {}))\n                    .replace(`__SERVER_HOST__`, JSON.stringify(serverHost))\n                    .replace(`__HMR_PROTOCOL__`, JSON.stringify(protocol))\n                    .replace(`__HMR_HOSTNAME__`, JSON.stringify(host))\n                    .replace(`__HMR_PORT__`, JSON.stringify(port))\n                    .replace(`__HMR_DIRECT_TARGET__`, JSON.stringify(directTarget))\n                    .replace(`__HMR_BASE__`, JSON.stringify(hmrBase))\n                    .replace(`__HMR_TIMEOUT__`, JSON.stringify(timeout))\n                    .replace(`__HMR_ENABLE_OVERLAY__`, JSON.stringify(overlay));\n            }\n            else if (!options?.ssr && code.includes('process.env.NODE_ENV')) {\n                // replace process.env.NODE_ENV instead of defining a global\n                // for it to avoid shimming a `process` object during dev,\n                // avoiding inconsistencies between dev and build\n                return code.replace(/\\bprocess\\.env\\.NODE_ENV\\b/g, config.define?.['process.env.NODE_ENV'] ||\n                    JSON.stringify(process.env.NODE_ENV || config.mode));\n            }\n        },\n    };\n}\nfunction serializeDefine(define) {\n    let res = `{`;\n    for (const key in define) {\n        const val = define[key];\n        res += `${JSON.stringify(key)}: ${typeof val === 'string' ? `(${val})` : JSON.stringify(val)}, `;\n    }\n    return res + `}`;\n}\n\nconst wasmHelperId = '\\0vite/wasm-helper';\nconst wasmHelper = async (opts = {}, url) => {\n    let result;\n    if (url.startsWith('data:')) {\n        const urlContent = url.replace(/^data:.*?base64,/, '');\n        let bytes;\n        if (typeof Buffer === 'function' && typeof Buffer.from === 'function') {\n            bytes = Buffer.from(urlContent, 'base64');\n        }\n        else if (typeof atob === 'function') {\n            const binaryString = atob(urlContent);\n            bytes = new Uint8Array(binaryString.length);\n            for (let i = 0; i < binaryString.length; i++) {\n                bytes[i] = binaryString.charCodeAt(i);\n            }\n        }\n        else {\n            throw new Error('Failed to decode base64-encoded data URL, Buffer and atob are not supported');\n        }\n        result = await WebAssembly.instantiate(bytes, opts);\n    }\n    else {\n        // https://github.com/mdn/webassembly-examples/issues/5\n        // WebAssembly.instantiateStreaming requires the server to provide the\n        // correct MIME type for .wasm files, which unfortunately doesn't work for\n        // a lot of static file servers, so we just work around it by getting the\n        // raw buffer.\n        const response = await fetch(url);\n        const contentType = response.headers.get('Content-Type') || '';\n        if ('instantiateStreaming' in WebAssembly &&\n            contentType.startsWith('application/wasm')) {\n            result = await WebAssembly.instantiateStreaming(response, opts);\n        }\n        else {\n            const buffer = await response.arrayBuffer();\n            result = await WebAssembly.instantiate(buffer, opts);\n        }\n    }\n    return result.instance;\n};\nconst wasmHelperCode = wasmHelper.toString();\nconst wasmHelperPlugin = (config) => {\n    return {\n        name: 'vite:wasm-helper',\n        resolveId(id) {\n            if (id === wasmHelperId) {\n                return id;\n            }\n        },\n        async load(id) {\n            if (id === wasmHelperId) {\n                return `export default ${wasmHelperCode}`;\n            }\n            if (!id.endsWith('.wasm?init')) {\n                return;\n            }\n            const url = await fileToUrl(id, config, this);\n            return `\nimport initWasm from \"${wasmHelperId}\"\nexport default opts => initWasm(opts, ${JSON.stringify(url)})\n`;\n        },\n    };\n};\nconst wasmFallbackPlugin = () => {\n    return {\n        name: 'vite:wasm-fallback',\n        async load(id) {\n            if (!id.endsWith('.wasm')) {\n                return;\n            }\n            throw new Error('\"ESM integration proposal for Wasm\" is not supported currently. ' +\n                'Use vite-plugin-wasm or other community plugins to handle this. ' +\n                'Alternatively, you can use `.wasm?init` or `.wasm?url`. ' +\n                'See https://vitejs.dev/guide/features.html#webassembly for more details.');\n        },\n    };\n};\n\n/**\n * A plugin to avoid an aliased AND optimized dep from being aliased in src\n */\nfunction preAliasPlugin(config) {\n    const findPatterns = getAliasPatterns(config.resolve.alias);\n    const isConfiguredAsExternal = createIsConfiguredAsSsrExternal(config);\n    const isBuild = config.command === 'build';\n    return {\n        name: 'vite:pre-alias',\n        async resolveId(id, importer, options) {\n            const ssr = options?.ssr === true;\n            const depsOptimizer = getDepsOptimizer(config, ssr);\n            if (importer &&\n                depsOptimizer &&\n                bareImportRE.test(id) &&\n                !options?.scan &&\n                id !== '@vite/client' &&\n                id !== '@vite/env') {\n                if (findPatterns.find((pattern) => matches(pattern, id))) {\n                    const optimizedId = await tryOptimizedResolve(depsOptimizer, id, importer);\n                    if (optimizedId) {\n                        return optimizedId; // aliased dep already optimized\n                    }\n                    const resolved = await this.resolve(id, importer, {\n                        skipSelf: true,\n                        ...options,\n                    });\n                    if (resolved && !depsOptimizer.isOptimizedDepFile(resolved.id)) {\n                        const optimizeDeps = depsOptimizer.options;\n                        const resolvedId = cleanUrl(resolved.id);\n                        const isVirtual = resolvedId === id || resolvedId.includes('\\0');\n                        if (!isVirtual &&\n                            fs$l.existsSync(resolvedId) &&\n                            !moduleListContains(optimizeDeps.exclude, id) &&\n                            path$o.isAbsolute(resolvedId) &&\n                            (resolvedId.includes('node_modules') ||\n                                optimizeDeps.include?.includes(id)) &&\n                            isOptimizable(resolvedId, optimizeDeps) &&\n                            !(isBuild && ssr && isConfiguredAsExternal(id)) &&\n                            (!ssr || optimizeAliasReplacementForSSR(resolvedId, optimizeDeps))) {\n                            // aliased dep has not yet been optimized\n                            const optimizedInfo = depsOptimizer.registerMissingImport(id, resolvedId);\n                            return { id: depsOptimizer.getOptimizedDepId(optimizedInfo) };\n                        }\n                    }\n                    return resolved;\n                }\n            }\n        },\n    };\n}\nfunction optimizeAliasReplacementForSSR(id, optimizeDeps) {\n    if (optimizeDeps.include?.includes(id)) {\n        return true;\n    }\n    // In the regular resolution, the default for non-external modules is to\n    // be optimized if they are CJS. Here, we don't have the package id but\n    // only the replacement file path. We could find the package.json from\n    // the id and respect the same default in the future.\n    // Default to not optimize an aliased replacement for now, forcing the\n    // user to explicitly add it to the ssr.optimizeDeps.include list.\n    return false;\n}\n// In sync with rollup plugin alias logic\nfunction matches(pattern, importee) {\n    if (pattern instanceof RegExp) {\n        return pattern.test(importee);\n    }\n    if (importee.length < pattern.length) {\n        return false;\n    }\n    if (importee === pattern) {\n        return true;\n    }\n    return importee.startsWith(pattern + '/');\n}\nfunction getAliasPatterns(entries) {\n    if (!entries) {\n        return [];\n    }\n    if (Array.isArray(entries)) {\n        return entries.map((entry) => entry.find);\n    }\n    return Object.entries(entries).map(([find]) => find);\n}\n\nconst nonJsRe = /\\.json(?:$|\\?)/;\nconst metaEnvRe = /import\\.meta\\.env\\.(.+)/;\nconst isNonJsRequest = (request) => nonJsRe.test(request);\nfunction definePlugin(config) {\n    const isBuild = config.command === 'build';\n    const isBuildLib = isBuild && config.build.lib;\n    // ignore replace process.env in lib build\n    const processEnv = {};\n    const processNodeEnv = {};\n    if (!isBuildLib) {\n        const nodeEnv = process.env.NODE_ENV || config.mode;\n        Object.assign(processEnv, {\n            'process.env.': `({}).`,\n            'global.process.env.': `({}).`,\n            'globalThis.process.env.': `({}).`,\n        });\n        Object.assign(processNodeEnv, {\n            'process.env.NODE_ENV': JSON.stringify(nodeEnv),\n            'global.process.env.NODE_ENV': JSON.stringify(nodeEnv),\n            'globalThis.process.env.NODE_ENV': JSON.stringify(nodeEnv),\n            __vite_process_env_NODE_ENV: JSON.stringify(nodeEnv),\n        });\n    }\n    const userDefine = {};\n    const userDefineEnv = {};\n    for (const key in config.define) {\n        const val = config.define[key];\n        userDefine[key] = typeof val === 'string' ? val : JSON.stringify(val);\n        // make sure `import.meta.env` object has user define properties\n        if (isBuild) {\n            const match = key.match(metaEnvRe);\n            if (match) {\n                userDefineEnv[match[1]] =\n                    // test if value is raw identifier to wrap with __vite__ so when\n                    // stringified for `import.meta.env`, we can remove the quotes and\n                    // retain being an identifier\n                    typeof val === 'string' && /^[\\p{L}_$]/u.test(val.trim())\n                        ? `__vite__${val}__vite__`\n                        : val;\n            }\n        }\n    }\n    // during dev, import.meta properties are handled by importAnalysis plugin.\n    // ignore replace import.meta.env in lib build\n    const importMetaKeys = {};\n    const importMetaFallbackKeys = {};\n    if (isBuild) {\n        const env = {\n            ...config.env,\n            SSR: !!config.build.ssr,\n        };\n        // set here to allow override with config.define\n        importMetaKeys['import.meta.hot'] = `undefined`;\n        for (const key in env) {\n            importMetaKeys[`import.meta.env.${key}`] = JSON.stringify(env[key]);\n        }\n        Object.assign(importMetaFallbackKeys, {\n            'import.meta.env.': `({}).`,\n            'import.meta.env': JSON.stringify({ ...env, ...userDefineEnv }).replace(/\"__vite__(.+?)__vite__\"/g, (_, val) => val),\n        });\n    }\n    function generatePattern(ssr) {\n        const replaceProcessEnv = !ssr || config.ssr?.target === 'webworker';\n        const replacements = {\n            ...(replaceProcessEnv ? processNodeEnv : {}),\n            ...importMetaKeys,\n            ...userDefine,\n            ...importMetaFallbackKeys,\n            ...(replaceProcessEnv ? processEnv : {}),\n        };\n        if (isBuild && !replaceProcessEnv) {\n            replacements['__vite_process_env_NODE_ENV'] = 'process.env.NODE_ENV';\n        }\n        const replacementsKeys = Object.keys(replacements);\n        const pattern = replacementsKeys.length\n            ? new RegExp(\n            // Mustn't be preceded by a char that can be part of an identifier\n            // or a '.' that isn't part of a spread operator\n            '(?<![\\\\p{L}\\\\p{N}_$]|(?<!\\\\.\\\\.)\\\\.)(' +\n                replacementsKeys\n                    .map((str) => {\n                    return str.replace(/[-[\\]/{}()*+?.\\\\^$|]/g, '\\\\$&');\n                })\n                    .join('|') +\n                // Mustn't be followed by a char that can be part of an identifier\n                // or an assignment (but allow equality operators)\n                ')(?:(?<=\\\\.)|(?![\\\\p{L}\\\\p{N}_$]|\\\\s*?=[^=]))', 'gu')\n            : null;\n        return [replacements, pattern];\n    }\n    const defaultPattern = generatePattern(false);\n    const ssrPattern = generatePattern(true);\n    return {\n        name: 'vite:define',\n        transform(code, id, options) {\n            const ssr = options?.ssr === true;\n            if (!ssr && !isBuild) {\n                // for dev we inject actual global defines in the vite client to\n                // avoid the transform cost.\n                return;\n            }\n            if (\n            // exclude html, css and static assets for performance\n            isHTMLRequest(id) ||\n                isCSSRequest(id) ||\n                isNonJsRequest(id) ||\n                config.assetsInclude(id)) {\n                return;\n            }\n            const [replacements, pattern] = ssr ? ssrPattern : defaultPattern;\n            if (!pattern) {\n                return null;\n            }\n            if (ssr && !isBuild) {\n                // ssr + dev, simple replace\n                return code.replace(pattern, (_, match) => {\n                    return '' + replacements[match];\n                });\n            }\n            const s = new MagicString(code);\n            let hasReplaced = false;\n            let match;\n            while ((match = pattern.exec(code))) {\n                hasReplaced = true;\n                const start = match.index;\n                const end = start + match[0].length;\n                const replacement = '' + replacements[match[1]];\n                s.update(start, end, replacement);\n            }\n            if (!hasReplaced) {\n                return null;\n            }\n            return transformStableResult(s, id, config);\n        },\n    };\n}\n\nconst ignoreFlagRE = /\\/\\*\\s*@vite-ignore\\s*\\*\\//;\nfunction err(e, pos) {\n    const error = new Error(e);\n    error.pos = pos;\n    return error;\n}\nfunction parseWorkerOptions(rawOpts, optsStartIndex) {\n    let opts = {};\n    try {\n        opts = evalValue(rawOpts);\n    }\n    catch {\n        throw err('Vite is unable to parse the worker options as the value is not static.' +\n            'To ignore this error, please use /* @vite-ignore */ in the worker options.', optsStartIndex);\n    }\n    if (opts == null) {\n        return {};\n    }\n    if (typeof opts !== 'object') {\n        throw err(`Expected worker options to be an object, got ${typeof opts}`, optsStartIndex);\n    }\n    return opts;\n}\nfunction getWorkerType(raw, clean, i) {\n    const commaIndex = clean.indexOf(',', i);\n    if (commaIndex === -1) {\n        return 'classic';\n    }\n    const endIndex = clean.indexOf(')', i);\n    // case: ') ... ,' mean no worker options params\n    if (commaIndex > endIndex) {\n        return 'classic';\n    }\n    // need to find in comment code\n    const workerOptString = raw\n        .substring(commaIndex + 1, endIndex)\n        .replace(/\\}[\\s\\S]*,/g, '}'); // strip trailing comma for parsing\n    const hasViteIgnore = ignoreFlagRE.test(workerOptString);\n    if (hasViteIgnore) {\n        return 'ignore';\n    }\n    // need to find in no comment code\n    const cleanWorkerOptString = clean.substring(commaIndex + 1, endIndex).trim();\n    if (!cleanWorkerOptString.length) {\n        return 'classic';\n    }\n    const workerOpts = parseWorkerOptions(workerOptString, commaIndex + 1);\n    if (workerOpts.type && ['classic', 'module'].includes(workerOpts.type)) {\n        return workerOpts.type;\n    }\n    return 'classic';\n}\nfunction workerImportMetaUrlPlugin(config) {\n    const isBuild = config.command === 'build';\n    let workerResolver;\n    return {\n        name: 'vite:worker-import-meta-url',\n        async transform(code, id, options) {\n            const ssr = options?.ssr === true;\n            if (!options?.ssr &&\n                (code.includes('new Worker') || code.includes('new SharedWorker')) &&\n                code.includes('new URL') &&\n                code.includes(`import.meta.url`)) {\n                const query = parseRequest(id);\n                let s;\n                const cleanString = stripLiteral(code);\n                const workerImportMetaUrlRE = /\\bnew\\s+(?:Worker|SharedWorker)\\s*\\(\\s*(new\\s+URL\\s*\\(\\s*('[^']+'|\"[^\"]+\"|`[^`]+`)\\s*,\\s*import\\.meta\\.url\\s*\\))/g;\n                let match;\n                while ((match = workerImportMetaUrlRE.exec(cleanString))) {\n                    const { 0: allExp, 1: exp, 2: emptyUrl, index } = match;\n                    const urlIndex = allExp.indexOf(exp) + index;\n                    const urlStart = cleanString.indexOf(emptyUrl, index);\n                    const urlEnd = urlStart + emptyUrl.length;\n                    const rawUrl = code.slice(urlStart, urlEnd);\n                    // potential dynamic template string\n                    if (rawUrl[0] === '`' && /\\$\\{/.test(rawUrl)) {\n                        this.error(`\\`new URL(url, import.meta.url)\\` is not supported in dynamic template string.`, urlIndex);\n                    }\n                    s || (s = new MagicString(code));\n                    const workerType = getWorkerType(code, cleanString, index + allExp.length);\n                    const url = rawUrl.slice(1, -1);\n                    let file;\n                    if (url.startsWith('.')) {\n                        file = path$o.resolve(path$o.dirname(id), url);\n                    }\n                    else {\n                        workerResolver ?? (workerResolver = config.createResolver({\n                            extensions: [],\n                            tryIndex: false,\n                            preferRelative: true,\n                        }));\n                        file = await workerResolver(url, id);\n                        file ?? (file = url.startsWith('/')\n                            ? slash$1(path$o.join(config.publicDir, url))\n                            : slash$1(path$o.resolve(path$o.dirname(id), url)));\n                    }\n                    let builtUrl;\n                    if (isBuild) {\n                        getDepsOptimizer(config, ssr)?.registerWorkersSource(id);\n                        builtUrl = await workerFileToUrl(config, file, query);\n                    }\n                    else {\n                        builtUrl = await fileToUrl(cleanUrl(file), config, this);\n                        builtUrl = injectQuery(builtUrl, WORKER_FILE_ID);\n                        builtUrl = injectQuery(builtUrl, `type=${workerType}`);\n                    }\n                    s.update(urlIndex, urlIndex + exp.length, `new URL(${JSON.stringify(builtUrl)}, self.location)`);\n                }\n                if (s) {\n                    return transformStableResult(s, id, config);\n                }\n                return null;\n            }\n        },\n    };\n}\n\n/**\n * Convert `new URL('./foo.png', import.meta.url)` to its resolved built URL\n *\n * Supports template string with dynamic segments:\n * ```\n * new URL(`./dir/${name}.png`, import.meta.url)\n * // transformed to\n * import.meta.glob('./dir/**.png', { eager: true, import: 'default' })[`./dir/${name}.png`]\n * ```\n */\nfunction assetImportMetaUrlPlugin(config) {\n    const normalizedPublicDir = normalizePath$3(config.publicDir);\n    let assetResolver;\n    return {\n        name: 'vite:asset-import-meta-url',\n        async transform(code, id, options) {\n            if (!options?.ssr &&\n                id !== preloadHelperId &&\n                code.includes('new URL') &&\n                code.includes(`import.meta.url`)) {\n                let s;\n                const assetImportMetaUrlRE = /\\bnew\\s+URL\\s*\\(\\s*('[^']+'|\"[^\"]+\"|`[^`]+`)\\s*,\\s*import\\.meta\\.url\\s*(?:,\\s*)?\\)/g;\n                const cleanString = stripLiteral(code);\n                let match;\n                while ((match = assetImportMetaUrlRE.exec(cleanString))) {\n                    const { 0: exp, 1: emptyUrl, index } = match;\n                    const urlStart = cleanString.indexOf(emptyUrl, index);\n                    const urlEnd = urlStart + emptyUrl.length;\n                    const rawUrl = code.slice(urlStart, urlEnd);\n                    if (!s)\n                        s = new MagicString(code);\n                    // potential dynamic template string\n                    if (rawUrl[0] === '`' && /\\$\\{/.test(rawUrl)) {\n                        const ast = this.parse(rawUrl);\n                        const templateLiteral = ast.body[0].expression;\n                        if (templateLiteral.expressions.length) {\n                            const pattern = JSON.stringify(buildGlobPattern(templateLiteral));\n                            // Note: native import.meta.url is not supported in the baseline\n                            // target so we use the global location here. It can be\n                            // window.location or self.location in case it is used in a Web Worker.\n                            // @see https://developer.mozilla.org/en-US/docs/Web/API/Window/self\n                            s.update(index, index + exp.length, `new URL((import.meta.glob(${pattern}, { eager: true, import: 'default', as: 'url' }))[${rawUrl}], self.location)`);\n                            continue;\n                        }\n                    }\n                    const url = rawUrl.slice(1, -1);\n                    let file;\n                    if (url.startsWith('.')) {\n                        file = slash$1(path$o.resolve(path$o.dirname(id), url));\n                    }\n                    else {\n                        assetResolver ?? (assetResolver = config.createResolver({\n                            extensions: [],\n                            mainFields: [],\n                            tryIndex: false,\n                            preferRelative: true,\n                        }));\n                        file = await assetResolver(url, id);\n                        file ?? (file = url.startsWith('/')\n                            ? slash$1(path$o.join(config.publicDir, url))\n                            : slash$1(path$o.resolve(path$o.dirname(id), url)));\n                    }\n                    // Get final asset URL. If the file does not exist,\n                    // we fall back to the initial URL and let it resolve in runtime\n                    let builtUrl;\n                    if (file) {\n                        try {\n                            if (isParentDirectory(normalizedPublicDir, file)) {\n                                const publicPath = '/' + path$o.posix.relative(normalizedPublicDir, file);\n                                builtUrl = await fileToUrl(publicPath, config, this);\n                            }\n                            else {\n                                builtUrl = await fileToUrl(file, config, this);\n                            }\n                        }\n                        catch {\n                            // do nothing, we'll log a warning after this\n                        }\n                    }\n                    if (!builtUrl) {\n                        const rawExp = code.slice(index, index + exp.length);\n                        config.logger.warnOnce(`\\n${rawExp} doesn't exist at build time, it will remain unchanged to be resolved at runtime`);\n                        builtUrl = url;\n                    }\n                    s.update(index, index + exp.length, `new URL(${JSON.stringify(builtUrl)}, self.location)`);\n                }\n                if (s) {\n                    return transformStableResult(s, id, config);\n                }\n            }\n            return null;\n        },\n    };\n}\nfunction buildGlobPattern(ast) {\n    let pattern = '';\n    let lastElementIndex = -1;\n    for (const exp of ast.expressions) {\n        for (let i = lastElementIndex + 1; i < ast.quasis.length; i++) {\n            const el = ast.quasis[i];\n            if (el.end < exp.start) {\n                pattern += el.value.raw;\n                lastElementIndex = i;\n            }\n        }\n        pattern += '**';\n    }\n    for (let i = lastElementIndex + 1; i < ast.quasis.length; i++) {\n        pattern += ast.quasis[i].value.raw;\n    }\n    return pattern;\n}\n\n/**\n * plugin to ensure rollup can watch correctly.\n */\nfunction ensureWatchPlugin() {\n    return {\n        name: 'vite:ensure-watch',\n        load(id) {\n            if (queryRE.test(id)) {\n                this.addWatchFile(cleanUrl(id));\n            }\n            return null;\n        },\n    };\n}\n\n/**\n * Prepares the rendered chunks to contain additional metadata during build.\n */\nfunction metadataPlugin() {\n    return {\n        name: 'vite:build-metadata',\n        async renderChunk(_code, chunk) {\n            chunk.viteMetadata = {\n                importedAssets: new Set(),\n                importedCss: new Set(),\n            };\n            return null;\n        },\n    };\n}\n\nclass VariableDynamicImportError extends Error {}\n\n/* eslint-disable-next-line no-template-curly-in-string */\nconst example = 'For example: import(`./foo/${bar}.js`).';\n\nfunction sanitizeString(str) {\n  if (str.includes('*')) {\n    throw new VariableDynamicImportError('A dynamic import cannot contain * characters.');\n  }\n  return str;\n}\n\nfunction templateLiteralToGlob(node) {\n  let glob = '';\n\n  for (let i = 0; i < node.quasis.length; i += 1) {\n    glob += sanitizeString(node.quasis[i].value.raw);\n    if (node.expressions[i]) {\n      glob += expressionToGlob(node.expressions[i]);\n    }\n  }\n\n  return glob;\n}\n\nfunction callExpressionToGlob(node) {\n  const { callee } = node;\n  if (\n    callee.type === 'MemberExpression' &&\n    callee.property.type === 'Identifier' &&\n    callee.property.name === 'concat'\n  ) {\n    return `${expressionToGlob(callee.object)}${node.arguments.map(expressionToGlob).join('')}`;\n  }\n  return '*';\n}\n\nfunction binaryExpressionToGlob(node) {\n  if (node.operator !== '+') {\n    throw new VariableDynamicImportError(`${node.operator} operator is not supported.`);\n  }\n\n  return `${expressionToGlob(node.left)}${expressionToGlob(node.right)}`;\n}\n\nfunction expressionToGlob(node) {\n  switch (node.type) {\n    case 'TemplateLiteral':\n      return templateLiteralToGlob(node);\n    case 'CallExpression':\n      return callExpressionToGlob(node);\n    case 'BinaryExpression':\n      return binaryExpressionToGlob(node);\n    case 'Literal': {\n      return sanitizeString(node.value);\n    }\n    default:\n      return '*';\n  }\n}\n\nconst defaultProtocol = 'file:';\nconst ignoredProtocols = ['data:', 'http:', 'https:'];\n\nfunction shouldIgnore(glob) {\n  const containsAsterisk = glob.includes('*');\n\n  const globURL = new URL(glob, defaultProtocol);\n\n  const containsIgnoredProtocol = ignoredProtocols.some(\n    (ignoredProtocol) => ignoredProtocol === globURL.protocol\n  );\n\n  return !containsAsterisk || containsIgnoredProtocol;\n}\n\nfunction dynamicImportToGlob(node, sourceString) {\n  let glob = expressionToGlob(node);\n\n  if (shouldIgnore(glob)) {\n    return null;\n  }\n\n  glob = glob.replace(/\\*\\*/g, '*');\n\n  if (glob.startsWith('*')) {\n    throw new VariableDynamicImportError(\n      `invalid import \"${sourceString}\". It cannot be statically analyzed. Variable dynamic imports must start with ./ and be limited to a specific directory. ${example}`\n    );\n  }\n\n  if (glob.startsWith('/')) {\n    throw new VariableDynamicImportError(\n      `invalid import \"${sourceString}\". Variable absolute imports are not supported, imports must start with ./ in the static part of the import. ${example}`\n    );\n  }\n\n  if (!glob.startsWith('./') && !glob.startsWith('../')) {\n    throw new VariableDynamicImportError(\n      `invalid import \"${sourceString}\". Variable bare imports are not supported, imports must start with ./ in the static part of the import. ${example}`\n    );\n  }\n\n  // Disallow ./*.ext\n  const ownDirectoryStarExtension = /^\\.\\/\\*\\.[\\w]+$/;\n  if (ownDirectoryStarExtension.test(glob)) {\n    throw new VariableDynamicImportError(\n      `${\n        `invalid import \"${sourceString}\". Variable imports cannot import their own directory, ` +\n        'place imports in a separate directory or make the import filename more specific. '\n      }${example}`\n    );\n  }\n\n  if (require$$0$4.extname(glob) === '') {\n    throw new VariableDynamicImportError(\n      `invalid import \"${sourceString}\". A file extension must be included in the static part of the import. ${example}`\n    );\n  }\n\n  return glob;\n}\n\nconst dynamicImportHelperId = '\\0vite/dynamic-import-helper';\nconst dynamicImportHelper = (glob, path) => {\n    const v = glob[path];\n    if (v) {\n        return typeof v === 'function' ? v() : Promise.resolve(v);\n    }\n    return new Promise((_, reject) => {\n        (typeof queueMicrotask === 'function' ? queueMicrotask : setTimeout)(reject.bind(null, new Error('Unknown variable dynamic import: ' + path)));\n    });\n};\nfunction parseDynamicImportPattern(strings) {\n    const filename = strings.slice(1, -1);\n    const rawQuery = parseRequest(filename);\n    let globParams = null;\n    const ast = parse$d(strings, {\n        ecmaVersion: 'latest',\n        sourceType: 'module',\n    }).body[0].expression;\n    const userPatternQuery = dynamicImportToGlob(ast, filename);\n    if (!userPatternQuery) {\n        return null;\n    }\n    const [userPattern] = userPatternQuery.split(requestQuerySplitRE, 2);\n    const [rawPattern] = filename.split(requestQuerySplitRE, 2);\n    if (rawQuery?.raw !== undefined) {\n        globParams = { as: 'raw' };\n    }\n    if (rawQuery?.url !== undefined) {\n        globParams = { as: 'url' };\n    }\n    if (rawQuery?.worker !== undefined) {\n        globParams = { as: 'worker' };\n    }\n    return {\n        globParams,\n        userPattern,\n        rawPattern,\n    };\n}\nasync function transformDynamicImport(importSource, importer, resolve, root) {\n    if (importSource[1] !== '.' && importSource[1] !== '/') {\n        const resolvedFileName = await resolve(importSource.slice(1, -1), importer);\n        if (!resolvedFileName) {\n            return null;\n        }\n        const relativeFileName = posix$1.relative(posix$1.dirname(normalizePath$3(importer)), normalizePath$3(resolvedFileName));\n        importSource = normalizePath$3('`' + (relativeFileName[0] === '.' ? '' : './') + relativeFileName + '`');\n    }\n    const dynamicImportPattern = parseDynamicImportPattern(importSource);\n    if (!dynamicImportPattern) {\n        return null;\n    }\n    const { globParams, rawPattern, userPattern } = dynamicImportPattern;\n    const params = globParams\n        ? `, ${JSON.stringify({ ...globParams, import: '*' })}`\n        : '';\n    let newRawPattern = posix$1.relative(posix$1.dirname(importer), await toAbsoluteGlob(rawPattern, root, importer, resolve));\n    if (!/^\\.{1,2}\\//.test(newRawPattern)) {\n        newRawPattern = `./${newRawPattern}`;\n    }\n    const exp = `(import.meta.glob(${JSON.stringify(userPattern)}${params}))`;\n    return {\n        rawPattern: newRawPattern,\n        pattern: userPattern,\n        glob: exp,\n    };\n}\nfunction dynamicImportVarsPlugin(config) {\n    const resolve = config.createResolver({\n        preferRelative: true,\n        tryIndex: false,\n        extensions: [],\n    });\n    const { include, exclude, warnOnError } = config.build.dynamicImportVarsOptions;\n    const filter = createFilter(include, exclude);\n    return {\n        name: 'vite:dynamic-import-vars',\n        resolveId(id) {\n            if (id === dynamicImportHelperId) {\n                return id;\n            }\n        },\n        load(id) {\n            if (id === dynamicImportHelperId) {\n                return 'export default ' + dynamicImportHelper.toString();\n            }\n        },\n        async transform(source, importer) {\n            if (!filter(importer)) {\n                return;\n            }\n            await init;\n            let imports = [];\n            try {\n                imports = parse$e(source)[0];\n            }\n            catch (e) {\n                // ignore as it might not be a JS file, the subsequent plugins will catch the error\n                return null;\n            }\n            if (!imports.length) {\n                return null;\n            }\n            let s;\n            let needDynamicImportHelper = false;\n            for (let index = 0; index < imports.length; index++) {\n                const { s: start, e: end, ss: expStart, se: expEnd, d: dynamicIndex, } = imports[index];\n                if (dynamicIndex === -1 || source[start] !== '`') {\n                    continue;\n                }\n                s || (s = new MagicString(source));\n                let result;\n                try {\n                    // When import string is using backticks, es-module-lexer `end` captures\n                    // until the closing parenthesis, instead of the closing backtick.\n                    // There may be inline comments between the backtick and the closing\n                    // parenthesis, so we manually remove them for now.\n                    // See https://github.com/guybedford/es-module-lexer/issues/118\n                    const importSource = removeComments(source.slice(start, end)).trim();\n                    result = await transformDynamicImport(importSource, importer, resolve, config.root);\n                }\n                catch (error) {\n                    if (warnOnError) {\n                        this.warn(error);\n                    }\n                    else {\n                        this.error(error);\n                    }\n                }\n                if (!result) {\n                    continue;\n                }\n                const { rawPattern, glob } = result;\n                needDynamicImportHelper = true;\n                s.overwrite(expStart, expEnd, `__variableDynamicImportRuntimeHelper(${glob}, \\`${rawPattern}\\`)`);\n            }\n            if (s) {\n                if (needDynamicImportHelper) {\n                    s.prepend(`import __variableDynamicImportRuntimeHelper from \"${dynamicImportHelperId}\";`);\n                }\n                return transformStableResult(s, importer, config);\n            }\n        },\n    };\n}\n\nasync function resolvePlugins(config, prePlugins, normalPlugins, postPlugins) {\n    const isBuild = config.command === 'build';\n    const isWatch = isBuild && !!config.build.watch;\n    const buildPlugins = isBuild\n        ? await (await Promise.resolve().then(function () { return build$1; })).resolveBuildPlugins(config)\n        : { pre: [], post: [] };\n    const { modulePreload } = config.build;\n    return [\n        isWatch ? ensureWatchPlugin() : null,\n        isBuild ? metadataPlugin() : null,\n        preAliasPlugin(config),\n        alias$1({ entries: config.resolve.alias }),\n        ...prePlugins,\n        modulePreload === true ||\n            (typeof modulePreload === 'object' && modulePreload.polyfill)\n            ? modulePreloadPolyfillPlugin(config)\n            : null,\n        ...(isDepsOptimizerEnabled(config, false) ||\n            isDepsOptimizerEnabled(config, true)\n            ? [\n                isBuild\n                    ? optimizedDepsBuildPlugin(config)\n                    : optimizedDepsPlugin(config),\n            ]\n            : []),\n        resolvePlugin({\n            ...config.resolve,\n            root: config.root,\n            isProduction: config.isProduction,\n            isBuild,\n            packageCache: config.packageCache,\n            ssrConfig: config.ssr,\n            asSrc: true,\n            getDepsOptimizer: (ssr) => getDepsOptimizer(config, ssr),\n            shouldExternalize: isBuild && config.build.ssr && config.ssr?.format !== 'cjs'\n                ? (id) => shouldExternalizeForSSR(id, config)\n                : undefined,\n        }),\n        htmlInlineProxyPlugin(config),\n        cssPlugin(config),\n        config.esbuild !== false ? esbuildPlugin(config.esbuild) : null,\n        jsonPlugin({\n            namedExports: true,\n            ...config.json,\n        }, isBuild),\n        wasmHelperPlugin(config),\n        webWorkerPlugin(config),\n        assetPlugin(config),\n        ...normalPlugins,\n        wasmFallbackPlugin(),\n        definePlugin(config),\n        cssPostPlugin(config),\n        isBuild && buildHtmlPlugin(config),\n        workerImportMetaUrlPlugin(config),\n        assetImportMetaUrlPlugin(config),\n        ...buildPlugins.pre,\n        dynamicImportVarsPlugin(config),\n        importGlobPlugin(config),\n        ...postPlugins,\n        ...buildPlugins.post,\n        // internal server-only plugins are always applied after everything else\n        ...(isBuild\n            ? []\n            : [clientInjectionsPlugin(config), importAnalysisPlugin(config)]),\n    ].filter(Boolean);\n}\nfunction createPluginHookUtils(plugins) {\n    // sort plugins per hook\n    const sortedPluginsCache = new Map();\n    function getSortedPlugins(hookName) {\n        if (sortedPluginsCache.has(hookName))\n            return sortedPluginsCache.get(hookName);\n        const sorted = getSortedPluginsByHook(hookName, plugins);\n        sortedPluginsCache.set(hookName, sorted);\n        return sorted;\n    }\n    function getSortedPluginHooks(hookName) {\n        const plugins = getSortedPlugins(hookName);\n        return plugins\n            .map((p) => {\n            const hook = p[hookName];\n            return typeof hook === 'object' && 'handler' in hook\n                ? hook.handler\n                : hook;\n        })\n            .filter(Boolean);\n    }\n    return {\n        getSortedPlugins,\n        getSortedPluginHooks,\n    };\n}\nfunction getSortedPluginsByHook(hookName, plugins) {\n    const pre = [];\n    const normal = [];\n    const post = [];\n    for (const plugin of plugins) {\n        const hook = plugin[hookName];\n        if (hook) {\n            if (typeof hook === 'object') {\n                if (hook.order === 'pre') {\n                    pre.push(plugin);\n                    continue;\n                }\n                if (hook.order === 'post') {\n                    post.push(plugin);\n                    continue;\n                }\n            }\n            normal.push(plugin);\n        }\n    }\n    return [...pre, ...normal, ...post];\n}\n\nfunction ansiRegex({onlyFirst = false} = {}) {\n\tconst pattern = [\n\t    '[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]*)*)?\\\\u0007)',\n\t\t'(?:(?:\\\\d{1,4}(?:;\\\\d{0,4})*)?[\\\\dA-PR-TZcf-ntqry=><~]))'\n\t].join('|');\n\n\treturn new RegExp(pattern, onlyFirst ? undefined : 'g');\n}\n\nfunction stripAnsi(string) {\n\tif (typeof string !== 'string') {\n\t\tthrow new TypeError(`Expected a \\`string\\`, got \\`${typeof string}\\``);\n\t}\n\n\treturn string.replace(ansiRegex(), '');\n}\n\nfunction prepareError(err) {\n    // only copy the information we need and avoid serializing unnecessary\n    // properties, since some errors may attach full objects (e.g. PostCSS)\n    return {\n        message: stripAnsi(err.message),\n        stack: stripAnsi(cleanStack(err.stack || '')),\n        id: err.id,\n        frame: stripAnsi(err.frame || ''),\n        plugin: err.plugin,\n        pluginCode: err.pluginCode,\n        loc: err.loc,\n    };\n}\nfunction buildErrorMessage(err, args = [], includeStack = true) {\n    if (err.plugin)\n        args.push(`  Plugin: ${picocolorsExports.magenta(err.plugin)}`);\n    const loc = err.loc ? `:${err.loc.line}:${err.loc.column}` : '';\n    if (err.id)\n        args.push(`  File: ${picocolorsExports.cyan(err.id)}${loc}`);\n    if (err.frame)\n        args.push(picocolorsExports.yellow(pad$1(err.frame)));\n    if (includeStack && err.stack)\n        args.push(pad$1(cleanStack(err.stack)));\n    return args.join('\\n');\n}\nfunction cleanStack(stack) {\n    return stack\n        .split(/\\n/g)\n        .filter((l) => /^\\s*at/.test(l))\n        .join('\\n');\n}\nfunction logError(server, err) {\n    const msg = buildErrorMessage(err, [\n        picocolorsExports.red(`Internal server error: ${err.message}`),\n    ]);\n    server.config.logger.error(msg, {\n        clear: true,\n        timestamp: true,\n        error: err,\n    });\n    server.ws.send({\n        type: 'error',\n        err: prepareError(err),\n    });\n}\nfunction errorMiddleware(server, allowNext = false) {\n    // note the 4 args must be kept for connect to treat this as error middleware\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteErrorMiddleware(err, _req, res, next) {\n        logError(server, err);\n        if (allowNext) {\n            next();\n        }\n        else {\n            res.statusCode = 500;\n            res.end(`\n        <!DOCTYPE html>\n        <html lang=\"en\">\n          <head>\n            <meta charset=\"UTF-8\" />\n            <title>Error</title>\n            <script type=\"module\">\n              import { ErrorOverlay } from '/@vite/client'\n              document.body.appendChild(new ErrorOverlay(${JSON.stringify(prepareError(err)).replace(/</g, '\\\\u003c')}))\n            </script>\n          </head>\n          <body>\n          </body>\n        </html>\n      `);\n        }\n    };\n}\n\n/**\n * This file is refactored into TypeScript based on\n * https://github.com/preactjs/wmr/blob/main/packages/wmr/src/lib/rollup-plugin-container.js\n */\nlet parser = Parser$1;\nasync function createPluginContainer(config, moduleGraph, watcher) {\n    const isDebug = process.env.DEBUG;\n    const { plugins, logger, root, build: { rollupOptions }, } = config;\n    const { getSortedPluginHooks, getSortedPlugins } = createPluginHookUtils(plugins);\n    const seenResolves = {};\n    const debugResolve = createDebugger('vite:resolve');\n    const debugPluginResolve = createDebugger('vite:plugin-resolve', {\n        onlyWhenFocused: 'vite:plugin',\n    });\n    const debugPluginTransform = createDebugger('vite:plugin-transform', {\n        onlyWhenFocused: 'vite:plugin',\n    });\n    const debugSourcemapCombineFlag = 'vite:sourcemap-combine';\n    const isDebugSourcemapCombineFocused = process.env.DEBUG?.includes(debugSourcemapCombineFlag);\n    const debugSourcemapCombineFilter = process.env.DEBUG_VITE_SOURCEMAP_COMBINE_FILTER;\n    const debugSourcemapCombine = createDebugger('vite:sourcemap-combine', {\n        onlyWhenFocused: true,\n    });\n    // ---------------------------------------------------------------------------\n    const watchFiles = new Set();\n    const minimalContext = {\n        meta: {\n            rollupVersion: VERSION,\n            watchMode: true,\n        },\n    };\n    function warnIncompatibleMethod(method, plugin) {\n        logger.warn(picocolorsExports.cyan(`[plugin:${plugin}] `) +\n            picocolorsExports.yellow(`context method ${picocolorsExports.bold(`${method}()`)} is not supported in serve mode. This plugin is likely not vite-compatible.`));\n    }\n    // parallel, ignores returns\n    async function hookParallel(hookName, context, args) {\n        const parallelPromises = [];\n        for (const plugin of getSortedPlugins(hookName)) {\n            const hook = plugin[hookName];\n            if (!hook)\n                continue;\n            // @ts-expect-error hook is not a primitive\n            const handler = 'handler' in hook ? hook.handler : hook;\n            if (hook.sequential) {\n                await Promise.all(parallelPromises);\n                parallelPromises.length = 0;\n                await handler.apply(context(plugin), args(plugin));\n            }\n            else {\n                parallelPromises.push(handler.apply(context(plugin), args(plugin)));\n            }\n        }\n        await Promise.all(parallelPromises);\n    }\n    // throw when an unsupported ModuleInfo property is accessed,\n    // so that incompatible plugins fail in a non-cryptic way.\n    const ModuleInfoProxy = {\n        get(info, key) {\n            if (key in info) {\n                return info[key];\n            }\n            throw Error(`[vite] The \"${key}\" property of ModuleInfo is not supported.`);\n        },\n    };\n    // same default value of \"moduleInfo.meta\" as in Rollup\n    const EMPTY_OBJECT = Object.freeze({});\n    function getModuleInfo(id) {\n        const module = moduleGraph?.getModuleById(id);\n        if (!module) {\n            return null;\n        }\n        if (!module.info) {\n            module.info = new Proxy({ id, meta: module.meta || EMPTY_OBJECT }, ModuleInfoProxy);\n        }\n        return module.info;\n    }\n    function updateModuleInfo(id, { meta }) {\n        if (meta) {\n            const moduleInfo = getModuleInfo(id);\n            if (moduleInfo) {\n                moduleInfo.meta = { ...moduleInfo.meta, ...meta };\n            }\n        }\n    }\n    // we should create a new context for each async hook pipeline so that the\n    // active plugin in that pipeline can be tracked in a concurrency-safe manner.\n    // using a class to make creating new contexts more efficient\n    class Context {\n        constructor(initialPlugin) {\n            this.meta = minimalContext.meta;\n            this.ssr = false;\n            this._scan = false;\n            this._activeId = null;\n            this._activeCode = null;\n            this._addedImports = null;\n            this._activePlugin = initialPlugin || null;\n        }\n        parse(code, opts = {}) {\n            return parser.parse(code, {\n                sourceType: 'module',\n                ecmaVersion: 'latest',\n                locations: true,\n                ...opts,\n            });\n        }\n        async resolve(id, importer, options) {\n            let skip;\n            if (options?.skipSelf && this._activePlugin) {\n                skip = new Set(this._resolveSkips);\n                skip.add(this._activePlugin);\n            }\n            let out = await container.resolveId(id, importer, {\n                assertions: options?.assertions,\n                custom: options?.custom,\n                isEntry: !!options?.isEntry,\n                skip,\n                ssr: this.ssr,\n                scan: this._scan,\n            });\n            if (typeof out === 'string')\n                out = { id: out };\n            return out;\n        }\n        getModuleInfo(id) {\n            return getModuleInfo(id);\n        }\n        getModuleIds() {\n            return moduleGraph\n                ? moduleGraph.idToModuleMap.keys()\n                : Array.prototype[Symbol.iterator]();\n        }\n        addWatchFile(id) {\n            watchFiles.add(id);\n            (this._addedImports || (this._addedImports = new Set())).add(id);\n            if (watcher)\n                ensureWatchedFile(watcher, id, root);\n        }\n        getWatchFiles() {\n            return [...watchFiles];\n        }\n        emitFile(assetOrFile) {\n            warnIncompatibleMethod(`emitFile`, this._activePlugin.name);\n            return '';\n        }\n        setAssetSource() {\n            warnIncompatibleMethod(`setAssetSource`, this._activePlugin.name);\n        }\n        getFileName() {\n            warnIncompatibleMethod(`getFileName`, this._activePlugin.name);\n            return '';\n        }\n        warn(e, position) {\n            const err = formatError(e, position, this);\n            const msg = buildErrorMessage(err, [picocolorsExports.yellow(`warning: ${err.message}`)], false);\n            logger.warn(msg, {\n                clear: true,\n                timestamp: true,\n            });\n        }\n        error(e, position) {\n            // error thrown here is caught by the transform middleware and passed on\n            // the the error middleware.\n            throw formatError(e, position, this);\n        }\n    }\n    function formatError(e, position, ctx) {\n        const err = (typeof e === 'string' ? new Error(e) : e);\n        if (err.pluginCode) {\n            return err; // The plugin likely called `this.error`\n        }\n        if (err.file && err.name === 'CssSyntaxError') {\n            err.id = normalizePath$3(err.file);\n        }\n        if (ctx._activePlugin)\n            err.plugin = ctx._activePlugin.name;\n        if (ctx._activeId && !err.id)\n            err.id = ctx._activeId;\n        if (ctx._activeCode) {\n            err.pluginCode = ctx._activeCode;\n            // some rollup plugins, e.g. json, sets err.position instead of err.pos\n            const pos = position ?? err.pos ?? err.position;\n            if (pos != null) {\n                let errLocation;\n                try {\n                    errLocation = numberToPos(ctx._activeCode, pos);\n                }\n                catch (err2) {\n                    logger.error(picocolorsExports.red(`Error in error handler:\\n${err2.stack || err2.message}\\n`), \n                    // print extra newline to separate the two errors\n                    { error: err2 });\n                    throw err;\n                }\n                err.loc = err.loc || {\n                    file: err.id,\n                    ...errLocation,\n                };\n                err.frame = err.frame || generateCodeFrame(ctx._activeCode, pos);\n            }\n            else if (err.loc) {\n                // css preprocessors may report errors in an included file\n                if (!err.frame) {\n                    let code = ctx._activeCode;\n                    if (err.loc.file) {\n                        err.id = normalizePath$3(err.loc.file);\n                        try {\n                            code = fs$l.readFileSync(err.loc.file, 'utf-8');\n                        }\n                        catch { }\n                    }\n                    err.frame = generateCodeFrame(code, err.loc);\n                }\n            }\n            else if (err.line && err.column) {\n                err.loc = {\n                    file: err.id,\n                    line: err.line,\n                    column: err.column,\n                };\n                err.frame = err.frame || generateCodeFrame(err.id, err.loc);\n            }\n            if (err.loc && ctx instanceof TransformContext) {\n                const rawSourceMap = ctx._getCombinedSourcemap();\n                if (rawSourceMap) {\n                    const traced = new TraceMap(rawSourceMap);\n                    const { source, line, column } = originalPositionFor$1(traced, {\n                        line: Number(err.loc.line),\n                        column: Number(err.loc.column),\n                    });\n                    if (source && line != null && column != null) {\n                        err.loc = { file: source, line, column };\n                    }\n                }\n            }\n        }\n        else if (err.loc) {\n            if (!err.frame) {\n                let code = err.pluginCode;\n                if (err.loc.file) {\n                    err.id = normalizePath$3(err.loc.file);\n                    if (!code) {\n                        try {\n                            code = fs$l.readFileSync(err.loc.file, 'utf-8');\n                        }\n                        catch { }\n                    }\n                }\n                if (code) {\n                    err.frame = generateCodeFrame(code, err.loc);\n                }\n            }\n        }\n        return err;\n    }\n    class TransformContext extends Context {\n        constructor(filename, code, inMap) {\n            super();\n            this.originalSourcemap = null;\n            this.sourcemapChain = [];\n            this.combinedMap = null;\n            this.filename = filename;\n            this.originalCode = code;\n            if (inMap) {\n                if (isDebugSourcemapCombineFocused) {\n                    // @ts-expect-error inject name for debug purpose\n                    inMap.name = '$inMap';\n                }\n                this.sourcemapChain.push(inMap);\n            }\n        }\n        _getCombinedSourcemap(createIfNull = false) {\n            if (debugSourcemapCombineFilter &&\n                this.filename.includes(debugSourcemapCombineFilter)) {\n                debugSourcemapCombine('----------', this.filename);\n                debugSourcemapCombine(this.combinedMap);\n                debugSourcemapCombine(this.sourcemapChain);\n                debugSourcemapCombine('----------');\n            }\n            let combinedMap = this.combinedMap;\n            for (let m of this.sourcemapChain) {\n                if (typeof m === 'string')\n                    m = JSON.parse(m);\n                if (!('version' in m)) {\n                    // empty, nullified source map\n                    combinedMap = this.combinedMap = null;\n                    this.sourcemapChain.length = 0;\n                    break;\n                }\n                if (!combinedMap) {\n                    combinedMap = m;\n                }\n                else {\n                    combinedMap = combineSourcemaps(cleanUrl(this.filename), [\n                        {\n                            ...m,\n                            sourcesContent: combinedMap.sourcesContent,\n                        },\n                        combinedMap,\n                    ]);\n                }\n            }\n            if (!combinedMap) {\n                return createIfNull\n                    ? new MagicString(this.originalCode).generateMap({\n                        includeContent: true,\n                        hires: true,\n                        source: cleanUrl(this.filename),\n                    })\n                    : null;\n            }\n            if (combinedMap !== this.combinedMap) {\n                this.combinedMap = combinedMap;\n                this.sourcemapChain.length = 0;\n            }\n            return this.combinedMap;\n        }\n        getCombinedSourcemap() {\n            return this._getCombinedSourcemap(true);\n        }\n    }\n    let closed = false;\n    const container = {\n        options: await (async () => {\n            let options = rollupOptions;\n            for (const optionsHook of getSortedPluginHooks('options')) {\n                options = (await optionsHook.call(minimalContext, options)) || options;\n            }\n            if (options.acornInjectPlugins) {\n                parser = Parser$1.extend(...arraify(options.acornInjectPlugins));\n            }\n            return {\n                acorn,\n                acornInjectPlugins: [],\n                ...options,\n            };\n        })(),\n        getModuleInfo,\n        async buildStart() {\n            await hookParallel('buildStart', (plugin) => new Context(plugin), () => [container.options]);\n        },\n        async resolveId(rawId, importer = join$2(root, 'index.html'), options) {\n            const skip = options?.skip;\n            const ssr = options?.ssr;\n            const scan = !!options?.scan;\n            const ctx = new Context();\n            ctx.ssr = !!ssr;\n            ctx._scan = scan;\n            ctx._resolveSkips = skip;\n            const resolveStart = isDebug ? performance.now() : 0;\n            let id = null;\n            const partial = {};\n            for (const plugin of getSortedPlugins('resolveId')) {\n                if (!plugin.resolveId)\n                    continue;\n                if (skip?.has(plugin))\n                    continue;\n                ctx._activePlugin = plugin;\n                const pluginResolveStart = isDebug ? performance.now() : 0;\n                const handler = 'handler' in plugin.resolveId\n                    ? plugin.resolveId.handler\n                    : plugin.resolveId;\n                const result = await handler.call(ctx, rawId, importer, {\n                    assertions: options?.assertions ?? {},\n                    custom: options?.custom,\n                    isEntry: !!options?.isEntry,\n                    ssr,\n                    scan,\n                });\n                if (!result)\n                    continue;\n                if (typeof result === 'string') {\n                    id = result;\n                }\n                else {\n                    id = result.id;\n                    Object.assign(partial, result);\n                }\n                isDebug &&\n                    debugPluginResolve(timeFrom(pluginResolveStart), plugin.name, prettifyUrl(id, root));\n                // resolveId() is hookFirst - first non-null result is returned.\n                break;\n            }\n            if (isDebug && rawId !== id && !rawId.startsWith(FS_PREFIX)) {\n                const key = rawId + id;\n                // avoid spamming\n                if (!seenResolves[key]) {\n                    seenResolves[key] = true;\n                    debugResolve(`${timeFrom(resolveStart)} ${picocolorsExports.cyan(rawId)} -> ${picocolorsExports.dim(id)}`);\n                }\n            }\n            if (id) {\n                partial.id = isExternalUrl(id) ? id : normalizePath$3(id);\n                return partial;\n            }\n            else {\n                return null;\n            }\n        },\n        async load(id, options) {\n            const ssr = options?.ssr;\n            const ctx = new Context();\n            ctx.ssr = !!ssr;\n            for (const plugin of getSortedPlugins('load')) {\n                if (!plugin.load)\n                    continue;\n                ctx._activePlugin = plugin;\n                const handler = 'handler' in plugin.load ? plugin.load.handler : plugin.load;\n                const result = await handler.call(ctx, id, { ssr });\n                if (result != null) {\n                    if (isObject$1(result)) {\n                        updateModuleInfo(id, result);\n                    }\n                    return result;\n                }\n            }\n            return null;\n        },\n        async transform(code, id, options) {\n            const inMap = options?.inMap;\n            const ssr = options?.ssr;\n            const ctx = new TransformContext(id, code, inMap);\n            ctx.ssr = !!ssr;\n            for (const plugin of getSortedPlugins('transform')) {\n                if (!plugin.transform)\n                    continue;\n                ctx._activePlugin = plugin;\n                ctx._activeId = id;\n                ctx._activeCode = code;\n                const start = isDebug ? performance.now() : 0;\n                let result;\n                const handler = 'handler' in plugin.transform\n                    ? plugin.transform.handler\n                    : plugin.transform;\n                try {\n                    result = await handler.call(ctx, code, id, { ssr });\n                }\n                catch (e) {\n                    ctx.error(e);\n                }\n                if (!result)\n                    continue;\n                isDebug &&\n                    debugPluginTransform(timeFrom(start), plugin.name, prettifyUrl(id, root));\n                if (isObject$1(result)) {\n                    if (result.code !== undefined) {\n                        code = result.code;\n                        if (result.map) {\n                            if (isDebugSourcemapCombineFocused) {\n                                // @ts-expect-error inject plugin name for debug purpose\n                                result.map.name = plugin.name;\n                            }\n                            ctx.sourcemapChain.push(result.map);\n                        }\n                    }\n                    updateModuleInfo(id, result);\n                }\n                else {\n                    code = result;\n                }\n            }\n            return {\n                code,\n                map: ctx._getCombinedSourcemap(),\n            };\n        },\n        async close() {\n            if (closed)\n                return;\n            const ctx = new Context();\n            await hookParallel('buildEnd', () => ctx, () => []);\n            await hookParallel('closeBundle', () => ctx, () => []);\n            closed = true;\n        },\n    };\n    return container;\n}\n\nconst debug$8 = createDebugger('vite:deps');\nconst htmlTypesRE = /\\.(html|vue|svelte|astro|imba)$/;\n// A simple regex to detect import sources. This is only used on\n// <script lang=\"ts\"> blocks in vue (setup only) or svelte files, since\n// seemingly unused imports are dropped by esbuild when transpiling TS which\n// prevents it from crawling further.\n// We can't use es-module-lexer because it can't handle TS, and don't want to\n// use Acorn because it's slow. Luckily this doesn't have to be bullet proof\n// since even missed imports can be caught at runtime, and false positives will\n// simply be ignored.\nconst importsRE = /(?<!\\/\\/.*)(?<=^|;|\\*\\/)\\s*import(?!\\s+type)(?:[\\w*{}\\n\\r\\t, ]+from)?\\s*(\"[^\"]+\"|'[^']+')\\s*(?=$|;|\\/\\/|\\/\\*)/gm;\nasync function scanImports(config) {\n    // Only used to scan non-ssr code\n    const start = performance.now();\n    let entries = [];\n    const explicitEntryPatterns = config.optimizeDeps.entries;\n    const buildInput = config.build.rollupOptions?.input;\n    if (explicitEntryPatterns) {\n        entries = await globEntries(explicitEntryPatterns, config);\n    }\n    else if (buildInput) {\n        const resolvePath = (p) => path$o.resolve(config.root, p);\n        if (typeof buildInput === 'string') {\n            entries = [resolvePath(buildInput)];\n        }\n        else if (Array.isArray(buildInput)) {\n            entries = buildInput.map(resolvePath);\n        }\n        else if (isObject$1(buildInput)) {\n            entries = Object.values(buildInput).map(resolvePath);\n        }\n        else {\n            throw new Error('invalid rollupOptions.input value.');\n        }\n    }\n    else {\n        entries = await globEntries('**/*.html', config);\n    }\n    // Non-supported entry file types and virtual files should not be scanned for\n    // dependencies.\n    entries = entries.filter((entry) => isScannable(entry) && fs$l.existsSync(entry));\n    if (!entries.length) {\n        if (!explicitEntryPatterns && !config.optimizeDeps.include) {\n            config.logger.warn(picocolorsExports.yellow('(!) Could not auto-determine entry point from rollupOptions or html files ' +\n                'and there are no explicit optimizeDeps.include patterns. ' +\n                'Skipping dependency pre-bundling.'));\n        }\n        return { deps: {}, missing: {} };\n    }\n    else {\n        debug$8(`Crawling dependencies using entries:\\n  ${entries.join('\\n  ')}`);\n    }\n    const deps = {};\n    const missing = {};\n    const container = await createPluginContainer(config);\n    const plugin = esbuildScanPlugin(config, container, deps, missing, entries);\n    const { plugins = [], ...esbuildOptions } = config.optimizeDeps?.esbuildOptions ?? {};\n    await build$3({\n        absWorkingDir: process.cwd(),\n        write: false,\n        stdin: {\n            contents: entries.map((e) => `import ${JSON.stringify(e)}`).join('\\n'),\n            loader: 'js',\n        },\n        bundle: true,\n        format: 'esm',\n        logLevel: 'error',\n        plugins: [...plugins, plugin],\n        ...esbuildOptions,\n    });\n    debug$8(`Scan completed in ${(performance.now() - start).toFixed(2)}ms:`, deps);\n    return {\n        // Ensure a fixed order so hashes are stable and improve logs\n        deps: orderedDependencies(deps),\n        missing,\n    };\n}\nfunction orderedDependencies(deps) {\n    const depsList = Object.entries(deps);\n    // Ensure the same browserHash for the same set of dependencies\n    depsList.sort((a, b) => a[0].localeCompare(b[0]));\n    return Object.fromEntries(depsList);\n}\nfunction globEntries(pattern, config) {\n    return out(pattern, {\n        cwd: config.root,\n        ignore: [\n            '**/node_modules/**',\n            `**/${config.build.outDir}/**`,\n            // if there aren't explicit entries, also ignore other common folders\n            ...(config.optimizeDeps.entries\n                ? []\n                : [`**/__tests__/**`, `**/coverage/**`]),\n        ],\n        absolute: true,\n        suppressErrors: true, // suppress EACCES errors\n    });\n}\nconst scriptModuleRE = /(<script\\b[^>]+type\\s*=\\s*(?:\"module\"|'module')[^>]*>)(.*?)<\\/script>/gis;\nconst scriptRE = /(<script(?:\\s[^>]*>|>))(.*?)<\\/script>/gis;\nconst commentRE = /<!--.*?-->/gs;\nconst srcRE = /\\bsrc\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/i;\nconst typeRE = /\\btype\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/i;\nconst langRE = /\\blang\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/i;\nconst contextRE = /\\bcontext\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/i;\nfunction esbuildScanPlugin(config, container, depImports, missing, entries) {\n    const seen = new Map();\n    const resolve = async (id, importer, options) => {\n        const key = id + (importer && path$o.dirname(importer));\n        if (seen.has(key)) {\n            return seen.get(key);\n        }\n        const resolved = await container.resolveId(id, importer && normalizePath$3(importer), {\n            ...options,\n            scan: true,\n        });\n        const res = resolved?.id;\n        seen.set(key, res);\n        return res;\n    };\n    const include = config.optimizeDeps?.include;\n    const exclude = [\n        ...(config.optimizeDeps?.exclude || []),\n        '@vite/client',\n        '@vite/env',\n    ];\n    const externalUnlessEntry = ({ path }) => ({\n        path,\n        external: !entries.includes(path),\n    });\n    const doTransformGlobImport = async (contents, id, loader) => {\n        let transpiledContents;\n        // transpile because `transformGlobImport` only expects js\n        if (loader !== 'js') {\n            transpiledContents = (await transform$2(contents, { loader })).code;\n        }\n        else {\n            transpiledContents = contents;\n        }\n        const result = await transformGlobImport(transpiledContents, id, config.root, resolve, config.isProduction);\n        return result?.s.toString() || transpiledContents;\n    };\n    return {\n        name: 'vite:dep-scan',\n        setup(build) {\n            const scripts = {};\n            // external urls\n            build.onResolve({ filter: externalRE }, ({ path }) => ({\n                path,\n                external: true,\n            }));\n            // data urls\n            build.onResolve({ filter: dataUrlRE }, ({ path }) => ({\n                path,\n                external: true,\n            }));\n            // local scripts (`<script>` in Svelte and `<script setup>` in Vue)\n            build.onResolve({ filter: virtualModuleRE }, ({ path }) => {\n                return {\n                    // strip prefix to get valid filesystem path so esbuild can resolve imports in the file\n                    path: path.replace(virtualModulePrefix, ''),\n                    namespace: 'script',\n                };\n            });\n            build.onLoad({ filter: /.*/, namespace: 'script' }, ({ path }) => {\n                return scripts[path];\n            });\n            // html types: extract script contents -----------------------------------\n            build.onResolve({ filter: htmlTypesRE }, async ({ path, importer }) => {\n                const resolved = await resolve(path, importer);\n                if (!resolved)\n                    return;\n                // It is possible for the scanner to scan html types in node_modules.\n                // If we can optimize this html type, skip it so it's handled by the\n                // bare import resolve, and recorded as optimization dep.\n                if (resolved.includes('node_modules') &&\n                    isOptimizable(resolved, config.optimizeDeps))\n                    return;\n                return {\n                    path: resolved,\n                    namespace: 'html',\n                };\n            });\n            // extract scripts inside HTML-like files and treat it as a js module\n            build.onLoad({ filter: htmlTypesRE, namespace: 'html' }, async ({ path }) => {\n                let raw = fs$l.readFileSync(path, 'utf-8');\n                // Avoid matching the content of the comment\n                raw = raw.replace(commentRE, '<!---->');\n                const isHtml = path.endsWith('.html');\n                const regex = isHtml ? scriptModuleRE : scriptRE;\n                regex.lastIndex = 0;\n                let js = '';\n                let scriptId = 0;\n                let match;\n                while ((match = regex.exec(raw))) {\n                    const [, openTag, content] = match;\n                    const typeMatch = openTag.match(typeRE);\n                    const type = typeMatch && (typeMatch[1] || typeMatch[2] || typeMatch[3]);\n                    const langMatch = openTag.match(langRE);\n                    const lang = langMatch && (langMatch[1] || langMatch[2] || langMatch[3]);\n                    // skip type=\"application/ld+json\" and other non-JS types\n                    if (type &&\n                        !(type.includes('javascript') ||\n                            type.includes('ecmascript') ||\n                            type === 'module')) {\n                        continue;\n                    }\n                    let loader = 'js';\n                    if (lang === 'ts' || lang === 'tsx' || lang === 'jsx') {\n                        loader = lang;\n                    }\n                    else if (path.endsWith('.astro')) {\n                        loader = 'ts';\n                    }\n                    const srcMatch = openTag.match(srcRE);\n                    if (srcMatch) {\n                        const src = srcMatch[1] || srcMatch[2] || srcMatch[3];\n                        js += `import ${JSON.stringify(src)}\\n`;\n                    }\n                    else if (content.trim()) {\n                        // The reason why virtual modules are needed:\n                        // 1. There can be module scripts (`<script context=\"module\">` in Svelte and `<script>` in Vue)\n                        // or local scripts (`<script>` in Svelte and `<script setup>` in Vue)\n                        // 2. There can be multiple module scripts in html\n                        // We need to handle these separately in case variable names are reused between them\n                        // append imports in TS to prevent esbuild from removing them\n                        // since they may be used in the template\n                        const contents = content +\n                            (loader.startsWith('ts') ? extractImportPaths(content) : '');\n                        const key = `${path}?id=${scriptId++}`;\n                        if (contents.includes('import.meta.glob')) {\n                            scripts[key] = {\n                                loader: 'js',\n                                contents: await doTransformGlobImport(contents, path, loader),\n                                pluginData: {\n                                    htmlType: { loader },\n                                },\n                            };\n                        }\n                        else {\n                            scripts[key] = {\n                                loader,\n                                contents,\n                                pluginData: {\n                                    htmlType: { loader },\n                                },\n                            };\n                        }\n                        const virtualModulePath = JSON.stringify(virtualModulePrefix + key);\n                        const contextMatch = openTag.match(contextRE);\n                        const context = contextMatch &&\n                            (contextMatch[1] || contextMatch[2] || contextMatch[3]);\n                        // Especially for Svelte files, exports in <script context=\"module\"> means module exports,\n                        // exports in <script> means component props. To avoid having two same export name from the\n                        // star exports, we need to ignore exports in <script>\n                        if (path.endsWith('.svelte') && context !== 'module') {\n                            js += `import ${virtualModulePath}\\n`;\n                        }\n                        else {\n                            js += `export * from ${virtualModulePath}\\n`;\n                        }\n                    }\n                }\n                // This will trigger incorrectly if `export default` is contained\n                // anywhere in a string. Svelte and Astro files can't have\n                // `export default` as code so we know if it's encountered it's a\n                // false positive (e.g. contained in a string)\n                if (!path.endsWith('.vue') || !js.includes('export default')) {\n                    js += '\\nexport default {}';\n                }\n                return {\n                    loader: 'js',\n                    contents: js,\n                };\n            });\n            // bare imports: record and externalize ----------------------------------\n            build.onResolve({\n                // avoid matching windows volume\n                filter: /^[\\w@][^:]/,\n            }, async ({ path: id, importer, pluginData }) => {\n                if (moduleListContains(exclude, id)) {\n                    return externalUnlessEntry({ path: id });\n                }\n                if (depImports[id]) {\n                    return externalUnlessEntry({ path: id });\n                }\n                const resolved = await resolve(id, importer, {\n                    custom: {\n                        depScan: { loader: pluginData?.htmlType?.loader },\n                    },\n                });\n                if (resolved) {\n                    if (shouldExternalizeDep(resolved, id)) {\n                        return externalUnlessEntry({ path: id });\n                    }\n                    if (resolved.includes('node_modules') || include?.includes(id)) {\n                        // dependency or forced included, externalize and stop crawling\n                        if (isOptimizable(resolved, config.optimizeDeps)) {\n                            depImports[id] = resolved;\n                        }\n                        return externalUnlessEntry({ path: id });\n                    }\n                    else if (isScannable(resolved)) {\n                        const namespace = htmlTypesRE.test(resolved) ? 'html' : undefined;\n                        // linked package, keep crawling\n                        return {\n                            path: path$o.resolve(resolved),\n                            namespace,\n                        };\n                    }\n                    else {\n                        return externalUnlessEntry({ path: id });\n                    }\n                }\n                else {\n                    missing[id] = normalizePath$3(importer);\n                }\n            });\n            // Externalized file types -----------------------------------------------\n            // these are done on raw ids using esbuild's native regex filter so it\n            // should be faster than doing it in the catch-all via js\n            // they are done after the bare import resolve because a package name\n            // may end with these extensions\n            // css\n            build.onResolve({ filter: CSS_LANGS_RE }, externalUnlessEntry);\n            // json & wasm\n            build.onResolve({ filter: /\\.(json|json5|wasm)$/ }, externalUnlessEntry);\n            // known asset types\n            build.onResolve({\n                filter: new RegExp(`\\\\.(${KNOWN_ASSET_TYPES.join('|')})$`),\n            }, externalUnlessEntry);\n            // known vite query types: ?worker, ?raw\n            build.onResolve({ filter: SPECIAL_QUERY_RE }, ({ path }) => ({\n                path,\n                external: true,\n            }));\n            // catch all -------------------------------------------------------------\n            build.onResolve({\n                filter: /.*/,\n            }, async ({ path: id, importer, pluginData }) => {\n                // use vite resolver to support urls and omitted extensions\n                const resolved = await resolve(id, importer, {\n                    custom: {\n                        depScan: { loader: pluginData?.htmlType?.loader },\n                    },\n                });\n                if (resolved) {\n                    if (shouldExternalizeDep(resolved, id) || !isScannable(resolved)) {\n                        return externalUnlessEntry({ path: id });\n                    }\n                    const namespace = htmlTypesRE.test(resolved) ? 'html' : undefined;\n                    return {\n                        path: path$o.resolve(cleanUrl(resolved)),\n                        namespace,\n                    };\n                }\n                else {\n                    // resolve failed... probably unsupported type\n                    return externalUnlessEntry({ path: id });\n                }\n            });\n            // for jsx/tsx, we need to access the content and check for\n            // presence of import.meta.glob, since it results in import relationships\n            // but isn't crawled by esbuild.\n            build.onLoad({ filter: JS_TYPES_RE }, async ({ path: id }) => {\n                let ext = path$o.extname(id).slice(1);\n                if (ext === 'mjs')\n                    ext = 'js';\n                let contents = fs$l.readFileSync(id, 'utf-8');\n                if (ext.endsWith('x') && config.esbuild && config.esbuild.jsxInject) {\n                    contents = config.esbuild.jsxInject + `\\n` + contents;\n                }\n                const loader = config.optimizeDeps?.esbuildOptions?.loader?.[`.${ext}`] ||\n                    ext;\n                if (contents.includes('import.meta.glob')) {\n                    return {\n                        loader: 'js',\n                        contents: await doTransformGlobImport(contents, id, loader),\n                    };\n                }\n                return {\n                    loader,\n                    contents,\n                };\n            });\n        },\n    };\n}\n/**\n * when using TS + (Vue + `<script setup>`) or Svelte, imports may seem\n * unused to esbuild and dropped in the build output, which prevents\n * esbuild from crawling further.\n * the solution is to add `import 'x'` for every source to force\n * esbuild to keep crawling due to potential side effects.\n */\nfunction extractImportPaths(code) {\n    // empty singleline & multiline comments to avoid matching comments\n    code = code\n        .replace(multilineCommentsRE$1, '/* */')\n        .replace(singlelineCommentsRE$1, '');\n    let js = '';\n    let m;\n    importsRE.lastIndex = 0;\n    while ((m = importsRE.exec(code)) != null) {\n        js += `\\nimport ${m[1]}`;\n    }\n    return js;\n}\nfunction shouldExternalizeDep(resolvedId, rawId) {\n    // not a valid file path\n    if (!path$o.isAbsolute(resolvedId)) {\n        return true;\n    }\n    // virtual id\n    if (resolvedId === rawId || resolvedId.includes('\\0')) {\n        return true;\n    }\n    return false;\n}\nfunction isScannable(id) {\n    return JS_TYPES_RE.test(id) || htmlTypesRE.test(id);\n}\n\nconst isDebugEnabled$1 = _debug('vite:deps').enabled;\n/**\n * The amount to wait for requests to register newly found dependencies before triggering\n * a re-bundle + page reload\n */\nconst debounceMs = 100;\nconst depsOptimizerMap = new WeakMap();\nconst devSsrDepsOptimizerMap = new WeakMap();\nfunction getDepsOptimizer(config, ssr) {\n    // Workers compilation shares the DepsOptimizer from the main build\n    const isDevSsr = ssr && config.command !== 'build';\n    return (isDevSsr ? devSsrDepsOptimizerMap : depsOptimizerMap).get(config.mainConfig || config);\n}\nasync function initDepsOptimizer(config, server) {\n    // Non Dev SSR Optimizer\n    const ssr = config.command === 'build' && !!config.build.ssr;\n    if (!getDepsOptimizer(config, ssr)) {\n        await createDepsOptimizer(config, server);\n    }\n}\nlet creatingDevSsrOptimizer;\nasync function initDevSsrDepsOptimizer(config, server) {\n    if (getDepsOptimizer(config, true)) {\n        // ssr\n        return;\n    }\n    if (creatingDevSsrOptimizer) {\n        return creatingDevSsrOptimizer;\n    }\n    creatingDevSsrOptimizer = (async function () {\n        // Important: scanning needs to be done before starting the SSR dev optimizer\n        // If ssrLoadModule is called before server.listen(), the main deps optimizer\n        // will not be yet created\n        const ssr = false;\n        if (!getDepsOptimizer(config, ssr)) {\n            await initDepsOptimizer(config, server);\n        }\n        await getDepsOptimizer(config, ssr).scanProcessing;\n        await createDevSsrDepsOptimizer(config);\n        creatingDevSsrOptimizer = undefined;\n    })();\n    return await creatingDevSsrOptimizer;\n}\nasync function createDepsOptimizer(config, server) {\n    const { logger } = config;\n    const isBuild = config.command === 'build';\n    const ssr = isBuild && !!config.build.ssr; // safe as Dev SSR don't use this optimizer\n    const sessionTimestamp = Date.now().toString();\n    const cachedMetadata = loadCachedDepOptimizationMetadata(config, ssr);\n    let handle;\n    let closed = false;\n    let metadata = cachedMetadata || initDepsOptimizerMetadata(config, ssr, sessionTimestamp);\n    const depsOptimizer = {\n        metadata,\n        registerMissingImport,\n        run: () => debouncedProcessing(0),\n        isOptimizedDepFile: (id) => isOptimizedDepFile(id, config),\n        isOptimizedDepUrl: createIsOptimizedDepUrl(config),\n        getOptimizedDepId: (depInfo) => isBuild ? depInfo.file : `${depInfo.file}?v=${depInfo.browserHash}`,\n        registerWorkersSource,\n        delayDepsOptimizerUntil,\n        resetRegisteredIds,\n        ensureFirstRun,\n        close,\n        options: getDepOptimizationConfig(config, ssr),\n    };\n    depsOptimizerMap.set(config, depsOptimizer);\n    let newDepsDiscovered = false;\n    let newDepsToLog = [];\n    let newDepsToLogHandle;\n    const logNewlyDiscoveredDeps = () => {\n        if (newDepsToLog.length) {\n            config.logger.info(picocolorsExports.green(`✨ new dependencies optimized: ${depsLogString(newDepsToLog)}`), {\n                timestamp: true,\n            });\n            newDepsToLog = [];\n        }\n    };\n    let depOptimizationProcessing = newDepOptimizationProcessing();\n    let depOptimizationProcessingQueue = [];\n    const resolveEnqueuedProcessingPromises = () => {\n        // Resolve all the processings (including the ones which were delayed)\n        for (const processing of depOptimizationProcessingQueue) {\n            processing.resolve();\n        }\n        depOptimizationProcessingQueue = [];\n    };\n    let enqueuedRerun;\n    let currentlyProcessing = false;\n    // If there wasn't a cache or it is outdated, we need to prepare a first run\n    let firstRunCalled = !!cachedMetadata;\n    let postScanOptimizationResult;\n    let optimizingNewDeps;\n    async function close() {\n        closed = true;\n        await Promise.allSettled([\n            depsOptimizer.scanProcessing,\n            postScanOptimizationResult,\n            optimizingNewDeps,\n        ]);\n    }\n    if (!cachedMetadata) {\n        // Enter processing state until crawl of static imports ends\n        currentlyProcessing = true;\n        // Initialize discovered deps with manually added optimizeDeps.include info\n        const deps = {};\n        await addManuallyIncludedOptimizeDeps(deps, config, ssr);\n        const discovered = await toDiscoveredDependencies(config, deps, ssr, sessionTimestamp);\n        for (const depInfo of Object.values(discovered)) {\n            addOptimizedDepInfo(metadata, 'discovered', {\n                ...depInfo,\n                processing: depOptimizationProcessing.promise,\n            });\n            newDepsDiscovered = true;\n        }\n        if (!isBuild) {\n            // Important, the scanner is dev only\n            depsOptimizer.scanProcessing = new Promise((resolve) => {\n                // Ensure server listen is called before the scanner\n                setTimeout(async () => {\n                    try {\n                        debuggerViteDeps(picocolorsExports.green(`scanning for dependencies...`));\n                        const deps = await discoverProjectDependencies(config);\n                        debuggerViteDeps(picocolorsExports.green(Object.keys(deps).length > 0\n                            ? `dependencies found by scanner: ${depsLogString(Object.keys(deps))}`\n                            : `no dependencies found by scanner`));\n                        // Add these dependencies to the discovered list, as these are currently\n                        // used by the preAliasPlugin to support aliased and optimized deps.\n                        // This is also used by the CJS externalization heuristics in legacy mode\n                        for (const id of Object.keys(deps)) {\n                            if (!metadata.discovered[id]) {\n                                addMissingDep(id, deps[id]);\n                            }\n                        }\n                        const knownDeps = prepareKnownDeps();\n                        // For dev, we run the scanner and the first optimization\n                        // run on the background, but we wait until crawling has ended\n                        // to decide if we send this result to the browser or we need to\n                        // do another optimize step\n                        postScanOptimizationResult = runOptimizeDeps(config, knownDeps);\n                    }\n                    catch (e) {\n                        logger.error(e.message);\n                    }\n                    finally {\n                        resolve();\n                        depsOptimizer.scanProcessing = undefined;\n                    }\n                }, 0);\n            });\n        }\n    }\n    function startNextDiscoveredBatch() {\n        newDepsDiscovered = false;\n        // Add the current depOptimizationProcessing to the queue, these\n        // promises are going to be resolved once a rerun is committed\n        depOptimizationProcessingQueue.push(depOptimizationProcessing);\n        // Create a new promise for the next rerun, discovered missing\n        // dependencies will be assigned this promise from this point\n        depOptimizationProcessing = newDepOptimizationProcessing();\n    }\n    async function optimizeNewDeps() {\n        // a successful completion of the optimizeDeps rerun will end up\n        // creating new bundled version of all current and discovered deps\n        // in the cache dir and a new metadata info object assigned\n        // to _metadata. A fullReload is only issued if the previous bundled\n        // dependencies have changed.\n        // if the rerun fails, _metadata remains untouched, current discovered\n        // deps are cleaned, and a fullReload is issued\n        // All deps, previous known and newly discovered are rebundled,\n        // respect insertion order to keep the metadata file stable\n        const knownDeps = prepareKnownDeps();\n        startNextDiscoveredBatch();\n        return await runOptimizeDeps(config, knownDeps);\n    }\n    function prepareKnownDeps() {\n        const knownDeps = {};\n        // Clone optimized info objects, fileHash, browserHash may be changed for them\n        for (const dep of Object.keys(metadata.optimized)) {\n            knownDeps[dep] = { ...metadata.optimized[dep] };\n        }\n        for (const dep of Object.keys(metadata.discovered)) {\n            // Clone the discovered info discarding its processing promise\n            const { processing, ...info } = metadata.discovered[dep];\n            knownDeps[dep] = info;\n        }\n        return knownDeps;\n    }\n    async function runOptimizer(preRunResult) {\n        const isRerun = firstRunCalled;\n        firstRunCalled = true;\n        // Ensure that rerun is called sequentially\n        enqueuedRerun = undefined;\n        // Ensure that a rerun will not be issued for current discovered deps\n        if (handle)\n            clearTimeout(handle);\n        if (closed || Object.keys(metadata.discovered).length === 0) {\n            currentlyProcessing = false;\n            return;\n        }\n        currentlyProcessing = true;\n        try {\n            const processingResult = preRunResult ?? (await (optimizingNewDeps = optimizeNewDeps()));\n            optimizingNewDeps = undefined;\n            if (closed) {\n                currentlyProcessing = false;\n                processingResult.cancel();\n                resolveEnqueuedProcessingPromises();\n                return;\n            }\n            const newData = processingResult.metadata;\n            const needsInteropMismatch = findInteropMismatches(metadata.discovered, newData.optimized);\n            // After a re-optimization, if the internal bundled chunks change a full page reload\n            // is required. If the files are stable, we can avoid the reload that is expensive\n            // for large applications. Comparing their fileHash we can find out if it is safe to\n            // keep the current browser state.\n            const needsReload = needsInteropMismatch.length > 0 ||\n                metadata.hash !== newData.hash ||\n                Object.keys(metadata.optimized).some((dep) => {\n                    return (metadata.optimized[dep].fileHash !== newData.optimized[dep].fileHash);\n                });\n            const commitProcessing = async () => {\n                await processingResult.commit();\n                // While optimizeDeps is running, new missing deps may be discovered,\n                // in which case they will keep being added to metadata.discovered\n                for (const id in metadata.discovered) {\n                    if (!newData.optimized[id]) {\n                        addOptimizedDepInfo(newData, 'discovered', metadata.discovered[id]);\n                    }\n                }\n                // If we don't reload the page, we need to keep browserHash stable\n                if (!needsReload) {\n                    newData.browserHash = metadata.browserHash;\n                    for (const dep in newData.chunks) {\n                        newData.chunks[dep].browserHash = metadata.browserHash;\n                    }\n                    for (const dep in newData.optimized) {\n                        newData.optimized[dep].browserHash = (metadata.optimized[dep] || metadata.discovered[dep]).browserHash;\n                    }\n                }\n                // Commit hash and needsInterop changes to the discovered deps info\n                // object. Allow for code to await for the discovered processing promise\n                // and use the information in the same object\n                for (const o in newData.optimized) {\n                    const discovered = metadata.discovered[o];\n                    if (discovered) {\n                        const optimized = newData.optimized[o];\n                        discovered.browserHash = optimized.browserHash;\n                        discovered.fileHash = optimized.fileHash;\n                        discovered.needsInterop = optimized.needsInterop;\n                        discovered.processing = undefined;\n                    }\n                }\n                if (isRerun) {\n                    newDepsToLog.push(...Object.keys(newData.optimized).filter((dep) => !metadata.optimized[dep]));\n                }\n                metadata = depsOptimizer.metadata = newData;\n                resolveEnqueuedProcessingPromises();\n            };\n            if (!needsReload) {\n                await commitProcessing();\n                if (!isDebugEnabled$1) {\n                    if (newDepsToLogHandle)\n                        clearTimeout(newDepsToLogHandle);\n                    newDepsToLogHandle = setTimeout(() => {\n                        newDepsToLogHandle = undefined;\n                        logNewlyDiscoveredDeps();\n                    }, 2 * debounceMs);\n                }\n                else {\n                    debuggerViteDeps(picocolorsExports.green(`✨ ${!isRerun\n                        ? `dependencies optimized`\n                        : `optimized dependencies unchanged`}`));\n                }\n            }\n            else {\n                if (newDepsDiscovered) {\n                    // There are newly discovered deps, and another rerun is about to be\n                    // executed. Avoid the current full reload discarding this rerun result\n                    // We don't resolve the processing promise, as they will be resolved\n                    // once a rerun is committed\n                    processingResult.cancel();\n                    debuggerViteDeps(picocolorsExports.green(`✨ delaying reload as new dependencies have been found...`));\n                }\n                else {\n                    await commitProcessing();\n                    if (!isDebugEnabled$1) {\n                        if (newDepsToLogHandle)\n                            clearTimeout(newDepsToLogHandle);\n                        newDepsToLogHandle = undefined;\n                        logNewlyDiscoveredDeps();\n                    }\n                    logger.info(picocolorsExports.green(`✨ optimized dependencies changed. reloading`), {\n                        timestamp: true,\n                    });\n                    if (needsInteropMismatch.length > 0) {\n                        config.logger.warn(`Mixed ESM and CJS detected in ${picocolorsExports.yellow(needsInteropMismatch.join(', '))}, add ${needsInteropMismatch.length === 1 ? 'it' : 'them'} to optimizeDeps.needsInterop to speed up cold start`, {\n                            timestamp: true,\n                        });\n                    }\n                    fullReload();\n                }\n            }\n        }\n        catch (e) {\n            logger.error(picocolorsExports.red(`error while updating dependencies:\\n${e.stack}`), { timestamp: true, error: e });\n            resolveEnqueuedProcessingPromises();\n            // Reset missing deps, let the server rediscover the dependencies\n            metadata.discovered = {};\n        }\n        currentlyProcessing = false;\n        // @ts-expect-error `enqueuedRerun` could exist because `debouncedProcessing` may run while awaited\n        enqueuedRerun?.();\n    }\n    function fullReload() {\n        if (server) {\n            // Cached transform results have stale imports (resolved to\n            // old locations) so they need to be invalidated before the page is\n            // reloaded.\n            server.moduleGraph.invalidateAll();\n            server.ws.send({\n                type: 'full-reload',\n                path: '*',\n            });\n        }\n    }\n    async function rerun() {\n        // debounce time to wait for new missing deps finished, issue a new\n        // optimization of deps (both old and newly found) once the previous\n        // optimizeDeps processing is finished\n        const deps = Object.keys(metadata.discovered);\n        const depsString = depsLogString(deps);\n        debuggerViteDeps(picocolorsExports.green(`new dependencies found: ${depsString}`));\n        runOptimizer();\n    }\n    function getDiscoveredBrowserHash(hash, deps, missing) {\n        return getHash(hash + JSON.stringify(deps) + JSON.stringify(missing) + sessionTimestamp);\n    }\n    function registerMissingImport(id, resolved) {\n        const optimized = metadata.optimized[id];\n        if (optimized) {\n            return optimized;\n        }\n        const chunk = metadata.chunks[id];\n        if (chunk) {\n            return chunk;\n        }\n        let missing = metadata.discovered[id];\n        if (missing) {\n            // We are already discover this dependency\n            // It will be processed in the next rerun call\n            return missing;\n        }\n        missing = addMissingDep(id, resolved);\n        // Until the first optimize run is called, avoid triggering processing\n        // We'll wait until the user codebase is eagerly processed by Vite so\n        // we can get a list of every missing dependency before giving to the\n        // browser a dependency that may be outdated, thus avoiding full page reloads\n        if (firstRunCalled) {\n            // Debounced rerun, let other missing dependencies be discovered before\n            // the running next optimizeDeps\n            debouncedProcessing();\n        }\n        // Return the path for the optimized bundle, this path is known before\n        // esbuild is run to generate the pre-bundle\n        return missing;\n    }\n    function addMissingDep(id, resolved) {\n        newDepsDiscovered = true;\n        return addOptimizedDepInfo(metadata, 'discovered', {\n            id,\n            file: getOptimizedDepPath(id, config, ssr),\n            src: resolved,\n            // Adding a browserHash to this missing dependency that is unique to\n            // the current state of known + missing deps. If its optimizeDeps run\n            // doesn't alter the bundled files of previous known dependencies,\n            // we don't need a full reload and this browserHash will be kept\n            browserHash: getDiscoveredBrowserHash(metadata.hash, depsFromOptimizedDepInfo(metadata.optimized), depsFromOptimizedDepInfo(metadata.discovered)),\n            // loading of this pre-bundled dep needs to await for its processing\n            // promise to be resolved\n            processing: depOptimizationProcessing.promise,\n            exportsData: extractExportsData(resolved, config, ssr),\n        });\n    }\n    function debouncedProcessing(timeout = debounceMs) {\n        if (!newDepsDiscovered) {\n            return;\n        }\n        // Debounced rerun, let other missing dependencies be discovered before\n        // the running next optimizeDeps\n        enqueuedRerun = undefined;\n        if (handle)\n            clearTimeout(handle);\n        if (newDepsToLogHandle)\n            clearTimeout(newDepsToLogHandle);\n        newDepsToLogHandle = undefined;\n        handle = setTimeout(() => {\n            handle = undefined;\n            enqueuedRerun = rerun;\n            if (!currentlyProcessing) {\n                enqueuedRerun();\n            }\n        }, timeout);\n    }\n    async function onCrawlEnd() {\n        debuggerViteDeps(picocolorsExports.green(`✨ static imports crawl ended`));\n        if (firstRunCalled) {\n            return;\n        }\n        currentlyProcessing = false;\n        const crawlDeps = Object.keys(metadata.discovered);\n        // Await for the scan+optimize step running in the background\n        // It normally should be over by the time crawling of user code ended\n        await depsOptimizer.scanProcessing;\n        if (!isBuild && postScanOptimizationResult) {\n            const result = await postScanOptimizationResult;\n            postScanOptimizationResult = undefined;\n            const scanDeps = Object.keys(result.metadata.optimized);\n            if (scanDeps.length === 0 && crawlDeps.length === 0) {\n                debuggerViteDeps(picocolorsExports.green(`✨ no dependencies found by the scanner or crawling static imports`));\n                result.cancel();\n                firstRunCalled = true;\n                return;\n            }\n            const needsInteropMismatch = findInteropMismatches(metadata.discovered, result.metadata.optimized);\n            const scannerMissedDeps = crawlDeps.some((dep) => !scanDeps.includes(dep));\n            const outdatedResult = needsInteropMismatch.length > 0 || scannerMissedDeps;\n            if (outdatedResult) {\n                // Drop this scan result, and perform a new optimization to avoid a full reload\n                result.cancel();\n                // Add deps found by the scanner to the discovered deps while crawling\n                for (const dep of scanDeps) {\n                    if (!crawlDeps.includes(dep)) {\n                        addMissingDep(dep, result.metadata.optimized[dep].src);\n                    }\n                }\n                if (scannerMissedDeps) {\n                    debuggerViteDeps(picocolorsExports.yellow(`✨ new dependencies were found while crawling that weren't detected by the scanner`));\n                }\n                debuggerViteDeps(picocolorsExports.green(`✨ re-running optimizer`));\n                debouncedProcessing(0);\n            }\n            else {\n                debuggerViteDeps(picocolorsExports.green(`✨ using post-scan optimizer result, the scanner found every used dependency`));\n                startNextDiscoveredBatch();\n                runOptimizer(result);\n            }\n        }\n        else {\n            if (crawlDeps.length === 0) {\n                debuggerViteDeps(picocolorsExports.green(`✨ no dependencies found while crawling the static imports`));\n                firstRunCalled = true;\n            }\n            else {\n                // queue the first optimizer run\n                debouncedProcessing(0);\n            }\n        }\n    }\n    const runOptimizerIfIdleAfterMs = 100;\n    let registeredIds = [];\n    let seenIds = new Set();\n    let workersSources = new Set();\n    let waitingOn;\n    let firstRunEnsured = false;\n    function resetRegisteredIds() {\n        registeredIds = [];\n        seenIds = new Set();\n        workersSources = new Set();\n        waitingOn = undefined;\n        firstRunEnsured = false;\n    }\n    // If all the inputs are dependencies, we aren't going to get any\n    // delayDepsOptimizerUntil(id) calls. We need to guard against this\n    // by forcing a rerun if no deps have been registered\n    function ensureFirstRun() {\n        if (!firstRunEnsured && !firstRunCalled && registeredIds.length === 0) {\n            setTimeout(() => {\n                if (!closed && registeredIds.length === 0) {\n                    onCrawlEnd();\n                }\n            }, runOptimizerIfIdleAfterMs);\n        }\n        firstRunEnsured = true;\n    }\n    function registerWorkersSource(id) {\n        workersSources.add(id);\n        // Avoid waiting for this id, as it may be blocked by the rollup\n        // bundling process of the worker that also depends on the optimizer\n        registeredIds = registeredIds.filter((registered) => registered.id !== id);\n        if (waitingOn === id) {\n            waitingOn = undefined;\n            runOptimizerWhenIdle();\n        }\n    }\n    function delayDepsOptimizerUntil(id, done) {\n        if (!depsOptimizer.isOptimizedDepFile(id) && !seenIds.has(id)) {\n            seenIds.add(id);\n            registeredIds.push({ id, done });\n            runOptimizerWhenIdle();\n        }\n    }\n    function runOptimizerWhenIdle() {\n        if (!waitingOn) {\n            const next = registeredIds.pop();\n            if (next) {\n                waitingOn = next.id;\n                const afterLoad = () => {\n                    waitingOn = undefined;\n                    if (!closed && !workersSources.has(next.id)) {\n                        if (registeredIds.length > 0) {\n                            runOptimizerWhenIdle();\n                        }\n                        else {\n                            onCrawlEnd();\n                        }\n                    }\n                };\n                next\n                    .done()\n                    .then(() => {\n                    setTimeout(afterLoad, registeredIds.length > 0 ? 0 : runOptimizerIfIdleAfterMs);\n                })\n                    .catch(afterLoad);\n            }\n        }\n    }\n}\nasync function createDevSsrDepsOptimizer(config) {\n    const metadata = await optimizeServerSsrDeps(config);\n    const depsOptimizer = {\n        metadata,\n        isOptimizedDepFile: (id) => isOptimizedDepFile(id, config),\n        isOptimizedDepUrl: createIsOptimizedDepUrl(config),\n        getOptimizedDepId: (depInfo) => `${depInfo.file}?v=${depInfo.browserHash}`,\n        registerMissingImport: () => {\n            throw new Error('Vite Internal Error: registerMissingImport is not supported in dev SSR');\n        },\n        // noop, there is no scanning during dev SSR\n        // the optimizer blocks the server start\n        run: () => { },\n        registerWorkersSource: (id) => { },\n        delayDepsOptimizerUntil: (id, done) => { },\n        resetRegisteredIds: () => { },\n        ensureFirstRun: () => { },\n        close: async () => { },\n        options: config.ssr.optimizeDeps,\n    };\n    devSsrDepsOptimizerMap.set(config, depsOptimizer);\n}\nfunction findInteropMismatches(discovered, optimized) {\n    const needsInteropMismatch = [];\n    for (const dep in discovered) {\n        const discoveredDepInfo = discovered[dep];\n        const depInfo = optimized[dep];\n        if (depInfo) {\n            if (discoveredDepInfo.needsInterop !== undefined &&\n                depInfo.needsInterop !== discoveredDepInfo.needsInterop) {\n                // This only happens when a discovered dependency has mixed ESM and CJS syntax\n                // and it hasn't been manually added to optimizeDeps.needsInterop\n                needsInteropMismatch.push(dep);\n                debuggerViteDeps(picocolorsExports.cyan(`✨ needsInterop mismatch detected for ${dep}`));\n            }\n        }\n    }\n    return needsInteropMismatch;\n}\n\nconst debuggerViteDeps = createDebugger('vite:deps');\nconst debug$7 = debuggerViteDeps;\nconst isDebugEnabled = _debug('vite:deps').enabled;\nconst jsExtensionRE = /\\.js$/i;\nconst jsMapExtensionRE = /\\.js\\.map$/i;\n/**\n * Scan and optimize dependencies within a project.\n * Used by Vite CLI when running `vite optimize`.\n */\nasync function optimizeDeps(config, force = config.optimizeDeps.force, asCommand = false) {\n    const log = asCommand ? config.logger.info : debug$7;\n    const ssr = config.command === 'build' && !!config.build.ssr;\n    const cachedMetadata = loadCachedDepOptimizationMetadata(config, ssr, force, asCommand);\n    if (cachedMetadata) {\n        return cachedMetadata;\n    }\n    const deps = await discoverProjectDependencies(config);\n    const depsString = depsLogString(Object.keys(deps));\n    log(picocolorsExports.green(`Optimizing dependencies:\\n  ${depsString}`));\n    await addManuallyIncludedOptimizeDeps(deps, config, ssr);\n    const depsInfo = toDiscoveredDependencies(config, deps, ssr);\n    const result = await runOptimizeDeps(config, depsInfo);\n    await result.commit();\n    return result.metadata;\n}\nasync function optimizeServerSsrDeps(config) {\n    const ssr = true;\n    const cachedMetadata = loadCachedDepOptimizationMetadata(config, ssr, config.optimizeDeps.force, false);\n    if (cachedMetadata) {\n        return cachedMetadata;\n    }\n    let alsoInclude;\n    let noExternalFilter;\n    const { exclude } = getDepOptimizationConfig(config, ssr);\n    const noExternal = config.ssr?.noExternal;\n    if (noExternal) {\n        alsoInclude = arraify(noExternal).filter((ne) => typeof ne === 'string');\n        noExternalFilter =\n            noExternal === true\n                ? (dep) => true\n                : createFilter$1(undefined, exclude, {\n                    resolve: false,\n                });\n    }\n    const deps = {};\n    await addManuallyIncludedOptimizeDeps(deps, config, ssr, alsoInclude, noExternalFilter);\n    const depsInfo = toDiscoveredDependencies(config, deps, true);\n    const result = await runOptimizeDeps(config, depsInfo, true);\n    await result.commit();\n    return result.metadata;\n}\nfunction initDepsOptimizerMetadata(config, ssr, timestamp) {\n    const hash = getDepHash(config, ssr);\n    return {\n        hash,\n        browserHash: getOptimizedBrowserHash(hash, {}, timestamp),\n        optimized: {},\n        chunks: {},\n        discovered: {},\n        depInfoList: [],\n    };\n}\nfunction addOptimizedDepInfo(metadata, type, depInfo) {\n    metadata[type][depInfo.id] = depInfo;\n    metadata.depInfoList.push(depInfo);\n    return depInfo;\n}\n/**\n * Creates the initial dep optimization metadata, loading it from the deps cache\n * if it exists and pre-bundling isn't forced\n */\nfunction loadCachedDepOptimizationMetadata(config, ssr, force = config.optimizeDeps.force, asCommand = false) {\n    const log = asCommand ? config.logger.info : debug$7;\n    // Before Vite 2.9, dependencies were cached in the root of the cacheDir\n    // For compat, we remove the cache if we find the old structure\n    if (fs$l.existsSync(path$o.join(config.cacheDir, '_metadata.json'))) {\n        emptyDir(config.cacheDir);\n    }\n    const depsCacheDir = getDepsCacheDir(config, ssr);\n    if (!force) {\n        let cachedMetadata;\n        try {\n            const cachedMetadataPath = path$o.join(depsCacheDir, '_metadata.json');\n            cachedMetadata = parseDepsOptimizerMetadata(fs$l.readFileSync(cachedMetadataPath, 'utf-8'), depsCacheDir);\n        }\n        catch (e) { }\n        // hash is consistent, no need to re-bundle\n        if (cachedMetadata && cachedMetadata.hash === getDepHash(config, ssr)) {\n            log('Hash is consistent. Skipping. Use --force to override.');\n            // Nothing to commit or cancel as we are using the cache, we only\n            // need to resolve the processing promise so requests can move on\n            return cachedMetadata;\n        }\n    }\n    else {\n        config.logger.info('Forced re-optimization of dependencies');\n    }\n    // Start with a fresh cache\n    fs$l.rmSync(depsCacheDir, { recursive: true, force: true });\n}\n/**\n * Initial optimizeDeps at server start. Perform a fast scan using esbuild to\n * find deps to pre-bundle and include user hard-coded dependencies\n */\nasync function discoverProjectDependencies(config) {\n    const { deps, missing } = await scanImports(config);\n    const missingIds = Object.keys(missing);\n    if (missingIds.length) {\n        throw new Error(`The following dependencies are imported but could not be resolved:\\n\\n  ${missingIds\n            .map((id) => `${picocolorsExports.cyan(id)} ${picocolorsExports.white(picocolorsExports.dim(`(imported by ${missing[id]})`))}`)\n            .join(`\\n  `)}\\n\\nAre they installed?`);\n    }\n    return deps;\n}\nfunction toDiscoveredDependencies(config, deps, ssr, timestamp) {\n    const browserHash = getOptimizedBrowserHash(getDepHash(config, ssr), deps, timestamp);\n    const discovered = {};\n    for (const id in deps) {\n        const src = deps[id];\n        discovered[id] = {\n            id,\n            file: getOptimizedDepPath(id, config, ssr),\n            src,\n            browserHash: browserHash,\n            exportsData: extractExportsData(src, config, ssr),\n        };\n    }\n    return discovered;\n}\nfunction depsLogString(qualifiedIds) {\n    if (isDebugEnabled) {\n        return picocolorsExports.yellow(qualifiedIds.join(`, `));\n    }\n    else {\n        const total = qualifiedIds.length;\n        const maxListed = 5;\n        const listed = Math.min(total, maxListed);\n        const extra = Math.max(0, total - maxListed);\n        return picocolorsExports.yellow(qualifiedIds.slice(0, listed).join(`, `) +\n            (extra > 0 ? `, ...and ${extra} more` : ``));\n    }\n}\n/**\n * Internally, Vite uses this function to prepare a optimizeDeps run. When Vite starts, we can get\n * the metadata and start the server without waiting for the optimizeDeps processing to be completed\n */\nasync function runOptimizeDeps(resolvedConfig, depsInfo, ssr = resolvedConfig.command === 'build' &&\n    !!resolvedConfig.build.ssr) {\n    const isBuild = resolvedConfig.command === 'build';\n    const config = {\n        ...resolvedConfig,\n        command: 'build',\n    };\n    const depsCacheDir = getDepsCacheDir(resolvedConfig, ssr);\n    const processingCacheDir = getProcessingDepsCacheDir(resolvedConfig, ssr);\n    // Create a temporal directory so we don't need to delete optimized deps\n    // until they have been processed. This also avoids leaving the deps cache\n    // directory in a corrupted state if there is an error\n    if (fs$l.existsSync(processingCacheDir)) {\n        emptyDir(processingCacheDir);\n    }\n    else {\n        fs$l.mkdirSync(processingCacheDir, { recursive: true });\n    }\n    // a hint for Node.js\n    // all files in the cache directory should be recognized as ES modules\n    writeFile(path$o.resolve(processingCacheDir, 'package.json'), JSON.stringify({ type: 'module' }));\n    const metadata = initDepsOptimizerMetadata(config, ssr);\n    metadata.browserHash = getOptimizedBrowserHash(metadata.hash, depsFromOptimizedDepInfo(depsInfo));\n    // We prebundle dependencies with esbuild and cache them, but there is no need\n    // to wait here. Code that needs to access the cached deps needs to await\n    // the optimizedDepInfo.processing promise for each dep\n    const qualifiedIds = Object.keys(depsInfo);\n    const processingResult = {\n        metadata,\n        async commit() {\n            // Write metadata file, delete `deps` folder and rename the `processing` folder to `deps`\n            // Processing is done, we can now replace the depsCacheDir with processingCacheDir\n            // Rewire the file paths from the temporal processing dir to the final deps cache dir\n            await removeDir(depsCacheDir);\n            await renameDir(processingCacheDir, depsCacheDir);\n        },\n        cancel() {\n            fs$l.rmSync(processingCacheDir, { recursive: true, force: true });\n        },\n    };\n    if (!qualifiedIds.length) {\n        return processingResult;\n    }\n    // esbuild generates nested directory output with lowest common ancestor base\n    // this is unpredictable and makes it difficult to analyze entry / output\n    // mapping. So what we do here is:\n    // 1. flatten all ids to eliminate slash\n    // 2. in the plugin, read the entry ourselves as virtual files to retain the\n    //    path.\n    const flatIdDeps = {};\n    const idToExports = {};\n    const optimizeDeps = getDepOptimizationConfig(config, ssr);\n    const { plugins: pluginsFromConfig = [], ...esbuildOptions } = optimizeDeps?.esbuildOptions ?? {};\n    for (const id in depsInfo) {\n        const src = depsInfo[id].src;\n        const exportsData = await (depsInfo[id].exportsData ??\n            extractExportsData(src, config, ssr));\n        if (exportsData.jsxLoader) {\n            // Ensure that optimization won't fail by defaulting '.js' to the JSX parser.\n            // This is useful for packages such as Gatsby.\n            esbuildOptions.loader = {\n                '.js': 'jsx',\n                ...esbuildOptions.loader,\n            };\n        }\n        const flatId = flattenId(id);\n        flatIdDeps[flatId] = src;\n        idToExports[id] = exportsData;\n    }\n    // esbuild automatically replaces process.env.NODE_ENV for platform 'browser'\n    // In lib mode, we need to keep process.env.NODE_ENV untouched, so to at build\n    // time we replace it by __vite_process_env_NODE_ENV. This placeholder will be\n    // later replaced by the define plugin\n    const define = {\n        'process.env.NODE_ENV': isBuild\n            ? '__vite_process_env_NODE_ENV'\n            : JSON.stringify(process.env.NODE_ENV || config.mode),\n    };\n    const platform = ssr && config.ssr?.target !== 'webworker' ? 'node' : 'browser';\n    const external = [...(optimizeDeps?.exclude ?? [])];\n    if (isBuild) {\n        let rollupOptionsExternal = config?.build?.rollupOptions?.external;\n        if (rollupOptionsExternal) {\n            if (typeof rollupOptionsExternal === 'string') {\n                rollupOptionsExternal = [rollupOptionsExternal];\n            }\n            // TODO: decide whether to support RegExp and function options\n            // They're not supported yet because `optimizeDeps.exclude` currently only accepts strings\n            if (!Array.isArray(rollupOptionsExternal) ||\n                rollupOptionsExternal.some((ext) => typeof ext !== 'string')) {\n                throw new Error(`[vite] 'build.rollupOptions.external' can only be an array of strings or a string when using esbuild optimization at build time.`);\n            }\n            external.push(...rollupOptionsExternal);\n        }\n    }\n    const plugins = [...pluginsFromConfig];\n    if (external.length) {\n        plugins.push(esbuildCjsExternalPlugin(external, platform));\n    }\n    plugins.push(esbuildDepPlugin(flatIdDeps, external, config, ssr));\n    const start = performance.now();\n    const result = await build$3({\n        absWorkingDir: process.cwd(),\n        entryPoints: Object.keys(flatIdDeps),\n        bundle: true,\n        // We can't use platform 'neutral', as esbuild has custom handling\n        // when the platform is 'node' or 'browser' that can't be emulated\n        // by using mainFields and conditions\n        platform,\n        define,\n        format: 'esm',\n        // See https://github.com/evanw/esbuild/issues/1921#issuecomment-1152991694\n        banner: platform === 'node'\n            ? {\n                js: `import { createRequire } from 'module';const require = createRequire(import.meta.url);`,\n            }\n            : undefined,\n        target: isBuild ? config.build.target || undefined : ESBUILD_MODULES_TARGET,\n        external,\n        logLevel: 'error',\n        splitting: true,\n        sourcemap: true,\n        outdir: processingCacheDir,\n        ignoreAnnotations: !isBuild,\n        metafile: true,\n        plugins,\n        charset: 'utf8',\n        ...esbuildOptions,\n        supported: {\n            'dynamic-import': true,\n            'import-meta': true,\n            ...esbuildOptions.supported,\n        },\n    });\n    const meta = result.metafile;\n    // the paths in `meta.outputs` are relative to `process.cwd()`\n    const processingCacheDirOutputPath = path$o.relative(process.cwd(), processingCacheDir);\n    for (const id in depsInfo) {\n        const output = esbuildOutputFromId(meta.outputs, id, processingCacheDir);\n        const { exportsData, ...info } = depsInfo[id];\n        addOptimizedDepInfo(metadata, 'optimized', {\n            ...info,\n            // We only need to hash the output.imports in to check for stability, but adding the hash\n            // and file path gives us a unique hash that may be useful for other things in the future\n            fileHash: getHash(metadata.hash + depsInfo[id].file + JSON.stringify(output.imports)),\n            browserHash: metadata.browserHash,\n            // After bundling we have more information and can warn the user about legacy packages\n            // that require manual configuration\n            needsInterop: needsInterop(config, ssr, id, idToExports[id], output),\n        });\n    }\n    for (const o of Object.keys(meta.outputs)) {\n        if (!o.match(jsMapExtensionRE)) {\n            const id = path$o\n                .relative(processingCacheDirOutputPath, o)\n                .replace(jsExtensionRE, '');\n            const file = getOptimizedDepPath(id, resolvedConfig, ssr);\n            if (!findOptimizedDepInfoInRecord(metadata.optimized, (depInfo) => depInfo.file === file)) {\n                addOptimizedDepInfo(metadata, 'chunks', {\n                    id,\n                    file,\n                    needsInterop: false,\n                    browserHash: metadata.browserHash,\n                });\n            }\n        }\n    }\n    const dataPath = path$o.join(processingCacheDir, '_metadata.json');\n    writeFile(dataPath, stringifyDepsOptimizerMetadata(metadata, depsCacheDir));\n    debug$7(`deps bundled in ${(performance.now() - start).toFixed(2)}ms`);\n    return processingResult;\n}\nasync function findKnownImports(config, ssr) {\n    const deps = (await scanImports(config)).deps;\n    await addManuallyIncludedOptimizeDeps(deps, config, ssr);\n    return Object.keys(deps);\n}\nasync function addManuallyIncludedOptimizeDeps(deps, config, ssr, extra = [], filter) {\n    const { logger } = config;\n    const optimizeDeps = getDepOptimizationConfig(config, ssr);\n    const optimizeDepsInclude = optimizeDeps?.include ?? [];\n    if (optimizeDepsInclude.length || extra.length) {\n        const unableToOptimize = (id, msg) => {\n            if (optimizeDepsInclude.includes(id)) {\n                logger.warn(`${msg}: ${picocolorsExports.cyan(id)}, present in '${ssr ? 'ssr.' : ''}optimizeDeps.include'`);\n            }\n        };\n        const resolve = config.createResolver({\n            asSrc: false,\n            scan: true,\n            ssrOptimizeCheck: ssr,\n            ssrConfig: config.ssr,\n        });\n        for (const id of [...optimizeDepsInclude, ...extra]) {\n            // normalize 'foo   >bar` as 'foo > bar' to prevent same id being added\n            // and for pretty printing\n            const normalizedId = normalizeId(id);\n            if (!deps[normalizedId] && filter?.(normalizedId) !== false) {\n                const entry = await resolve(id, undefined, undefined, ssr);\n                if (entry) {\n                    if (isOptimizable(entry, optimizeDeps)) {\n                        if (!entry.endsWith('?__vite_skip_optimization')) {\n                            deps[normalizedId] = entry;\n                        }\n                    }\n                    else {\n                        unableToOptimize(entry, 'Cannot optimize dependency');\n                    }\n                }\n                else {\n                    unableToOptimize(id, 'Failed to resolve dependency');\n                }\n            }\n        }\n    }\n}\nfunction newDepOptimizationProcessing() {\n    let resolve;\n    const promise = new Promise((_resolve) => {\n        resolve = _resolve;\n    });\n    return { promise, resolve: resolve };\n}\n// Convert to { id: src }\nfunction depsFromOptimizedDepInfo(depsInfo) {\n    return Object.fromEntries(Object.entries(depsInfo).map((d) => [d[0], d[1].src]));\n}\nfunction getOptimizedDepPath(id, config, ssr) {\n    return normalizePath$3(path$o.resolve(getDepsCacheDir(config, ssr), flattenId(id) + '.js'));\n}\nfunction getDepsCacheSuffix(config, ssr) {\n    let suffix = '';\n    if (config.command === 'build') {\n        // Differentiate build caches depending on outDir to allow parallel builds\n        const { outDir } = config.build;\n        const buildId = outDir.length > 8 || outDir.includes('/') ? getHash(outDir) : outDir;\n        suffix += `_build-${buildId}`;\n    }\n    if (ssr) {\n        suffix += '_ssr';\n    }\n    return suffix;\n}\nfunction getDepsCacheDir(config, ssr) {\n    return getDepsCacheDirPrefix(config) + getDepsCacheSuffix(config, ssr);\n}\nfunction getProcessingDepsCacheDir(config, ssr) {\n    return (getDepsCacheDirPrefix(config) + getDepsCacheSuffix(config, ssr) + '_temp');\n}\nfunction getDepsCacheDirPrefix(config) {\n    return normalizePath$3(path$o.resolve(config.cacheDir, 'deps'));\n}\nfunction isOptimizedDepFile(id, config) {\n    return id.startsWith(getDepsCacheDirPrefix(config));\n}\nfunction createIsOptimizedDepUrl(config) {\n    const { root } = config;\n    const depsCacheDir = getDepsCacheDirPrefix(config);\n    // determine the url prefix of files inside cache directory\n    const depsCacheDirRelative = normalizePath$3(path$o.relative(root, depsCacheDir));\n    const depsCacheDirPrefix = depsCacheDirRelative.startsWith('../')\n        ? // if the cache directory is outside root, the url prefix would be something\n            // like '/@fs/absolute/path/to/node_modules/.vite'\n            `/@fs/${normalizePath$3(depsCacheDir).replace(/^\\//, '')}`\n        : // if the cache directory is inside root, the url prefix would be something\n            // like '/node_modules/.vite'\n            `/${depsCacheDirRelative}`;\n    return function isOptimizedDepUrl(url) {\n        return url.startsWith(depsCacheDirPrefix);\n    };\n}\nfunction parseDepsOptimizerMetadata(jsonMetadata, depsCacheDir) {\n    const { hash, browserHash, optimized, chunks } = JSON.parse(jsonMetadata, (key, value) => {\n        // Paths can be absolute or relative to the deps cache dir where\n        // the _metadata.json is located\n        if (key === 'file' || key === 'src') {\n            return normalizePath$3(path$o.resolve(depsCacheDir, value));\n        }\n        return value;\n    });\n    if (!chunks ||\n        Object.values(optimized).some((depInfo) => !depInfo.fileHash)) {\n        // outdated _metadata.json version, ignore\n        return;\n    }\n    const metadata = {\n        hash,\n        browserHash,\n        optimized: {},\n        discovered: {},\n        chunks: {},\n        depInfoList: [],\n    };\n    for (const id of Object.keys(optimized)) {\n        addOptimizedDepInfo(metadata, 'optimized', {\n            ...optimized[id],\n            id,\n            browserHash,\n        });\n    }\n    for (const id of Object.keys(chunks)) {\n        addOptimizedDepInfo(metadata, 'chunks', {\n            ...chunks[id],\n            id,\n            browserHash,\n            needsInterop: false,\n        });\n    }\n    return metadata;\n}\n/**\n * Stringify metadata for deps cache. Remove processing promises\n * and individual dep info browserHash. Once the cache is reload\n * the next time the server start we need to use the global\n * browserHash to allow long term caching\n */\nfunction stringifyDepsOptimizerMetadata(metadata, depsCacheDir) {\n    const { hash, browserHash, optimized, chunks } = metadata;\n    return JSON.stringify({\n        hash,\n        browserHash,\n        optimized: Object.fromEntries(Object.values(optimized).map(({ id, src, file, fileHash, needsInterop }) => [\n            id,\n            {\n                src,\n                file,\n                fileHash,\n                needsInterop,\n            },\n        ])),\n        chunks: Object.fromEntries(Object.values(chunks).map(({ id, file }) => [id, { file }])),\n    }, (key, value) => {\n        // Paths can be absolute or relative to the deps cache dir where\n        // the _metadata.json is located\n        if (key === 'file' || key === 'src') {\n            return normalizePath$3(path$o.relative(depsCacheDir, value));\n        }\n        return value;\n    }, 2);\n}\nfunction esbuildOutputFromId(outputs, id, cacheDirOutputPath) {\n    const cwd = process.cwd();\n    const flatId = flattenId(id) + '.js';\n    const normalizedOutputPath = normalizePath$3(path$o.relative(cwd, path$o.join(cacheDirOutputPath, flatId)));\n    const output = outputs[normalizedOutputPath];\n    if (output) {\n        return output;\n    }\n    // If the root dir was symlinked, esbuild could return output keys as `../cwd/`\n    // Normalize keys to support this case too\n    for (const [key, value] of Object.entries(outputs)) {\n        if (normalizePath$3(path$o.relative(cwd, key)) === normalizedOutputPath) {\n            return value;\n        }\n    }\n}\nasync function extractExportsData(filePath, config, ssr) {\n    await init;\n    const optimizeDeps = getDepOptimizationConfig(config, ssr);\n    const esbuildOptions = optimizeDeps?.esbuildOptions ?? {};\n    if (optimizeDeps.extensions?.some((ext) => filePath.endsWith(ext))) {\n        // For custom supported extensions, build the entry file to transform it into JS,\n        // and then parse with es-module-lexer. Note that the `bundle` option is not `true`,\n        // so only the entry file is being transformed.\n        const result = await build$3({\n            ...esbuildOptions,\n            entryPoints: [filePath],\n            write: false,\n            format: 'esm',\n        });\n        const [imports, exports, facade] = parse$e(result.outputFiles[0].text);\n        return {\n            hasImports: imports.length > 0,\n            exports: exports.map((e) => e.n),\n            facade,\n        };\n    }\n    let parseResult;\n    let usedJsxLoader = false;\n    const entryContent = fs$l.readFileSync(filePath, 'utf-8');\n    try {\n        parseResult = parse$e(entryContent);\n    }\n    catch {\n        const loader = esbuildOptions.loader?.[path$o.extname(filePath)] || 'jsx';\n        debug$7(`Unable to parse: ${filePath}.\\n Trying again with a ${loader} transform.`);\n        const transformed = await transformWithEsbuild(entryContent, filePath, {\n            loader,\n        });\n        // Ensure that optimization won't fail by defaulting '.js' to the JSX parser.\n        // This is useful for packages such as Gatsby.\n        esbuildOptions.loader = {\n            '.js': 'jsx',\n            ...esbuildOptions.loader,\n        };\n        parseResult = parse$e(transformed.code);\n        usedJsxLoader = true;\n    }\n    const [imports, exports, facade] = parseResult;\n    const exportsData = {\n        hasImports: imports.length > 0,\n        exports: exports.map((e) => e.n),\n        facade,\n        hasReExports: imports.some(({ ss, se }) => {\n            const exp = entryContent.slice(ss, se);\n            return /export\\s+\\*\\s+from/.test(exp);\n        }),\n        jsxLoader: usedJsxLoader,\n    };\n    return exportsData;\n}\nfunction needsInterop(config, ssr, id, exportsData, output) {\n    if (getDepOptimizationConfig(config, ssr)?.needsInterop?.includes(id)) {\n        return true;\n    }\n    const { hasImports, exports } = exportsData;\n    // entry has no ESM syntax - likely CJS or UMD\n    if (!exports.length && !hasImports) {\n        return true;\n    }\n    if (output) {\n        // if a peer dependency used require() on an ESM dependency, esbuild turns the\n        // ESM dependency's entry chunk into a single default export... detect\n        // such cases by checking exports mismatch, and force interop.\n        const generatedExports = output.exports;\n        if (!generatedExports ||\n            (isSingleDefaultExport(generatedExports) &&\n                !isSingleDefaultExport(exports))) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction isSingleDefaultExport(exports) {\n    return exports.length === 1 && exports[0] === 'default';\n}\nconst lockfileFormats = [\n    { name: 'package-lock.json', checkPatches: true },\n    { name: 'yarn.lock', checkPatches: true },\n    { name: 'pnpm-lock.yaml', checkPatches: false },\n    { name: 'bun.lockb', checkPatches: true },\n];\nfunction getDepHash(config, ssr) {\n    const lockfilePath = lookupFile(config.root, lockfileFormats.map((l) => l.name), { pathOnly: true });\n    let content = lockfilePath ? fs$l.readFileSync(lockfilePath, 'utf-8') : '';\n    if (lockfilePath) {\n        const lockfileName = path$o.basename(lockfilePath);\n        const { checkPatches } = lockfileFormats.find((f) => f.name === lockfileName);\n        if (checkPatches) {\n            // Default of https://github.com/ds300/patch-package\n            const fullPath = path$o.join(path$o.dirname(lockfilePath), 'patches');\n            if (fs$l.existsSync(fullPath)) {\n                const stats = fs$l.statSync(fullPath);\n                if (stats.isDirectory()) {\n                    content += stats.mtimeMs.toString();\n                }\n            }\n        }\n    }\n    // also take config into account\n    // only a subset of config options that can affect dep optimization\n    const optimizeDeps = getDepOptimizationConfig(config, ssr);\n    content += JSON.stringify({\n        mode: process.env.NODE_ENV || config.mode,\n        root: config.root,\n        resolve: config.resolve,\n        buildTarget: config.build.target,\n        assetsInclude: config.assetsInclude,\n        plugins: config.plugins.map((p) => p.name),\n        optimizeDeps: {\n            include: optimizeDeps?.include,\n            exclude: optimizeDeps?.exclude,\n            esbuildOptions: {\n                ...optimizeDeps?.esbuildOptions,\n                plugins: optimizeDeps?.esbuildOptions?.plugins?.map((p) => p.name),\n            },\n        },\n    }, (_, value) => {\n        if (typeof value === 'function' || value instanceof RegExp) {\n            return value.toString();\n        }\n        return value;\n    });\n    return getHash(content);\n}\nfunction getOptimizedBrowserHash(hash, deps, timestamp = '') {\n    return getHash(hash + JSON.stringify(deps) + timestamp);\n}\nfunction optimizedDepInfoFromId(metadata, id) {\n    return (metadata.optimized[id] || metadata.discovered[id] || metadata.chunks[id]);\n}\nfunction optimizedDepInfoFromFile(metadata, file) {\n    return metadata.depInfoList.find((depInfo) => depInfo.file === file);\n}\nfunction findOptimizedDepInfoInRecord(dependenciesInfo, callbackFn) {\n    for (const o of Object.keys(dependenciesInfo)) {\n        const info = dependenciesInfo[o];\n        if (callbackFn(info, o)) {\n            return info;\n        }\n    }\n}\nasync function optimizedDepNeedsInterop(metadata, file, config, ssr) {\n    const depInfo = optimizedDepInfoFromFile(metadata, file);\n    if (depInfo?.src && depInfo.needsInterop === undefined) {\n        depInfo.exportsData ?? (depInfo.exportsData = extractExportsData(depInfo.src, config, ssr));\n        depInfo.needsInterop = needsInterop(config, ssr, depInfo.id, await depInfo.exportsData);\n    }\n    return depInfo?.needsInterop;\n}\n\nvar index$1 = {\n  __proto__: null,\n  addManuallyIncludedOptimizeDeps: addManuallyIncludedOptimizeDeps,\n  addOptimizedDepInfo: addOptimizedDepInfo,\n  createIsOptimizedDepUrl: createIsOptimizedDepUrl,\n  debuggerViteDeps: debuggerViteDeps,\n  depsFromOptimizedDepInfo: depsFromOptimizedDepInfo,\n  depsLogString: depsLogString,\n  discoverProjectDependencies: discoverProjectDependencies,\n  extractExportsData: extractExportsData,\n  findKnownImports: findKnownImports,\n  getDepHash: getDepHash,\n  getDepsCacheDir: getDepsCacheDir,\n  getDepsCacheDirPrefix: getDepsCacheDirPrefix,\n  getDepsOptimizer: getDepsOptimizer,\n  getOptimizedDepPath: getOptimizedDepPath,\n  initDepsOptimizer: initDepsOptimizer,\n  initDepsOptimizerMetadata: initDepsOptimizerMetadata,\n  initDevSsrDepsOptimizer: initDevSsrDepsOptimizer,\n  isOptimizedDepFile: isOptimizedDepFile,\n  loadCachedDepOptimizationMetadata: loadCachedDepOptimizationMetadata,\n  newDepOptimizationProcessing: newDepOptimizationProcessing,\n  optimizeDeps: optimizeDeps,\n  optimizeServerSsrDeps: optimizeServerSsrDeps,\n  optimizedDepInfoFromFile: optimizedDepInfoFromFile,\n  optimizedDepInfoFromId: optimizedDepInfoFromId,\n  optimizedDepNeedsInterop: optimizedDepNeedsInterop,\n  runOptimizeDeps: runOptimizeDeps,\n  toDiscoveredDependencies: toDiscoveredDependencies\n};\n\n/**\n * A flag for injected helpers. This flag will be set to `false` if the output\n * target is not native es - so that injected helper logic can be conditionally\n * dropped.\n */\nconst isModernFlag = `__VITE_IS_MODERN__`;\nconst preloadMethod = `__vitePreload`;\nconst preloadMarker = `__VITE_PRELOAD__`;\nconst preloadHelperId = '\\0vite/preload-helper';\nconst preloadMarkerWithQuote = `\"${preloadMarker}\"`;\nconst dynamicImportPrefixRE = /import\\s*\\(/;\n// TODO: abstract\nconst optimizedDepChunkRE = /\\/chunk-[A-Z\\d]{8}\\.js/;\nconst optimizedDepDynamicRE = /-[A-Z\\d]{8}\\.js/;\nfunction toRelativePath(filename, importer) {\n    const relPath = path$o.relative(path$o.dirname(importer), filename);\n    return relPath.startsWith('.') ? relPath : `./${relPath}`;\n}\n/**\n * Helper for preloading CSS and direct imports of async chunks in parallel to\n * the async chunk itself.\n */\nfunction detectScriptRel() {\n    const relList = document.createElement('link').relList;\n    return relList && relList.supports && relList.supports('modulepreload')\n        ? 'modulepreload'\n        : 'preload';\n}\nfunction preload(baseModule, deps, importerUrl) {\n    // @ts-expect-error __VITE_IS_MODERN__ will be replaced with boolean later\n    if (!__VITE_IS_MODERN__ || !deps || deps.length === 0) {\n        return baseModule();\n    }\n    const links = document.getElementsByTagName('link');\n    return Promise.all(deps.map((dep) => {\n        // @ts-expect-error assetsURL is declared before preload.toString()\n        dep = assetsURL(dep, importerUrl);\n        if (dep in seen)\n            return;\n        seen[dep] = true;\n        const isCss = dep.endsWith('.css');\n        const cssSelector = isCss ? '[rel=\"stylesheet\"]' : '';\n        const isBaseRelative = !!importerUrl;\n        // check if the file is already preloaded by SSR markup\n        if (isBaseRelative) {\n            // When isBaseRelative is true then we have `importerUrl` and `dep` is\n            // already converted to an absolute URL by the `assetsURL` function\n            for (let i = links.length - 1; i >= 0; i--) {\n                const link = links[i];\n                // The `links[i].href` is an absolute URL thanks to browser doing the work\n                // for us. See https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#reflecting-content-attributes-in-idl-attributes:idl-domstring-5\n                if (link.href === dep && (!isCss || link.rel === 'stylesheet')) {\n                    return;\n                }\n            }\n        }\n        else if (document.querySelector(`link[href=\"${dep}\"]${cssSelector}`)) {\n            return;\n        }\n        const link = document.createElement('link');\n        link.rel = isCss ? 'stylesheet' : scriptRel;\n        if (!isCss) {\n            link.as = 'script';\n            link.crossOrigin = '';\n        }\n        link.href = dep;\n        document.head.appendChild(link);\n        if (isCss) {\n            return new Promise((res, rej) => {\n                link.addEventListener('load', res);\n                link.addEventListener('error', () => rej(new Error(`Unable to preload CSS for ${dep}`)));\n            });\n        }\n    })).then(() => baseModule());\n}\n/**\n * Build only. During serve this is performed as part of ./importAnalysis.\n */\nfunction buildImportAnalysisPlugin(config) {\n    const ssr = !!config.build.ssr;\n    const isWorker = config.isWorker;\n    const insertPreload = !(ssr ||\n        !!config.build.lib ||\n        isWorker ||\n        config.build.modulePreload === false);\n    const resolveModulePreloadDependencies = config.build.modulePreload && config.build.modulePreload.resolveDependencies;\n    const renderBuiltUrl = config.experimental.renderBuiltUrl;\n    const customModulePreloadPaths = !!(resolveModulePreloadDependencies || renderBuiltUrl);\n    const isRelativeBase = config.base === './' || config.base === '';\n    const optimizeModulePreloadRelativePaths = isRelativeBase && !customModulePreloadPaths;\n    const { modulePreload } = config.build;\n    const scriptRel = modulePreload && modulePreload.polyfill\n        ? `'modulepreload'`\n        : `(${detectScriptRel.toString()})()`;\n    // There are three different cases for the preload list format in __vitePreload\n    //\n    // __vitePreload(() => import(asyncChunk), [ ...deps... ])\n    //\n    // This is maintained to keep backwards compatibility as some users developed plugins\n    // using regex over this list to workaround the fact that module preload wasn't\n    // configurable.\n    const assetsURL = customModulePreloadPaths\n        ? // If `experimental.renderBuiltUrl` or `build.modulePreload.resolveDependencies` are used\n            // the dependencies are already resolved. To avoid the need for `new URL(dep, import.meta.url)`\n            // a helper `__vitePreloadRelativeDep` is used to resolve from relative paths which can be minimized.\n            `function(dep, importerUrl) { return dep.startsWith('.') ? new URL(dep, importerUrl).href : dep }`\n        : optimizeModulePreloadRelativePaths\n            ? // If there isn't custom resolvers affecting the deps list, deps in the list are relative\n                // to the current chunk and are resolved to absolute URL by the __vitePreload helper itself.\n                // The importerUrl is passed as third parameter to __vitePreload in this case\n                `function(dep, importerUrl) { return new URL(dep, importerUrl).href }`\n            : // If the base isn't relative, then the deps are relative to the projects `outDir` and the base\n                // is appended inside __vitePreload too.\n                `function(dep) { return ${JSON.stringify(config.base)}+dep }`;\n    const preloadCode = `const scriptRel = ${scriptRel};const assetsURL = ${assetsURL};const seen = {};export const ${preloadMethod} = ${preload.toString()}`;\n    return {\n        name: 'vite:build-import-analysis',\n        resolveId(id) {\n            if (id === preloadHelperId) {\n                return id;\n            }\n        },\n        load(id) {\n            if (id === preloadHelperId) {\n                return preloadCode;\n            }\n        },\n        async transform(source, importer) {\n            if (importer.includes('node_modules') &&\n                !dynamicImportPrefixRE.test(source)) {\n                return;\n            }\n            await init;\n            let imports = [];\n            try {\n                imports = parse$e(source)[0];\n            }\n            catch (e) {\n                this.error(e, e.idx);\n            }\n            if (!imports.length) {\n                return null;\n            }\n            const { root } = config;\n            const depsOptimizer = getDepsOptimizer(config, ssr);\n            const normalizeUrl = async (url, pos) => {\n                let importerFile = importer;\n                const optimizeDeps = getDepOptimizationConfig(config, ssr);\n                if (moduleListContains(optimizeDeps?.exclude, url)) {\n                    if (depsOptimizer) {\n                        await depsOptimizer.scanProcessing;\n                        // if the dependency encountered in the optimized file was excluded from the optimization\n                        // the dependency needs to be resolved starting from the original source location of the optimized file\n                        // because starting from node_modules/.vite will not find the dependency if it was not hoisted\n                        // (that is, if it is under node_modules directory in the package source of the optimized file)\n                        for (const optimizedModule of depsOptimizer.metadata.depInfoList) {\n                            if (!optimizedModule.src)\n                                continue; // Ignore chunks\n                            if (optimizedModule.file === importer) {\n                                importerFile = optimizedModule.src;\n                            }\n                        }\n                    }\n                }\n                const resolved = await this.resolve(url, importerFile);\n                if (!resolved) {\n                    // in ssr, we should let node handle the missing modules\n                    if (ssr) {\n                        return [url, url];\n                    }\n                    return this.error(`Failed to resolve import \"${url}\" from \"${path$o.relative(process.cwd(), importerFile)}\". Does the file exist?`, pos);\n                }\n                // normalize all imports into resolved URLs\n                // e.g. `import 'foo'` -> `import '/@fs/.../node_modules/foo/index.js'`\n                if (resolved.id.startsWith(root + '/')) {\n                    // in root: infer short absolute path from root\n                    url = resolved.id.slice(root.length);\n                }\n                else {\n                    url = resolved.id;\n                }\n                if (isExternalUrl(url)) {\n                    return [url, url];\n                }\n                return [url, resolved.id];\n            };\n            let s;\n            const str = () => s || (s = new MagicString(source));\n            let needPreloadHelper = false;\n            for (let index = 0; index < imports.length; index++) {\n                const { s: start, e: end, ss: expStart, se: expEnd, n: specifier, d: dynamicIndex, a: assertIndex, } = imports[index];\n                const isDynamicImport = dynamicIndex > -1;\n                // strip import assertions as we can process them ourselves\n                if (!isDynamicImport && assertIndex > -1) {\n                    str().remove(end + 1, expEnd);\n                }\n                if (isDynamicImport && insertPreload) {\n                    needPreloadHelper = true;\n                    str().prependLeft(expStart, `${preloadMethod}(() => `);\n                    str().appendRight(expEnd, `,${isModernFlag}?\"${preloadMarker}\":void 0${optimizeModulePreloadRelativePaths || customModulePreloadPaths\n                        ? ',import.meta.url'\n                        : ''})`);\n                }\n                // static import or valid string in dynamic import\n                // If resolvable, let's resolve it\n                if (depsOptimizer && specifier) {\n                    // skip external / data uri\n                    if (isExternalUrl(specifier) || isDataUrl(specifier)) {\n                        continue;\n                    }\n                    // normalize\n                    const [url, resolvedId] = await normalizeUrl(specifier, start);\n                    if (url !== specifier) {\n                        if (depsOptimizer.isOptimizedDepFile(resolvedId) &&\n                            !resolvedId.match(optimizedDepChunkRE)) {\n                            const file = cleanUrl(resolvedId); // Remove ?v={hash}\n                            const needsInterop = await optimizedDepNeedsInterop(depsOptimizer.metadata, file, config, ssr);\n                            let rewriteDone = false;\n                            if (needsInterop === undefined) {\n                                // Non-entry dynamic imports from dependencies will reach here as there isn't\n                                // optimize info for them, but they don't need es interop. If the request isn't\n                                // a dynamic import, then it is an internal Vite error\n                                if (!file.match(optimizedDepDynamicRE)) {\n                                    config.logger.error(picocolorsExports.red(`Vite Error, ${url} optimized info should be defined`));\n                                }\n                            }\n                            else if (needsInterop) {\n                                // config.logger.info(`${url} needs interop`)\n                                interopNamedImports(str(), imports[index], url, index);\n                                rewriteDone = true;\n                            }\n                            if (!rewriteDone) {\n                                let rewrittenUrl = JSON.stringify(file);\n                                if (!isDynamicImport)\n                                    rewrittenUrl = rewrittenUrl.slice(1, -1);\n                                str().update(start, end, rewrittenUrl);\n                            }\n                        }\n                    }\n                }\n                // Differentiate CSS imports that use the default export from those that\n                // do not by injecting a ?used query - this allows us to avoid including\n                // the CSS string when unnecessary (esbuild has trouble tree-shaking\n                // them)\n                if (specifier &&\n                    isCSSRequest(specifier) &&\n                    // always inject ?used query when it is a dynamic import\n                    // because there is no way to check whether the default export is used\n                    (source.slice(expStart, start).includes('from') || isDynamicImport) &&\n                    // already has ?used query (by import.meta.glob)\n                    !specifier.match(/\\?used(&|$)/) &&\n                    // edge case for package names ending with .css (e.g normalize.css)\n                    !(bareImportRE.test(specifier) && !specifier.includes('/'))) {\n                    const url = specifier.replace(/\\?|$/, (m) => `?used${m ? '&' : ''}`);\n                    str().update(start, end, isDynamicImport ? `'${url}'` : url);\n                }\n            }\n            if (needPreloadHelper &&\n                insertPreload &&\n                !source.includes(`const ${preloadMethod} =`)) {\n                str().prepend(`import { ${preloadMethod} } from \"${preloadHelperId}\";`);\n            }\n            if (s) {\n                return {\n                    code: s.toString(),\n                    map: config.build.sourcemap ? s.generateMap({ hires: true }) : null,\n                };\n            }\n        },\n        renderChunk(code, _, { format }) {\n            // make sure we only perform the preload logic in modern builds.\n            if (code.indexOf(isModernFlag) > -1) {\n                const re = new RegExp(isModernFlag, 'g');\n                const isModern = String(format === 'es');\n                if (config.build.sourcemap) {\n                    const s = new MagicString(code);\n                    let match;\n                    while ((match = re.exec(code))) {\n                        s.update(match.index, match.index + isModernFlag.length, isModern);\n                    }\n                    return {\n                        code: s.toString(),\n                        map: s.generateMap({ hires: true }),\n                    };\n                }\n                else {\n                    return code.replace(re, isModern);\n                }\n            }\n            return null;\n        },\n        generateBundle({ format }, bundle) {\n            if (format !== 'es' ||\n                ssr ||\n                isWorker ||\n                config.build.modulePreload === false) {\n                return;\n            }\n            for (const file in bundle) {\n                const chunk = bundle[file];\n                // can't use chunk.dynamicImports.length here since some modules e.g.\n                // dynamic import to constant json may get inlined.\n                if (chunk.type === 'chunk' && chunk.code.indexOf(preloadMarker) > -1) {\n                    const code = chunk.code;\n                    let imports;\n                    try {\n                        imports = parse$e(code)[0].filter((i) => i.d > -1);\n                    }\n                    catch (e) {\n                        this.error(e, e.idx);\n                    }\n                    const s = new MagicString(code);\n                    const rewroteMarkerStartPos = new Set(); // position of the leading double quote\n                    if (imports.length) {\n                        for (let index = 0; index < imports.length; index++) {\n                            // To handle escape sequences in specifier strings, the .n field will be provided where possible.\n                            const { n: name, s: start, e: end, ss: expStart, se: expEnd, } = imports[index];\n                            // check the chunk being imported\n                            let url = name;\n                            if (!url) {\n                                const rawUrl = code.slice(start, end);\n                                if (rawUrl[0] === `\"` && rawUrl[rawUrl.length - 1] === `\"`)\n                                    url = rawUrl.slice(1, -1);\n                            }\n                            const deps = new Set();\n                            let hasRemovedPureCssChunk = false;\n                            let normalizedFile = undefined;\n                            if (url) {\n                                normalizedFile = path$o.posix.join(path$o.posix.dirname(chunk.fileName), url);\n                                const ownerFilename = chunk.fileName;\n                                // literal import - trace direct imports and add to deps\n                                const analyzed = new Set();\n                                const addDeps = (filename) => {\n                                    if (filename === ownerFilename)\n                                        return;\n                                    if (analyzed.has(filename))\n                                        return;\n                                    analyzed.add(filename);\n                                    const chunk = bundle[filename];\n                                    if (chunk) {\n                                        deps.add(chunk.fileName);\n                                        chunk.imports.forEach(addDeps);\n                                        // Ensure that the css imported by current chunk is loaded after the dependencies.\n                                        // So the style of current chunk won't be overwritten unexpectedly.\n                                        chunk.viteMetadata.importedCss.forEach((file) => {\n                                            deps.add(file);\n                                        });\n                                    }\n                                    else {\n                                        const removedPureCssFiles = removedPureCssFilesCache.get(config);\n                                        const chunk = removedPureCssFiles.get(filename);\n                                        if (chunk) {\n                                            if (chunk.viteMetadata.importedCss.size) {\n                                                chunk.viteMetadata.importedCss.forEach((file) => {\n                                                    deps.add(file);\n                                                });\n                                                hasRemovedPureCssChunk = true;\n                                            }\n                                            s.update(expStart, expEnd, 'Promise.resolve({})');\n                                        }\n                                    }\n                                };\n                                addDeps(normalizedFile);\n                            }\n                            let markerStartPos = code.indexOf(preloadMarkerWithQuote, end);\n                            // fix issue #3051\n                            if (markerStartPos === -1 && imports.length === 1) {\n                                markerStartPos = code.indexOf(preloadMarkerWithQuote);\n                            }\n                            if (markerStartPos > 0) {\n                                // the dep list includes the main chunk, so only need to reload when there are actual other deps.\n                                const depsArray = deps.size > 1 ||\n                                    // main chunk is removed\n                                    (hasRemovedPureCssChunk && deps.size > 0)\n                                    ? [...deps]\n                                    : [];\n                                let renderedDeps;\n                                if (normalizedFile && customModulePreloadPaths) {\n                                    const { modulePreload } = config.build;\n                                    const resolveDependencies = modulePreload && modulePreload.resolveDependencies;\n                                    let resolvedDeps;\n                                    if (resolveDependencies) {\n                                        // We can't let the user remove css deps as these aren't really preloads, they are just using\n                                        // the same mechanism as module preloads for this chunk\n                                        const cssDeps = [];\n                                        const otherDeps = [];\n                                        for (const dep of depsArray) {\n                                            (dep.endsWith('.css') ? cssDeps : otherDeps).push(dep);\n                                        }\n                                        resolvedDeps = [\n                                            ...resolveDependencies(normalizedFile, otherDeps, {\n                                                hostId: file,\n                                                hostType: 'js',\n                                            }),\n                                            ...cssDeps,\n                                        ];\n                                    }\n                                    else {\n                                        resolvedDeps = depsArray;\n                                    }\n                                    renderedDeps = resolvedDeps.map((dep) => {\n                                        const replacement = toOutputFilePathInJS(dep, 'asset', chunk.fileName, 'js', config, toRelativePath);\n                                        const replacementString = typeof replacement === 'string'\n                                            ? JSON.stringify(replacement)\n                                            : replacement.runtime;\n                                        return replacementString;\n                                    });\n                                }\n                                else {\n                                    renderedDeps = depsArray.map((d) => \n                                    // Don't include the assets dir if the default asset file names\n                                    // are used, the path will be reconstructed by the import preload helper\n                                    JSON.stringify(optimizeModulePreloadRelativePaths\n                                        ? toRelativePath(d, file)\n                                        : d));\n                                }\n                                s.update(markerStartPos, markerStartPos + preloadMarkerWithQuote.length, `[${renderedDeps.join(',')}]`);\n                                rewroteMarkerStartPos.add(markerStartPos);\n                            }\n                        }\n                    }\n                    // there may still be markers due to inlined dynamic imports, remove\n                    // all the markers regardless\n                    let markerStartPos = code.indexOf(preloadMarkerWithQuote);\n                    while (markerStartPos >= 0) {\n                        if (!rewroteMarkerStartPos.has(markerStartPos)) {\n                            s.update(markerStartPos, markerStartPos + preloadMarkerWithQuote.length, 'void 0');\n                        }\n                        markerStartPos = code.indexOf(preloadMarkerWithQuote, markerStartPos + preloadMarkerWithQuote.length);\n                    }\n                    if (s.hasChanged()) {\n                        chunk.code = s.toString();\n                        if (config.build.sourcemap && chunk.map) {\n                            const nextMap = s.generateMap({\n                                source: chunk.fileName,\n                                hires: true,\n                            });\n                            const map = combineSourcemaps(chunk.fileName, [nextMap, chunk.map], false);\n                            map.toUrl = () => genSourceMapUrl(map);\n                            chunk.map = map;\n                        }\n                    }\n                }\n            }\n        },\n    };\n}\n\nfunction ssrManifestPlugin(config) {\n    // module id => preload assets mapping\n    const ssrManifest = {};\n    const base = config.base; // TODO:base\n    return {\n        name: 'vite:ssr-manifest',\n        generateBundle(_options, bundle) {\n            for (const file in bundle) {\n                const chunk = bundle[file];\n                if (chunk.type === 'chunk') {\n                    for (const id in chunk.modules) {\n                        const normalizedId = normalizePath$3(relative$2(config.root, id));\n                        const mappedChunks = ssrManifest[normalizedId] ?? (ssrManifest[normalizedId] = []);\n                        if (!chunk.isEntry) {\n                            mappedChunks.push(joinUrlSegments(base, chunk.fileName));\n                            // <link> tags for entry chunks are already generated in static HTML,\n                            // so we only need to record info for non-entry chunks.\n                            chunk.viteMetadata.importedCss.forEach((file) => {\n                                mappedChunks.push(joinUrlSegments(base, file));\n                            });\n                        }\n                        chunk.viteMetadata.importedAssets.forEach((file) => {\n                            mappedChunks.push(joinUrlSegments(base, file));\n                        });\n                    }\n                    if (chunk.code.includes(preloadMethod)) {\n                        // generate css deps map\n                        const code = chunk.code;\n                        let imports;\n                        try {\n                            imports = parse$e(code)[0].filter((i) => i.n && i.d > -1);\n                        }\n                        catch (e) {\n                            this.error(e, e.idx);\n                        }\n                        if (imports.length) {\n                            for (let index = 0; index < imports.length; index++) {\n                                const { s: start, e: end, n: name } = imports[index];\n                                // check the chunk being imported\n                                const url = code.slice(start, end);\n                                const deps = [];\n                                const ownerFilename = chunk.fileName;\n                                // literal import - trace direct imports and add to deps\n                                const analyzed = new Set();\n                                const addDeps = (filename) => {\n                                    if (filename === ownerFilename)\n                                        return;\n                                    if (analyzed.has(filename))\n                                        return;\n                                    analyzed.add(filename);\n                                    const chunk = bundle[filename];\n                                    if (chunk) {\n                                        chunk.viteMetadata.importedCss.forEach((file) => {\n                                            deps.push(joinUrlSegments(base, file)); // TODO:base\n                                        });\n                                        chunk.imports.forEach(addDeps);\n                                    }\n                                };\n                                const normalizedFile = normalizePath$3(join$2(dirname$2(chunk.fileName), url.slice(1, -1)));\n                                addDeps(normalizedFile);\n                                ssrManifest[basename$2(name)] = deps;\n                            }\n                        }\n                    }\n                }\n            }\n            this.emitFile({\n                fileName: typeof config.build.ssrManifest === 'string'\n                    ? config.build.ssrManifest\n                    : 'ssr-manifest.json',\n                type: 'asset',\n                source: jsonStableStringify(ssrManifest, { space: 2 }),\n            });\n        },\n    };\n}\n\n/**\n * A plugin to provide build load fallback for arbitrary request with queries.\n */\nfunction loadFallbackPlugin() {\n    return {\n        name: 'vite:load-fallback',\n        async load(id) {\n            try {\n                // if we don't add `await` here, we couldn't catch the error in readFile\n                return await promises$2.readFile(cleanUrl(id), 'utf-8');\n            }\n            catch (e) {\n                return promises$2.readFile(id, 'utf-8');\n            }\n        },\n    };\n}\n\nfunction resolveChokidarOptions(config, options) {\n    const { ignored = [], ...otherOptions } = options ?? {};\n    const resolvedWatchOptions = {\n        ignored: [\n            '**/.git/**',\n            '**/node_modules/**',\n            '**/test-results/**',\n            out.escapePath(config.cacheDir) + '/**',\n            ...(Array.isArray(ignored) ? ignored : [ignored]),\n        ],\n        ignoreInitial: true,\n        ignorePermissionErrors: true,\n        ...otherOptions,\n    };\n    return resolvedWatchOptions;\n}\n\n/**\n * make sure systemjs register wrap to had complete parameters in system format\n */\nfunction completeSystemWrapPlugin() {\n    const SystemJSWrapRE = /System.register\\(.*(\\(exports\\)|\\(\\))/g;\n    return {\n        name: 'vite:force-systemjs-wrap-complete',\n        renderChunk(code, chunk, opts) {\n            if (opts.format === 'system') {\n                return {\n                    code: code.replace(SystemJSWrapRE, (s, s1) => s.replace(s1, '(exports, module)')),\n                    map: null,\n                };\n            }\n        },\n    };\n}\n\nconst alias = {\n    js: 'application/javascript',\n    css: 'text/css',\n    html: 'text/html',\n    json: 'application/json',\n};\nfunction send$1(req, res, content, type, options) {\n    const { etag = etag_1(content, { weak: true }), cacheControl = 'no-cache', headers, map, } = options;\n    if (res.writableEnded) {\n        return;\n    }\n    if (req.headers['if-none-match'] === etag) {\n        res.statusCode = 304;\n        res.end();\n        return;\n    }\n    res.setHeader('Content-Type', alias[type] || type);\n    res.setHeader('Cache-Control', cacheControl);\n    res.setHeader('Etag', etag);\n    if (headers) {\n        for (const name in headers) {\n            res.setHeader(name, headers[name]);\n        }\n    }\n    // inject source map reference\n    if (map && map.mappings) {\n        if (type === 'js' || type === 'css') {\n            content = getCodeWithSourcemap(type, content.toString(), map);\n        }\n    }\n    res.statusCode = 200;\n    res.end(content);\n    return;\n}\n\n// https://github.com/vitejs/vite/issues/2820#issuecomment-812495079\nconst ROOT_FILES = [\n    // '.git',\n    // https://pnpm.js.org/workspaces/\n    'pnpm-workspace.yaml',\n    // https://rushjs.io/pages/advanced/config_files/\n    // 'rush.json',\n    // https://nx.dev/latest/react/getting-started/nx-setup\n    // 'workspace.json',\n    // 'nx.json',\n    // https://github.com/lerna/lerna#lernajson\n    'lerna.json',\n];\n// npm: https://docs.npmjs.com/cli/v7/using-npm/workspaces#installing-workspaces\n// yarn: https://classic.yarnpkg.com/en/docs/workspaces/#toc-how-to-use-it\nfunction hasWorkspacePackageJSON(root) {\n    const path = join$2(root, 'package.json');\n    if (!isFileReadable(path)) {\n        return false;\n    }\n    const content = JSON.parse(fs$l.readFileSync(path, 'utf-8')) || {};\n    return !!content.workspaces;\n}\nfunction hasRootFile(root) {\n    return ROOT_FILES.some((file) => fs$l.existsSync(join$2(root, file)));\n}\nfunction hasPackageJSON(root) {\n    const path = join$2(root, 'package.json');\n    return fs$l.existsSync(path);\n}\n/**\n * Search up for the nearest `package.json`\n */\nfunction searchForPackageRoot(current, root = current) {\n    if (hasPackageJSON(current))\n        return current;\n    const dir = dirname$2(current);\n    // reach the fs root\n    if (!dir || dir === current)\n        return root;\n    return searchForPackageRoot(dir, root);\n}\n/**\n * Search up for the nearest workspace root\n */\nfunction searchForWorkspaceRoot(current, root = searchForPackageRoot(current)) {\n    if (hasRootFile(current))\n        return current;\n    if (hasWorkspacePackageJSON(current))\n        return current;\n    const dir = dirname$2(current);\n    // reach the fs root\n    if (!dir || dir === current)\n        return root;\n    return searchForWorkspaceRoot(dir, root);\n}\n\nvar mainExports = {};\nvar main$1 = {\n  get exports(){ return mainExports; },\n  set exports(v){ mainExports = v; },\n};\n\nvar name = \"dotenv\";\nvar version$1 = \"16.0.3\";\nvar description = \"Loads environment variables from .env file\";\nvar main = \"lib/main.js\";\nvar types = \"lib/main.d.ts\";\nvar exports = {\n\t\".\": {\n\t\trequire: \"./lib/main.js\",\n\t\ttypes: \"./lib/main.d.ts\",\n\t\t\"default\": \"./lib/main.js\"\n\t},\n\t\"./config\": \"./config.js\",\n\t\"./config.js\": \"./config.js\",\n\t\"./lib/env-options\": \"./lib/env-options.js\",\n\t\"./lib/env-options.js\": \"./lib/env-options.js\",\n\t\"./lib/cli-options\": \"./lib/cli-options.js\",\n\t\"./lib/cli-options.js\": \"./lib/cli-options.js\",\n\t\"./package.json\": \"./package.json\"\n};\nvar scripts = {\n\t\"dts-check\": \"tsc --project tests/types/tsconfig.json\",\n\tlint: \"standard\",\n\t\"lint-readme\": \"standard-markdown\",\n\tpretest: \"npm run lint && npm run dts-check\",\n\ttest: \"tap tests/*.js --100 -Rspec\",\n\tprerelease: \"npm test\",\n\trelease: \"standard-version\"\n};\nvar repository = {\n\ttype: \"git\",\n\turl: \"git://github.com/motdotla/dotenv.git\"\n};\nvar keywords = [\n\t\"dotenv\",\n\t\"env\",\n\t\".env\",\n\t\"environment\",\n\t\"variables\",\n\t\"config\",\n\t\"settings\"\n];\nvar readmeFilename = \"README.md\";\nvar license = \"BSD-2-Clause\";\nvar devDependencies = {\n\t\"@types/node\": \"^17.0.9\",\n\tdecache: \"^4.6.1\",\n\tdtslint: \"^3.7.0\",\n\tsinon: \"^12.0.1\",\n\tstandard: \"^16.0.4\",\n\t\"standard-markdown\": \"^7.1.0\",\n\t\"standard-version\": \"^9.3.2\",\n\ttap: \"^15.1.6\",\n\ttar: \"^6.1.11\",\n\ttypescript: \"^4.5.4\"\n};\nvar engines = {\n\tnode: \">=12\"\n};\nvar require$$3 = {\n\tname: name,\n\tversion: version$1,\n\tdescription: description,\n\tmain: main,\n\ttypes: types,\n\texports: exports,\n\tscripts: scripts,\n\trepository: repository,\n\tkeywords: keywords,\n\treadmeFilename: readmeFilename,\n\tlicense: license,\n\tdevDependencies: devDependencies,\n\tengines: engines\n};\n\nconst fs$9 = require$$0__default;\nconst path$9 = require$$0$4;\nconst os$2 = require$$2;\nconst packageJson = require$$3;\n\nconst version = packageJson.version;\n\nconst LINE = /(?:^|^)\\s*(?:export\\s+)?([\\w.-]+)(?:\\s*=\\s*?|:\\s+?)(\\s*'(?:\\\\'|[^'])*'|\\s*\"(?:\\\\\"|[^\"])*\"|\\s*`(?:\\\\`|[^`])*`|[^#\\r\\n]+)?\\s*(?:#.*)?(?:$|$)/mg;\n\n// Parser src into an Object\nfunction parse$8 (src) {\n  const obj = {};\n\n  // Convert buffer to string\n  let lines = src.toString();\n\n  // Convert line breaks to same format\n  lines = lines.replace(/\\r\\n?/mg, '\\n');\n\n  let match;\n  while ((match = LINE.exec(lines)) != null) {\n    const key = match[1];\n\n    // Default undefined or null to empty string\n    let value = (match[2] || '');\n\n    // Remove whitespace\n    value = value.trim();\n\n    // Check if double quoted\n    const maybeQuote = value[0];\n\n    // Remove surrounding quotes\n    value = value.replace(/^(['\"`])([\\s\\S]*)\\1$/mg, '$2');\n\n    // Expand newlines if double quoted\n    if (maybeQuote === '\"') {\n      value = value.replace(/\\\\n/g, '\\n');\n      value = value.replace(/\\\\r/g, '\\r');\n    }\n\n    // Add to object\n    obj[key] = value;\n  }\n\n  return obj\n}\n\nfunction _log (message) {\n  console.log(`[dotenv@${version}][DEBUG] ${message}`);\n}\n\nfunction _resolveHome (envPath) {\n  return envPath[0] === '~' ? path$9.join(os$2.homedir(), envPath.slice(1)) : envPath\n}\n\n// Populates process.env from .env file\nfunction config (options) {\n  let dotenvPath = path$9.resolve(process.cwd(), '.env');\n  let encoding = 'utf8';\n  const debug = Boolean(options && options.debug);\n  const override = Boolean(options && options.override);\n\n  if (options) {\n    if (options.path != null) {\n      dotenvPath = _resolveHome(options.path);\n    }\n    if (options.encoding != null) {\n      encoding = options.encoding;\n    }\n  }\n\n  try {\n    // Specifying an encoding returns a string instead of a buffer\n    const parsed = DotenvModule.parse(fs$9.readFileSync(dotenvPath, { encoding }));\n\n    Object.keys(parsed).forEach(function (key) {\n      if (!Object.prototype.hasOwnProperty.call(process.env, key)) {\n        process.env[key] = parsed[key];\n      } else {\n        if (override === true) {\n          process.env[key] = parsed[key];\n        }\n\n        if (debug) {\n          if (override === true) {\n            _log(`\"${key}\" is already defined in \\`process.env\\` and WAS overwritten`);\n          } else {\n            _log(`\"${key}\" is already defined in \\`process.env\\` and was NOT overwritten`);\n          }\n        }\n      }\n    });\n\n    return { parsed }\n  } catch (e) {\n    if (debug) {\n      _log(`Failed to load ${dotenvPath} ${e.message}`);\n    }\n\n    return { error: e }\n  }\n}\n\nconst DotenvModule = {\n  config,\n  parse: parse$8\n};\n\nmainExports.config = DotenvModule.config;\nvar parse_1$1 = mainExports.parse = DotenvModule.parse;\nmain$1.exports = DotenvModule;\n\nfunction _interpolate (envValue, environment, config) {\n  const matches = envValue.match(/(.?\\${*[\\w]*(?::-[\\w/]*)?}*)/g) || [];\n\n  return matches.reduce(function (newEnv, match, index) {\n    const parts = /(.?)\\${*([\\w]*(?::-[\\w/]*)?)?}*/g.exec(match);\n    if (!parts || parts.length === 0) {\n      return newEnv\n    }\n\n    const prefix = parts[1];\n\n    let value, replacePart;\n\n    if (prefix === '\\\\') {\n      replacePart = parts[0];\n      value = replacePart.replace('\\\\$', '$');\n    } else {\n      // PATCH: compatible with env variables ended with unescaped $\n      if(!parts[2]) {\n        return newEnv\n      }\n      const keyParts = parts[2].split(':-');\n      const key = keyParts[0];\n      replacePart = parts[0].substring(prefix.length);\n      // process.env value 'wins' over .env file's value\n      value = Object.prototype.hasOwnProperty.call(environment, key)\n        ? environment[key]\n        : (config.parsed[key] || keyParts[1] || '');\n\n      // If the value is found, remove nested expansions.\n      if (keyParts.length > 1 && value) {\n        const replaceNested = matches[index + 1];\n        matches[index + 1] = '';\n\n        newEnv = newEnv.replace(replaceNested, '');\n      }\n      // Resolve recursive interpolations\n      value = _interpolate(value, environment, config);\n    }\n\n    return newEnv.replace(replacePart, value)\n  }, envValue)\n}\n\nfunction expand (config) {\n  // if ignoring process.env, use a blank object\n  const environment = config.ignoreProcessEnv ? {} : process.env;\n\n  for (const configKey in config.parsed) {\n    const value = Object.prototype.hasOwnProperty.call(environment, configKey) ? environment[configKey] : config.parsed[configKey];\n\n    config.parsed[configKey] = _interpolate(value, environment, config);\n  }\n\n  // PATCH: don't write to process.env\n  // for (const processKey in config.parsed) {\n  //   environment[processKey] = config.parsed[processKey]\n  // }\n\n  return config\n}\n\nvar expand_1 = expand;\n\nfunction loadEnv(mode, envDir, prefixes = 'VITE_') {\n    if (mode === 'local') {\n        throw new Error(`\"local\" cannot be used as a mode name because it conflicts with ` +\n            `the .local postfix for .env files.`);\n    }\n    prefixes = arraify(prefixes);\n    const env = {};\n    const envFiles = [\n        /** default file */ `.env`,\n        /** local file */ `.env.local`,\n        /** mode file */ `.env.${mode}`,\n        /** mode local file */ `.env.${mode}.local`,\n    ];\n    const parsed = Object.fromEntries(envFiles.flatMap((file) => {\n        const path = lookupFile(envDir, [file], {\n            pathOnly: true,\n            rootDir: envDir,\n        });\n        if (!path)\n            return [];\n        return Object.entries(parse_1$1(fs$l.readFileSync(path)));\n    }));\n    // test NODE_ENV override before expand as otherwise process.env.NODE_ENV would override this\n    if (parsed.NODE_ENV && process.env.VITE_USER_NODE_ENV === undefined) {\n        process.env.VITE_USER_NODE_ENV = parsed.NODE_ENV;\n    }\n    // support BROWSER and BROWSER_ARGS env variables\n    if (parsed.BROWSER && process.env.BROWSER === undefined) {\n        process.env.BROWSER = parsed.BROWSER;\n    }\n    if (parsed.BROWSER_ARGS && process.env.BROWSER_ARGS === undefined) {\n        process.env.BROWSER_ARGS = parsed.BROWSER_ARGS;\n    }\n    // let environment variables use each other\n    // `expand` patched in patches/dotenv-expand@9.0.0.patch\n    expand_1({ parsed });\n    // only keys that start with prefix are exposed to client\n    for (const [key, value] of Object.entries(parsed)) {\n        if (prefixes.some((prefix) => key.startsWith(prefix))) {\n            env[key] = value;\n        }\n    }\n    // check if there are actual env variables starting with VITE_*\n    // these are typically provided inline and should be prioritized\n    for (const key in process.env) {\n        if (prefixes.some((prefix) => key.startsWith(prefix))) {\n            env[key] = process.env[key];\n        }\n    }\n    return env;\n}\nfunction resolveEnvPrefix({ envPrefix = 'VITE_', }) {\n    envPrefix = arraify(envPrefix);\n    if (envPrefix.some((prefix) => prefix === '')) {\n        throw new Error(`envPrefix option contains value '', which could lead unexpected exposure of sensitive information.`);\n    }\n    return envPrefix;\n}\n\nfunction resolveBuildOptions(raw, logger) {\n    const deprecatedPolyfillModulePreload = raw?.polyfillModulePreload;\n    if (raw) {\n        const { polyfillModulePreload, ...rest } = raw;\n        raw = rest;\n        if (deprecatedPolyfillModulePreload !== undefined) {\n            logger.warn('polyfillModulePreload is deprecated. Use modulePreload.polyfill instead.');\n        }\n        if (deprecatedPolyfillModulePreload === false &&\n            raw.modulePreload === undefined) {\n            raw.modulePreload = { polyfill: false };\n        }\n    }\n    const modulePreload = raw?.modulePreload;\n    const defaultModulePreload = {\n        polyfill: true,\n    };\n    const defaultBuildOptions = {\n        outDir: 'dist',\n        assetsDir: 'assets',\n        assetsInlineLimit: 4096,\n        cssCodeSplit: !raw?.lib,\n        sourcemap: false,\n        rollupOptions: {},\n        minify: raw?.ssr ? false : 'esbuild',\n        terserOptions: {},\n        write: true,\n        emptyOutDir: null,\n        copyPublicDir: true,\n        manifest: false,\n        lib: false,\n        ssr: false,\n        ssrManifest: false,\n        ssrEmitAssets: false,\n        reportCompressedSize: true,\n        chunkSizeWarningLimit: 500,\n        watch: null,\n    };\n    const userBuildOptions = raw\n        ? mergeConfig(defaultBuildOptions, raw)\n        : defaultBuildOptions;\n    // @ts-expect-error Fallback options instead of merging\n    const resolved = {\n        target: 'modules',\n        cssTarget: false,\n        ...userBuildOptions,\n        commonjsOptions: {\n            include: [/node_modules/],\n            extensions: ['.js', '.cjs'],\n            ...userBuildOptions.commonjsOptions,\n        },\n        dynamicImportVarsOptions: {\n            warnOnError: true,\n            exclude: [/node_modules/],\n            ...userBuildOptions.dynamicImportVarsOptions,\n        },\n        // Resolve to false | object\n        modulePreload: modulePreload === false\n            ? false\n            : typeof modulePreload === 'object'\n                ? {\n                    ...defaultModulePreload,\n                    ...modulePreload,\n                }\n                : defaultModulePreload,\n    };\n    // handle special build targets\n    if (resolved.target === 'modules') {\n        resolved.target = ESBUILD_MODULES_TARGET;\n    }\n    else if (resolved.target === 'esnext' && resolved.minify === 'terser') {\n        // esnext + terser: limit to es2021 so it can be minified by terser\n        resolved.target = 'es2021';\n    }\n    if (!resolved.cssTarget) {\n        resolved.cssTarget = resolved.target;\n    }\n    // normalize false string into actual false\n    if (resolved.minify === 'false') {\n        resolved.minify = false;\n    }\n    if (resolved.minify === true) {\n        resolved.minify = 'esbuild';\n    }\n    return resolved;\n}\nasync function resolveBuildPlugins(config) {\n    const options = config.build;\n    const { commonjsOptions } = options;\n    const usePluginCommonjs = !Array.isArray(commonjsOptions?.include) ||\n        commonjsOptions?.include.length !== 0;\n    const rollupOptionsPlugins = options.rollupOptions.plugins;\n    return {\n        pre: [\n            completeSystemWrapPlugin(),\n            ...(options.watch ? [ensureWatchPlugin()] : []),\n            watchPackageDataPlugin(config),\n            ...(usePluginCommonjs ? [commonjs(options.commonjsOptions)] : []),\n            dataURIPlugin(),\n            ...(await asyncFlatten(Array.isArray(rollupOptionsPlugins)\n                ? rollupOptionsPlugins\n                : [rollupOptionsPlugins])).filter(Boolean),\n        ],\n        post: [\n            buildImportAnalysisPlugin(config),\n            ...(config.esbuild !== false ? [buildEsbuildPlugin(config)] : []),\n            ...(options.minify ? [terserPlugin(config)] : []),\n            ...(options.manifest ? [manifestPlugin(config)] : []),\n            ...(options.ssrManifest ? [ssrManifestPlugin(config)] : []),\n            ...(!config.isWorker ? [buildReporterPlugin(config)] : []),\n            loadFallbackPlugin(),\n        ],\n    };\n}\n/**\n * Bundles the app for production.\n * Returns a Promise containing the build result.\n */\nasync function build(inlineConfig = {}) {\n    const config = await resolveConfig(inlineConfig, 'build', 'production', 'production');\n    const options = config.build;\n    const ssr = !!options.ssr;\n    const libOptions = options.lib;\n    config.logger.info(picocolorsExports.cyan(`vite v${VERSION$1} ${picocolorsExports.green(`building ${ssr ? `SSR bundle ` : ``}for ${config.mode}...`)}`));\n    const resolve = (p) => path$o.resolve(config.root, p);\n    const input = libOptions\n        ? options.rollupOptions?.input ||\n            (typeof libOptions.entry === 'string'\n                ? resolve(libOptions.entry)\n                : Array.isArray(libOptions.entry)\n                    ? libOptions.entry.map(resolve)\n                    : Object.fromEntries(Object.entries(libOptions.entry).map(([alias, file]) => [\n                        alias,\n                        resolve(file),\n                    ])))\n        : typeof options.ssr === 'string'\n            ? resolve(options.ssr)\n            : options.rollupOptions?.input || resolve('index.html');\n    if (ssr && typeof input === 'string' && input.endsWith('.html')) {\n        throw new Error(`rollupOptions.input should not be an html file when building for SSR. ` +\n            `Please specify a dedicated SSR entry.`);\n    }\n    const outDir = resolve(options.outDir);\n    // inject ssr arg to plugin load/transform hooks\n    const plugins = (ssr ? config.plugins.map((p) => injectSsrFlagToHooks(p)) : config.plugins);\n    const userExternal = options.rollupOptions?.external;\n    let external = userExternal;\n    // In CJS, we can pass the externals to rollup as is. In ESM, we need to\n    // do it in the resolve plugin so we can add the resolved extension for\n    // deep node_modules imports\n    if (ssr && config.legacy?.buildSsrCjsExternalHeuristics) {\n        external = await cjsSsrResolveExternal(config, userExternal);\n    }\n    if (isDepsOptimizerEnabled(config, ssr)) {\n        await initDepsOptimizer(config);\n    }\n    const rollupOptions = {\n        context: 'globalThis',\n        preserveEntrySignatures: ssr\n            ? 'allow-extension'\n            : libOptions\n                ? 'strict'\n                : false,\n        cache: config.build.watch ? undefined : false,\n        ...options.rollupOptions,\n        input,\n        plugins,\n        external,\n        onwarn(warning, warn) {\n            onRollupWarning(warning, warn, config);\n        },\n    };\n    const outputBuildError = (e) => {\n        let msg = picocolorsExports.red((e.plugin ? `[${e.plugin}] ` : '') + e.message);\n        if (e.id) {\n            msg += `\\nfile: ${picocolorsExports.cyan(e.id + (e.loc ? `:${e.loc.line}:${e.loc.column}` : ''))}`;\n        }\n        if (e.frame) {\n            msg += `\\n` + picocolorsExports.yellow(e.frame);\n        }\n        config.logger.error(msg, { error: e });\n    };\n    let bundle;\n    try {\n        const buildOutputOptions = (output = {}) => {\n            // @ts-expect-error See https://github.com/vitejs/vite/issues/5812#issuecomment-984345618\n            if (output.output) {\n                config.logger.warn(`You've set \"rollupOptions.output.output\" in your config. ` +\n                    `This is deprecated and will override all Vite.js default output options. ` +\n                    `Please use \"rollupOptions.output\" instead.`);\n            }\n            const ssrNodeBuild = ssr && config.ssr.target === 'node';\n            const ssrWorkerBuild = ssr && config.ssr.target === 'webworker';\n            const cjsSsrBuild = ssr && config.ssr.format === 'cjs';\n            const format = output.format || (cjsSsrBuild ? 'cjs' : 'es');\n            const jsExt = ssrNodeBuild || libOptions\n                ? resolveOutputJsExtension(format, getPkgJson(config.root)?.type)\n                : 'js';\n            return {\n                dir: outDir,\n                // Default format is 'es' for regular and for SSR builds\n                format,\n                exports: cjsSsrBuild ? 'named' : 'auto',\n                sourcemap: options.sourcemap,\n                name: libOptions ? libOptions.name : undefined,\n                // es2015 enables `generatedCode.symbols`\n                // - #764 add `Symbol.toStringTag` when build es module into cjs chunk\n                // - #1048 add `Symbol.toStringTag` for module default export\n                generatedCode: 'es2015',\n                entryFileNames: ssr\n                    ? `[name].${jsExt}`\n                    : libOptions\n                        ? ({ name }) => resolveLibFilename(libOptions, format, name, config.root, jsExt)\n                        : path$o.posix.join(options.assetsDir, `[name]-[hash].${jsExt}`),\n                chunkFileNames: libOptions\n                    ? `[name]-[hash].${jsExt}`\n                    : path$o.posix.join(options.assetsDir, `[name]-[hash].${jsExt}`),\n                assetFileNames: libOptions\n                    ? `[name].[ext]`\n                    : path$o.posix.join(options.assetsDir, `[name]-[hash].[ext]`),\n                inlineDynamicImports: output.format === 'umd' ||\n                    output.format === 'iife' ||\n                    (ssrWorkerBuild &&\n                        (typeof input === 'string' || Object.keys(input).length === 1)),\n                ...output,\n            };\n        };\n        // resolve lib mode outputs\n        const outputs = resolveBuildOutputs(options.rollupOptions?.output, libOptions, config.logger);\n        const normalizedOutputs = [];\n        if (Array.isArray(outputs)) {\n            for (const resolvedOutput of outputs) {\n                normalizedOutputs.push(buildOutputOptions(resolvedOutput));\n            }\n        }\n        else {\n            normalizedOutputs.push(buildOutputOptions(outputs));\n        }\n        const outDirs = normalizedOutputs.map(({ dir }) => resolve(dir));\n        // watch file changes with rollup\n        if (config.build.watch) {\n            config.logger.info(picocolorsExports.cyan(`\\nwatching for file changes...`));\n            const resolvedChokidarOptions = resolveChokidarOptions(config, config.build.watch.chokidar);\n            const { watch } = await import('rollup');\n            const watcher = watch({\n                ...rollupOptions,\n                output: normalizedOutputs,\n                watch: {\n                    ...config.build.watch,\n                    chokidar: resolvedChokidarOptions,\n                },\n            });\n            watcher.on('event', (event) => {\n                if (event.code === 'BUNDLE_START') {\n                    config.logger.info(picocolorsExports.cyan(`\\nbuild started...`));\n                    if (options.write) {\n                        prepareOutDir(outDirs, options.emptyOutDir, config);\n                    }\n                }\n                else if (event.code === 'BUNDLE_END') {\n                    event.result.close();\n                    config.logger.info(picocolorsExports.cyan(`built in ${event.duration}ms.`));\n                }\n                else if (event.code === 'ERROR') {\n                    outputBuildError(event.error);\n                }\n            });\n            return watcher;\n        }\n        // write or generate files with rollup\n        const { rollup } = await import('rollup');\n        bundle = await rollup(rollupOptions);\n        if (options.write) {\n            prepareOutDir(outDirs, options.emptyOutDir, config);\n        }\n        const res = [];\n        for (const output of normalizedOutputs) {\n            res.push(await bundle[options.write ? 'write' : 'generate'](output));\n        }\n        return Array.isArray(outputs) ? res : res[0];\n    }\n    catch (e) {\n        outputBuildError(e);\n        throw e;\n    }\n    finally {\n        if (bundle)\n            await bundle.close();\n    }\n}\nfunction prepareOutDir(outDirs, emptyOutDir, config) {\n    const nonDuplicateDirs = new Set(outDirs);\n    let outside = false;\n    if (emptyOutDir == null) {\n        for (const outDir of nonDuplicateDirs) {\n            if (fs$l.existsSync(outDir) &&\n                !normalizePath$3(outDir).startsWith(config.root + '/')) {\n                // warn if outDir is outside of root\n                config.logger.warn(picocolorsExports.yellow(`\\n${picocolorsExports.bold(`(!)`)} outDir ${picocolorsExports.white(picocolorsExports.dim(outDir))} is not inside project root and will not be emptied.\\n` +\n                    `Use --emptyOutDir to override.\\n`));\n                outside = true;\n                break;\n            }\n        }\n    }\n    for (const outDir of nonDuplicateDirs) {\n        if (!outside && emptyOutDir !== false && fs$l.existsSync(outDir)) {\n            // skip those other outDirs which are nested in current outDir\n            const skipDirs = outDirs\n                .map((dir) => {\n                const relative = path$o.relative(outDir, dir);\n                if (relative &&\n                    !relative.startsWith('..') &&\n                    !path$o.isAbsolute(relative)) {\n                    return relative;\n                }\n                return '';\n            })\n                .filter(Boolean);\n            emptyDir(outDir, [...skipDirs, '.git']);\n        }\n        if (config.build.copyPublicDir &&\n            config.publicDir &&\n            fs$l.existsSync(config.publicDir)) {\n            copyDir(config.publicDir, outDir);\n        }\n    }\n}\nfunction getPkgJson(root) {\n    return JSON.parse(lookupFile(root, ['package.json']) || `{}`);\n}\nfunction getPkgName(name) {\n    return name?.startsWith('@') ? name.split('/')[1] : name;\n}\nfunction resolveOutputJsExtension(format, type = 'commonjs') {\n    if (type === 'module') {\n        return format === 'cjs' || format === 'umd' ? 'cjs' : 'js';\n    }\n    else {\n        return format === 'es' ? 'mjs' : 'js';\n    }\n}\nfunction resolveLibFilename(libOptions, format, entryName, root, extension) {\n    if (typeof libOptions.fileName === 'function') {\n        return libOptions.fileName(format, entryName);\n    }\n    const packageJson = getPkgJson(root);\n    const name = libOptions.fileName ||\n        (typeof libOptions.entry === 'string'\n            ? getPkgName(packageJson.name)\n            : entryName);\n    if (!name)\n        throw new Error('Name in package.json is required if option \"build.lib.fileName\" is not provided.');\n    extension ?? (extension = resolveOutputJsExtension(format, packageJson.type));\n    if (format === 'cjs' || format === 'es') {\n        return `${name}.${extension}`;\n    }\n    return `${name}.${format}.${extension}`;\n}\nfunction resolveBuildOutputs(outputs, libOptions, logger) {\n    if (libOptions) {\n        const libHasMultipleEntries = typeof libOptions.entry !== 'string' &&\n            Object.values(libOptions.entry).length > 1;\n        const libFormats = libOptions.formats ||\n            (libHasMultipleEntries ? ['es', 'cjs'] : ['es', 'umd']);\n        if (!Array.isArray(outputs)) {\n            if (libFormats.includes('umd') || libFormats.includes('iife')) {\n                if (libHasMultipleEntries) {\n                    throw new Error('Multiple entry points are not supported when output formats include \"umd\" or \"iife\".');\n                }\n                if (!libOptions.name) {\n                    throw new Error('Option \"build.lib.name\" is required when output formats include \"umd\" or \"iife\".');\n                }\n            }\n            return libFormats.map((format) => ({ ...outputs, format }));\n        }\n        // By this point, we know \"outputs\" is an Array.\n        if (libOptions.formats) {\n            logger.warn(picocolorsExports.yellow('\"build.lib.formats\" will be ignored because \"build.rollupOptions.output\" is already an array format.'));\n        }\n        outputs.forEach((output) => {\n            if (['umd', 'iife'].includes(output.format) && !output.name) {\n                throw new Error('Entries in \"build.rollupOptions.output\" must specify \"name\" when the format is \"umd\" or \"iife\".');\n            }\n        });\n    }\n    return outputs;\n}\nconst warningIgnoreList = [`CIRCULAR_DEPENDENCY`, `THIS_IS_UNDEFINED`];\nconst dynamicImportWarningIgnoreList = [\n    `Unsupported expression`,\n    `statically analyzed`,\n];\nfunction onRollupWarning(warning, warn, config) {\n    if (warning.code === 'UNRESOLVED_IMPORT') {\n        const id = warning.id;\n        const exporter = warning.exporter;\n        // throw unless it's commonjs external...\n        if (!id || !/\\?commonjs-external$/.test(id)) {\n            throw new Error(`[vite]: Rollup failed to resolve import \"${exporter}\" from \"${id}\".\\n` +\n                `This is most likely unintended because it can break your application at runtime.\\n` +\n                `If you do want to externalize this module explicitly add it to\\n` +\n                `\\`build.rollupOptions.external\\``);\n        }\n    }\n    if (warning.plugin === 'rollup-plugin-dynamic-import-variables' &&\n        dynamicImportWarningIgnoreList.some((msg) => warning.message.includes(msg))) {\n        return;\n    }\n    if (!warningIgnoreList.includes(warning.code)) {\n        const userOnWarn = config.build.rollupOptions?.onwarn;\n        if (userOnWarn) {\n            userOnWarn(warning, warn);\n        }\n        else if (warning.code === 'PLUGIN_WARNING') {\n            config.logger.warn(`${picocolorsExports.bold(picocolorsExports.yellow(`[plugin:${warning.plugin}]`))} ${picocolorsExports.yellow(warning.message)}`);\n        }\n        else {\n            warn(warning);\n        }\n    }\n}\nasync function cjsSsrResolveExternal(config, user) {\n    // see if we have cached deps data available\n    let knownImports;\n    const dataPath = path$o.join(getDepsCacheDir(config, false), '_metadata.json');\n    try {\n        const data = JSON.parse(fs$l.readFileSync(dataPath, 'utf-8'));\n        knownImports = Object.keys(data.optimized);\n    }\n    catch (e) { }\n    if (!knownImports) {\n        // no dev deps optimization data, do a fresh scan\n        knownImports = await findKnownImports(config, false); // needs to use non-ssr\n    }\n    const ssrExternals = cjsSsrResolveExternals(config, knownImports);\n    return (id, parentId, isResolved) => {\n        const isExternal = cjsShouldExternalizeForSSR(id, ssrExternals);\n        if (isExternal) {\n            return true;\n        }\n        if (user) {\n            return resolveUserExternal(user, id, parentId, isResolved);\n        }\n    };\n}\nfunction resolveUserExternal(user, id, parentId, isResolved) {\n    if (typeof user === 'function') {\n        return user(id, parentId, isResolved);\n    }\n    else if (Array.isArray(user)) {\n        return user.some((test) => isExternal(id, test));\n    }\n    else {\n        return isExternal(id, user);\n    }\n}\nfunction isExternal(id, test) {\n    if (typeof test === 'string') {\n        return id === test;\n    }\n    else {\n        return test.test(id);\n    }\n}\nfunction injectSsrFlagToHooks(plugin) {\n    const { resolveId, load, transform } = plugin;\n    return {\n        ...plugin,\n        resolveId: wrapSsrResolveId(resolveId),\n        load: wrapSsrLoad(load),\n        transform: wrapSsrTransform(transform),\n    };\n}\nfunction wrapSsrResolveId(hook) {\n    if (!hook)\n        return;\n    const fn = 'handler' in hook ? hook.handler : hook;\n    const handler = function (id, importer, options) {\n        return fn.call(this, id, importer, injectSsrFlag(options));\n    };\n    if ('handler' in hook) {\n        return {\n            ...hook,\n            handler,\n        };\n    }\n    else {\n        return handler;\n    }\n}\nfunction wrapSsrLoad(hook) {\n    if (!hook)\n        return;\n    const fn = 'handler' in hook ? hook.handler : hook;\n    const handler = function (id, ...args) {\n        // @ts-expect-error: Receiving options param to be future-proof if Rollup adds it\n        return fn.call(this, id, injectSsrFlag(args[0]));\n    };\n    if ('handler' in hook) {\n        return {\n            ...hook,\n            handler,\n        };\n    }\n    else {\n        return handler;\n    }\n}\nfunction wrapSsrTransform(hook) {\n    if (!hook)\n        return;\n    const fn = 'handler' in hook ? hook.handler : hook;\n    const handler = function (code, importer, ...args) {\n        // @ts-expect-error: Receiving options param to be future-proof if Rollup adds it\n        return fn.call(this, code, importer, injectSsrFlag(args[0]));\n    };\n    if ('handler' in hook) {\n        return {\n            ...hook,\n            handler,\n        };\n    }\n    else {\n        return handler;\n    }\n}\nfunction injectSsrFlag(options) {\n    return { ...(options ?? {}), ssr: true };\n}\n/*\n  The following functions are copied from rollup\n  https://github.com/rollup/rollup/blob/c5269747cd3dd14c4b306e8cea36f248d9c1aa01/src/ast/nodes/MetaProperty.ts#L189-L232\n\n  https://github.com/rollup/rollup\n  The MIT License (MIT)\n  Copyright (c) 2017 [these people](https://github.com/rollup/rollup/graphs/contributors)\n  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\nconst getResolveUrl = (path, URL = 'URL') => `new ${URL}(${path}).href`;\nconst getRelativeUrlFromDocument = (relativePath, umd = false) => getResolveUrl(`'${relativePath}', ${umd ? `typeof document === 'undefined' ? location.href : ` : ''}document.currentScript && document.currentScript.src || document.baseURI`);\nconst relativeUrlMechanisms = {\n    amd: (relativePath) => {\n        if (relativePath[0] !== '.')\n            relativePath = './' + relativePath;\n        return getResolveUrl(`require.toUrl('${relativePath}'), document.baseURI`);\n    },\n    cjs: (relativePath) => `(typeof document === 'undefined' ? ${getResolveUrl(`'file:' + __dirname + '/${relativePath}'`, `(require('u' + 'rl').URL)`)} : ${getRelativeUrlFromDocument(relativePath)})`,\n    es: (relativePath) => getResolveUrl(`'${relativePath}', import.meta.url`),\n    iife: (relativePath) => getRelativeUrlFromDocument(relativePath),\n    // NOTE: make sure rollup generate `module` params\n    system: (relativePath) => getResolveUrl(`'${relativePath}', module.meta.url`),\n    umd: (relativePath) => `(typeof document === 'undefined' && typeof location === 'undefined' ? ${getResolveUrl(`'file:' + __dirname + '/${relativePath}'`, `(require('u' + 'rl').URL)`)} : ${getRelativeUrlFromDocument(relativePath, true)})`,\n};\nfunction toOutputFilePathInJS(filename, type, hostId, hostType, config, toRelative) {\n    const { renderBuiltUrl } = config.experimental;\n    let relative = config.base === '' || config.base === './';\n    if (renderBuiltUrl) {\n        const result = renderBuiltUrl(filename, {\n            hostId,\n            hostType,\n            type,\n            ssr: !!config.build.ssr,\n        });\n        if (typeof result === 'object') {\n            if (result.runtime) {\n                return { runtime: result.runtime };\n            }\n            if (typeof result.relative === 'boolean') {\n                relative = result.relative;\n            }\n        }\n        else if (result) {\n            return result;\n        }\n    }\n    if (relative && !config.build.ssr) {\n        return toRelative(filename, hostId);\n    }\n    return joinUrlSegments(config.base, filename);\n}\nfunction createToImportMetaURLBasedRelativeRuntime(format) {\n    const toRelativePath = relativeUrlMechanisms[format];\n    return (filename, importer) => ({\n        runtime: toRelativePath(path$o.posix.relative(path$o.dirname(importer), filename)),\n    });\n}\nfunction toOutputFilePathWithoutRuntime(filename, type, hostId, hostType, config, toRelative) {\n    const { renderBuiltUrl } = config.experimental;\n    let relative = config.base === '' || config.base === './';\n    if (renderBuiltUrl) {\n        const result = renderBuiltUrl(filename, {\n            hostId,\n            hostType,\n            type,\n            ssr: !!config.build.ssr,\n        });\n        if (typeof result === 'object') {\n            if (result.runtime) {\n                throw new Error(`{ runtime: \"${result.runtime}\" } is not supported for assets in ${hostType} files: ${filename}`);\n            }\n            if (typeof result.relative === 'boolean') {\n                relative = result.relative;\n            }\n        }\n        else if (result) {\n            return result;\n        }\n    }\n    if (relative && !config.build.ssr) {\n        return toRelative(filename, hostId);\n    }\n    else {\n        return joinUrlSegments(config.base, filename);\n    }\n}\nconst toOutputFilePathInCss = toOutputFilePathWithoutRuntime;\nconst toOutputFilePathInHtml = toOutputFilePathWithoutRuntime;\n\nvar build$1 = {\n  __proto__: null,\n  build: build,\n  createToImportMetaURLBasedRelativeRuntime: createToImportMetaURLBasedRelativeRuntime,\n  onRollupWarning: onRollupWarning,\n  resolveBuildOptions: resolveBuildOptions,\n  resolveBuildOutputs: resolveBuildOutputs,\n  resolveBuildPlugins: resolveBuildPlugins,\n  resolveLibFilename: resolveLibFilename,\n  toOutputFilePathInCss: toOutputFilePathInCss,\n  toOutputFilePathInHtml: toOutputFilePathInHtml,\n  toOutputFilePathInJS: toOutputFilePathInJS,\n  toOutputFilePathWithoutRuntime: toOutputFilePathWithoutRuntime\n};\n\nvar srcExports = {};\nvar src = {\n  get exports(){ return srcExports; },\n  set exports(v){ srcExports = v; },\n};\n\nvar browserExports = {};\nvar browser = {\n  get exports(){ return browserExports; },\n  set exports(v){ browserExports = v; },\n};\n\nvar debugExports = {};\nvar debug$6 = {\n  get exports(){ return debugExports; },\n  set exports(v){ debugExports = v; },\n};\n\n/**\n * Helpers.\n */\n\nvar ms;\nvar hasRequiredMs;\n\nfunction requireMs () {\n\tif (hasRequiredMs) return ms;\n\thasRequiredMs = 1;\n\tvar s = 1000;\n\tvar m = s * 60;\n\tvar h = m * 60;\n\tvar d = h * 24;\n\tvar y = d * 365.25;\n\n\t/**\n\t * Parse or format the given `val`.\n\t *\n\t * Options:\n\t *\n\t *  - `long` verbose formatting [false]\n\t *\n\t * @param {String|Number} val\n\t * @param {Object} [options]\n\t * @throws {Error} throw an error if val is not a non-empty string or a number\n\t * @return {String|Number}\n\t * @api public\n\t */\n\n\tms = function(val, options) {\n\t  options = options || {};\n\t  var type = typeof val;\n\t  if (type === 'string' && val.length > 0) {\n\t    return parse(val);\n\t  } else if (type === 'number' && isNaN(val) === false) {\n\t    return options.long ? fmtLong(val) : fmtShort(val);\n\t  }\n\t  throw new Error(\n\t    'val is not a non-empty string or a valid number. val=' +\n\t      JSON.stringify(val)\n\t  );\n\t};\n\n\t/**\n\t * Parse the given `str` and return milliseconds.\n\t *\n\t * @param {String} str\n\t * @return {Number}\n\t * @api private\n\t */\n\n\tfunction parse(str) {\n\t  str = String(str);\n\t  if (str.length > 100) {\n\t    return;\n\t  }\n\t  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(\n\t    str\n\t  );\n\t  if (!match) {\n\t    return;\n\t  }\n\t  var n = parseFloat(match[1]);\n\t  var type = (match[2] || 'ms').toLowerCase();\n\t  switch (type) {\n\t    case 'years':\n\t    case 'year':\n\t    case 'yrs':\n\t    case 'yr':\n\t    case 'y':\n\t      return n * y;\n\t    case 'days':\n\t    case 'day':\n\t    case 'd':\n\t      return n * d;\n\t    case 'hours':\n\t    case 'hour':\n\t    case 'hrs':\n\t    case 'hr':\n\t    case 'h':\n\t      return n * h;\n\t    case 'minutes':\n\t    case 'minute':\n\t    case 'mins':\n\t    case 'min':\n\t    case 'm':\n\t      return n * m;\n\t    case 'seconds':\n\t    case 'second':\n\t    case 'secs':\n\t    case 'sec':\n\t    case 's':\n\t      return n * s;\n\t    case 'milliseconds':\n\t    case 'millisecond':\n\t    case 'msecs':\n\t    case 'msec':\n\t    case 'ms':\n\t      return n;\n\t    default:\n\t      return undefined;\n\t  }\n\t}\n\n\t/**\n\t * Short format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\n\tfunction fmtShort(ms) {\n\t  if (ms >= d) {\n\t    return Math.round(ms / d) + 'd';\n\t  }\n\t  if (ms >= h) {\n\t    return Math.round(ms / h) + 'h';\n\t  }\n\t  if (ms >= m) {\n\t    return Math.round(ms / m) + 'm';\n\t  }\n\t  if (ms >= s) {\n\t    return Math.round(ms / s) + 's';\n\t  }\n\t  return ms + 'ms';\n\t}\n\n\t/**\n\t * Long format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\n\tfunction fmtLong(ms) {\n\t  return plural(ms, d, 'day') ||\n\t    plural(ms, h, 'hour') ||\n\t    plural(ms, m, 'minute') ||\n\t    plural(ms, s, 'second') ||\n\t    ms + ' ms';\n\t}\n\n\t/**\n\t * Pluralization helper.\n\t */\n\n\tfunction plural(ms, n, name) {\n\t  if (ms < n) {\n\t    return;\n\t  }\n\t  if (ms < n * 1.5) {\n\t    return Math.floor(ms / n) + ' ' + name;\n\t  }\n\t  return Math.ceil(ms / n) + ' ' + name + 's';\n\t}\n\treturn ms;\n}\n\nvar hasRequiredDebug;\n\nfunction requireDebug () {\n\tif (hasRequiredDebug) return debugExports;\n\thasRequiredDebug = 1;\n\t(function (module, exports) {\n\t\t/**\n\t\t * This is the common logic for both the Node.js and web browser\n\t\t * implementations of `debug()`.\n\t\t *\n\t\t * Expose `debug()` as the module.\n\t\t */\n\n\t\texports = module.exports = createDebug.debug = createDebug['default'] = createDebug;\n\t\texports.coerce = coerce;\n\t\texports.disable = disable;\n\t\texports.enable = enable;\n\t\texports.enabled = enabled;\n\t\texports.humanize = requireMs();\n\n\t\t/**\n\t\t * The currently active debug mode names, and names to skip.\n\t\t */\n\n\t\texports.names = [];\n\t\texports.skips = [];\n\n\t\t/**\n\t\t * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t\t *\n\t\t * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t\t */\n\n\t\texports.formatters = {};\n\n\t\t/**\n\t\t * Previous log timestamp.\n\t\t */\n\n\t\tvar prevTime;\n\n\t\t/**\n\t\t * Select a color.\n\t\t * @param {String} namespace\n\t\t * @return {Number}\n\t\t * @api private\n\t\t */\n\n\t\tfunction selectColor(namespace) {\n\t\t  var hash = 0, i;\n\n\t\t  for (i in namespace) {\n\t\t    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t    hash |= 0; // Convert to 32bit integer\n\t\t  }\n\n\t\t  return exports.colors[Math.abs(hash) % exports.colors.length];\n\t\t}\n\n\t\t/**\n\t\t * Create a debugger with the given `namespace`.\n\t\t *\n\t\t * @param {String} namespace\n\t\t * @return {Function}\n\t\t * @api public\n\t\t */\n\n\t\tfunction createDebug(namespace) {\n\n\t\t  function debug() {\n\t\t    // disabled?\n\t\t    if (!debug.enabled) return;\n\n\t\t    var self = debug;\n\n\t\t    // set `diff` timestamp\n\t\t    var curr = +new Date();\n\t\t    var ms = curr - (prevTime || curr);\n\t\t    self.diff = ms;\n\t\t    self.prev = prevTime;\n\t\t    self.curr = curr;\n\t\t    prevTime = curr;\n\n\t\t    // turn the `arguments` into a proper Array\n\t\t    var args = new Array(arguments.length);\n\t\t    for (var i = 0; i < args.length; i++) {\n\t\t      args[i] = arguments[i];\n\t\t    }\n\n\t\t    args[0] = exports.coerce(args[0]);\n\n\t\t    if ('string' !== typeof args[0]) {\n\t\t      // anything else let's inspect with %O\n\t\t      args.unshift('%O');\n\t\t    }\n\n\t\t    // apply any `formatters` transformations\n\t\t    var index = 0;\n\t\t    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n\t\t      // if we encounter an escaped % then don't increase the array index\n\t\t      if (match === '%%') return match;\n\t\t      index++;\n\t\t      var formatter = exports.formatters[format];\n\t\t      if ('function' === typeof formatter) {\n\t\t        var val = args[index];\n\t\t        match = formatter.call(self, val);\n\n\t\t        // now we need to remove `args[index]` since it's inlined in the `format`\n\t\t        args.splice(index, 1);\n\t\t        index--;\n\t\t      }\n\t\t      return match;\n\t\t    });\n\n\t\t    // apply env-specific formatting (colors, etc.)\n\t\t    exports.formatArgs.call(self, args);\n\n\t\t    var logFn = debug.log || exports.log || console.log.bind(console);\n\t\t    logFn.apply(self, args);\n\t\t  }\n\n\t\t  debug.namespace = namespace;\n\t\t  debug.enabled = exports.enabled(namespace);\n\t\t  debug.useColors = exports.useColors();\n\t\t  debug.color = selectColor(namespace);\n\n\t\t  // env-specific initialization logic for debug instances\n\t\t  if ('function' === typeof exports.init) {\n\t\t    exports.init(debug);\n\t\t  }\n\n\t\t  return debug;\n\t\t}\n\n\t\t/**\n\t\t * Enables a debug mode by namespaces. This can include modes\n\t\t * separated by a colon and wildcards.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api public\n\t\t */\n\n\t\tfunction enable(namespaces) {\n\t\t  exports.save(namespaces);\n\n\t\t  exports.names = [];\n\t\t  exports.skips = [];\n\n\t\t  var split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\t  var len = split.length;\n\n\t\t  for (var i = 0; i < len; i++) {\n\t\t    if (!split[i]) continue; // ignore empty strings\n\t\t    namespaces = split[i].replace(/\\*/g, '.*?');\n\t\t    if (namespaces[0] === '-') {\n\t\t      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n\t\t    } else {\n\t\t      exports.names.push(new RegExp('^' + namespaces + '$'));\n\t\t    }\n\t\t  }\n\t\t}\n\n\t\t/**\n\t\t * Disable debug output.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction disable() {\n\t\t  exports.enable('');\n\t\t}\n\n\t\t/**\n\t\t * Returns true if the given mode name is enabled, false otherwise.\n\t\t *\n\t\t * @param {String} name\n\t\t * @return {Boolean}\n\t\t * @api public\n\t\t */\n\n\t\tfunction enabled(name) {\n\t\t  var i, len;\n\t\t  for (i = 0, len = exports.skips.length; i < len; i++) {\n\t\t    if (exports.skips[i].test(name)) {\n\t\t      return false;\n\t\t    }\n\t\t  }\n\t\t  for (i = 0, len = exports.names.length; i < len; i++) {\n\t\t    if (exports.names[i].test(name)) {\n\t\t      return true;\n\t\t    }\n\t\t  }\n\t\t  return false;\n\t\t}\n\n\t\t/**\n\t\t * Coerce `val`.\n\t\t *\n\t\t * @param {Mixed} val\n\t\t * @return {Mixed}\n\t\t * @api private\n\t\t */\n\n\t\tfunction coerce(val) {\n\t\t  if (val instanceof Error) return val.stack || val.message;\n\t\t  return val;\n\t\t}\n} (debug$6, debugExports));\n\treturn debugExports;\n}\n\n/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nvar hasRequiredBrowser;\n\nfunction requireBrowser () {\n\tif (hasRequiredBrowser) return browserExports;\n\thasRequiredBrowser = 1;\n\t(function (module, exports) {\n\t\texports = module.exports = requireDebug();\n\t\texports.log = log;\n\t\texports.formatArgs = formatArgs;\n\t\texports.save = save;\n\t\texports.load = load;\n\t\texports.useColors = useColors;\n\t\texports.storage = 'undefined' != typeof chrome\n\t\t               && 'undefined' != typeof chrome.storage\n\t\t                  ? chrome.storage.local\n\t\t                  : localstorage();\n\n\t\t/**\n\t\t * Colors.\n\t\t */\n\n\t\texports.colors = [\n\t\t  'lightseagreen',\n\t\t  'forestgreen',\n\t\t  'goldenrod',\n\t\t  'dodgerblue',\n\t\t  'darkorchid',\n\t\t  'crimson'\n\t\t];\n\n\t\t/**\n\t\t * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n\t\t * and the Firebug extension (any Firefox version) are known\n\t\t * to support \"%c\" CSS customizations.\n\t\t *\n\t\t * TODO: add a `localStorage` variable to explicitly enable/disable colors\n\t\t */\n\n\t\tfunction useColors() {\n\t\t  // NB: In an Electron preload script, document will be defined but not fully\n\t\t  // initialized. Since we know we're in Chrome, we'll just detect this case\n\t\t  // explicitly\n\t\t  if (typeof window !== 'undefined' && window.process && window.process.type === 'renderer') {\n\t\t    return true;\n\t\t  }\n\n\t\t  // is webkit? http://stackoverflow.com/a/16459606/376773\n\t\t  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\t\t  return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t    // is firebug? http://stackoverflow.com/a/398120/376773\n\t\t    (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t    // is firefox >= v31?\n\t\t    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t    // double check webkit in userAgent just in case we are in a worker\n\t\t    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n\t\t}\n\n\t\t/**\n\t\t * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n\t\t */\n\n\t\texports.formatters.j = function(v) {\n\t\t  try {\n\t\t    return JSON.stringify(v);\n\t\t  } catch (err) {\n\t\t    return '[UnexpectedJSONParseError]: ' + err.message;\n\t\t  }\n\t\t};\n\n\n\t\t/**\n\t\t * Colorize log arguments if enabled.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction formatArgs(args) {\n\t\t  var useColors = this.useColors;\n\n\t\t  args[0] = (useColors ? '%c' : '')\n\t\t    + this.namespace\n\t\t    + (useColors ? ' %c' : ' ')\n\t\t    + args[0]\n\t\t    + (useColors ? '%c ' : ' ')\n\t\t    + '+' + exports.humanize(this.diff);\n\n\t\t  if (!useColors) return;\n\n\t\t  var c = 'color: ' + this.color;\n\t\t  args.splice(1, 0, c, 'color: inherit');\n\n\t\t  // the final \"%c\" is somewhat tricky, because there could be other\n\t\t  // arguments passed either before or after the %c, so we need to\n\t\t  // figure out the correct index to insert the CSS into\n\t\t  var index = 0;\n\t\t  var lastC = 0;\n\t\t  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n\t\t    if ('%%' === match) return;\n\t\t    index++;\n\t\t    if ('%c' === match) {\n\t\t      // we only are interested in the *last* %c\n\t\t      // (the user may have provided their own)\n\t\t      lastC = index;\n\t\t    }\n\t\t  });\n\n\t\t  args.splice(lastC, 0, c);\n\t\t}\n\n\t\t/**\n\t\t * Invokes `console.log()` when available.\n\t\t * No-op when `console.log` is not a \"function\".\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction log() {\n\t\t  // this hackery is required for IE8/9, where\n\t\t  // the `console.log` function doesn't have 'apply'\n\t\t  return 'object' === typeof console\n\t\t    && console.log\n\t\t    && Function.prototype.apply.call(console.log, console, arguments);\n\t\t}\n\n\t\t/**\n\t\t * Save `namespaces`.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api private\n\t\t */\n\n\t\tfunction save(namespaces) {\n\t\t  try {\n\t\t    if (null == namespaces) {\n\t\t      exports.storage.removeItem('debug');\n\t\t    } else {\n\t\t      exports.storage.debug = namespaces;\n\t\t    }\n\t\t  } catch(e) {}\n\t\t}\n\n\t\t/**\n\t\t * Load `namespaces`.\n\t\t *\n\t\t * @return {String} returns the previously persisted debug modes\n\t\t * @api private\n\t\t */\n\n\t\tfunction load() {\n\t\t  var r;\n\t\t  try {\n\t\t    r = exports.storage.debug;\n\t\t  } catch(e) {}\n\n\t\t  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\t\t  if (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\t    r = process.env.DEBUG;\n\t\t  }\n\n\t\t  return r;\n\t\t}\n\n\t\t/**\n\t\t * Enable namespaces listed in `localStorage.debug` initially.\n\t\t */\n\n\t\texports.enable(load());\n\n\t\t/**\n\t\t * Localstorage attempts to return the localstorage.\n\t\t *\n\t\t * This is necessary because safari throws\n\t\t * when a user disables cookies/localstorage\n\t\t * and you attempt to access it.\n\t\t *\n\t\t * @return {LocalStorage}\n\t\t * @api private\n\t\t */\n\n\t\tfunction localstorage() {\n\t\t  try {\n\t\t    return window.localStorage;\n\t\t  } catch (e) {}\n\t\t}\n} (browser, browserExports));\n\treturn browserExports;\n}\n\nvar nodeExports = {};\nvar node = {\n  get exports(){ return nodeExports; },\n  set exports(v){ nodeExports = v; },\n};\n\n/**\n * Module dependencies.\n */\n\nvar hasRequiredNode;\n\nfunction requireNode () {\n\tif (hasRequiredNode) return nodeExports;\n\thasRequiredNode = 1;\n\t(function (module, exports) {\n\t\tvar tty = require$$0$3;\n\t\tvar util = require$$0$6;\n\n\t\t/**\n\t\t * This is the Node.js implementation of `debug()`.\n\t\t *\n\t\t * Expose `debug()` as the module.\n\t\t */\n\n\t\texports = module.exports = requireDebug();\n\t\texports.init = init;\n\t\texports.log = log;\n\t\texports.formatArgs = formatArgs;\n\t\texports.save = save;\n\t\texports.load = load;\n\t\texports.useColors = useColors;\n\n\t\t/**\n\t\t * Colors.\n\t\t */\n\n\t\texports.colors = [6, 2, 3, 4, 5, 1];\n\n\t\t/**\n\t\t * Build up the default `inspectOpts` object from the environment variables.\n\t\t *\n\t\t *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n\t\t */\n\n\t\texports.inspectOpts = Object.keys(process.env).filter(function (key) {\n\t\t  return /^debug_/i.test(key);\n\t\t}).reduce(function (obj, key) {\n\t\t  // camel-case\n\t\t  var prop = key\n\t\t    .substring(6)\n\t\t    .toLowerCase()\n\t\t    .replace(/_([a-z])/g, function (_, k) { return k.toUpperCase() });\n\n\t\t  // coerce string value into JS value\n\t\t  var val = process.env[key];\n\t\t  if (/^(yes|on|true|enabled)$/i.test(val)) val = true;\n\t\t  else if (/^(no|off|false|disabled)$/i.test(val)) val = false;\n\t\t  else if (val === 'null') val = null;\n\t\t  else val = Number(val);\n\n\t\t  obj[prop] = val;\n\t\t  return obj;\n\t\t}, {});\n\n\t\t/**\n\t\t * The file descriptor to write the `debug()` calls to.\n\t\t * Set the `DEBUG_FD` env variable to override with another value. i.e.:\n\t\t *\n\t\t *   $ DEBUG_FD=3 node script.js 3>debug.log\n\t\t */\n\n\t\tvar fd = parseInt(process.env.DEBUG_FD, 10) || 2;\n\n\t\tif (1 !== fd && 2 !== fd) {\n\t\t  util.deprecate(function(){}, 'except for stderr(2) and stdout(1), any other usage of DEBUG_FD is deprecated. Override debug.log if you want to use a different log function (https://git.io/debug_fd)')();\n\t\t}\n\n\t\tvar stream = 1 === fd ? process.stdout :\n\t\t             2 === fd ? process.stderr :\n\t\t             createWritableStdioStream(fd);\n\n\t\t/**\n\t\t * Is stdout a TTY? Colored output is enabled when `true`.\n\t\t */\n\n\t\tfunction useColors() {\n\t\t  return 'colors' in exports.inspectOpts\n\t\t    ? Boolean(exports.inspectOpts.colors)\n\t\t    : tty.isatty(fd);\n\t\t}\n\n\t\t/**\n\t\t * Map %o to `util.inspect()`, all on a single line.\n\t\t */\n\n\t\texports.formatters.o = function(v) {\n\t\t  this.inspectOpts.colors = this.useColors;\n\t\t  return util.inspect(v, this.inspectOpts)\n\t\t    .split('\\n').map(function(str) {\n\t\t      return str.trim()\n\t\t    }).join(' ');\n\t\t};\n\n\t\t/**\n\t\t * Map %o to `util.inspect()`, allowing multiple lines if needed.\n\t\t */\n\n\t\texports.formatters.O = function(v) {\n\t\t  this.inspectOpts.colors = this.useColors;\n\t\t  return util.inspect(v, this.inspectOpts);\n\t\t};\n\n\t\t/**\n\t\t * Adds ANSI color escape codes if enabled.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction formatArgs(args) {\n\t\t  var name = this.namespace;\n\t\t  var useColors = this.useColors;\n\n\t\t  if (useColors) {\n\t\t    var c = this.color;\n\t\t    var prefix = '  \\u001b[3' + c + ';1m' + name + ' ' + '\\u001b[0m';\n\n\t\t    args[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n\t\t    args.push('\\u001b[3' + c + 'm+' + exports.humanize(this.diff) + '\\u001b[0m');\n\t\t  } else {\n\t\t    args[0] = new Date().toUTCString()\n\t\t      + ' ' + name + ' ' + args[0];\n\t\t  }\n\t\t}\n\n\t\t/**\n\t\t * Invokes `util.format()` with the specified arguments and writes to `stream`.\n\t\t */\n\n\t\tfunction log() {\n\t\t  return stream.write(util.format.apply(util, arguments) + '\\n');\n\t\t}\n\n\t\t/**\n\t\t * Save `namespaces`.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api private\n\t\t */\n\n\t\tfunction save(namespaces) {\n\t\t  if (null == namespaces) {\n\t\t    // If you set a process.env field to null or undefined, it gets cast to the\n\t\t    // string 'null' or 'undefined'. Just delete instead.\n\t\t    delete process.env.DEBUG;\n\t\t  } else {\n\t\t    process.env.DEBUG = namespaces;\n\t\t  }\n\t\t}\n\n\t\t/**\n\t\t * Load `namespaces`.\n\t\t *\n\t\t * @return {String} returns the previously persisted debug modes\n\t\t * @api private\n\t\t */\n\n\t\tfunction load() {\n\t\t  return process.env.DEBUG;\n\t\t}\n\n\t\t/**\n\t\t * Copied from `node/src/node.js`.\n\t\t *\n\t\t * XXX: It's lame that node doesn't expose this API out-of-the-box. It also\n\t\t * relies on the undocumented `tty_wrap.guessHandleType()` which is also lame.\n\t\t */\n\n\t\tfunction createWritableStdioStream (fd) {\n\t\t  var stream;\n\t\t  var tty_wrap = process.binding('tty_wrap');\n\n\t\t  // Note stream._type is used for test-module-load-list.js\n\n\t\t  switch (tty_wrap.guessHandleType(fd)) {\n\t\t    case 'TTY':\n\t\t      stream = new tty.WriteStream(fd);\n\t\t      stream._type = 'tty';\n\n\t\t      // Hack to have stream not keep the event loop alive.\n\t\t      // See https://github.com/joyent/node/issues/1726\n\t\t      if (stream._handle && stream._handle.unref) {\n\t\t        stream._handle.unref();\n\t\t      }\n\t\t      break;\n\n\t\t    case 'FILE':\n\t\t      var fs = require$$0__default;\n\t\t      stream = new fs.SyncWriteStream(fd, { autoClose: false });\n\t\t      stream._type = 'fs';\n\t\t      break;\n\n\t\t    case 'PIPE':\n\t\t    case 'TCP':\n\t\t      var net = require$$3$2;\n\t\t      stream = new net.Socket({\n\t\t        fd: fd,\n\t\t        readable: false,\n\t\t        writable: true\n\t\t      });\n\n\t\t      // FIXME Should probably have an option in net.Socket to create a\n\t\t      // stream from an existing fd which is writable only. But for now\n\t\t      // we'll just add this hack and set the `readable` member to false.\n\t\t      // Test: ./node test/fixtures/echo.js < /etc/passwd\n\t\t      stream.readable = false;\n\t\t      stream.read = null;\n\t\t      stream._type = 'pipe';\n\n\t\t      // FIXME Hack to have stream not keep the event loop alive.\n\t\t      // See https://github.com/joyent/node/issues/1726\n\t\t      if (stream._handle && stream._handle.unref) {\n\t\t        stream._handle.unref();\n\t\t      }\n\t\t      break;\n\n\t\t    default:\n\t\t      // Probably an error on in uv_guess_handle()\n\t\t      throw new Error('Implement me. Unknown stream file type!');\n\t\t  }\n\n\t\t  // For supporting legacy API we put the FD here.\n\t\t  stream.fd = fd;\n\n\t\t  stream._isStdio = true;\n\n\t\t  return stream;\n\t\t}\n\n\t\t/**\n\t\t * Init logic for `debug` instances.\n\t\t *\n\t\t * Create a new `inspectOpts` object in case `useColors` is set\n\t\t * differently for a particular `debug` instance.\n\t\t */\n\n\t\tfunction init (debug) {\n\t\t  debug.inspectOpts = {};\n\n\t\t  var keys = Object.keys(exports.inspectOpts);\n\t\t  for (var i = 0; i < keys.length; i++) {\n\t\t    debug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];\n\t\t  }\n\t\t}\n\n\t\t/**\n\t\t * Enable namespaces listed in `process.env.DEBUG` initially.\n\t\t */\n\n\t\texports.enable(load());\n} (node, nodeExports));\n\treturn nodeExports;\n}\n\n/**\n * Detect Electron renderer process, which is node, but we should\n * treat as a browser.\n */\n\n(function (module) {\n\tif (typeof process !== 'undefined' && process.type === 'renderer') {\n\t  module.exports = requireBrowser();\n\t} else {\n\t  module.exports = requireNode();\n\t}\n} (src));\n\n/*!\n * encodeurl\n * Copyright(c) 2016 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module exports.\n * @public\n */\n\nvar encodeurl = encodeUrl$1;\n\n/**\n * RegExp to match non-URL code points, *after* encoding (i.e. not including \"%\")\n * and including invalid escape sequences.\n * @private\n */\n\nvar ENCODE_CHARS_REGEXP = /(?:[^\\x21\\x25\\x26-\\x3B\\x3D\\x3F-\\x5B\\x5D\\x5F\\x61-\\x7A\\x7E]|%(?:[^0-9A-Fa-f]|[0-9A-Fa-f][^0-9A-Fa-f]|$))+/g;\n\n/**\n * RegExp to match unmatched surrogate pair.\n * @private\n */\n\nvar UNMATCHED_SURROGATE_PAIR_REGEXP = /(^|[^\\uD800-\\uDBFF])[\\uDC00-\\uDFFF]|[\\uD800-\\uDBFF]([^\\uDC00-\\uDFFF]|$)/g;\n\n/**\n * String to replace unmatched surrogate pair with.\n * @private\n */\n\nvar UNMATCHED_SURROGATE_PAIR_REPLACE = '$1\\uFFFD$2';\n\n/**\n * Encode a URL to a percent-encoded form, excluding already-encoded sequences.\n *\n * This function will take an already-encoded URL and encode all the non-URL\n * code points. This function will not encode the \"%\" character unless it is\n * not part of a valid sequence (`%20` will be left as-is, but `%foo` will\n * be encoded as `%25foo`).\n *\n * This encode is meant to be \"safe\" and does not throw errors. It will try as\n * hard as it can to properly encode the given URL, including replacing any raw,\n * unpaired surrogate pairs with the Unicode replacement character prior to\n * encoding.\n *\n * @param {string} url\n * @return {string}\n * @public\n */\n\nfunction encodeUrl$1 (url) {\n  return String(url)\n    .replace(UNMATCHED_SURROGATE_PAIR_REGEXP, UNMATCHED_SURROGATE_PAIR_REPLACE)\n    .replace(ENCODE_CHARS_REGEXP, encodeURI)\n}\n\n/*!\n * escape-html\n * Copyright(c) 2012-2013 TJ Holowaychuk\n * Copyright(c) 2015 Andreas Lubbe\n * Copyright(c) 2015 Tiancheng \"Timothy\" Gu\n * MIT Licensed\n */\n\n/**\n * Module variables.\n * @private\n */\n\nvar matchHtmlRegExp = /[\"'&<>]/;\n\n/**\n * Module exports.\n * @public\n */\n\nvar escapeHtml_1 = escapeHtml$1;\n\n/**\n * Escape special characters in the given string of html.\n *\n * @param  {string} string The string to escape for inserting into HTML\n * @return {string}\n * @public\n */\n\nfunction escapeHtml$1(string) {\n  var str = '' + string;\n  var match = matchHtmlRegExp.exec(str);\n\n  if (!match) {\n    return str;\n  }\n\n  var escape;\n  var html = '';\n  var index = 0;\n  var lastIndex = 0;\n\n  for (index = match.index; index < str.length; index++) {\n    switch (str.charCodeAt(index)) {\n      case 34: // \"\n        escape = '&quot;';\n        break;\n      case 38: // &\n        escape = '&amp;';\n        break;\n      case 39: // '\n        escape = '&#39;';\n        break;\n      case 60: // <\n        escape = '&lt;';\n        break;\n      case 62: // >\n        escape = '&gt;';\n        break;\n      default:\n        continue;\n    }\n\n    if (lastIndex !== index) {\n      html += str.substring(lastIndex, index);\n    }\n\n    lastIndex = index + 1;\n    html += escape;\n  }\n\n  return lastIndex !== index\n    ? html + str.substring(lastIndex, index)\n    : html;\n}\n\nvar onFinishedExports = {};\nvar onFinished$2 = {\n  get exports(){ return onFinishedExports; },\n  set exports(v){ onFinishedExports = v; },\n};\n\n/*!\n * ee-first\n * Copyright(c) 2014 Jonathan Ong\n * MIT Licensed\n */\n\n/**\n * Module exports.\n * @public\n */\n\nvar eeFirst = first$1;\n\n/**\n * Get the first event in a set of event emitters and event pairs.\n *\n * @param {array} stuff\n * @param {function} done\n * @public\n */\n\nfunction first$1(stuff, done) {\n  if (!Array.isArray(stuff))\n    throw new TypeError('arg must be an array of [ee, events...] arrays')\n\n  var cleanups = [];\n\n  for (var i = 0; i < stuff.length; i++) {\n    var arr = stuff[i];\n\n    if (!Array.isArray(arr) || arr.length < 2)\n      throw new TypeError('each array member must be [ee, events...]')\n\n    var ee = arr[0];\n\n    for (var j = 1; j < arr.length; j++) {\n      var event = arr[j];\n      var fn = listener(event, callback);\n\n      // listen to the event\n      ee.on(event, fn);\n      // push this listener to the list of cleanups\n      cleanups.push({\n        ee: ee,\n        event: event,\n        fn: fn,\n      });\n    }\n  }\n\n  function callback() {\n    cleanup();\n    done.apply(null, arguments);\n  }\n\n  function cleanup() {\n    var x;\n    for (var i = 0; i < cleanups.length; i++) {\n      x = cleanups[i];\n      x.ee.removeListener(x.event, x.fn);\n    }\n  }\n\n  function thunk(fn) {\n    done = fn;\n  }\n\n  thunk.cancel = cleanup;\n\n  return thunk\n}\n\n/**\n * Create the event listener.\n * @private\n */\n\nfunction listener(event, done) {\n  return function onevent(arg1) {\n    var args = new Array(arguments.length);\n    var ee = this;\n    var err = event === 'error'\n      ? arg1\n      : null;\n\n    // copy args to prevent arguments escaping scope\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    done(err, ee, event, args);\n  }\n}\n\n/*!\n * on-finished\n * Copyright(c) 2013 Jonathan Ong\n * Copyright(c) 2014 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module exports.\n * @public\n */\n\nonFinished$2.exports = onFinished$1;\nonFinishedExports.isFinished = isFinished$1;\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar first = eeFirst;\n\n/**\n * Variables.\n * @private\n */\n\n/* istanbul ignore next */\nvar defer$2 = typeof setImmediate === 'function'\n  ? setImmediate\n  : function(fn){ process.nextTick(fn.bind.apply(fn, arguments)); };\n\n/**\n * Invoke callback when the response has finished, useful for\n * cleaning up resources afterwards.\n *\n * @param {object} msg\n * @param {function} listener\n * @return {object}\n * @public\n */\n\nfunction onFinished$1(msg, listener) {\n  if (isFinished$1(msg) !== false) {\n    defer$2(listener, null, msg);\n    return msg\n  }\n\n  // attach the listener to the message\n  attachListener(msg, listener);\n\n  return msg\n}\n\n/**\n * Determine if message is already finished.\n *\n * @param {object} msg\n * @return {boolean}\n * @public\n */\n\nfunction isFinished$1(msg) {\n  var socket = msg.socket;\n\n  if (typeof msg.finished === 'boolean') {\n    // OutgoingMessage\n    return Boolean(msg.finished || (socket && !socket.writable))\n  }\n\n  if (typeof msg.complete === 'boolean') {\n    // IncomingMessage\n    return Boolean(msg.upgrade || !socket || !socket.readable || (msg.complete && !msg.readable))\n  }\n\n  // don't know\n  return undefined\n}\n\n/**\n * Attach a finished listener to the message.\n *\n * @param {object} msg\n * @param {function} callback\n * @private\n */\n\nfunction attachFinishedListener(msg, callback) {\n  var eeMsg;\n  var eeSocket;\n  var finished = false;\n\n  function onFinish(error) {\n    eeMsg.cancel();\n    eeSocket.cancel();\n\n    finished = true;\n    callback(error);\n  }\n\n  // finished on first message event\n  eeMsg = eeSocket = first([[msg, 'end', 'finish']], onFinish);\n\n  function onSocket(socket) {\n    // remove listener\n    msg.removeListener('socket', onSocket);\n\n    if (finished) return\n    if (eeMsg !== eeSocket) return\n\n    // finished on first socket event\n    eeSocket = first([[socket, 'error', 'close']], onFinish);\n  }\n\n  if (msg.socket) {\n    // socket already assigned\n    onSocket(msg.socket);\n    return\n  }\n\n  // wait for socket to be assigned\n  msg.on('socket', onSocket);\n\n  if (msg.socket === undefined) {\n    // node.js 0.8 patch\n    patchAssignSocket(msg, onSocket);\n  }\n}\n\n/**\n * Attach the listener to the message.\n *\n * @param {object} msg\n * @return {function}\n * @private\n */\n\nfunction attachListener(msg, listener) {\n  var attached = msg.__onFinished;\n\n  // create a private single listener with queue\n  if (!attached || !attached.queue) {\n    attached = msg.__onFinished = createListener(msg);\n    attachFinishedListener(msg, attached);\n  }\n\n  attached.queue.push(listener);\n}\n\n/**\n * Create listener on message.\n *\n * @param {object} msg\n * @return {function}\n * @private\n */\n\nfunction createListener(msg) {\n  function listener(err) {\n    if (msg.__onFinished === listener) msg.__onFinished = null;\n    if (!listener.queue) return\n\n    var queue = listener.queue;\n    listener.queue = null;\n\n    for (var i = 0; i < queue.length; i++) {\n      queue[i](err, msg);\n    }\n  }\n\n  listener.queue = [];\n\n  return listener\n}\n\n/**\n * Patch ServerResponse.prototype.assignSocket for node.js 0.8.\n *\n * @param {ServerResponse} res\n * @param {function} callback\n * @private\n */\n\nfunction patchAssignSocket(res, callback) {\n  var assignSocket = res.assignSocket;\n\n  if (typeof assignSocket !== 'function') return\n\n  // res.on('socket', callback) is broken in 0.8\n  res.assignSocket = function _assignSocket(socket) {\n    assignSocket.call(this, socket);\n    callback(socket);\n  };\n}\n\nvar parseurlExports = {};\nvar parseurl$1 = {\n  get exports(){ return parseurlExports; },\n  set exports(v){ parseurlExports = v; },\n};\n\n/*!\n * parseurl\n * Copyright(c) 2014 Jonathan Ong\n * Copyright(c) 2014-2017 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar url$3 = require$$0$9;\nvar parse$7 = url$3.parse;\nvar Url = url$3.Url;\n\n/**\n * Module exports.\n * @public\n */\n\nparseurl$1.exports = parseurl;\nparseurlExports.original = originalurl;\n\n/**\n * Parse the `req` url with memoization.\n *\n * @param {ServerRequest} req\n * @return {Object}\n * @public\n */\n\nfunction parseurl (req) {\n  var url = req.url;\n\n  if (url === undefined) {\n    // URL is undefined\n    return undefined\n  }\n\n  var parsed = req._parsedUrl;\n\n  if (fresh(url, parsed)) {\n    // Return cached URL parse\n    return parsed\n  }\n\n  // Parse the URL\n  parsed = fastparse(url);\n  parsed._raw = url;\n\n  return (req._parsedUrl = parsed)\n}\n/**\n * Parse the `req` original url with fallback and memoization.\n *\n * @param {ServerRequest} req\n * @return {Object}\n * @public\n */\n\nfunction originalurl (req) {\n  var url = req.originalUrl;\n\n  if (typeof url !== 'string') {\n    // Fallback\n    return parseurl(req)\n  }\n\n  var parsed = req._parsedOriginalUrl;\n\n  if (fresh(url, parsed)) {\n    // Return cached URL parse\n    return parsed\n  }\n\n  // Parse the URL\n  parsed = fastparse(url);\n  parsed._raw = url;\n\n  return (req._parsedOriginalUrl = parsed)\n}\n/**\n * Parse the `str` url with fast-path short-cut.\n *\n * @param {string} str\n * @return {Object}\n * @private\n */\n\nfunction fastparse (str) {\n  if (typeof str !== 'string' || str.charCodeAt(0) !== 0x2f /* / */) {\n    return parse$7(str)\n  }\n\n  var pathname = str;\n  var query = null;\n  var search = null;\n\n  // This takes the regexp from https://github.com/joyent/node/pull/7878\n  // Which is /^(\\/[^?#\\s]*)(\\?[^#\\s]*)?$/\n  // And unrolls it into a for loop\n  for (var i = 1; i < str.length; i++) {\n    switch (str.charCodeAt(i)) {\n      case 0x3f: /* ?  */\n        if (search === null) {\n          pathname = str.substring(0, i);\n          query = str.substring(i + 1);\n          search = str.substring(i);\n        }\n        break\n      case 0x09: /* \\t */\n      case 0x0a: /* \\n */\n      case 0x0c: /* \\f */\n      case 0x0d: /* \\r */\n      case 0x20: /*    */\n      case 0x23: /* #  */\n      case 0xa0:\n      case 0xfeff:\n        return parse$7(str)\n    }\n  }\n\n  var url = Url !== undefined\n    ? new Url()\n    : {};\n\n  url.path = str;\n  url.href = str;\n  url.pathname = pathname;\n\n  if (search !== null) {\n    url.query = query;\n    url.search = search;\n  }\n\n  return url\n}\n\n/**\n * Determine if parsed is still fresh for url.\n *\n * @param {string} url\n * @param {object} parsedUrl\n * @return {boolean}\n * @private\n */\n\nfunction fresh (url, parsedUrl) {\n  return typeof parsedUrl === 'object' &&\n    parsedUrl !== null &&\n    (Url === undefined || parsedUrl instanceof Url) &&\n    parsedUrl._raw === url\n}\n\nvar require$$0$1 = {\n\t\"100\": \"Continue\",\n\t\"101\": \"Switching Protocols\",\n\t\"102\": \"Processing\",\n\t\"103\": \"Early Hints\",\n\t\"200\": \"OK\",\n\t\"201\": \"Created\",\n\t\"202\": \"Accepted\",\n\t\"203\": \"Non-Authoritative Information\",\n\t\"204\": \"No Content\",\n\t\"205\": \"Reset Content\",\n\t\"206\": \"Partial Content\",\n\t\"207\": \"Multi-Status\",\n\t\"208\": \"Already Reported\",\n\t\"226\": \"IM Used\",\n\t\"300\": \"Multiple Choices\",\n\t\"301\": \"Moved Permanently\",\n\t\"302\": \"Found\",\n\t\"303\": \"See Other\",\n\t\"304\": \"Not Modified\",\n\t\"305\": \"Use Proxy\",\n\t\"306\": \"(Unused)\",\n\t\"307\": \"Temporary Redirect\",\n\t\"308\": \"Permanent Redirect\",\n\t\"400\": \"Bad Request\",\n\t\"401\": \"Unauthorized\",\n\t\"402\": \"Payment Required\",\n\t\"403\": \"Forbidden\",\n\t\"404\": \"Not Found\",\n\t\"405\": \"Method Not Allowed\",\n\t\"406\": \"Not Acceptable\",\n\t\"407\": \"Proxy Authentication Required\",\n\t\"408\": \"Request Timeout\",\n\t\"409\": \"Conflict\",\n\t\"410\": \"Gone\",\n\t\"411\": \"Length Required\",\n\t\"412\": \"Precondition Failed\",\n\t\"413\": \"Payload Too Large\",\n\t\"414\": \"URI Too Long\",\n\t\"415\": \"Unsupported Media Type\",\n\t\"416\": \"Range Not Satisfiable\",\n\t\"417\": \"Expectation Failed\",\n\t\"418\": \"I'm a teapot\",\n\t\"421\": \"Misdirected Request\",\n\t\"422\": \"Unprocessable Entity\",\n\t\"423\": \"Locked\",\n\t\"424\": \"Failed Dependency\",\n\t\"425\": \"Unordered Collection\",\n\t\"426\": \"Upgrade Required\",\n\t\"428\": \"Precondition Required\",\n\t\"429\": \"Too Many Requests\",\n\t\"431\": \"Request Header Fields Too Large\",\n\t\"451\": \"Unavailable For Legal Reasons\",\n\t\"500\": \"Internal Server Error\",\n\t\"501\": \"Not Implemented\",\n\t\"502\": \"Bad Gateway\",\n\t\"503\": \"Service Unavailable\",\n\t\"504\": \"Gateway Timeout\",\n\t\"505\": \"HTTP Version Not Supported\",\n\t\"506\": \"Variant Also Negotiates\",\n\t\"507\": \"Insufficient Storage\",\n\t\"508\": \"Loop Detected\",\n\t\"509\": \"Bandwidth Limit Exceeded\",\n\t\"510\": \"Not Extended\",\n\t\"511\": \"Network Authentication Required\"\n};\n\n/*!\n * statuses\n * Copyright(c) 2014 Jonathan Ong\n * Copyright(c) 2016 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar codes = require$$0$1;\n\n/**\n * Module exports.\n * @public\n */\n\nvar statuses$1 = status;\n\n// status code to message map\nstatus.STATUS_CODES = codes;\n\n// array of status codes\nstatus.codes = populateStatusesMap(status, codes);\n\n// status codes for redirects\nstatus.redirect = {\n  300: true,\n  301: true,\n  302: true,\n  303: true,\n  305: true,\n  307: true,\n  308: true\n};\n\n// status codes for empty bodies\nstatus.empty = {\n  204: true,\n  205: true,\n  304: true\n};\n\n// status codes for when you should retry the request\nstatus.retry = {\n  502: true,\n  503: true,\n  504: true\n};\n\n/**\n * Populate the statuses map for given codes.\n * @private\n */\n\nfunction populateStatusesMap (statuses, codes) {\n  var arr = [];\n\n  Object.keys(codes).forEach(function forEachCode (code) {\n    var message = codes[code];\n    var status = Number(code);\n\n    // Populate properties\n    statuses[status] = message;\n    statuses[message] = status;\n    statuses[message.toLowerCase()] = status;\n\n    // Add to array\n    arr.push(status);\n  });\n\n  return arr\n}\n\n/**\n * Get the status code.\n *\n * Given a number, this will throw if it is not a known status\n * code, otherwise the code will be returned. Given a string,\n * the string will be parsed for a number and return the code\n * if valid, otherwise will lookup the code assuming this is\n * the status message.\n *\n * @param {string|number} code\n * @returns {number}\n * @public\n */\n\nfunction status (code) {\n  if (typeof code === 'number') {\n    if (!status[code]) throw new Error('invalid status code: ' + code)\n    return code\n  }\n\n  if (typeof code !== 'string') {\n    throw new TypeError('code must be a number or string')\n  }\n\n  // '403'\n  var n = parseInt(code, 10);\n  if (!isNaN(n)) {\n    if (!status[n]) throw new Error('invalid status code: ' + n)\n    return n\n  }\n\n  n = status[code.toLowerCase()];\n  if (!n) throw new Error('invalid status message: \"' + code + '\"')\n  return n\n}\n\n/*!\n * unpipe\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module exports.\n * @public\n */\n\nvar unpipe_1 = unpipe$1;\n\n/**\n * Determine if there are Node.js pipe-like data listeners.\n * @private\n */\n\nfunction hasPipeDataListeners(stream) {\n  var listeners = stream.listeners('data');\n\n  for (var i = 0; i < listeners.length; i++) {\n    if (listeners[i].name === 'ondata') {\n      return true\n    }\n  }\n\n  return false\n}\n\n/**\n * Unpipe a stream from all destinations.\n *\n * @param {object} stream\n * @public\n */\n\nfunction unpipe$1(stream) {\n  if (!stream) {\n    throw new TypeError('argument stream is required')\n  }\n\n  if (typeof stream.unpipe === 'function') {\n    // new-style\n    stream.unpipe();\n    return\n  }\n\n  // Node.js 0.8 hack\n  if (!hasPipeDataListeners(stream)) {\n    return\n  }\n\n  var listener;\n  var listeners = stream.listeners('close');\n\n  for (var i = 0; i < listeners.length; i++) {\n    listener = listeners[i];\n\n    if (listener.name !== 'cleanup' && listener.name !== 'onclose') {\n      continue\n    }\n\n    // invoke the listener\n    listener.call(stream);\n  }\n}\n\n/*!\n * finalhandler\n * Copyright(c) 2014-2017 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar debug$5 = srcExports('finalhandler');\nvar encodeUrl = encodeurl;\nvar escapeHtml = escapeHtml_1;\nvar onFinished = onFinishedExports;\nvar parseUrl$1 = parseurlExports;\nvar statuses = statuses$1;\nvar unpipe = unpipe_1;\n\n/**\n * Module variables.\n * @private\n */\n\nvar DOUBLE_SPACE_REGEXP = /\\x20{2}/g;\nvar NEWLINE_REGEXP = /\\n/g;\n\n/* istanbul ignore next */\nvar defer$1 = typeof setImmediate === 'function'\n  ? setImmediate\n  : function (fn) { process.nextTick(fn.bind.apply(fn, arguments)); };\nvar isFinished = onFinished.isFinished;\n\n/**\n * Create a minimal HTML document.\n *\n * @param {string} message\n * @private\n */\n\nfunction createHtmlDocument (message) {\n  var body = escapeHtml(message)\n    .replace(NEWLINE_REGEXP, '<br>')\n    .replace(DOUBLE_SPACE_REGEXP, ' &nbsp;');\n\n  return '<!DOCTYPE html>\\n' +\n    '<html lang=\"en\">\\n' +\n    '<head>\\n' +\n    '<meta charset=\"utf-8\">\\n' +\n    '<title>Error</title>\\n' +\n    '</head>\\n' +\n    '<body>\\n' +\n    '<pre>' + body + '</pre>\\n' +\n    '</body>\\n' +\n    '</html>\\n'\n}\n\n/**\n * Module exports.\n * @public\n */\n\nvar finalhandler_1 = finalhandler$1;\n\n/**\n * Create a function to handle the final response.\n *\n * @param {Request} req\n * @param {Response} res\n * @param {Object} [options]\n * @return {Function}\n * @public\n */\n\nfunction finalhandler$1 (req, res, options) {\n  var opts = options || {};\n\n  // get environment\n  var env = opts.env || process.env.NODE_ENV || 'development';\n\n  // get error callback\n  var onerror = opts.onerror;\n\n  return function (err) {\n    var headers;\n    var msg;\n    var status;\n\n    // ignore 404 on in-flight response\n    if (!err && headersSent(res)) {\n      debug$5('cannot 404 after headers sent');\n      return\n    }\n\n    // unhandled error\n    if (err) {\n      // respect status code from error\n      status = getErrorStatusCode(err);\n\n      if (status === undefined) {\n        // fallback to status code on response\n        status = getResponseStatusCode(res);\n      } else {\n        // respect headers from error\n        headers = getErrorHeaders(err);\n      }\n\n      // get error message\n      msg = getErrorMessage(err, status, env);\n    } else {\n      // not found\n      status = 404;\n      msg = 'Cannot ' + req.method + ' ' + encodeUrl(getResourceName(req));\n    }\n\n    debug$5('default %s', status);\n\n    // schedule onerror callback\n    if (err && onerror) {\n      defer$1(onerror, err, req, res);\n    }\n\n    // cannot actually respond\n    if (headersSent(res)) {\n      debug$5('cannot %d after headers sent', status);\n      req.socket.destroy();\n      return\n    }\n\n    // send response\n    send(req, res, status, headers, msg);\n  }\n}\n\n/**\n * Get headers from Error object.\n *\n * @param {Error} err\n * @return {object}\n * @private\n */\n\nfunction getErrorHeaders (err) {\n  if (!err.headers || typeof err.headers !== 'object') {\n    return undefined\n  }\n\n  var headers = Object.create(null);\n  var keys = Object.keys(err.headers);\n\n  for (var i = 0; i < keys.length; i++) {\n    var key = keys[i];\n    headers[key] = err.headers[key];\n  }\n\n  return headers\n}\n\n/**\n * Get message from Error object, fallback to status message.\n *\n * @param {Error} err\n * @param {number} status\n * @param {string} env\n * @return {string}\n * @private\n */\n\nfunction getErrorMessage (err, status, env) {\n  var msg;\n\n  if (env !== 'production') {\n    // use err.stack, which typically includes err.message\n    msg = err.stack;\n\n    // fallback to err.toString() when possible\n    if (!msg && typeof err.toString === 'function') {\n      msg = err.toString();\n    }\n  }\n\n  return msg || statuses[status]\n}\n\n/**\n * Get status code from Error object.\n *\n * @param {Error} err\n * @return {number}\n * @private\n */\n\nfunction getErrorStatusCode (err) {\n  // check err.status\n  if (typeof err.status === 'number' && err.status >= 400 && err.status < 600) {\n    return err.status\n  }\n\n  // check err.statusCode\n  if (typeof err.statusCode === 'number' && err.statusCode >= 400 && err.statusCode < 600) {\n    return err.statusCode\n  }\n\n  return undefined\n}\n\n/**\n * Get resource name for the request.\n *\n * This is typically just the original pathname of the request\n * but will fallback to \"resource\" is that cannot be determined.\n *\n * @param {IncomingMessage} req\n * @return {string}\n * @private\n */\n\nfunction getResourceName (req) {\n  try {\n    return parseUrl$1.original(req).pathname\n  } catch (e) {\n    return 'resource'\n  }\n}\n\n/**\n * Get status code from response.\n *\n * @param {OutgoingMessage} res\n * @return {number}\n * @private\n */\n\nfunction getResponseStatusCode (res) {\n  var status = res.statusCode;\n\n  // default status code to 500 if outside valid range\n  if (typeof status !== 'number' || status < 400 || status > 599) {\n    status = 500;\n  }\n\n  return status\n}\n\n/**\n * Determine if the response headers have been sent.\n *\n * @param {object} res\n * @returns {boolean}\n * @private\n */\n\nfunction headersSent (res) {\n  return typeof res.headersSent !== 'boolean'\n    ? Boolean(res._header)\n    : res.headersSent\n}\n\n/**\n * Send response.\n *\n * @param {IncomingMessage} req\n * @param {OutgoingMessage} res\n * @param {number} status\n * @param {object} headers\n * @param {string} message\n * @private\n */\n\nfunction send (req, res, status, headers, message) {\n  function write () {\n    // response body\n    var body = createHtmlDocument(message);\n\n    // response status\n    res.statusCode = status;\n    res.statusMessage = statuses[status];\n\n    // response headers\n    setHeaders(res, headers);\n\n    // security headers\n    res.setHeader('Content-Security-Policy', \"default-src 'none'\");\n    res.setHeader('X-Content-Type-Options', 'nosniff');\n\n    // standard headers\n    res.setHeader('Content-Type', 'text/html; charset=utf-8');\n    res.setHeader('Content-Length', Buffer.byteLength(body, 'utf8'));\n\n    if (req.method === 'HEAD') {\n      res.end();\n      return\n    }\n\n    res.end(body, 'utf8');\n  }\n\n  if (isFinished(req)) {\n    write();\n    return\n  }\n\n  // unpipe everything from the request\n  unpipe(req);\n\n  // flush the request\n  onFinished(req, write);\n  req.resume();\n}\n\n/**\n * Set response headers from an object.\n *\n * @param {OutgoingMessage} res\n * @param {object} headers\n * @private\n */\n\nfunction setHeaders (res, headers) {\n  if (!headers) {\n    return\n  }\n\n  var keys = Object.keys(headers);\n  for (var i = 0; i < keys.length; i++) {\n    var key = keys[i];\n    res.setHeader(key, headers[key]);\n  }\n}\n\nvar utilsMergeExports = {};\nvar utilsMerge = {\n  get exports(){ return utilsMergeExports; },\n  set exports(v){ utilsMergeExports = v; },\n};\n\n/**\n * Merge object b with object a.\n *\n *     var a = { foo: 'bar' }\n *       , b = { bar: 'baz' };\n *\n *     merge(a, b);\n *     // => { foo: 'bar', bar: 'baz' }\n *\n * @param {Object} a\n * @param {Object} b\n * @return {Object}\n * @api public\n */\n\n(function (module, exports) {\n\tmodule.exports = function(a, b){\n\t  if (a && b) {\n\t    for (var key in b) {\n\t      a[key] = b[key];\n\t    }\n\t  }\n\t  return a;\n\t};\n} (utilsMerge));\n\n/*!\n * connect\n * Copyright(c) 2010 Sencha Inc.\n * Copyright(c) 2011 TJ Holowaychuk\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar debug$4 = srcExports('connect:dispatcher');\nvar EventEmitter$3 = require$$0$5.EventEmitter;\nvar finalhandler = finalhandler_1;\nvar http$4 = require$$1$1;\nvar merge = utilsMergeExports;\nvar parseUrl = parseurlExports;\n\n/**\n * Module exports.\n * @public\n */\n\nvar connect = createServer$1;\n\n/**\n * Module variables.\n * @private\n */\n\nvar env = process.env.NODE_ENV || 'development';\nvar proto = {};\n\n/* istanbul ignore next */\nvar defer = typeof setImmediate === 'function'\n  ? setImmediate\n  : function(fn){ process.nextTick(fn.bind.apply(fn, arguments)); };\n\n/**\n * Create a new connect server.\n *\n * @return {function}\n * @public\n */\n\nfunction createServer$1() {\n  function app(req, res, next){ app.handle(req, res, next); }\n  merge(app, proto);\n  merge(app, EventEmitter$3.prototype);\n  app.route = '/';\n  app.stack = [];\n  return app;\n}\n\n/**\n * Utilize the given middleware `handle` to the given `route`,\n * defaulting to _/_. This \"route\" is the mount-point for the\n * middleware, when given a value other than _/_ the middleware\n * is only effective when that segment is present in the request's\n * pathname.\n *\n * For example if we were to mount a function at _/admin_, it would\n * be invoked on _/admin_, and _/admin/settings_, however it would\n * not be invoked for _/_, or _/posts_.\n *\n * @param {String|Function|Server} route, callback or server\n * @param {Function|Server} callback or server\n * @return {Server} for chaining\n * @public\n */\n\nproto.use = function use(route, fn) {\n  var handle = fn;\n  var path = route;\n\n  // default route to '/'\n  if (typeof route !== 'string') {\n    handle = route;\n    path = '/';\n  }\n\n  // wrap sub-apps\n  if (typeof handle.handle === 'function') {\n    var server = handle;\n    server.route = path;\n    handle = function (req, res, next) {\n      server.handle(req, res, next);\n    };\n  }\n\n  // wrap vanilla http.Servers\n  if (handle instanceof http$4.Server) {\n    handle = handle.listeners('request')[0];\n  }\n\n  // strip trailing slash\n  if (path[path.length - 1] === '/') {\n    path = path.slice(0, -1);\n  }\n\n  // add the middleware\n  debug$4('use %s %s', path || '/', handle.name || 'anonymous');\n  this.stack.push({ route: path, handle: handle });\n\n  return this;\n};\n\n/**\n * Handle server requests, punting them down\n * the middleware stack.\n *\n * @private\n */\n\nproto.handle = function handle(req, res, out) {\n  var index = 0;\n  var protohost = getProtohost(req.url) || '';\n  var removed = '';\n  var slashAdded = false;\n  var stack = this.stack;\n\n  // final function handler\n  var done = out || finalhandler(req, res, {\n    env: env,\n    onerror: logerror\n  });\n\n  // store the original URL\n  req.originalUrl = req.originalUrl || req.url;\n\n  function next(err) {\n    if (slashAdded) {\n      req.url = req.url.substr(1);\n      slashAdded = false;\n    }\n\n    if (removed.length !== 0) {\n      req.url = protohost + removed + req.url.substr(protohost.length);\n      removed = '';\n    }\n\n    // next callback\n    var layer = stack[index++];\n\n    // all done\n    if (!layer) {\n      defer(done, err);\n      return;\n    }\n\n    // route data\n    var path = parseUrl(req).pathname || '/';\n    var route = layer.route;\n\n    // skip this layer if the route doesn't match\n    if (path.toLowerCase().substr(0, route.length) !== route.toLowerCase()) {\n      return next(err);\n    }\n\n    // skip if route match does not border \"/\", \".\", or end\n    var c = path.length > route.length && path[route.length];\n    if (c && c !== '/' && c !== '.') {\n      return next(err);\n    }\n\n    // trim off the part of the url that matches the route\n    if (route.length !== 0 && route !== '/') {\n      removed = route;\n      req.url = protohost + req.url.substr(protohost.length + removed.length);\n\n      // ensure leading slash\n      if (!protohost && req.url[0] !== '/') {\n        req.url = '/' + req.url;\n        slashAdded = true;\n      }\n    }\n\n    // call the layer handle\n    call(layer.handle, route, err, req, res, next);\n  }\n\n  next();\n};\n\n/**\n * Listen for connections.\n *\n * This method takes the same arguments\n * as node's `http.Server#listen()`.\n *\n * HTTP and HTTPS:\n *\n * If you run your application both as HTTP\n * and HTTPS you may wrap them individually,\n * since your Connect \"server\" is really just\n * a JavaScript `Function`.\n *\n *      var connect = require('connect')\n *        , http = require('http')\n *        , https = require('https');\n *\n *      var app = connect();\n *\n *      http.createServer(app).listen(80);\n *      https.createServer(options, app).listen(443);\n *\n * @return {http.Server}\n * @api public\n */\n\nproto.listen = function listen() {\n  var server = http$4.createServer(this);\n  return server.listen.apply(server, arguments);\n};\n\n/**\n * Invoke a route handle.\n * @private\n */\n\nfunction call(handle, route, err, req, res, next) {\n  var arity = handle.length;\n  var error = err;\n  var hasError = Boolean(err);\n\n  debug$4('%s %s : %s', handle.name || '<anonymous>', route, req.originalUrl);\n\n  try {\n    if (hasError && arity === 4) {\n      // error-handling middleware\n      handle(err, req, res, next);\n      return;\n    } else if (!hasError && arity < 4) {\n      // request-handling middleware\n      handle(req, res, next);\n      return;\n    }\n  } catch (e) {\n    // replace the error\n    error = e;\n  }\n\n  // continue\n  next(error);\n}\n\n/**\n * Log error using console.error.\n *\n * @param {Error} err\n * @private\n */\n\nfunction logerror(err) {\n  if (env !== 'test') console.error(err.stack || err.toString());\n}\n\n/**\n * Get get protocol + host for a URL.\n *\n * @param {string} url\n * @private\n */\n\nfunction getProtohost(url) {\n  if (url.length === 0 || url[0] === '/') {\n    return undefined;\n  }\n\n  var fqdnIndex = url.indexOf('://');\n\n  return fqdnIndex !== -1 && url.lastIndexOf('?', fqdnIndex) === -1\n    ? url.substr(0, url.indexOf('/', 3 + fqdnIndex))\n    : undefined;\n}\n\nvar libExports$1 = {};\nvar lib$1 = {\n  get exports(){ return libExports$1; },\n  set exports(v){ libExports$1 = v; },\n};\n\n/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n/* eslint-disable no-unused-vars */\nvar getOwnPropertySymbols = Object.getOwnPropertySymbols;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line no-new-wrappers\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (err) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nvar objectAssign = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (getOwnPropertySymbols) {\n\t\t\tsymbols = getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n\nvar varyExports = {};\nvar vary$1 = {\n  get exports(){ return varyExports; },\n  set exports(v){ varyExports = v; },\n};\n\n/*!\n * vary\n * Copyright(c) 2014-2017 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module exports.\n */\n\nvary$1.exports = vary;\nvaryExports.append = append;\n\n/**\n * RegExp to match field-name in RFC 7230 sec 3.2\n *\n * field-name    = token\n * token         = 1*tchar\n * tchar         = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"\n *               / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"\n *               / DIGIT / ALPHA\n *               ; any VCHAR, except delimiters\n */\n\nvar FIELD_NAME_REGEXP = /^[!#$%&'*+\\-.^_`|~0-9A-Za-z]+$/;\n\n/**\n * Append a field to a vary header.\n *\n * @param {String} header\n * @param {String|Array} field\n * @return {String}\n * @public\n */\n\nfunction append (header, field) {\n  if (typeof header !== 'string') {\n    throw new TypeError('header argument is required')\n  }\n\n  if (!field) {\n    throw new TypeError('field argument is required')\n  }\n\n  // get fields array\n  var fields = !Array.isArray(field)\n    ? parse$6(String(field))\n    : field;\n\n  // assert on invalid field names\n  for (var j = 0; j < fields.length; j++) {\n    if (!FIELD_NAME_REGEXP.test(fields[j])) {\n      throw new TypeError('field argument contains an invalid header name')\n    }\n  }\n\n  // existing, unspecified vary\n  if (header === '*') {\n    return header\n  }\n\n  // enumerate current values\n  var val = header;\n  var vals = parse$6(header.toLowerCase());\n\n  // unspecified vary\n  if (fields.indexOf('*') !== -1 || vals.indexOf('*') !== -1) {\n    return '*'\n  }\n\n  for (var i = 0; i < fields.length; i++) {\n    var fld = fields[i].toLowerCase();\n\n    // append value (case-preserving)\n    if (vals.indexOf(fld) === -1) {\n      vals.push(fld);\n      val = val\n        ? val + ', ' + fields[i]\n        : fields[i];\n    }\n  }\n\n  return val\n}\n\n/**\n * Parse a vary header into an array.\n *\n * @param {String} header\n * @return {Array}\n * @private\n */\n\nfunction parse$6 (header) {\n  var end = 0;\n  var list = [];\n  var start = 0;\n\n  // gather tokens\n  for (var i = 0, len = header.length; i < len; i++) {\n    switch (header.charCodeAt(i)) {\n      case 0x20: /*   */\n        if (start === end) {\n          start = end = i + 1;\n        }\n        break\n      case 0x2c: /* , */\n        list.push(header.substring(start, end));\n        start = end = i + 1;\n        break\n      default:\n        end = i + 1;\n        break\n    }\n  }\n\n  // final token\n  list.push(header.substring(start, end));\n\n  return list\n}\n\n/**\n * Mark that a request is varied on a header field.\n *\n * @param {Object} res\n * @param {String|Array} field\n * @public\n */\n\nfunction vary (res, field) {\n  if (!res || !res.getHeader || !res.setHeader) {\n    // quack quack\n    throw new TypeError('res argument is required')\n  }\n\n  // get existing header\n  var val = res.getHeader('Vary') || '';\n  var header = Array.isArray(val)\n    ? val.join(', ')\n    : String(val);\n\n  // set new header\n  if ((val = append(header, field))) {\n    res.setHeader('Vary', val);\n  }\n}\n\n(function () {\n\n  var assign = objectAssign;\n  var vary = varyExports;\n\n  var defaults = {\n    origin: '*',\n    methods: 'GET,HEAD,PUT,PATCH,POST,DELETE',\n    preflightContinue: false,\n    optionsSuccessStatus: 204\n  };\n\n  function isString(s) {\n    return typeof s === 'string' || s instanceof String;\n  }\n\n  function isOriginAllowed(origin, allowedOrigin) {\n    if (Array.isArray(allowedOrigin)) {\n      for (var i = 0; i < allowedOrigin.length; ++i) {\n        if (isOriginAllowed(origin, allowedOrigin[i])) {\n          return true;\n        }\n      }\n      return false;\n    } else if (isString(allowedOrigin)) {\n      return origin === allowedOrigin;\n    } else if (allowedOrigin instanceof RegExp) {\n      return allowedOrigin.test(origin);\n    } else {\n      return !!allowedOrigin;\n    }\n  }\n\n  function configureOrigin(options, req) {\n    var requestOrigin = req.headers.origin,\n      headers = [],\n      isAllowed;\n\n    if (!options.origin || options.origin === '*') {\n      // allow any origin\n      headers.push([{\n        key: 'Access-Control-Allow-Origin',\n        value: '*'\n      }]);\n    } else if (isString(options.origin)) {\n      // fixed origin\n      headers.push([{\n        key: 'Access-Control-Allow-Origin',\n        value: options.origin\n      }]);\n      headers.push([{\n        key: 'Vary',\n        value: 'Origin'\n      }]);\n    } else {\n      isAllowed = isOriginAllowed(requestOrigin, options.origin);\n      // reflect origin\n      headers.push([{\n        key: 'Access-Control-Allow-Origin',\n        value: isAllowed ? requestOrigin : false\n      }]);\n      headers.push([{\n        key: 'Vary',\n        value: 'Origin'\n      }]);\n    }\n\n    return headers;\n  }\n\n  function configureMethods(options) {\n    var methods = options.methods;\n    if (methods.join) {\n      methods = options.methods.join(','); // .methods is an array, so turn it into a string\n    }\n    return {\n      key: 'Access-Control-Allow-Methods',\n      value: methods\n    };\n  }\n\n  function configureCredentials(options) {\n    if (options.credentials === true) {\n      return {\n        key: 'Access-Control-Allow-Credentials',\n        value: 'true'\n      };\n    }\n    return null;\n  }\n\n  function configureAllowedHeaders(options, req) {\n    var allowedHeaders = options.allowedHeaders || options.headers;\n    var headers = [];\n\n    if (!allowedHeaders) {\n      allowedHeaders = req.headers['access-control-request-headers']; // .headers wasn't specified, so reflect the request headers\n      headers.push([{\n        key: 'Vary',\n        value: 'Access-Control-Request-Headers'\n      }]);\n    } else if (allowedHeaders.join) {\n      allowedHeaders = allowedHeaders.join(','); // .headers is an array, so turn it into a string\n    }\n    if (allowedHeaders && allowedHeaders.length) {\n      headers.push([{\n        key: 'Access-Control-Allow-Headers',\n        value: allowedHeaders\n      }]);\n    }\n\n    return headers;\n  }\n\n  function configureExposedHeaders(options) {\n    var headers = options.exposedHeaders;\n    if (!headers) {\n      return null;\n    } else if (headers.join) {\n      headers = headers.join(','); // .headers is an array, so turn it into a string\n    }\n    if (headers && headers.length) {\n      return {\n        key: 'Access-Control-Expose-Headers',\n        value: headers\n      };\n    }\n    return null;\n  }\n\n  function configureMaxAge(options) {\n    var maxAge = (typeof options.maxAge === 'number' || options.maxAge) && options.maxAge.toString();\n    if (maxAge && maxAge.length) {\n      return {\n        key: 'Access-Control-Max-Age',\n        value: maxAge\n      };\n    }\n    return null;\n  }\n\n  function applyHeaders(headers, res) {\n    for (var i = 0, n = headers.length; i < n; i++) {\n      var header = headers[i];\n      if (header) {\n        if (Array.isArray(header)) {\n          applyHeaders(header, res);\n        } else if (header.key === 'Vary' && header.value) {\n          vary(res, header.value);\n        } else if (header.value) {\n          res.setHeader(header.key, header.value);\n        }\n      }\n    }\n  }\n\n  function cors(options, req, res, next) {\n    var headers = [],\n      method = req.method && req.method.toUpperCase && req.method.toUpperCase();\n\n    if (method === 'OPTIONS') {\n      // preflight\n      headers.push(configureOrigin(options, req));\n      headers.push(configureCredentials(options));\n      headers.push(configureMethods(options));\n      headers.push(configureAllowedHeaders(options, req));\n      headers.push(configureMaxAge(options));\n      headers.push(configureExposedHeaders(options));\n      applyHeaders(headers, res);\n\n      if (options.preflightContinue) {\n        next();\n      } else {\n        // Safari (and potentially other browsers) need content-length 0,\n        //   for 204 or they just hang waiting for a body\n        res.statusCode = options.optionsSuccessStatus;\n        res.setHeader('Content-Length', '0');\n        res.end();\n      }\n    } else {\n      // actual response\n      headers.push(configureOrigin(options, req));\n      headers.push(configureCredentials(options));\n      headers.push(configureExposedHeaders(options));\n      applyHeaders(headers, res);\n      next();\n    }\n  }\n\n  function middlewareWrapper(o) {\n    // if options are static (either via defaults or custom options passed in), wrap in a function\n    var optionsCallback = null;\n    if (typeof o === 'function') {\n      optionsCallback = o;\n    } else {\n      optionsCallback = function (req, cb) {\n        cb(null, o);\n      };\n    }\n\n    return function corsMiddleware(req, res, next) {\n      optionsCallback(req, function (err, options) {\n        if (err) {\n          next(err);\n        } else {\n          var corsOptions = assign({}, defaults, options);\n          var originCallback = null;\n          if (corsOptions.origin && typeof corsOptions.origin === 'function') {\n            originCallback = corsOptions.origin;\n          } else if (corsOptions.origin) {\n            originCallback = function (origin, cb) {\n              cb(null, corsOptions.origin);\n            };\n          }\n\n          if (originCallback) {\n            originCallback(req.headers.origin, function (err2, origin) {\n              if (err2 || !origin) {\n                next(err2);\n              } else {\n                corsOptions.origin = origin;\n                cors(corsOptions, req, res, next);\n              }\n            });\n          } else {\n            next();\n          }\n        }\n      });\n    };\n  }\n\n  // can pass either an options hash, an options delegate, or nothing\n  lib$1.exports = middlewareWrapper;\n\n}());\n\nvar chokidar = {};\n\nconst fs$8 = require$$0__default;\nconst { Readable } = require$$0$7;\nconst sysPath$3 = require$$0$4;\nconst { promisify: promisify$3 } = require$$0$6;\nconst picomatch$1 = picomatchExports;\n\nconst readdir$1 = promisify$3(fs$8.readdir);\nconst stat$3 = promisify$3(fs$8.stat);\nconst lstat$2 = promisify$3(fs$8.lstat);\nconst realpath$1 = promisify$3(fs$8.realpath);\n\n/**\n * @typedef {Object} EntryInfo\n * @property {String} path\n * @property {String} fullPath\n * @property {fs.Stats=} stats\n * @property {fs.Dirent=} dirent\n * @property {String} basename\n */\n\nconst BANG$2 = '!';\nconst RECURSIVE_ERROR_CODE = 'READDIRP_RECURSIVE_ERROR';\nconst NORMAL_FLOW_ERRORS = new Set(['ENOENT', 'EPERM', 'EACCES', 'ELOOP', RECURSIVE_ERROR_CODE]);\nconst FILE_TYPE = 'files';\nconst DIR_TYPE = 'directories';\nconst FILE_DIR_TYPE = 'files_directories';\nconst EVERYTHING_TYPE = 'all';\nconst ALL_TYPES = [FILE_TYPE, DIR_TYPE, FILE_DIR_TYPE, EVERYTHING_TYPE];\n\nconst isNormalFlowError = error => NORMAL_FLOW_ERRORS.has(error.code);\nconst [maj, min] = process.versions.node.split('.').slice(0, 2).map(n => Number.parseInt(n, 10));\nconst wantBigintFsStats = process.platform === 'win32' && (maj > 10 || (maj === 10 && min >= 5));\n\nconst normalizeFilter = filter => {\n  if (filter === undefined) return;\n  if (typeof filter === 'function') return filter;\n\n  if (typeof filter === 'string') {\n    const glob = picomatch$1(filter.trim());\n    return entry => glob(entry.basename);\n  }\n\n  if (Array.isArray(filter)) {\n    const positive = [];\n    const negative = [];\n    for (const item of filter) {\n      const trimmed = item.trim();\n      if (trimmed.charAt(0) === BANG$2) {\n        negative.push(picomatch$1(trimmed.slice(1)));\n      } else {\n        positive.push(picomatch$1(trimmed));\n      }\n    }\n\n    if (negative.length > 0) {\n      if (positive.length > 0) {\n        return entry =>\n          positive.some(f => f(entry.basename)) && !negative.some(f => f(entry.basename));\n      }\n      return entry => !negative.some(f => f(entry.basename));\n    }\n    return entry => positive.some(f => f(entry.basename));\n  }\n};\n\nclass ReaddirpStream extends Readable {\n  static get defaultOptions() {\n    return {\n      root: '.',\n      /* eslint-disable no-unused-vars */\n      fileFilter: (path) => true,\n      directoryFilter: (path) => true,\n      /* eslint-enable no-unused-vars */\n      type: FILE_TYPE,\n      lstat: false,\n      depth: 2147483648,\n      alwaysStat: false\n    };\n  }\n\n  constructor(options = {}) {\n    super({\n      objectMode: true,\n      autoDestroy: true,\n      highWaterMark: options.highWaterMark || 4096\n    });\n    const opts = { ...ReaddirpStream.defaultOptions, ...options };\n    const { root, type } = opts;\n\n    this._fileFilter = normalizeFilter(opts.fileFilter);\n    this._directoryFilter = normalizeFilter(opts.directoryFilter);\n\n    const statMethod = opts.lstat ? lstat$2 : stat$3;\n    // Use bigint stats if it's windows and stat() supports options (node 10+).\n    if (wantBigintFsStats) {\n      this._stat = path => statMethod(path, { bigint: true });\n    } else {\n      this._stat = statMethod;\n    }\n\n    this._maxDepth = opts.depth;\n    this._wantsDir = [DIR_TYPE, FILE_DIR_TYPE, EVERYTHING_TYPE].includes(type);\n    this._wantsFile = [FILE_TYPE, FILE_DIR_TYPE, EVERYTHING_TYPE].includes(type);\n    this._wantsEverything = type === EVERYTHING_TYPE;\n    this._root = sysPath$3.resolve(root);\n    this._isDirent = ('Dirent' in fs$8) && !opts.alwaysStat;\n    this._statsProp = this._isDirent ? 'dirent' : 'stats';\n    this._rdOptions = { encoding: 'utf8', withFileTypes: this._isDirent };\n\n    // Launch stream with one parent, the root dir.\n    this.parents = [this._exploreDir(root, 1)];\n    this.reading = false;\n    this.parent = undefined;\n  }\n\n  async _read(batch) {\n    if (this.reading) return;\n    this.reading = true;\n\n    try {\n      while (!this.destroyed && batch > 0) {\n        const { path, depth, files = [] } = this.parent || {};\n\n        if (files.length > 0) {\n          const slice = files.splice(0, batch).map(dirent => this._formatEntry(dirent, path));\n          for (const entry of await Promise.all(slice)) {\n            if (this.destroyed) return;\n\n            const entryType = await this._getEntryType(entry);\n            if (entryType === 'directory' && this._directoryFilter(entry)) {\n              if (depth <= this._maxDepth) {\n                this.parents.push(this._exploreDir(entry.fullPath, depth + 1));\n              }\n\n              if (this._wantsDir) {\n                this.push(entry);\n                batch--;\n              }\n            } else if ((entryType === 'file' || this._includeAsFile(entry)) && this._fileFilter(entry)) {\n              if (this._wantsFile) {\n                this.push(entry);\n                batch--;\n              }\n            }\n          }\n        } else {\n          const parent = this.parents.pop();\n          if (!parent) {\n            this.push(null);\n            break;\n          }\n          this.parent = await parent;\n          if (this.destroyed) return;\n        }\n      }\n    } catch (error) {\n      this.destroy(error);\n    } finally {\n      this.reading = false;\n    }\n  }\n\n  async _exploreDir(path, depth) {\n    let files;\n    try {\n      files = await readdir$1(path, this._rdOptions);\n    } catch (error) {\n      this._onError(error);\n    }\n    return { files, depth, path };\n  }\n\n  async _formatEntry(dirent, path) {\n    let entry;\n    try {\n      const basename = this._isDirent ? dirent.name : dirent;\n      const fullPath = sysPath$3.resolve(sysPath$3.join(path, basename));\n      entry = { path: sysPath$3.relative(this._root, fullPath), fullPath, basename };\n      entry[this._statsProp] = this._isDirent ? dirent : await this._stat(fullPath);\n    } catch (err) {\n      this._onError(err);\n    }\n    return entry;\n  }\n\n  _onError(err) {\n    if (isNormalFlowError(err) && !this.destroyed) {\n      this.emit('warn', err);\n    } else {\n      this.destroy(err);\n    }\n  }\n\n  async _getEntryType(entry) {\n    // entry may be undefined, because a warning or an error were emitted\n    // and the statsProp is undefined\n    const stats = entry && entry[this._statsProp];\n    if (!stats) {\n      return;\n    }\n    if (stats.isFile()) {\n      return 'file';\n    }\n    if (stats.isDirectory()) {\n      return 'directory';\n    }\n    if (stats && stats.isSymbolicLink()) {\n      const full = entry.fullPath;\n      try {\n        const entryRealPath = await realpath$1(full);\n        const entryRealPathStats = await lstat$2(entryRealPath);\n        if (entryRealPathStats.isFile()) {\n          return 'file';\n        }\n        if (entryRealPathStats.isDirectory()) {\n          const len = entryRealPath.length;\n          if (full.startsWith(entryRealPath) && full.substr(len, 1) === sysPath$3.sep) {\n            const recursiveError = new Error(\n              `Circular symlink detected: \"${full}\" points to \"${entryRealPath}\"`\n            );\n            recursiveError.code = RECURSIVE_ERROR_CODE;\n            return this._onError(recursiveError);\n          }\n          return 'directory';\n        }\n      } catch (error) {\n        this._onError(error);\n      }\n    }\n  }\n\n  _includeAsFile(entry) {\n    const stats = entry && entry[this._statsProp];\n\n    return stats && this._wantsEverything && !stats.isDirectory();\n  }\n}\n\n/**\n * @typedef {Object} ReaddirpArguments\n * @property {Function=} fileFilter\n * @property {Function=} directoryFilter\n * @property {String=} type\n * @property {Number=} depth\n * @property {String=} root\n * @property {Boolean=} lstat\n * @property {Boolean=} bigint\n */\n\n/**\n * Main function which ends up calling readdirRec and reads all files and directories in given root recursively.\n * @param {String} root Root directory\n * @param {ReaddirpArguments=} options Options to specify root (start directory), filters and recursion depth\n */\nconst readdirp$1 = (root, options = {}) => {\n  let type = options.entryType || options.type;\n  if (type === 'both') type = FILE_DIR_TYPE; // backwards-compatibility\n  if (type) options.type = type;\n  if (!root) {\n    throw new Error('readdirp: root argument is required. Usage: readdirp(root, options)');\n  } else if (typeof root !== 'string') {\n    throw new TypeError('readdirp: root argument must be a string. Usage: readdirp(root, options)');\n  } else if (type && !ALL_TYPES.includes(type)) {\n    throw new Error(`readdirp: Invalid type passed. Use one of ${ALL_TYPES.join(', ')}`);\n  }\n\n  options.root = root;\n  return new ReaddirpStream(options);\n};\n\nconst readdirpPromise = (root, options = {}) => {\n  return new Promise((resolve, reject) => {\n    const files = [];\n    readdirp$1(root, options)\n      .on('data', entry => files.push(entry))\n      .on('end', () => resolve(files))\n      .on('error', error => reject(error));\n  });\n};\n\nreaddirp$1.promise = readdirpPromise;\nreaddirp$1.ReaddirpStream = ReaddirpStream;\nreaddirp$1.default = readdirp$1;\n\nvar readdirp_1 = readdirp$1;\n\nvar anymatchExports = {};\nvar anymatch$2 = {\n  get exports(){ return anymatchExports; },\n  set exports(v){ anymatchExports = v; },\n};\n\n/*!\n * normalize-path <https://github.com/jonschlinkert/normalize-path>\n *\n * Copyright (c) 2014-2018, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nvar normalizePath$2 = function(path, stripTrailing) {\n  if (typeof path !== 'string') {\n    throw new TypeError('expected path to be a string');\n  }\n\n  if (path === '\\\\' || path === '/') return '/';\n\n  var len = path.length;\n  if (len <= 1) return path;\n\n  // ensure that win32 namespaces has two leading slashes, so that the path is\n  // handled properly by the win32 version of path.parse() after being normalized\n  // https://msdn.microsoft.com/library/windows/desktop/aa365247(v=vs.85).aspx#namespaces\n  var prefix = '';\n  if (len > 4 && path[3] === '\\\\') {\n    var ch = path[2];\n    if ((ch === '?' || ch === '.') && path.slice(0, 2) === '\\\\\\\\') {\n      path = path.slice(2);\n      prefix = '//';\n    }\n  }\n\n  var segs = path.split(/[/\\\\]+/);\n  if (stripTrailing !== false && segs[segs.length - 1] === '') {\n    segs.pop();\n  }\n  return prefix + segs.join('/');\n};\n\nObject.defineProperty(anymatchExports, \"__esModule\", { value: true });\n\nconst picomatch = picomatchExports;\nconst normalizePath$1 = normalizePath$2;\n\n/**\n * @typedef {(testString: string) => boolean} AnymatchFn\n * @typedef {string|RegExp|AnymatchFn} AnymatchPattern\n * @typedef {AnymatchPattern|AnymatchPattern[]} AnymatchMatcher\n */\nconst BANG$1 = '!';\nconst DEFAULT_OPTIONS = {returnIndex: false};\nconst arrify$1 = (item) => Array.isArray(item) ? item : [item];\n\n/**\n * @param {AnymatchPattern} matcher\n * @param {object} options\n * @returns {AnymatchFn}\n */\nconst createPattern = (matcher, options) => {\n  if (typeof matcher === 'function') {\n    return matcher;\n  }\n  if (typeof matcher === 'string') {\n    const glob = picomatch(matcher, options);\n    return (string) => matcher === string || glob(string);\n  }\n  if (matcher instanceof RegExp) {\n    return (string) => matcher.test(string);\n  }\n  return (string) => false;\n};\n\n/**\n * @param {Array<Function>} patterns\n * @param {Array<Function>} negPatterns\n * @param {String|Array} args\n * @param {Boolean} returnIndex\n * @returns {boolean|number}\n */\nconst matchPatterns = (patterns, negPatterns, args, returnIndex) => {\n  const isList = Array.isArray(args);\n  const _path = isList ? args[0] : args;\n  if (!isList && typeof _path !== 'string') {\n    throw new TypeError('anymatch: second argument must be a string: got ' +\n      Object.prototype.toString.call(_path))\n  }\n  const path = normalizePath$1(_path);\n\n  for (let index = 0; index < negPatterns.length; index++) {\n    const nglob = negPatterns[index];\n    if (nglob(path)) {\n      return returnIndex ? -1 : false;\n    }\n  }\n\n  const applied = isList && [path].concat(args.slice(1));\n  for (let index = 0; index < patterns.length; index++) {\n    const pattern = patterns[index];\n    if (isList ? pattern(...applied) : pattern(path)) {\n      return returnIndex ? index : true;\n    }\n  }\n\n  return returnIndex ? -1 : false;\n};\n\n/**\n * @param {AnymatchMatcher} matchers\n * @param {Array|string} testString\n * @param {object} options\n * @returns {boolean|number|Function}\n */\nconst anymatch$1 = (matchers, testString, options = DEFAULT_OPTIONS) => {\n  if (matchers == null) {\n    throw new TypeError('anymatch: specify first argument');\n  }\n  const opts = typeof options === 'boolean' ? {returnIndex: options} : options;\n  const returnIndex = opts.returnIndex || false;\n\n  // Early cache for matchers.\n  const mtchers = arrify$1(matchers);\n  const negatedGlobs = mtchers\n    .filter(item => typeof item === 'string' && item.charAt(0) === BANG$1)\n    .map(item => item.slice(1))\n    .map(item => picomatch(item, opts));\n  const patterns = mtchers\n    .filter(item => typeof item !== 'string' || (typeof item === 'string' && item.charAt(0) !== BANG$1))\n    .map(matcher => createPattern(matcher, opts));\n\n  if (testString == null) {\n    return (testString, ri = false) => {\n      const returnIndex = typeof ri === 'boolean' ? ri : false;\n      return matchPatterns(patterns, negatedGlobs, testString, returnIndex);\n    }\n  }\n\n  return matchPatterns(patterns, negatedGlobs, testString, returnIndex);\n};\n\nanymatch$1.default = anymatch$1;\nanymatch$2.exports = anymatch$1;\n\nvar binaryExtensionsExports = {};\nvar binaryExtensions$1 = {\n  get exports(){ return binaryExtensionsExports; },\n  set exports(v){ binaryExtensionsExports = v; },\n};\n\nvar require$$0 = [\n\t\"3dm\",\n\t\"3ds\",\n\t\"3g2\",\n\t\"3gp\",\n\t\"7z\",\n\t\"a\",\n\t\"aac\",\n\t\"adp\",\n\t\"ai\",\n\t\"aif\",\n\t\"aiff\",\n\t\"alz\",\n\t\"ape\",\n\t\"apk\",\n\t\"appimage\",\n\t\"ar\",\n\t\"arj\",\n\t\"asf\",\n\t\"au\",\n\t\"avi\",\n\t\"bak\",\n\t\"baml\",\n\t\"bh\",\n\t\"bin\",\n\t\"bk\",\n\t\"bmp\",\n\t\"btif\",\n\t\"bz2\",\n\t\"bzip2\",\n\t\"cab\",\n\t\"caf\",\n\t\"cgm\",\n\t\"class\",\n\t\"cmx\",\n\t\"cpio\",\n\t\"cr2\",\n\t\"cur\",\n\t\"dat\",\n\t\"dcm\",\n\t\"deb\",\n\t\"dex\",\n\t\"djvu\",\n\t\"dll\",\n\t\"dmg\",\n\t\"dng\",\n\t\"doc\",\n\t\"docm\",\n\t\"docx\",\n\t\"dot\",\n\t\"dotm\",\n\t\"dra\",\n\t\"DS_Store\",\n\t\"dsk\",\n\t\"dts\",\n\t\"dtshd\",\n\t\"dvb\",\n\t\"dwg\",\n\t\"dxf\",\n\t\"ecelp4800\",\n\t\"ecelp7470\",\n\t\"ecelp9600\",\n\t\"egg\",\n\t\"eol\",\n\t\"eot\",\n\t\"epub\",\n\t\"exe\",\n\t\"f4v\",\n\t\"fbs\",\n\t\"fh\",\n\t\"fla\",\n\t\"flac\",\n\t\"flatpak\",\n\t\"fli\",\n\t\"flv\",\n\t\"fpx\",\n\t\"fst\",\n\t\"fvt\",\n\t\"g3\",\n\t\"gh\",\n\t\"gif\",\n\t\"graffle\",\n\t\"gz\",\n\t\"gzip\",\n\t\"h261\",\n\t\"h263\",\n\t\"h264\",\n\t\"icns\",\n\t\"ico\",\n\t\"ief\",\n\t\"img\",\n\t\"ipa\",\n\t\"iso\",\n\t\"jar\",\n\t\"jpeg\",\n\t\"jpg\",\n\t\"jpgv\",\n\t\"jpm\",\n\t\"jxr\",\n\t\"key\",\n\t\"ktx\",\n\t\"lha\",\n\t\"lib\",\n\t\"lvp\",\n\t\"lz\",\n\t\"lzh\",\n\t\"lzma\",\n\t\"lzo\",\n\t\"m3u\",\n\t\"m4a\",\n\t\"m4v\",\n\t\"mar\",\n\t\"mdi\",\n\t\"mht\",\n\t\"mid\",\n\t\"midi\",\n\t\"mj2\",\n\t\"mka\",\n\t\"mkv\",\n\t\"mmr\",\n\t\"mng\",\n\t\"mobi\",\n\t\"mov\",\n\t\"movie\",\n\t\"mp3\",\n\t\"mp4\",\n\t\"mp4a\",\n\t\"mpeg\",\n\t\"mpg\",\n\t\"mpga\",\n\t\"mxu\",\n\t\"nef\",\n\t\"npx\",\n\t\"numbers\",\n\t\"nupkg\",\n\t\"o\",\n\t\"odp\",\n\t\"ods\",\n\t\"odt\",\n\t\"oga\",\n\t\"ogg\",\n\t\"ogv\",\n\t\"otf\",\n\t\"ott\",\n\t\"pages\",\n\t\"pbm\",\n\t\"pcx\",\n\t\"pdb\",\n\t\"pdf\",\n\t\"pea\",\n\t\"pgm\",\n\t\"pic\",\n\t\"png\",\n\t\"pnm\",\n\t\"pot\",\n\t\"potm\",\n\t\"potx\",\n\t\"ppa\",\n\t\"ppam\",\n\t\"ppm\",\n\t\"pps\",\n\t\"ppsm\",\n\t\"ppsx\",\n\t\"ppt\",\n\t\"pptm\",\n\t\"pptx\",\n\t\"psd\",\n\t\"pya\",\n\t\"pyc\",\n\t\"pyo\",\n\t\"pyv\",\n\t\"qt\",\n\t\"rar\",\n\t\"ras\",\n\t\"raw\",\n\t\"resources\",\n\t\"rgb\",\n\t\"rip\",\n\t\"rlc\",\n\t\"rmf\",\n\t\"rmvb\",\n\t\"rpm\",\n\t\"rtf\",\n\t\"rz\",\n\t\"s3m\",\n\t\"s7z\",\n\t\"scpt\",\n\t\"sgi\",\n\t\"shar\",\n\t\"snap\",\n\t\"sil\",\n\t\"sketch\",\n\t\"slk\",\n\t\"smv\",\n\t\"snk\",\n\t\"so\",\n\t\"stl\",\n\t\"suo\",\n\t\"sub\",\n\t\"swf\",\n\t\"tar\",\n\t\"tbz\",\n\t\"tbz2\",\n\t\"tga\",\n\t\"tgz\",\n\t\"thmx\",\n\t\"tif\",\n\t\"tiff\",\n\t\"tlz\",\n\t\"ttc\",\n\t\"ttf\",\n\t\"txz\",\n\t\"udf\",\n\t\"uvh\",\n\t\"uvi\",\n\t\"uvm\",\n\t\"uvp\",\n\t\"uvs\",\n\t\"uvu\",\n\t\"viv\",\n\t\"vob\",\n\t\"war\",\n\t\"wav\",\n\t\"wax\",\n\t\"wbmp\",\n\t\"wdp\",\n\t\"weba\",\n\t\"webm\",\n\t\"webp\",\n\t\"whl\",\n\t\"wim\",\n\t\"wm\",\n\t\"wma\",\n\t\"wmv\",\n\t\"wmx\",\n\t\"woff\",\n\t\"woff2\",\n\t\"wrm\",\n\t\"wvx\",\n\t\"xbm\",\n\t\"xif\",\n\t\"xla\",\n\t\"xlam\",\n\t\"xls\",\n\t\"xlsb\",\n\t\"xlsm\",\n\t\"xlsx\",\n\t\"xlt\",\n\t\"xltm\",\n\t\"xltx\",\n\t\"xm\",\n\t\"xmind\",\n\t\"xpi\",\n\t\"xpm\",\n\t\"xwd\",\n\t\"xz\",\n\t\"z\",\n\t\"zip\",\n\t\"zipx\"\n];\n\n(function (module) {\n\tmodule.exports = require$$0;\n} (binaryExtensions$1));\n\nconst path$8 = require$$0$4;\nconst binaryExtensions = binaryExtensionsExports;\n\nconst extensions = new Set(binaryExtensions);\n\nvar isBinaryPath$1 = filePath => extensions.has(path$8.extname(filePath).slice(1).toLowerCase());\n\nvar constants$1 = {};\n\n(function (exports) {\n\n\tconst {sep} = require$$0$4;\n\tconst {platform} = process;\n\tconst os = require$$2;\n\n\texports.EV_ALL = 'all';\n\texports.EV_READY = 'ready';\n\texports.EV_ADD = 'add';\n\texports.EV_CHANGE = 'change';\n\texports.EV_ADD_DIR = 'addDir';\n\texports.EV_UNLINK = 'unlink';\n\texports.EV_UNLINK_DIR = 'unlinkDir';\n\texports.EV_RAW = 'raw';\n\texports.EV_ERROR = 'error';\n\n\texports.STR_DATA = 'data';\n\texports.STR_END = 'end';\n\texports.STR_CLOSE = 'close';\n\n\texports.FSEVENT_CREATED = 'created';\n\texports.FSEVENT_MODIFIED = 'modified';\n\texports.FSEVENT_DELETED = 'deleted';\n\texports.FSEVENT_MOVED = 'moved';\n\texports.FSEVENT_CLONED = 'cloned';\n\texports.FSEVENT_UNKNOWN = 'unknown';\n\texports.FSEVENT_TYPE_FILE = 'file';\n\texports.FSEVENT_TYPE_DIRECTORY = 'directory';\n\texports.FSEVENT_TYPE_SYMLINK = 'symlink';\n\n\texports.KEY_LISTENERS = 'listeners';\n\texports.KEY_ERR = 'errHandlers';\n\texports.KEY_RAW = 'rawEmitters';\n\texports.HANDLER_KEYS = [exports.KEY_LISTENERS, exports.KEY_ERR, exports.KEY_RAW];\n\n\texports.DOT_SLASH = `.${sep}`;\n\n\texports.BACK_SLASH_RE = /\\\\/g;\n\texports.DOUBLE_SLASH_RE = /\\/\\//;\n\texports.SLASH_OR_BACK_SLASH_RE = /[/\\\\]/;\n\texports.DOT_RE = /\\..*\\.(sw[px])$|~$|\\.subl.*\\.tmp/;\n\texports.REPLACER_RE = /^\\.[/\\\\]/;\n\n\texports.SLASH = '/';\n\texports.SLASH_SLASH = '//';\n\texports.BRACE_START = '{';\n\texports.BANG = '!';\n\texports.ONE_DOT = '.';\n\texports.TWO_DOTS = '..';\n\texports.STAR = '*';\n\texports.GLOBSTAR = '**';\n\texports.ROOT_GLOBSTAR = '/**/*';\n\texports.SLASH_GLOBSTAR = '/**';\n\texports.DIR_SUFFIX = 'Dir';\n\texports.ANYMATCH_OPTS = {dot: true};\n\texports.STRING_TYPE = 'string';\n\texports.FUNCTION_TYPE = 'function';\n\texports.EMPTY_STR = '';\n\texports.EMPTY_FN = () => {};\n\texports.IDENTITY_FN = val => val;\n\n\texports.isWindows = platform === 'win32';\n\texports.isMacos = platform === 'darwin';\n\texports.isLinux = platform === 'linux';\n\texports.isIBMi = os.type() === 'OS400';\n} (constants$1));\n\nconst fs$7 = require$$0__default;\nconst sysPath$2 = require$$0$4;\nconst { promisify: promisify$2 } = require$$0$6;\nconst isBinaryPath = isBinaryPath$1;\nconst {\n  isWindows: isWindows$2,\n  isLinux,\n  EMPTY_FN: EMPTY_FN$2,\n  EMPTY_STR: EMPTY_STR$1,\n  KEY_LISTENERS,\n  KEY_ERR,\n  KEY_RAW,\n  HANDLER_KEYS,\n  EV_CHANGE: EV_CHANGE$2,\n  EV_ADD: EV_ADD$2,\n  EV_ADD_DIR: EV_ADD_DIR$2,\n  EV_ERROR: EV_ERROR$2,\n  STR_DATA: STR_DATA$1,\n  STR_END: STR_END$2,\n  BRACE_START: BRACE_START$1,\n  STAR\n} = constants$1;\n\nconst THROTTLE_MODE_WATCH = 'watch';\n\nconst open$1 = promisify$2(fs$7.open);\nconst stat$2 = promisify$2(fs$7.stat);\nconst lstat$1 = promisify$2(fs$7.lstat);\nconst close = promisify$2(fs$7.close);\nconst fsrealpath = promisify$2(fs$7.realpath);\n\nconst statMethods$1 = { lstat: lstat$1, stat: stat$2 };\n\n// TODO: emit errors properly. Example: EMFILE on Macos.\nconst foreach = (val, fn) => {\n  if (val instanceof Set) {\n    val.forEach(fn);\n  } else {\n    fn(val);\n  }\n};\n\nconst addAndConvert = (main, prop, item) => {\n  let container = main[prop];\n  if (!(container instanceof Set)) {\n    main[prop] = container = new Set([container]);\n  }\n  container.add(item);\n};\n\nconst clearItem = cont => key => {\n  const set = cont[key];\n  if (set instanceof Set) {\n    set.clear();\n  } else {\n    delete cont[key];\n  }\n};\n\nconst delFromSet = (main, prop, item) => {\n  const container = main[prop];\n  if (container instanceof Set) {\n    container.delete(item);\n  } else if (container === item) {\n    delete main[prop];\n  }\n};\n\nconst isEmptySet = (val) => val instanceof Set ? val.size === 0 : !val;\n\n/**\n * @typedef {String} Path\n */\n\n// fs_watch helpers\n\n// object to hold per-process fs_watch instances\n// (may be shared across chokidar FSWatcher instances)\n\n/**\n * @typedef {Object} FsWatchContainer\n * @property {Set} listeners\n * @property {Set} errHandlers\n * @property {Set} rawEmitters\n * @property {fs.FSWatcher=} watcher\n * @property {Boolean=} watcherUnusable\n */\n\n/**\n * @type {Map<String,FsWatchContainer>}\n */\nconst FsWatchInstances = new Map();\n\n/**\n * Instantiates the fs_watch interface\n * @param {String} path to be watched\n * @param {Object} options to be passed to fs_watch\n * @param {Function} listener main event handler\n * @param {Function} errHandler emits info about errors\n * @param {Function} emitRaw emits raw event data\n * @returns {fs.FSWatcher} new fsevents instance\n */\nfunction createFsWatchInstance(path, options, listener, errHandler, emitRaw) {\n  const handleEvent = (rawEvent, evPath) => {\n    listener(path);\n    emitRaw(rawEvent, evPath, {watchedPath: path});\n\n    // emit based on events occurring for files from a directory's watcher in\n    // case the file's watcher misses it (and rely on throttling to de-dupe)\n    if (evPath && path !== evPath) {\n      fsWatchBroadcast(\n        sysPath$2.resolve(path, evPath), KEY_LISTENERS, sysPath$2.join(path, evPath)\n      );\n    }\n  };\n  try {\n    return fs$7.watch(path, options, handleEvent);\n  } catch (error) {\n    errHandler(error);\n  }\n}\n\n/**\n * Helper for passing fs_watch event data to a collection of listeners\n * @param {Path} fullPath absolute path bound to fs_watch instance\n * @param {String} type listener type\n * @param {*=} val1 arguments to be passed to listeners\n * @param {*=} val2\n * @param {*=} val3\n */\nconst fsWatchBroadcast = (fullPath, type, val1, val2, val3) => {\n  const cont = FsWatchInstances.get(fullPath);\n  if (!cont) return;\n  foreach(cont[type], (listener) => {\n    listener(val1, val2, val3);\n  });\n};\n\n/**\n * Instantiates the fs_watch interface or binds listeners\n * to an existing one covering the same file system entry\n * @param {String} path\n * @param {String} fullPath absolute path\n * @param {Object} options to be passed to fs_watch\n * @param {Object} handlers container for event listener functions\n */\nconst setFsWatchListener = (path, fullPath, options, handlers) => {\n  const {listener, errHandler, rawEmitter} = handlers;\n  let cont = FsWatchInstances.get(fullPath);\n\n  /** @type {fs.FSWatcher=} */\n  let watcher;\n  if (!options.persistent) {\n    watcher = createFsWatchInstance(\n      path, options, listener, errHandler, rawEmitter\n    );\n    return watcher.close.bind(watcher);\n  }\n  if (cont) {\n    addAndConvert(cont, KEY_LISTENERS, listener);\n    addAndConvert(cont, KEY_ERR, errHandler);\n    addAndConvert(cont, KEY_RAW, rawEmitter);\n  } else {\n    watcher = createFsWatchInstance(\n      path,\n      options,\n      fsWatchBroadcast.bind(null, fullPath, KEY_LISTENERS),\n      errHandler, // no need to use broadcast here\n      fsWatchBroadcast.bind(null, fullPath, KEY_RAW)\n    );\n    if (!watcher) return;\n    watcher.on(EV_ERROR$2, async (error) => {\n      const broadcastErr = fsWatchBroadcast.bind(null, fullPath, KEY_ERR);\n      cont.watcherUnusable = true; // documented since Node 10.4.1\n      // Workaround for https://github.com/joyent/node/issues/4337\n      if (isWindows$2 && error.code === 'EPERM') {\n        try {\n          const fd = await open$1(path, 'r');\n          await close(fd);\n          broadcastErr(error);\n        } catch (err) {}\n      } else {\n        broadcastErr(error);\n      }\n    });\n    cont = {\n      listeners: listener,\n      errHandlers: errHandler,\n      rawEmitters: rawEmitter,\n      watcher\n    };\n    FsWatchInstances.set(fullPath, cont);\n  }\n  // const index = cont.listeners.indexOf(listener);\n\n  // removes this instance's listeners and closes the underlying fs_watch\n  // instance if there are no more listeners left\n  return () => {\n    delFromSet(cont, KEY_LISTENERS, listener);\n    delFromSet(cont, KEY_ERR, errHandler);\n    delFromSet(cont, KEY_RAW, rawEmitter);\n    if (isEmptySet(cont.listeners)) {\n      // Check to protect against issue gh-730.\n      // if (cont.watcherUnusable) {\n      cont.watcher.close();\n      // }\n      FsWatchInstances.delete(fullPath);\n      HANDLER_KEYS.forEach(clearItem(cont));\n      cont.watcher = undefined;\n      Object.freeze(cont);\n    }\n  };\n};\n\n// fs_watchFile helpers\n\n// object to hold per-process fs_watchFile instances\n// (may be shared across chokidar FSWatcher instances)\nconst FsWatchFileInstances = new Map();\n\n/**\n * Instantiates the fs_watchFile interface or binds listeners\n * to an existing one covering the same file system entry\n * @param {String} path to be watched\n * @param {String} fullPath absolute path\n * @param {Object} options options to be passed to fs_watchFile\n * @param {Object} handlers container for event listener functions\n * @returns {Function} closer\n */\nconst setFsWatchFileListener = (path, fullPath, options, handlers) => {\n  const {listener, rawEmitter} = handlers;\n  let cont = FsWatchFileInstances.get(fullPath);\n\n  const copts = cont && cont.options;\n  if (copts && (copts.persistent < options.persistent || copts.interval > options.interval)) {\n    fs$7.unwatchFile(fullPath);\n    cont = undefined;\n  }\n\n  /* eslint-enable no-unused-vars, prefer-destructuring */\n\n  if (cont) {\n    addAndConvert(cont, KEY_LISTENERS, listener);\n    addAndConvert(cont, KEY_RAW, rawEmitter);\n  } else {\n    // TODO\n    // listeners.add(listener);\n    // rawEmitters.add(rawEmitter);\n    cont = {\n      listeners: listener,\n      rawEmitters: rawEmitter,\n      options,\n      watcher: fs$7.watchFile(fullPath, options, (curr, prev) => {\n        foreach(cont.rawEmitters, (rawEmitter) => {\n          rawEmitter(EV_CHANGE$2, fullPath, {curr, prev});\n        });\n        const currmtime = curr.mtimeMs;\n        if (curr.size !== prev.size || currmtime > prev.mtimeMs || currmtime === 0) {\n          foreach(cont.listeners, (listener) => listener(path, curr));\n        }\n      })\n    };\n    FsWatchFileInstances.set(fullPath, cont);\n  }\n  // const index = cont.listeners.indexOf(listener);\n\n  // Removes this instance's listeners and closes the underlying fs_watchFile\n  // instance if there are no more listeners left.\n  return () => {\n    delFromSet(cont, KEY_LISTENERS, listener);\n    delFromSet(cont, KEY_RAW, rawEmitter);\n    if (isEmptySet(cont.listeners)) {\n      FsWatchFileInstances.delete(fullPath);\n      fs$7.unwatchFile(fullPath);\n      cont.options = cont.watcher = undefined;\n      Object.freeze(cont);\n    }\n  };\n};\n\n/**\n * @mixin\n */\nlet NodeFsHandler$1 = class NodeFsHandler {\n\n/**\n * @param {import(\"../index\").FSWatcher} fsW\n */\nconstructor(fsW) {\n  this.fsw = fsW;\n  this._boundHandleError = (error) => fsW._handleError(error);\n}\n\n/**\n * Watch file for changes with fs_watchFile or fs_watch.\n * @param {String} path to file or dir\n * @param {Function} listener on fs change\n * @returns {Function} closer for the watcher instance\n */\n_watchWithNodeFs(path, listener) {\n  const opts = this.fsw.options;\n  const directory = sysPath$2.dirname(path);\n  const basename = sysPath$2.basename(path);\n  const parent = this.fsw._getWatchedDir(directory);\n  parent.add(basename);\n  const absolutePath = sysPath$2.resolve(path);\n  const options = {persistent: opts.persistent};\n  if (!listener) listener = EMPTY_FN$2;\n\n  let closer;\n  if (opts.usePolling) {\n    options.interval = opts.enableBinaryInterval && isBinaryPath(basename) ?\n      opts.binaryInterval : opts.interval;\n    closer = setFsWatchFileListener(path, absolutePath, options, {\n      listener,\n      rawEmitter: this.fsw._emitRaw\n    });\n  } else {\n    closer = setFsWatchListener(path, absolutePath, options, {\n      listener,\n      errHandler: this._boundHandleError,\n      rawEmitter: this.fsw._emitRaw\n    });\n  }\n  return closer;\n}\n\n/**\n * Watch a file and emit add event if warranted.\n * @param {Path} file Path\n * @param {fs.Stats} stats result of fs_stat\n * @param {Boolean} initialAdd was the file added at watch instantiation?\n * @returns {Function} closer for the watcher instance\n */\n_handleFile(file, stats, initialAdd) {\n  if (this.fsw.closed) {\n    return;\n  }\n  const dirname = sysPath$2.dirname(file);\n  const basename = sysPath$2.basename(file);\n  const parent = this.fsw._getWatchedDir(dirname);\n  // stats is always present\n  let prevStats = stats;\n\n  // if the file is already being watched, do nothing\n  if (parent.has(basename)) return;\n\n  const listener = async (path, newStats) => {\n    if (!this.fsw._throttle(THROTTLE_MODE_WATCH, file, 5)) return;\n    if (!newStats || newStats.mtimeMs === 0) {\n      try {\n        const newStats = await stat$2(file);\n        if (this.fsw.closed) return;\n        // Check that change event was not fired because of changed only accessTime.\n        const at = newStats.atimeMs;\n        const mt = newStats.mtimeMs;\n        if (!at || at <= mt || mt !== prevStats.mtimeMs) {\n          this.fsw._emit(EV_CHANGE$2, file, newStats);\n        }\n        if (isLinux && prevStats.ino !== newStats.ino) {\n          this.fsw._closeFile(path);\n          prevStats = newStats;\n          this.fsw._addPathCloser(path, this._watchWithNodeFs(file, listener));\n        } else {\n          prevStats = newStats;\n        }\n      } catch (error) {\n        // Fix issues where mtime is null but file is still present\n        this.fsw._remove(dirname, basename);\n      }\n      // add is about to be emitted if file not already tracked in parent\n    } else if (parent.has(basename)) {\n      // Check that change event was not fired because of changed only accessTime.\n      const at = newStats.atimeMs;\n      const mt = newStats.mtimeMs;\n      if (!at || at <= mt || mt !== prevStats.mtimeMs) {\n        this.fsw._emit(EV_CHANGE$2, file, newStats);\n      }\n      prevStats = newStats;\n    }\n  };\n  // kick off the watcher\n  const closer = this._watchWithNodeFs(file, listener);\n\n  // emit an add event if we're supposed to\n  if (!(initialAdd && this.fsw.options.ignoreInitial) && this.fsw._isntIgnored(file)) {\n    if (!this.fsw._throttle(EV_ADD$2, file, 0)) return;\n    this.fsw._emit(EV_ADD$2, file, stats);\n  }\n\n  return closer;\n}\n\n/**\n * Handle symlinks encountered while reading a dir.\n * @param {Object} entry returned by readdirp\n * @param {String} directory path of dir being read\n * @param {String} path of this item\n * @param {String} item basename of this item\n * @returns {Promise<Boolean>} true if no more processing is needed for this entry.\n */\nasync _handleSymlink(entry, directory, path, item) {\n  if (this.fsw.closed) {\n    return;\n  }\n  const full = entry.fullPath;\n  const dir = this.fsw._getWatchedDir(directory);\n\n  if (!this.fsw.options.followSymlinks) {\n    // watch symlink directly (don't follow) and detect changes\n    this.fsw._incrReadyCount();\n\n    let linkPath;\n    try {\n      linkPath = await fsrealpath(path);\n    } catch (e) {\n      this.fsw._emitReady();\n      return true;\n    }\n\n    if (this.fsw.closed) return;\n    if (dir.has(item)) {\n      if (this.fsw._symlinkPaths.get(full) !== linkPath) {\n        this.fsw._symlinkPaths.set(full, linkPath);\n        this.fsw._emit(EV_CHANGE$2, path, entry.stats);\n      }\n    } else {\n      dir.add(item);\n      this.fsw._symlinkPaths.set(full, linkPath);\n      this.fsw._emit(EV_ADD$2, path, entry.stats);\n    }\n    this.fsw._emitReady();\n    return true;\n  }\n\n  // don't follow the same symlink more than once\n  if (this.fsw._symlinkPaths.has(full)) {\n    return true;\n  }\n\n  this.fsw._symlinkPaths.set(full, true);\n}\n\n_handleRead(directory, initialAdd, wh, target, dir, depth, throttler) {\n  // Normalize the directory name on Windows\n  directory = sysPath$2.join(directory, EMPTY_STR$1);\n\n  if (!wh.hasGlob) {\n    throttler = this.fsw._throttle('readdir', directory, 1000);\n    if (!throttler) return;\n  }\n\n  const previous = this.fsw._getWatchedDir(wh.path);\n  const current = new Set();\n\n  let stream = this.fsw._readdirp(directory, {\n    fileFilter: entry => wh.filterPath(entry),\n    directoryFilter: entry => wh.filterDir(entry),\n    depth: 0\n  }).on(STR_DATA$1, async (entry) => {\n    if (this.fsw.closed) {\n      stream = undefined;\n      return;\n    }\n    const item = entry.path;\n    let path = sysPath$2.join(directory, item);\n    current.add(item);\n\n    if (entry.stats.isSymbolicLink() && await this._handleSymlink(entry, directory, path, item)) {\n      return;\n    }\n\n    if (this.fsw.closed) {\n      stream = undefined;\n      return;\n    }\n    // Files that present in current directory snapshot\n    // but absent in previous are added to watch list and\n    // emit `add` event.\n    if (item === target || !target && !previous.has(item)) {\n      this.fsw._incrReadyCount();\n\n      // ensure relativeness of path is preserved in case of watcher reuse\n      path = sysPath$2.join(dir, sysPath$2.relative(dir, path));\n\n      this._addToNodeFs(path, initialAdd, wh, depth + 1);\n    }\n  }).on(EV_ERROR$2, this._boundHandleError);\n\n  return new Promise(resolve =>\n    stream.once(STR_END$2, () => {\n      if (this.fsw.closed) {\n        stream = undefined;\n        return;\n      }\n      const wasThrottled = throttler ? throttler.clear() : false;\n\n      resolve();\n\n      // Files that absent in current directory snapshot\n      // but present in previous emit `remove` event\n      // and are removed from @watched[directory].\n      previous.getChildren().filter((item) => {\n        return item !== directory &&\n          !current.has(item) &&\n          // in case of intersecting globs;\n          // a path may have been filtered out of this readdir, but\n          // shouldn't be removed because it matches a different glob\n          (!wh.hasGlob || wh.filterPath({\n            fullPath: sysPath$2.resolve(directory, item)\n          }));\n      }).forEach((item) => {\n        this.fsw._remove(directory, item);\n      });\n\n      stream = undefined;\n\n      // one more time for any missed in case changes came in extremely quickly\n      if (wasThrottled) this._handleRead(directory, false, wh, target, dir, depth, throttler);\n    })\n  );\n}\n\n/**\n * Read directory to add / remove files from `@watched` list and re-read it on change.\n * @param {String} dir fs path\n * @param {fs.Stats} stats\n * @param {Boolean} initialAdd\n * @param {Number} depth relative to user-supplied path\n * @param {String} target child path targeted for watch\n * @param {Object} wh Common watch helpers for this path\n * @param {String} realpath\n * @returns {Promise<Function>} closer for the watcher instance.\n */\nasync _handleDir(dir, stats, initialAdd, depth, target, wh, realpath) {\n  const parentDir = this.fsw._getWatchedDir(sysPath$2.dirname(dir));\n  const tracked = parentDir.has(sysPath$2.basename(dir));\n  if (!(initialAdd && this.fsw.options.ignoreInitial) && !target && !tracked) {\n    if (!wh.hasGlob || wh.globFilter(dir)) this.fsw._emit(EV_ADD_DIR$2, dir, stats);\n  }\n\n  // ensure dir is tracked (harmless if redundant)\n  parentDir.add(sysPath$2.basename(dir));\n  this.fsw._getWatchedDir(dir);\n  let throttler;\n  let closer;\n\n  const oDepth = this.fsw.options.depth;\n  if ((oDepth == null || depth <= oDepth) && !this.fsw._symlinkPaths.has(realpath)) {\n    if (!target) {\n      await this._handleRead(dir, initialAdd, wh, target, dir, depth, throttler);\n      if (this.fsw.closed) return;\n    }\n\n    closer = this._watchWithNodeFs(dir, (dirPath, stats) => {\n      // if current directory is removed, do nothing\n      if (stats && stats.mtimeMs === 0) return;\n\n      this._handleRead(dirPath, false, wh, target, dir, depth, throttler);\n    });\n  }\n  return closer;\n}\n\n/**\n * Handle added file, directory, or glob pattern.\n * Delegates call to _handleFile / _handleDir after checks.\n * @param {String} path to file or ir\n * @param {Boolean} initialAdd was the file added at watch instantiation?\n * @param {Object} priorWh depth relative to user-supplied path\n * @param {Number} depth Child path actually targeted for watch\n * @param {String=} target Child path actually targeted for watch\n * @returns {Promise}\n */\nasync _addToNodeFs(path, initialAdd, priorWh, depth, target) {\n  const ready = this.fsw._emitReady;\n  if (this.fsw._isIgnored(path) || this.fsw.closed) {\n    ready();\n    return false;\n  }\n\n  const wh = this.fsw._getWatchHelpers(path, depth);\n  if (!wh.hasGlob && priorWh) {\n    wh.hasGlob = priorWh.hasGlob;\n    wh.globFilter = priorWh.globFilter;\n    wh.filterPath = entry => priorWh.filterPath(entry);\n    wh.filterDir = entry => priorWh.filterDir(entry);\n  }\n\n  // evaluate what is at the path we're being asked to watch\n  try {\n    const stats = await statMethods$1[wh.statMethod](wh.watchPath);\n    if (this.fsw.closed) return;\n    if (this.fsw._isIgnored(wh.watchPath, stats)) {\n      ready();\n      return false;\n    }\n\n    const follow = this.fsw.options.followSymlinks && !path.includes(STAR) && !path.includes(BRACE_START$1);\n    let closer;\n    if (stats.isDirectory()) {\n      const absPath = sysPath$2.resolve(path);\n      const targetPath = follow ? await fsrealpath(path) : path;\n      if (this.fsw.closed) return;\n      closer = await this._handleDir(wh.watchPath, stats, initialAdd, depth, target, wh, targetPath);\n      if (this.fsw.closed) return;\n      // preserve this symlink's target path\n      if (absPath !== targetPath && targetPath !== undefined) {\n        this.fsw._symlinkPaths.set(absPath, targetPath);\n      }\n    } else if (stats.isSymbolicLink()) {\n      const targetPath = follow ? await fsrealpath(path) : path;\n      if (this.fsw.closed) return;\n      const parent = sysPath$2.dirname(wh.watchPath);\n      this.fsw._getWatchedDir(parent).add(wh.watchPath);\n      this.fsw._emit(EV_ADD$2, wh.watchPath, stats);\n      closer = await this._handleDir(parent, stats, initialAdd, depth, path, wh, targetPath);\n      if (this.fsw.closed) return;\n\n      // preserve this symlink's target path\n      if (targetPath !== undefined) {\n        this.fsw._symlinkPaths.set(sysPath$2.resolve(path), targetPath);\n      }\n    } else {\n      closer = this._handleFile(wh.watchPath, stats, initialAdd);\n    }\n    ready();\n\n    this.fsw._addPathCloser(path, closer);\n    return false;\n\n  } catch (error) {\n    if (this.fsw._handleError(error)) {\n      ready();\n      return path;\n    }\n  }\n}\n\n};\n\nvar nodefsHandler = NodeFsHandler$1;\n\nvar fseventsHandlerExports = {};\nvar fseventsHandler = {\n  get exports(){ return fseventsHandlerExports; },\n  set exports(v){ fseventsHandlerExports = v; },\n};\n\nconst fs$6 = require$$0__default;\nconst sysPath$1 = require$$0$4;\nconst { promisify: promisify$1 } = require$$0$6;\n\nlet fsevents;\ntry {\n  fsevents = __require('fsevents');\n} catch (error) {\n  if (process.env.CHOKIDAR_PRINT_FSEVENTS_REQUIRE_ERROR) console.error(error);\n}\n\nif (fsevents) {\n  // TODO: real check\n  const mtch = process.version.match(/v(\\d+)\\.(\\d+)/);\n  if (mtch && mtch[1] && mtch[2]) {\n    const maj = Number.parseInt(mtch[1], 10);\n    const min = Number.parseInt(mtch[2], 10);\n    if (maj === 8 && min < 16) {\n      fsevents = undefined;\n    }\n  }\n}\n\nconst {\n  EV_ADD: EV_ADD$1,\n  EV_CHANGE: EV_CHANGE$1,\n  EV_ADD_DIR: EV_ADD_DIR$1,\n  EV_UNLINK: EV_UNLINK$1,\n  EV_ERROR: EV_ERROR$1,\n  STR_DATA,\n  STR_END: STR_END$1,\n  FSEVENT_CREATED,\n  FSEVENT_MODIFIED,\n  FSEVENT_DELETED,\n  FSEVENT_MOVED,\n  // FSEVENT_CLONED,\n  FSEVENT_UNKNOWN,\n  FSEVENT_TYPE_FILE,\n  FSEVENT_TYPE_DIRECTORY,\n  FSEVENT_TYPE_SYMLINK,\n\n  ROOT_GLOBSTAR,\n  DIR_SUFFIX,\n  DOT_SLASH,\n  FUNCTION_TYPE: FUNCTION_TYPE$1,\n  EMPTY_FN: EMPTY_FN$1,\n  IDENTITY_FN\n} = constants$1;\n\nconst Depth = (value) => isNaN(value) ? {} : {depth: value};\n\nconst stat$1 = promisify$1(fs$6.stat);\nconst lstat = promisify$1(fs$6.lstat);\nconst realpath = promisify$1(fs$6.realpath);\n\nconst statMethods = { stat: stat$1, lstat };\n\n/**\n * @typedef {String} Path\n */\n\n/**\n * @typedef {Object} FsEventsWatchContainer\n * @property {Set<Function>} listeners\n * @property {Function} rawEmitter\n * @property {{stop: Function}} watcher\n */\n\n// fsevents instance helper functions\n/**\n * Object to hold per-process fsevents instances (may be shared across chokidar FSWatcher instances)\n * @type {Map<Path,FsEventsWatchContainer>}\n */\nconst FSEventsWatchers = new Map();\n\n// Threshold of duplicate path prefixes at which to start\n// consolidating going forward\nconst consolidateThreshhold = 10;\n\nconst wrongEventFlags = new Set([\n  69888, 70400, 71424, 72704, 73472, 131328, 131840, 262912\n]);\n\n/**\n * Instantiates the fsevents interface\n * @param {Path} path path to be watched\n * @param {Function} callback called when fsevents is bound and ready\n * @returns {{stop: Function}} new fsevents instance\n */\nconst createFSEventsInstance = (path, callback) => {\n  const stop = fsevents.watch(path, callback);\n  return {stop};\n};\n\n/**\n * Instantiates the fsevents interface or binds listeners to an existing one covering\n * the same file tree.\n * @param {Path} path           - to be watched\n * @param {Path} realPath       - real path for symlinks\n * @param {Function} listener   - called when fsevents emits events\n * @param {Function} rawEmitter - passes data to listeners of the 'raw' event\n * @returns {Function} closer\n */\nfunction setFSEventsListener(path, realPath, listener, rawEmitter) {\n  let watchPath = sysPath$1.extname(realPath) ? sysPath$1.dirname(realPath) : realPath;\n\n  const parentPath = sysPath$1.dirname(watchPath);\n  let cont = FSEventsWatchers.get(watchPath);\n\n  // If we've accumulated a substantial number of paths that\n  // could have been consolidated by watching one directory\n  // above the current one, create a watcher on the parent\n  // path instead, so that we do consolidate going forward.\n  if (couldConsolidate(parentPath)) {\n    watchPath = parentPath;\n  }\n\n  const resolvedPath = sysPath$1.resolve(path);\n  const hasSymlink = resolvedPath !== realPath;\n\n  const filteredListener = (fullPath, flags, info) => {\n    if (hasSymlink) fullPath = fullPath.replace(realPath, resolvedPath);\n    if (\n      fullPath === resolvedPath ||\n      !fullPath.indexOf(resolvedPath + sysPath$1.sep)\n    ) listener(fullPath, flags, info);\n  };\n\n  // check if there is already a watcher on a parent path\n  // modifies `watchPath` to the parent path when it finds a match\n  let watchedParent = false;\n  for (const watchedPath of FSEventsWatchers.keys()) {\n    if (realPath.indexOf(sysPath$1.resolve(watchedPath) + sysPath$1.sep) === 0) {\n      watchPath = watchedPath;\n      cont = FSEventsWatchers.get(watchPath);\n      watchedParent = true;\n      break;\n    }\n  }\n\n  if (cont || watchedParent) {\n    cont.listeners.add(filteredListener);\n  } else {\n    cont = {\n      listeners: new Set([filteredListener]),\n      rawEmitter,\n      watcher: createFSEventsInstance(watchPath, (fullPath, flags) => {\n        if (!cont.listeners.size) return;\n        const info = fsevents.getInfo(fullPath, flags);\n        cont.listeners.forEach(list => {\n          list(fullPath, flags, info);\n        });\n\n        cont.rawEmitter(info.event, fullPath, info);\n      })\n    };\n    FSEventsWatchers.set(watchPath, cont);\n  }\n\n  // removes this instance's listeners and closes the underlying fsevents\n  // instance if there are no more listeners left\n  return () => {\n    const lst = cont.listeners;\n\n    lst.delete(filteredListener);\n    if (!lst.size) {\n      FSEventsWatchers.delete(watchPath);\n      if (cont.watcher) return cont.watcher.stop().then(() => {\n        cont.rawEmitter = cont.watcher = undefined;\n        Object.freeze(cont);\n      });\n    }\n  };\n}\n\n// Decide whether or not we should start a new higher-level\n// parent watcher\nconst couldConsolidate = (path) => {\n  let count = 0;\n  for (const watchPath of FSEventsWatchers.keys()) {\n    if (watchPath.indexOf(path) === 0) {\n      count++;\n      if (count >= consolidateThreshhold) {\n        return true;\n      }\n    }\n  }\n\n  return false;\n};\n\n// returns boolean indicating whether fsevents can be used\nconst canUse = () => fsevents && FSEventsWatchers.size < 128;\n\n// determines subdirectory traversal levels from root to path\nconst calcDepth = (path, root) => {\n  let i = 0;\n  while (!path.indexOf(root) && (path = sysPath$1.dirname(path)) !== root) i++;\n  return i;\n};\n\n// returns boolean indicating whether the fsevents' event info has the same type\n// as the one returned by fs.stat\nconst sameTypes = (info, stats) => (\n  info.type === FSEVENT_TYPE_DIRECTORY && stats.isDirectory() ||\n  info.type === FSEVENT_TYPE_SYMLINK && stats.isSymbolicLink() ||\n  info.type === FSEVENT_TYPE_FILE && stats.isFile()\n);\n\n/**\n * @mixin\n */\nlet FsEventsHandler$1 = class FsEventsHandler {\n\n/**\n * @param {import('../index').FSWatcher} fsw\n */\nconstructor(fsw) {\n  this.fsw = fsw;\n}\ncheckIgnored(path, stats) {\n  const ipaths = this.fsw._ignoredPaths;\n  if (this.fsw._isIgnored(path, stats)) {\n    ipaths.add(path);\n    if (stats && stats.isDirectory()) {\n      ipaths.add(path + ROOT_GLOBSTAR);\n    }\n    return true;\n  }\n\n  ipaths.delete(path);\n  ipaths.delete(path + ROOT_GLOBSTAR);\n}\n\naddOrChange(path, fullPath, realPath, parent, watchedDir, item, info, opts) {\n  const event = watchedDir.has(item) ? EV_CHANGE$1 : EV_ADD$1;\n  this.handleEvent(event, path, fullPath, realPath, parent, watchedDir, item, info, opts);\n}\n\nasync checkExists(path, fullPath, realPath, parent, watchedDir, item, info, opts) {\n  try {\n    const stats = await stat$1(path);\n    if (this.fsw.closed) return;\n    if (sameTypes(info, stats)) {\n      this.addOrChange(path, fullPath, realPath, parent, watchedDir, item, info, opts);\n    } else {\n      this.handleEvent(EV_UNLINK$1, path, fullPath, realPath, parent, watchedDir, item, info, opts);\n    }\n  } catch (error) {\n    if (error.code === 'EACCES') {\n      this.addOrChange(path, fullPath, realPath, parent, watchedDir, item, info, opts);\n    } else {\n      this.handleEvent(EV_UNLINK$1, path, fullPath, realPath, parent, watchedDir, item, info, opts);\n    }\n  }\n}\n\nhandleEvent(event, path, fullPath, realPath, parent, watchedDir, item, info, opts) {\n  if (this.fsw.closed || this.checkIgnored(path)) return;\n\n  if (event === EV_UNLINK$1) {\n    const isDirectory = info.type === FSEVENT_TYPE_DIRECTORY;\n    // suppress unlink events on never before seen files\n    if (isDirectory || watchedDir.has(item)) {\n      this.fsw._remove(parent, item, isDirectory);\n    }\n  } else {\n    if (event === EV_ADD$1) {\n      // track new directories\n      if (info.type === FSEVENT_TYPE_DIRECTORY) this.fsw._getWatchedDir(path);\n\n      if (info.type === FSEVENT_TYPE_SYMLINK && opts.followSymlinks) {\n        // push symlinks back to the top of the stack to get handled\n        const curDepth = opts.depth === undefined ?\n          undefined : calcDepth(fullPath, realPath) + 1;\n        return this._addToFsEvents(path, false, true, curDepth);\n      }\n\n      // track new paths\n      // (other than symlinks being followed, which will be tracked soon)\n      this.fsw._getWatchedDir(parent).add(item);\n    }\n    /**\n     * @type {'add'|'addDir'|'unlink'|'unlinkDir'}\n     */\n    const eventName = info.type === FSEVENT_TYPE_DIRECTORY ? event + DIR_SUFFIX : event;\n    this.fsw._emit(eventName, path);\n    if (eventName === EV_ADD_DIR$1) this._addToFsEvents(path, false, true);\n  }\n}\n\n/**\n * Handle symlinks encountered during directory scan\n * @param {String} watchPath  - file/dir path to be watched with fsevents\n * @param {String} realPath   - real path (in case of symlinks)\n * @param {Function} transform  - path transformer\n * @param {Function} globFilter - path filter in case a glob pattern was provided\n * @returns {Function} closer for the watcher instance\n*/\n_watchWithFsEvents(watchPath, realPath, transform, globFilter) {\n  if (this.fsw.closed || this.fsw._isIgnored(watchPath)) return;\n  const opts = this.fsw.options;\n  const watchCallback = async (fullPath, flags, info) => {\n    if (this.fsw.closed) return;\n    if (\n      opts.depth !== undefined &&\n      calcDepth(fullPath, realPath) > opts.depth\n    ) return;\n    const path = transform(sysPath$1.join(\n      watchPath, sysPath$1.relative(watchPath, fullPath)\n    ));\n    if (globFilter && !globFilter(path)) return;\n    // ensure directories are tracked\n    const parent = sysPath$1.dirname(path);\n    const item = sysPath$1.basename(path);\n    const watchedDir = this.fsw._getWatchedDir(\n      info.type === FSEVENT_TYPE_DIRECTORY ? path : parent\n    );\n\n    // correct for wrong events emitted\n    if (wrongEventFlags.has(flags) || info.event === FSEVENT_UNKNOWN) {\n      if (typeof opts.ignored === FUNCTION_TYPE$1) {\n        let stats;\n        try {\n          stats = await stat$1(path);\n        } catch (error) {}\n        if (this.fsw.closed) return;\n        if (this.checkIgnored(path, stats)) return;\n        if (sameTypes(info, stats)) {\n          this.addOrChange(path, fullPath, realPath, parent, watchedDir, item, info, opts);\n        } else {\n          this.handleEvent(EV_UNLINK$1, path, fullPath, realPath, parent, watchedDir, item, info, opts);\n        }\n      } else {\n        this.checkExists(path, fullPath, realPath, parent, watchedDir, item, info, opts);\n      }\n    } else {\n      switch (info.event) {\n      case FSEVENT_CREATED:\n      case FSEVENT_MODIFIED:\n        return this.addOrChange(path, fullPath, realPath, parent, watchedDir, item, info, opts);\n      case FSEVENT_DELETED:\n      case FSEVENT_MOVED:\n        return this.checkExists(path, fullPath, realPath, parent, watchedDir, item, info, opts);\n      }\n    }\n  };\n\n  const closer = setFSEventsListener(\n    watchPath,\n    realPath,\n    watchCallback,\n    this.fsw._emitRaw\n  );\n\n  this.fsw._emitReady();\n  return closer;\n}\n\n/**\n * Handle symlinks encountered during directory scan\n * @param {String} linkPath path to symlink\n * @param {String} fullPath absolute path to the symlink\n * @param {Function} transform pre-existing path transformer\n * @param {Number} curDepth level of subdirectories traversed to where symlink is\n * @returns {Promise<void>}\n */\nasync _handleFsEventsSymlink(linkPath, fullPath, transform, curDepth) {\n  // don't follow the same symlink more than once\n  if (this.fsw.closed || this.fsw._symlinkPaths.has(fullPath)) return;\n\n  this.fsw._symlinkPaths.set(fullPath, true);\n  this.fsw._incrReadyCount();\n\n  try {\n    const linkTarget = await realpath(linkPath);\n    if (this.fsw.closed) return;\n    if (this.fsw._isIgnored(linkTarget)) {\n      return this.fsw._emitReady();\n    }\n\n    this.fsw._incrReadyCount();\n\n    // add the linkTarget for watching with a wrapper for transform\n    // that causes emitted paths to incorporate the link's path\n    this._addToFsEvents(linkTarget || linkPath, (path) => {\n      let aliasedPath = linkPath;\n      if (linkTarget && linkTarget !== DOT_SLASH) {\n        aliasedPath = path.replace(linkTarget, linkPath);\n      } else if (path !== DOT_SLASH) {\n        aliasedPath = sysPath$1.join(linkPath, path);\n      }\n      return transform(aliasedPath);\n    }, false, curDepth);\n  } catch(error) {\n    if (this.fsw._handleError(error)) {\n      return this.fsw._emitReady();\n    }\n  }\n}\n\n/**\n *\n * @param {Path} newPath\n * @param {fs.Stats} stats\n */\nemitAdd(newPath, stats, processPath, opts, forceAdd) {\n  const pp = processPath(newPath);\n  const isDir = stats.isDirectory();\n  const dirObj = this.fsw._getWatchedDir(sysPath$1.dirname(pp));\n  const base = sysPath$1.basename(pp);\n\n  // ensure empty dirs get tracked\n  if (isDir) this.fsw._getWatchedDir(pp);\n  if (dirObj.has(base)) return;\n  dirObj.add(base);\n\n  if (!opts.ignoreInitial || forceAdd === true) {\n    this.fsw._emit(isDir ? EV_ADD_DIR$1 : EV_ADD$1, pp, stats);\n  }\n}\n\ninitWatch(realPath, path, wh, processPath) {\n  if (this.fsw.closed) return;\n  const closer = this._watchWithFsEvents(\n    wh.watchPath,\n    sysPath$1.resolve(realPath || wh.watchPath),\n    processPath,\n    wh.globFilter\n  );\n  this.fsw._addPathCloser(path, closer);\n}\n\n/**\n * Handle added path with fsevents\n * @param {String} path file/dir path or glob pattern\n * @param {Function|Boolean=} transform converts working path to what the user expects\n * @param {Boolean=} forceAdd ensure add is emitted\n * @param {Number=} priorDepth Level of subdirectories already traversed.\n * @returns {Promise<void>}\n */\nasync _addToFsEvents(path, transform, forceAdd, priorDepth) {\n  if (this.fsw.closed) {\n    return;\n  }\n  const opts = this.fsw.options;\n  const processPath = typeof transform === FUNCTION_TYPE$1 ? transform : IDENTITY_FN;\n\n  const wh = this.fsw._getWatchHelpers(path);\n\n  // evaluate what is at the path we're being asked to watch\n  try {\n    const stats = await statMethods[wh.statMethod](wh.watchPath);\n    if (this.fsw.closed) return;\n    if (this.fsw._isIgnored(wh.watchPath, stats)) {\n      throw null;\n    }\n    if (stats.isDirectory()) {\n      // emit addDir unless this is a glob parent\n      if (!wh.globFilter) this.emitAdd(processPath(path), stats, processPath, opts, forceAdd);\n\n      // don't recurse further if it would exceed depth setting\n      if (priorDepth && priorDepth > opts.depth) return;\n\n      // scan the contents of the dir\n      this.fsw._readdirp(wh.watchPath, {\n        fileFilter: entry => wh.filterPath(entry),\n        directoryFilter: entry => wh.filterDir(entry),\n        ...Depth(opts.depth - (priorDepth || 0))\n      }).on(STR_DATA, (entry) => {\n        // need to check filterPath on dirs b/c filterDir is less restrictive\n        if (this.fsw.closed) {\n          return;\n        }\n        if (entry.stats.isDirectory() && !wh.filterPath(entry)) return;\n\n        const joinedPath = sysPath$1.join(wh.watchPath, entry.path);\n        const {fullPath} = entry;\n\n        if (wh.followSymlinks && entry.stats.isSymbolicLink()) {\n          // preserve the current depth here since it can't be derived from\n          // real paths past the symlink\n          const curDepth = opts.depth === undefined ?\n            undefined : calcDepth(joinedPath, sysPath$1.resolve(wh.watchPath)) + 1;\n\n          this._handleFsEventsSymlink(joinedPath, fullPath, processPath, curDepth);\n        } else {\n          this.emitAdd(joinedPath, entry.stats, processPath, opts, forceAdd);\n        }\n      }).on(EV_ERROR$1, EMPTY_FN$1).on(STR_END$1, () => {\n        this.fsw._emitReady();\n      });\n    } else {\n      this.emitAdd(wh.watchPath, stats, processPath, opts, forceAdd);\n      this.fsw._emitReady();\n    }\n  } catch (error) {\n    if (!error || this.fsw._handleError(error)) {\n      // TODO: Strange thing: \"should not choke on an ignored watch path\" will be failed without 2 ready calls -__-\n      this.fsw._emitReady();\n      this.fsw._emitReady();\n    }\n  }\n\n  if (opts.persistent && forceAdd !== true) {\n    if (typeof transform === FUNCTION_TYPE$1) {\n      // realpath has already been resolved\n      this.initWatch(undefined, path, wh, processPath);\n    } else {\n      let realPath;\n      try {\n        realPath = await realpath(wh.watchPath);\n      } catch (e) {}\n      this.initWatch(realPath, path, wh, processPath);\n    }\n  }\n}\n\n};\n\nfseventsHandler.exports = FsEventsHandler$1;\nfseventsHandlerExports.canUse = canUse;\n\nconst { EventEmitter: EventEmitter$2 } = require$$0$5;\nconst fs$5 = require$$0__default;\nconst sysPath = require$$0$4;\nconst { promisify } = require$$0$6;\nconst readdirp = readdirp_1;\nconst anymatch = anymatchExports.default;\nconst globParent = globParent$2;\nconst isGlob = isGlob$2;\nconst braces = braces_1;\nconst normalizePath = normalizePath$2;\n\nconst NodeFsHandler = nodefsHandler;\nconst FsEventsHandler = fseventsHandlerExports;\nconst {\n  EV_ALL,\n  EV_READY,\n  EV_ADD,\n  EV_CHANGE,\n  EV_UNLINK,\n  EV_ADD_DIR,\n  EV_UNLINK_DIR,\n  EV_RAW,\n  EV_ERROR,\n\n  STR_CLOSE,\n  STR_END,\n\n  BACK_SLASH_RE,\n  DOUBLE_SLASH_RE,\n  SLASH_OR_BACK_SLASH_RE,\n  DOT_RE,\n  REPLACER_RE,\n\n  SLASH,\n  SLASH_SLASH,\n  BRACE_START,\n  BANG,\n  ONE_DOT,\n  TWO_DOTS,\n  GLOBSTAR,\n  SLASH_GLOBSTAR,\n  ANYMATCH_OPTS,\n  STRING_TYPE,\n  FUNCTION_TYPE,\n  EMPTY_STR,\n  EMPTY_FN,\n\n  isWindows: isWindows$1,\n  isMacos,\n  isIBMi\n} = constants$1;\n\nconst stat = promisify(fs$5.stat);\nconst readdir = promisify(fs$5.readdir);\n\n/**\n * @typedef {String} Path\n * @typedef {'all'|'add'|'addDir'|'change'|'unlink'|'unlinkDir'|'raw'|'error'|'ready'} EventName\n * @typedef {'readdir'|'watch'|'add'|'remove'|'change'} ThrottleType\n */\n\n/**\n *\n * @typedef {Object} WatchHelpers\n * @property {Boolean} followSymlinks\n * @property {'stat'|'lstat'} statMethod\n * @property {Path} path\n * @property {Path} watchPath\n * @property {Function} entryPath\n * @property {Boolean} hasGlob\n * @property {Object} globFilter\n * @property {Function} filterPath\n * @property {Function} filterDir\n */\n\nconst arrify = (value = []) => Array.isArray(value) ? value : [value];\nconst flatten = (list, result = []) => {\n  list.forEach(item => {\n    if (Array.isArray(item)) {\n      flatten(item, result);\n    } else {\n      result.push(item);\n    }\n  });\n  return result;\n};\n\nconst unifyPaths = (paths_) => {\n  /**\n   * @type {Array<String>}\n   */\n  const paths = flatten(arrify(paths_));\n  if (!paths.every(p => typeof p === STRING_TYPE)) {\n    throw new TypeError(`Non-string provided as watch path: ${paths}`);\n  }\n  return paths.map(normalizePathToUnix);\n};\n\n// If SLASH_SLASH occurs at the beginning of path, it is not replaced\n//     because \"//StoragePC/DrivePool/Movies\" is a valid network path\nconst toUnix = (string) => {\n  let str = string.replace(BACK_SLASH_RE, SLASH);\n  let prepend = false;\n  if (str.startsWith(SLASH_SLASH)) {\n    prepend = true;\n  }\n  while (str.match(DOUBLE_SLASH_RE)) {\n    str = str.replace(DOUBLE_SLASH_RE, SLASH);\n  }\n  if (prepend) {\n    str = SLASH + str;\n  }\n  return str;\n};\n\n// Our version of upath.normalize\n// TODO: this is not equal to path-normalize module - investigate why\nconst normalizePathToUnix = (path) => toUnix(sysPath.normalize(toUnix(path)));\n\nconst normalizeIgnored = (cwd = EMPTY_STR) => (path) => {\n  if (typeof path !== STRING_TYPE) return path;\n  return normalizePathToUnix(sysPath.isAbsolute(path) ? path : sysPath.join(cwd, path));\n};\n\nconst getAbsolutePath = (path, cwd) => {\n  if (sysPath.isAbsolute(path)) {\n    return path;\n  }\n  if (path.startsWith(BANG)) {\n    return BANG + sysPath.join(cwd, path.slice(1));\n  }\n  return sysPath.join(cwd, path);\n};\n\nconst undef = (opts, key) => opts[key] === undefined;\n\n/**\n * Directory entry.\n * @property {Path} path\n * @property {Set<Path>} items\n */\nclass DirEntry {\n  /**\n   * @param {Path} dir\n   * @param {Function} removeWatcher\n   */\n  constructor(dir, removeWatcher) {\n    this.path = dir;\n    this._removeWatcher = removeWatcher;\n    /** @type {Set<Path>} */\n    this.items = new Set();\n  }\n\n  add(item) {\n    const {items} = this;\n    if (!items) return;\n    if (item !== ONE_DOT && item !== TWO_DOTS) items.add(item);\n  }\n\n  async remove(item) {\n    const {items} = this;\n    if (!items) return;\n    items.delete(item);\n    if (items.size > 0) return;\n\n    const dir = this.path;\n    try {\n      await readdir(dir);\n    } catch (err) {\n      if (this._removeWatcher) {\n        this._removeWatcher(sysPath.dirname(dir), sysPath.basename(dir));\n      }\n    }\n  }\n\n  has(item) {\n    const {items} = this;\n    if (!items) return;\n    return items.has(item);\n  }\n\n  /**\n   * @returns {Array<String>}\n   */\n  getChildren() {\n    const {items} = this;\n    if (!items) return;\n    return [...items.values()];\n  }\n\n  dispose() {\n    this.items.clear();\n    delete this.path;\n    delete this._removeWatcher;\n    delete this.items;\n    Object.freeze(this);\n  }\n}\n\nconst STAT_METHOD_F = 'stat';\nconst STAT_METHOD_L = 'lstat';\nclass WatchHelper {\n  constructor(path, watchPath, follow, fsw) {\n    this.fsw = fsw;\n    this.path = path = path.replace(REPLACER_RE, EMPTY_STR);\n    this.watchPath = watchPath;\n    this.fullWatchPath = sysPath.resolve(watchPath);\n    this.hasGlob = watchPath !== path;\n    /** @type {object|boolean} */\n    if (path === EMPTY_STR) this.hasGlob = false;\n    this.globSymlink = this.hasGlob && follow ? undefined : false;\n    this.globFilter = this.hasGlob ? anymatch(path, undefined, ANYMATCH_OPTS) : false;\n    this.dirParts = this.getDirParts(path);\n    this.dirParts.forEach((parts) => {\n      if (parts.length > 1) parts.pop();\n    });\n    this.followSymlinks = follow;\n    this.statMethod = follow ? STAT_METHOD_F : STAT_METHOD_L;\n  }\n\n  checkGlobSymlink(entry) {\n    // only need to resolve once\n    // first entry should always have entry.parentDir === EMPTY_STR\n    if (this.globSymlink === undefined) {\n      this.globSymlink = entry.fullParentDir === this.fullWatchPath ?\n        false : {realPath: entry.fullParentDir, linkPath: this.fullWatchPath};\n    }\n\n    if (this.globSymlink) {\n      return entry.fullPath.replace(this.globSymlink.realPath, this.globSymlink.linkPath);\n    }\n\n    return entry.fullPath;\n  }\n\n  entryPath(entry) {\n    return sysPath.join(this.watchPath,\n      sysPath.relative(this.watchPath, this.checkGlobSymlink(entry))\n    );\n  }\n\n  filterPath(entry) {\n    const {stats} = entry;\n    if (stats && stats.isSymbolicLink()) return this.filterDir(entry);\n    const resolvedPath = this.entryPath(entry);\n    const matchesGlob = this.hasGlob && typeof this.globFilter === FUNCTION_TYPE ?\n      this.globFilter(resolvedPath) : true;\n    return matchesGlob &&\n      this.fsw._isntIgnored(resolvedPath, stats) &&\n      this.fsw._hasReadPermissions(stats);\n  }\n\n  getDirParts(path) {\n    if (!this.hasGlob) return [];\n    const parts = [];\n    const expandedPath = path.includes(BRACE_START) ? braces.expand(path) : [path];\n    expandedPath.forEach((path) => {\n      parts.push(sysPath.relative(this.watchPath, path).split(SLASH_OR_BACK_SLASH_RE));\n    });\n    return parts;\n  }\n\n  filterDir(entry) {\n    if (this.hasGlob) {\n      const entryParts = this.getDirParts(this.checkGlobSymlink(entry));\n      let globstar = false;\n      this.unmatchedGlob = !this.dirParts.some((parts) => {\n        return parts.every((part, i) => {\n          if (part === GLOBSTAR) globstar = true;\n          return globstar || !entryParts[0][i] || anymatch(part, entryParts[0][i], ANYMATCH_OPTS);\n        });\n      });\n    }\n    return !this.unmatchedGlob && this.fsw._isntIgnored(this.entryPath(entry), entry.stats);\n  }\n}\n\n/**\n * Watches files & directories for changes. Emitted events:\n * `add`, `addDir`, `change`, `unlink`, `unlinkDir`, `all`, `error`\n *\n *     new FSWatcher()\n *       .add(directories)\n *       .on('add', path => log('File', path, 'was added'))\n */\nclass FSWatcher extends EventEmitter$2 {\n// Not indenting methods for history sake; for now.\nconstructor(_opts) {\n  super();\n\n  const opts = {};\n  if (_opts) Object.assign(opts, _opts); // for frozen objects\n\n  /** @type {Map<String, DirEntry>} */\n  this._watched = new Map();\n  /** @type {Map<String, Array>} */\n  this._closers = new Map();\n  /** @type {Set<String>} */\n  this._ignoredPaths = new Set();\n\n  /** @type {Map<ThrottleType, Map>} */\n  this._throttled = new Map();\n\n  /** @type {Map<Path, String|Boolean>} */\n  this._symlinkPaths = new Map();\n\n  this._streams = new Set();\n  this.closed = false;\n\n  // Set up default options.\n  if (undef(opts, 'persistent')) opts.persistent = true;\n  if (undef(opts, 'ignoreInitial')) opts.ignoreInitial = false;\n  if (undef(opts, 'ignorePermissionErrors')) opts.ignorePermissionErrors = false;\n  if (undef(opts, 'interval')) opts.interval = 100;\n  if (undef(opts, 'binaryInterval')) opts.binaryInterval = 300;\n  if (undef(opts, 'disableGlobbing')) opts.disableGlobbing = false;\n  opts.enableBinaryInterval = opts.binaryInterval !== opts.interval;\n\n  // Enable fsevents on OS X when polling isn't explicitly enabled.\n  if (undef(opts, 'useFsEvents')) opts.useFsEvents = !opts.usePolling;\n\n  // If we can't use fsevents, ensure the options reflect it's disabled.\n  const canUseFsEvents = FsEventsHandler.canUse();\n  if (!canUseFsEvents) opts.useFsEvents = false;\n\n  // Use polling on Mac if not using fsevents.\n  // Other platforms use non-polling fs_watch.\n  if (undef(opts, 'usePolling') && !opts.useFsEvents) {\n    opts.usePolling = isMacos;\n  }\n\n  // Always default to polling on IBM i because fs.watch() is not available on IBM i.\n  if(isIBMi) {\n    opts.usePolling = true;\n  }\n\n  // Global override (useful for end-developers that need to force polling for all\n  // instances of chokidar, regardless of usage/dependency depth)\n  const envPoll = process.env.CHOKIDAR_USEPOLLING;\n  if (envPoll !== undefined) {\n    const envLower = envPoll.toLowerCase();\n\n    if (envLower === 'false' || envLower === '0') {\n      opts.usePolling = false;\n    } else if (envLower === 'true' || envLower === '1') {\n      opts.usePolling = true;\n    } else {\n      opts.usePolling = !!envLower;\n    }\n  }\n  const envInterval = process.env.CHOKIDAR_INTERVAL;\n  if (envInterval) {\n    opts.interval = Number.parseInt(envInterval, 10);\n  }\n\n  // Editor atomic write normalization enabled by default with fs.watch\n  if (undef(opts, 'atomic')) opts.atomic = !opts.usePolling && !opts.useFsEvents;\n  if (opts.atomic) this._pendingUnlinks = new Map();\n\n  if (undef(opts, 'followSymlinks')) opts.followSymlinks = true;\n\n  if (undef(opts, 'awaitWriteFinish')) opts.awaitWriteFinish = false;\n  if (opts.awaitWriteFinish === true) opts.awaitWriteFinish = {};\n  const awf = opts.awaitWriteFinish;\n  if (awf) {\n    if (!awf.stabilityThreshold) awf.stabilityThreshold = 2000;\n    if (!awf.pollInterval) awf.pollInterval = 100;\n    this._pendingWrites = new Map();\n  }\n  if (opts.ignored) opts.ignored = arrify(opts.ignored);\n\n  let readyCalls = 0;\n  this._emitReady = () => {\n    readyCalls++;\n    if (readyCalls >= this._readyCount) {\n      this._emitReady = EMPTY_FN;\n      this._readyEmitted = true;\n      // use process.nextTick to allow time for listener to be bound\n      process.nextTick(() => this.emit(EV_READY));\n    }\n  };\n  this._emitRaw = (...args) => this.emit(EV_RAW, ...args);\n  this._readyEmitted = false;\n  this.options = opts;\n\n  // Initialize with proper watcher.\n  if (opts.useFsEvents) {\n    this._fsEventsHandler = new FsEventsHandler(this);\n  } else {\n    this._nodeFsHandler = new NodeFsHandler(this);\n  }\n\n  // You’re frozen when your heart’s not open.\n  Object.freeze(opts);\n}\n\n// Public methods\n\n/**\n * Adds paths to be watched on an existing FSWatcher instance\n * @param {Path|Array<Path>} paths_\n * @param {String=} _origAdd private; for handling non-existent paths to be watched\n * @param {Boolean=} _internal private; indicates a non-user add\n * @returns {FSWatcher} for chaining\n */\nadd(paths_, _origAdd, _internal) {\n  const {cwd, disableGlobbing} = this.options;\n  this.closed = false;\n  let paths = unifyPaths(paths_);\n  if (cwd) {\n    paths = paths.map((path) => {\n      const absPath = getAbsolutePath(path, cwd);\n\n      // Check `path` instead of `absPath` because the cwd portion can't be a glob\n      if (disableGlobbing || !isGlob(path)) {\n        return absPath;\n      }\n      return normalizePath(absPath);\n    });\n  }\n\n  // set aside negated glob strings\n  paths = paths.filter((path) => {\n    if (path.startsWith(BANG)) {\n      this._ignoredPaths.add(path.slice(1));\n      return false;\n    }\n\n    // if a path is being added that was previously ignored, stop ignoring it\n    this._ignoredPaths.delete(path);\n    this._ignoredPaths.delete(path + SLASH_GLOBSTAR);\n\n    // reset the cached userIgnored anymatch fn\n    // to make ignoredPaths changes effective\n    this._userIgnored = undefined;\n\n    return true;\n  });\n\n  if (this.options.useFsEvents && this._fsEventsHandler) {\n    if (!this._readyCount) this._readyCount = paths.length;\n    if (this.options.persistent) this._readyCount *= 2;\n    paths.forEach((path) => this._fsEventsHandler._addToFsEvents(path));\n  } else {\n    if (!this._readyCount) this._readyCount = 0;\n    this._readyCount += paths.length;\n    Promise.all(\n      paths.map(async path => {\n        const res = await this._nodeFsHandler._addToNodeFs(path, !_internal, 0, 0, _origAdd);\n        if (res) this._emitReady();\n        return res;\n      })\n    ).then(results => {\n      if (this.closed) return;\n      results.filter(item => item).forEach(item => {\n        this.add(sysPath.dirname(item), sysPath.basename(_origAdd || item));\n      });\n    });\n  }\n\n  return this;\n}\n\n/**\n * Close watchers or start ignoring events from specified paths.\n * @param {Path|Array<Path>} paths_ - string or array of strings, file/directory paths and/or globs\n * @returns {FSWatcher} for chaining\n*/\nunwatch(paths_) {\n  if (this.closed) return this;\n  const paths = unifyPaths(paths_);\n  const {cwd} = this.options;\n\n  paths.forEach((path) => {\n    // convert to absolute path unless relative path already matches\n    if (!sysPath.isAbsolute(path) && !this._closers.has(path)) {\n      if (cwd) path = sysPath.join(cwd, path);\n      path = sysPath.resolve(path);\n    }\n\n    this._closePath(path);\n\n    this._ignoredPaths.add(path);\n    if (this._watched.has(path)) {\n      this._ignoredPaths.add(path + SLASH_GLOBSTAR);\n    }\n\n    // reset the cached userIgnored anymatch fn\n    // to make ignoredPaths changes effective\n    this._userIgnored = undefined;\n  });\n\n  return this;\n}\n\n/**\n * Close watchers and remove all listeners from watched paths.\n * @returns {Promise<void>}.\n*/\nclose() {\n  if (this.closed) return this._closePromise;\n  this.closed = true;\n\n  // Memory management.\n  this.removeAllListeners();\n  const closers = [];\n  this._closers.forEach(closerList => closerList.forEach(closer => {\n    const promise = closer();\n    if (promise instanceof Promise) closers.push(promise);\n  }));\n  this._streams.forEach(stream => stream.destroy());\n  this._userIgnored = undefined;\n  this._readyCount = 0;\n  this._readyEmitted = false;\n  this._watched.forEach(dirent => dirent.dispose());\n  ['closers', 'watched', 'streams', 'symlinkPaths', 'throttled'].forEach(key => {\n    this[`_${key}`].clear();\n  });\n\n  this._closePromise = closers.length ? Promise.all(closers).then(() => undefined) : Promise.resolve();\n  return this._closePromise;\n}\n\n/**\n * Expose list of watched paths\n * @returns {Object} for chaining\n*/\ngetWatched() {\n  const watchList = {};\n  this._watched.forEach((entry, dir) => {\n    const key = this.options.cwd ? sysPath.relative(this.options.cwd, dir) : dir;\n    watchList[key || ONE_DOT] = entry.getChildren().sort();\n  });\n  return watchList;\n}\n\nemitWithAll(event, args) {\n  this.emit(...args);\n  if (event !== EV_ERROR) this.emit(EV_ALL, ...args);\n}\n\n// Common helpers\n// --------------\n\n/**\n * Normalize and emit events.\n * Calling _emit DOES NOT MEAN emit() would be called!\n * @param {EventName} event Type of event\n * @param {Path} path File or directory path\n * @param {*=} val1 arguments to be passed with event\n * @param {*=} val2\n * @param {*=} val3\n * @returns the error if defined, otherwise the value of the FSWatcher instance's `closed` flag\n */\nasync _emit(event, path, val1, val2, val3) {\n  if (this.closed) return;\n\n  const opts = this.options;\n  if (isWindows$1) path = sysPath.normalize(path);\n  if (opts.cwd) path = sysPath.relative(opts.cwd, path);\n  /** @type Array<any> */\n  const args = [event, path];\n  if (val3 !== undefined) args.push(val1, val2, val3);\n  else if (val2 !== undefined) args.push(val1, val2);\n  else if (val1 !== undefined) args.push(val1);\n\n  const awf = opts.awaitWriteFinish;\n  let pw;\n  if (awf && (pw = this._pendingWrites.get(path))) {\n    pw.lastChange = new Date();\n    return this;\n  }\n\n  if (opts.atomic) {\n    if (event === EV_UNLINK) {\n      this._pendingUnlinks.set(path, args);\n      setTimeout(() => {\n        this._pendingUnlinks.forEach((entry, path) => {\n          this.emit(...entry);\n          this.emit(EV_ALL, ...entry);\n          this._pendingUnlinks.delete(path);\n        });\n      }, typeof opts.atomic === 'number' ? opts.atomic : 100);\n      return this;\n    }\n    if (event === EV_ADD && this._pendingUnlinks.has(path)) {\n      event = args[0] = EV_CHANGE;\n      this._pendingUnlinks.delete(path);\n    }\n  }\n\n  if (awf && (event === EV_ADD || event === EV_CHANGE) && this._readyEmitted) {\n    const awfEmit = (err, stats) => {\n      if (err) {\n        event = args[0] = EV_ERROR;\n        args[1] = err;\n        this.emitWithAll(event, args);\n      } else if (stats) {\n        // if stats doesn't exist the file must have been deleted\n        if (args.length > 2) {\n          args[2] = stats;\n        } else {\n          args.push(stats);\n        }\n        this.emitWithAll(event, args);\n      }\n    };\n\n    this._awaitWriteFinish(path, awf.stabilityThreshold, event, awfEmit);\n    return this;\n  }\n\n  if (event === EV_CHANGE) {\n    const isThrottled = !this._throttle(EV_CHANGE, path, 50);\n    if (isThrottled) return this;\n  }\n\n  if (opts.alwaysStat && val1 === undefined &&\n    (event === EV_ADD || event === EV_ADD_DIR || event === EV_CHANGE)\n  ) {\n    const fullPath = opts.cwd ? sysPath.join(opts.cwd, path) : path;\n    let stats;\n    try {\n      stats = await stat(fullPath);\n    } catch (err) {}\n    // Suppress event when fs_stat fails, to avoid sending undefined 'stat'\n    if (!stats || this.closed) return;\n    args.push(stats);\n  }\n  this.emitWithAll(event, args);\n\n  return this;\n}\n\n/**\n * Common handler for errors\n * @param {Error} error\n * @returns {Error|Boolean} The error if defined, otherwise the value of the FSWatcher instance's `closed` flag\n */\n_handleError(error) {\n  const code = error && error.code;\n  if (error && code !== 'ENOENT' && code !== 'ENOTDIR' &&\n    (!this.options.ignorePermissionErrors || (code !== 'EPERM' && code !== 'EACCES'))\n  ) {\n    this.emit(EV_ERROR, error);\n  }\n  return error || this.closed;\n}\n\n/**\n * Helper utility for throttling\n * @param {ThrottleType} actionType type being throttled\n * @param {Path} path being acted upon\n * @param {Number} timeout duration of time to suppress duplicate actions\n * @returns {Object|false} tracking object or false if action should be suppressed\n */\n_throttle(actionType, path, timeout) {\n  if (!this._throttled.has(actionType)) {\n    this._throttled.set(actionType, new Map());\n  }\n\n  /** @type {Map<Path, Object>} */\n  const action = this._throttled.get(actionType);\n  /** @type {Object} */\n  const actionPath = action.get(path);\n\n  if (actionPath) {\n    actionPath.count++;\n    return false;\n  }\n\n  let timeoutObject;\n  const clear = () => {\n    const item = action.get(path);\n    const count = item ? item.count : 0;\n    action.delete(path);\n    clearTimeout(timeoutObject);\n    if (item) clearTimeout(item.timeoutObject);\n    return count;\n  };\n  timeoutObject = setTimeout(clear, timeout);\n  const thr = {timeoutObject, clear, count: 0};\n  action.set(path, thr);\n  return thr;\n}\n\n_incrReadyCount() {\n  return this._readyCount++;\n}\n\n/**\n * Awaits write operation to finish.\n * Polls a newly created file for size variations. When files size does not change for 'threshold' milliseconds calls callback.\n * @param {Path} path being acted upon\n * @param {Number} threshold Time in milliseconds a file size must be fixed before acknowledging write OP is finished\n * @param {EventName} event\n * @param {Function} awfEmit Callback to be called when ready for event to be emitted.\n */\n_awaitWriteFinish(path, threshold, event, awfEmit) {\n  let timeoutHandler;\n\n  let fullPath = path;\n  if (this.options.cwd && !sysPath.isAbsolute(path)) {\n    fullPath = sysPath.join(this.options.cwd, path);\n  }\n\n  const now = new Date();\n\n  const awaitWriteFinish = (prevStat) => {\n    fs$5.stat(fullPath, (err, curStat) => {\n      if (err || !this._pendingWrites.has(path)) {\n        if (err && err.code !== 'ENOENT') awfEmit(err);\n        return;\n      }\n\n      const now = Number(new Date());\n\n      if (prevStat && curStat.size !== prevStat.size) {\n        this._pendingWrites.get(path).lastChange = now;\n      }\n      const pw = this._pendingWrites.get(path);\n      const df = now - pw.lastChange;\n\n      if (df >= threshold) {\n        this._pendingWrites.delete(path);\n        awfEmit(undefined, curStat);\n      } else {\n        timeoutHandler = setTimeout(\n          awaitWriteFinish,\n          this.options.awaitWriteFinish.pollInterval,\n          curStat\n        );\n      }\n    });\n  };\n\n  if (!this._pendingWrites.has(path)) {\n    this._pendingWrites.set(path, {\n      lastChange: now,\n      cancelWait: () => {\n        this._pendingWrites.delete(path);\n        clearTimeout(timeoutHandler);\n        return event;\n      }\n    });\n    timeoutHandler = setTimeout(\n      awaitWriteFinish,\n      this.options.awaitWriteFinish.pollInterval\n    );\n  }\n}\n\n_getGlobIgnored() {\n  return [...this._ignoredPaths.values()];\n}\n\n/**\n * Determines whether user has asked to ignore this path.\n * @param {Path} path filepath or dir\n * @param {fs.Stats=} stats result of fs.stat\n * @returns {Boolean}\n */\n_isIgnored(path, stats) {\n  if (this.options.atomic && DOT_RE.test(path)) return true;\n  if (!this._userIgnored) {\n    const {cwd} = this.options;\n    const ign = this.options.ignored;\n\n    const ignored = ign && ign.map(normalizeIgnored(cwd));\n    const paths = arrify(ignored)\n      .filter((path) => typeof path === STRING_TYPE && !isGlob(path))\n      .map((path) => path + SLASH_GLOBSTAR);\n    const list = this._getGlobIgnored().map(normalizeIgnored(cwd)).concat(ignored, paths);\n    this._userIgnored = anymatch(list, undefined, ANYMATCH_OPTS);\n  }\n\n  return this._userIgnored([path, stats]);\n}\n\n_isntIgnored(path, stat) {\n  return !this._isIgnored(path, stat);\n}\n\n/**\n * Provides a set of common helpers and properties relating to symlink and glob handling.\n * @param {Path} path file, directory, or glob pattern being watched\n * @param {Number=} depth at any depth > 0, this isn't a glob\n * @returns {WatchHelper} object containing helpers for this path\n */\n_getWatchHelpers(path, depth) {\n  const watchPath = depth || this.options.disableGlobbing || !isGlob(path) ? path : globParent(path);\n  const follow = this.options.followSymlinks;\n\n  return new WatchHelper(path, watchPath, follow, this);\n}\n\n// Directory helpers\n// -----------------\n\n/**\n * Provides directory tracking objects\n * @param {String} directory path of the directory\n * @returns {DirEntry} the directory's tracking object\n */\n_getWatchedDir(directory) {\n  if (!this._boundRemove) this._boundRemove = this._remove.bind(this);\n  const dir = sysPath.resolve(directory);\n  if (!this._watched.has(dir)) this._watched.set(dir, new DirEntry(dir, this._boundRemove));\n  return this._watched.get(dir);\n}\n\n// File helpers\n// ------------\n\n/**\n * Check for read permissions.\n * Based on this answer on SO: https://stackoverflow.com/a/11781404/1358405\n * @param {fs.Stats} stats - object, result of fs_stat\n * @returns {Boolean} indicates whether the file can be read\n*/\n_hasReadPermissions(stats) {\n  if (this.options.ignorePermissionErrors) return true;\n\n  // stats.mode may be bigint\n  const md = stats && Number.parseInt(stats.mode, 10);\n  const st = md & 0o777;\n  const it = Number.parseInt(st.toString(8)[0], 10);\n  return Boolean(4 & it);\n}\n\n/**\n * Handles emitting unlink events for\n * files and directories, and via recursion, for\n * files and directories within directories that are unlinked\n * @param {String} directory within which the following item is located\n * @param {String} item      base path of item/directory\n * @returns {void}\n*/\n_remove(directory, item, isDirectory) {\n  // if what is being deleted is a directory, get that directory's paths\n  // for recursive deleting and cleaning of watched object\n  // if it is not a directory, nestedDirectoryChildren will be empty array\n  const path = sysPath.join(directory, item);\n  const fullPath = sysPath.resolve(path);\n  isDirectory = isDirectory != null\n    ? isDirectory\n    : this._watched.has(path) || this._watched.has(fullPath);\n\n  // prevent duplicate handling in case of arriving here nearly simultaneously\n  // via multiple paths (such as _handleFile and _handleDir)\n  if (!this._throttle('remove', path, 100)) return;\n\n  // if the only watched file is removed, watch for its return\n  if (!isDirectory && !this.options.useFsEvents && this._watched.size === 1) {\n    this.add(directory, item, true);\n  }\n\n  // This will create a new entry in the watched object in either case\n  // so we got to do the directory check beforehand\n  const wp = this._getWatchedDir(path);\n  const nestedDirectoryChildren = wp.getChildren();\n\n  // Recursively remove children directories / files.\n  nestedDirectoryChildren.forEach(nested => this._remove(path, nested));\n\n  // Check if item was on the watched list and remove it\n  const parent = this._getWatchedDir(directory);\n  const wasTracked = parent.has(item);\n  parent.remove(item);\n\n  // Fixes issue #1042 -> Relative paths were detected and added as symlinks\n  // (https://github.com/paulmillr/chokidar/blob/e1753ddbc9571bdc33b4a4af172d52cb6e611c10/lib/nodefs-handler.js#L612),\n  // but never removed from the map in case the path was deleted.\n  // This leads to an incorrect state if the path was recreated:\n  // https://github.com/paulmillr/chokidar/blob/e1753ddbc9571bdc33b4a4af172d52cb6e611c10/lib/nodefs-handler.js#L553\n  if (this._symlinkPaths.has(fullPath)) {\n    this._symlinkPaths.delete(fullPath);\n  }\n\n  // If we wait for this file to be fully written, cancel the wait.\n  let relPath = path;\n  if (this.options.cwd) relPath = sysPath.relative(this.options.cwd, path);\n  if (this.options.awaitWriteFinish && this._pendingWrites.has(relPath)) {\n    const event = this._pendingWrites.get(relPath).cancelWait();\n    if (event === EV_ADD) return;\n  }\n\n  // The Entry will either be a directory that just got removed\n  // or a bogus entry to a file, in either case we have to remove it\n  this._watched.delete(path);\n  this._watched.delete(fullPath);\n  const eventName = isDirectory ? EV_UNLINK_DIR : EV_UNLINK;\n  if (wasTracked && !this._isIgnored(path)) this._emit(eventName, path);\n\n  // Avoid conflicts if we later create another file with the same name\n  if (!this.options.useFsEvents) {\n    this._closePath(path);\n  }\n}\n\n/**\n * Closes all watchers for a path\n * @param {Path} path\n */\n_closePath(path) {\n  this._closeFile(path);\n  const dir = sysPath.dirname(path);\n  this._getWatchedDir(dir).remove(sysPath.basename(path));\n}\n\n/**\n * Closes only file-specific watchers\n * @param {Path} path\n */\n_closeFile(path) {\n  const closers = this._closers.get(path);\n  if (!closers) return;\n  closers.forEach(closer => closer());\n  this._closers.delete(path);\n}\n\n/**\n *\n * @param {Path} path\n * @param {Function} closer\n */\n_addPathCloser(path, closer) {\n  if (!closer) return;\n  let list = this._closers.get(path);\n  if (!list) {\n    list = [];\n    this._closers.set(path, list);\n  }\n  list.push(closer);\n}\n\n_readdirp(root, opts) {\n  if (this.closed) return;\n  const options = {type: EV_ALL, alwaysStat: true, lstat: true, ...opts};\n  let stream = readdirp(root, options);\n  this._streams.add(stream);\n  stream.once(STR_CLOSE, () => {\n    stream = undefined;\n  });\n  stream.once(STR_END, () => {\n    if (stream) {\n      this._streams.delete(stream);\n      stream = undefined;\n    }\n  });\n  return stream;\n}\n\n}\n\n// Export FSWatcher class\nchokidar.FSWatcher = FSWatcher;\n\n/**\n * Instantiates watcher with paths to be tracked.\n * @param {String|Array<String>} paths file/directory paths and/or globs\n * @param {Object=} options chokidar opts\n * @returns an instance of FSWatcher for chaining.\n */\nconst watch = (paths, options) => {\n  const watcher = new FSWatcher(options);\n  watcher.add(paths);\n  return watcher;\n};\n\nchokidar.watch = watch;\n\nvar shellQuote$1 = {};\n\nshellQuote$1.quote = function (xs) {\n    return xs.map(function (s) {\n        if (s && typeof s === 'object') {\n            return s.op.replace(/(.)/g, '\\\\$1');\n        }\n        else if (/[\"\\s]/.test(s) && !/'/.test(s)) {\n            return \"'\" + s.replace(/(['\\\\])/g, '\\\\$1') + \"'\";\n        }\n        else if (/[\"'\\s]/.test(s)) {\n            return '\"' + s.replace(/([\"\\\\$`!])/g, '\\\\$1') + '\"';\n        }\n        else {\n            return String(s).replace(/([A-Za-z]:)?([#!\"$&'()*,:;<=>?@\\[\\\\\\]^`{|}])/g, '$1\\\\$2');\n        }\n    }).join(' ');\n};\n\n// '<(' is process substitution operator and\n// can be parsed the same as control operator\nvar CONTROL = '(?:' + [\n    '\\\\|\\\\|', '\\\\&\\\\&', ';;', '\\\\|\\\\&', '\\\\<\\\\(', '>>', '>\\\\&', '[&;()|<>]'\n].join('|') + ')';\nvar META = '|&;()<> \\\\t';\nvar BAREWORD = '(\\\\\\\\[\\'\"' + META + ']|[^\\\\s\\'\"' + META + '])+';\nvar SINGLE_QUOTE = '\"((\\\\\\\\\"|[^\"])*?)\"';\nvar DOUBLE_QUOTE = '\\'((\\\\\\\\\\'|[^\\'])*?)\\'';\n\nvar TOKEN = '';\nfor (var i = 0; i < 4; i++) {\n    TOKEN += (Math.pow(16,8)*Math.random()).toString(16);\n}\n\nshellQuote$1.parse = function (s, env, opts) {\n    var mapped = parse$5(s, env, opts);\n    if (typeof env !== 'function') return mapped;\n    return mapped.reduce(function (acc, s) {\n        if (typeof s === 'object') return acc.concat(s);\n        var xs = s.split(RegExp('(' + TOKEN + '.*?' + TOKEN + ')', 'g'));\n        if (xs.length === 1) return acc.concat(xs[0]);\n        return acc.concat(xs.filter(Boolean).map(function (x) {\n            if (RegExp('^' + TOKEN).test(x)) {\n                return JSON.parse(x.split(TOKEN)[1]);\n            }\n            else return x;\n        }));\n    }, []);\n};\n\nfunction parse$5 (s, env, opts) {\n    var chunker = new RegExp([\n        '(' + CONTROL + ')', // control chars\n        '(' + BAREWORD + '|' + SINGLE_QUOTE + '|' + DOUBLE_QUOTE + ')*'\n    ].join('|'), 'g');\n    var match = s.match(chunker).filter(Boolean);\n    var commented = false;\n\n    if (!match) return [];\n    if (!env) env = {};\n    if (!opts) opts = {};\n    return match.map(function (s, j) {\n        if (commented) {\n            return;\n        }\n        if (RegExp('^' + CONTROL + '$').test(s)) {\n            return { op: s };\n        }\n\n        // Hand-written scanner/parser for Bash quoting rules:\n        //\n        //  1. inside single quotes, all characters are printed literally.\n        //  2. inside double quotes, all characters are printed literally\n        //     except variables prefixed by '$' and backslashes followed by\n        //     either a double quote or another backslash.\n        //  3. outside of any quotes, backslashes are treated as escape\n        //     characters and not printed (unless they are themselves escaped)\n        //  4. quote context can switch mid-token if there is no whitespace\n        //     between the two quote contexts (e.g. all'one'\"token\" parses as\n        //     \"allonetoken\")\n        var SQ = \"'\";\n        var DQ = '\"';\n        var DS = '$';\n        var BS = opts.escape || '\\\\';\n        var quote = false;\n        var esc = false;\n        var out = '';\n        var isGlob = false;\n\n        for (var i = 0, len = s.length; i < len; i++) {\n            var c = s.charAt(i);\n            isGlob = isGlob || (!quote && (c === '*' || c === '?'));\n            if (esc) {\n                out += c;\n                esc = false;\n            }\n            else if (quote) {\n                if (c === quote) {\n                    quote = false;\n                }\n                else if (quote == SQ) {\n                    out += c;\n                }\n                else { // Double quote\n                    if (c === BS) {\n                        i += 1;\n                        c = s.charAt(i);\n                        if (c === DQ || c === BS || c === DS) {\n                            out += c;\n                        } else {\n                            out += BS + c;\n                        }\n                    }\n                    else if (c === DS) {\n                        out += parseEnvVar();\n                    }\n                    else {\n                        out += c;\n                    }\n                }\n            }\n            else if (c === DQ || c === SQ) {\n                quote = c;\n            }\n            else if (RegExp('^' + CONTROL + '$').test(c)) {\n                return { op: s };\n            }\n            else if (RegExp('^#$').test(c)) {\n                commented = true;\n                if (out.length){\n                    return [out, { comment: s.slice(i+1) + match.slice(j+1).join(' ') }];\n                }\n                return [{ comment: s.slice(i+1) + match.slice(j+1).join(' ') }];\n            }\n            else if (c === BS) {\n                esc = true;\n            }\n            else if (c === DS) {\n                out += parseEnvVar();\n            }\n            else out += c;\n        }\n\n        if (isGlob) return {op: 'glob', pattern: out};\n\n        return out;\n\n        function parseEnvVar() {\n            i += 1;\n            var varend, varname;\n            //debugger\n            if (s.charAt(i) === '{') {\n                i += 1;\n                if (s.charAt(i) === '}') {\n                    throw new Error(\"Bad substitution: \" + s.substr(i - 2, 3));\n                }\n                varend = s.indexOf('}', i);\n                if (varend < 0) {\n                    throw new Error(\"Bad substitution: \" + s.substr(i));\n                }\n                varname = s.substr(i, varend - i);\n                i = varend;\n            }\n            else if (/[*@#?$!_\\-]/.test(s.charAt(i))) {\n                varname = s.charAt(i);\n                i += 1;\n            }\n            else {\n                varend = s.substr(i).match(/[^\\w\\d_]/);\n                if (!varend) {\n                    varname = s.substr(i);\n                    i = s.length;\n                } else {\n                    varname = s.substr(i, varend.index);\n                    i += varend.index - 1;\n                }\n            }\n            return getVar(null, '', varname);\n        }\n    })\n    // finalize parsed aruments\n    .reduce(function(prev, arg){\n        if (arg === undefined){\n            return prev;\n        }\n        return prev.concat(arg);\n    },[]);\n\n    function getVar (_, pre, key) {\n        var r = typeof env === 'function' ? env(key) : env[key];\n        if (r === undefined && key != '')\n            r = '';\n        else if (r === undefined)\n            r = '$';\n\n        if (typeof r === 'object') {\n            return pre + TOKEN + JSON.stringify(r) + TOKEN;\n        }\n        else return pre + r;\n    }\n}\n\nvar osx = {\n  '/Applications/Atom.app/Contents/MacOS/Atom': 'atom',\n  '/Applications/Atom Beta.app/Contents/MacOS/Atom Beta':\n    '/Applications/Atom Beta.app/Contents/MacOS/Atom Beta',\n  '/Applications/Brackets.app/Contents/MacOS/Brackets': 'brackets',\n  '/Applications/Sublime Text.app/Contents/MacOS/Sublime Text':\n    '/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl',\n  '/Applications/Sublime Text.app/Contents/MacOS/sublime_text':\n    '/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl',\n  '/Applications/Sublime Text 2.app/Contents/MacOS/Sublime Text 2':\n    '/Applications/Sublime Text 2.app/Contents/SharedSupport/bin/subl',\n  '/Applications/Sublime Text Dev.app/Contents/MacOS/Sublime Text':\n    '/Applications/Sublime Text Dev.app/Contents/SharedSupport/bin/subl',\n  '/Applications/Visual Studio Code.app/Contents/MacOS/Electron': 'code',\n  '/Applications/Visual Studio Code - Insiders.app/Contents/MacOS/Electron':\n    'code-insiders',\n  '/Applications/VSCodium.app/Contents/MacOS/Electron': 'codium',\n  '/Applications/AppCode.app/Contents/MacOS/appcode':\n    '/Applications/AppCode.app/Contents/MacOS/appcode',\n  '/Applications/CLion.app/Contents/MacOS/clion':\n    '/Applications/CLion.app/Contents/MacOS/clion',\n  '/Applications/IntelliJ IDEA.app/Contents/MacOS/idea':\n    '/Applications/IntelliJ IDEA.app/Contents/MacOS/idea',\n  '/Applications/PhpStorm.app/Contents/MacOS/phpstorm':\n    '/Applications/PhpStorm.app/Contents/MacOS/phpstorm',\n  '/Applications/PyCharm.app/Contents/MacOS/pycharm':\n    '/Applications/PyCharm.app/Contents/MacOS/pycharm',\n  '/Applications/PyCharm CE.app/Contents/MacOS/pycharm':\n    '/Applications/PyCharm CE.app/Contents/MacOS/pycharm',\n  '/Applications/RubyMine.app/Contents/MacOS/rubymine':\n    '/Applications/RubyMine.app/Contents/MacOS/rubymine',\n  '/Applications/WebStorm.app/Contents/MacOS/webstorm':\n    '/Applications/WebStorm.app/Contents/MacOS/webstorm',\n  '/Applications/MacVim.app/Contents/MacOS/MacVim': 'mvim',\n  '/Applications/GoLand.app/Contents/MacOS/goland':\n    '/Applications/GoLand.app/Contents/MacOS/goland',\n  '/Applications/Rider.app/Contents/MacOS/rider':\n    '/Applications/Rider.app/Contents/MacOS/rider'\n};\n\nvar linux = {\n  atom: 'atom',\n  Brackets: 'brackets',\n  code: 'code',\n  'code-insiders': 'code-insiders',\n  codium: 'codium',\n  vscodium: 'vscodium',\n  emacs: 'emacs',\n  gvim: 'gvim',\n  'idea.sh': 'idea',\n  'phpstorm.sh': 'phpstorm',\n  'pycharm.sh': 'pycharm',\n  'rubymine.sh': 'rubymine',\n  sublime_text: 'subl',\n  vim: 'vim',\n  'webstorm.sh': 'webstorm',\n  'goland.sh': 'goland',\n  'rider.sh': 'rider'\n};\n\nvar windows$1 = [\n  'Brackets.exe',\n  'Code.exe',\n  'Code - Insiders.exe',\n  'VSCodium.exe',\n  'atom.exe',\n  'sublime_text.exe',\n  'notepad++.exe',\n  'clion.exe',\n  'clion64.exe',\n  'idea.exe',\n  'idea64.exe',\n  'phpstorm.exe',\n  'phpstorm64.exe',\n  'pycharm.exe',\n  'pycharm64.exe',\n  'rubymine.exe',\n  'rubymine64.exe',\n  'webstorm.exe',\n  'webstorm64.exe',\n  'goland.exe',\n  'goland64.exe',\n  'rider.exe',\n  'rider64.exe'\n];\n\nconst path$7 = require$$0$4;\nconst shellQuote = shellQuote$1;\nconst childProcess$2 = require$$2$1;\n\n// Map from full process name to binary that starts the process\n// We can't just re-use full process name, because it will spawn a new instance\n// of the app every time\nconst COMMON_EDITORS_OSX = osx;\nconst COMMON_EDITORS_LINUX = linux;\nconst COMMON_EDITORS_WIN = windows$1;\n\nvar guess = function guessEditor (specifiedEditor) {\n  if (specifiedEditor) {\n    return shellQuote.parse(specifiedEditor)\n  }\n\n  if (process.env.LAUNCH_EDITOR) {\n    return [process.env.LAUNCH_EDITOR]\n  }\n\n  if (process.versions.webcontainer) {\n    return [process.env.EDITOR || 'code']\n  }\n\n  // We can find out which editor is currently running by:\n  // `ps x` on macOS and Linux\n  // `Get-Process` on Windows\n  try {\n    if (process.platform === 'darwin') {\n      const output = childProcess$2\n        .execSync('ps x -o comm=', {\n          stdio: ['pipe', 'pipe', 'ignore']\n        })\n        .toString();\n      const processNames = Object.keys(COMMON_EDITORS_OSX);\n      const processList = output.split('\\n');\n      for (let i = 0; i < processNames.length; i++) {\n        const processName = processNames[i];\n        // Find editor by exact match.\n        if (output.indexOf(processName) !== -1) {\n          return [COMMON_EDITORS_OSX[processName]]\n        }\n        const processNameWithoutApplications = processName.replace('/Applications', '');\n        // Find editor installation not in /Applications.\n        if (output.indexOf(processNameWithoutApplications) !== -1) {\n          // Use the CLI command if one is specified\n          if (processName !== COMMON_EDITORS_OSX[processName]) {\n            return [COMMON_EDITORS_OSX[processName]]\n          }\n          // Use a partial match to find the running process path.  If one is found, use the\n          // existing path since it can be running from anywhere.\n          const runningProcess = processList.find((procName) => procName.endsWith(processNameWithoutApplications));\n          if (runningProcess !== undefined) {\n            return [runningProcess]\n          }\n        }\n      }\n    } else if (process.platform === 'win32') {\n      const output = childProcess$2\n        .execSync(\n          'powershell -NoProfile -Command \"Get-CimInstance -Query \\\\\"select executablepath from win32_process where executablepath is not null\\\\\" | % { $_.ExecutablePath }\"',\n          {\n            stdio: ['pipe', 'pipe', 'ignore']\n          }\n        )\n        .toString();\n      const runningProcesses = output.split('\\r\\n');\n      for (let i = 0; i < runningProcesses.length; i++) {\n        const fullProcessPath = runningProcesses[i].trim();\n        const shortProcessName = path$7.basename(fullProcessPath);\n\n        if (COMMON_EDITORS_WIN.indexOf(shortProcessName) !== -1) {\n          return [fullProcessPath]\n        }\n      }\n    } else if (process.platform === 'linux') {\n      // --no-heading No header line\n      // x List all processes owned by you\n      // -o comm Need only names column\n      const output = childProcess$2\n        .execSync('ps x --no-heading -o comm --sort=comm', {\n          stdio: ['pipe', 'pipe', 'ignore']\n        })\n        .toString();\n      const processNames = Object.keys(COMMON_EDITORS_LINUX);\n      for (let i = 0; i < processNames.length; i++) {\n        const processName = processNames[i];\n        if (output.indexOf(processName) !== -1) {\n          return [COMMON_EDITORS_LINUX[processName]]\n        }\n      }\n    }\n  } catch (error) {\n    // Ignore...\n  }\n\n  // Last resort, use old skool env vars\n  if (process.env.VISUAL) {\n    return [process.env.VISUAL]\n  } else if (process.env.EDITOR) {\n    return [process.env.EDITOR]\n  }\n\n  return [null]\n};\n\nconst path$6 = require$$0$4;\n\n// normalize file/line numbers into command line args for specific editors\nvar getArgs = function getArgumentsForPosition (\n  editor,\n  fileName,\n  lineNumber,\n  columnNumber = 1\n) {\n  const editorBasename = path$6.basename(editor).replace(/\\.(exe|cmd|bat)$/i, '');\n  switch (editorBasename) {\n    case 'atom':\n    case 'Atom':\n    case 'Atom Beta':\n    case 'subl':\n    case 'sublime':\n    case 'sublime_text':\n    case 'wstorm':\n    case 'charm':\n      return [`${fileName}:${lineNumber}:${columnNumber}`]\n    case 'notepad++':\n      return ['-n' + lineNumber, '-c' + columnNumber, fileName]\n    case 'vim':\n    case 'mvim':\n      return [`+call cursor(${lineNumber}, ${columnNumber})`, fileName]\n    case 'joe':\n    case 'gvim':\n      return ['+' + `${lineNumber}`, fileName]\n    case 'emacs':\n    case 'emacsclient':\n      return [`+${lineNumber}:${columnNumber}`, fileName]\n    case 'rmate':\n    case 'mate':\n    case 'mine':\n      return ['--line', lineNumber, fileName]\n    case 'code':\n    case 'Code':\n    case 'code-insiders':\n    case 'Code - Insiders':\n    case 'codium':\n    case 'vscodium':\n    case 'VSCodium':\n      return ['-r', '-g', `${fileName}:${lineNumber}:${columnNumber}`]\n    case 'appcode':\n    case 'clion':\n    case 'clion64':\n    case 'idea':\n    case 'idea64':\n    case 'phpstorm':\n    case 'phpstorm64':\n    case 'pycharm':\n    case 'pycharm64':\n    case 'rubymine':\n    case 'rubymine64':\n    case 'webstorm':\n    case 'webstorm64':\n    case 'goland':\n    case 'goland64':\n    case 'rider':\n    case 'rider64':\n      return ['--line', lineNumber, '--column', columnNumber, fileName]\n  }\n\n  if (process.env.LAUNCH_EDITOR) {\n    return [fileName, lineNumber, columnNumber]\n  }\n\n  // For all others, drop the lineNumber until we have\n  // a mapping above, since providing the lineNumber incorrectly\n  // can result in errors or confusing behavior.\n  return [fileName]\n};\n\n/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file at\n * https://github.com/facebookincubator/create-react-app/blob/master/LICENSE\n *\n * Modified by Yuxi Evan You\n */\n\nconst fs$4 = require$$0__default;\nconst os$1 = require$$2;\nconst path$5 = require$$0$4;\nconst colors = picocolorsExports;\nconst childProcess$1 = require$$2$1;\n\nconst guessEditor = guess;\nconst getArgumentsForPosition = getArgs;\n\nfunction wrapErrorCallback (cb) {\n  return (fileName, errorMessage) => {\n    console.log();\n    console.log(\n      colors.red('Could not open ' + path$5.basename(fileName) + ' in the editor.')\n    );\n    if (errorMessage) {\n      if (errorMessage[errorMessage.length - 1] !== '.') {\n        errorMessage += '.';\n      }\n      console.log(\n        colors.red('The editor process exited with an error: ' + errorMessage)\n      );\n    }\n    console.log();\n    if (cb) cb(fileName, errorMessage);\n  }\n}\n\nfunction isTerminalEditor (editor) {\n  switch (editor) {\n    case 'vim':\n    case 'emacs':\n    case 'nano':\n      return true\n  }\n  return false\n}\n\nconst positionRE = /:(\\d+)(:(\\d+))?$/;\nfunction parseFile (file) {\n  const fileName = file.replace(positionRE, '');\n  const match = file.match(positionRE);\n  const lineNumber = match && match[1];\n  const columnNumber = match && match[3];\n  return {\n    fileName,\n    lineNumber,\n    columnNumber\n  }\n}\n\nlet _childProcess = null;\n\nfunction launchEditor (file, specifiedEditor, onErrorCallback) {\n  const parsed = parseFile(file);\n  let { fileName } = parsed;\n  const { lineNumber, columnNumber } = parsed;\n\n  if (!fs$4.existsSync(fileName)) {\n    return\n  }\n\n  if (typeof specifiedEditor === 'function') {\n    onErrorCallback = specifiedEditor;\n    specifiedEditor = undefined;\n  }\n\n  onErrorCallback = wrapErrorCallback(onErrorCallback);\n\n  const [editor, ...args] = guessEditor(specifiedEditor);\n  if (!editor) {\n    onErrorCallback(fileName, null);\n    return\n  }\n\n  if (\n    process.platform === 'linux' &&\n    fileName.startsWith('/mnt/') &&\n    /Microsoft/i.test(os$1.release())\n  ) {\n    // Assume WSL / \"Bash on Ubuntu on Windows\" is being used, and\n    // that the file exists on the Windows file system.\n    // `os.release()` is \"4.4.0-43-Microsoft\" in the current release\n    // build of WSL, see: https://github.com/Microsoft/BashOnWindows/issues/423#issuecomment-221627364\n    // When a Windows editor is specified, interop functionality can\n    // handle the path translation, but only if a relative path is used.\n    fileName = path$5.relative('', fileName);\n  }\n\n  if (lineNumber) {\n    const extraArgs = getArgumentsForPosition(editor, fileName, lineNumber, columnNumber);\n    args.push.apply(args, extraArgs);\n  } else {\n    args.push(fileName);\n  }\n\n  if (_childProcess && isTerminalEditor(editor)) {\n    // There's an existing editor process already and it's attached\n    // to the terminal, so go kill it. Otherwise two separate editor\n    // instances attach to the stdin/stdout which gets confusing.\n    _childProcess.kill('SIGKILL');\n  }\n\n  if (process.platform === 'win32') {\n    // On Windows, launch the editor in a shell because spawn can only\n    // launch .exe files.\n    _childProcess = childProcess$1.spawn(\n      'cmd.exe',\n      ['/C', editor].concat(args),\n      { stdio: 'inherit' }\n    );\n  } else {\n    _childProcess = childProcess$1.spawn(editor, args, { stdio: 'inherit' });\n  }\n  _childProcess.on('exit', function (errorCode) {\n    _childProcess = null;\n\n    if (errorCode) {\n      onErrorCallback(fileName, '(code ' + errorCode + ')');\n    }\n  });\n\n  _childProcess.on('error', function (error) {\n    onErrorCallback(fileName, error.message);\n  });\n}\n\nvar launchEditor_1 = launchEditor;\n\nconst url$2 = require$$0$9;\nconst path$4 = require$$0$4;\nconst launch = launchEditor_1;\n\nvar launchEditorMiddleware = (specifiedEditor, srcRoot, onErrorCallback) => {\n  if (typeof specifiedEditor === 'function') {\n    onErrorCallback = specifiedEditor;\n    specifiedEditor = undefined;\n  }\n\n  if (typeof srcRoot === 'function') {\n    onErrorCallback = srcRoot;\n    srcRoot = undefined;\n  }\n\n  srcRoot = srcRoot || process.cwd();\n\n  return function launchEditorMiddleware (req, res, next) {\n    const { file } = url$2.parse(req.url, true).query || {};\n    if (!file) {\n      res.statusCode = 500;\n      res.end(`launch-editor-middleware: required query param \"file\" is missing.`);\n    } else {\n      launch(path$4.resolve(srcRoot, file), specifiedEditor, onErrorCallback);\n      res.end();\n    }\n  }\n};\n\nasync function resolveHttpServer({ proxy }, app, httpsOptions) {\n    if (!httpsOptions) {\n        const { createServer } = await import('node:http');\n        return createServer(app);\n    }\n    // #484 fallback to http1 when proxy is needed.\n    if (proxy) {\n        const { createServer } = await import('node:https');\n        return createServer(httpsOptions, app);\n    }\n    else {\n        const { createSecureServer } = await import('node:http2');\n        return createSecureServer({\n            // Manually increase the session memory to prevent 502 ENHANCE_YOUR_CALM\n            // errors on large numbers of requests\n            maxSessionMemory: 1000,\n            ...httpsOptions,\n            allowHTTP1: true,\n        }, \n        // @ts-expect-error TODO: is this correct?\n        app);\n    }\n}\nasync function resolveHttpsConfig(https) {\n    if (!https)\n        return undefined;\n    const httpsOption = isObject$1(https) ? { ...https } : {};\n    const { ca, cert, key, pfx } = httpsOption;\n    Object.assign(httpsOption, {\n        ca: readFileIfExists(ca),\n        cert: readFileIfExists(cert),\n        key: readFileIfExists(key),\n        pfx: readFileIfExists(pfx),\n    });\n    return httpsOption;\n}\nfunction readFileIfExists(value) {\n    if (typeof value === 'string') {\n        try {\n            return fs$l.readFileSync(path$o.resolve(value));\n        }\n        catch (e) {\n            return value;\n        }\n    }\n    return value;\n}\nasync function httpServerStart(httpServer, serverOptions) {\n    let { port, strictPort, host, logger } = serverOptions;\n    return new Promise((resolve, reject) => {\n        const onError = (e) => {\n            if (e.code === 'EADDRINUSE') {\n                if (strictPort) {\n                    httpServer.removeListener('error', onError);\n                    reject(new Error(`Port ${port} is already in use`));\n                }\n                else {\n                    logger.info(`Port ${port} is in use, trying another one...`);\n                    httpServer.listen(++port, host);\n                }\n            }\n            else {\n                httpServer.removeListener('error', onError);\n                reject(e);\n            }\n        };\n        httpServer.on('error', onError);\n        httpServer.listen(port, host, () => {\n            httpServer.removeListener('error', onError);\n            resolve(port);\n        });\n    });\n}\nfunction setClientErrorHandler(server, logger) {\n    server.on('clientError', (err, socket) => {\n        let msg = '400 Bad Request';\n        if (err.code === 'HPE_HEADER_OVERFLOW') {\n            msg = '431 Request Header Fields Too Large';\n            logger.warn(picocolorsExports.yellow('Server responded with status code 431. ' +\n                'See https://vitejs.dev/guide/troubleshooting.html#_431-request-header-fields-too-large.'));\n        }\n        if (err.code === 'ECONNRESET' || !socket.writable) {\n            return;\n        }\n        socket.end(`HTTP/1.1 ${msg}\\r\\n\\r\\n`);\n    });\n}\n\n/**\n * @typedef { import('estree').Node} Node\n * @typedef {{\n *   skip: () => void;\n *   remove: () => void;\n *   replace: (node: Node) => void;\n * }} WalkerContext\n */\n\nclass WalkerBase {\n\tconstructor() {\n\t\t/** @type {boolean} */\n\t\tthis.should_skip = false;\n\n\t\t/** @type {boolean} */\n\t\tthis.should_remove = false;\n\n\t\t/** @type {Node | null} */\n\t\tthis.replacement = null;\n\n\t\t/** @type {WalkerContext} */\n\t\tthis.context = {\n\t\t\tskip: () => (this.should_skip = true),\n\t\t\tremove: () => (this.should_remove = true),\n\t\t\treplace: (node) => (this.replacement = node)\n\t\t};\n\t}\n\n\t/**\n\t * @template {Node} Parent\n\t * @param {Parent | null | undefined} parent\n\t * @param {keyof Parent | null | undefined} prop\n\t * @param {number | null | undefined} index\n\t * @param {Node} node\n\t */\n\treplace(parent, prop, index, node) {\n\t\tif (parent && prop) {\n\t\t\tif (index != null) {\n\t\t\t\t/** @type {Array<Node>} */ (parent[prop])[index] = node;\n\t\t\t} else {\n\t\t\t\t/** @type {Node} */ (parent[prop]) = node;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * @template {Node} Parent\n\t * @param {Parent | null | undefined} parent\n\t * @param {keyof Parent | null | undefined} prop\n\t * @param {number | null | undefined} index\n\t */\n\tremove(parent, prop, index) {\n\t\tif (parent && prop) {\n\t\t\tif (index !== null && index !== undefined) {\n\t\t\t\t/** @type {Array<Node>} */ (parent[prop]).splice(index, 1);\n\t\t\t} else {\n\t\t\t\tdelete parent[prop];\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * @typedef { import('estree').Node} Node\n * @typedef { import('./walker.js').WalkerContext} WalkerContext\n * @typedef {(\n *    this: WalkerContext,\n *    node: Node,\n *    parent: Node | null,\n *    key: string | number | symbol | null | undefined,\n *    index: number | null | undefined\n * ) => void} SyncHandler\n */\n\nclass SyncWalker extends WalkerBase {\n\t/**\n\t *\n\t * @param {SyncHandler} [enter]\n\t * @param {SyncHandler} [leave]\n\t */\n\tconstructor(enter, leave) {\n\t\tsuper();\n\n\t\t/** @type {boolean} */\n\t\tthis.should_skip = false;\n\n\t\t/** @type {boolean} */\n\t\tthis.should_remove = false;\n\n\t\t/** @type {Node | null} */\n\t\tthis.replacement = null;\n\n\t\t/** @type {WalkerContext} */\n\t\tthis.context = {\n\t\t\tskip: () => (this.should_skip = true),\n\t\t\tremove: () => (this.should_remove = true),\n\t\t\treplace: (node) => (this.replacement = node)\n\t\t};\n\n\t\t/** @type {SyncHandler | undefined} */\n\t\tthis.enter = enter;\n\n\t\t/** @type {SyncHandler | undefined} */\n\t\tthis.leave = leave;\n\t}\n\n\t/**\n\t * @template {Node} Parent\n\t * @param {Node} node\n\t * @param {Parent | null} parent\n\t * @param {keyof Parent} [prop]\n\t * @param {number | null} [index]\n\t * @returns {Node | null}\n\t */\n\tvisit(node, parent, prop, index) {\n\t\tif (node) {\n\t\t\tif (this.enter) {\n\t\t\t\tconst _should_skip = this.should_skip;\n\t\t\t\tconst _should_remove = this.should_remove;\n\t\t\t\tconst _replacement = this.replacement;\n\t\t\t\tthis.should_skip = false;\n\t\t\t\tthis.should_remove = false;\n\t\t\t\tthis.replacement = null;\n\n\t\t\t\tthis.enter.call(this.context, node, parent, prop, index);\n\n\t\t\t\tif (this.replacement) {\n\t\t\t\t\tnode = this.replacement;\n\t\t\t\t\tthis.replace(parent, prop, index, node);\n\t\t\t\t}\n\n\t\t\t\tif (this.should_remove) {\n\t\t\t\t\tthis.remove(parent, prop, index);\n\t\t\t\t}\n\n\t\t\t\tconst skipped = this.should_skip;\n\t\t\t\tconst removed = this.should_remove;\n\n\t\t\t\tthis.should_skip = _should_skip;\n\t\t\t\tthis.should_remove = _should_remove;\n\t\t\t\tthis.replacement = _replacement;\n\n\t\t\t\tif (skipped) return node;\n\t\t\t\tif (removed) return null;\n\t\t\t}\n\n\t\t\t/** @type {keyof Node} */\n\t\t\tlet key;\n\n\t\t\tfor (key in node) {\n\t\t\t\t/** @type {unknown} */\n\t\t\t\tconst value = node[key];\n\n\t\t\t\tif (value && typeof value === 'object') {\n\t\t\t\t\tif (Array.isArray(value)) {\n\t\t\t\t\t\tconst nodes = /** @type {Array<unknown>} */ (value);\n\t\t\t\t\t\tfor (let i = 0; i < nodes.length; i += 1) {\n\t\t\t\t\t\t\tconst item = nodes[i];\n\t\t\t\t\t\t\tif (isNode(item)) {\n\t\t\t\t\t\t\t\tif (!this.visit(item, node, key, i)) {\n\t\t\t\t\t\t\t\t\t// removed\n\t\t\t\t\t\t\t\t\ti--;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (isNode(value)) {\n\t\t\t\t\t\tthis.visit(value, node, key, null);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (this.leave) {\n\t\t\t\tconst _replacement = this.replacement;\n\t\t\t\tconst _should_remove = this.should_remove;\n\t\t\t\tthis.replacement = null;\n\t\t\t\tthis.should_remove = false;\n\n\t\t\t\tthis.leave.call(this.context, node, parent, prop, index);\n\n\t\t\t\tif (this.replacement) {\n\t\t\t\t\tnode = this.replacement;\n\t\t\t\t\tthis.replace(parent, prop, index, node);\n\t\t\t\t}\n\n\t\t\t\tif (this.should_remove) {\n\t\t\t\t\tthis.remove(parent, prop, index);\n\t\t\t\t}\n\n\t\t\t\tconst removed = this.should_remove;\n\n\t\t\t\tthis.replacement = _replacement;\n\t\t\t\tthis.should_remove = _should_remove;\n\n\t\t\t\tif (removed) return null;\n\t\t\t}\n\t\t}\n\n\t\treturn node;\n\t}\n}\n\n/**\n * Ducktype a node.\n *\n * @param {unknown} value\n * @returns {value is Node}\n */\nfunction isNode(value) {\n\treturn (\n\t\tvalue !== null && typeof value === 'object' && 'type' in value && typeof value.type === 'string'\n\t);\n}\n\n/**\n * @typedef {import('estree').Node} Node\n * @typedef {import('./sync.js').SyncHandler} SyncHandler\n * @typedef {import('./async.js').AsyncHandler} AsyncHandler\n */\n\n/**\n * @param {Node} ast\n * @param {{\n *   enter?: SyncHandler\n *   leave?: SyncHandler\n * }} walker\n * @returns {Node | null}\n */\nfunction walk$1(ast, { enter, leave }) {\n\tconst instance = new SyncWalker(enter, leave);\n\treturn instance.visit(ast, null);\n}\n\n/**\n * @param {import('estree').Node} param\n * @returns {string[]}\n */\nfunction extract_names(param) {\n\treturn extract_identifiers(param).map(node => node.name);\n}\n\n/**\n * @param {import('estree').Node} param\n * @param {import('estree').Identifier[]} nodes\n * @returns {import('estree').Identifier[]}\n */\nfunction extract_identifiers(param, nodes = []) {\n\tswitch (param.type) {\n\t\tcase 'Identifier':\n\t\t\tnodes.push(param);\n\t\t\tbreak;\n\n\t\tcase 'MemberExpression':\n\t\t\tlet object = param;\n\t\t\twhile (object.type === 'MemberExpression') {\n\t\t\t\tobject = /** @type {any} */ (object.object);\n\t\t\t}\n\t\t\tnodes.push(/** @type {any} */ (object));\n\t\t\tbreak;\n\n\t\tcase 'ObjectPattern':\n\t\t\t/** @param {import('estree').Property | import('estree').RestElement} prop */\n\t\t\tconst handle_prop = (prop) => {\n\t\t\t\tif (prop.type === 'RestElement') {\n\t\t\t\t\textract_identifiers(prop.argument, nodes);\n\t\t\t\t} else {\n\t\t\t\t\textract_identifiers(prop.value, nodes);\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tparam.properties.forEach(handle_prop);\n\t\t\tbreak;\n\n\t\tcase 'ArrayPattern':\n\t\t\t/** @param {import('estree').Node} element */\n\t\t\tconst handle_element = (element) => {\n\t\t\t\tif (element) extract_identifiers(element, nodes);\n\t\t\t};\n\n\t\t\tparam.elements.forEach((element) => {\n\t\t\t\tif (element) {\n\t\t\t\t\thandle_element(element);\n\t\t\t\t}\n\t\t\t});\n\t\t\tbreak;\n\n\t\tcase 'RestElement':\n\t\t\textract_identifiers(param.argument, nodes);\n\t\t\tbreak;\n\n\t\tcase 'AssignmentPattern':\n\t\t\textract_identifiers(param.left, nodes);\n\t\t\tbreak;\n\t}\n\n\treturn nodes;\n}\n\nconst ssrModuleExportsKey = `__vite_ssr_exports__`;\nconst ssrImportKey = `__vite_ssr_import__`;\nconst ssrDynamicImportKey = `__vite_ssr_dynamic_import__`;\nconst ssrExportAllKey = `__vite_ssr_exportAll__`;\nconst ssrImportMetaKey = `__vite_ssr_import_meta__`;\nasync function ssrTransform(code, inMap, url, originalCode, options) {\n    if (options?.json?.stringify && isJSONRequest(url)) {\n        return ssrTransformJSON(code, inMap);\n    }\n    return ssrTransformScript(code, inMap, url, originalCode);\n}\nasync function ssrTransformJSON(code, inMap) {\n    return {\n        code: code.replace('export default', `${ssrModuleExportsKey}.default =`),\n        map: inMap,\n        deps: [],\n        dynamicDeps: [],\n    };\n}\nasync function ssrTransformScript(code, inMap, url, originalCode) {\n    const s = new MagicString(code);\n    let ast;\n    try {\n        ast = parser.parse(code, {\n            sourceType: 'module',\n            ecmaVersion: 'latest',\n            locations: true,\n            allowHashBang: true,\n        });\n    }\n    catch (err) {\n        if (!err.loc || !err.loc.line)\n            throw err;\n        const line = err.loc.line;\n        throw new Error(`Parse failure: ${err.message}\\nAt file: ${url}\\nContents of line ${line}: ${code.split('\\n')[line - 1]}`);\n    }\n    let uid = 0;\n    const deps = new Set();\n    const dynamicDeps = new Set();\n    const idToImportMap = new Map();\n    const declaredConst = new Set();\n    function defineImport(node, source) {\n        deps.add(source);\n        const importId = `__vite_ssr_import_${uid++}__`;\n        s.appendRight(node.start, `const ${importId} = await ${ssrImportKey}(${JSON.stringify(source)});\\n`);\n        return importId;\n    }\n    function defineExport(position, name, local = name) {\n        s.appendLeft(position, `\\nObject.defineProperty(${ssrModuleExportsKey}, \"${name}\", ` +\n            `{ enumerable: true, configurable: true, get(){ return ${local} }});`);\n    }\n    // 1. check all import statements and record id -> importName map\n    for (const node of ast.body) {\n        // import foo from 'foo' --> foo -> __import_foo__.default\n        // import { baz } from 'foo' --> baz -> __import_foo__.baz\n        // import * as ok from 'foo' --> ok -> __import_foo__\n        if (node.type === 'ImportDeclaration') {\n            s.remove(node.start, node.end);\n            const importId = defineImport(node, node.source.value);\n            for (const spec of node.specifiers) {\n                if (spec.type === 'ImportSpecifier') {\n                    idToImportMap.set(spec.local.name, `${importId}.${spec.imported.name}`);\n                }\n                else if (spec.type === 'ImportDefaultSpecifier') {\n                    idToImportMap.set(spec.local.name, `${importId}.default`);\n                }\n                else {\n                    // namespace specifier\n                    idToImportMap.set(spec.local.name, importId);\n                }\n            }\n        }\n    }\n    // 2. check all export statements and define exports\n    for (const node of ast.body) {\n        // named exports\n        if (node.type === 'ExportNamedDeclaration') {\n            if (node.declaration) {\n                if (node.declaration.type === 'FunctionDeclaration' ||\n                    node.declaration.type === 'ClassDeclaration') {\n                    // export function foo() {}\n                    defineExport(node.end, node.declaration.id.name);\n                }\n                else {\n                    // export const foo = 1, bar = 2\n                    for (const declaration of node.declaration.declarations) {\n                        const names = extract_names(declaration.id);\n                        for (const name of names) {\n                            defineExport(node.end, name);\n                        }\n                    }\n                }\n                s.remove(node.start, node.declaration.start);\n            }\n            else {\n                s.remove(node.start, node.end);\n                if (node.source) {\n                    // export { foo, bar } from './foo'\n                    const importId = defineImport(node, node.source.value);\n                    for (const spec of node.specifiers) {\n                        defineExport(node.end, spec.exported.name, `${importId}.${spec.local.name}`);\n                    }\n                }\n                else {\n                    // export { foo, bar }\n                    for (const spec of node.specifiers) {\n                        const local = spec.local.name;\n                        const binding = idToImportMap.get(local);\n                        defineExport(node.end, spec.exported.name, binding || local);\n                    }\n                }\n            }\n        }\n        // default export\n        if (node.type === 'ExportDefaultDeclaration') {\n            const expressionTypes = ['FunctionExpression', 'ClassExpression'];\n            if ('id' in node.declaration &&\n                node.declaration.id &&\n                !expressionTypes.includes(node.declaration.type)) {\n                // named hoistable/class exports\n                // export default function foo() {}\n                // export default class A {}\n                const { name } = node.declaration.id;\n                s.remove(node.start, node.start + 15 /* 'export default '.length */);\n                s.append(`\\nObject.defineProperty(${ssrModuleExportsKey}, \"default\", ` +\n                    `{ enumerable: true, configurable: true, value: ${name} });`);\n            }\n            else {\n                // anonymous default exports\n                s.update(node.start, node.start + 14 /* 'export default'.length */, `${ssrModuleExportsKey}.default =`);\n            }\n        }\n        // export * from './foo'\n        if (node.type === 'ExportAllDeclaration') {\n            s.remove(node.start, node.end);\n            const importId = defineImport(node, node.source.value);\n            if (node.exported) {\n                defineExport(node.end, node.exported.name, `${importId}`);\n            }\n            else {\n                s.appendLeft(node.end, `${ssrExportAllKey}(${importId});`);\n            }\n        }\n    }\n    // 3. convert references to import bindings & import.meta references\n    walk(ast, {\n        onIdentifier(id, parent, parentStack) {\n            const grandparent = parentStack[1];\n            const binding = idToImportMap.get(id.name);\n            if (!binding) {\n                return;\n            }\n            if (isStaticProperty(parent) && parent.shorthand) {\n                // let binding used in a property shorthand\n                // { foo } -> { foo: __import_x__.foo }\n                // skip for destructuring patterns\n                if (!isNodeInPattern(parent) ||\n                    isInDestructuringAssignment(parent, parentStack)) {\n                    s.appendLeft(id.end, `: ${binding}`);\n                }\n            }\n            else if ((parent.type === 'PropertyDefinition' &&\n                grandparent?.type === 'ClassBody') ||\n                (parent.type === 'ClassDeclaration' && id === parent.superClass)) {\n                if (!declaredConst.has(id.name)) {\n                    declaredConst.add(id.name);\n                    // locate the top-most node containing the class declaration\n                    const topNode = parentStack[parentStack.length - 2];\n                    s.prependRight(topNode.start, `const ${id.name} = ${binding};\\n`);\n                }\n            }\n            else {\n                s.update(id.start, id.end, binding);\n            }\n        },\n        onImportMeta(node) {\n            s.update(node.start, node.end, ssrImportMetaKey);\n        },\n        onDynamicImport(node) {\n            s.update(node.start, node.start + 6, ssrDynamicImportKey);\n            if (node.type === 'ImportExpression' && node.source.type === 'Literal') {\n                dynamicDeps.add(node.source.value);\n            }\n        },\n    });\n    let map = s.generateMap({ hires: true });\n    if (inMap && inMap.mappings && inMap.sources.length > 0) {\n        map = combineSourcemaps(url, [\n            {\n                ...map,\n                sources: inMap.sources,\n                sourcesContent: inMap.sourcesContent,\n            },\n            inMap,\n        ], false);\n    }\n    else {\n        map.sources = [url];\n        // needs to use originalCode instead of code\n        // because code might be already transformed even if map is null\n        map.sourcesContent = [originalCode];\n    }\n    return {\n        code: s.toString(),\n        map,\n        deps: [...deps],\n        dynamicDeps: [...dynamicDeps],\n    };\n}\nconst isNodeInPatternWeakSet = new WeakSet();\nconst setIsNodeInPattern = (node) => isNodeInPatternWeakSet.add(node);\nconst isNodeInPattern = (node) => isNodeInPatternWeakSet.has(node);\n/**\n * Same logic from \\@vue/compiler-core & \\@vue/compiler-sfc\n * Except this is using acorn AST\n */\nfunction walk(root, { onIdentifier, onImportMeta, onDynamicImport }) {\n    const parentStack = [];\n    const varKindStack = [];\n    const scopeMap = new WeakMap();\n    const identifiers = [];\n    const setScope = (node, name) => {\n        let scopeIds = scopeMap.get(node);\n        if (scopeIds && scopeIds.has(name)) {\n            return;\n        }\n        if (!scopeIds) {\n            scopeIds = new Set();\n            scopeMap.set(node, scopeIds);\n        }\n        scopeIds.add(name);\n    };\n    function isInScope(name, parents) {\n        return parents.some((node) => node && scopeMap.get(node)?.has(name));\n    }\n    function handlePattern(p, parentScope) {\n        if (p.type === 'Identifier') {\n            setScope(parentScope, p.name);\n        }\n        else if (p.type === 'RestElement') {\n            handlePattern(p.argument, parentScope);\n        }\n        else if (p.type === 'ObjectPattern') {\n            p.properties.forEach((property) => {\n                if (property.type === 'RestElement') {\n                    setScope(parentScope, property.argument.name);\n                }\n                else {\n                    handlePattern(property.value, parentScope);\n                }\n            });\n        }\n        else if (p.type === 'ArrayPattern') {\n            p.elements.forEach((element) => {\n                if (element) {\n                    handlePattern(element, parentScope);\n                }\n            });\n        }\n        else if (p.type === 'AssignmentPattern') {\n            handlePattern(p.left, parentScope);\n        }\n        else {\n            setScope(parentScope, p.name);\n        }\n    }\n    walk$1(root, {\n        enter(node, parent) {\n            if (node.type === 'ImportDeclaration') {\n                return this.skip();\n            }\n            // track parent stack, skip for \"else-if\"/\"else\" branches as acorn nests\n            // the ast within \"if\" nodes instead of flattening them\n            if (parent &&\n                !(parent.type === 'IfStatement' && node === parent.alternate)) {\n                parentStack.unshift(parent);\n            }\n            // track variable declaration kind stack used by VariableDeclarator\n            if (node.type === 'VariableDeclaration') {\n                varKindStack.unshift(node.kind);\n            }\n            if (node.type === 'MetaProperty' && node.meta.name === 'import') {\n                onImportMeta(node);\n            }\n            else if (node.type === 'ImportExpression') {\n                onDynamicImport(node);\n            }\n            if (node.type === 'Identifier') {\n                if (!isInScope(node.name, parentStack) &&\n                    isRefIdentifier(node, parent, parentStack)) {\n                    // record the identifier, for DFS -> BFS\n                    identifiers.push([node, parentStack.slice(0)]);\n                }\n            }\n            else if (isFunction(node)) {\n                // If it is a function declaration, it could be shadowing an import\n                // Add its name to the scope so it won't get replaced\n                if (node.type === 'FunctionDeclaration') {\n                    const parentScope = findParentScope(parentStack);\n                    if (parentScope) {\n                        setScope(parentScope, node.id.name);\n                    }\n                }\n                // walk function expressions and add its arguments to known identifiers\n                // so that we don't prefix them\n                node.params.forEach((p) => {\n                    if (p.type === 'ObjectPattern' || p.type === 'ArrayPattern') {\n                        handlePattern(p, node);\n                        return;\n                    }\n                    walk$1(p.type === 'AssignmentPattern' ? p.left : p, {\n                        enter(child, parent) {\n                            // skip params default value of destructure\n                            if (parent?.type === 'AssignmentPattern' &&\n                                parent?.right === child) {\n                                return this.skip();\n                            }\n                            if (child.type !== 'Identifier')\n                                return;\n                            // do not record as scope variable if is a destructuring keyword\n                            if (isStaticPropertyKey(child, parent))\n                                return;\n                            // do not record if this is a default value\n                            // assignment of a destructuring variable\n                            if ((parent?.type === 'TemplateLiteral' &&\n                                parent?.expressions.includes(child)) ||\n                                (parent?.type === 'CallExpression' && parent?.callee === child)) {\n                                return;\n                            }\n                            setScope(node, child.name);\n                        },\n                    });\n                });\n            }\n            else if (node.type === 'Property' && parent.type === 'ObjectPattern') {\n                // mark property in destructuring pattern\n                setIsNodeInPattern(node);\n            }\n            else if (node.type === 'VariableDeclarator') {\n                const parentFunction = findParentScope(parentStack, varKindStack[0] === 'var');\n                if (parentFunction) {\n                    handlePattern(node.id, parentFunction);\n                }\n            }\n            else if (node.type === 'CatchClause' && node.param) {\n                handlePattern(node.param, node);\n            }\n        },\n        leave(node, parent) {\n            // untrack parent stack from above\n            if (parent &&\n                !(parent.type === 'IfStatement' && node === parent.alternate)) {\n                parentStack.shift();\n            }\n            if (node.type === 'VariableDeclaration') {\n                varKindStack.shift();\n            }\n        },\n    });\n    // emit the identifier events in BFS so the hoisted declarations\n    // can be captured correctly\n    identifiers.forEach(([node, stack]) => {\n        if (!isInScope(node.name, stack))\n            onIdentifier(node, stack[0], stack);\n    });\n}\nfunction isRefIdentifier(id, parent, parentStack) {\n    // declaration id\n    if (parent.type === 'CatchClause' ||\n        ((parent.type === 'VariableDeclarator' ||\n            parent.type === 'ClassDeclaration') &&\n            parent.id === id)) {\n        return false;\n    }\n    if (isFunction(parent)) {\n        // function declaration/expression id\n        if (parent.id === id) {\n            return false;\n        }\n        // params list\n        if (parent.params.includes(id)) {\n            return false;\n        }\n    }\n    // class method name\n    if (parent.type === 'MethodDefinition' && !parent.computed) {\n        return false;\n    }\n    // property key\n    if (isStaticPropertyKey(id, parent)) {\n        return false;\n    }\n    // object destructuring pattern\n    if (isNodeInPattern(parent) && parent.value === id) {\n        return false;\n    }\n    // non-assignment array destructuring pattern\n    if (parent.type === 'ArrayPattern' &&\n        !isInDestructuringAssignment(parent, parentStack)) {\n        return false;\n    }\n    // member expression property\n    if (parent.type === 'MemberExpression' &&\n        parent.property === id &&\n        !parent.computed) {\n        return false;\n    }\n    if (parent.type === 'ExportSpecifier') {\n        return false;\n    }\n    // is a special keyword but parsed as identifier\n    if (id.name === 'arguments') {\n        return false;\n    }\n    return true;\n}\nconst isStaticProperty = (node) => node && node.type === 'Property' && !node.computed;\nconst isStaticPropertyKey = (node, parent) => isStaticProperty(parent) && parent.key === node;\nconst functionNodeTypeRE = /Function(?:Expression|Declaration)$|Method$/;\nfunction isFunction(node) {\n    return functionNodeTypeRE.test(node.type);\n}\nfunction findParentScope(parentStack, isVar = false) {\n    const predicate = isVar\n        ? isFunction\n        : (node) => node.type === 'BlockStatement';\n    return parentStack.find(predicate);\n}\nfunction isInDestructuringAssignment(parent, parentStack) {\n    if (parent &&\n        (parent.type === 'Property' || parent.type === 'ArrayPattern')) {\n        return parentStack.some((i) => i.type === 'AssignmentExpression');\n    }\n    return false;\n}\n\nlet offset;\ntry {\n    new Function('throw new Error(1)')();\n}\ncatch (e) {\n    // in Node 12, stack traces account for the function wrapper.\n    // in Node 13 and later, the function wrapper adds two lines,\n    // which must be subtracted to generate a valid mapping\n    const match = /:(\\d+):\\d+\\)$/.exec(e.stack.split('\\n')[1]);\n    offset = match ? +match[1] - 1 : 0;\n}\nfunction ssrRewriteStacktrace(stack, moduleGraph) {\n    return stack\n        .split('\\n')\n        .map((line) => {\n        return line.replace(/^ {4}at (?:(\\S.*?)\\s\\()?(.+?):(\\d+)(?::(\\d+))?\\)?/, (input, varName, url, line, column) => {\n            if (!url)\n                return input;\n            const mod = moduleGraph.urlToModuleMap.get(url);\n            const rawSourceMap = mod?.ssrTransformResult?.map;\n            if (!rawSourceMap) {\n                return input;\n            }\n            const traced = new TraceMap(rawSourceMap);\n            const pos = originalPositionFor$1(traced, {\n                line: Number(line) - offset,\n                column: Number(column),\n            });\n            if (!pos.source || pos.line == null || pos.column == null) {\n                return input;\n            }\n            const trimmedVarName = varName.trim();\n            const source = `${pos.source}:${pos.line}:${pos.column}`;\n            if (!trimmedVarName || trimmedVarName === 'eval') {\n                return `    at ${source}`;\n            }\n            else {\n                return `    at ${trimmedVarName} (${source})`;\n            }\n        });\n    })\n        .join('\\n');\n}\nfunction rebindErrorStacktrace(e, stacktrace) {\n    const { configurable, writable } = Object.getOwnPropertyDescriptor(e, 'stack');\n    if (configurable) {\n        Object.defineProperty(e, 'stack', {\n            value: stacktrace,\n            enumerable: true,\n            configurable: true,\n            writable: true,\n        });\n    }\n    else if (writable) {\n        e.stack = stacktrace;\n    }\n}\nconst rewroteStacktraces = new WeakSet();\nfunction ssrFixStacktrace(e, moduleGraph) {\n    if (!e.stack)\n        return;\n    // stacktrace shouldn't be rewritten more than once\n    if (rewroteStacktraces.has(e))\n        return;\n    const stacktrace = ssrRewriteStacktrace(e.stack, moduleGraph);\n    rebindErrorStacktrace(e, stacktrace);\n    rewroteStacktraces.add(e);\n}\n\nconst pendingModules = new Map();\nconst pendingImports = new Map();\nasync function ssrLoadModule(url, server, context = { global }, urlStack = [], fixStacktrace) {\n    url = unwrapId(url);\n    // when we instantiate multiple dependency modules in parallel, they may\n    // point to shared modules. We need to avoid duplicate instantiation attempts\n    // by register every module as pending synchronously so that all subsequent\n    // request to that module are simply waiting on the same promise.\n    const pending = pendingModules.get(url);\n    if (pending) {\n        return pending;\n    }\n    const modulePromise = instantiateModule(url, server, context, urlStack, fixStacktrace);\n    pendingModules.set(url, modulePromise);\n    modulePromise\n        .catch(() => {\n        pendingImports.delete(url);\n    })\n        .finally(() => {\n        pendingModules.delete(url);\n    });\n    return modulePromise;\n}\nasync function instantiateModule(url, server, context = { global }, urlStack = [], fixStacktrace) {\n    const { moduleGraph } = server;\n    const mod = await moduleGraph.ensureEntryFromUrl(url, true);\n    if (mod.ssrError) {\n        throw mod.ssrError;\n    }\n    if (mod.ssrModule) {\n        return mod.ssrModule;\n    }\n    const result = mod.ssrTransformResult ||\n        (await transformRequest(url, server, { ssr: true }));\n    if (!result) {\n        // TODO more info? is this even necessary?\n        throw new Error(`failed to load module for ssr: ${url}`);\n    }\n    const ssrModule = {\n        [Symbol.toStringTag]: 'Module',\n    };\n    Object.defineProperty(ssrModule, '__esModule', { value: true });\n    // Tolerate circular imports by ensuring the module can be\n    // referenced before it's been instantiated.\n    mod.ssrModule = ssrModule;\n    const ssrImportMeta = {\n        // The filesystem URL, matching native Node.js modules\n        url: pathToFileURL(mod.file).toString(),\n    };\n    urlStack = urlStack.concat(url);\n    const isCircular = (url) => urlStack.includes(url);\n    const { isProduction, resolve: { dedupe, preserveSymlinks }, root, } = server.config;\n    const resolveOptions = {\n        mainFields: ['main'],\n        browserField: true,\n        conditions: [],\n        overrideConditions: ['production', 'development'],\n        extensions: ['.js', '.cjs', '.json'],\n        dedupe,\n        preserveSymlinks,\n        isBuild: false,\n        isProduction,\n        root,\n    };\n    // Since dynamic imports can happen in parallel, we need to\n    // account for multiple pending deps and duplicate imports.\n    const pendingDeps = [];\n    const ssrImport = async (dep) => {\n        if (dep[0] !== '.' && dep[0] !== '/') {\n            return nodeImport(dep, mod.file, resolveOptions);\n        }\n        // convert to rollup URL because `pendingImports`, `moduleGraph.urlToModuleMap` requires that\n        dep = unwrapId(dep);\n        if (!isCircular(dep) && !pendingImports.get(dep)?.some(isCircular)) {\n            pendingDeps.push(dep);\n            if (pendingDeps.length === 1) {\n                pendingImports.set(url, pendingDeps);\n            }\n            const mod = await ssrLoadModule(dep, server, context, urlStack, fixStacktrace);\n            if (pendingDeps.length === 1) {\n                pendingImports.delete(url);\n            }\n            else {\n                pendingDeps.splice(pendingDeps.indexOf(dep), 1);\n            }\n            // return local module to avoid race condition #5470\n            return mod;\n        }\n        return moduleGraph.urlToModuleMap.get(dep)?.ssrModule;\n    };\n    const ssrDynamicImport = (dep) => {\n        // #3087 dynamic import vars is ignored at rewrite import path,\n        // so here need process relative path\n        if (dep[0] === '.') {\n            dep = path$o.posix.resolve(path$o.dirname(url), dep);\n        }\n        return ssrImport(dep);\n    };\n    function ssrExportAll(sourceModule) {\n        for (const key in sourceModule) {\n            if (key !== 'default') {\n                Object.defineProperty(ssrModule, key, {\n                    enumerable: true,\n                    configurable: true,\n                    get() {\n                        return sourceModule[key];\n                    },\n                });\n            }\n        }\n    }\n    try {\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        const AsyncFunction = async function () { }.constructor;\n        const initModule = new AsyncFunction(`global`, ssrModuleExportsKey, ssrImportMetaKey, ssrImportKey, ssrDynamicImportKey, ssrExportAllKey, '\"use strict\";' + result.code + `\\n//# sourceURL=${mod.url}`);\n        await initModule(context.global, ssrModule, ssrImportMeta, ssrImport, ssrDynamicImport, ssrExportAll);\n    }\n    catch (e) {\n        mod.ssrError = e;\n        if (e.stack && fixStacktrace) {\n            ssrFixStacktrace(e, moduleGraph);\n            server.config.logger.error(`Error when evaluating SSR module ${url}:\\n${e.stack}`, {\n                timestamp: true,\n                clear: server.config.clearScreen,\n                error: e,\n            });\n        }\n        throw e;\n    }\n    return Object.freeze(ssrModule);\n}\n// In node@12+ we can use dynamic import to load CJS and ESM\nasync function nodeImport(id, importer, resolveOptions) {\n    let url;\n    if (id.startsWith('node:') || isBuiltin(id)) {\n        url = id;\n    }\n    else {\n        const resolved = tryNodeResolve(id, importer, \n        // Non-external modules can import ESM-only modules, but only outside\n        // of test runs, because we use Node `require` in Jest to avoid segfault.\n        // @ts-expect-error jest only exists when running Jest\n        typeof jest === 'undefined'\n            ? { ...resolveOptions, tryEsmOnly: true }\n            : resolveOptions, false);\n        if (!resolved) {\n            const err = new Error(`Cannot find module '${id}' imported from '${importer}'`);\n            err.code = 'ERR_MODULE_NOT_FOUND';\n            throw err;\n        }\n        url = resolved.id;\n        if (usingDynamicImport) {\n            url = pathToFileURL(url).toString();\n        }\n    }\n    try {\n        const mod = await dynamicImport(url);\n        return proxyESM(mod);\n    }\n    catch { }\n}\n// rollup-style default import interop for cjs\nfunction proxyESM(mod) {\n    // This is the only sensible option when the exports object is a primitive\n    if (isPrimitive(mod))\n        return { default: mod };\n    let defaultExport = 'default' in mod ? mod.default : mod;\n    if (!isPrimitive(defaultExport) && '__esModule' in defaultExport) {\n        mod = defaultExport;\n        if ('default' in defaultExport) {\n            defaultExport = defaultExport.default;\n        }\n    }\n    return new Proxy(mod, {\n        get(mod, prop) {\n            if (prop === 'default')\n                return defaultExport;\n            return mod[prop] ?? defaultExport?.[prop];\n        },\n    });\n}\nfunction isPrimitive(value) {\n    return !value || (typeof value !== 'object' && typeof value !== 'function');\n}\n\nvar isWslExports = {};\nvar isWsl$2 = {\n  get exports(){ return isWslExports; },\n  set exports(v){ isWslExports = v; },\n};\n\nconst fs$3 = require$$0__default;\n\nlet isDocker$2;\n\nfunction hasDockerEnv() {\n\ttry {\n\t\tfs$3.statSync('/.dockerenv');\n\t\treturn true;\n\t} catch (_) {\n\t\treturn false;\n\t}\n}\n\nfunction hasDockerCGroup() {\n\ttry {\n\t\treturn fs$3.readFileSync('/proc/self/cgroup', 'utf8').includes('docker');\n\t} catch (_) {\n\t\treturn false;\n\t}\n}\n\nvar isDocker_1 = () => {\n\tif (isDocker$2 === undefined) {\n\t\tisDocker$2 = hasDockerEnv() || hasDockerCGroup();\n\t}\n\n\treturn isDocker$2;\n};\n\nconst os = require$$2;\nconst fs$2 = require$$0__default;\nconst isDocker$1 = isDocker_1;\n\nconst isWsl$1 = () => {\n\tif (process.platform !== 'linux') {\n\t\treturn false;\n\t}\n\n\tif (os.release().toLowerCase().includes('microsoft')) {\n\t\tif (isDocker$1()) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t}\n\n\ttry {\n\t\treturn fs$2.readFileSync('/proc/version', 'utf8').toLowerCase().includes('microsoft') ?\n\t\t\t!isDocker$1() : false;\n\t} catch (_) {\n\t\treturn false;\n\t}\n};\n\nif (process.env.__IS_WSL_TEST__) {\n\tisWsl$2.exports = isWsl$1;\n} else {\n\tisWsl$2.exports = isWsl$1();\n}\n\nvar defineLazyProp = (object, propertyName, fn) => {\n\tconst define = value => Object.defineProperty(object, propertyName, {value, enumerable: true, writable: true});\n\n\tObject.defineProperty(object, propertyName, {\n\t\tconfigurable: true,\n\t\tenumerable: true,\n\t\tget() {\n\t\t\tconst result = fn();\n\t\t\tdefine(result);\n\t\t\treturn result;\n\t\t},\n\t\tset(value) {\n\t\t\tdefine(value);\n\t\t}\n\t});\n\n\treturn object;\n};\n\nconst path$3 = require$$0$4;\nconst childProcess = require$$2$1;\nconst {promises: fs$1, constants: fsConstants} = require$$0__default;\nconst isWsl = isWslExports;\nconst isDocker = isDocker_1;\nconst defineLazyProperty = defineLazyProp;\n\n// Path to included `xdg-open`.\nconst localXdgOpenPath = path$3.join(__dirname, 'xdg-open');\n\nconst {platform, arch} = process;\n\n/**\nGet the mount point for fixed drives in WSL.\n\n@inner\n@returns {string} The mount point.\n*/\nconst getWslDrivesMountPoint = (() => {\n\t// Default value for \"root\" param\n\t// according to https://docs.microsoft.com/en-us/windows/wsl/wsl-config\n\tconst defaultMountPoint = '/mnt/';\n\n\tlet mountPoint;\n\n\treturn async function () {\n\t\tif (mountPoint) {\n\t\t\t// Return memoized mount point value\n\t\t\treturn mountPoint;\n\t\t}\n\n\t\tconst configFilePath = '/etc/wsl.conf';\n\n\t\tlet isConfigFileExists = false;\n\t\ttry {\n\t\t\tawait fs$1.access(configFilePath, fsConstants.F_OK);\n\t\t\tisConfigFileExists = true;\n\t\t} catch {}\n\n\t\tif (!isConfigFileExists) {\n\t\t\treturn defaultMountPoint;\n\t\t}\n\n\t\tconst configContent = await fs$1.readFile(configFilePath, {encoding: 'utf8'});\n\t\tconst configMountPoint = /(?<!#.*)root\\s*=\\s*(?<mountPoint>.*)/g.exec(configContent);\n\n\t\tif (!configMountPoint) {\n\t\t\treturn defaultMountPoint;\n\t\t}\n\n\t\tmountPoint = configMountPoint.groups.mountPoint.trim();\n\t\tmountPoint = mountPoint.endsWith('/') ? mountPoint : `${mountPoint}/`;\n\n\t\treturn mountPoint;\n\t};\n})();\n\nconst pTryEach = async (array, mapper) => {\n\tlet latestError;\n\n\tfor (const item of array) {\n\t\ttry {\n\t\t\treturn await mapper(item); // eslint-disable-line no-await-in-loop\n\t\t} catch (error) {\n\t\t\tlatestError = error;\n\t\t}\n\t}\n\n\tthrow latestError;\n};\n\nconst baseOpen = async options => {\n\toptions = {\n\t\twait: false,\n\t\tbackground: false,\n\t\tnewInstance: false,\n\t\tallowNonzeroExitCode: false,\n\t\t...options\n\t};\n\n\tif (Array.isArray(options.app)) {\n\t\treturn pTryEach(options.app, singleApp => baseOpen({\n\t\t\t...options,\n\t\t\tapp: singleApp\n\t\t}));\n\t}\n\n\tlet {name: app, arguments: appArguments = []} = options.app || {};\n\tappArguments = [...appArguments];\n\n\tif (Array.isArray(app)) {\n\t\treturn pTryEach(app, appName => baseOpen({\n\t\t\t...options,\n\t\t\tapp: {\n\t\t\t\tname: appName,\n\t\t\t\targuments: appArguments\n\t\t\t}\n\t\t}));\n\t}\n\n\tlet command;\n\tconst cliArguments = [];\n\tconst childProcessOptions = {};\n\n\tif (platform === 'darwin') {\n\t\tcommand = 'open';\n\n\t\tif (options.wait) {\n\t\t\tcliArguments.push('--wait-apps');\n\t\t}\n\n\t\tif (options.background) {\n\t\t\tcliArguments.push('--background');\n\t\t}\n\n\t\tif (options.newInstance) {\n\t\t\tcliArguments.push('--new');\n\t\t}\n\n\t\tif (app) {\n\t\t\tcliArguments.push('-a', app);\n\t\t}\n\t} else if (platform === 'win32' || (isWsl && !isDocker())) {\n\t\tconst mountPoint = await getWslDrivesMountPoint();\n\n\t\tcommand = isWsl ?\n\t\t\t`${mountPoint}c/Windows/System32/WindowsPowerShell/v1.0/powershell.exe` :\n\t\t\t`${process.env.SYSTEMROOT}\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell`;\n\n\t\tcliArguments.push(\n\t\t\t'-NoProfile',\n\t\t\t'-NonInteractive',\n\t\t\t'–ExecutionPolicy',\n\t\t\t'Bypass',\n\t\t\t'-EncodedCommand'\n\t\t);\n\n\t\tif (!isWsl) {\n\t\t\tchildProcessOptions.windowsVerbatimArguments = true;\n\t\t}\n\n\t\tconst encodedArguments = ['Start'];\n\n\t\tif (options.wait) {\n\t\t\tencodedArguments.push('-Wait');\n\t\t}\n\n\t\tif (app) {\n\t\t\t// Double quote with double quotes to ensure the inner quotes are passed through.\n\t\t\t// Inner quotes are delimited for PowerShell interpretation with backticks.\n\t\t\tencodedArguments.push(`\"\\`\"${app}\\`\"\"`, '-ArgumentList');\n\t\t\tif (options.target) {\n\t\t\t\tappArguments.unshift(options.target);\n\t\t\t}\n\t\t} else if (options.target) {\n\t\t\tencodedArguments.push(`\"${options.target}\"`);\n\t\t}\n\n\t\tif (appArguments.length > 0) {\n\t\t\tappArguments = appArguments.map(arg => `\"\\`\"${arg}\\`\"\"`);\n\t\t\tencodedArguments.push(appArguments.join(','));\n\t\t}\n\n\t\t// Using Base64-encoded command, accepted by PowerShell, to allow special characters.\n\t\toptions.target = Buffer.from(encodedArguments.join(' '), 'utf16le').toString('base64');\n\t} else {\n\t\tif (app) {\n\t\t\tcommand = app;\n\t\t} else {\n\t\t\t// When bundled by Webpack, there's no actual package file path and no local `xdg-open`.\n\t\t\tconst isBundled = !__dirname || __dirname === '/';\n\n\t\t\t// Check if local `xdg-open` exists and is executable.\n\t\t\tlet exeLocalXdgOpen = false;\n\t\t\ttry {\n\t\t\t\tawait fs$1.access(localXdgOpenPath, fsConstants.X_OK);\n\t\t\t\texeLocalXdgOpen = true;\n\t\t\t} catch {}\n\n\t\t\tconst useSystemXdgOpen = process.versions.electron ||\n\t\t\t\tplatform === 'android' || isBundled || !exeLocalXdgOpen;\n\t\t\tcommand = useSystemXdgOpen ? 'xdg-open' : localXdgOpenPath;\n\t\t}\n\n\t\tif (appArguments.length > 0) {\n\t\t\tcliArguments.push(...appArguments);\n\t\t}\n\n\t\tif (!options.wait) {\n\t\t\t// `xdg-open` will block the process unless stdio is ignored\n\t\t\t// and it's detached from the parent even if it's unref'd.\n\t\t\tchildProcessOptions.stdio = 'ignore';\n\t\t\tchildProcessOptions.detached = true;\n\t\t}\n\t}\n\n\tif (options.target) {\n\t\tcliArguments.push(options.target);\n\t}\n\n\tif (platform === 'darwin' && appArguments.length > 0) {\n\t\tcliArguments.push('--args', ...appArguments);\n\t}\n\n\tconst subprocess = childProcess.spawn(command, cliArguments, childProcessOptions);\n\n\tif (options.wait) {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tsubprocess.once('error', reject);\n\n\t\t\tsubprocess.once('close', exitCode => {\n\t\t\t\tif (options.allowNonzeroExitCode && exitCode > 0) {\n\t\t\t\t\treject(new Error(`Exited with code ${exitCode}`));\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tresolve(subprocess);\n\t\t\t});\n\t\t});\n\t}\n\n\tsubprocess.unref();\n\n\treturn subprocess;\n};\n\nconst open = (target, options) => {\n\tif (typeof target !== 'string') {\n\t\tthrow new TypeError('Expected a `target`');\n\t}\n\n\treturn baseOpen({\n\t\t...options,\n\t\ttarget\n\t});\n};\n\nconst openApp = (name, options) => {\n\tif (typeof name !== 'string') {\n\t\tthrow new TypeError('Expected a `name`');\n\t}\n\n\tconst {arguments: appArguments = []} = options || {};\n\tif (appArguments !== undefined && appArguments !== null && !Array.isArray(appArguments)) {\n\t\tthrow new TypeError('Expected `appArguments` as Array type');\n\t}\n\n\treturn baseOpen({\n\t\t...options,\n\t\tapp: {\n\t\t\tname,\n\t\t\targuments: appArguments\n\t\t}\n\t});\n};\n\nfunction detectArchBinary(binary) {\n\tif (typeof binary === 'string' || Array.isArray(binary)) {\n\t\treturn binary;\n\t}\n\n\tconst {[arch]: archBinary} = binary;\n\n\tif (!archBinary) {\n\t\tthrow new Error(`${arch} is not supported`);\n\t}\n\n\treturn archBinary;\n}\n\nfunction detectPlatformBinary({[platform]: platformBinary}, {wsl}) {\n\tif (wsl && isWsl) {\n\t\treturn detectArchBinary(wsl);\n\t}\n\n\tif (!platformBinary) {\n\t\tthrow new Error(`${platform} is not supported`);\n\t}\n\n\treturn detectArchBinary(platformBinary);\n}\n\nconst apps = {};\n\ndefineLazyProperty(apps, 'chrome', () => detectPlatformBinary({\n\tdarwin: 'google chrome',\n\twin32: 'chrome',\n\tlinux: ['google-chrome', 'google-chrome-stable', 'chromium']\n}, {\n\twsl: {\n\t\tia32: '/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe',\n\t\tx64: ['/mnt/c/Program Files/Google/Chrome/Application/chrome.exe', '/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe']\n\t}\n}));\n\ndefineLazyProperty(apps, 'firefox', () => detectPlatformBinary({\n\tdarwin: 'firefox',\n\twin32: 'C:\\\\Program Files\\\\Mozilla Firefox\\\\firefox.exe',\n\tlinux: 'firefox'\n}, {\n\twsl: '/mnt/c/Program Files/Mozilla Firefox/firefox.exe'\n}));\n\ndefineLazyProperty(apps, 'edge', () => detectPlatformBinary({\n\tdarwin: 'microsoft edge',\n\twin32: 'msedge',\n\tlinux: ['microsoft-edge', 'microsoft-edge-dev']\n}, {\n\twsl: '/mnt/c/Program Files (x86)/Microsoft/Edge/Application/msedge.exe'\n}));\n\nopen.apps = apps;\nopen.openApp = openApp;\n\nvar open_1 = open;\n\nvar crossSpawnExports = {};\nvar crossSpawn = {\n  get exports(){ return crossSpawnExports; },\n  set exports(v){ crossSpawnExports = v; },\n};\n\nvar windows;\nvar hasRequiredWindows;\n\nfunction requireWindows () {\n\tif (hasRequiredWindows) return windows;\n\thasRequiredWindows = 1;\n\twindows = isexe;\n\tisexe.sync = sync;\n\n\tvar fs = require$$0__default;\n\n\tfunction checkPathExt (path, options) {\n\t  var pathext = options.pathExt !== undefined ?\n\t    options.pathExt : process.env.PATHEXT;\n\n\t  if (!pathext) {\n\t    return true\n\t  }\n\n\t  pathext = pathext.split(';');\n\t  if (pathext.indexOf('') !== -1) {\n\t    return true\n\t  }\n\t  for (var i = 0; i < pathext.length; i++) {\n\t    var p = pathext[i].toLowerCase();\n\t    if (p && path.substr(-p.length).toLowerCase() === p) {\n\t      return true\n\t    }\n\t  }\n\t  return false\n\t}\n\n\tfunction checkStat (stat, path, options) {\n\t  if (!stat.isSymbolicLink() && !stat.isFile()) {\n\t    return false\n\t  }\n\t  return checkPathExt(path, options)\n\t}\n\n\tfunction isexe (path, options, cb) {\n\t  fs.stat(path, function (er, stat) {\n\t    cb(er, er ? false : checkStat(stat, path, options));\n\t  });\n\t}\n\n\tfunction sync (path, options) {\n\t  return checkStat(fs.statSync(path), path, options)\n\t}\n\treturn windows;\n}\n\nvar mode;\nvar hasRequiredMode;\n\nfunction requireMode () {\n\tif (hasRequiredMode) return mode;\n\thasRequiredMode = 1;\n\tmode = isexe;\n\tisexe.sync = sync;\n\n\tvar fs = require$$0__default;\n\n\tfunction isexe (path, options, cb) {\n\t  fs.stat(path, function (er, stat) {\n\t    cb(er, er ? false : checkStat(stat, options));\n\t  });\n\t}\n\n\tfunction sync (path, options) {\n\t  return checkStat(fs.statSync(path), options)\n\t}\n\n\tfunction checkStat (stat, options) {\n\t  return stat.isFile() && checkMode(stat, options)\n\t}\n\n\tfunction checkMode (stat, options) {\n\t  var mod = stat.mode;\n\t  var uid = stat.uid;\n\t  var gid = stat.gid;\n\n\t  var myUid = options.uid !== undefined ?\n\t    options.uid : process.getuid && process.getuid();\n\t  var myGid = options.gid !== undefined ?\n\t    options.gid : process.getgid && process.getgid();\n\n\t  var u = parseInt('100', 8);\n\t  var g = parseInt('010', 8);\n\t  var o = parseInt('001', 8);\n\t  var ug = u | g;\n\n\t  var ret = (mod & o) ||\n\t    (mod & g) && gid === myGid ||\n\t    (mod & u) && uid === myUid ||\n\t    (mod & ug) && myUid === 0;\n\n\t  return ret\n\t}\n\treturn mode;\n}\n\nvar core;\nif (process.platform === 'win32' || commonjsGlobal.TESTING_WINDOWS) {\n  core = requireWindows();\n} else {\n  core = requireMode();\n}\n\nvar isexe_1 = isexe$1;\nisexe$1.sync = sync;\n\nfunction isexe$1 (path, options, cb) {\n  if (typeof options === 'function') {\n    cb = options;\n    options = {};\n  }\n\n  if (!cb) {\n    if (typeof Promise !== 'function') {\n      throw new TypeError('callback not provided')\n    }\n\n    return new Promise(function (resolve, reject) {\n      isexe$1(path, options || {}, function (er, is) {\n        if (er) {\n          reject(er);\n        } else {\n          resolve(is);\n        }\n      });\n    })\n  }\n\n  core(path, options || {}, function (er, is) {\n    // ignore EACCES because that just means we aren't allowed to run it\n    if (er) {\n      if (er.code === 'EACCES' || options && options.ignoreErrors) {\n        er = null;\n        is = false;\n      }\n    }\n    cb(er, is);\n  });\n}\n\nfunction sync (path, options) {\n  // my kingdom for a filtered catch\n  try {\n    return core.sync(path, options || {})\n  } catch (er) {\n    if (options && options.ignoreErrors || er.code === 'EACCES') {\n      return false\n    } else {\n      throw er\n    }\n  }\n}\n\nconst isWindows = process.platform === 'win32' ||\n    process.env.OSTYPE === 'cygwin' ||\n    process.env.OSTYPE === 'msys';\n\nconst path$2 = require$$0$4;\nconst COLON = isWindows ? ';' : ':';\nconst isexe = isexe_1;\n\nconst getNotFoundError = (cmd) =>\n  Object.assign(new Error(`not found: ${cmd}`), { code: 'ENOENT' });\n\nconst getPathInfo = (cmd, opt) => {\n  const colon = opt.colon || COLON;\n\n  // If it has a slash, then we don't bother searching the pathenv.\n  // just check the file itself, and that's it.\n  const pathEnv = cmd.match(/\\//) || isWindows && cmd.match(/\\\\/) ? ['']\n    : (\n      [\n        // windows always checks the cwd first\n        ...(isWindows ? [process.cwd()] : []),\n        ...(opt.path || process.env.PATH ||\n          /* istanbul ignore next: very unusual */ '').split(colon),\n      ]\n    );\n  const pathExtExe = isWindows\n    ? opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM'\n    : '';\n  const pathExt = isWindows ? pathExtExe.split(colon) : [''];\n\n  if (isWindows) {\n    if (cmd.indexOf('.') !== -1 && pathExt[0] !== '')\n      pathExt.unshift('');\n  }\n\n  return {\n    pathEnv,\n    pathExt,\n    pathExtExe,\n  }\n};\n\nconst which$1 = (cmd, opt, cb) => {\n  if (typeof opt === 'function') {\n    cb = opt;\n    opt = {};\n  }\n  if (!opt)\n    opt = {};\n\n  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt);\n  const found = [];\n\n  const step = i => new Promise((resolve, reject) => {\n    if (i === pathEnv.length)\n      return opt.all && found.length ? resolve(found)\n        : reject(getNotFoundError(cmd))\n\n    const ppRaw = pathEnv[i];\n    const pathPart = /^\".*\"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw;\n\n    const pCmd = path$2.join(pathPart, cmd);\n    const p = !pathPart && /^\\.[\\\\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd\n      : pCmd;\n\n    resolve(subStep(p, i, 0));\n  });\n\n  const subStep = (p, i, ii) => new Promise((resolve, reject) => {\n    if (ii === pathExt.length)\n      return resolve(step(i + 1))\n    const ext = pathExt[ii];\n    isexe(p + ext, { pathExt: pathExtExe }, (er, is) => {\n      if (!er && is) {\n        if (opt.all)\n          found.push(p + ext);\n        else\n          return resolve(p + ext)\n      }\n      return resolve(subStep(p, i, ii + 1))\n    });\n  });\n\n  return cb ? step(0).then(res => cb(null, res), cb) : step(0)\n};\n\nconst whichSync = (cmd, opt) => {\n  opt = opt || {};\n\n  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt);\n  const found = [];\n\n  for (let i = 0; i < pathEnv.length; i ++) {\n    const ppRaw = pathEnv[i];\n    const pathPart = /^\".*\"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw;\n\n    const pCmd = path$2.join(pathPart, cmd);\n    const p = !pathPart && /^\\.[\\\\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd\n      : pCmd;\n\n    for (let j = 0; j < pathExt.length; j ++) {\n      const cur = p + pathExt[j];\n      try {\n        const is = isexe.sync(cur, { pathExt: pathExtExe });\n        if (is) {\n          if (opt.all)\n            found.push(cur);\n          else\n            return cur\n        }\n      } catch (ex) {}\n    }\n  }\n\n  if (opt.all && found.length)\n    return found\n\n  if (opt.nothrow)\n    return null\n\n  throw getNotFoundError(cmd)\n};\n\nvar which_1 = which$1;\nwhich$1.sync = whichSync;\n\nvar pathKeyExports = {};\nvar pathKey$1 = {\n  get exports(){ return pathKeyExports; },\n  set exports(v){ pathKeyExports = v; },\n};\n\nconst pathKey = (options = {}) => {\n\tconst environment = options.env || process.env;\n\tconst platform = options.platform || process.platform;\n\n\tif (platform !== 'win32') {\n\t\treturn 'PATH';\n\t}\n\n\treturn Object.keys(environment).reverse().find(key => key.toUpperCase() === 'PATH') || 'Path';\n};\n\npathKey$1.exports = pathKey;\n// TODO: Remove this for the next major release\npathKeyExports.default = pathKey;\n\nconst path$1 = require$$0$4;\nconst which = which_1;\nconst getPathKey = pathKeyExports;\n\nfunction resolveCommandAttempt(parsed, withoutPathExt) {\n    const env = parsed.options.env || process.env;\n    const cwd = process.cwd();\n    const hasCustomCwd = parsed.options.cwd != null;\n    // Worker threads do not have process.chdir()\n    const shouldSwitchCwd = hasCustomCwd && process.chdir !== undefined && !process.chdir.disabled;\n\n    // If a custom `cwd` was specified, we need to change the process cwd\n    // because `which` will do stat calls but does not support a custom cwd\n    if (shouldSwitchCwd) {\n        try {\n            process.chdir(parsed.options.cwd);\n        } catch (err) {\n            /* Empty */\n        }\n    }\n\n    let resolved;\n\n    try {\n        resolved = which.sync(parsed.command, {\n            path: env[getPathKey({ env })],\n            pathExt: withoutPathExt ? path$1.delimiter : undefined,\n        });\n    } catch (e) {\n        /* Empty */\n    } finally {\n        if (shouldSwitchCwd) {\n            process.chdir(cwd);\n        }\n    }\n\n    // If we successfully resolved, ensure that an absolute path is returned\n    // Note that when a custom `cwd` was used, we need to resolve to an absolute path based on it\n    if (resolved) {\n        resolved = path$1.resolve(hasCustomCwd ? parsed.options.cwd : '', resolved);\n    }\n\n    return resolved;\n}\n\nfunction resolveCommand$1(parsed) {\n    return resolveCommandAttempt(parsed) || resolveCommandAttempt(parsed, true);\n}\n\nvar resolveCommand_1 = resolveCommand$1;\n\nvar _escape = {};\n\n// See http://www.robvanderwoude.com/escapechars.php\nconst metaCharsRegExp = /([()\\][%!^\"`<>&|;, *?])/g;\n\nfunction escapeCommand(arg) {\n    // Escape meta chars\n    arg = arg.replace(metaCharsRegExp, '^$1');\n\n    return arg;\n}\n\nfunction escapeArgument(arg, doubleEscapeMetaChars) {\n    // Convert to string\n    arg = `${arg}`;\n\n    // Algorithm below is based on https://qntm.org/cmd\n\n    // Sequence of backslashes followed by a double quote:\n    // double up all the backslashes and escape the double quote\n    arg = arg.replace(/(\\\\*)\"/g, '$1$1\\\\\"');\n\n    // Sequence of backslashes followed by the end of the string\n    // (which will become a double quote later):\n    // double up all the backslashes\n    arg = arg.replace(/(\\\\*)$/, '$1$1');\n\n    // All other backslashes occur literally\n\n    // Quote the whole thing:\n    arg = `\"${arg}\"`;\n\n    // Escape meta chars\n    arg = arg.replace(metaCharsRegExp, '^$1');\n\n    // Double escape meta chars if necessary\n    if (doubleEscapeMetaChars) {\n        arg = arg.replace(metaCharsRegExp, '^$1');\n    }\n\n    return arg;\n}\n\n_escape.command = escapeCommand;\n_escape.argument = escapeArgument;\n\nvar shebangRegex$1 = /^#!(.*)/;\n\nconst shebangRegex = shebangRegex$1;\n\nvar shebangCommand$1 = (string = '') => {\n\tconst match = string.match(shebangRegex);\n\n\tif (!match) {\n\t\treturn null;\n\t}\n\n\tconst [path, argument] = match[0].replace(/#! ?/, '').split(' ');\n\tconst binary = path.split('/').pop();\n\n\tif (binary === 'env') {\n\t\treturn argument;\n\t}\n\n\treturn argument ? `${binary} ${argument}` : binary;\n};\n\nconst fs = require$$0__default;\nconst shebangCommand = shebangCommand$1;\n\nfunction readShebang$1(command) {\n    // Read the first 150 bytes from the file\n    const size = 150;\n    const buffer = Buffer.alloc(size);\n\n    let fd;\n\n    try {\n        fd = fs.openSync(command, 'r');\n        fs.readSync(fd, buffer, 0, size, 0);\n        fs.closeSync(fd);\n    } catch (e) { /* Empty */ }\n\n    // Attempt to extract shebang (null is returned if not a shebang)\n    return shebangCommand(buffer.toString());\n}\n\nvar readShebang_1 = readShebang$1;\n\nconst path = require$$0$4;\nconst resolveCommand = resolveCommand_1;\nconst escape$1 = _escape;\nconst readShebang = readShebang_1;\n\nconst isWin$1 = process.platform === 'win32';\nconst isExecutableRegExp = /\\.(?:com|exe)$/i;\nconst isCmdShimRegExp = /node_modules[\\\\/].bin[\\\\/][^\\\\/]+\\.cmd$/i;\n\nfunction detectShebang(parsed) {\n    parsed.file = resolveCommand(parsed);\n\n    const shebang = parsed.file && readShebang(parsed.file);\n\n    if (shebang) {\n        parsed.args.unshift(parsed.file);\n        parsed.command = shebang;\n\n        return resolveCommand(parsed);\n    }\n\n    return parsed.file;\n}\n\nfunction parseNonShell(parsed) {\n    if (!isWin$1) {\n        return parsed;\n    }\n\n    // Detect & add support for shebangs\n    const commandFile = detectShebang(parsed);\n\n    // We don't need a shell if the command filename is an executable\n    const needsShell = !isExecutableRegExp.test(commandFile);\n\n    // If a shell is required, use cmd.exe and take care of escaping everything correctly\n    // Note that `forceShell` is an hidden option used only in tests\n    if (parsed.options.forceShell || needsShell) {\n        // Need to double escape meta chars if the command is a cmd-shim located in `node_modules/.bin/`\n        // The cmd-shim simply calls execute the package bin file with NodeJS, proxying any argument\n        // Because the escape of metachars with ^ gets interpreted when the cmd.exe is first called,\n        // we need to double escape them\n        const needsDoubleEscapeMetaChars = isCmdShimRegExp.test(commandFile);\n\n        // Normalize posix paths into OS compatible paths (e.g.: foo/bar -> foo\\bar)\n        // This is necessary otherwise it will always fail with ENOENT in those cases\n        parsed.command = path.normalize(parsed.command);\n\n        // Escape command & arguments\n        parsed.command = escape$1.command(parsed.command);\n        parsed.args = parsed.args.map((arg) => escape$1.argument(arg, needsDoubleEscapeMetaChars));\n\n        const shellCommand = [parsed.command].concat(parsed.args).join(' ');\n\n        parsed.args = ['/d', '/s', '/c', `\"${shellCommand}\"`];\n        parsed.command = process.env.comspec || 'cmd.exe';\n        parsed.options.windowsVerbatimArguments = true; // Tell node's spawn that the arguments are already escaped\n    }\n\n    return parsed;\n}\n\nfunction parse$4(command, args, options) {\n    // Normalize arguments, similar to nodejs\n    if (args && !Array.isArray(args)) {\n        options = args;\n        args = null;\n    }\n\n    args = args ? args.slice(0) : []; // Clone array to avoid changing the original\n    options = Object.assign({}, options); // Clone object to avoid changing the original\n\n    // Build our parsed object\n    const parsed = {\n        command,\n        args,\n        options,\n        file: undefined,\n        original: {\n            command,\n            args,\n        },\n    };\n\n    // Delegate further parsing to shell or non-shell\n    return options.shell ? parsed : parseNonShell(parsed);\n}\n\nvar parse_1 = parse$4;\n\nconst isWin = process.platform === 'win32';\n\nfunction notFoundError(original, syscall) {\n    return Object.assign(new Error(`${syscall} ${original.command} ENOENT`), {\n        code: 'ENOENT',\n        errno: 'ENOENT',\n        syscall: `${syscall} ${original.command}`,\n        path: original.command,\n        spawnargs: original.args,\n    });\n}\n\nfunction hookChildProcess(cp, parsed) {\n    if (!isWin) {\n        return;\n    }\n\n    const originalEmit = cp.emit;\n\n    cp.emit = function (name, arg1) {\n        // If emitting \"exit\" event and exit code is 1, we need to check if\n        // the command exists and emit an \"error\" instead\n        // See https://github.com/IndigoUnited/node-cross-spawn/issues/16\n        if (name === 'exit') {\n            const err = verifyENOENT(arg1, parsed);\n\n            if (err) {\n                return originalEmit.call(cp, 'error', err);\n            }\n        }\n\n        return originalEmit.apply(cp, arguments); // eslint-disable-line prefer-rest-params\n    };\n}\n\nfunction verifyENOENT(status, parsed) {\n    if (isWin && status === 1 && !parsed.file) {\n        return notFoundError(parsed.original, 'spawn');\n    }\n\n    return null;\n}\n\nfunction verifyENOENTSync(status, parsed) {\n    if (isWin && status === 1 && !parsed.file) {\n        return notFoundError(parsed.original, 'spawnSync');\n    }\n\n    return null;\n}\n\nvar enoent$1 = {\n    hookChildProcess,\n    verifyENOENT,\n    verifyENOENTSync,\n    notFoundError,\n};\n\nconst cp = require$$2$1;\nconst parse$3 = parse_1;\nconst enoent = enoent$1;\n\nfunction spawn(command, args, options) {\n    // Parse the arguments\n    const parsed = parse$3(command, args, options);\n\n    // Spawn the child process\n    const spawned = cp.spawn(parsed.command, parsed.args, parsed.options);\n\n    // Hook into child process \"exit\" event to emit an error if the command\n    // does not exists, see: https://github.com/IndigoUnited/node-cross-spawn/issues/16\n    enoent.hookChildProcess(spawned, parsed);\n\n    return spawned;\n}\n\nfunction spawnSync(command, args, options) {\n    // Parse the arguments\n    const parsed = parse$3(command, args, options);\n\n    // Spawn the child process\n    const result = cp.spawnSync(parsed.command, parsed.args, parsed.options);\n\n    // Analyze if the command does not exist, see: https://github.com/IndigoUnited/node-cross-spawn/issues/16\n    result.error = result.error || enoent.verifyENOENTSync(result.status, parsed);\n\n    return result;\n}\n\ncrossSpawn.exports = spawn;\ncrossSpawnExports.spawn = spawn;\ncrossSpawnExports.sync = spawnSync;\n\ncrossSpawnExports._parse = parse$3;\ncrossSpawnExports._enoent = enoent;\n\n/**\n * The following is modified based on source found in\n * https://github.com/facebook/create-react-app\n *\n * MIT Licensed\n * Copyright (c) 2015-present, Facebook, Inc.\n * https://github.com/facebook/create-react-app/blob/master/LICENSE\n *\n */\n/**\n * Reads the BROWSER environment variable and decides what to do with it.\n * Returns true if it opened a browser or ran a node.js script, otherwise false.\n */\nfunction openBrowser(url, opt, logger) {\n    // The browser executable to open.\n    // See https://github.com/sindresorhus/open#app for documentation.\n    const browser = typeof opt === 'string' ? opt : process.env.BROWSER || '';\n    if (browser.toLowerCase().endsWith('.js')) {\n        return executeNodeScript(browser, url, logger);\n    }\n    else if (browser.toLowerCase() !== 'none') {\n        const browserArgs = process.env.BROWSER_ARGS\n            ? process.env.BROWSER_ARGS.split(' ')\n            : [];\n        return startBrowserProcess(browser, browserArgs, url);\n    }\n    return false;\n}\nfunction executeNodeScript(scriptPath, url, logger) {\n    const extraArgs = process.argv.slice(2);\n    const child = crossSpawnExports(process.execPath, [scriptPath, ...extraArgs, url], {\n        stdio: 'inherit',\n    });\n    child.on('close', (code) => {\n        if (code !== 0) {\n            logger.error(picocolorsExports.red(`\\nThe script specified as BROWSER environment variable failed.\\n\\n${picocolorsExports.cyan(scriptPath)} exited with code ${code}.`), { error: null });\n        }\n    });\n    return true;\n}\nconst supportedChromiumBrowsers = [\n    'Google Chrome Canary',\n    'Google Chrome Dev',\n    'Google Chrome Beta',\n    'Google Chrome',\n    'Microsoft Edge',\n    'Brave Browser',\n    'Vivaldi',\n    'Chromium',\n];\nfunction startBrowserProcess(browser, browserArgs, url) {\n    // If we're on OS X, the user hasn't specifically\n    // requested a different browser, we can try opening\n    // a Chromium browser with AppleScript. This lets us reuse an\n    // existing tab when possible instead of creating a new one.\n    const preferredOSXBrowser = browser === 'google chrome' ? 'Google Chrome' : browser;\n    const shouldTryOpenChromeWithAppleScript = process.platform === 'darwin' &&\n        (!preferredOSXBrowser ||\n            supportedChromiumBrowsers.includes(preferredOSXBrowser));\n    if (shouldTryOpenChromeWithAppleScript) {\n        try {\n            const ps = execSync('ps cax').toString();\n            const openedBrowser = preferredOSXBrowser && ps.includes(preferredOSXBrowser)\n                ? preferredOSXBrowser\n                : supportedChromiumBrowsers.find((b) => ps.includes(b));\n            if (openedBrowser) {\n                // Try our best to reuse existing tab with AppleScript\n                execSync(`osascript openChrome.applescript \"${encodeURI(url)}\" \"${openedBrowser}\"`, {\n                    cwd: join$2(VITE_PACKAGE_DIR, 'bin'),\n                    stdio: 'ignore',\n                });\n                return true;\n            }\n        }\n        catch (err) {\n            // Ignore errors\n        }\n    }\n    // Another special case: on OS X, check if BROWSER has been set to \"open\".\n    // In this case, instead of passing the string `open` to `open` function (which won't work),\n    // just ignore it (thus ensuring the intended behavior, i.e. opening the system browser):\n    // https://github.com/facebook/create-react-app/pull/1690#issuecomment-283518768\n    if (process.platform === 'darwin' && browser === 'open') {\n        browser = undefined;\n    }\n    // Fallback to open\n    // (It will always open new tab)\n    try {\n        const options = browser\n            ? { app: { name: browser, arguments: browserArgs } }\n            : {};\n        open_1(url, options).catch(() => { }); // Prevent `unhandledRejection` error.\n        return true;\n    }\n    catch (err) {\n        return false;\n    }\n}\n\nfunction bindShortcuts(server, opts) {\n    if (!server.httpServer || !process.stdin.isTTY || process.env.CI) {\n        return;\n    }\n    server._shortcutsOptions = opts;\n    if (opts.print) {\n        server.config.logger.info(picocolorsExports.dim(picocolorsExports.green('  ➜')) +\n            picocolorsExports.dim('  press ') +\n            picocolorsExports.bold('h') +\n            picocolorsExports.dim(' to show help'));\n    }\n    const shortcuts = (opts.customShortcuts ?? [])\n        .filter(isDefined)\n        .concat(BASE_SHORTCUTS);\n    let actionRunning = false;\n    const onInput = async (input) => {\n        // ctrl+c or ctrl+d\n        if (input === '\\x03' || input === '\\x04') {\n            await server.close().finally(() => process.exit(1));\n            return;\n        }\n        if (actionRunning)\n            return;\n        if (input === 'h') {\n            server.config.logger.info([\n                '',\n                picocolorsExports.bold('  Shortcuts'),\n                ...shortcuts.map((shortcut) => picocolorsExports.dim('  press ') +\n                    picocolorsExports.bold(shortcut.key) +\n                    picocolorsExports.dim(` to ${shortcut.description}`)),\n            ].join('\\n'));\n        }\n        const shortcut = shortcuts.find((shortcut) => shortcut.key === input);\n        if (!shortcut)\n            return;\n        actionRunning = true;\n        await shortcut.action(server);\n        actionRunning = false;\n    };\n    process.stdin.setRawMode(true);\n    process.stdin.on('data', onInput).setEncoding('utf8').resume();\n    server.httpServer.on('close', () => {\n        process.stdin.off('data', onInput).pause();\n    });\n}\nconst BASE_SHORTCUTS = [\n    {\n        key: 'r',\n        description: 'restart the server',\n        async action(server) {\n            await server.restart();\n        },\n    },\n    {\n        key: 'u',\n        description: 'show server url',\n        action(server) {\n            server.config.logger.info('');\n            server.printUrls();\n        },\n    },\n    {\n        key: 'o',\n        description: 'open in browser',\n        action(server) {\n            const url = server.resolvedUrls?.local[0];\n            if (!url) {\n                server.config.logger.warn('No URL available to open in browser');\n                return;\n            }\n            openBrowser(url, true, server.config.logger);\n        },\n    },\n    {\n        key: 'c',\n        description: 'clear console',\n        action(server) {\n            server.config.logger.clearScreen('error');\n        },\n    },\n    {\n        key: 'q',\n        description: 'quit',\n        async action(server) {\n            await server.close().finally(() => process.exit());\n        },\n    },\n];\n\nvar bufferUtilExports = {};\nvar bufferUtil$1 = {\n  get exports(){ return bufferUtilExports; },\n  set exports(v){ bufferUtilExports = v; },\n};\n\nvar constants = {\n  BINARY_TYPES: ['nodebuffer', 'arraybuffer', 'fragments'],\n  EMPTY_BUFFER: Buffer.alloc(0),\n  GUID: '258EAFA5-E914-47DA-95CA-C5AB0DC85B11',\n  kForOnEventAttribute: Symbol('kIsForOnEventAttribute'),\n  kListener: Symbol('kListener'),\n  kStatusCode: Symbol('status-code'),\n  kWebSocket: Symbol('websocket'),\n  NOOP: () => {}\n};\n\nconst { EMPTY_BUFFER: EMPTY_BUFFER$3 } = constants;\n\nconst FastBuffer$2 = Buffer[Symbol.species];\n\n/**\n * Merges an array of buffers into a new buffer.\n *\n * @param {Buffer[]} list The array of buffers to concat\n * @param {Number} totalLength The total length of buffers in the list\n * @return {Buffer} The resulting buffer\n * @public\n */\nfunction concat$1(list, totalLength) {\n  if (list.length === 0) return EMPTY_BUFFER$3;\n  if (list.length === 1) return list[0];\n\n  const target = Buffer.allocUnsafe(totalLength);\n  let offset = 0;\n\n  for (let i = 0; i < list.length; i++) {\n    const buf = list[i];\n    target.set(buf, offset);\n    offset += buf.length;\n  }\n\n  if (offset < totalLength) {\n    return new FastBuffer$2(target.buffer, target.byteOffset, offset);\n  }\n\n  return target;\n}\n\n/**\n * Masks a buffer using the given mask.\n *\n * @param {Buffer} source The buffer to mask\n * @param {Buffer} mask The mask to use\n * @param {Buffer} output The buffer where to store the result\n * @param {Number} offset The offset at which to start writing\n * @param {Number} length The number of bytes to mask.\n * @public\n */\nfunction _mask(source, mask, output, offset, length) {\n  for (let i = 0; i < length; i++) {\n    output[offset + i] = source[i] ^ mask[i & 3];\n  }\n}\n\n/**\n * Unmasks a buffer using the given mask.\n *\n * @param {Buffer} buffer The buffer to unmask\n * @param {Buffer} mask The mask to use\n * @public\n */\nfunction _unmask(buffer, mask) {\n  for (let i = 0; i < buffer.length; i++) {\n    buffer[i] ^= mask[i & 3];\n  }\n}\n\n/**\n * Converts a buffer to an `ArrayBuffer`.\n *\n * @param {Buffer} buf The buffer to convert\n * @return {ArrayBuffer} Converted buffer\n * @public\n */\nfunction toArrayBuffer$1(buf) {\n  if (buf.length === buf.buffer.byteLength) {\n    return buf.buffer;\n  }\n\n  return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.length);\n}\n\n/**\n * Converts `data` to a `Buffer`.\n *\n * @param {*} data The data to convert\n * @return {Buffer} The buffer\n * @throws {TypeError}\n * @public\n */\nfunction toBuffer$2(data) {\n  toBuffer$2.readOnly = true;\n\n  if (Buffer.isBuffer(data)) return data;\n\n  let buf;\n\n  if (data instanceof ArrayBuffer) {\n    buf = new FastBuffer$2(data);\n  } else if (ArrayBuffer.isView(data)) {\n    buf = new FastBuffer$2(data.buffer, data.byteOffset, data.byteLength);\n  } else {\n    buf = Buffer.from(data);\n    toBuffer$2.readOnly = false;\n  }\n\n  return buf;\n}\n\nbufferUtil$1.exports = {\n  concat: concat$1,\n  mask: _mask,\n  toArrayBuffer: toArrayBuffer$1,\n  toBuffer: toBuffer$2,\n  unmask: _unmask\n};\n\n/* istanbul ignore else  */\nif (!process.env.WS_NO_BUFFER_UTIL) {\n  try {\n    const bufferUtil = require('bufferutil');\n\n    bufferUtilExports.mask = function (source, mask, output, offset, length) {\n      if (length < 48) _mask(source, mask, output, offset, length);\n      else bufferUtil.mask(source, mask, output, offset, length);\n    };\n\n    bufferUtilExports.unmask = function (buffer, mask) {\n      if (buffer.length < 32) _unmask(buffer, mask);\n      else bufferUtil.unmask(buffer, mask);\n    };\n  } catch (e) {\n    // Continue regardless of the error.\n  }\n}\n\nconst kDone = Symbol('kDone');\nconst kRun = Symbol('kRun');\n\n/**\n * A very simple job queue with adjustable concurrency. Adapted from\n * https://github.com/STRML/async-limiter\n */\nlet Limiter$1 = class Limiter {\n  /**\n   * Creates a new `Limiter`.\n   *\n   * @param {Number} [concurrency=Infinity] The maximum number of jobs allowed\n   *     to run concurrently\n   */\n  constructor(concurrency) {\n    this[kDone] = () => {\n      this.pending--;\n      this[kRun]();\n    };\n    this.concurrency = concurrency || Infinity;\n    this.jobs = [];\n    this.pending = 0;\n  }\n\n  /**\n   * Adds a job to the queue.\n   *\n   * @param {Function} job The job to run\n   * @public\n   */\n  add(job) {\n    this.jobs.push(job);\n    this[kRun]();\n  }\n\n  /**\n   * Removes a job from the queue and runs it if possible.\n   *\n   * @private\n   */\n  [kRun]() {\n    if (this.pending === this.concurrency) return;\n\n    if (this.jobs.length) {\n      const job = this.jobs.shift();\n\n      this.pending++;\n      job(this[kDone]);\n    }\n  }\n};\n\nvar limiter = Limiter$1;\n\nconst zlib = require$$0$a;\n\nconst bufferUtil = bufferUtilExports;\nconst Limiter = limiter;\nconst { kStatusCode: kStatusCode$2 } = constants;\n\nconst FastBuffer$1 = Buffer[Symbol.species];\nconst TRAILER = Buffer.from([0x00, 0x00, 0xff, 0xff]);\nconst kPerMessageDeflate = Symbol('permessage-deflate');\nconst kTotalLength = Symbol('total-length');\nconst kCallback = Symbol('callback');\nconst kBuffers = Symbol('buffers');\nconst kError$1 = Symbol('error');\n\n//\n// We limit zlib concurrency, which prevents severe memory fragmentation\n// as documented in https://github.com/nodejs/node/issues/8871#issuecomment-250915913\n// and https://github.com/websockets/ws/issues/1202\n//\n// Intentionally global; it's the global thread pool that's an issue.\n//\nlet zlibLimiter;\n\n/**\n * permessage-deflate implementation.\n */\nlet PerMessageDeflate$4 = class PerMessageDeflate {\n  /**\n   * Creates a PerMessageDeflate instance.\n   *\n   * @param {Object} [options] Configuration options\n   * @param {(Boolean|Number)} [options.clientMaxWindowBits] Advertise support\n   *     for, or request, a custom client window size\n   * @param {Boolean} [options.clientNoContextTakeover=false] Advertise/\n   *     acknowledge disabling of client context takeover\n   * @param {Number} [options.concurrencyLimit=10] The number of concurrent\n   *     calls to zlib\n   * @param {(Boolean|Number)} [options.serverMaxWindowBits] Request/confirm the\n   *     use of a custom server window size\n   * @param {Boolean} [options.serverNoContextTakeover=false] Request/accept\n   *     disabling of server context takeover\n   * @param {Number} [options.threshold=1024] Size (in bytes) below which\n   *     messages should not be compressed if context takeover is disabled\n   * @param {Object} [options.zlibDeflateOptions] Options to pass to zlib on\n   *     deflate\n   * @param {Object} [options.zlibInflateOptions] Options to pass to zlib on\n   *     inflate\n   * @param {Boolean} [isServer=false] Create the instance in either server or\n   *     client mode\n   * @param {Number} [maxPayload=0] The maximum allowed message length\n   */\n  constructor(options, isServer, maxPayload) {\n    this._maxPayload = maxPayload | 0;\n    this._options = options || {};\n    this._threshold =\n      this._options.threshold !== undefined ? this._options.threshold : 1024;\n    this._isServer = !!isServer;\n    this._deflate = null;\n    this._inflate = null;\n\n    this.params = null;\n\n    if (!zlibLimiter) {\n      const concurrency =\n        this._options.concurrencyLimit !== undefined\n          ? this._options.concurrencyLimit\n          : 10;\n      zlibLimiter = new Limiter(concurrency);\n    }\n  }\n\n  /**\n   * @type {String}\n   */\n  static get extensionName() {\n    return 'permessage-deflate';\n  }\n\n  /**\n   * Create an extension negotiation offer.\n   *\n   * @return {Object} Extension parameters\n   * @public\n   */\n  offer() {\n    const params = {};\n\n    if (this._options.serverNoContextTakeover) {\n      params.server_no_context_takeover = true;\n    }\n    if (this._options.clientNoContextTakeover) {\n      params.client_no_context_takeover = true;\n    }\n    if (this._options.serverMaxWindowBits) {\n      params.server_max_window_bits = this._options.serverMaxWindowBits;\n    }\n    if (this._options.clientMaxWindowBits) {\n      params.client_max_window_bits = this._options.clientMaxWindowBits;\n    } else if (this._options.clientMaxWindowBits == null) {\n      params.client_max_window_bits = true;\n    }\n\n    return params;\n  }\n\n  /**\n   * Accept an extension negotiation offer/response.\n   *\n   * @param {Array} configurations The extension negotiation offers/reponse\n   * @return {Object} Accepted configuration\n   * @public\n   */\n  accept(configurations) {\n    configurations = this.normalizeParams(configurations);\n\n    this.params = this._isServer\n      ? this.acceptAsServer(configurations)\n      : this.acceptAsClient(configurations);\n\n    return this.params;\n  }\n\n  /**\n   * Releases all resources used by the extension.\n   *\n   * @public\n   */\n  cleanup() {\n    if (this._inflate) {\n      this._inflate.close();\n      this._inflate = null;\n    }\n\n    if (this._deflate) {\n      const callback = this._deflate[kCallback];\n\n      this._deflate.close();\n      this._deflate = null;\n\n      if (callback) {\n        callback(\n          new Error(\n            'The deflate stream was closed while data was being processed'\n          )\n        );\n      }\n    }\n  }\n\n  /**\n   *  Accept an extension negotiation offer.\n   *\n   * @param {Array} offers The extension negotiation offers\n   * @return {Object} Accepted configuration\n   * @private\n   */\n  acceptAsServer(offers) {\n    const opts = this._options;\n    const accepted = offers.find((params) => {\n      if (\n        (opts.serverNoContextTakeover === false &&\n          params.server_no_context_takeover) ||\n        (params.server_max_window_bits &&\n          (opts.serverMaxWindowBits === false ||\n            (typeof opts.serverMaxWindowBits === 'number' &&\n              opts.serverMaxWindowBits > params.server_max_window_bits))) ||\n        (typeof opts.clientMaxWindowBits === 'number' &&\n          !params.client_max_window_bits)\n      ) {\n        return false;\n      }\n\n      return true;\n    });\n\n    if (!accepted) {\n      throw new Error('None of the extension offers can be accepted');\n    }\n\n    if (opts.serverNoContextTakeover) {\n      accepted.server_no_context_takeover = true;\n    }\n    if (opts.clientNoContextTakeover) {\n      accepted.client_no_context_takeover = true;\n    }\n    if (typeof opts.serverMaxWindowBits === 'number') {\n      accepted.server_max_window_bits = opts.serverMaxWindowBits;\n    }\n    if (typeof opts.clientMaxWindowBits === 'number') {\n      accepted.client_max_window_bits = opts.clientMaxWindowBits;\n    } else if (\n      accepted.client_max_window_bits === true ||\n      opts.clientMaxWindowBits === false\n    ) {\n      delete accepted.client_max_window_bits;\n    }\n\n    return accepted;\n  }\n\n  /**\n   * Accept the extension negotiation response.\n   *\n   * @param {Array} response The extension negotiation response\n   * @return {Object} Accepted configuration\n   * @private\n   */\n  acceptAsClient(response) {\n    const params = response[0];\n\n    if (\n      this._options.clientNoContextTakeover === false &&\n      params.client_no_context_takeover\n    ) {\n      throw new Error('Unexpected parameter \"client_no_context_takeover\"');\n    }\n\n    if (!params.client_max_window_bits) {\n      if (typeof this._options.clientMaxWindowBits === 'number') {\n        params.client_max_window_bits = this._options.clientMaxWindowBits;\n      }\n    } else if (\n      this._options.clientMaxWindowBits === false ||\n      (typeof this._options.clientMaxWindowBits === 'number' &&\n        params.client_max_window_bits > this._options.clientMaxWindowBits)\n    ) {\n      throw new Error(\n        'Unexpected or invalid parameter \"client_max_window_bits\"'\n      );\n    }\n\n    return params;\n  }\n\n  /**\n   * Normalize parameters.\n   *\n   * @param {Array} configurations The extension negotiation offers/reponse\n   * @return {Array} The offers/response with normalized parameters\n   * @private\n   */\n  normalizeParams(configurations) {\n    configurations.forEach((params) => {\n      Object.keys(params).forEach((key) => {\n        let value = params[key];\n\n        if (value.length > 1) {\n          throw new Error(`Parameter \"${key}\" must have only a single value`);\n        }\n\n        value = value[0];\n\n        if (key === 'client_max_window_bits') {\n          if (value !== true) {\n            const num = +value;\n            if (!Number.isInteger(num) || num < 8 || num > 15) {\n              throw new TypeError(\n                `Invalid value for parameter \"${key}\": ${value}`\n              );\n            }\n            value = num;\n          } else if (!this._isServer) {\n            throw new TypeError(\n              `Invalid value for parameter \"${key}\": ${value}`\n            );\n          }\n        } else if (key === 'server_max_window_bits') {\n          const num = +value;\n          if (!Number.isInteger(num) || num < 8 || num > 15) {\n            throw new TypeError(\n              `Invalid value for parameter \"${key}\": ${value}`\n            );\n          }\n          value = num;\n        } else if (\n          key === 'client_no_context_takeover' ||\n          key === 'server_no_context_takeover'\n        ) {\n          if (value !== true) {\n            throw new TypeError(\n              `Invalid value for parameter \"${key}\": ${value}`\n            );\n          }\n        } else {\n          throw new Error(`Unknown parameter \"${key}\"`);\n        }\n\n        params[key] = value;\n      });\n    });\n\n    return configurations;\n  }\n\n  /**\n   * Decompress data. Concurrency limited.\n   *\n   * @param {Buffer} data Compressed data\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @public\n   */\n  decompress(data, fin, callback) {\n    zlibLimiter.add((done) => {\n      this._decompress(data, fin, (err, result) => {\n        done();\n        callback(err, result);\n      });\n    });\n  }\n\n  /**\n   * Compress data. Concurrency limited.\n   *\n   * @param {(Buffer|String)} data Data to compress\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @public\n   */\n  compress(data, fin, callback) {\n    zlibLimiter.add((done) => {\n      this._compress(data, fin, (err, result) => {\n        done();\n        callback(err, result);\n      });\n    });\n  }\n\n  /**\n   * Decompress data.\n   *\n   * @param {Buffer} data Compressed data\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @private\n   */\n  _decompress(data, fin, callback) {\n    const endpoint = this._isServer ? 'client' : 'server';\n\n    if (!this._inflate) {\n      const key = `${endpoint}_max_window_bits`;\n      const windowBits =\n        typeof this.params[key] !== 'number'\n          ? zlib.Z_DEFAULT_WINDOWBITS\n          : this.params[key];\n\n      this._inflate = zlib.createInflateRaw({\n        ...this._options.zlibInflateOptions,\n        windowBits\n      });\n      this._inflate[kPerMessageDeflate] = this;\n      this._inflate[kTotalLength] = 0;\n      this._inflate[kBuffers] = [];\n      this._inflate.on('error', inflateOnError);\n      this._inflate.on('data', inflateOnData);\n    }\n\n    this._inflate[kCallback] = callback;\n\n    this._inflate.write(data);\n    if (fin) this._inflate.write(TRAILER);\n\n    this._inflate.flush(() => {\n      const err = this._inflate[kError$1];\n\n      if (err) {\n        this._inflate.close();\n        this._inflate = null;\n        callback(err);\n        return;\n      }\n\n      const data = bufferUtil.concat(\n        this._inflate[kBuffers],\n        this._inflate[kTotalLength]\n      );\n\n      if (this._inflate._readableState.endEmitted) {\n        this._inflate.close();\n        this._inflate = null;\n      } else {\n        this._inflate[kTotalLength] = 0;\n        this._inflate[kBuffers] = [];\n\n        if (fin && this.params[`${endpoint}_no_context_takeover`]) {\n          this._inflate.reset();\n        }\n      }\n\n      callback(null, data);\n    });\n  }\n\n  /**\n   * Compress data.\n   *\n   * @param {(Buffer|String)} data Data to compress\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @private\n   */\n  _compress(data, fin, callback) {\n    const endpoint = this._isServer ? 'server' : 'client';\n\n    if (!this._deflate) {\n      const key = `${endpoint}_max_window_bits`;\n      const windowBits =\n        typeof this.params[key] !== 'number'\n          ? zlib.Z_DEFAULT_WINDOWBITS\n          : this.params[key];\n\n      this._deflate = zlib.createDeflateRaw({\n        ...this._options.zlibDeflateOptions,\n        windowBits\n      });\n\n      this._deflate[kTotalLength] = 0;\n      this._deflate[kBuffers] = [];\n\n      this._deflate.on('data', deflateOnData);\n    }\n\n    this._deflate[kCallback] = callback;\n\n    this._deflate.write(data);\n    this._deflate.flush(zlib.Z_SYNC_FLUSH, () => {\n      if (!this._deflate) {\n        //\n        // The deflate stream was closed while data was being processed.\n        //\n        return;\n      }\n\n      let data = bufferUtil.concat(\n        this._deflate[kBuffers],\n        this._deflate[kTotalLength]\n      );\n\n      if (fin) {\n        data = new FastBuffer$1(data.buffer, data.byteOffset, data.length - 4);\n      }\n\n      //\n      // Ensure that the callback will not be called again in\n      // `PerMessageDeflate#cleanup()`.\n      //\n      this._deflate[kCallback] = null;\n\n      this._deflate[kTotalLength] = 0;\n      this._deflate[kBuffers] = [];\n\n      if (fin && this.params[`${endpoint}_no_context_takeover`]) {\n        this._deflate.reset();\n      }\n\n      callback(null, data);\n    });\n  }\n};\n\nvar permessageDeflate = PerMessageDeflate$4;\n\n/**\n * The listener of the `zlib.DeflateRaw` stream `'data'` event.\n *\n * @param {Buffer} chunk A chunk of data\n * @private\n */\nfunction deflateOnData(chunk) {\n  this[kBuffers].push(chunk);\n  this[kTotalLength] += chunk.length;\n}\n\n/**\n * The listener of the `zlib.InflateRaw` stream `'data'` event.\n *\n * @param {Buffer} chunk A chunk of data\n * @private\n */\nfunction inflateOnData(chunk) {\n  this[kTotalLength] += chunk.length;\n\n  if (\n    this[kPerMessageDeflate]._maxPayload < 1 ||\n    this[kTotalLength] <= this[kPerMessageDeflate]._maxPayload\n  ) {\n    this[kBuffers].push(chunk);\n    return;\n  }\n\n  this[kError$1] = new RangeError('Max payload size exceeded');\n  this[kError$1].code = 'WS_ERR_UNSUPPORTED_MESSAGE_LENGTH';\n  this[kError$1][kStatusCode$2] = 1009;\n  this.removeListener('data', inflateOnData);\n  this.reset();\n}\n\n/**\n * The listener of the `zlib.InflateRaw` stream `'error'` event.\n *\n * @param {Error} err The emitted error\n * @private\n */\nfunction inflateOnError(err) {\n  //\n  // There is no need to call `Zlib#close()` as the handle is automatically\n  // closed when an error is emitted.\n  //\n  this[kPerMessageDeflate]._inflate = null;\n  err[kStatusCode$2] = 1007;\n  this[kCallback](err);\n}\n\nvar validationExports = {};\nvar validation = {\n  get exports(){ return validationExports; },\n  set exports(v){ validationExports = v; },\n};\n\nconst { isUtf8 } = require$$0$b;\n\n//\n// Allowed token characters:\n//\n// '!', '#', '$', '%', '&', ''', '*', '+', '-',\n// '.', 0-9, A-Z, '^', '_', '`', a-z, '|', '~'\n//\n// tokenChars[32] === 0 // ' '\n// tokenChars[33] === 1 // '!'\n// tokenChars[34] === 0 // '\"'\n// ...\n//\n// prettier-ignore\nconst tokenChars$2 = [\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0 - 15\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 16 - 31\n  0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, // 32 - 47\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, // 48 - 63\n  0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 64 - 79\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, // 80 - 95\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 96 - 111\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0 // 112 - 127\n];\n\n/**\n * Checks if a status code is allowed in a close frame.\n *\n * @param {Number} code The status code\n * @return {Boolean} `true` if the status code is valid, else `false`\n * @public\n */\nfunction isValidStatusCode$2(code) {\n  return (\n    (code >= 1000 &&\n      code <= 1014 &&\n      code !== 1004 &&\n      code !== 1005 &&\n      code !== 1006) ||\n    (code >= 3000 && code <= 4999)\n  );\n}\n\n/**\n * Checks if a given buffer contains only correct UTF-8.\n * Ported from https://www.cl.cam.ac.uk/%7Emgk25/ucs/utf8_check.c by\n * Markus Kuhn.\n *\n * @param {Buffer} buf The buffer to check\n * @return {Boolean} `true` if `buf` contains only correct UTF-8, else `false`\n * @public\n */\nfunction _isValidUTF8(buf) {\n  const len = buf.length;\n  let i = 0;\n\n  while (i < len) {\n    if ((buf[i] & 0x80) === 0) {\n      // 0xxxxxxx\n      i++;\n    } else if ((buf[i] & 0xe0) === 0xc0) {\n      // 110xxxxx 10xxxxxx\n      if (\n        i + 1 === len ||\n        (buf[i + 1] & 0xc0) !== 0x80 ||\n        (buf[i] & 0xfe) === 0xc0 // Overlong\n      ) {\n        return false;\n      }\n\n      i += 2;\n    } else if ((buf[i] & 0xf0) === 0xe0) {\n      // 1110xxxx 10xxxxxx 10xxxxxx\n      if (\n        i + 2 >= len ||\n        (buf[i + 1] & 0xc0) !== 0x80 ||\n        (buf[i + 2] & 0xc0) !== 0x80 ||\n        (buf[i] === 0xe0 && (buf[i + 1] & 0xe0) === 0x80) || // Overlong\n        (buf[i] === 0xed && (buf[i + 1] & 0xe0) === 0xa0) // Surrogate (U+D800 - U+DFFF)\n      ) {\n        return false;\n      }\n\n      i += 3;\n    } else if ((buf[i] & 0xf8) === 0xf0) {\n      // 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n      if (\n        i + 3 >= len ||\n        (buf[i + 1] & 0xc0) !== 0x80 ||\n        (buf[i + 2] & 0xc0) !== 0x80 ||\n        (buf[i + 3] & 0xc0) !== 0x80 ||\n        (buf[i] === 0xf0 && (buf[i + 1] & 0xf0) === 0x80) || // Overlong\n        (buf[i] === 0xf4 && buf[i + 1] > 0x8f) ||\n        buf[i] > 0xf4 // > U+10FFFF\n      ) {\n        return false;\n      }\n\n      i += 4;\n    } else {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nvalidation.exports = {\n  isValidStatusCode: isValidStatusCode$2,\n  isValidUTF8: _isValidUTF8,\n  tokenChars: tokenChars$2\n};\n\nif (isUtf8) {\n  validationExports.isValidUTF8 = function (buf) {\n    return buf.length < 24 ? _isValidUTF8(buf) : isUtf8(buf);\n  };\n} /* istanbul ignore else  */ else if (!process.env.WS_NO_UTF_8_VALIDATE) {\n  try {\n    const isValidUTF8 = require('utf-8-validate');\n\n    validationExports.isValidUTF8 = function (buf) {\n      return buf.length < 32 ? _isValidUTF8(buf) : isValidUTF8(buf);\n    };\n  } catch (e) {\n    // Continue regardless of the error.\n  }\n}\n\nconst { Writable: Writable$1 } = require$$0$7;\n\nconst PerMessageDeflate$3 = permessageDeflate;\nconst {\n  BINARY_TYPES: BINARY_TYPES$1,\n  EMPTY_BUFFER: EMPTY_BUFFER$2,\n  kStatusCode: kStatusCode$1,\n  kWebSocket: kWebSocket$2\n} = constants;\nconst { concat, toArrayBuffer, unmask } = bufferUtilExports;\nconst { isValidStatusCode: isValidStatusCode$1, isValidUTF8 } = validationExports;\n\nconst FastBuffer = Buffer[Symbol.species];\nconst GET_INFO = 0;\nconst GET_PAYLOAD_LENGTH_16 = 1;\nconst GET_PAYLOAD_LENGTH_64 = 2;\nconst GET_MASK = 3;\nconst GET_DATA = 4;\nconst INFLATING = 5;\n\n/**\n * HyBi Receiver implementation.\n *\n * @extends Writable\n */\nlet Receiver$1 = class Receiver extends Writable$1 {\n  /**\n   * Creates a Receiver instance.\n   *\n   * @param {Object} [options] Options object\n   * @param {String} [options.binaryType=nodebuffer] The type for binary data\n   * @param {Object} [options.extensions] An object containing the negotiated\n   *     extensions\n   * @param {Boolean} [options.isServer=false] Specifies whether to operate in\n   *     client or server mode\n   * @param {Number} [options.maxPayload=0] The maximum allowed message length\n   * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n   *     not to skip UTF-8 validation for text and close messages\n   */\n  constructor(options = {}) {\n    super();\n\n    this._binaryType = options.binaryType || BINARY_TYPES$1[0];\n    this._extensions = options.extensions || {};\n    this._isServer = !!options.isServer;\n    this._maxPayload = options.maxPayload | 0;\n    this._skipUTF8Validation = !!options.skipUTF8Validation;\n    this[kWebSocket$2] = undefined;\n\n    this._bufferedBytes = 0;\n    this._buffers = [];\n\n    this._compressed = false;\n    this._payloadLength = 0;\n    this._mask = undefined;\n    this._fragmented = 0;\n    this._masked = false;\n    this._fin = false;\n    this._opcode = 0;\n\n    this._totalPayloadLength = 0;\n    this._messageLength = 0;\n    this._fragments = [];\n\n    this._state = GET_INFO;\n    this._loop = false;\n  }\n\n  /**\n   * Implements `Writable.prototype._write()`.\n   *\n   * @param {Buffer} chunk The chunk of data to write\n   * @param {String} encoding The character encoding of `chunk`\n   * @param {Function} cb Callback\n   * @private\n   */\n  _write(chunk, encoding, cb) {\n    if (this._opcode === 0x08 && this._state == GET_INFO) return cb();\n\n    this._bufferedBytes += chunk.length;\n    this._buffers.push(chunk);\n    this.startLoop(cb);\n  }\n\n  /**\n   * Consumes `n` bytes from the buffered data.\n   *\n   * @param {Number} n The number of bytes to consume\n   * @return {Buffer} The consumed bytes\n   * @private\n   */\n  consume(n) {\n    this._bufferedBytes -= n;\n\n    if (n === this._buffers[0].length) return this._buffers.shift();\n\n    if (n < this._buffers[0].length) {\n      const buf = this._buffers[0];\n      this._buffers[0] = new FastBuffer(\n        buf.buffer,\n        buf.byteOffset + n,\n        buf.length - n\n      );\n\n      return new FastBuffer(buf.buffer, buf.byteOffset, n);\n    }\n\n    const dst = Buffer.allocUnsafe(n);\n\n    do {\n      const buf = this._buffers[0];\n      const offset = dst.length - n;\n\n      if (n >= buf.length) {\n        dst.set(this._buffers.shift(), offset);\n      } else {\n        dst.set(new Uint8Array(buf.buffer, buf.byteOffset, n), offset);\n        this._buffers[0] = new FastBuffer(\n          buf.buffer,\n          buf.byteOffset + n,\n          buf.length - n\n        );\n      }\n\n      n -= buf.length;\n    } while (n > 0);\n\n    return dst;\n  }\n\n  /**\n   * Starts the parsing loop.\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  startLoop(cb) {\n    let err;\n    this._loop = true;\n\n    do {\n      switch (this._state) {\n        case GET_INFO:\n          err = this.getInfo();\n          break;\n        case GET_PAYLOAD_LENGTH_16:\n          err = this.getPayloadLength16();\n          break;\n        case GET_PAYLOAD_LENGTH_64:\n          err = this.getPayloadLength64();\n          break;\n        case GET_MASK:\n          this.getMask();\n          break;\n        case GET_DATA:\n          err = this.getData(cb);\n          break;\n        default:\n          // `INFLATING`\n          this._loop = false;\n          return;\n      }\n    } while (this._loop);\n\n    cb(err);\n  }\n\n  /**\n   * Reads the first two bytes of a frame.\n   *\n   * @return {(RangeError|undefined)} A possible error\n   * @private\n   */\n  getInfo() {\n    if (this._bufferedBytes < 2) {\n      this._loop = false;\n      return;\n    }\n\n    const buf = this.consume(2);\n\n    if ((buf[0] & 0x30) !== 0x00) {\n      this._loop = false;\n      return error(\n        RangeError,\n        'RSV2 and RSV3 must be clear',\n        true,\n        1002,\n        'WS_ERR_UNEXPECTED_RSV_2_3'\n      );\n    }\n\n    const compressed = (buf[0] & 0x40) === 0x40;\n\n    if (compressed && !this._extensions[PerMessageDeflate$3.extensionName]) {\n      this._loop = false;\n      return error(\n        RangeError,\n        'RSV1 must be clear',\n        true,\n        1002,\n        'WS_ERR_UNEXPECTED_RSV_1'\n      );\n    }\n\n    this._fin = (buf[0] & 0x80) === 0x80;\n    this._opcode = buf[0] & 0x0f;\n    this._payloadLength = buf[1] & 0x7f;\n\n    if (this._opcode === 0x00) {\n      if (compressed) {\n        this._loop = false;\n        return error(\n          RangeError,\n          'RSV1 must be clear',\n          true,\n          1002,\n          'WS_ERR_UNEXPECTED_RSV_1'\n        );\n      }\n\n      if (!this._fragmented) {\n        this._loop = false;\n        return error(\n          RangeError,\n          'invalid opcode 0',\n          true,\n          1002,\n          'WS_ERR_INVALID_OPCODE'\n        );\n      }\n\n      this._opcode = this._fragmented;\n    } else if (this._opcode === 0x01 || this._opcode === 0x02) {\n      if (this._fragmented) {\n        this._loop = false;\n        return error(\n          RangeError,\n          `invalid opcode ${this._opcode}`,\n          true,\n          1002,\n          'WS_ERR_INVALID_OPCODE'\n        );\n      }\n\n      this._compressed = compressed;\n    } else if (this._opcode > 0x07 && this._opcode < 0x0b) {\n      if (!this._fin) {\n        this._loop = false;\n        return error(\n          RangeError,\n          'FIN must be set',\n          true,\n          1002,\n          'WS_ERR_EXPECTED_FIN'\n        );\n      }\n\n      if (compressed) {\n        this._loop = false;\n        return error(\n          RangeError,\n          'RSV1 must be clear',\n          true,\n          1002,\n          'WS_ERR_UNEXPECTED_RSV_1'\n        );\n      }\n\n      if (\n        this._payloadLength > 0x7d ||\n        (this._opcode === 0x08 && this._payloadLength === 1)\n      ) {\n        this._loop = false;\n        return error(\n          RangeError,\n          `invalid payload length ${this._payloadLength}`,\n          true,\n          1002,\n          'WS_ERR_INVALID_CONTROL_PAYLOAD_LENGTH'\n        );\n      }\n    } else {\n      this._loop = false;\n      return error(\n        RangeError,\n        `invalid opcode ${this._opcode}`,\n        true,\n        1002,\n        'WS_ERR_INVALID_OPCODE'\n      );\n    }\n\n    if (!this._fin && !this._fragmented) this._fragmented = this._opcode;\n    this._masked = (buf[1] & 0x80) === 0x80;\n\n    if (this._isServer) {\n      if (!this._masked) {\n        this._loop = false;\n        return error(\n          RangeError,\n          'MASK must be set',\n          true,\n          1002,\n          'WS_ERR_EXPECTED_MASK'\n        );\n      }\n    } else if (this._masked) {\n      this._loop = false;\n      return error(\n        RangeError,\n        'MASK must be clear',\n        true,\n        1002,\n        'WS_ERR_UNEXPECTED_MASK'\n      );\n    }\n\n    if (this._payloadLength === 126) this._state = GET_PAYLOAD_LENGTH_16;\n    else if (this._payloadLength === 127) this._state = GET_PAYLOAD_LENGTH_64;\n    else return this.haveLength();\n  }\n\n  /**\n   * Gets extended payload length (7+16).\n   *\n   * @return {(RangeError|undefined)} A possible error\n   * @private\n   */\n  getPayloadLength16() {\n    if (this._bufferedBytes < 2) {\n      this._loop = false;\n      return;\n    }\n\n    this._payloadLength = this.consume(2).readUInt16BE(0);\n    return this.haveLength();\n  }\n\n  /**\n   * Gets extended payload length (7+64).\n   *\n   * @return {(RangeError|undefined)} A possible error\n   * @private\n   */\n  getPayloadLength64() {\n    if (this._bufferedBytes < 8) {\n      this._loop = false;\n      return;\n    }\n\n    const buf = this.consume(8);\n    const num = buf.readUInt32BE(0);\n\n    //\n    // The maximum safe integer in JavaScript is 2^53 - 1. An error is returned\n    // if payload length is greater than this number.\n    //\n    if (num > Math.pow(2, 53 - 32) - 1) {\n      this._loop = false;\n      return error(\n        RangeError,\n        'Unsupported WebSocket frame: payload length > 2^53 - 1',\n        false,\n        1009,\n        'WS_ERR_UNSUPPORTED_DATA_PAYLOAD_LENGTH'\n      );\n    }\n\n    this._payloadLength = num * Math.pow(2, 32) + buf.readUInt32BE(4);\n    return this.haveLength();\n  }\n\n  /**\n   * Payload length has been read.\n   *\n   * @return {(RangeError|undefined)} A possible error\n   * @private\n   */\n  haveLength() {\n    if (this._payloadLength && this._opcode < 0x08) {\n      this._totalPayloadLength += this._payloadLength;\n      if (this._totalPayloadLength > this._maxPayload && this._maxPayload > 0) {\n        this._loop = false;\n        return error(\n          RangeError,\n          'Max payload size exceeded',\n          false,\n          1009,\n          'WS_ERR_UNSUPPORTED_MESSAGE_LENGTH'\n        );\n      }\n    }\n\n    if (this._masked) this._state = GET_MASK;\n    else this._state = GET_DATA;\n  }\n\n  /**\n   * Reads mask bytes.\n   *\n   * @private\n   */\n  getMask() {\n    if (this._bufferedBytes < 4) {\n      this._loop = false;\n      return;\n    }\n\n    this._mask = this.consume(4);\n    this._state = GET_DATA;\n  }\n\n  /**\n   * Reads data bytes.\n   *\n   * @param {Function} cb Callback\n   * @return {(Error|RangeError|undefined)} A possible error\n   * @private\n   */\n  getData(cb) {\n    let data = EMPTY_BUFFER$2;\n\n    if (this._payloadLength) {\n      if (this._bufferedBytes < this._payloadLength) {\n        this._loop = false;\n        return;\n      }\n\n      data = this.consume(this._payloadLength);\n\n      if (\n        this._masked &&\n        (this._mask[0] | this._mask[1] | this._mask[2] | this._mask[3]) !== 0\n      ) {\n        unmask(data, this._mask);\n      }\n    }\n\n    if (this._opcode > 0x07) return this.controlMessage(data);\n\n    if (this._compressed) {\n      this._state = INFLATING;\n      this.decompress(data, cb);\n      return;\n    }\n\n    if (data.length) {\n      //\n      // This message is not compressed so its length is the sum of the payload\n      // length of all fragments.\n      //\n      this._messageLength = this._totalPayloadLength;\n      this._fragments.push(data);\n    }\n\n    return this.dataMessage();\n  }\n\n  /**\n   * Decompresses data.\n   *\n   * @param {Buffer} data Compressed data\n   * @param {Function} cb Callback\n   * @private\n   */\n  decompress(data, cb) {\n    const perMessageDeflate = this._extensions[PerMessageDeflate$3.extensionName];\n\n    perMessageDeflate.decompress(data, this._fin, (err, buf) => {\n      if (err) return cb(err);\n\n      if (buf.length) {\n        this._messageLength += buf.length;\n        if (this._messageLength > this._maxPayload && this._maxPayload > 0) {\n          return cb(\n            error(\n              RangeError,\n              'Max payload size exceeded',\n              false,\n              1009,\n              'WS_ERR_UNSUPPORTED_MESSAGE_LENGTH'\n            )\n          );\n        }\n\n        this._fragments.push(buf);\n      }\n\n      const er = this.dataMessage();\n      if (er) return cb(er);\n\n      this.startLoop(cb);\n    });\n  }\n\n  /**\n   * Handles a data message.\n   *\n   * @return {(Error|undefined)} A possible error\n   * @private\n   */\n  dataMessage() {\n    if (this._fin) {\n      const messageLength = this._messageLength;\n      const fragments = this._fragments;\n\n      this._totalPayloadLength = 0;\n      this._messageLength = 0;\n      this._fragmented = 0;\n      this._fragments = [];\n\n      if (this._opcode === 2) {\n        let data;\n\n        if (this._binaryType === 'nodebuffer') {\n          data = concat(fragments, messageLength);\n        } else if (this._binaryType === 'arraybuffer') {\n          data = toArrayBuffer(concat(fragments, messageLength));\n        } else {\n          data = fragments;\n        }\n\n        this.emit('message', data, true);\n      } else {\n        const buf = concat(fragments, messageLength);\n\n        if (!this._skipUTF8Validation && !isValidUTF8(buf)) {\n          this._loop = false;\n          return error(\n            Error,\n            'invalid UTF-8 sequence',\n            true,\n            1007,\n            'WS_ERR_INVALID_UTF8'\n          );\n        }\n\n        this.emit('message', buf, false);\n      }\n    }\n\n    this._state = GET_INFO;\n  }\n\n  /**\n   * Handles a control message.\n   *\n   * @param {Buffer} data Data to handle\n   * @return {(Error|RangeError|undefined)} A possible error\n   * @private\n   */\n  controlMessage(data) {\n    if (this._opcode === 0x08) {\n      this._loop = false;\n\n      if (data.length === 0) {\n        this.emit('conclude', 1005, EMPTY_BUFFER$2);\n        this.end();\n      } else {\n        const code = data.readUInt16BE(0);\n\n        if (!isValidStatusCode$1(code)) {\n          return error(\n            RangeError,\n            `invalid status code ${code}`,\n            true,\n            1002,\n            'WS_ERR_INVALID_CLOSE_CODE'\n          );\n        }\n\n        const buf = new FastBuffer(\n          data.buffer,\n          data.byteOffset + 2,\n          data.length - 2\n        );\n\n        if (!this._skipUTF8Validation && !isValidUTF8(buf)) {\n          return error(\n            Error,\n            'invalid UTF-8 sequence',\n            true,\n            1007,\n            'WS_ERR_INVALID_UTF8'\n          );\n        }\n\n        this.emit('conclude', code, buf);\n        this.end();\n      }\n    } else if (this._opcode === 0x09) {\n      this.emit('ping', data);\n    } else {\n      this.emit('pong', data);\n    }\n\n    this._state = GET_INFO;\n  }\n};\n\nvar receiver = Receiver$1;\n\n/**\n * Builds an error object.\n *\n * @param {function(new:Error|RangeError)} ErrorCtor The error constructor\n * @param {String} message The error message\n * @param {Boolean} prefix Specifies whether or not to add a default prefix to\n *     `message`\n * @param {Number} statusCode The status code\n * @param {String} errorCode The exposed error code\n * @return {(Error|RangeError)} The error\n * @private\n */\nfunction error(ErrorCtor, message, prefix, statusCode, errorCode) {\n  const err = new ErrorCtor(\n    prefix ? `Invalid WebSocket frame: ${message}` : message\n  );\n\n  Error.captureStackTrace(err, error);\n  err.code = errorCode;\n  err[kStatusCode$1] = statusCode;\n  return err;\n}\n\n/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^net|tls$\" }] */\nconst { randomFillSync } = require$$5$1;\n\nconst PerMessageDeflate$2 = permessageDeflate;\nconst { EMPTY_BUFFER: EMPTY_BUFFER$1 } = constants;\nconst { isValidStatusCode } = validationExports;\nconst { mask: applyMask, toBuffer: toBuffer$1 } = bufferUtilExports;\n\nconst kByteLength = Symbol('kByteLength');\nconst maskBuffer = Buffer.alloc(4);\n\n/**\n * HyBi Sender implementation.\n */\nlet Sender$1 = class Sender {\n  /**\n   * Creates a Sender instance.\n   *\n   * @param {(net.Socket|tls.Socket)} socket The connection socket\n   * @param {Object} [extensions] An object containing the negotiated extensions\n   * @param {Function} [generateMask] The function used to generate the masking\n   *     key\n   */\n  constructor(socket, extensions, generateMask) {\n    this._extensions = extensions || {};\n\n    if (generateMask) {\n      this._generateMask = generateMask;\n      this._maskBuffer = Buffer.alloc(4);\n    }\n\n    this._socket = socket;\n\n    this._firstFragment = true;\n    this._compress = false;\n\n    this._bufferedBytes = 0;\n    this._deflating = false;\n    this._queue = [];\n  }\n\n  /**\n   * Frames a piece of data according to the HyBi WebSocket protocol.\n   *\n   * @param {(Buffer|String)} data The data to frame\n   * @param {Object} options Options object\n   * @param {Boolean} [options.fin=false] Specifies whether or not to set the\n   *     FIN bit\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Buffer} [options.maskBuffer] The buffer used to store the masking\n   *     key\n   * @param {Number} options.opcode The opcode\n   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be\n   *     modified\n   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the\n   *     RSV1 bit\n   * @return {(Buffer|String)[]} The framed data\n   * @public\n   */\n  static frame(data, options) {\n    let mask;\n    let merge = false;\n    let offset = 2;\n    let skipMasking = false;\n\n    if (options.mask) {\n      mask = options.maskBuffer || maskBuffer;\n\n      if (options.generateMask) {\n        options.generateMask(mask);\n      } else {\n        randomFillSync(mask, 0, 4);\n      }\n\n      skipMasking = (mask[0] | mask[1] | mask[2] | mask[3]) === 0;\n      offset = 6;\n    }\n\n    let dataLength;\n\n    if (typeof data === 'string') {\n      if (\n        (!options.mask || skipMasking) &&\n        options[kByteLength] !== undefined\n      ) {\n        dataLength = options[kByteLength];\n      } else {\n        data = Buffer.from(data);\n        dataLength = data.length;\n      }\n    } else {\n      dataLength = data.length;\n      merge = options.mask && options.readOnly && !skipMasking;\n    }\n\n    let payloadLength = dataLength;\n\n    if (dataLength >= 65536) {\n      offset += 8;\n      payloadLength = 127;\n    } else if (dataLength > 125) {\n      offset += 2;\n      payloadLength = 126;\n    }\n\n    const target = Buffer.allocUnsafe(merge ? dataLength + offset : offset);\n\n    target[0] = options.fin ? options.opcode | 0x80 : options.opcode;\n    if (options.rsv1) target[0] |= 0x40;\n\n    target[1] = payloadLength;\n\n    if (payloadLength === 126) {\n      target.writeUInt16BE(dataLength, 2);\n    } else if (payloadLength === 127) {\n      target[2] = target[3] = 0;\n      target.writeUIntBE(dataLength, 4, 6);\n    }\n\n    if (!options.mask) return [target, data];\n\n    target[1] |= 0x80;\n    target[offset - 4] = mask[0];\n    target[offset - 3] = mask[1];\n    target[offset - 2] = mask[2];\n    target[offset - 1] = mask[3];\n\n    if (skipMasking) return [target, data];\n\n    if (merge) {\n      applyMask(data, mask, target, offset, dataLength);\n      return [target];\n    }\n\n    applyMask(data, mask, data, 0, dataLength);\n    return [target, data];\n  }\n\n  /**\n   * Sends a close message to the other peer.\n   *\n   * @param {Number} [code] The status code component of the body\n   * @param {(String|Buffer)} [data] The message component of the body\n   * @param {Boolean} [mask=false] Specifies whether or not to mask the message\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  close(code, data, mask, cb) {\n    let buf;\n\n    if (code === undefined) {\n      buf = EMPTY_BUFFER$1;\n    } else if (typeof code !== 'number' || !isValidStatusCode(code)) {\n      throw new TypeError('First argument must be a valid error code number');\n    } else if (data === undefined || !data.length) {\n      buf = Buffer.allocUnsafe(2);\n      buf.writeUInt16BE(code, 0);\n    } else {\n      const length = Buffer.byteLength(data);\n\n      if (length > 123) {\n        throw new RangeError('The message must not be greater than 123 bytes');\n      }\n\n      buf = Buffer.allocUnsafe(2 + length);\n      buf.writeUInt16BE(code, 0);\n\n      if (typeof data === 'string') {\n        buf.write(data, 2);\n      } else {\n        buf.set(data, 2);\n      }\n    }\n\n    const options = {\n      [kByteLength]: buf.length,\n      fin: true,\n      generateMask: this._generateMask,\n      mask,\n      maskBuffer: this._maskBuffer,\n      opcode: 0x08,\n      readOnly: false,\n      rsv1: false\n    };\n\n    if (this._deflating) {\n      this.enqueue([this.dispatch, buf, false, options, cb]);\n    } else {\n      this.sendFrame(Sender$1.frame(buf, options), cb);\n    }\n  }\n\n  /**\n   * Sends a ping message to the other peer.\n   *\n   * @param {*} data The message to send\n   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  ping(data, mask, cb) {\n    let byteLength;\n    let readOnly;\n\n    if (typeof data === 'string') {\n      byteLength = Buffer.byteLength(data);\n      readOnly = false;\n    } else {\n      data = toBuffer$1(data);\n      byteLength = data.length;\n      readOnly = toBuffer$1.readOnly;\n    }\n\n    if (byteLength > 125) {\n      throw new RangeError('The data size must not be greater than 125 bytes');\n    }\n\n    const options = {\n      [kByteLength]: byteLength,\n      fin: true,\n      generateMask: this._generateMask,\n      mask,\n      maskBuffer: this._maskBuffer,\n      opcode: 0x09,\n      readOnly,\n      rsv1: false\n    };\n\n    if (this._deflating) {\n      this.enqueue([this.dispatch, data, false, options, cb]);\n    } else {\n      this.sendFrame(Sender$1.frame(data, options), cb);\n    }\n  }\n\n  /**\n   * Sends a pong message to the other peer.\n   *\n   * @param {*} data The message to send\n   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  pong(data, mask, cb) {\n    let byteLength;\n    let readOnly;\n\n    if (typeof data === 'string') {\n      byteLength = Buffer.byteLength(data);\n      readOnly = false;\n    } else {\n      data = toBuffer$1(data);\n      byteLength = data.length;\n      readOnly = toBuffer$1.readOnly;\n    }\n\n    if (byteLength > 125) {\n      throw new RangeError('The data size must not be greater than 125 bytes');\n    }\n\n    const options = {\n      [kByteLength]: byteLength,\n      fin: true,\n      generateMask: this._generateMask,\n      mask,\n      maskBuffer: this._maskBuffer,\n      opcode: 0x0a,\n      readOnly,\n      rsv1: false\n    };\n\n    if (this._deflating) {\n      this.enqueue([this.dispatch, data, false, options, cb]);\n    } else {\n      this.sendFrame(Sender$1.frame(data, options), cb);\n    }\n  }\n\n  /**\n   * Sends a data message to the other peer.\n   *\n   * @param {*} data The message to send\n   * @param {Object} options Options object\n   * @param {Boolean} [options.binary=false] Specifies whether `data` is binary\n   *     or text\n   * @param {Boolean} [options.compress=false] Specifies whether or not to\n   *     compress `data`\n   * @param {Boolean} [options.fin=false] Specifies whether the fragment is the\n   *     last one\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  send(data, options, cb) {\n    const perMessageDeflate = this._extensions[PerMessageDeflate$2.extensionName];\n    let opcode = options.binary ? 2 : 1;\n    let rsv1 = options.compress;\n\n    let byteLength;\n    let readOnly;\n\n    if (typeof data === 'string') {\n      byteLength = Buffer.byteLength(data);\n      readOnly = false;\n    } else {\n      data = toBuffer$1(data);\n      byteLength = data.length;\n      readOnly = toBuffer$1.readOnly;\n    }\n\n    if (this._firstFragment) {\n      this._firstFragment = false;\n      if (\n        rsv1 &&\n        perMessageDeflate &&\n        perMessageDeflate.params[\n          perMessageDeflate._isServer\n            ? 'server_no_context_takeover'\n            : 'client_no_context_takeover'\n        ]\n      ) {\n        rsv1 = byteLength >= perMessageDeflate._threshold;\n      }\n      this._compress = rsv1;\n    } else {\n      rsv1 = false;\n      opcode = 0;\n    }\n\n    if (options.fin) this._firstFragment = true;\n\n    if (perMessageDeflate) {\n      const opts = {\n        [kByteLength]: byteLength,\n        fin: options.fin,\n        generateMask: this._generateMask,\n        mask: options.mask,\n        maskBuffer: this._maskBuffer,\n        opcode,\n        readOnly,\n        rsv1\n      };\n\n      if (this._deflating) {\n        this.enqueue([this.dispatch, data, this._compress, opts, cb]);\n      } else {\n        this.dispatch(data, this._compress, opts, cb);\n      }\n    } else {\n      this.sendFrame(\n        Sender$1.frame(data, {\n          [kByteLength]: byteLength,\n          fin: options.fin,\n          generateMask: this._generateMask,\n          mask: options.mask,\n          maskBuffer: this._maskBuffer,\n          opcode,\n          readOnly,\n          rsv1: false\n        }),\n        cb\n      );\n    }\n  }\n\n  /**\n   * Dispatches a message.\n   *\n   * @param {(Buffer|String)} data The message to send\n   * @param {Boolean} [compress=false] Specifies whether or not to compress\n   *     `data`\n   * @param {Object} options Options object\n   * @param {Boolean} [options.fin=false] Specifies whether or not to set the\n   *     FIN bit\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Buffer} [options.maskBuffer] The buffer used to store the masking\n   *     key\n   * @param {Number} options.opcode The opcode\n   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be\n   *     modified\n   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the\n   *     RSV1 bit\n   * @param {Function} [cb] Callback\n   * @private\n   */\n  dispatch(data, compress, options, cb) {\n    if (!compress) {\n      this.sendFrame(Sender$1.frame(data, options), cb);\n      return;\n    }\n\n    const perMessageDeflate = this._extensions[PerMessageDeflate$2.extensionName];\n\n    this._bufferedBytes += options[kByteLength];\n    this._deflating = true;\n    perMessageDeflate.compress(data, options.fin, (_, buf) => {\n      if (this._socket.destroyed) {\n        const err = new Error(\n          'The socket was closed while data was being compressed'\n        );\n\n        if (typeof cb === 'function') cb(err);\n\n        for (let i = 0; i < this._queue.length; i++) {\n          const params = this._queue[i];\n          const callback = params[params.length - 1];\n\n          if (typeof callback === 'function') callback(err);\n        }\n\n        return;\n      }\n\n      this._bufferedBytes -= options[kByteLength];\n      this._deflating = false;\n      options.readOnly = false;\n      this.sendFrame(Sender$1.frame(buf, options), cb);\n      this.dequeue();\n    });\n  }\n\n  /**\n   * Executes queued send operations.\n   *\n   * @private\n   */\n  dequeue() {\n    while (!this._deflating && this._queue.length) {\n      const params = this._queue.shift();\n\n      this._bufferedBytes -= params[3][kByteLength];\n      Reflect.apply(params[0], this, params.slice(1));\n    }\n  }\n\n  /**\n   * Enqueues a send operation.\n   *\n   * @param {Array} params Send operation parameters.\n   * @private\n   */\n  enqueue(params) {\n    this._bufferedBytes += params[3][kByteLength];\n    this._queue.push(params);\n  }\n\n  /**\n   * Sends a frame.\n   *\n   * @param {Buffer[]} list The frame to send\n   * @param {Function} [cb] Callback\n   * @private\n   */\n  sendFrame(list, cb) {\n    if (list.length === 2) {\n      this._socket.cork();\n      this._socket.write(list[0]);\n      this._socket.write(list[1], cb);\n      this._socket.uncork();\n    } else {\n      this._socket.write(list[0], cb);\n    }\n  }\n};\n\nvar sender = Sender$1;\n\nconst { kForOnEventAttribute: kForOnEventAttribute$1, kListener: kListener$1 } = constants;\n\nconst kCode = Symbol('kCode');\nconst kData = Symbol('kData');\nconst kError = Symbol('kError');\nconst kMessage = Symbol('kMessage');\nconst kReason = Symbol('kReason');\nconst kTarget = Symbol('kTarget');\nconst kType = Symbol('kType');\nconst kWasClean = Symbol('kWasClean');\n\n/**\n * Class representing an event.\n */\nclass Event {\n  /**\n   * Create a new `Event`.\n   *\n   * @param {String} type The name of the event\n   * @throws {TypeError} If the `type` argument is not specified\n   */\n  constructor(type) {\n    this[kTarget] = null;\n    this[kType] = type;\n  }\n\n  /**\n   * @type {*}\n   */\n  get target() {\n    return this[kTarget];\n  }\n\n  /**\n   * @type {String}\n   */\n  get type() {\n    return this[kType];\n  }\n}\n\nObject.defineProperty(Event.prototype, 'target', { enumerable: true });\nObject.defineProperty(Event.prototype, 'type', { enumerable: true });\n\n/**\n * Class representing a close event.\n *\n * @extends Event\n */\nclass CloseEvent extends Event {\n  /**\n   * Create a new `CloseEvent`.\n   *\n   * @param {String} type The name of the event\n   * @param {Object} [options] A dictionary object that allows for setting\n   *     attributes via object members of the same name\n   * @param {Number} [options.code=0] The status code explaining why the\n   *     connection was closed\n   * @param {String} [options.reason=''] A human-readable string explaining why\n   *     the connection was closed\n   * @param {Boolean} [options.wasClean=false] Indicates whether or not the\n   *     connection was cleanly closed\n   */\n  constructor(type, options = {}) {\n    super(type);\n\n    this[kCode] = options.code === undefined ? 0 : options.code;\n    this[kReason] = options.reason === undefined ? '' : options.reason;\n    this[kWasClean] = options.wasClean === undefined ? false : options.wasClean;\n  }\n\n  /**\n   * @type {Number}\n   */\n  get code() {\n    return this[kCode];\n  }\n\n  /**\n   * @type {String}\n   */\n  get reason() {\n    return this[kReason];\n  }\n\n  /**\n   * @type {Boolean}\n   */\n  get wasClean() {\n    return this[kWasClean];\n  }\n}\n\nObject.defineProperty(CloseEvent.prototype, 'code', { enumerable: true });\nObject.defineProperty(CloseEvent.prototype, 'reason', { enumerable: true });\nObject.defineProperty(CloseEvent.prototype, 'wasClean', { enumerable: true });\n\n/**\n * Class representing an error event.\n *\n * @extends Event\n */\nclass ErrorEvent extends Event {\n  /**\n   * Create a new `ErrorEvent`.\n   *\n   * @param {String} type The name of the event\n   * @param {Object} [options] A dictionary object that allows for setting\n   *     attributes via object members of the same name\n   * @param {*} [options.error=null] The error that generated this event\n   * @param {String} [options.message=''] The error message\n   */\n  constructor(type, options = {}) {\n    super(type);\n\n    this[kError] = options.error === undefined ? null : options.error;\n    this[kMessage] = options.message === undefined ? '' : options.message;\n  }\n\n  /**\n   * @type {*}\n   */\n  get error() {\n    return this[kError];\n  }\n\n  /**\n   * @type {String}\n   */\n  get message() {\n    return this[kMessage];\n  }\n}\n\nObject.defineProperty(ErrorEvent.prototype, 'error', { enumerable: true });\nObject.defineProperty(ErrorEvent.prototype, 'message', { enumerable: true });\n\n/**\n * Class representing a message event.\n *\n * @extends Event\n */\nclass MessageEvent extends Event {\n  /**\n   * Create a new `MessageEvent`.\n   *\n   * @param {String} type The name of the event\n   * @param {Object} [options] A dictionary object that allows for setting\n   *     attributes via object members of the same name\n   * @param {*} [options.data=null] The message content\n   */\n  constructor(type, options = {}) {\n    super(type);\n\n    this[kData] = options.data === undefined ? null : options.data;\n  }\n\n  /**\n   * @type {*}\n   */\n  get data() {\n    return this[kData];\n  }\n}\n\nObject.defineProperty(MessageEvent.prototype, 'data', { enumerable: true });\n\n/**\n * This provides methods for emulating the `EventTarget` interface. It's not\n * meant to be used directly.\n *\n * @mixin\n */\nconst EventTarget = {\n  /**\n   * Register an event listener.\n   *\n   * @param {String} type A string representing the event type to listen for\n   * @param {(Function|Object)} handler The listener to add\n   * @param {Object} [options] An options object specifies characteristics about\n   *     the event listener\n   * @param {Boolean} [options.once=false] A `Boolean` indicating that the\n   *     listener should be invoked at most once after being added. If `true`,\n   *     the listener would be automatically removed when invoked.\n   * @public\n   */\n  addEventListener(type, handler, options = {}) {\n    for (const listener of this.listeners(type)) {\n      if (\n        !options[kForOnEventAttribute$1] &&\n        listener[kListener$1] === handler &&\n        !listener[kForOnEventAttribute$1]\n      ) {\n        return;\n      }\n    }\n\n    let wrapper;\n\n    if (type === 'message') {\n      wrapper = function onMessage(data, isBinary) {\n        const event = new MessageEvent('message', {\n          data: isBinary ? data : data.toString()\n        });\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else if (type === 'close') {\n      wrapper = function onClose(code, message) {\n        const event = new CloseEvent('close', {\n          code,\n          reason: message.toString(),\n          wasClean: this._closeFrameReceived && this._closeFrameSent\n        });\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else if (type === 'error') {\n      wrapper = function onError(error) {\n        const event = new ErrorEvent('error', {\n          error,\n          message: error.message\n        });\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else if (type === 'open') {\n      wrapper = function onOpen() {\n        const event = new Event('open');\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else {\n      return;\n    }\n\n    wrapper[kForOnEventAttribute$1] = !!options[kForOnEventAttribute$1];\n    wrapper[kListener$1] = handler;\n\n    if (options.once) {\n      this.once(type, wrapper);\n    } else {\n      this.on(type, wrapper);\n    }\n  },\n\n  /**\n   * Remove an event listener.\n   *\n   * @param {String} type A string representing the event type to remove\n   * @param {(Function|Object)} handler The listener to remove\n   * @public\n   */\n  removeEventListener(type, handler) {\n    for (const listener of this.listeners(type)) {\n      if (listener[kListener$1] === handler && !listener[kForOnEventAttribute$1]) {\n        this.removeListener(type, listener);\n        break;\n      }\n    }\n  }\n};\n\nvar eventTarget = {\n  CloseEvent,\n  ErrorEvent,\n  Event,\n  EventTarget,\n  MessageEvent\n};\n\n/**\n * Call an event listener\n *\n * @param {(Function|Object)} listener The listener to call\n * @param {*} thisArg The value to use as `this`` when calling the listener\n * @param {Event} event The event to pass to the listener\n * @private\n */\nfunction callListener(listener, thisArg, event) {\n  if (typeof listener === 'object' && listener.handleEvent) {\n    listener.handleEvent.call(listener, event);\n  } else {\n    listener.call(thisArg, event);\n  }\n}\n\nconst { tokenChars: tokenChars$1 } = validationExports;\n\n/**\n * Adds an offer to the map of extension offers or a parameter to the map of\n * parameters.\n *\n * @param {Object} dest The map of extension offers or parameters\n * @param {String} name The extension or parameter name\n * @param {(Object|Boolean|String)} elem The extension parameters or the\n *     parameter value\n * @private\n */\nfunction push(dest, name, elem) {\n  if (dest[name] === undefined) dest[name] = [elem];\n  else dest[name].push(elem);\n}\n\n/**\n * Parses the `Sec-WebSocket-Extensions` header into an object.\n *\n * @param {String} header The field value of the header\n * @return {Object} The parsed object\n * @public\n */\nfunction parse$2(header) {\n  const offers = Object.create(null);\n  let params = Object.create(null);\n  let mustUnescape = false;\n  let isEscaping = false;\n  let inQuotes = false;\n  let extensionName;\n  let paramName;\n  let start = -1;\n  let code = -1;\n  let end = -1;\n  let i = 0;\n\n  for (; i < header.length; i++) {\n    code = header.charCodeAt(i);\n\n    if (extensionName === undefined) {\n      if (end === -1 && tokenChars$1[code] === 1) {\n        if (start === -1) start = i;\n      } else if (\n        i !== 0 &&\n        (code === 0x20 /* ' ' */ || code === 0x09) /* '\\t' */\n      ) {\n        if (end === -1 && start !== -1) end = i;\n      } else if (code === 0x3b /* ';' */ || code === 0x2c /* ',' */) {\n        if (start === -1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n\n        if (end === -1) end = i;\n        const name = header.slice(start, end);\n        if (code === 0x2c) {\n          push(offers, name, params);\n          params = Object.create(null);\n        } else {\n          extensionName = name;\n        }\n\n        start = end = -1;\n      } else {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n    } else if (paramName === undefined) {\n      if (end === -1 && tokenChars$1[code] === 1) {\n        if (start === -1) start = i;\n      } else if (code === 0x20 || code === 0x09) {\n        if (end === -1 && start !== -1) end = i;\n      } else if (code === 0x3b || code === 0x2c) {\n        if (start === -1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n\n        if (end === -1) end = i;\n        push(params, header.slice(start, end), true);\n        if (code === 0x2c) {\n          push(offers, extensionName, params);\n          params = Object.create(null);\n          extensionName = undefined;\n        }\n\n        start = end = -1;\n      } else if (code === 0x3d /* '=' */ && start !== -1 && end === -1) {\n        paramName = header.slice(start, i);\n        start = end = -1;\n      } else {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n    } else {\n      //\n      // The value of a quoted-string after unescaping must conform to the\n      // token ABNF, so only token characters are valid.\n      // Ref: https://tools.ietf.org/html/rfc6455#section-9.1\n      //\n      if (isEscaping) {\n        if (tokenChars$1[code] !== 1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n        if (start === -1) start = i;\n        else if (!mustUnescape) mustUnescape = true;\n        isEscaping = false;\n      } else if (inQuotes) {\n        if (tokenChars$1[code] === 1) {\n          if (start === -1) start = i;\n        } else if (code === 0x22 /* '\"' */ && start !== -1) {\n          inQuotes = false;\n          end = i;\n        } else if (code === 0x5c /* '\\' */) {\n          isEscaping = true;\n        } else {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n      } else if (code === 0x22 && header.charCodeAt(i - 1) === 0x3d) {\n        inQuotes = true;\n      } else if (end === -1 && tokenChars$1[code] === 1) {\n        if (start === -1) start = i;\n      } else if (start !== -1 && (code === 0x20 || code === 0x09)) {\n        if (end === -1) end = i;\n      } else if (code === 0x3b || code === 0x2c) {\n        if (start === -1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n\n        if (end === -1) end = i;\n        let value = header.slice(start, end);\n        if (mustUnescape) {\n          value = value.replace(/\\\\/g, '');\n          mustUnescape = false;\n        }\n        push(params, paramName, value);\n        if (code === 0x2c) {\n          push(offers, extensionName, params);\n          params = Object.create(null);\n          extensionName = undefined;\n        }\n\n        paramName = undefined;\n        start = end = -1;\n      } else {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n    }\n  }\n\n  if (start === -1 || inQuotes || code === 0x20 || code === 0x09) {\n    throw new SyntaxError('Unexpected end of input');\n  }\n\n  if (end === -1) end = i;\n  const token = header.slice(start, end);\n  if (extensionName === undefined) {\n    push(offers, token, params);\n  } else {\n    if (paramName === undefined) {\n      push(params, token, true);\n    } else if (mustUnescape) {\n      push(params, paramName, token.replace(/\\\\/g, ''));\n    } else {\n      push(params, paramName, token);\n    }\n    push(offers, extensionName, params);\n  }\n\n  return offers;\n}\n\n/**\n * Builds the `Sec-WebSocket-Extensions` header field value.\n *\n * @param {Object} extensions The map of extensions and parameters to format\n * @return {String} A string representing the given object\n * @public\n */\nfunction format$1(extensions) {\n  return Object.keys(extensions)\n    .map((extension) => {\n      let configurations = extensions[extension];\n      if (!Array.isArray(configurations)) configurations = [configurations];\n      return configurations\n        .map((params) => {\n          return [extension]\n            .concat(\n              Object.keys(params).map((k) => {\n                let values = params[k];\n                if (!Array.isArray(values)) values = [values];\n                return values\n                  .map((v) => (v === true ? k : `${k}=${v}`))\n                  .join('; ');\n              })\n            )\n            .join('; ');\n        })\n        .join(', ');\n    })\n    .join(', ');\n}\n\nvar extension$1 = { format: format$1, parse: parse$2 };\n\n/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^Readable$\" }] */\n\nconst EventEmitter$1 = require$$0$5;\nconst https$2 = require$$1$2;\nconst http$3 = require$$1$1;\nconst net = require$$3$2;\nconst tls = require$$4;\nconst { randomBytes, createHash: createHash$1 } = require$$5$1;\nconst { URL: URL$2 } = require$$0$9;\n\nconst PerMessageDeflate$1 = permessageDeflate;\nconst Receiver = receiver;\nconst Sender = sender;\nconst {\n  BINARY_TYPES,\n  EMPTY_BUFFER,\n  GUID: GUID$1,\n  kForOnEventAttribute,\n  kListener,\n  kStatusCode,\n  kWebSocket: kWebSocket$1,\n  NOOP\n} = constants;\nconst {\n  EventTarget: { addEventListener, removeEventListener }\n} = eventTarget;\nconst { format, parse: parse$1 } = extension$1;\nconst { toBuffer } = bufferUtilExports;\n\nconst closeTimeout = 30 * 1000;\nconst kAborted = Symbol('kAborted');\nconst protocolVersions = [8, 13];\nconst readyStates = ['CONNECTING', 'OPEN', 'CLOSING', 'CLOSED'];\nconst subprotocolRegex = /^[!#$%&'*+\\-.0-9A-Z^_`|a-z~]+$/;\n\n/**\n * Class representing a WebSocket.\n *\n * @extends EventEmitter\n */\nlet WebSocket$1 = class WebSocket extends EventEmitter$1 {\n  /**\n   * Create a new `WebSocket`.\n   *\n   * @param {(String|URL)} address The URL to which to connect\n   * @param {(String|String[])} [protocols] The subprotocols\n   * @param {Object} [options] Connection options\n   */\n  constructor(address, protocols, options) {\n    super();\n\n    this._binaryType = BINARY_TYPES[0];\n    this._closeCode = 1006;\n    this._closeFrameReceived = false;\n    this._closeFrameSent = false;\n    this._closeMessage = EMPTY_BUFFER;\n    this._closeTimer = null;\n    this._extensions = {};\n    this._paused = false;\n    this._protocol = '';\n    this._readyState = WebSocket$1.CONNECTING;\n    this._receiver = null;\n    this._sender = null;\n    this._socket = null;\n\n    if (address !== null) {\n      this._bufferedAmount = 0;\n      this._isServer = false;\n      this._redirects = 0;\n\n      if (protocols === undefined) {\n        protocols = [];\n      } else if (!Array.isArray(protocols)) {\n        if (typeof protocols === 'object' && protocols !== null) {\n          options = protocols;\n          protocols = [];\n        } else {\n          protocols = [protocols];\n        }\n      }\n\n      initAsClient(this, address, protocols, options);\n    } else {\n      this._isServer = true;\n    }\n  }\n\n  /**\n   * This deviates from the WHATWG interface since ws doesn't support the\n   * required default \"blob\" type (instead we define a custom \"nodebuffer\"\n   * type).\n   *\n   * @type {String}\n   */\n  get binaryType() {\n    return this._binaryType;\n  }\n\n  set binaryType(type) {\n    if (!BINARY_TYPES.includes(type)) return;\n\n    this._binaryType = type;\n\n    //\n    // Allow to change `binaryType` on the fly.\n    //\n    if (this._receiver) this._receiver._binaryType = type;\n  }\n\n  /**\n   * @type {Number}\n   */\n  get bufferedAmount() {\n    if (!this._socket) return this._bufferedAmount;\n\n    return this._socket._writableState.length + this._sender._bufferedBytes;\n  }\n\n  /**\n   * @type {String}\n   */\n  get extensions() {\n    return Object.keys(this._extensions).join();\n  }\n\n  /**\n   * @type {Boolean}\n   */\n  get isPaused() {\n    return this._paused;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onclose() {\n    return null;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onerror() {\n    return null;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onopen() {\n    return null;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onmessage() {\n    return null;\n  }\n\n  /**\n   * @type {String}\n   */\n  get protocol() {\n    return this._protocol;\n  }\n\n  /**\n   * @type {Number}\n   */\n  get readyState() {\n    return this._readyState;\n  }\n\n  /**\n   * @type {String}\n   */\n  get url() {\n    return this._url;\n  }\n\n  /**\n   * Set up the socket and the internal resources.\n   *\n   * @param {(net.Socket|tls.Socket)} socket The network socket between the\n   *     server and client\n   * @param {Buffer} head The first packet of the upgraded stream\n   * @param {Object} options Options object\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Number} [options.maxPayload=0] The maximum allowed message size\n   * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n   *     not to skip UTF-8 validation for text and close messages\n   * @private\n   */\n  setSocket(socket, head, options) {\n    const receiver = new Receiver({\n      binaryType: this.binaryType,\n      extensions: this._extensions,\n      isServer: this._isServer,\n      maxPayload: options.maxPayload,\n      skipUTF8Validation: options.skipUTF8Validation\n    });\n\n    this._sender = new Sender(socket, this._extensions, options.generateMask);\n    this._receiver = receiver;\n    this._socket = socket;\n\n    receiver[kWebSocket$1] = this;\n    socket[kWebSocket$1] = this;\n\n    receiver.on('conclude', receiverOnConclude);\n    receiver.on('drain', receiverOnDrain);\n    receiver.on('error', receiverOnError);\n    receiver.on('message', receiverOnMessage);\n    receiver.on('ping', receiverOnPing);\n    receiver.on('pong', receiverOnPong);\n\n    socket.setTimeout(0);\n    socket.setNoDelay();\n\n    if (head.length > 0) socket.unshift(head);\n\n    socket.on('close', socketOnClose);\n    socket.on('data', socketOnData);\n    socket.on('end', socketOnEnd);\n    socket.on('error', socketOnError$1);\n\n    this._readyState = WebSocket$1.OPEN;\n    this.emit('open');\n  }\n\n  /**\n   * Emit the `'close'` event.\n   *\n   * @private\n   */\n  emitClose() {\n    if (!this._socket) {\n      this._readyState = WebSocket$1.CLOSED;\n      this.emit('close', this._closeCode, this._closeMessage);\n      return;\n    }\n\n    if (this._extensions[PerMessageDeflate$1.extensionName]) {\n      this._extensions[PerMessageDeflate$1.extensionName].cleanup();\n    }\n\n    this._receiver.removeAllListeners();\n    this._readyState = WebSocket$1.CLOSED;\n    this.emit('close', this._closeCode, this._closeMessage);\n  }\n\n  /**\n   * Start a closing handshake.\n   *\n   *          +----------+   +-----------+   +----------+\n   *     - - -|ws.close()|-->|close frame|-->|ws.close()|- - -\n   *    |     +----------+   +-----------+   +----------+     |\n   *          +----------+   +-----------+         |\n   * CLOSING  |ws.close()|<--|close frame|<--+-----+       CLOSING\n   *          +----------+   +-----------+   |\n   *    |           |                        |   +---+        |\n   *                +------------------------+-->|fin| - - - -\n   *    |         +---+                      |   +---+\n   *     - - - - -|fin|<---------------------+\n   *              +---+\n   *\n   * @param {Number} [code] Status code explaining why the connection is closing\n   * @param {(String|Buffer)} [data] The reason why the connection is\n   *     closing\n   * @public\n   */\n  close(code, data) {\n    if (this.readyState === WebSocket$1.CLOSED) return;\n    if (this.readyState === WebSocket$1.CONNECTING) {\n      const msg = 'WebSocket was closed before the connection was established';\n      abortHandshake$1(this, this._req, msg);\n      return;\n    }\n\n    if (this.readyState === WebSocket$1.CLOSING) {\n      if (\n        this._closeFrameSent &&\n        (this._closeFrameReceived || this._receiver._writableState.errorEmitted)\n      ) {\n        this._socket.end();\n      }\n\n      return;\n    }\n\n    this._readyState = WebSocket$1.CLOSING;\n    this._sender.close(code, data, !this._isServer, (err) => {\n      //\n      // This error is handled by the `'error'` listener on the socket. We only\n      // want to know if the close frame has been sent here.\n      //\n      if (err) return;\n\n      this._closeFrameSent = true;\n\n      if (\n        this._closeFrameReceived ||\n        this._receiver._writableState.errorEmitted\n      ) {\n        this._socket.end();\n      }\n    });\n\n    //\n    // Specify a timeout for the closing handshake to complete.\n    //\n    this._closeTimer = setTimeout(\n      this._socket.destroy.bind(this._socket),\n      closeTimeout\n    );\n  }\n\n  /**\n   * Pause the socket.\n   *\n   * @public\n   */\n  pause() {\n    if (\n      this.readyState === WebSocket$1.CONNECTING ||\n      this.readyState === WebSocket$1.CLOSED\n    ) {\n      return;\n    }\n\n    this._paused = true;\n    this._socket.pause();\n  }\n\n  /**\n   * Send a ping.\n   *\n   * @param {*} [data] The data to send\n   * @param {Boolean} [mask] Indicates whether or not to mask `data`\n   * @param {Function} [cb] Callback which is executed when the ping is sent\n   * @public\n   */\n  ping(data, mask, cb) {\n    if (this.readyState === WebSocket$1.CONNECTING) {\n      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');\n    }\n\n    if (typeof data === 'function') {\n      cb = data;\n      data = mask = undefined;\n    } else if (typeof mask === 'function') {\n      cb = mask;\n      mask = undefined;\n    }\n\n    if (typeof data === 'number') data = data.toString();\n\n    if (this.readyState !== WebSocket$1.OPEN) {\n      sendAfterClose(this, data, cb);\n      return;\n    }\n\n    if (mask === undefined) mask = !this._isServer;\n    this._sender.ping(data || EMPTY_BUFFER, mask, cb);\n  }\n\n  /**\n   * Send a pong.\n   *\n   * @param {*} [data] The data to send\n   * @param {Boolean} [mask] Indicates whether or not to mask `data`\n   * @param {Function} [cb] Callback which is executed when the pong is sent\n   * @public\n   */\n  pong(data, mask, cb) {\n    if (this.readyState === WebSocket$1.CONNECTING) {\n      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');\n    }\n\n    if (typeof data === 'function') {\n      cb = data;\n      data = mask = undefined;\n    } else if (typeof mask === 'function') {\n      cb = mask;\n      mask = undefined;\n    }\n\n    if (typeof data === 'number') data = data.toString();\n\n    if (this.readyState !== WebSocket$1.OPEN) {\n      sendAfterClose(this, data, cb);\n      return;\n    }\n\n    if (mask === undefined) mask = !this._isServer;\n    this._sender.pong(data || EMPTY_BUFFER, mask, cb);\n  }\n\n  /**\n   * Resume the socket.\n   *\n   * @public\n   */\n  resume() {\n    if (\n      this.readyState === WebSocket$1.CONNECTING ||\n      this.readyState === WebSocket$1.CLOSED\n    ) {\n      return;\n    }\n\n    this._paused = false;\n    if (!this._receiver._writableState.needDrain) this._socket.resume();\n  }\n\n  /**\n   * Send a data message.\n   *\n   * @param {*} data The message to send\n   * @param {Object} [options] Options object\n   * @param {Boolean} [options.binary] Specifies whether `data` is binary or\n   *     text\n   * @param {Boolean} [options.compress] Specifies whether or not to compress\n   *     `data`\n   * @param {Boolean} [options.fin=true] Specifies whether the fragment is the\n   *     last one\n   * @param {Boolean} [options.mask] Specifies whether or not to mask `data`\n   * @param {Function} [cb] Callback which is executed when data is written out\n   * @public\n   */\n  send(data, options, cb) {\n    if (this.readyState === WebSocket$1.CONNECTING) {\n      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');\n    }\n\n    if (typeof options === 'function') {\n      cb = options;\n      options = {};\n    }\n\n    if (typeof data === 'number') data = data.toString();\n\n    if (this.readyState !== WebSocket$1.OPEN) {\n      sendAfterClose(this, data, cb);\n      return;\n    }\n\n    const opts = {\n      binary: typeof data !== 'string',\n      mask: !this._isServer,\n      compress: true,\n      fin: true,\n      ...options\n    };\n\n    if (!this._extensions[PerMessageDeflate$1.extensionName]) {\n      opts.compress = false;\n    }\n\n    this._sender.send(data || EMPTY_BUFFER, opts, cb);\n  }\n\n  /**\n   * Forcibly close the connection.\n   *\n   * @public\n   */\n  terminate() {\n    if (this.readyState === WebSocket$1.CLOSED) return;\n    if (this.readyState === WebSocket$1.CONNECTING) {\n      const msg = 'WebSocket was closed before the connection was established';\n      abortHandshake$1(this, this._req, msg);\n      return;\n    }\n\n    if (this._socket) {\n      this._readyState = WebSocket$1.CLOSING;\n      this._socket.destroy();\n    }\n  }\n};\n\n/**\n * @constant {Number} CONNECTING\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket$1, 'CONNECTING', {\n  enumerable: true,\n  value: readyStates.indexOf('CONNECTING')\n});\n\n/**\n * @constant {Number} CONNECTING\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket$1.prototype, 'CONNECTING', {\n  enumerable: true,\n  value: readyStates.indexOf('CONNECTING')\n});\n\n/**\n * @constant {Number} OPEN\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket$1, 'OPEN', {\n  enumerable: true,\n  value: readyStates.indexOf('OPEN')\n});\n\n/**\n * @constant {Number} OPEN\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket$1.prototype, 'OPEN', {\n  enumerable: true,\n  value: readyStates.indexOf('OPEN')\n});\n\n/**\n * @constant {Number} CLOSING\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket$1, 'CLOSING', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSING')\n});\n\n/**\n * @constant {Number} CLOSING\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket$1.prototype, 'CLOSING', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSING')\n});\n\n/**\n * @constant {Number} CLOSED\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket$1, 'CLOSED', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSED')\n});\n\n/**\n * @constant {Number} CLOSED\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket$1.prototype, 'CLOSED', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSED')\n});\n\n[\n  'binaryType',\n  'bufferedAmount',\n  'extensions',\n  'isPaused',\n  'protocol',\n  'readyState',\n  'url'\n].forEach((property) => {\n  Object.defineProperty(WebSocket$1.prototype, property, { enumerable: true });\n});\n\n//\n// Add the `onopen`, `onerror`, `onclose`, and `onmessage` attributes.\n// See https://html.spec.whatwg.org/multipage/comms.html#the-websocket-interface\n//\n['open', 'error', 'close', 'message'].forEach((method) => {\n  Object.defineProperty(WebSocket$1.prototype, `on${method}`, {\n    enumerable: true,\n    get() {\n      for (const listener of this.listeners(method)) {\n        if (listener[kForOnEventAttribute]) return listener[kListener];\n      }\n\n      return null;\n    },\n    set(handler) {\n      for (const listener of this.listeners(method)) {\n        if (listener[kForOnEventAttribute]) {\n          this.removeListener(method, listener);\n          break;\n        }\n      }\n\n      if (typeof handler !== 'function') return;\n\n      this.addEventListener(method, handler, {\n        [kForOnEventAttribute]: true\n      });\n    }\n  });\n});\n\nWebSocket$1.prototype.addEventListener = addEventListener;\nWebSocket$1.prototype.removeEventListener = removeEventListener;\n\nvar websocket = WebSocket$1;\n\n/**\n * Initialize a WebSocket client.\n *\n * @param {WebSocket} websocket The client to initialize\n * @param {(String|URL)} address The URL to which to connect\n * @param {Array} protocols The subprotocols\n * @param {Object} [options] Connection options\n * @param {Boolean} [options.followRedirects=false] Whether or not to follow\n *     redirects\n * @param {Function} [options.generateMask] The function used to generate the\n *     masking key\n * @param {Number} [options.handshakeTimeout] Timeout in milliseconds for the\n *     handshake request\n * @param {Number} [options.maxPayload=104857600] The maximum allowed message\n *     size\n * @param {Number} [options.maxRedirects=10] The maximum number of redirects\n *     allowed\n * @param {String} [options.origin] Value of the `Origin` or\n *     `Sec-WebSocket-Origin` header\n * @param {(Boolean|Object)} [options.perMessageDeflate=true] Enable/disable\n *     permessage-deflate\n * @param {Number} [options.protocolVersion=13] Value of the\n *     `Sec-WebSocket-Version` header\n * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n *     not to skip UTF-8 validation for text and close messages\n * @private\n */\nfunction initAsClient(websocket, address, protocols, options) {\n  const opts = {\n    protocolVersion: protocolVersions[1],\n    maxPayload: 100 * 1024 * 1024,\n    skipUTF8Validation: false,\n    perMessageDeflate: true,\n    followRedirects: false,\n    maxRedirects: 10,\n    ...options,\n    createConnection: undefined,\n    socketPath: undefined,\n    hostname: undefined,\n    protocol: undefined,\n    timeout: undefined,\n    method: 'GET',\n    host: undefined,\n    path: undefined,\n    port: undefined\n  };\n\n  if (!protocolVersions.includes(opts.protocolVersion)) {\n    throw new RangeError(\n      `Unsupported protocol version: ${opts.protocolVersion} ` +\n        `(supported versions: ${protocolVersions.join(', ')})`\n    );\n  }\n\n  let parsedUrl;\n\n  if (address instanceof URL$2) {\n    parsedUrl = address;\n    websocket._url = address.href;\n  } else {\n    try {\n      parsedUrl = new URL$2(address);\n    } catch (e) {\n      throw new SyntaxError(`Invalid URL: ${address}`);\n    }\n\n    websocket._url = address;\n  }\n\n  const isSecure = parsedUrl.protocol === 'wss:';\n  const isIpcUrl = parsedUrl.protocol === 'ws+unix:';\n  let invalidUrlMessage;\n\n  if (parsedUrl.protocol !== 'ws:' && !isSecure && !isIpcUrl) {\n    invalidUrlMessage =\n      'The URL\\'s protocol must be one of \"ws:\", \"wss:\", or \"ws+unix:\"';\n  } else if (isIpcUrl && !parsedUrl.pathname) {\n    invalidUrlMessage = \"The URL's pathname is empty\";\n  } else if (parsedUrl.hash) {\n    invalidUrlMessage = 'The URL contains a fragment identifier';\n  }\n\n  if (invalidUrlMessage) {\n    const err = new SyntaxError(invalidUrlMessage);\n\n    if (websocket._redirects === 0) {\n      throw err;\n    } else {\n      emitErrorAndClose(websocket, err);\n      return;\n    }\n  }\n\n  const defaultPort = isSecure ? 443 : 80;\n  const key = randomBytes(16).toString('base64');\n  const request = isSecure ? https$2.request : http$3.request;\n  const protocolSet = new Set();\n  let perMessageDeflate;\n\n  opts.createConnection = isSecure ? tlsConnect : netConnect;\n  opts.defaultPort = opts.defaultPort || defaultPort;\n  opts.port = parsedUrl.port || defaultPort;\n  opts.host = parsedUrl.hostname.startsWith('[')\n    ? parsedUrl.hostname.slice(1, -1)\n    : parsedUrl.hostname;\n  opts.headers = {\n    ...opts.headers,\n    'Sec-WebSocket-Version': opts.protocolVersion,\n    'Sec-WebSocket-Key': key,\n    Connection: 'Upgrade',\n    Upgrade: 'websocket'\n  };\n  opts.path = parsedUrl.pathname + parsedUrl.search;\n  opts.timeout = opts.handshakeTimeout;\n\n  if (opts.perMessageDeflate) {\n    perMessageDeflate = new PerMessageDeflate$1(\n      opts.perMessageDeflate !== true ? opts.perMessageDeflate : {},\n      false,\n      opts.maxPayload\n    );\n    opts.headers['Sec-WebSocket-Extensions'] = format({\n      [PerMessageDeflate$1.extensionName]: perMessageDeflate.offer()\n    });\n  }\n  if (protocols.length) {\n    for (const protocol of protocols) {\n      if (\n        typeof protocol !== 'string' ||\n        !subprotocolRegex.test(protocol) ||\n        protocolSet.has(protocol)\n      ) {\n        throw new SyntaxError(\n          'An invalid or duplicated subprotocol was specified'\n        );\n      }\n\n      protocolSet.add(protocol);\n    }\n\n    opts.headers['Sec-WebSocket-Protocol'] = protocols.join(',');\n  }\n  if (opts.origin) {\n    if (opts.protocolVersion < 13) {\n      opts.headers['Sec-WebSocket-Origin'] = opts.origin;\n    } else {\n      opts.headers.Origin = opts.origin;\n    }\n  }\n  if (parsedUrl.username || parsedUrl.password) {\n    opts.auth = `${parsedUrl.username}:${parsedUrl.password}`;\n  }\n\n  if (isIpcUrl) {\n    const parts = opts.path.split(':');\n\n    opts.socketPath = parts[0];\n    opts.path = parts[1];\n  }\n\n  let req;\n\n  if (opts.followRedirects) {\n    if (websocket._redirects === 0) {\n      websocket._originalIpc = isIpcUrl;\n      websocket._originalSecure = isSecure;\n      websocket._originalHostOrSocketPath = isIpcUrl\n        ? opts.socketPath\n        : parsedUrl.host;\n\n      const headers = options && options.headers;\n\n      //\n      // Shallow copy the user provided options so that headers can be changed\n      // without mutating the original object.\n      //\n      options = { ...options, headers: {} };\n\n      if (headers) {\n        for (const [key, value] of Object.entries(headers)) {\n          options.headers[key.toLowerCase()] = value;\n        }\n      }\n    } else if (websocket.listenerCount('redirect') === 0) {\n      const isSameHost = isIpcUrl\n        ? websocket._originalIpc\n          ? opts.socketPath === websocket._originalHostOrSocketPath\n          : false\n        : websocket._originalIpc\n        ? false\n        : parsedUrl.host === websocket._originalHostOrSocketPath;\n\n      if (!isSameHost || (websocket._originalSecure && !isSecure)) {\n        //\n        // Match curl 7.77.0 behavior and drop the following headers. These\n        // headers are also dropped when following a redirect to a subdomain.\n        //\n        delete opts.headers.authorization;\n        delete opts.headers.cookie;\n\n        if (!isSameHost) delete opts.headers.host;\n\n        opts.auth = undefined;\n      }\n    }\n\n    //\n    // Match curl 7.77.0 behavior and make the first `Authorization` header win.\n    // If the `Authorization` header is set, then there is nothing to do as it\n    // will take precedence.\n    //\n    if (opts.auth && !options.headers.authorization) {\n      options.headers.authorization =\n        'Basic ' + Buffer.from(opts.auth).toString('base64');\n    }\n\n    req = websocket._req = request(opts);\n\n    if (websocket._redirects) {\n      //\n      // Unlike what is done for the `'upgrade'` event, no early exit is\n      // triggered here if the user calls `websocket.close()` or\n      // `websocket.terminate()` from a listener of the `'redirect'` event. This\n      // is because the user can also call `request.destroy()` with an error\n      // before calling `websocket.close()` or `websocket.terminate()` and this\n      // would result in an error being emitted on the `request` object with no\n      // `'error'` event listeners attached.\n      //\n      websocket.emit('redirect', websocket.url, req);\n    }\n  } else {\n    req = websocket._req = request(opts);\n  }\n\n  if (opts.timeout) {\n    req.on('timeout', () => {\n      abortHandshake$1(websocket, req, 'Opening handshake has timed out');\n    });\n  }\n\n  req.on('error', (err) => {\n    if (req === null || req[kAborted]) return;\n\n    req = websocket._req = null;\n    emitErrorAndClose(websocket, err);\n  });\n\n  req.on('response', (res) => {\n    const location = res.headers.location;\n    const statusCode = res.statusCode;\n\n    if (\n      location &&\n      opts.followRedirects &&\n      statusCode >= 300 &&\n      statusCode < 400\n    ) {\n      if (++websocket._redirects > opts.maxRedirects) {\n        abortHandshake$1(websocket, req, 'Maximum redirects exceeded');\n        return;\n      }\n\n      req.abort();\n\n      let addr;\n\n      try {\n        addr = new URL$2(location, address);\n      } catch (e) {\n        const err = new SyntaxError(`Invalid URL: ${location}`);\n        emitErrorAndClose(websocket, err);\n        return;\n      }\n\n      initAsClient(websocket, addr, protocols, options);\n    } else if (!websocket.emit('unexpected-response', req, res)) {\n      abortHandshake$1(\n        websocket,\n        req,\n        `Unexpected server response: ${res.statusCode}`\n      );\n    }\n  });\n\n  req.on('upgrade', (res, socket, head) => {\n    websocket.emit('upgrade', res);\n\n    //\n    // The user may have closed the connection from a listener of the\n    // `'upgrade'` event.\n    //\n    if (websocket.readyState !== WebSocket$1.CONNECTING) return;\n\n    req = websocket._req = null;\n\n    if (res.headers.upgrade.toLowerCase() !== 'websocket') {\n      abortHandshake$1(websocket, socket, 'Invalid Upgrade header');\n      return;\n    }\n\n    const digest = createHash$1('sha1')\n      .update(key + GUID$1)\n      .digest('base64');\n\n    if (res.headers['sec-websocket-accept'] !== digest) {\n      abortHandshake$1(websocket, socket, 'Invalid Sec-WebSocket-Accept header');\n      return;\n    }\n\n    const serverProt = res.headers['sec-websocket-protocol'];\n    let protError;\n\n    if (serverProt !== undefined) {\n      if (!protocolSet.size) {\n        protError = 'Server sent a subprotocol but none was requested';\n      } else if (!protocolSet.has(serverProt)) {\n        protError = 'Server sent an invalid subprotocol';\n      }\n    } else if (protocolSet.size) {\n      protError = 'Server sent no subprotocol';\n    }\n\n    if (protError) {\n      abortHandshake$1(websocket, socket, protError);\n      return;\n    }\n\n    if (serverProt) websocket._protocol = serverProt;\n\n    const secWebSocketExtensions = res.headers['sec-websocket-extensions'];\n\n    if (secWebSocketExtensions !== undefined) {\n      if (!perMessageDeflate) {\n        const message =\n          'Server sent a Sec-WebSocket-Extensions header but no extension ' +\n          'was requested';\n        abortHandshake$1(websocket, socket, message);\n        return;\n      }\n\n      let extensions;\n\n      try {\n        extensions = parse$1(secWebSocketExtensions);\n      } catch (err) {\n        const message = 'Invalid Sec-WebSocket-Extensions header';\n        abortHandshake$1(websocket, socket, message);\n        return;\n      }\n\n      const extensionNames = Object.keys(extensions);\n\n      if (\n        extensionNames.length !== 1 ||\n        extensionNames[0] !== PerMessageDeflate$1.extensionName\n      ) {\n        const message = 'Server indicated an extension that was not requested';\n        abortHandshake$1(websocket, socket, message);\n        return;\n      }\n\n      try {\n        perMessageDeflate.accept(extensions[PerMessageDeflate$1.extensionName]);\n      } catch (err) {\n        const message = 'Invalid Sec-WebSocket-Extensions header';\n        abortHandshake$1(websocket, socket, message);\n        return;\n      }\n\n      websocket._extensions[PerMessageDeflate$1.extensionName] =\n        perMessageDeflate;\n    }\n\n    websocket.setSocket(socket, head, {\n      generateMask: opts.generateMask,\n      maxPayload: opts.maxPayload,\n      skipUTF8Validation: opts.skipUTF8Validation\n    });\n  });\n\n  req.end();\n}\n\n/**\n * Emit the `'error'` and `'close'` events.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @param {Error} The error to emit\n * @private\n */\nfunction emitErrorAndClose(websocket, err) {\n  websocket._readyState = WebSocket$1.CLOSING;\n  websocket.emit('error', err);\n  websocket.emitClose();\n}\n\n/**\n * Create a `net.Socket` and initiate a connection.\n *\n * @param {Object} options Connection options\n * @return {net.Socket} The newly created socket used to start the connection\n * @private\n */\nfunction netConnect(options) {\n  options.path = options.socketPath;\n  return net.connect(options);\n}\n\n/**\n * Create a `tls.TLSSocket` and initiate a connection.\n *\n * @param {Object} options Connection options\n * @return {tls.TLSSocket} The newly created socket used to start the connection\n * @private\n */\nfunction tlsConnect(options) {\n  options.path = undefined;\n\n  if (!options.servername && options.servername !== '') {\n    options.servername = net.isIP(options.host) ? '' : options.host;\n  }\n\n  return tls.connect(options);\n}\n\n/**\n * Abort the handshake and emit an error.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @param {(http.ClientRequest|net.Socket|tls.Socket)} stream The request to\n *     abort or the socket to destroy\n * @param {String} message The error message\n * @private\n */\nfunction abortHandshake$1(websocket, stream, message) {\n  websocket._readyState = WebSocket$1.CLOSING;\n\n  const err = new Error(message);\n  Error.captureStackTrace(err, abortHandshake$1);\n\n  if (stream.setHeader) {\n    stream[kAborted] = true;\n    stream.abort();\n\n    if (stream.socket && !stream.socket.destroyed) {\n      //\n      // On Node.js >= 14.3.0 `request.abort()` does not destroy the socket if\n      // called after the request completed. See\n      // https://github.com/websockets/ws/issues/1869.\n      //\n      stream.socket.destroy();\n    }\n\n    process.nextTick(emitErrorAndClose, websocket, err);\n  } else {\n    stream.destroy(err);\n    stream.once('error', websocket.emit.bind(websocket, 'error'));\n    stream.once('close', websocket.emitClose.bind(websocket));\n  }\n}\n\n/**\n * Handle cases where the `ping()`, `pong()`, or `send()` methods are called\n * when the `readyState` attribute is `CLOSING` or `CLOSED`.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @param {*} [data] The data to send\n * @param {Function} [cb] Callback\n * @private\n */\nfunction sendAfterClose(websocket, data, cb) {\n  if (data) {\n    const length = toBuffer(data).length;\n\n    //\n    // The `_bufferedAmount` property is used only when the peer is a client and\n    // the opening handshake fails. Under these circumstances, in fact, the\n    // `setSocket()` method is not called, so the `_socket` and `_sender`\n    // properties are set to `null`.\n    //\n    if (websocket._socket) websocket._sender._bufferedBytes += length;\n    else websocket._bufferedAmount += length;\n  }\n\n  if (cb) {\n    const err = new Error(\n      `WebSocket is not open: readyState ${websocket.readyState} ` +\n        `(${readyStates[websocket.readyState]})`\n    );\n    process.nextTick(cb, err);\n  }\n}\n\n/**\n * The listener of the `Receiver` `'conclude'` event.\n *\n * @param {Number} code The status code\n * @param {Buffer} reason The reason for closing\n * @private\n */\nfunction receiverOnConclude(code, reason) {\n  const websocket = this[kWebSocket$1];\n\n  websocket._closeFrameReceived = true;\n  websocket._closeMessage = reason;\n  websocket._closeCode = code;\n\n  if (websocket._socket[kWebSocket$1] === undefined) return;\n\n  websocket._socket.removeListener('data', socketOnData);\n  process.nextTick(resume, websocket._socket);\n\n  if (code === 1005) websocket.close();\n  else websocket.close(code, reason);\n}\n\n/**\n * The listener of the `Receiver` `'drain'` event.\n *\n * @private\n */\nfunction receiverOnDrain() {\n  const websocket = this[kWebSocket$1];\n\n  if (!websocket.isPaused) websocket._socket.resume();\n}\n\n/**\n * The listener of the `Receiver` `'error'` event.\n *\n * @param {(RangeError|Error)} err The emitted error\n * @private\n */\nfunction receiverOnError(err) {\n  const websocket = this[kWebSocket$1];\n\n  if (websocket._socket[kWebSocket$1] !== undefined) {\n    websocket._socket.removeListener('data', socketOnData);\n\n    //\n    // On Node.js < 14.0.0 the `'error'` event is emitted synchronously. See\n    // https://github.com/websockets/ws/issues/1940.\n    //\n    process.nextTick(resume, websocket._socket);\n\n    websocket.close(err[kStatusCode]);\n  }\n\n  websocket.emit('error', err);\n}\n\n/**\n * The listener of the `Receiver` `'finish'` event.\n *\n * @private\n */\nfunction receiverOnFinish() {\n  this[kWebSocket$1].emitClose();\n}\n\n/**\n * The listener of the `Receiver` `'message'` event.\n *\n * @param {Buffer|ArrayBuffer|Buffer[])} data The message\n * @param {Boolean} isBinary Specifies whether the message is binary or not\n * @private\n */\nfunction receiverOnMessage(data, isBinary) {\n  this[kWebSocket$1].emit('message', data, isBinary);\n}\n\n/**\n * The listener of the `Receiver` `'ping'` event.\n *\n * @param {Buffer} data The data included in the ping frame\n * @private\n */\nfunction receiverOnPing(data) {\n  const websocket = this[kWebSocket$1];\n\n  websocket.pong(data, !websocket._isServer, NOOP);\n  websocket.emit('ping', data);\n}\n\n/**\n * The listener of the `Receiver` `'pong'` event.\n *\n * @param {Buffer} data The data included in the pong frame\n * @private\n */\nfunction receiverOnPong(data) {\n  this[kWebSocket$1].emit('pong', data);\n}\n\n/**\n * Resume a readable stream\n *\n * @param {Readable} stream The readable stream\n * @private\n */\nfunction resume(stream) {\n  stream.resume();\n}\n\n/**\n * The listener of the `net.Socket` `'close'` event.\n *\n * @private\n */\nfunction socketOnClose() {\n  const websocket = this[kWebSocket$1];\n\n  this.removeListener('close', socketOnClose);\n  this.removeListener('data', socketOnData);\n  this.removeListener('end', socketOnEnd);\n\n  websocket._readyState = WebSocket$1.CLOSING;\n\n  let chunk;\n\n  //\n  // The close frame might not have been received or the `'end'` event emitted,\n  // for example, if the socket was destroyed due to an error. Ensure that the\n  // `receiver` stream is closed after writing any remaining buffered data to\n  // it. If the readable side of the socket is in flowing mode then there is no\n  // buffered data as everything has been already written and `readable.read()`\n  // will return `null`. If instead, the socket is paused, any possible buffered\n  // data will be read as a single chunk.\n  //\n  if (\n    !this._readableState.endEmitted &&\n    !websocket._closeFrameReceived &&\n    !websocket._receiver._writableState.errorEmitted &&\n    (chunk = websocket._socket.read()) !== null\n  ) {\n    websocket._receiver.write(chunk);\n  }\n\n  websocket._receiver.end();\n\n  this[kWebSocket$1] = undefined;\n\n  clearTimeout(websocket._closeTimer);\n\n  if (\n    websocket._receiver._writableState.finished ||\n    websocket._receiver._writableState.errorEmitted\n  ) {\n    websocket.emitClose();\n  } else {\n    websocket._receiver.on('error', receiverOnFinish);\n    websocket._receiver.on('finish', receiverOnFinish);\n  }\n}\n\n/**\n * The listener of the `net.Socket` `'data'` event.\n *\n * @param {Buffer} chunk A chunk of data\n * @private\n */\nfunction socketOnData(chunk) {\n  if (!this[kWebSocket$1]._receiver.write(chunk)) {\n    this.pause();\n  }\n}\n\n/**\n * The listener of the `net.Socket` `'end'` event.\n *\n * @private\n */\nfunction socketOnEnd() {\n  const websocket = this[kWebSocket$1];\n\n  websocket._readyState = WebSocket$1.CLOSING;\n  websocket._receiver.end();\n  this.end();\n}\n\n/**\n * The listener of the `net.Socket` `'error'` event.\n *\n * @private\n */\nfunction socketOnError$1() {\n  const websocket = this[kWebSocket$1];\n\n  this.removeListener('error', socketOnError$1);\n  this.on('error', NOOP);\n\n  if (websocket) {\n    websocket._readyState = WebSocket$1.CLOSING;\n    this.destroy();\n  }\n}\n\nconst { tokenChars } = validationExports;\n\n/**\n * Parses the `Sec-WebSocket-Protocol` header into a set of subprotocol names.\n *\n * @param {String} header The field value of the header\n * @return {Set} The subprotocol names\n * @public\n */\nfunction parse(header) {\n  const protocols = new Set();\n  let start = -1;\n  let end = -1;\n  let i = 0;\n\n  for (i; i < header.length; i++) {\n    const code = header.charCodeAt(i);\n\n    if (end === -1 && tokenChars[code] === 1) {\n      if (start === -1) start = i;\n    } else if (\n      i !== 0 &&\n      (code === 0x20 /* ' ' */ || code === 0x09) /* '\\t' */\n    ) {\n      if (end === -1 && start !== -1) end = i;\n    } else if (code === 0x2c /* ',' */) {\n      if (start === -1) {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n\n      if (end === -1) end = i;\n\n      const protocol = header.slice(start, end);\n\n      if (protocols.has(protocol)) {\n        throw new SyntaxError(`The \"${protocol}\" subprotocol is duplicated`);\n      }\n\n      protocols.add(protocol);\n      start = end = -1;\n    } else {\n      throw new SyntaxError(`Unexpected character at index ${i}`);\n    }\n  }\n\n  if (start === -1 || end !== -1) {\n    throw new SyntaxError('Unexpected end of input');\n  }\n\n  const protocol = header.slice(start, i);\n\n  if (protocols.has(protocol)) {\n    throw new SyntaxError(`The \"${protocol}\" subprotocol is duplicated`);\n  }\n\n  protocols.add(protocol);\n  return protocols;\n}\n\nvar subprotocol$1 = { parse };\n\n/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^net|tls|https$\" }] */\n\nconst EventEmitter = require$$0$5;\nconst http$2 = require$$1$1;\nconst { createHash } = require$$5$1;\n\nconst extension = extension$1;\nconst PerMessageDeflate = permessageDeflate;\nconst subprotocol = subprotocol$1;\nconst WebSocket = websocket;\nconst { GUID, kWebSocket } = constants;\n\nconst keyRegex = /^[+/0-9A-Za-z]{22}==$/;\n\nconst RUNNING = 0;\nconst CLOSING = 1;\nconst CLOSED = 2;\n\n/**\n * Class representing a WebSocket server.\n *\n * @extends EventEmitter\n */\nclass WebSocketServer extends EventEmitter {\n  /**\n   * Create a `WebSocketServer` instance.\n   *\n   * @param {Object} options Configuration options\n   * @param {Number} [options.backlog=511] The maximum length of the queue of\n   *     pending connections\n   * @param {Boolean} [options.clientTracking=true] Specifies whether or not to\n   *     track clients\n   * @param {Function} [options.handleProtocols] A hook to handle protocols\n   * @param {String} [options.host] The hostname where to bind the server\n   * @param {Number} [options.maxPayload=104857600] The maximum allowed message\n   *     size\n   * @param {Boolean} [options.noServer=false] Enable no server mode\n   * @param {String} [options.path] Accept only connections matching this path\n   * @param {(Boolean|Object)} [options.perMessageDeflate=false] Enable/disable\n   *     permessage-deflate\n   * @param {Number} [options.port] The port where to bind the server\n   * @param {(http.Server|https.Server)} [options.server] A pre-created HTTP/S\n   *     server to use\n   * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n   *     not to skip UTF-8 validation for text and close messages\n   * @param {Function} [options.verifyClient] A hook to reject connections\n   * @param {Function} [options.WebSocket=WebSocket] Specifies the `WebSocket`\n   *     class to use. It must be the `WebSocket` class or class that extends it\n   * @param {Function} [callback] A listener for the `listening` event\n   */\n  constructor(options, callback) {\n    super();\n\n    options = {\n      maxPayload: 100 * 1024 * 1024,\n      skipUTF8Validation: false,\n      perMessageDeflate: false,\n      handleProtocols: null,\n      clientTracking: true,\n      verifyClient: null,\n      noServer: false,\n      backlog: null, // use default (511 as implemented in net.js)\n      server: null,\n      host: null,\n      path: null,\n      port: null,\n      WebSocket,\n      ...options\n    };\n\n    if (\n      (options.port == null && !options.server && !options.noServer) ||\n      (options.port != null && (options.server || options.noServer)) ||\n      (options.server && options.noServer)\n    ) {\n      throw new TypeError(\n        'One and only one of the \"port\", \"server\", or \"noServer\" options ' +\n          'must be specified'\n      );\n    }\n\n    if (options.port != null) {\n      this._server = http$2.createServer((req, res) => {\n        const body = http$2.STATUS_CODES[426];\n\n        res.writeHead(426, {\n          'Content-Length': body.length,\n          'Content-Type': 'text/plain'\n        });\n        res.end(body);\n      });\n      this._server.listen(\n        options.port,\n        options.host,\n        options.backlog,\n        callback\n      );\n    } else if (options.server) {\n      this._server = options.server;\n    }\n\n    if (this._server) {\n      const emitConnection = this.emit.bind(this, 'connection');\n\n      this._removeListeners = addListeners(this._server, {\n        listening: this.emit.bind(this, 'listening'),\n        error: this.emit.bind(this, 'error'),\n        upgrade: (req, socket, head) => {\n          this.handleUpgrade(req, socket, head, emitConnection);\n        }\n      });\n    }\n\n    if (options.perMessageDeflate === true) options.perMessageDeflate = {};\n    if (options.clientTracking) {\n      this.clients = new Set();\n      this._shouldEmitClose = false;\n    }\n\n    this.options = options;\n    this._state = RUNNING;\n  }\n\n  /**\n   * Returns the bound address, the address family name, and port of the server\n   * as reported by the operating system if listening on an IP socket.\n   * If the server is listening on a pipe or UNIX domain socket, the name is\n   * returned as a string.\n   *\n   * @return {(Object|String|null)} The address of the server\n   * @public\n   */\n  address() {\n    if (this.options.noServer) {\n      throw new Error('The server is operating in \"noServer\" mode');\n    }\n\n    if (!this._server) return null;\n    return this._server.address();\n  }\n\n  /**\n   * Stop the server from accepting new connections and emit the `'close'` event\n   * when all existing connections are closed.\n   *\n   * @param {Function} [cb] A one-time listener for the `'close'` event\n   * @public\n   */\n  close(cb) {\n    if (this._state === CLOSED) {\n      if (cb) {\n        this.once('close', () => {\n          cb(new Error('The server is not running'));\n        });\n      }\n\n      process.nextTick(emitClose, this);\n      return;\n    }\n\n    if (cb) this.once('close', cb);\n\n    if (this._state === CLOSING) return;\n    this._state = CLOSING;\n\n    if (this.options.noServer || this.options.server) {\n      if (this._server) {\n        this._removeListeners();\n        this._removeListeners = this._server = null;\n      }\n\n      if (this.clients) {\n        if (!this.clients.size) {\n          process.nextTick(emitClose, this);\n        } else {\n          this._shouldEmitClose = true;\n        }\n      } else {\n        process.nextTick(emitClose, this);\n      }\n    } else {\n      const server = this._server;\n\n      this._removeListeners();\n      this._removeListeners = this._server = null;\n\n      //\n      // The HTTP/S server was created internally. Close it, and rely on its\n      // `'close'` event.\n      //\n      server.close(() => {\n        emitClose(this);\n      });\n    }\n  }\n\n  /**\n   * See if a given request should be handled by this server instance.\n   *\n   * @param {http.IncomingMessage} req Request object to inspect\n   * @return {Boolean} `true` if the request is valid, else `false`\n   * @public\n   */\n  shouldHandle(req) {\n    if (this.options.path) {\n      const index = req.url.indexOf('?');\n      const pathname = index !== -1 ? req.url.slice(0, index) : req.url;\n\n      if (pathname !== this.options.path) return false;\n    }\n\n    return true;\n  }\n\n  /**\n   * Handle a HTTP Upgrade request.\n   *\n   * @param {http.IncomingMessage} req The request object\n   * @param {(net.Socket|tls.Socket)} socket The network socket between the\n   *     server and client\n   * @param {Buffer} head The first packet of the upgraded stream\n   * @param {Function} cb Callback\n   * @public\n   */\n  handleUpgrade(req, socket, head, cb) {\n    socket.on('error', socketOnError);\n\n    const key = req.headers['sec-websocket-key'];\n    const version = +req.headers['sec-websocket-version'];\n\n    if (req.method !== 'GET') {\n      const message = 'Invalid HTTP method';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 405, message);\n      return;\n    }\n\n    if (req.headers.upgrade.toLowerCase() !== 'websocket') {\n      const message = 'Invalid Upgrade header';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n      return;\n    }\n\n    if (!key || !keyRegex.test(key)) {\n      const message = 'Missing or invalid Sec-WebSocket-Key header';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n      return;\n    }\n\n    if (version !== 8 && version !== 13) {\n      const message = 'Missing or invalid Sec-WebSocket-Version header';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n      return;\n    }\n\n    if (!this.shouldHandle(req)) {\n      abortHandshake(socket, 400);\n      return;\n    }\n\n    const secWebSocketProtocol = req.headers['sec-websocket-protocol'];\n    let protocols = new Set();\n\n    if (secWebSocketProtocol !== undefined) {\n      try {\n        protocols = subprotocol.parse(secWebSocketProtocol);\n      } catch (err) {\n        const message = 'Invalid Sec-WebSocket-Protocol header';\n        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n        return;\n      }\n    }\n\n    const secWebSocketExtensions = req.headers['sec-websocket-extensions'];\n    const extensions = {};\n\n    if (\n      this.options.perMessageDeflate &&\n      secWebSocketExtensions !== undefined\n    ) {\n      const perMessageDeflate = new PerMessageDeflate(\n        this.options.perMessageDeflate,\n        true,\n        this.options.maxPayload\n      );\n\n      try {\n        const offers = extension.parse(secWebSocketExtensions);\n\n        if (offers[PerMessageDeflate.extensionName]) {\n          perMessageDeflate.accept(offers[PerMessageDeflate.extensionName]);\n          extensions[PerMessageDeflate.extensionName] = perMessageDeflate;\n        }\n      } catch (err) {\n        const message =\n          'Invalid or unacceptable Sec-WebSocket-Extensions header';\n        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n        return;\n      }\n    }\n\n    //\n    // Optionally call external client verification handler.\n    //\n    if (this.options.verifyClient) {\n      const info = {\n        origin:\n          req.headers[`${version === 8 ? 'sec-websocket-origin' : 'origin'}`],\n        secure: !!(req.socket.authorized || req.socket.encrypted),\n        req\n      };\n\n      if (this.options.verifyClient.length === 2) {\n        this.options.verifyClient(info, (verified, code, message, headers) => {\n          if (!verified) {\n            return abortHandshake(socket, code || 401, message, headers);\n          }\n\n          this.completeUpgrade(\n            extensions,\n            key,\n            protocols,\n            req,\n            socket,\n            head,\n            cb\n          );\n        });\n        return;\n      }\n\n      if (!this.options.verifyClient(info)) return abortHandshake(socket, 401);\n    }\n\n    this.completeUpgrade(extensions, key, protocols, req, socket, head, cb);\n  }\n\n  /**\n   * Upgrade the connection to WebSocket.\n   *\n   * @param {Object} extensions The accepted extensions\n   * @param {String} key The value of the `Sec-WebSocket-Key` header\n   * @param {Set} protocols The subprotocols\n   * @param {http.IncomingMessage} req The request object\n   * @param {(net.Socket|tls.Socket)} socket The network socket between the\n   *     server and client\n   * @param {Buffer} head The first packet of the upgraded stream\n   * @param {Function} cb Callback\n   * @throws {Error} If called more than once with the same socket\n   * @private\n   */\n  completeUpgrade(extensions, key, protocols, req, socket, head, cb) {\n    //\n    // Destroy the socket if the client has already sent a FIN packet.\n    //\n    if (!socket.readable || !socket.writable) return socket.destroy();\n\n    if (socket[kWebSocket]) {\n      throw new Error(\n        'server.handleUpgrade() was called more than once with the same ' +\n          'socket, possibly due to a misconfiguration'\n      );\n    }\n\n    if (this._state > RUNNING) return abortHandshake(socket, 503);\n\n    const digest = createHash('sha1')\n      .update(key + GUID)\n      .digest('base64');\n\n    const headers = [\n      'HTTP/1.1 101 Switching Protocols',\n      'Upgrade: websocket',\n      'Connection: Upgrade',\n      `Sec-WebSocket-Accept: ${digest}`\n    ];\n\n    const ws = new this.options.WebSocket(null);\n\n    if (protocols.size) {\n      //\n      // Optionally call external protocol selection handler.\n      //\n      const protocol = this.options.handleProtocols\n        ? this.options.handleProtocols(protocols, req)\n        : protocols.values().next().value;\n\n      if (protocol) {\n        headers.push(`Sec-WebSocket-Protocol: ${protocol}`);\n        ws._protocol = protocol;\n      }\n    }\n\n    if (extensions[PerMessageDeflate.extensionName]) {\n      const params = extensions[PerMessageDeflate.extensionName].params;\n      const value = extension.format({\n        [PerMessageDeflate.extensionName]: [params]\n      });\n      headers.push(`Sec-WebSocket-Extensions: ${value}`);\n      ws._extensions = extensions;\n    }\n\n    //\n    // Allow external modification/inspection of handshake headers.\n    //\n    this.emit('headers', headers, req);\n\n    socket.write(headers.concat('\\r\\n').join('\\r\\n'));\n    socket.removeListener('error', socketOnError);\n\n    ws.setSocket(socket, head, {\n      maxPayload: this.options.maxPayload,\n      skipUTF8Validation: this.options.skipUTF8Validation\n    });\n\n    if (this.clients) {\n      this.clients.add(ws);\n      ws.on('close', () => {\n        this.clients.delete(ws);\n\n        if (this._shouldEmitClose && !this.clients.size) {\n          process.nextTick(emitClose, this);\n        }\n      });\n    }\n\n    cb(ws, req);\n  }\n}\n\nvar websocketServer = WebSocketServer;\n\n/**\n * Add event listeners on an `EventEmitter` using a map of <event, listener>\n * pairs.\n *\n * @param {EventEmitter} server The event emitter\n * @param {Object.<String, Function>} map The listeners to add\n * @return {Function} A function that will remove the added listeners when\n *     called\n * @private\n */\nfunction addListeners(server, map) {\n  for (const event of Object.keys(map)) server.on(event, map[event]);\n\n  return function removeListeners() {\n    for (const event of Object.keys(map)) {\n      server.removeListener(event, map[event]);\n    }\n  };\n}\n\n/**\n * Emit a `'close'` event on an `EventEmitter`.\n *\n * @param {EventEmitter} server The event emitter\n * @private\n */\nfunction emitClose(server) {\n  server._state = CLOSED;\n  server.emit('close');\n}\n\n/**\n * Handle socket errors.\n *\n * @private\n */\nfunction socketOnError() {\n  this.destroy();\n}\n\n/**\n * Close the connection when preconditions are not fulfilled.\n *\n * @param {(net.Socket|tls.Socket)} socket The socket of the upgrade request\n * @param {Number} code The HTTP response status code\n * @param {String} [message] The HTTP response body\n * @param {Object} [headers] Additional HTTP response headers\n * @private\n */\nfunction abortHandshake(socket, code, message, headers) {\n  //\n  // The socket is writable unless the user destroyed or ended it before calling\n  // `server.handleUpgrade()` or in the `verifyClient` function, which is a user\n  // error. Handling this does not make much sense as the worst that can happen\n  // is that some of the data written by the user might be discarded due to the\n  // call to `socket.end()` below, which triggers an `'error'` event that in\n  // turn causes the socket to be destroyed.\n  //\n  message = message || http$2.STATUS_CODES[code];\n  headers = {\n    Connection: 'close',\n    'Content-Type': 'text/html',\n    'Content-Length': Buffer.byteLength(message),\n    ...headers\n  };\n\n  socket.once('finish', socket.destroy);\n\n  socket.end(\n    `HTTP/1.1 ${code} ${http$2.STATUS_CODES[code]}\\r\\n` +\n      Object.keys(headers)\n        .map((h) => `${h}: ${headers[h]}`)\n        .join('\\r\\n') +\n      '\\r\\n\\r\\n' +\n      message\n  );\n}\n\n/**\n * Emit a `'wsClientError'` event on a `WebSocketServer` if there is at least\n * one listener for it, otherwise call `abortHandshake()`.\n *\n * @param {WebSocketServer} server The WebSocket server\n * @param {http.IncomingMessage} req The request object\n * @param {(net.Socket|tls.Socket)} socket The socket of the upgrade request\n * @param {Number} code The HTTP response status code\n * @param {String} message The HTTP response body\n * @private\n */\nfunction abortHandshakeOrEmitwsClientError(server, req, socket, code, message) {\n  if (server.listenerCount('wsClientError')) {\n    const err = new Error(message);\n    Error.captureStackTrace(err, abortHandshakeOrEmitwsClientError);\n\n    server.emit('wsClientError', err, socket, req);\n  } else {\n    abortHandshake(socket, code, message);\n  }\n}\n\nconst HMR_HEADER = 'vite-hmr';\nconst wsServerEvents = [\n    'connection',\n    'error',\n    'headers',\n    'listening',\n    'message',\n];\nfunction createWebSocketServer(server, config, httpsOptions) {\n    let wss;\n    let httpsServer = undefined;\n    const hmr = isObject$1(config.server.hmr) && config.server.hmr;\n    const hmrServer = hmr && hmr.server;\n    const hmrPort = hmr && hmr.port;\n    // TODO: the main server port may not have been chosen yet as it may use the next available\n    const portsAreCompatible = !hmrPort || hmrPort === config.server.port;\n    const wsServer = hmrServer || (portsAreCompatible && server);\n    const customListeners = new Map();\n    const clientsMap = new WeakMap();\n    if (wsServer) {\n        wss = new websocketServer({ noServer: true });\n        wsServer.on('upgrade', (req, socket, head) => {\n            if (req.headers['sec-websocket-protocol'] === HMR_HEADER) {\n                wss.handleUpgrade(req, socket, head, (ws) => {\n                    wss.emit('connection', ws, req);\n                });\n            }\n        });\n    }\n    else {\n        const websocketServerOptions = {};\n        const port = hmrPort || 24678;\n        const host = (hmr && hmr.host) || undefined;\n        if (httpsOptions) {\n            // if we're serving the middlewares over https, the ws library doesn't support automatically creating an https server, so we need to do it ourselves\n            // create an inline https server and mount the websocket server to it\n            httpsServer = createServer$2(httpsOptions, (req, res) => {\n                const statusCode = 426;\n                const body = STATUS_CODES[statusCode];\n                if (!body)\n                    throw new Error(`No body text found for the ${statusCode} status code`);\n                res.writeHead(statusCode, {\n                    'Content-Length': body.length,\n                    'Content-Type': 'text/plain',\n                });\n                res.end(body);\n            });\n            httpsServer.listen(port, host);\n            websocketServerOptions.server = httpsServer;\n        }\n        else {\n            // we don't need to serve over https, just let ws handle its own server\n            websocketServerOptions.port = port;\n            if (host) {\n                websocketServerOptions.host = host;\n            }\n        }\n        // vite dev server in middleware mode\n        wss = new websocketServer(websocketServerOptions);\n    }\n    wss.on('connection', (socket) => {\n        socket.on('message', (raw) => {\n            if (!customListeners.size)\n                return;\n            let parsed;\n            try {\n                parsed = JSON.parse(String(raw));\n            }\n            catch { }\n            if (!parsed || parsed.type !== 'custom' || !parsed.event)\n                return;\n            const listeners = customListeners.get(parsed.event);\n            if (!listeners?.size)\n                return;\n            const client = getSocketClient(socket);\n            listeners.forEach((listener) => listener(parsed.data, client));\n        });\n        socket.on('error', (err) => {\n            config.logger.error(`${picocolorsExports.red(`ws error:`)}\\n${err.stack}`, {\n                timestamp: true,\n                error: err,\n            });\n        });\n        socket.send(JSON.stringify({ type: 'connected' }));\n        if (bufferedError) {\n            socket.send(JSON.stringify(bufferedError));\n            bufferedError = null;\n        }\n    });\n    wss.on('error', (e) => {\n        if (e.code === 'EADDRINUSE') {\n            config.logger.error(picocolorsExports.red(`WebSocket server error: Port is already in use`), { error: e });\n        }\n        else {\n            config.logger.error(picocolorsExports.red(`WebSocket server error:\\n${e.stack || e.message}`), { error: e });\n        }\n    });\n    // Provide a wrapper to the ws client so we can send messages in JSON format\n    // To be consistent with server.ws.send\n    function getSocketClient(socket) {\n        if (!clientsMap.has(socket)) {\n            clientsMap.set(socket, {\n                send: (...args) => {\n                    let payload;\n                    if (typeof args[0] === 'string') {\n                        payload = {\n                            type: 'custom',\n                            event: args[0],\n                            data: args[1],\n                        };\n                    }\n                    else {\n                        payload = args[0];\n                    }\n                    socket.send(JSON.stringify(payload));\n                },\n                socket,\n            });\n        }\n        return clientsMap.get(socket);\n    }\n    // On page reloads, if a file fails to compile and returns 500, the server\n    // sends the error payload before the client connection is established.\n    // If we have no open clients, buffer the error and send it to the next\n    // connected client.\n    let bufferedError = null;\n    return {\n        on: ((event, fn) => {\n            if (wsServerEvents.includes(event))\n                wss.on(event, fn);\n            else {\n                if (!customListeners.has(event)) {\n                    customListeners.set(event, new Set());\n                }\n                customListeners.get(event).add(fn);\n            }\n        }),\n        off: ((event, fn) => {\n            if (wsServerEvents.includes(event)) {\n                wss.off(event, fn);\n            }\n            else {\n                customListeners.get(event)?.delete(fn);\n            }\n        }),\n        get clients() {\n            return new Set(Array.from(wss.clients).map(getSocketClient));\n        },\n        send(...args) {\n            let payload;\n            if (typeof args[0] === 'string') {\n                payload = {\n                    type: 'custom',\n                    event: args[0],\n                    data: args[1],\n                };\n            }\n            else {\n                payload = args[0];\n            }\n            if (payload.type === 'error' && !wss.clients.size) {\n                bufferedError = payload;\n                return;\n            }\n            const stringified = JSON.stringify(payload);\n            wss.clients.forEach((client) => {\n                // readyState 1 means the connection is open\n                if (client.readyState === 1) {\n                    client.send(stringified);\n                }\n            });\n        },\n        close() {\n            return new Promise((resolve, reject) => {\n                wss.clients.forEach((client) => {\n                    client.terminate();\n                });\n                wss.close((err) => {\n                    if (err) {\n                        reject(err);\n                    }\n                    else {\n                        if (httpsServer) {\n                            httpsServer.close((err) => {\n                                if (err) {\n                                    reject(err);\n                                }\n                                else {\n                                    resolve();\n                                }\n                            });\n                        }\n                        else {\n                            resolve();\n                        }\n                    }\n                });\n            });\n        },\n    };\n}\n\n// this middleware is only active when (base !== '/')\nfunction baseMiddleware({ config, }) {\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteBaseMiddleware(req, res, next) {\n        const url = req.url;\n        const parsed = new URL(url, 'http://vitejs.dev');\n        const path = parsed.pathname || '/';\n        const base = config.rawBase;\n        if (path.startsWith(base)) {\n            // rewrite url to remove base. this ensures that other middleware does\n            // not need to consider base being prepended or not\n            req.url = stripBase(url, base);\n            return next();\n        }\n        // skip redirect and error fallback on middleware mode, #4057\n        if (config.server.middlewareMode) {\n            return next();\n        }\n        if (path === '/' || path === '/index.html') {\n            // redirect root visit to based url with search and hash\n            res.writeHead(302, {\n                Location: base + (parsed.search || '') + (parsed.hash || ''),\n            });\n            res.end();\n            return;\n        }\n        else if (req.headers.accept?.includes('text/html')) {\n            // non-based page visit\n            const redirectPath = url + '/' !== base ? joinUrlSegments(base, url) : base;\n            res.writeHead(404, {\n                'Content-Type': 'text/html',\n            });\n            res.end(`The server is configured with a public base URL of ${base} - ` +\n                `did you mean to visit <a href=\"${redirectPath}\">${redirectPath}</a> instead?`);\n            return;\n        }\n        next();\n    };\n}\n\nvar httpProxyExports$1 = {};\nvar httpProxy$3 = {\n  get exports(){ return httpProxyExports$1; },\n  set exports(v){ httpProxyExports$1 = v; },\n};\n\nvar httpProxyExports = {};\nvar httpProxy$2 = {\n  get exports(){ return httpProxyExports; },\n  set exports(v){ httpProxyExports = v; },\n};\n\nvar eventemitter3Exports = {};\nvar eventemitter3 = {\n  get exports(){ return eventemitter3Exports; },\n  set exports(v){ eventemitter3Exports = v; },\n};\n\n(function (module) {\n\n\tvar has = Object.prototype.hasOwnProperty\n\t  , prefix = '~';\n\n\t/**\n\t * Constructor to create a storage for our `EE` objects.\n\t * An `Events` instance is a plain object whose properties are event names.\n\t *\n\t * @constructor\n\t * @private\n\t */\n\tfunction Events() {}\n\n\t//\n\t// We try to not inherit from `Object.prototype`. In some engines creating an\n\t// instance in this way is faster than calling `Object.create(null)` directly.\n\t// If `Object.create(null)` is not supported we prefix the event names with a\n\t// character to make sure that the built-in object properties are not\n\t// overridden or used as an attack vector.\n\t//\n\tif (Object.create) {\n\t  Events.prototype = Object.create(null);\n\n\t  //\n\t  // This hack is needed because the `__proto__` property is still inherited in\n\t  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\n\t  //\n\t  if (!new Events().__proto__) prefix = false;\n\t}\n\n\t/**\n\t * Representation of a single event listener.\n\t *\n\t * @param {Function} fn The listener function.\n\t * @param {*} context The context to invoke the listener with.\n\t * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\n\t * @constructor\n\t * @private\n\t */\n\tfunction EE(fn, context, once) {\n\t  this.fn = fn;\n\t  this.context = context;\n\t  this.once = once || false;\n\t}\n\n\t/**\n\t * Add a listener for a given event.\n\t *\n\t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn The listener function.\n\t * @param {*} context The context to invoke the listener with.\n\t * @param {Boolean} once Specify if the listener is a one-time listener.\n\t * @returns {EventEmitter}\n\t * @private\n\t */\n\tfunction addListener(emitter, event, fn, context, once) {\n\t  if (typeof fn !== 'function') {\n\t    throw new TypeError('The listener must be a function');\n\t  }\n\n\t  var listener = new EE(fn, context || emitter, once)\n\t    , evt = prefix ? prefix + event : event;\n\n\t  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\n\t  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\n\t  else emitter._events[evt] = [emitter._events[evt], listener];\n\n\t  return emitter;\n\t}\n\n\t/**\n\t * Clear event by name.\n\t *\n\t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n\t * @param {(String|Symbol)} evt The Event name.\n\t * @private\n\t */\n\tfunction clearEvent(emitter, evt) {\n\t  if (--emitter._eventsCount === 0) emitter._events = new Events();\n\t  else delete emitter._events[evt];\n\t}\n\n\t/**\n\t * Minimal `EventEmitter` interface that is molded against the Node.js\n\t * `EventEmitter` interface.\n\t *\n\t * @constructor\n\t * @public\n\t */\n\tfunction EventEmitter() {\n\t  this._events = new Events();\n\t  this._eventsCount = 0;\n\t}\n\n\t/**\n\t * Return an array listing the events for which the emitter has registered\n\t * listeners.\n\t *\n\t * @returns {Array}\n\t * @public\n\t */\n\tEventEmitter.prototype.eventNames = function eventNames() {\n\t  var names = []\n\t    , events\n\t    , name;\n\n\t  if (this._eventsCount === 0) return names;\n\n\t  for (name in (events = this._events)) {\n\t    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);\n\t  }\n\n\t  if (Object.getOwnPropertySymbols) {\n\t    return names.concat(Object.getOwnPropertySymbols(events));\n\t  }\n\n\t  return names;\n\t};\n\n\t/**\n\t * Return the listeners registered for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @returns {Array} The registered listeners.\n\t * @public\n\t */\n\tEventEmitter.prototype.listeners = function listeners(event) {\n\t  var evt = prefix ? prefix + event : event\n\t    , handlers = this._events[evt];\n\n\t  if (!handlers) return [];\n\t  if (handlers.fn) return [handlers.fn];\n\n\t  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {\n\t    ee[i] = handlers[i].fn;\n\t  }\n\n\t  return ee;\n\t};\n\n\t/**\n\t * Return the number of listeners listening to a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @returns {Number} The number of listeners.\n\t * @public\n\t */\n\tEventEmitter.prototype.listenerCount = function listenerCount(event) {\n\t  var evt = prefix ? prefix + event : event\n\t    , listeners = this._events[evt];\n\n\t  if (!listeners) return 0;\n\t  if (listeners.fn) return 1;\n\t  return listeners.length;\n\t};\n\n\t/**\n\t * Calls each of the listeners registered for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @returns {Boolean} `true` if the event had listeners, else `false`.\n\t * @public\n\t */\n\tEventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\n\t  var evt = prefix ? prefix + event : event;\n\n\t  if (!this._events[evt]) return false;\n\n\t  var listeners = this._events[evt]\n\t    , len = arguments.length\n\t    , args\n\t    , i;\n\n\t  if (listeners.fn) {\n\t    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\n\n\t    switch (len) {\n\t      case 1: return listeners.fn.call(listeners.context), true;\n\t      case 2: return listeners.fn.call(listeners.context, a1), true;\n\t      case 3: return listeners.fn.call(listeners.context, a1, a2), true;\n\t      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;\n\t      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\n\t      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\n\t    }\n\n\t    for (i = 1, args = new Array(len -1); i < len; i++) {\n\t      args[i - 1] = arguments[i];\n\t    }\n\n\t    listeners.fn.apply(listeners.context, args);\n\t  } else {\n\t    var length = listeners.length\n\t      , j;\n\n\t    for (i = 0; i < length; i++) {\n\t      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\n\n\t      switch (len) {\n\t        case 1: listeners[i].fn.call(listeners[i].context); break;\n\t        case 2: listeners[i].fn.call(listeners[i].context, a1); break;\n\t        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;\n\t        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;\n\t        default:\n\t          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {\n\t            args[j - 1] = arguments[j];\n\t          }\n\n\t          listeners[i].fn.apply(listeners[i].context, args);\n\t      }\n\t    }\n\t  }\n\n\t  return true;\n\t};\n\n\t/**\n\t * Add a listener for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn The listener function.\n\t * @param {*} [context=this] The context to invoke the listener with.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.on = function on(event, fn, context) {\n\t  return addListener(this, event, fn, context, false);\n\t};\n\n\t/**\n\t * Add a one-time listener for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn The listener function.\n\t * @param {*} [context=this] The context to invoke the listener with.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.once = function once(event, fn, context) {\n\t  return addListener(this, event, fn, context, true);\n\t};\n\n\t/**\n\t * Remove the listeners of a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn Only remove the listeners that match this function.\n\t * @param {*} context Only remove the listeners that have this context.\n\t * @param {Boolean} once Only remove one-time listeners.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\n\t  var evt = prefix ? prefix + event : event;\n\n\t  if (!this._events[evt]) return this;\n\t  if (!fn) {\n\t    clearEvent(this, evt);\n\t    return this;\n\t  }\n\n\t  var listeners = this._events[evt];\n\n\t  if (listeners.fn) {\n\t    if (\n\t      listeners.fn === fn &&\n\t      (!once || listeners.once) &&\n\t      (!context || listeners.context === context)\n\t    ) {\n\t      clearEvent(this, evt);\n\t    }\n\t  } else {\n\t    for (var i = 0, events = [], length = listeners.length; i < length; i++) {\n\t      if (\n\t        listeners[i].fn !== fn ||\n\t        (once && !listeners[i].once) ||\n\t        (context && listeners[i].context !== context)\n\t      ) {\n\t        events.push(listeners[i]);\n\t      }\n\t    }\n\n\t    //\n\t    // Reset the array, or remove it completely if we have no more listeners.\n\t    //\n\t    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\n\t    else clearEvent(this, evt);\n\t  }\n\n\t  return this;\n\t};\n\n\t/**\n\t * Remove all listeners, or those of the specified event.\n\t *\n\t * @param {(String|Symbol)} [event] The event name.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\n\t  var evt;\n\n\t  if (event) {\n\t    evt = prefix ? prefix + event : event;\n\t    if (this._events[evt]) clearEvent(this, evt);\n\t  } else {\n\t    this._events = new Events();\n\t    this._eventsCount = 0;\n\t  }\n\n\t  return this;\n\t};\n\n\t//\n\t// Alias methods names because people roll like that.\n\t//\n\tEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\tEventEmitter.prototype.addListener = EventEmitter.prototype.on;\n\n\t//\n\t// Expose the prefix.\n\t//\n\tEventEmitter.prefixed = prefix;\n\n\t//\n\t// Allow `EventEmitter` to be imported as module namespace.\n\t//\n\tEventEmitter.EventEmitter = EventEmitter;\n\n\t//\n\t// Expose the module.\n\t//\n\t{\n\t  module.exports = EventEmitter;\n\t}\n} (eventemitter3));\n\nvar common$3 = {};\n\n/**\n * Check if we're required to add a port number.\n *\n * @see https://url.spec.whatwg.org/#default-port\n * @param {Number|String} port Port number we need to check\n * @param {String} protocol Protocol we need to check against.\n * @returns {Boolean} Is it a default port for the given protocol\n * @api private\n */\nvar requiresPort = function required(port, protocol) {\n  protocol = protocol.split(':')[0];\n  port = +port;\n\n  if (!port) return false;\n\n  switch (protocol) {\n    case 'http':\n    case 'ws':\n    return port !== 80;\n\n    case 'https':\n    case 'wss':\n    return port !== 443;\n\n    case 'ftp':\n    return port !== 21;\n\n    case 'gopher':\n    return port !== 70;\n\n    case 'file':\n    return false;\n  }\n\n  return port !== 0;\n};\n\n(function (exports) {\n\tvar common   = exports,\n\t    url      = require$$0$9,\n\t    extend   = require$$0$6._extend,\n\t    required = requiresPort;\n\n\tvar upgradeHeader = /(^|,)\\s*upgrade\\s*($|,)/i,\n\t    isSSL = /^https|wss/;\n\n\t/**\n\t * Simple Regex for testing if protocol is https\n\t */\n\tcommon.isSSL = isSSL;\n\t/**\n\t * Copies the right headers from `options` and `req` to\n\t * `outgoing` which is then used to fire the proxied\n\t * request.\n\t *\n\t * Examples:\n\t *\n\t *    common.setupOutgoing(outgoing, options, req)\n\t *    // => { host: ..., hostname: ...}\n\t *\n\t * @param {Object} Outgoing Base object to be filled with required properties\n\t * @param {Object} Options Config object passed to the proxy\n\t * @param {ClientRequest} Req Request Object\n\t * @param {String} Forward String to select forward or target\n\t * \n\t * @return {Object} Outgoing Object with all required properties set\n\t *\n\t * @api private\n\t */\n\n\tcommon.setupOutgoing = function(outgoing, options, req, forward) {\n\t  outgoing.port = options[forward || 'target'].port ||\n\t                  (isSSL.test(options[forward || 'target'].protocol) ? 443 : 80);\n\n\t  ['host', 'hostname', 'socketPath', 'pfx', 'key',\n\t    'passphrase', 'cert', 'ca', 'ciphers', 'secureProtocol'].forEach(\n\t    function(e) { outgoing[e] = options[forward || 'target'][e]; }\n\t  );\n\n\t  outgoing.method = options.method || req.method;\n\t  outgoing.headers = extend({}, req.headers);\n\n\t  if (options.headers){\n\t    extend(outgoing.headers, options.headers);\n\t  }\n\n\t  if (options.auth) {\n\t    outgoing.auth = options.auth;\n\t  }\n\t  \n\t  if (options.ca) {\n\t      outgoing.ca = options.ca;\n\t  }\n\n\t  if (isSSL.test(options[forward || 'target'].protocol)) {\n\t    outgoing.rejectUnauthorized = (typeof options.secure === \"undefined\") ? true : options.secure;\n\t  }\n\n\n\t  outgoing.agent = options.agent || false;\n\t  outgoing.localAddress = options.localAddress;\n\n\t  //\n\t  // Remark: If we are false and not upgrading, set the connection: close. This is the right thing to do\n\t  // as node core doesn't handle this COMPLETELY properly yet.\n\t  //\n\t  if (!outgoing.agent) {\n\t    outgoing.headers = outgoing.headers || {};\n\t    if (typeof outgoing.headers.connection !== 'string'\n\t        || !upgradeHeader.test(outgoing.headers.connection)\n\t       ) { outgoing.headers.connection = 'close'; }\n\t  }\n\n\n\t  // the final path is target path + relative path requested by user:\n\t  var target = options[forward || 'target'];\n\t  var targetPath = target && options.prependPath !== false\n\t    ? (target.path || '')\n\t    : '';\n\n\t  //\n\t  // Remark: Can we somehow not use url.parse as a perf optimization?\n\t  //\n\t  var outgoingPath = !options.toProxy\n\t    ? (url.parse(req.url).path || '')\n\t    : req.url;\n\n\t  //\n\t  // Remark: ignorePath will just straight up ignore whatever the request's\n\t  // path is. This can be labeled as FOOT-GUN material if you do not know what\n\t  // you are doing and are using conflicting options.\n\t  //\n\t  outgoingPath = !options.ignorePath ? outgoingPath : '';\n\n\t  outgoing.path = common.urlJoin(targetPath, outgoingPath);\n\n\t  if (options.changeOrigin) {\n\t    outgoing.headers.host =\n\t      required(outgoing.port, options[forward || 'target'].protocol) && !hasPort(outgoing.host)\n\t        ? outgoing.host + ':' + outgoing.port\n\t        : outgoing.host;\n\t  }\n\t  return outgoing;\n\t};\n\n\t/**\n\t * Set the proper configuration for sockets,\n\t * set no delay and set keep alive, also set\n\t * the timeout to 0.\n\t *\n\t * Examples:\n\t *\n\t *    common.setupSocket(socket)\n\t *    // => Socket\n\t *\n\t * @param {Socket} Socket instance to setup\n\t * \n\t * @return {Socket} Return the configured socket.\n\t *\n\t * @api private\n\t */\n\n\tcommon.setupSocket = function(socket) {\n\t  socket.setTimeout(0);\n\t  socket.setNoDelay(true);\n\n\t  socket.setKeepAlive(true, 0);\n\n\t  return socket;\n\t};\n\n\t/**\n\t * Get the port number from the host. Or guess it based on the connection type.\n\t *\n\t * @param {Request} req Incoming HTTP request.\n\t *\n\t * @return {String} The port number.\n\t *\n\t * @api private\n\t */\n\tcommon.getPort = function(req) {\n\t  var res = req.headers.host ? req.headers.host.match(/:(\\d+)/) : '';\n\n\t  return res ?\n\t    res[1] :\n\t    common.hasEncryptedConnection(req) ? '443' : '80';\n\t};\n\n\t/**\n\t * Check if the request has an encrypted connection.\n\t *\n\t * @param {Request} req Incoming HTTP request.\n\t *\n\t * @return {Boolean} Whether the connection is encrypted or not.\n\t *\n\t * @api private\n\t */\n\tcommon.hasEncryptedConnection = function(req) {\n\t  return Boolean(req.connection.encrypted || req.connection.pair);\n\t};\n\n\t/**\n\t * OS-agnostic join (doesn't break on URLs like path.join does on Windows)>\n\t *\n\t * @return {String} The generated path.\n\t *\n\t * @api private\n\t */\n\n\tcommon.urlJoin = function() {\n\t    //\n\t    // We do not want to mess with the query string. All we want to touch is the path.\n\t    //\n\t  var args = Array.prototype.slice.call(arguments),\n\t      lastIndex = args.length - 1,\n\t      last = args[lastIndex],\n\t      lastSegs = last.split('?'),\n\t      retSegs;\n\n\t  args[lastIndex] = lastSegs.shift();\n\n\t  //\n\t  // Join all strings, but remove empty strings so we don't get extra slashes from\n\t  // joining e.g. ['', 'am']\n\t  //\n\t  retSegs = [\n\t    args.filter(Boolean).join('/')\n\t        .replace(/\\/+/g, '/')\n\t        .replace('http:/', 'http://')\n\t        .replace('https:/', 'https://')\n\t  ];\n\n\t  // Only join the query string if it exists so we don't have trailing a '?'\n\t  // on every request\n\n\t  // Handle case where there could be multiple ? in the URL.\n\t  retSegs.push.apply(retSegs, lastSegs);\n\n\t  return retSegs.join('?')\n\t};\n\n\t/**\n\t * Rewrites or removes the domain of a cookie header\n\t *\n\t * @param {String|Array} Header\n\t * @param {Object} Config, mapping of domain to rewritten domain.\n\t *                 '*' key to match any domain, null value to remove the domain.\n\t *\n\t * @api private\n\t */\n\tcommon.rewriteCookieProperty = function rewriteCookieProperty(header, config, property) {\n\t  if (Array.isArray(header)) {\n\t    return header.map(function (headerElement) {\n\t      return rewriteCookieProperty(headerElement, config, property);\n\t    });\n\t  }\n\t  return header.replace(new RegExp(\"(;\\\\s*\" + property + \"=)([^;]+)\", 'i'), function(match, prefix, previousValue) {\n\t    var newValue;\n\t    if (previousValue in config) {\n\t      newValue = config[previousValue];\n\t    } else if ('*' in config) {\n\t      newValue = config['*'];\n\t    } else {\n\t      //no match, return previous value\n\t      return match;\n\t    }\n\t    if (newValue) {\n\t      //replace value\n\t      return prefix + newValue;\n\t    } else {\n\t      //remove value\n\t      return '';\n\t    }\n\t  });\n\t};\n\n\t/**\n\t * Check the host and see if it potentially has a port in it (keep it simple)\n\t *\n\t * @returns {Boolean} Whether we have one or not\n\t *\n\t * @api private\n\t */\n\tfunction hasPort(host) {\n\t  return !!~host.indexOf(':');\n\t}} (common$3));\n\nvar url$1    = require$$0$9,\n    common$2 = common$3;\n\n\nvar redirectRegex = /^201|30(1|2|7|8)$/;\n\n/*!\n * Array of passes.\n *\n * A `pass` is just a function that is executed on `req, res, options`\n * so that you can easily add new checks while still keeping the base\n * flexible.\n */\n\nvar webOutgoing = { // <--\n\n  /**\n   * If is a HTTP 1.0 request, remove chunk headers\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {proxyResponse} Res Response object from the proxy request\n   *\n   * @api private\n   */\n  removeChunked: function removeChunked(req, res, proxyRes) {\n    if (req.httpVersion === '1.0') {\n      delete proxyRes.headers['transfer-encoding'];\n    }\n  },\n\n  /**\n   * If is a HTTP 1.0 request, set the correct connection header\n   * or if connection header not present, then use `keep-alive`\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {proxyResponse} Res Response object from the proxy request\n   *\n   * @api private\n   */\n  setConnection: function setConnection(req, res, proxyRes) {\n    if (req.httpVersion === '1.0') {\n      proxyRes.headers.connection = req.headers.connection || 'close';\n    } else if (req.httpVersion !== '2.0' && !proxyRes.headers.connection) {\n      proxyRes.headers.connection = req.headers.connection || 'keep-alive';\n    }\n  },\n\n  setRedirectHostRewrite: function setRedirectHostRewrite(req, res, proxyRes, options) {\n    if ((options.hostRewrite || options.autoRewrite || options.protocolRewrite)\n        && proxyRes.headers['location']\n        && redirectRegex.test(proxyRes.statusCode)) {\n      var target = url$1.parse(options.target);\n      var u = url$1.parse(proxyRes.headers['location']);\n\n      // make sure the redirected host matches the target host before rewriting\n      if (target.host != u.host) {\n        return;\n      }\n\n      if (options.hostRewrite) {\n        u.host = options.hostRewrite;\n      } else if (options.autoRewrite) {\n        u.host = req.headers['host'];\n      }\n      if (options.protocolRewrite) {\n        u.protocol = options.protocolRewrite;\n      }\n\n      proxyRes.headers['location'] = u.format();\n    }\n  },\n  /**\n   * Copy headers from proxyResponse to response\n   * set each header in response object.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {proxyResponse} Res Response object from the proxy request\n   * @param {Object} Options options.cookieDomainRewrite: Config to rewrite cookie domain\n   *\n   * @api private\n   */\n  writeHeaders: function writeHeaders(req, res, proxyRes, options) {\n    var rewriteCookieDomainConfig = options.cookieDomainRewrite,\n        rewriteCookiePathConfig = options.cookiePathRewrite,\n        preserveHeaderKeyCase = options.preserveHeaderKeyCase,\n        rawHeaderKeyMap,\n        setHeader = function(key, header) {\n          if (header == undefined) return;\n          if (rewriteCookieDomainConfig && key.toLowerCase() === 'set-cookie') {\n            header = common$2.rewriteCookieProperty(header, rewriteCookieDomainConfig, 'domain');\n          }\n          if (rewriteCookiePathConfig && key.toLowerCase() === 'set-cookie') {\n            header = common$2.rewriteCookieProperty(header, rewriteCookiePathConfig, 'path');\n          }\n          res.setHeader(String(key).trim(), header);\n        };\n\n    if (typeof rewriteCookieDomainConfig === 'string') { //also test for ''\n      rewriteCookieDomainConfig = { '*': rewriteCookieDomainConfig };\n    }\n\n    if (typeof rewriteCookiePathConfig === 'string') { //also test for ''\n      rewriteCookiePathConfig = { '*': rewriteCookiePathConfig };\n    }\n\n    // message.rawHeaders is added in: v0.11.6\n    // https://nodejs.org/api/http.html#http_message_rawheaders\n    if (preserveHeaderKeyCase && proxyRes.rawHeaders != undefined) {\n      rawHeaderKeyMap = {};\n      for (var i = 0; i < proxyRes.rawHeaders.length; i += 2) {\n        var key = proxyRes.rawHeaders[i];\n        rawHeaderKeyMap[key.toLowerCase()] = key;\n      }\n    }\n\n    Object.keys(proxyRes.headers).forEach(function(key) {\n      var header = proxyRes.headers[key];\n      if (preserveHeaderKeyCase && rawHeaderKeyMap) {\n        key = rawHeaderKeyMap[key] || key;\n      }\n      setHeader(key, header);\n    });\n  },\n\n  /**\n   * Set the statusCode from the proxyResponse\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {proxyResponse} Res Response object from the proxy request\n   *\n   * @api private\n   */\n  writeStatusCode: function writeStatusCode(req, res, proxyRes) {\n    // From Node.js docs: response.writeHead(statusCode[, statusMessage][, headers])\n    if(proxyRes.statusMessage) {\n      res.statusCode = proxyRes.statusCode;\n      res.statusMessage = proxyRes.statusMessage;\n    } else {\n      res.statusCode = proxyRes.statusCode;\n    }\n  }\n\n};\n\nvar followRedirectsExports = {};\nvar followRedirects$1 = {\n  get exports(){ return followRedirectsExports; },\n  set exports(v){ followRedirectsExports = v; },\n};\n\nvar debug$3;\n\nvar debug_1 = function () {\n  if (!debug$3) {\n    try {\n      /* eslint global-require: off */\n      debug$3 = require(\"debug\")(\"follow-redirects\");\n    }\n    catch (error) { /* */ }\n    if (typeof debug$3 !== \"function\") {\n      debug$3 = function () { /* */ };\n    }\n  }\n  debug$3.apply(null, arguments);\n};\n\nvar url = require$$0$9;\nvar URL$1 = url.URL;\nvar http$1 = require$$1$1;\nvar https$1 = require$$1$2;\nvar Writable = require$$0$7.Writable;\nvar assert = require$$5;\nvar debug$2 = debug_1;\n\n// Create handlers that pass events from native requests\nvar events = [\"abort\", \"aborted\", \"connect\", \"error\", \"socket\", \"timeout\"];\nvar eventHandlers = Object.create(null);\nevents.forEach(function (event) {\n  eventHandlers[event] = function (arg1, arg2, arg3) {\n    this._redirectable.emit(event, arg1, arg2, arg3);\n  };\n});\n\n// Error types with codes\nvar RedirectionError = createErrorType(\n  \"ERR_FR_REDIRECTION_FAILURE\",\n  \"Redirected request failed\"\n);\nvar TooManyRedirectsError = createErrorType(\n  \"ERR_FR_TOO_MANY_REDIRECTS\",\n  \"Maximum number of redirects exceeded\"\n);\nvar MaxBodyLengthExceededError = createErrorType(\n  \"ERR_FR_MAX_BODY_LENGTH_EXCEEDED\",\n  \"Request body larger than maxBodyLength limit\"\n);\nvar WriteAfterEndError = createErrorType(\n  \"ERR_STREAM_WRITE_AFTER_END\",\n  \"write after end\"\n);\n\n// An HTTP(S) request that can be redirected\nfunction RedirectableRequest(options, responseCallback) {\n  // Initialize the request\n  Writable.call(this);\n  this._sanitizeOptions(options);\n  this._options = options;\n  this._ended = false;\n  this._ending = false;\n  this._redirectCount = 0;\n  this._redirects = [];\n  this._requestBodyLength = 0;\n  this._requestBodyBuffers = [];\n\n  // Attach a callback if passed\n  if (responseCallback) {\n    this.on(\"response\", responseCallback);\n  }\n\n  // React to responses of native requests\n  var self = this;\n  this._onNativeResponse = function (response) {\n    self._processResponse(response);\n  };\n\n  // Perform the first request\n  this._performRequest();\n}\nRedirectableRequest.prototype = Object.create(Writable.prototype);\n\nRedirectableRequest.prototype.abort = function () {\n  abortRequest(this._currentRequest);\n  this.emit(\"abort\");\n};\n\n// Writes buffered data to the current native request\nRedirectableRequest.prototype.write = function (data, encoding, callback) {\n  // Writing is not allowed if end has been called\n  if (this._ending) {\n    throw new WriteAfterEndError();\n  }\n\n  // Validate input and shift parameters if necessary\n  if (!(typeof data === \"string\" || typeof data === \"object\" && (\"length\" in data))) {\n    throw new TypeError(\"data should be a string, Buffer or Uint8Array\");\n  }\n  if (typeof encoding === \"function\") {\n    callback = encoding;\n    encoding = null;\n  }\n\n  // Ignore empty buffers, since writing them doesn't invoke the callback\n  // https://github.com/nodejs/node/issues/22066\n  if (data.length === 0) {\n    if (callback) {\n      callback();\n    }\n    return;\n  }\n  // Only write when we don't exceed the maximum body length\n  if (this._requestBodyLength + data.length <= this._options.maxBodyLength) {\n    this._requestBodyLength += data.length;\n    this._requestBodyBuffers.push({ data: data, encoding: encoding });\n    this._currentRequest.write(data, encoding, callback);\n  }\n  // Error when we exceed the maximum body length\n  else {\n    this.emit(\"error\", new MaxBodyLengthExceededError());\n    this.abort();\n  }\n};\n\n// Ends the current native request\nRedirectableRequest.prototype.end = function (data, encoding, callback) {\n  // Shift parameters if necessary\n  if (typeof data === \"function\") {\n    callback = data;\n    data = encoding = null;\n  }\n  else if (typeof encoding === \"function\") {\n    callback = encoding;\n    encoding = null;\n  }\n\n  // Write data if needed and end\n  if (!data) {\n    this._ended = this._ending = true;\n    this._currentRequest.end(null, null, callback);\n  }\n  else {\n    var self = this;\n    var currentRequest = this._currentRequest;\n    this.write(data, encoding, function () {\n      self._ended = true;\n      currentRequest.end(null, null, callback);\n    });\n    this._ending = true;\n  }\n};\n\n// Sets a header value on the current native request\nRedirectableRequest.prototype.setHeader = function (name, value) {\n  this._options.headers[name] = value;\n  this._currentRequest.setHeader(name, value);\n};\n\n// Clears a header value on the current native request\nRedirectableRequest.prototype.removeHeader = function (name) {\n  delete this._options.headers[name];\n  this._currentRequest.removeHeader(name);\n};\n\n// Global timeout for all underlying requests\nRedirectableRequest.prototype.setTimeout = function (msecs, callback) {\n  var self = this;\n\n  // Destroys the socket on timeout\n  function destroyOnTimeout(socket) {\n    socket.setTimeout(msecs);\n    socket.removeListener(\"timeout\", socket.destroy);\n    socket.addListener(\"timeout\", socket.destroy);\n  }\n\n  // Sets up a timer to trigger a timeout event\n  function startTimer(socket) {\n    if (self._timeout) {\n      clearTimeout(self._timeout);\n    }\n    self._timeout = setTimeout(function () {\n      self.emit(\"timeout\");\n      clearTimer();\n    }, msecs);\n    destroyOnTimeout(socket);\n  }\n\n  // Stops a timeout from triggering\n  function clearTimer() {\n    // Clear the timeout\n    if (self._timeout) {\n      clearTimeout(self._timeout);\n      self._timeout = null;\n    }\n\n    // Clean up all attached listeners\n    self.removeListener(\"abort\", clearTimer);\n    self.removeListener(\"error\", clearTimer);\n    self.removeListener(\"response\", clearTimer);\n    if (callback) {\n      self.removeListener(\"timeout\", callback);\n    }\n    if (!self.socket) {\n      self._currentRequest.removeListener(\"socket\", startTimer);\n    }\n  }\n\n  // Attach callback if passed\n  if (callback) {\n    this.on(\"timeout\", callback);\n  }\n\n  // Start the timer if or when the socket is opened\n  if (this.socket) {\n    startTimer(this.socket);\n  }\n  else {\n    this._currentRequest.once(\"socket\", startTimer);\n  }\n\n  // Clean up on events\n  this.on(\"socket\", destroyOnTimeout);\n  this.on(\"abort\", clearTimer);\n  this.on(\"error\", clearTimer);\n  this.on(\"response\", clearTimer);\n\n  return this;\n};\n\n// Proxy all other public ClientRequest methods\n[\n  \"flushHeaders\", \"getHeader\",\n  \"setNoDelay\", \"setSocketKeepAlive\",\n].forEach(function (method) {\n  RedirectableRequest.prototype[method] = function (a, b) {\n    return this._currentRequest[method](a, b);\n  };\n});\n\n// Proxy all public ClientRequest properties\n[\"aborted\", \"connection\", \"socket\"].forEach(function (property) {\n  Object.defineProperty(RedirectableRequest.prototype, property, {\n    get: function () { return this._currentRequest[property]; },\n  });\n});\n\nRedirectableRequest.prototype._sanitizeOptions = function (options) {\n  // Ensure headers are always present\n  if (!options.headers) {\n    options.headers = {};\n  }\n\n  // Since http.request treats host as an alias of hostname,\n  // but the url module interprets host as hostname plus port,\n  // eliminate the host property to avoid confusion.\n  if (options.host) {\n    // Use hostname if set, because it has precedence\n    if (!options.hostname) {\n      options.hostname = options.host;\n    }\n    delete options.host;\n  }\n\n  // Complete the URL object when necessary\n  if (!options.pathname && options.path) {\n    var searchPos = options.path.indexOf(\"?\");\n    if (searchPos < 0) {\n      options.pathname = options.path;\n    }\n    else {\n      options.pathname = options.path.substring(0, searchPos);\n      options.search = options.path.substring(searchPos);\n    }\n  }\n};\n\n\n// Executes the next native request (initial or redirect)\nRedirectableRequest.prototype._performRequest = function () {\n  // Load the native protocol\n  var protocol = this._options.protocol;\n  var nativeProtocol = this._options.nativeProtocols[protocol];\n  if (!nativeProtocol) {\n    this.emit(\"error\", new TypeError(\"Unsupported protocol \" + protocol));\n    return;\n  }\n\n  // If specified, use the agent corresponding to the protocol\n  // (HTTP and HTTPS use different types of agents)\n  if (this._options.agents) {\n    var scheme = protocol.slice(0, -1);\n    this._options.agent = this._options.agents[scheme];\n  }\n\n  // Create the native request\n  var request = this._currentRequest =\n        nativeProtocol.request(this._options, this._onNativeResponse);\n  this._currentUrl = url.format(this._options);\n\n  // Set up event handlers\n  request._redirectable = this;\n  for (var e = 0; e < events.length; e++) {\n    request.on(events[e], eventHandlers[events[e]]);\n  }\n\n  // End a redirected request\n  // (The first request must be ended explicitly with RedirectableRequest#end)\n  if (this._isRedirect) {\n    // Write the request entity and end.\n    var i = 0;\n    var self = this;\n    var buffers = this._requestBodyBuffers;\n    (function writeNext(error) {\n      // Only write if this request has not been redirected yet\n      /* istanbul ignore else */\n      if (request === self._currentRequest) {\n        // Report any write errors\n        /* istanbul ignore if */\n        if (error) {\n          self.emit(\"error\", error);\n        }\n        // Write the next buffer if there are still left\n        else if (i < buffers.length) {\n          var buffer = buffers[i++];\n          /* istanbul ignore else */\n          if (!request.finished) {\n            request.write(buffer.data, buffer.encoding, writeNext);\n          }\n        }\n        // End the request if `end` has been called on us\n        else if (self._ended) {\n          request.end();\n        }\n      }\n    }());\n  }\n};\n\n// Processes a response from the current native request\nRedirectableRequest.prototype._processResponse = function (response) {\n  // Store the redirected response\n  var statusCode = response.statusCode;\n  if (this._options.trackRedirects) {\n    this._redirects.push({\n      url: this._currentUrl,\n      headers: response.headers,\n      statusCode: statusCode,\n    });\n  }\n\n  // RFC7231§6.4: The 3xx (Redirection) class of status code indicates\n  // that further action needs to be taken by the user agent in order to\n  // fulfill the request. If a Location header field is provided,\n  // the user agent MAY automatically redirect its request to the URI\n  // referenced by the Location field value,\n  // even if the specific status code is not understood.\n\n  // If the response is not a redirect; return it as-is\n  var location = response.headers.location;\n  if (!location || this._options.followRedirects === false ||\n      statusCode < 300 || statusCode >= 400) {\n    response.responseUrl = this._currentUrl;\n    response.redirects = this._redirects;\n    this.emit(\"response\", response);\n\n    // Clean up\n    this._requestBodyBuffers = [];\n    return;\n  }\n\n  // The response is a redirect, so abort the current request\n  abortRequest(this._currentRequest);\n  // Discard the remainder of the response to avoid waiting for data\n  response.destroy();\n\n  // RFC7231§6.4: A client SHOULD detect and intervene\n  // in cyclical redirections (i.e., \"infinite\" redirection loops).\n  if (++this._redirectCount > this._options.maxRedirects) {\n    this.emit(\"error\", new TooManyRedirectsError());\n    return;\n  }\n\n  // Store the request headers if applicable\n  var requestHeaders;\n  var beforeRedirect = this._options.beforeRedirect;\n  if (beforeRedirect) {\n    requestHeaders = Object.assign({\n      // The Host header was set by nativeProtocol.request\n      Host: response.req.getHeader(\"host\"),\n    }, this._options.headers);\n  }\n\n  // RFC7231§6.4: Automatic redirection needs to done with\n  // care for methods not known to be safe, […]\n  // RFC7231§6.4.2–3: For historical reasons, a user agent MAY change\n  // the request method from POST to GET for the subsequent request.\n  var method = this._options.method;\n  if ((statusCode === 301 || statusCode === 302) && this._options.method === \"POST\" ||\n      // RFC7231§6.4.4: The 303 (See Other) status code indicates that\n      // the server is redirecting the user agent to a different resource […]\n      // A user agent can perform a retrieval request targeting that URI\n      // (a GET or HEAD request if using HTTP) […]\n      (statusCode === 303) && !/^(?:GET|HEAD)$/.test(this._options.method)) {\n    this._options.method = \"GET\";\n    // Drop a possible entity and headers related to it\n    this._requestBodyBuffers = [];\n    removeMatchingHeaders(/^content-/i, this._options.headers);\n  }\n\n  // Drop the Host header, as the redirect might lead to a different host\n  var currentHostHeader = removeMatchingHeaders(/^host$/i, this._options.headers);\n\n  // If the redirect is relative, carry over the host of the last request\n  var currentUrlParts = url.parse(this._currentUrl);\n  var currentHost = currentHostHeader || currentUrlParts.host;\n  var currentUrl = /^\\w+:/.test(location) ? this._currentUrl :\n    url.format(Object.assign(currentUrlParts, { host: currentHost }));\n\n  // Determine the URL of the redirection\n  var redirectUrl;\n  try {\n    redirectUrl = url.resolve(currentUrl, location);\n  }\n  catch (cause) {\n    this.emit(\"error\", new RedirectionError(cause));\n    return;\n  }\n\n  // Create the redirected request\n  debug$2(\"redirecting to\", redirectUrl);\n  this._isRedirect = true;\n  var redirectUrlParts = url.parse(redirectUrl);\n  Object.assign(this._options, redirectUrlParts);\n\n  // Drop confidential headers when redirecting to a less secure protocol\n  // or to a different domain that is not a superdomain\n  if (redirectUrlParts.protocol !== currentUrlParts.protocol &&\n     redirectUrlParts.protocol !== \"https:\" ||\n     redirectUrlParts.host !== currentHost &&\n     !isSubdomain(redirectUrlParts.host, currentHost)) {\n    removeMatchingHeaders(/^(?:authorization|cookie)$/i, this._options.headers);\n  }\n\n  // Evaluate the beforeRedirect callback\n  if (typeof beforeRedirect === \"function\") {\n    var responseDetails = {\n      headers: response.headers,\n      statusCode: statusCode,\n    };\n    var requestDetails = {\n      url: currentUrl,\n      method: method,\n      headers: requestHeaders,\n    };\n    try {\n      beforeRedirect(this._options, responseDetails, requestDetails);\n    }\n    catch (err) {\n      this.emit(\"error\", err);\n      return;\n    }\n    this._sanitizeOptions(this._options);\n  }\n\n  // Perform the redirected request\n  try {\n    this._performRequest();\n  }\n  catch (cause) {\n    this.emit(\"error\", new RedirectionError(cause));\n  }\n};\n\n// Wraps the key/value object of protocols with redirect functionality\nfunction wrap(protocols) {\n  // Default settings\n  var exports = {\n    maxRedirects: 21,\n    maxBodyLength: 10 * 1024 * 1024,\n  };\n\n  // Wrap each protocol\n  var nativeProtocols = {};\n  Object.keys(protocols).forEach(function (scheme) {\n    var protocol = scheme + \":\";\n    var nativeProtocol = nativeProtocols[protocol] = protocols[scheme];\n    var wrappedProtocol = exports[scheme] = Object.create(nativeProtocol);\n\n    // Executes a request, following redirects\n    function request(input, options, callback) {\n      // Parse parameters\n      if (typeof input === \"string\") {\n        var urlStr = input;\n        try {\n          input = urlToOptions(new URL$1(urlStr));\n        }\n        catch (err) {\n          /* istanbul ignore next */\n          input = url.parse(urlStr);\n        }\n      }\n      else if (URL$1 && (input instanceof URL$1)) {\n        input = urlToOptions(input);\n      }\n      else {\n        callback = options;\n        options = input;\n        input = { protocol: protocol };\n      }\n      if (typeof options === \"function\") {\n        callback = options;\n        options = null;\n      }\n\n      // Set defaults\n      options = Object.assign({\n        maxRedirects: exports.maxRedirects,\n        maxBodyLength: exports.maxBodyLength,\n      }, input, options);\n      options.nativeProtocols = nativeProtocols;\n\n      assert.equal(options.protocol, protocol, \"protocol mismatch\");\n      debug$2(\"options\", options);\n      return new RedirectableRequest(options, callback);\n    }\n\n    // Executes a GET request, following redirects\n    function get(input, options, callback) {\n      var wrappedRequest = wrappedProtocol.request(input, options, callback);\n      wrappedRequest.end();\n      return wrappedRequest;\n    }\n\n    // Expose the properties on the wrapped protocol\n    Object.defineProperties(wrappedProtocol, {\n      request: { value: request, configurable: true, enumerable: true, writable: true },\n      get: { value: get, configurable: true, enumerable: true, writable: true },\n    });\n  });\n  return exports;\n}\n\n/* istanbul ignore next */\nfunction noop$1() { /* empty */ }\n\n// from https://github.com/nodejs/node/blob/master/lib/internal/url.js\nfunction urlToOptions(urlObject) {\n  var options = {\n    protocol: urlObject.protocol,\n    hostname: urlObject.hostname.startsWith(\"[\") ?\n      /* istanbul ignore next */\n      urlObject.hostname.slice(1, -1) :\n      urlObject.hostname,\n    hash: urlObject.hash,\n    search: urlObject.search,\n    pathname: urlObject.pathname,\n    path: urlObject.pathname + urlObject.search,\n    href: urlObject.href,\n  };\n  if (urlObject.port !== \"\") {\n    options.port = Number(urlObject.port);\n  }\n  return options;\n}\n\nfunction removeMatchingHeaders(regex, headers) {\n  var lastValue;\n  for (var header in headers) {\n    if (regex.test(header)) {\n      lastValue = headers[header];\n      delete headers[header];\n    }\n  }\n  return (lastValue === null || typeof lastValue === \"undefined\") ?\n    undefined : String(lastValue).trim();\n}\n\nfunction createErrorType(code, defaultMessage) {\n  function CustomError(cause) {\n    Error.captureStackTrace(this, this.constructor);\n    if (!cause) {\n      this.message = defaultMessage;\n    }\n    else {\n      this.message = defaultMessage + \": \" + cause.message;\n      this.cause = cause;\n    }\n  }\n  CustomError.prototype = new Error();\n  CustomError.prototype.constructor = CustomError;\n  CustomError.prototype.name = \"Error [\" + code + \"]\";\n  CustomError.prototype.code = code;\n  return CustomError;\n}\n\nfunction abortRequest(request) {\n  for (var e = 0; e < events.length; e++) {\n    request.removeListener(events[e], eventHandlers[events[e]]);\n  }\n  request.on(\"error\", noop$1);\n  request.abort();\n}\n\nfunction isSubdomain(subdomain, domain) {\n  const dot = subdomain.length - domain.length - 1;\n  return dot > 0 && subdomain[dot] === \".\" && subdomain.endsWith(domain);\n}\n\n// Exports\nfollowRedirects$1.exports = wrap({ http: http$1, https: https$1 });\nfollowRedirectsExports.wrap = wrap;\n\nvar httpNative   = require$$1$1,\n    httpsNative  = require$$1$2,\n    web_o  = webOutgoing,\n    common$1 = common$3,\n    followRedirects = followRedirectsExports;\n\nweb_o = Object.keys(web_o).map(function(pass) {\n  return web_o[pass];\n});\n\nvar nativeAgents = { http: httpNative, https: httpsNative };\n\n/*!\n * Array of passes.\n *\n * A `pass` is just a function that is executed on `req, res, options`\n * so that you can easily add new checks while still keeping the base\n * flexible.\n */\n\n\nvar webIncoming = {\n\n  /**\n   * Sets `content-length` to '0' if request is of DELETE type.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {Object} Options Config object passed to the proxy\n   *\n   * @api private\n   */\n\n  deleteLength: function deleteLength(req, res, options) {\n    if((req.method === 'DELETE' || req.method === 'OPTIONS')\n       && !req.headers['content-length']) {\n      req.headers['content-length'] = '0';\n      delete req.headers['transfer-encoding'];\n    }\n  },\n\n  /**\n   * Sets timeout in request socket if it was specified in options.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {Object} Options Config object passed to the proxy\n   *\n   * @api private\n   */\n\n  timeout: function timeout(req, res, options) {\n    if(options.timeout) {\n      req.socket.setTimeout(options.timeout);\n    }\n  },\n\n  /**\n   * Sets `x-forwarded-*` headers if specified in config.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {Object} Options Config object passed to the proxy\n   *\n   * @api private\n   */\n\n  XHeaders: function XHeaders(req, res, options) {\n    if(!options.xfwd) return;\n\n    var encrypted = req.isSpdy || common$1.hasEncryptedConnection(req);\n    var values = {\n      for  : req.connection.remoteAddress || req.socket.remoteAddress,\n      port : common$1.getPort(req),\n      proto: encrypted ? 'https' : 'http'\n    };\n\n    ['for', 'port', 'proto'].forEach(function(header) {\n      req.headers['x-forwarded-' + header] =\n        (req.headers['x-forwarded-' + header] || '') +\n        (req.headers['x-forwarded-' + header] ? ',' : '') +\n        values[header];\n    });\n\n    req.headers['x-forwarded-host'] = req.headers['x-forwarded-host'] || req.headers['host'] || '';\n  },\n\n  /**\n   * Does the actual proxying. If `forward` is enabled fires up\n   * a ForwardStream, same happens for ProxyStream. The request\n   * just dies otherwise.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {IncomingMessage} Res Response object\n   * @param {Object} Options Config object passed to the proxy\n   *\n   * @api private\n   */\n\n  stream: function stream(req, res, options, _, server, clb) {\n\n    // And we begin!\n    server.emit('start', req, res, options.target || options.forward);\n\n    var agents = options.followRedirects ? followRedirects : nativeAgents;\n    var http = agents.http;\n    var https = agents.https;\n\n    if(options.forward) {\n      // If forward enable, so just pipe the request\n      var forwardReq = (options.forward.protocol === 'https:' ? https : http).request(\n        common$1.setupOutgoing(options.ssl || {}, options, req, 'forward')\n      );\n\n      // error handler (e.g. ECONNRESET, ECONNREFUSED)\n      // Handle errors on incoming request as well as it makes sense to\n      var forwardError = createErrorHandler(forwardReq, options.forward);\n      req.on('error', forwardError);\n      forwardReq.on('error', forwardError);\n\n      (options.buffer || req).pipe(forwardReq);\n      if(!options.target) { return res.end(); }\n    }\n\n    // Request initalization\n    var proxyReq = (options.target.protocol === 'https:' ? https : http).request(\n      common$1.setupOutgoing(options.ssl || {}, options, req)\n    );\n\n    // Enable developers to modify the proxyReq before headers are sent\n    proxyReq.on('socket', function(socket) {\n      if(server && !proxyReq.getHeader('expect')) {\n        server.emit('proxyReq', proxyReq, req, res, options);\n      }\n    });\n\n    // allow outgoing socket to timeout so that we could\n    // show an error page at the initial request\n    if(options.proxyTimeout) {\n      proxyReq.setTimeout(options.proxyTimeout, function() {\n         proxyReq.abort();\n      });\n    }\n\n    // Ensure we abort proxy if request is aborted\n    req.on('aborted', function () {\n      proxyReq.abort();\n    });\n\n    // handle errors in proxy and incoming request, just like for forward proxy\n    var proxyError = createErrorHandler(proxyReq, options.target);\n    req.on('error', proxyError);\n    proxyReq.on('error', proxyError);\n\n    function createErrorHandler(proxyReq, url) {\n      return function proxyError(err) {\n        if (req.socket.destroyed && err.code === 'ECONNRESET') {\n          server.emit('econnreset', err, req, res, url);\n          return proxyReq.abort();\n        }\n\n        if (clb) {\n          clb(err, req, res, url);\n        } else {\n          server.emit('error', err, req, res, url);\n        }\n      }\n    }\n\n    (options.buffer || req).pipe(proxyReq);\n\n    proxyReq.on('response', function(proxyRes) {\n      if(server) { server.emit('proxyRes', proxyRes, req, res); }\n\n      if(!res.headersSent && !options.selfHandleResponse) {\n        for(var i=0; i < web_o.length; i++) {\n          if(web_o[i](req, res, proxyRes, options)) { break; }\n        }\n      }\n\n      if (!res.finished) {\n        // Allow us to listen when the proxy has completed\n        proxyRes.on('end', function () {\n          if (server) server.emit('end', req, res, proxyRes);\n        });\n        // We pipe to the response unless its expected to be handled by the user\n        if (!options.selfHandleResponse) proxyRes.pipe(res);\n      } else {\n        if (server) server.emit('end', req, res, proxyRes);\n      }\n    });\n  }\n\n};\n\nvar http   = require$$1$1,\n    https  = require$$1$2,\n    common = common$3;\n\n/*!\n * Array of passes.\n *\n * A `pass` is just a function that is executed on `req, socket, options`\n * so that you can easily add new checks while still keeping the base\n * flexible.\n */\n\n/*\n * Websockets Passes\n *\n */\n\n\nvar wsIncoming = {\n  /**\n   * WebSocket requests must have the `GET` method and\n   * the `upgrade:websocket` header\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {Socket} Websocket\n   *\n   * @api private\n   */\n\n  checkMethodAndHeader : function checkMethodAndHeader(req, socket) {\n    if (req.method !== 'GET' || !req.headers.upgrade) {\n      socket.destroy();\n      return true;\n    }\n\n    if (req.headers.upgrade.toLowerCase() !== 'websocket') {\n      socket.destroy();\n      return true;\n    }\n  },\n\n  /**\n   * Sets `x-forwarded-*` headers if specified in config.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {Socket} Websocket\n   * @param {Object} Options Config object passed to the proxy\n   *\n   * @api private\n   */\n\n  XHeaders : function XHeaders(req, socket, options) {\n    if(!options.xfwd) return;\n\n    var values = {\n      for  : req.connection.remoteAddress || req.socket.remoteAddress,\n      port : common.getPort(req),\n      proto: common.hasEncryptedConnection(req) ? 'wss' : 'ws'\n    };\n\n    ['for', 'port', 'proto'].forEach(function(header) {\n      req.headers['x-forwarded-' + header] =\n        (req.headers['x-forwarded-' + header] || '') +\n        (req.headers['x-forwarded-' + header] ? ',' : '') +\n        values[header];\n    });\n  },\n\n  /**\n   * Does the actual proxying. Make the request and upgrade it\n   * send the Switching Protocols request and pipe the sockets.\n   *\n   * @param {ClientRequest} Req Request object\n   * @param {Socket} Websocket\n   * @param {Object} Options Config object passed to the proxy\n   *\n   * @api private\n   */\n  stream : function stream(req, socket, options, head, server, clb) {\n\n    var createHttpHeader = function(line, headers) {\n      return Object.keys(headers).reduce(function (head, key) {\n        var value = headers[key];\n\n        if (!Array.isArray(value)) {\n          head.push(key + ': ' + value);\n          return head;\n        }\n\n        for (var i = 0; i < value.length; i++) {\n          head.push(key + ': ' + value[i]);\n        }\n        return head;\n      }, [line])\n      .join('\\r\\n') + '\\r\\n\\r\\n';\n    };\n\n    common.setupSocket(socket);\n\n    if (head && head.length) socket.unshift(head);\n\n\n    var proxyReq = (common.isSSL.test(options.target.protocol) ? https : http).request(\n      common.setupOutgoing(options.ssl || {}, options, req)\n    );\n\n    // Enable developers to modify the proxyReq before headers are sent\n    if (server) { server.emit('proxyReqWs', proxyReq, req, socket, options, head); }\n\n    // Error Handler\n    proxyReq.on('error', onOutgoingError);\n    proxyReq.on('response', function (res) {\n      // if upgrade event isn't going to happen, close the socket\n      if (!res.upgrade) {\n        socket.write(createHttpHeader('HTTP/' + res.httpVersion + ' ' + res.statusCode + ' ' + res.statusMessage, res.headers));\n        res.pipe(socket);\n      }\n    });\n\n    proxyReq.on('upgrade', function(proxyRes, proxySocket, proxyHead) {\n      proxySocket.on('error', onOutgoingError);\n\n      // Allow us to listen when the websocket has completed\n      proxySocket.on('end', function () {\n        server.emit('close', proxyRes, proxySocket, proxyHead);\n      });\n\n      // The pipe below will end proxySocket if socket closes cleanly, but not\n      // if it errors (eg, vanishes from the net and starts returning\n      // EHOSTUNREACH). We need to do that explicitly.\n      socket.on('error', function () {\n        proxySocket.end();\n      });\n\n      common.setupSocket(proxySocket);\n\n      if (proxyHead && proxyHead.length) proxySocket.unshift(proxyHead);\n\n      //\n      // Remark: Handle writing the headers to the socket when switching protocols\n      // Also handles when a header is an array\n      //\n      socket.write(createHttpHeader('HTTP/1.1 101 Switching Protocols', proxyRes.headers));\n\n      proxySocket.pipe(socket).pipe(proxySocket);\n\n      server.emit('open', proxySocket);\n      server.emit('proxySocket', proxySocket);  //DEPRECATED.\n    });\n\n    return proxyReq.end(); // XXX: CHECK IF THIS IS THIS CORRECT\n\n    function onOutgoingError(err) {\n      if (clb) {\n        clb(err, req, socket);\n      } else {\n        server.emit('error', err, req, socket);\n      }\n      socket.end();\n    }\n  }\n};\n\n(function (module) {\n\tvar httpProxy = module.exports,\n\t    extend    = require$$0$6._extend,\n\t    parse_url = require$$0$9.parse,\n\t    EE3       = eventemitter3Exports,\n\t    http      = require$$1$1,\n\t    https     = require$$1$2,\n\t    web       = webIncoming,\n\t    ws        = wsIncoming;\n\n\thttpProxy.Server = ProxyServer;\n\n\t/**\n\t * Returns a function that creates the loader for\n\t * either `ws` or `web`'s  passes.\n\t *\n\t * Examples:\n\t *\n\t *    httpProxy.createRightProxy('ws')\n\t *    // => [Function]\n\t *\n\t * @param {String} Type Either 'ws' or 'web'\n\t * \n\t * @return {Function} Loader Function that when called returns an iterator for the right passes\n\t *\n\t * @api private\n\t */\n\n\tfunction createRightProxy(type) {\n\n\t  return function(options) {\n\t    return function(req, res /*, [head], [opts] */) {\n\t      var passes = (type === 'ws') ? this.wsPasses : this.webPasses,\n\t          args = [].slice.call(arguments),\n\t          cntr = args.length - 1,\n\t          head, cbl;\n\n\t      /* optional args parse begin */\n\t      if(typeof args[cntr] === 'function') {\n\t        cbl = args[cntr];\n\n\t        cntr--;\n\t      }\n\n\t      var requestOptions = options;\n\t      if(\n\t        !(args[cntr] instanceof Buffer) &&\n\t        args[cntr] !== res\n\t      ) {\n\t        //Copy global options\n\t        requestOptions = extend({}, options);\n\t        //Overwrite with request options\n\t        extend(requestOptions, args[cntr]);\n\n\t        cntr--;\n\t      }\n\n\t      if(args[cntr] instanceof Buffer) {\n\t        head = args[cntr];\n\t      }\n\n\t      /* optional args parse end */\n\n\t      ['target', 'forward'].forEach(function(e) {\n\t        if (typeof requestOptions[e] === 'string')\n\t          requestOptions[e] = parse_url(requestOptions[e]);\n\t      });\n\n\t      if (!requestOptions.target && !requestOptions.forward) {\n\t        return this.emit('error', new Error('Must provide a proper URL as target'));\n\t      }\n\n\t      for(var i=0; i < passes.length; i++) {\n\t        /**\n\t         * Call of passes functions\n\t         * pass(req, res, options, head)\n\t         *\n\t         * In WebSockets case the `res` variable\n\t         * refer to the connection socket\n\t         * pass(req, socket, options, head)\n\t         */\n\t        if(passes[i](req, res, requestOptions, head, this, cbl)) { // passes can return a truthy value to halt the loop\n\t          break;\n\t        }\n\t      }\n\t    };\n\t  };\n\t}\n\thttpProxy.createRightProxy = createRightProxy;\n\n\tfunction ProxyServer(options) {\n\t  EE3.call(this);\n\n\t  options = options || {};\n\t  options.prependPath = options.prependPath === false ? false : true;\n\n\t  this.web = this.proxyRequest           = createRightProxy('web')(options);\n\t  this.ws  = this.proxyWebsocketRequest  = createRightProxy('ws')(options);\n\t  this.options = options;\n\n\t  this.webPasses = Object.keys(web).map(function(pass) {\n\t    return web[pass];\n\t  });\n\n\t  this.wsPasses = Object.keys(ws).map(function(pass) {\n\t    return ws[pass];\n\t  });\n\n\t  this.on('error', this.onError, this);\n\n\t}\n\n\trequire$$0$6.inherits(ProxyServer, EE3);\n\n\tProxyServer.prototype.onError = function (err) {\n\t  //\n\t  // Remark: Replicate node core behavior using EE3\n\t  // so we force people to handle their own errors\n\t  //\n\t  if(this.listeners('error').length === 1) {\n\t    throw err;\n\t  }\n\t};\n\n\tProxyServer.prototype.listen = function(port, hostname) {\n\t  var self    = this,\n\t      closure = function(req, res) { self.web(req, res); };\n\n\t  this._server  = this.options.ssl ?\n\t    https.createServer(this.options.ssl, closure) :\n\t    http.createServer(closure);\n\n\t  if(this.options.ws) {\n\t    this._server.on('upgrade', function(req, socket, head) { self.ws(req, socket, head); });\n\t  }\n\n\t  this._server.listen(port, hostname);\n\n\t  return this;\n\t};\n\n\tProxyServer.prototype.close = function(callback) {\n\t  var self = this;\n\t  if (this._server) {\n\t    this._server.close(done);\n\t  }\n\n\t  // Wrap callback to nullify server after all open connections are closed.\n\t  function done() {\n\t    self._server = null;\n\t    if (callback) {\n\t      callback.apply(null, arguments);\n\t    }\n\t  }\t};\n\n\tProxyServer.prototype.before = function(type, passName, callback) {\n\t  if (type !== 'ws' && type !== 'web') {\n\t    throw new Error('type must be `web` or `ws`');\n\t  }\n\t  var passes = (type === 'ws') ? this.wsPasses : this.webPasses,\n\t      i = false;\n\n\t  passes.forEach(function(v, idx) {\n\t    if(v.name === passName) i = idx;\n\t  });\n\n\t  if(i === false) throw new Error('No such pass');\n\n\t  passes.splice(i, 0, callback);\n\t};\n\tProxyServer.prototype.after = function(type, passName, callback) {\n\t  if (type !== 'ws' && type !== 'web') {\n\t    throw new Error('type must be `web` or `ws`');\n\t  }\n\t  var passes = (type === 'ws') ? this.wsPasses : this.webPasses,\n\t      i = false;\n\n\t  passes.forEach(function(v, idx) {\n\t    if(v.name === passName) i = idx;\n\t  });\n\n\t  if(i === false) throw new Error('No such pass');\n\n\t  passes.splice(i++, 0, callback);\n\t};\n} (httpProxy$2));\n\n// Use explicit /index.js to help browserify negociation in require '/lib/http-proxy' (!)\nvar ProxyServer = httpProxyExports.Server;\n\n\n/**\n * Creates the proxy server.\n *\n * Examples:\n *\n *    httpProxy.createProxyServer({ .. }, 8000)\n *    // => '{ web: [Function], ws: [Function] ... }'\n *\n * @param {Object} Options Config object passed to the proxy\n *\n * @return {Object} Proxy Proxy object with handlers for `ws` and `web` requests\n *\n * @api public\n */\n\n\nfunction createProxyServer(options) {\n  /*\n   *  `options` is needed and it must have the following layout:\n   *\n   *  {\n   *    target : <url string to be parsed with the url module>\n   *    forward: <url string to be parsed with the url module>\n   *    agent  : <object to be passed to http(s).request>\n   *    ssl    : <object to be passed to https.createServer()>\n   *    ws     : <true/false, if you want to proxy websockets>\n   *    xfwd   : <true/false, adds x-forward headers>\n   *    secure : <true/false, verify SSL certificate>\n   *    toProxy: <true/false, explicitly specify if we are proxying to another proxy>\n   *    prependPath: <true/false, Default: true - specify whether you want to prepend the target's path to the proxy path>\n   *    ignorePath: <true/false, Default: false - specify whether you want to ignore the proxy path of the incoming request>\n   *    localAddress : <Local interface string to bind for outgoing connections>\n   *    changeOrigin: <true/false, Default: false - changes the origin of the host header to the target URL>\n   *    preserveHeaderKeyCase: <true/false, Default: false - specify whether you want to keep letter case of response header key >\n   *    auth   : Basic authentication i.e. 'user:password' to compute an Authorization header.\n   *    hostRewrite: rewrites the location hostname on (201/301/302/307/308) redirects, Default: null.\n   *    autoRewrite: rewrites the location host/port on (201/301/302/307/308) redirects based on requested host/port. Default: false.\n   *    protocolRewrite: rewrites the location protocol on (201/301/302/307/308) redirects to 'http' or 'https'. Default: null.\n   *  }\n   *\n   *  NOTE: `options.ws` and `options.ssl` are optional.\n   *    `options.target and `options.forward` cannot be\n   *    both missing\n   *  }\n   */\n\n  return new ProxyServer(options);\n}\n\n\nProxyServer.createProxyServer = createProxyServer;\nProxyServer.createServer      = createProxyServer;\nProxyServer.createProxy       = createProxyServer;\n\n\n\n\n/**\n * Export the proxy \"Server\" as the main export.\n */\nvar httpProxy$1 = ProxyServer;\n\n/*!\n * Caron dimonio, con occhi di bragia\n * loro accennando, tutte le raccoglie;\n * batte col remo qualunque s’adagia \n *\n * Charon the demon, with the eyes of glede,\n * Beckoning to them, collects them all together,\n * Beats with his oar whoever lags behind\n *          \n *          Dante - The Divine Comedy (Canto III)\n */\n\n(function (module) {\n\tmodule.exports = httpProxy$1;\n} (httpProxy$3));\n\nvar httpProxy = /*@__PURE__*/getDefaultExportFromCjs(httpProxyExports$1);\n\nconst debug$1 = createDebugger('vite:proxy');\nfunction proxyMiddleware(httpServer, options, config) {\n    // lazy require only when proxy is used\n    const proxies = {};\n    Object.keys(options).forEach((context) => {\n        let opts = options[context];\n        if (!opts) {\n            return;\n        }\n        if (typeof opts === 'string') {\n            opts = { target: opts, changeOrigin: true };\n        }\n        const proxy = httpProxy.createProxyServer(opts);\n        proxy.on('error', (err, req, originalRes) => {\n            // When it is ws proxy, res is net.Socket\n            const res = originalRes;\n            if ('req' in res) {\n                config.logger.error(`${picocolorsExports.red(`http proxy error at ${originalRes.req.url}:`)}\\n${err.stack}`, {\n                    timestamp: true,\n                    error: err,\n                });\n                if (!res.headersSent && !res.writableEnded) {\n                    res\n                        .writeHead(500, {\n                        'Content-Type': 'text/plain',\n                    })\n                        .end();\n                }\n            }\n            else {\n                config.logger.error(`${picocolorsExports.red(`ws proxy error:`)}\\n${err.stack}`, {\n                    timestamp: true,\n                    error: err,\n                });\n                res.end();\n            }\n        });\n        if (opts.configure) {\n            opts.configure(proxy, opts);\n        }\n        // clone before saving because http-proxy mutates the options\n        proxies[context] = [proxy, { ...opts }];\n    });\n    if (httpServer) {\n        httpServer.on('upgrade', (req, socket, head) => {\n            const url = req.url;\n            for (const context in proxies) {\n                if (doesProxyContextMatchUrl(context, url)) {\n                    const [proxy, opts] = proxies[context];\n                    if ((opts.ws ||\n                        opts.target?.toString().startsWith('ws:') ||\n                        opts.target?.toString().startsWith('wss:')) &&\n                        req.headers['sec-websocket-protocol'] !== HMR_HEADER) {\n                        if (opts.rewrite) {\n                            req.url = opts.rewrite(url);\n                        }\n                        debug$1(`${req.url} -> ws ${opts.target}`);\n                        proxy.ws(req, socket, head);\n                        return;\n                    }\n                }\n            }\n        });\n    }\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteProxyMiddleware(req, res, next) {\n        const url = req.url;\n        for (const context in proxies) {\n            if (doesProxyContextMatchUrl(context, url)) {\n                const [proxy, opts] = proxies[context];\n                const options = {};\n                if (opts.bypass) {\n                    const bypassResult = opts.bypass(req, res, opts);\n                    if (typeof bypassResult === 'string') {\n                        req.url = bypassResult;\n                        debug$1(`bypass: ${req.url} -> ${bypassResult}`);\n                        return next();\n                    }\n                    else if (bypassResult === false) {\n                        debug$1(`bypass: ${req.url} -> 404`);\n                        return res.end(404);\n                    }\n                }\n                debug$1(`${req.url} -> ${opts.target || opts.forward}`);\n                if (opts.rewrite) {\n                    req.url = opts.rewrite(req.url);\n                }\n                proxy.web(req, res, options);\n                return;\n            }\n        }\n        next();\n    };\n}\nfunction doesProxyContextMatchUrl(context, url) {\n    return ((context.startsWith('^') && new RegExp(context).test(url)) ||\n        url.startsWith(context));\n}\n\nvar libExports = {};\nvar lib = {\n  get exports(){ return libExports; },\n  set exports(v){ libExports = v; },\n};\n\n(function (module, exports) {\n\n\tvar url = require$$0$9;\n\n\tmodule.exports = function historyApiFallback(options) {\n\t  options = options || {};\n\t  var logger = getLogger(options);\n\n\t  return function(req, res, next) {\n\t    var headers = req.headers;\n\t    if (req.method !== 'GET' && req.method !== 'HEAD') {\n\t      logger(\n\t        'Not rewriting',\n\t        req.method,\n\t        req.url,\n\t        'because the method is not GET or HEAD.'\n\t      );\n\t      return next();\n\t    } else if (!headers || typeof headers.accept !== 'string') {\n\t      logger(\n\t        'Not rewriting',\n\t        req.method,\n\t        req.url,\n\t        'because the client did not send an HTTP accept header.'\n\t      );\n\t      return next();\n\t    } else if (headers.accept.indexOf('application/json') === 0) {\n\t      logger(\n\t        'Not rewriting',\n\t        req.method,\n\t        req.url,\n\t        'because the client prefers JSON.'\n\t      );\n\t      return next();\n\t    } else if (!acceptsHtml(headers.accept, options)) {\n\t      logger(\n\t        'Not rewriting',\n\t        req.method,\n\t        req.url,\n\t        'because the client does not accept HTML.'\n\t      );\n\t      return next();\n\t    }\n\n\t    var parsedUrl = url.parse(req.url);\n\t    var rewriteTarget;\n\t    options.rewrites = options.rewrites || [];\n\t    for (var i = 0; i < options.rewrites.length; i++) {\n\t      var rewrite = options.rewrites[i];\n\t      var match = parsedUrl.pathname.match(rewrite.from);\n\t      if (match !== null) {\n\t        rewriteTarget = evaluateRewriteRule(parsedUrl, match, rewrite.to, req);\n\n\t        if(rewriteTarget.charAt(0) !== '/') {\n\t          logger(\n\t            'We recommend using an absolute path for the rewrite target.',\n\t            'Received a non-absolute rewrite target',\n\t            rewriteTarget,\n\t            'for URL',\n\t            req.url\n\t          );\n\t        }\n\n\t        logger('Rewriting', req.method, req.url, 'to', rewriteTarget);\n\t        req.url = rewriteTarget;\n\t        return next();\n\t      }\n\t    }\n\n\t    var pathname = parsedUrl.pathname;\n\t    if (pathname.lastIndexOf('.') > pathname.lastIndexOf('/') &&\n\t        options.disableDotRule !== true) {\n\t      logger(\n\t        'Not rewriting',\n\t        req.method,\n\t        req.url,\n\t        'because the path includes a dot (.) character.'\n\t      );\n\t      return next();\n\t    }\n\n\t    rewriteTarget = options.index || '/index.html';\n\t    logger('Rewriting', req.method, req.url, 'to', rewriteTarget);\n\t    req.url = rewriteTarget;\n\t    next();\n\t  };\n\t};\n\n\tfunction evaluateRewriteRule(parsedUrl, match, rule, req) {\n\t  if (typeof rule === 'string') {\n\t    return rule;\n\t  } else if (typeof rule !== 'function') {\n\t    throw new Error('Rewrite rule can only be of type string or function.');\n\t  }\n\n\t  return rule({\n\t    parsedUrl: parsedUrl,\n\t    match: match,\n\t    request: req\n\t  });\n\t}\n\n\tfunction acceptsHtml(header, options) {\n\t  options.htmlAcceptHeaders = options.htmlAcceptHeaders || ['text/html', '*/*'];\n\t  for (var i = 0; i < options.htmlAcceptHeaders.length; i++) {\n\t    if (header.indexOf(options.htmlAcceptHeaders[i]) !== -1) {\n\t      return true;\n\t    }\n\t  }\n\t  return false;\n\t}\n\n\tfunction getLogger(options) {\n\t  if (options && options.logger) {\n\t    return options.logger;\n\t  } else if (options && options.verbose) {\n\t    // eslint-disable-next-line no-console\n\t    return console.log.bind(console);\n\t  }\n\t  return function(){};\n\t}\n} (lib));\n\nvar history = libExports;\n\nfunction htmlFallbackMiddleware(root, spaFallback) {\n    const historyHtmlFallbackMiddleware = history({\n        logger: createDebugger('vite:html-fallback'),\n        // support /dir/ without explicit index.html\n        rewrites: [\n            {\n                from: /\\/$/,\n                to({ parsedUrl, request }) {\n                    const rewritten = decodeURIComponent(parsedUrl.pathname) + 'index.html';\n                    if (fs$l.existsSync(path$o.join(root, rewritten))) {\n                        return rewritten;\n                    }\n                    return spaFallback ? `/index.html` : request.url;\n                },\n            },\n        ],\n    });\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteHtmlFallbackMiddleware(req, res, next) {\n        return historyHtmlFallbackMiddleware(req, res, next);\n    };\n}\n\nconst debugCache = createDebugger('vite:cache');\nconst isDebug = !!process.env.DEBUG;\nconst knownIgnoreList = new Set(['/', '/favicon.ico']);\nfunction transformMiddleware(server) {\n    const { config: { root, logger }, moduleGraph, } = server;\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return async function viteTransformMiddleware(req, res, next) {\n        if (req.method !== 'GET' || knownIgnoreList.has(req.url)) {\n            return next();\n        }\n        let url;\n        try {\n            url = decodeURI(removeTimestampQuery(req.url)).replace(NULL_BYTE_PLACEHOLDER, '\\0');\n        }\n        catch (e) {\n            return next(e);\n        }\n        const withoutQuery = cleanUrl(url);\n        try {\n            const isSourceMap = withoutQuery.endsWith('.map');\n            // since we generate source map references, handle those requests here\n            if (isSourceMap) {\n                const depsOptimizer = getDepsOptimizer(server.config, false); // non-ssr\n                if (depsOptimizer?.isOptimizedDepUrl(url)) {\n                    // If the browser is requesting a source map for an optimized dep, it\n                    // means that the dependency has already been pre-bundled and loaded\n                    const mapFile = url.startsWith(FS_PREFIX)\n                        ? fsPathFromId(url)\n                        : normalizePath$3(ensureVolumeInPath(path$o.resolve(root, url.slice(1))));\n                    try {\n                        const map = await promises$2.readFile(mapFile, 'utf-8');\n                        return send$1(req, res, map, 'json', {\n                            headers: server.config.server.headers,\n                        });\n                    }\n                    catch (e) {\n                        // Outdated source map request for optimized deps, this isn't an error\n                        // but part of the normal flow when re-optimizing after missing deps\n                        // Send back an empty source map so the browser doesn't issue warnings\n                        const dummySourceMap = {\n                            version: 3,\n                            file: mapFile.replace(/\\.map$/, ''),\n                            sources: [],\n                            sourcesContent: [],\n                            names: [],\n                            mappings: ';;;;;;;;;',\n                        };\n                        return send$1(req, res, JSON.stringify(dummySourceMap), 'json', {\n                            cacheControl: 'no-cache',\n                            headers: server.config.server.headers,\n                        });\n                    }\n                }\n                else {\n                    const originalUrl = url.replace(/\\.map($|\\?)/, '$1');\n                    const map = (await moduleGraph.getModuleByUrl(originalUrl, false))\n                        ?.transformResult?.map;\n                    if (map) {\n                        return send$1(req, res, JSON.stringify(map), 'json', {\n                            headers: server.config.server.headers,\n                        });\n                    }\n                    else {\n                        return next();\n                    }\n                }\n            }\n            // check if public dir is inside root dir\n            const publicDir = normalizePath$3(server.config.publicDir);\n            const rootDir = normalizePath$3(server.config.root);\n            if (publicDir.startsWith(rootDir)) {\n                const publicPath = `${publicDir.slice(rootDir.length)}/`;\n                // warn explicit public paths\n                if (url.startsWith(publicPath)) {\n                    let warning;\n                    if (isImportRequest(url)) {\n                        const rawUrl = removeImportQuery(url);\n                        warning =\n                            'Assets in public cannot be imported from JavaScript.\\n' +\n                                `Instead of ${picocolorsExports.cyan(rawUrl)}, put the file in the src directory, and use ${picocolorsExports.cyan(rawUrl.replace(publicPath, '/src/'))} instead.`;\n                    }\n                    else {\n                        warning =\n                            `files in the public directory are served at the root path.\\n` +\n                                `Instead of ${picocolorsExports.cyan(url)}, use ${picocolorsExports.cyan(url.replace(publicPath, '/'))}.`;\n                    }\n                    logger.warn(picocolorsExports.yellow(warning));\n                }\n            }\n            if (isJSRequest(url) ||\n                isImportRequest(url) ||\n                isCSSRequest(url) ||\n                isHTMLProxy(url)) {\n                // strip ?import\n                url = removeImportQuery(url);\n                // Strip valid id prefix. This is prepended to resolved Ids that are\n                // not valid browser import specifiers by the importAnalysis plugin.\n                url = unwrapId(url);\n                // for CSS, we need to differentiate between normal CSS requests and\n                // imports\n                if (isCSSRequest(url) &&\n                    !isDirectRequest(url) &&\n                    req.headers.accept?.includes('text/css')) {\n                    url = injectQuery(url, 'direct');\n                }\n                // check if we can return 304 early\n                const ifNoneMatch = req.headers['if-none-match'];\n                if (ifNoneMatch &&\n                    (await moduleGraph.getModuleByUrl(url, false))?.transformResult\n                        ?.etag === ifNoneMatch) {\n                    isDebug && debugCache(`[304] ${prettifyUrl(url, root)}`);\n                    res.statusCode = 304;\n                    return res.end();\n                }\n                // resolve, load and transform using the plugin container\n                const result = await transformRequest(url, server, {\n                    html: req.headers.accept?.includes('text/html'),\n                });\n                if (result) {\n                    const depsOptimizer = getDepsOptimizer(server.config, false); // non-ssr\n                    const type = isDirectCSSRequest(url) ? 'css' : 'js';\n                    const isDep = DEP_VERSION_RE.test(url) || depsOptimizer?.isOptimizedDepUrl(url);\n                    return send$1(req, res, result.code, type, {\n                        etag: result.etag,\n                        // allow browser to cache npm deps!\n                        cacheControl: isDep ? 'max-age=31536000,immutable' : 'no-cache',\n                        headers: server.config.server.headers,\n                        map: result.map,\n                    });\n                }\n            }\n        }\n        catch (e) {\n            if (e?.code === ERR_OPTIMIZE_DEPS_PROCESSING_ERROR) {\n                // Skip if response has already been sent\n                if (!res.writableEnded) {\n                    res.statusCode = 504; // status code request timeout\n                    res.end();\n                }\n                // This timeout is unexpected\n                logger.error(e.message);\n                return;\n            }\n            if (e?.code === ERR_OUTDATED_OPTIMIZED_DEP) {\n                // Skip if response has already been sent\n                if (!res.writableEnded) {\n                    res.statusCode = 504; // status code request timeout\n                    res.end();\n                }\n                // We don't need to log an error in this case, the request\n                // is outdated because new dependencies were discovered and\n                // the new pre-bundle dependencies have changed.\n                // A full-page reload has been issued, and these old requests\n                // can't be properly fulfilled. This isn't an unexpected\n                // error but a normal part of the missing deps discovery flow\n                return;\n            }\n            if (e?.code === ERR_LOAD_URL) {\n                // Let other middleware handle if we can't load the url via transformRequest\n                return next();\n            }\n            return next(e);\n        }\n        next();\n    };\n}\n\nfunction createDevHtmlTransformFn(server) {\n    const [preHooks, normalHooks, postHooks] = resolveHtmlTransforms(server.config.plugins);\n    return (url, html, originalUrl) => {\n        return applyHtmlTransforms(html, [\n            preImportMapHook(server.config),\n            ...preHooks,\n            devHtmlHook,\n            ...normalHooks,\n            ...postHooks,\n            postImportMapHook(),\n        ], {\n            path: url,\n            filename: getHtmlFilename(url, server),\n            server,\n            originalUrl,\n        });\n    };\n}\nfunction getHtmlFilename(url, server) {\n    if (url.startsWith(FS_PREFIX)) {\n        return decodeURIComponent(fsPathFromId(url));\n    }\n    else {\n        return decodeURIComponent(normalizePath$3(path$o.join(server.config.root, url.slice(1))));\n    }\n}\nconst startsWithSingleSlashRE = /^\\/(?!\\/)/;\nconst processNodeUrl = (attr, sourceCodeLocation, s, config, htmlPath, originalUrl, moduleGraph) => {\n    let url = attr.value || '';\n    if (moduleGraph) {\n        const mod = moduleGraph.urlToModuleMap.get(url);\n        if (mod && mod.lastHMRTimestamp > 0) {\n            url = injectQuery(url, `t=${mod.lastHMRTimestamp}`);\n        }\n    }\n    const devBase = config.base;\n    if (startsWithSingleSlashRE.test(url)) {\n        // prefix with base (dev only, base is never relative)\n        const fullUrl = path$o.posix.join(devBase, url);\n        overwriteAttrValue(s, sourceCodeLocation, fullUrl);\n    }\n    else if (url.startsWith('.') &&\n        originalUrl &&\n        originalUrl !== '/' &&\n        htmlPath === '/index.html') {\n        // prefix with base (dev only, base is never relative)\n        const replacer = (url) => path$o.posix.join(devBase, url);\n        // #3230 if some request url (localhost:3000/a/b) return to fallback html, the relative assets\n        // path will add `/a/` prefix, it will caused 404.\n        // rewrite before `./index.js` -> `localhost:5173/a/index.js`.\n        // rewrite after `../index.js` -> `localhost:5173/index.js`.\n        const processedUrl = attr.name === 'srcset' && attr.prefix === undefined\n            ? processSrcSetSync(url, ({ url }) => replacer(url))\n            : replacer(url);\n        overwriteAttrValue(s, sourceCodeLocation, processedUrl);\n    }\n};\nconst devHtmlHook = async (html, { path: htmlPath, filename, server, originalUrl }) => {\n    const { config, moduleGraph, watcher } = server;\n    const base = config.base || '/';\n    let proxyModulePath;\n    let proxyModuleUrl;\n    const trailingSlash = htmlPath.endsWith('/');\n    if (!trailingSlash && fs$l.existsSync(filename)) {\n        proxyModulePath = htmlPath;\n        proxyModuleUrl = joinUrlSegments(base, htmlPath);\n    }\n    else {\n        // There are users of vite.transformIndexHtml calling it with url '/'\n        // for SSR integrations #7993, filename is root for this case\n        // A user may also use a valid name for a virtual html file\n        // Mark the path as virtual in both cases so sourcemaps aren't processed\n        // and ids are properly handled\n        const validPath = `${htmlPath}${trailingSlash ? 'index.html' : ''}`;\n        proxyModulePath = `\\0${validPath}`;\n        proxyModuleUrl = wrapId(proxyModulePath);\n    }\n    const s = new MagicString(html);\n    let inlineModuleIndex = -1;\n    const proxyCacheUrl = cleanUrl(proxyModulePath).replace(normalizePath$3(config.root), '');\n    const styleUrl = [];\n    const addInlineModule = (node, ext) => {\n        inlineModuleIndex++;\n        const contentNode = node.childNodes[0];\n        const code = contentNode.value;\n        let map;\n        if (!proxyModulePath.startsWith('\\0')) {\n            map = new MagicString(html)\n                .snip(contentNode.sourceCodeLocation.startOffset, contentNode.sourceCodeLocation.endOffset)\n                .generateMap({ hires: true });\n            map.sources = [filename];\n            map.file = filename;\n        }\n        // add HTML Proxy to Map\n        addToHTMLProxyCache(config, proxyCacheUrl, inlineModuleIndex, { code, map });\n        // inline js module. convert to src=\"proxy\" (dev only, base is never relative)\n        const modulePath = `${proxyModuleUrl}?html-proxy&index=${inlineModuleIndex}.${ext}`;\n        // invalidate the module so the newly cached contents will be served\n        const module = server?.moduleGraph.getModuleById(modulePath);\n        if (module) {\n            server?.moduleGraph.invalidateModule(module);\n        }\n        s.update(node.sourceCodeLocation.startOffset, node.sourceCodeLocation.endOffset, `<script type=\"module\" src=\"${modulePath}\"></script>`);\n    };\n    await traverseHtml(html, filename, (node) => {\n        if (!nodeIsElement(node)) {\n            return;\n        }\n        // script tags\n        if (node.nodeName === 'script') {\n            const { src, sourceCodeLocation, isModule } = getScriptInfo(node);\n            if (src) {\n                processNodeUrl(src, sourceCodeLocation, s, config, htmlPath, originalUrl, moduleGraph);\n            }\n            else if (isModule && node.childNodes.length) {\n                addInlineModule(node, 'js');\n            }\n        }\n        if (node.nodeName === 'style' && node.childNodes.length) {\n            const children = node.childNodes[0];\n            styleUrl.push({\n                start: children.sourceCodeLocation.startOffset,\n                end: children.sourceCodeLocation.endOffset,\n                code: children.value,\n            });\n        }\n        // elements with [href/src] attrs\n        const assetAttrs = assetAttrsConfig[node.nodeName];\n        if (assetAttrs) {\n            for (const p of node.attrs) {\n                const attrKey = getAttrKey(p);\n                if (p.value && assetAttrs.includes(attrKey)) {\n                    processNodeUrl(p, node.sourceCodeLocation.attrs[attrKey], s, config, htmlPath, originalUrl);\n                }\n            }\n        }\n    });\n    await Promise.all(styleUrl.map(async ({ start, end, code }, index) => {\n        const url = `${proxyModulePath}?html-proxy&direct&index=${index}.css`;\n        // ensure module in graph after successful load\n        const mod = await moduleGraph.ensureEntryFromUrl(url, false);\n        ensureWatchedFile(watcher, mod.file, config.root);\n        const result = await server.pluginContainer.transform(code, mod.id);\n        s.overwrite(start, end, result?.code || '');\n    }));\n    html = s.toString();\n    return {\n        html,\n        tags: [\n            {\n                tag: 'script',\n                attrs: {\n                    type: 'module',\n                    src: path$o.posix.join(base, CLIENT_PUBLIC_PATH),\n                },\n                injectTo: 'head-prepend',\n            },\n        ],\n    };\n};\nfunction indexHtmlMiddleware(server) {\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return async function viteIndexHtmlMiddleware(req, res, next) {\n        if (res.writableEnded) {\n            return next();\n        }\n        const url = req.url && cleanUrl(req.url);\n        // htmlFallbackMiddleware appends '.html' to URLs\n        if (url?.endsWith('.html') && req.headers['sec-fetch-dest'] !== 'script') {\n            const filename = getHtmlFilename(url, server);\n            if (fs$l.existsSync(filename)) {\n                try {\n                    let html = fs$l.readFileSync(filename, 'utf-8');\n                    html = await server.transformIndexHtml(url, html, req.originalUrl);\n                    return send$1(req, res, html, 'html', {\n                        headers: server.config.server.headers,\n                    });\n                }\n                catch (e) {\n                    return next(e);\n                }\n            }\n        }\n        next();\n    };\n}\n\nconst logTime = createDebugger('vite:time');\nfunction timeMiddleware(root) {\n    // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n    return function viteTimeMiddleware(req, res, next) {\n        const start = performance.now();\n        const end = res.end;\n        res.end = (...args) => {\n            logTime(`${timeFrom(start)} ${prettifyUrl(req.url, root)}`);\n            return end.call(res, ...args);\n        };\n        next();\n    };\n}\n\nclass ModuleNode {\n    /**\n     * @param setIsSelfAccepting - set `false` to set `isSelfAccepting` later. e.g. #7870\n     */\n    constructor(url, setIsSelfAccepting = true) {\n        /**\n         * Resolved file system path + query\n         */\n        this.id = null;\n        this.file = null;\n        this.importers = new Set();\n        this.importedModules = new Set();\n        this.acceptedHmrDeps = new Set();\n        this.acceptedHmrExports = null;\n        this.importedBindings = null;\n        this.transformResult = null;\n        this.ssrTransformResult = null;\n        this.ssrModule = null;\n        this.ssrError = null;\n        this.lastHMRTimestamp = 0;\n        this.lastInvalidationTimestamp = 0;\n        this.url = url;\n        this.type = isDirectCSSRequest(url) ? 'css' : 'js';\n        if (setIsSelfAccepting) {\n            this.isSelfAccepting = false;\n        }\n    }\n}\nclass ModuleGraph {\n    constructor(resolveId) {\n        this.resolveId = resolveId;\n        this.urlToModuleMap = new Map();\n        this.idToModuleMap = new Map();\n        // a single file may corresponds to multiple modules with different queries\n        this.fileToModulesMap = new Map();\n        this.safeModulesPath = new Set();\n    }\n    async getModuleByUrl(rawUrl, ssr) {\n        const [url] = await this.resolveUrl(rawUrl, ssr);\n        return this.urlToModuleMap.get(url);\n    }\n    getModuleById(id) {\n        return this.idToModuleMap.get(removeTimestampQuery(id));\n    }\n    getModulesByFile(file) {\n        return this.fileToModulesMap.get(file);\n    }\n    onFileChange(file) {\n        const mods = this.getModulesByFile(file);\n        if (mods) {\n            const seen = new Set();\n            mods.forEach((mod) => {\n                this.invalidateModule(mod, seen);\n            });\n        }\n    }\n    invalidateModule(mod, seen = new Set(), timestamp = Date.now(), isHmr = false) {\n        if (seen.has(mod)) {\n            return;\n        }\n        seen.add(mod);\n        if (isHmr) {\n            mod.lastHMRTimestamp = timestamp;\n        }\n        else {\n            // Save the timestamp for this invalidation, so we can avoid caching the result of possible already started\n            // processing being done for this module\n            mod.lastInvalidationTimestamp = timestamp;\n        }\n        // Don't invalidate mod.info and mod.meta, as they are part of the processing pipeline\n        // Invalidating the transform result is enough to ensure this module is re-processed next time it is requested\n        mod.transformResult = null;\n        mod.ssrTransformResult = null;\n        mod.ssrModule = null;\n        mod.ssrError = null;\n        mod.importers.forEach((importer) => {\n            if (!importer.acceptedHmrDeps.has(mod)) {\n                this.invalidateModule(importer, seen, timestamp, isHmr);\n            }\n        });\n    }\n    invalidateAll() {\n        const timestamp = Date.now();\n        const seen = new Set();\n        this.idToModuleMap.forEach((mod) => {\n            this.invalidateModule(mod, seen, timestamp);\n        });\n    }\n    /**\n     * Update the module graph based on a module's updated imports information\n     * If there are dependencies that no longer have any importers, they are\n     * returned as a Set.\n     */\n    async updateModuleInfo(mod, importedModules, importedBindings, acceptedModules, acceptedExports, isSelfAccepting, ssr) {\n        mod.isSelfAccepting = isSelfAccepting;\n        const prevImports = mod.importedModules;\n        const nextImports = (mod.importedModules = new Set());\n        let noLongerImported;\n        // update import graph\n        for (const imported of importedModules) {\n            const dep = typeof imported === 'string'\n                ? await this.ensureEntryFromUrl(imported, ssr)\n                : imported;\n            dep.importers.add(mod);\n            nextImports.add(dep);\n        }\n        // remove the importer from deps that were imported but no longer are.\n        prevImports.forEach((dep) => {\n            if (!nextImports.has(dep)) {\n                dep.importers.delete(mod);\n                if (!dep.importers.size) {\n                    (noLongerImported || (noLongerImported = new Set())).add(dep);\n                }\n            }\n        });\n        // update accepted hmr deps\n        const deps = (mod.acceptedHmrDeps = new Set());\n        for (const accepted of acceptedModules) {\n            const dep = typeof accepted === 'string'\n                ? await this.ensureEntryFromUrl(accepted, ssr)\n                : accepted;\n            deps.add(dep);\n        }\n        // update accepted hmr exports\n        mod.acceptedHmrExports = acceptedExports;\n        mod.importedBindings = importedBindings;\n        return noLongerImported;\n    }\n    async ensureEntryFromUrl(rawUrl, ssr, setIsSelfAccepting = true) {\n        const [url, resolvedId, meta] = await this.resolveUrl(rawUrl, ssr);\n        let mod = this.idToModuleMap.get(resolvedId);\n        if (!mod) {\n            mod = new ModuleNode(url, setIsSelfAccepting);\n            if (meta)\n                mod.meta = meta;\n            this.urlToModuleMap.set(url, mod);\n            mod.id = resolvedId;\n            this.idToModuleMap.set(resolvedId, mod);\n            const file = (mod.file = cleanUrl(resolvedId));\n            let fileMappedModules = this.fileToModulesMap.get(file);\n            if (!fileMappedModules) {\n                fileMappedModules = new Set();\n                this.fileToModulesMap.set(file, fileMappedModules);\n            }\n            fileMappedModules.add(mod);\n        }\n        // multiple urls can map to the same module and id, make sure we register\n        // the url to the existing module in that case\n        else if (!this.urlToModuleMap.has(url)) {\n            this.urlToModuleMap.set(url, mod);\n        }\n        return mod;\n    }\n    // some deps, like a css file referenced via @import, don't have its own\n    // url because they are inlined into the main css import. But they still\n    // need to be represented in the module graph so that they can trigger\n    // hmr in the importing css file.\n    createFileOnlyEntry(file) {\n        file = normalizePath$3(file);\n        let fileMappedModules = this.fileToModulesMap.get(file);\n        if (!fileMappedModules) {\n            fileMappedModules = new Set();\n            this.fileToModulesMap.set(file, fileMappedModules);\n        }\n        const url = `${FS_PREFIX}${file}`;\n        for (const m of fileMappedModules) {\n            if (m.url === url || m.id === file) {\n                return m;\n            }\n        }\n        const mod = new ModuleNode(url);\n        mod.file = file;\n        fileMappedModules.add(mod);\n        return mod;\n    }\n    // for incoming urls, it is important to:\n    // 1. remove the HMR timestamp query (?t=xxxx)\n    // 2. resolve its extension so that urls with or without extension all map to\n    // the same module\n    async resolveUrl(url, ssr) {\n        url = removeImportQuery(removeTimestampQuery(url));\n        const resolved = await this.resolveId(url, !!ssr);\n        const resolvedId = resolved?.id || url;\n        if (url !== resolvedId &&\n            !url.includes('\\0') &&\n            !url.startsWith(`virtual:`)) {\n            const ext = extname$1(cleanUrl(resolvedId));\n            const { pathname, search, hash } = new URL(url, 'relative://');\n            if (ext && !pathname.endsWith(ext)) {\n                url = pathname + ext + search + hash;\n            }\n        }\n        return [url, resolvedId, resolved?.meta];\n    }\n}\n\nasync function createServer(inlineConfig = {}) {\n    const config = await resolveConfig(inlineConfig, 'serve');\n    const { root, server: serverConfig } = config;\n    const httpsOptions = await resolveHttpsConfig(config.server.https);\n    const { middlewareMode } = serverConfig;\n    const resolvedWatchOptions = resolveChokidarOptions(config, {\n        disableGlobbing: true,\n        ...serverConfig.watch,\n    });\n    const middlewares = connect();\n    const httpServer = middlewareMode\n        ? null\n        : await resolveHttpServer(serverConfig, middlewares, httpsOptions);\n    const ws = createWebSocketServer(httpServer, config, httpsOptions);\n    if (httpServer) {\n        setClientErrorHandler(httpServer, config.logger);\n    }\n    const watcher = chokidar.watch(path$o.resolve(root), resolvedWatchOptions);\n    const moduleGraph = new ModuleGraph((url, ssr) => container.resolveId(url, undefined, { ssr }));\n    const container = await createPluginContainer(config, moduleGraph, watcher);\n    const closeHttpServer = createServerCloseFn(httpServer);\n    let exitProcess;\n    const server = {\n        config,\n        middlewares,\n        httpServer,\n        watcher,\n        pluginContainer: container,\n        ws,\n        moduleGraph,\n        resolvedUrls: null,\n        ssrTransform(code, inMap, url, originalCode = code) {\n            return ssrTransform(code, inMap, url, originalCode, server.config);\n        },\n        transformRequest(url, options) {\n            return transformRequest(url, server, options);\n        },\n        transformIndexHtml: null,\n        async ssrLoadModule(url, opts) {\n            if (isDepsOptimizerEnabled(config, true)) {\n                await initDevSsrDepsOptimizer(config, server);\n            }\n            await updateCjsSsrExternals(server);\n            return ssrLoadModule(url, server, undefined, undefined, opts?.fixStacktrace);\n        },\n        ssrFixStacktrace(e) {\n            ssrFixStacktrace(e, moduleGraph);\n        },\n        ssrRewriteStacktrace(stack) {\n            return ssrRewriteStacktrace(stack, moduleGraph);\n        },\n        async reloadModule(module) {\n            if (serverConfig.hmr !== false && module.file) {\n                updateModules(module.file, [module], Date.now(), server);\n            }\n        },\n        async listen(port, isRestart) {\n            await startServer(server, port, isRestart);\n            if (httpServer) {\n                server.resolvedUrls = await resolveServerUrls(httpServer, config.server, config);\n            }\n            return server;\n        },\n        async close() {\n            if (!middlewareMode) {\n                process.off('SIGTERM', exitProcess);\n                if (process.env.CI !== 'true') {\n                    process.stdin.off('end', exitProcess);\n                }\n            }\n            await Promise.allSettled([\n                watcher.close(),\n                ws.close(),\n                container.close(),\n                getDepsOptimizer(server.config)?.close(),\n                getDepsOptimizer(server.config, true)?.close(),\n                closeHttpServer(),\n            ]);\n            server.resolvedUrls = null;\n        },\n        printUrls() {\n            if (server.resolvedUrls) {\n                printServerUrls(server.resolvedUrls, serverConfig.host, config.logger.info);\n            }\n            else if (middlewareMode) {\n                throw new Error('cannot print server URLs in middleware mode.');\n            }\n            else {\n                throw new Error('cannot print server URLs before server.listen is called.');\n            }\n        },\n        async restart(forceOptimize) {\n            if (!server._restartPromise) {\n                server._forceOptimizeOnRestart = !!forceOptimize;\n                server._restartPromise = restartServer(server).finally(() => {\n                    server._restartPromise = null;\n                    server._forceOptimizeOnRestart = false;\n                });\n            }\n            return server._restartPromise;\n        },\n        _ssrExternals: null,\n        _restartPromise: null,\n        _importGlobMap: new Map(),\n        _forceOptimizeOnRestart: false,\n        _pendingRequests: new Map(),\n        _fsDenyGlob: picomatch$3(config.server.fs.deny, { matchBase: true }),\n        _shortcutsOptions: undefined,\n    };\n    server.transformIndexHtml = createDevHtmlTransformFn(server);\n    if (!middlewareMode) {\n        exitProcess = async () => {\n            try {\n                await server.close();\n            }\n            finally {\n                process.exit();\n            }\n        };\n        process.once('SIGTERM', exitProcess);\n        if (process.env.CI !== 'true') {\n            process.stdin.on('end', exitProcess);\n        }\n    }\n    const { packageCache } = config;\n    const setPackageData = packageCache.set.bind(packageCache);\n    packageCache.set = (id, pkg) => {\n        if (id.endsWith('.json')) {\n            watcher.add(id);\n        }\n        return setPackageData(id, pkg);\n    };\n    watcher.on('change', async (file) => {\n        file = normalizePath$3(file);\n        if (file.endsWith('/package.json')) {\n            return invalidatePackageData(packageCache, file);\n        }\n        // invalidate module graph cache on file change\n        moduleGraph.onFileChange(file);\n        if (serverConfig.hmr !== false) {\n            try {\n                await handleHMRUpdate(file, server);\n            }\n            catch (err) {\n                ws.send({\n                    type: 'error',\n                    err: prepareError(err),\n                });\n            }\n        }\n    });\n    watcher.on('add', (file) => {\n        handleFileAddUnlink(normalizePath$3(file), server);\n    });\n    watcher.on('unlink', (file) => {\n        handleFileAddUnlink(normalizePath$3(file), server);\n    });\n    ws.on('vite:invalidate', async ({ path, message }) => {\n        const mod = moduleGraph.urlToModuleMap.get(path);\n        if (mod && mod.isSelfAccepting && mod.lastHMRTimestamp > 0) {\n            config.logger.info(picocolorsExports.yellow(`hmr invalidate `) +\n                picocolorsExports.dim(path) +\n                (message ? ` ${message}` : ''), { timestamp: true });\n            const file = getShortName(mod.file, config.root);\n            updateModules(file, [...mod.importers], mod.lastHMRTimestamp, server, true);\n        }\n    });\n    if (!middlewareMode && httpServer) {\n        httpServer.once('listening', () => {\n            // update actual port since this may be different from initial value\n            serverConfig.port = httpServer.address().port;\n        });\n    }\n    // apply server configuration hooks from plugins\n    const postHooks = [];\n    for (const hook of config.getSortedPluginHooks('configureServer')) {\n        postHooks.push(await hook(server));\n    }\n    // Internal middlewares ------------------------------------------------------\n    // request timer\n    if (process.env.DEBUG) {\n        middlewares.use(timeMiddleware(root));\n    }\n    // cors (enabled by default)\n    const { cors } = serverConfig;\n    if (cors !== false) {\n        middlewares.use(libExports$1(typeof cors === 'boolean' ? {} : cors));\n    }\n    // proxy\n    const { proxy } = serverConfig;\n    if (proxy) {\n        middlewares.use(proxyMiddleware(httpServer, proxy, config));\n    }\n    // base\n    if (config.base !== '/') {\n        middlewares.use(baseMiddleware(server));\n    }\n    // open in editor support\n    middlewares.use('/__open-in-editor', launchEditorMiddleware());\n    // serve static files under /public\n    // this applies before the transform middleware so that these files are served\n    // as-is without transforms.\n    if (config.publicDir) {\n        middlewares.use(servePublicMiddleware(config.publicDir, config.server.headers));\n    }\n    // main transform middleware\n    middlewares.use(transformMiddleware(server));\n    // serve static files\n    middlewares.use(serveRawFsMiddleware(server));\n    middlewares.use(serveStaticMiddleware(root, server));\n    // html fallback\n    if (config.appType === 'spa' || config.appType === 'mpa') {\n        middlewares.use(htmlFallbackMiddleware(root, config.appType === 'spa'));\n    }\n    // run post config hooks\n    // This is applied before the html middleware so that user middleware can\n    // serve custom content instead of index.html.\n    postHooks.forEach((fn) => fn && fn());\n    if (config.appType === 'spa' || config.appType === 'mpa') {\n        // transform index.html\n        middlewares.use(indexHtmlMiddleware(server));\n        // handle 404s\n        // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n        middlewares.use(function vite404Middleware(_, res) {\n            res.statusCode = 404;\n            res.end();\n        });\n    }\n    // error handler\n    middlewares.use(errorMiddleware(server, middlewareMode));\n    let initingServer;\n    let serverInited = false;\n    const initServer = async () => {\n        if (serverInited) {\n            return;\n        }\n        if (initingServer) {\n            return initingServer;\n        }\n        initingServer = (async function () {\n            await container.buildStart({});\n            if (isDepsOptimizerEnabled(config, false)) {\n                // non-ssr\n                await initDepsOptimizer(config, server);\n            }\n            initingServer = undefined;\n            serverInited = true;\n        })();\n        return initingServer;\n    };\n    if (!middlewareMode && httpServer) {\n        // overwrite listen to init optimizer before server start\n        const listen = httpServer.listen.bind(httpServer);\n        httpServer.listen = (async (port, ...args) => {\n            try {\n                await initServer();\n            }\n            catch (e) {\n                httpServer.emit('error', e);\n                return;\n            }\n            return listen(port, ...args);\n        });\n    }\n    else {\n        await initServer();\n    }\n    return server;\n}\nasync function startServer(server, inlinePort, isRestart = false) {\n    const httpServer = server.httpServer;\n    if (!httpServer) {\n        throw new Error('Cannot call server.listen in middleware mode.');\n    }\n    const options = server.config.server;\n    const port = inlinePort ?? options.port ?? DEFAULT_DEV_PORT;\n    const hostname = await resolveHostname(options.host);\n    const protocol = options.https ? 'https' : 'http';\n    const serverPort = await httpServerStart(httpServer, {\n        port,\n        strictPort: options.strictPort,\n        host: hostname.host,\n        logger: server.config.logger,\n    });\n    if (options.open && !isRestart) {\n        const path = typeof options.open === 'string' ? options.open : server.config.base;\n        openBrowser(path.startsWith('http')\n            ? path\n            : new URL(path, `${protocol}://${hostname.name}:${serverPort}`).href, true, server.config.logger);\n    }\n}\nfunction createServerCloseFn(server) {\n    if (!server) {\n        return () => { };\n    }\n    let hasListened = false;\n    const openSockets = new Set();\n    server.on('connection', (socket) => {\n        openSockets.add(socket);\n        socket.on('close', () => {\n            openSockets.delete(socket);\n        });\n    });\n    server.once('listening', () => {\n        hasListened = true;\n    });\n    return () => new Promise((resolve, reject) => {\n        openSockets.forEach((s) => s.destroy());\n        if (hasListened) {\n            server.close((err) => {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve();\n                }\n            });\n        }\n        else {\n            resolve();\n        }\n    });\n}\nfunction resolvedAllowDir(root, dir) {\n    return normalizePath$3(path$o.resolve(root, dir));\n}\nfunction resolveServerOptions(root, raw, logger) {\n    const server = {\n        preTransformRequests: true,\n        ...raw,\n        middlewareMode: !!raw?.middlewareMode,\n    };\n    let allowDirs = server.fs?.allow;\n    const deny = server.fs?.deny || ['.env', '.env.*', '*.{crt,pem}'];\n    if (!allowDirs) {\n        allowDirs = [searchForWorkspaceRoot(root)];\n    }\n    allowDirs = allowDirs.map((i) => resolvedAllowDir(root, i));\n    // only push client dir when vite itself is outside-of-root\n    const resolvedClientDir = resolvedAllowDir(root, CLIENT_DIR);\n    if (!allowDirs.some((dir) => isParentDirectory(dir, resolvedClientDir))) {\n        allowDirs.push(resolvedClientDir);\n    }\n    server.fs = {\n        strict: server.fs?.strict ?? true,\n        allow: allowDirs,\n        deny,\n    };\n    if (server.origin?.endsWith('/')) {\n        server.origin = server.origin.slice(0, -1);\n        logger.warn(picocolorsExports.yellow(`${picocolorsExports.bold('(!)')} server.origin should not end with \"/\". Using \"${server.origin}\" instead.`));\n    }\n    return server;\n}\nasync function restartServer(server) {\n    global.__vite_start_time = performance.now();\n    const { port: prevPort, host: prevHost } = server.config.server;\n    const shortcutsOptions = server._shortcutsOptions;\n    await server.close();\n    let inlineConfig = server.config.inlineConfig;\n    if (server._forceOptimizeOnRestart) {\n        inlineConfig = mergeConfig(inlineConfig, {\n            optimizeDeps: {\n                force: true,\n            },\n        });\n    }\n    let newServer = null;\n    try {\n        newServer = await createServer(inlineConfig);\n    }\n    catch (err) {\n        server.config.logger.error(err.message, {\n            timestamp: true,\n        });\n        return;\n    }\n    // prevent new server `restart` function from calling\n    newServer._restartPromise = server._restartPromise;\n    Object.assign(server, newServer);\n    const { logger, server: { port, host, middlewareMode }, } = server.config;\n    if (!middlewareMode) {\n        await server.listen(port, true);\n        logger.info('server restarted.', { timestamp: true });\n        if ((port ?? DEFAULT_DEV_PORT) !== (prevPort ?? DEFAULT_DEV_PORT) ||\n            host !== prevHost) {\n            logger.info('');\n            server.printUrls();\n        }\n    }\n    else {\n        logger.info('server restarted.', { timestamp: true });\n    }\n    if (shortcutsOptions) {\n        shortcutsOptions.print = false;\n        bindShortcuts(newServer, shortcutsOptions);\n    }\n    // new server (the current server) can restart now\n    newServer._restartPromise = null;\n}\nasync function updateCjsSsrExternals(server) {\n    if (!server._ssrExternals) {\n        let knownImports = [];\n        // Important! We use the non-ssr optimized deps to find known imports\n        // Only the explicitly defined deps are optimized during dev SSR, so\n        // we use the generated list from the scanned deps in regular dev.\n        // This is part of the v2 externalization heuristics and it is kept\n        // for backwards compatibility in case user needs to fallback to the\n        // legacy scheme. It may be removed in a future v3 minor.\n        const depsOptimizer = getDepsOptimizer(server.config, false); // non-ssr\n        if (depsOptimizer) {\n            await depsOptimizer.scanProcessing;\n            knownImports = [\n                ...Object.keys(depsOptimizer.metadata.optimized),\n                ...Object.keys(depsOptimizer.metadata.discovered),\n            ];\n        }\n        server._ssrExternals = cjsSsrResolveExternals(server.config, knownImports);\n    }\n}\n\nvar index = {\n  __proto__: null,\n  createServer: createServer,\n  resolveServerOptions: resolveServerOptions,\n  searchForWorkspaceRoot: searchForWorkspaceRoot\n};\n\n/* eslint-disable */\n/* global Buffer */\nconst noop = () => { };\nconst mimes = /text|javascript|\\/json|xml/i;\nconst threshold = 1024;\nconst level = -1;\nlet brotli = false;\nconst getChunkSize = (chunk, enc) => (chunk ? Buffer.byteLength(chunk, enc) : 0);\nfunction compression() {\n    const brotliOpts = (typeof brotli === 'object' && brotli) || {};\n    const gzipOpts = {};\n    // disable Brotli on Node<12.7 where it is unsupported:\n    if (!zlib$1.createBrotliCompress)\n        brotli = false;\n    return (req, res, next = noop) => {\n        const accept = req.headers['accept-encoding'] + '';\n        const encoding = ((brotli && accept.match(/\\bbr\\b/)) ||\n            (accept.match(/\\bgzip\\b/)) ||\n            [])[0];\n        // skip if no response body or no supported encoding:\n        if (req.method === 'HEAD' || !encoding)\n            return next();\n        /** @type {zlib.Gzip | zlib.BrotliCompress} */\n        let compress;\n        let pendingStatus;\n        /** @type {[string, function][]?} */\n        let pendingListeners = [];\n        let started = false;\n        let size = 0;\n        function start() {\n            started = true;\n            size = res.getHeader('Content-Length') | 0 || size;\n            const compressible = mimes.test(String(res.getHeader('Content-Type') || 'text/plain'));\n            const cleartext = !res.getHeader('Content-Encoding');\n            const listeners = pendingListeners || [];\n            if (compressible && cleartext && size >= threshold) {\n                res.setHeader('Content-Encoding', encoding);\n                res.removeHeader('Content-Length');\n                if (encoding === 'br') {\n                    const params = {\n                        [zlib$1.constants.BROTLI_PARAM_QUALITY]: level,\n                        [zlib$1.constants.BROTLI_PARAM_SIZE_HINT]: size,\n                    };\n                    compress = zlib$1.createBrotliCompress({\n                        params: Object.assign(params, brotliOpts),\n                    });\n                }\n                else {\n                    compress = zlib$1.createGzip(Object.assign({ level }, gzipOpts));\n                }\n                // backpressure\n                compress.on('data', (chunk) => write.call(res, chunk) === false && compress.pause());\n                on.call(res, 'drain', () => compress.resume());\n                compress.on('end', () => end.call(res));\n                listeners.forEach((p) => compress.on.apply(compress, p));\n            }\n            else {\n                pendingListeners = null;\n                listeners.forEach((p) => on.apply(res, p));\n            }\n            writeHead.call(res, pendingStatus || res.statusCode);\n        }\n        const { end, write, on, writeHead } = res;\n        res.writeHead = function (status, reason, headers) {\n            if (typeof reason !== 'string')\n                [headers, reason] = [reason, headers];\n            if (headers)\n                for (let i in headers)\n                    res.setHeader(i, headers[i]);\n            pendingStatus = status;\n            return this;\n        };\n        res.write = function (chunk, enc, cb) {\n            size += getChunkSize(chunk, enc);\n            if (!started)\n                start();\n            if (!compress)\n                return write.apply(this, arguments);\n            return compress.write.apply(compress, arguments);\n        };\n        res.end = function (chunk, enc, cb) {\n            if (arguments.length > 0 && typeof chunk !== 'function') {\n                size += getChunkSize(chunk, enc);\n            }\n            if (!started)\n                start();\n            if (!compress)\n                return end.apply(this, arguments);\n            return compress.end.apply(compress, arguments);\n        };\n        res.on = function (type, listener) {\n            if (!pendingListeners || type !== 'drain')\n                on.call(this, type, listener);\n            else if (compress)\n                compress.on(type, listener);\n            else\n                pendingListeners.push([type, listener]);\n            return this;\n        };\n        next();\n    };\n}\n\nfunction resolvePreviewOptions(preview, server) {\n    // The preview server inherits every CommonServerOption from the `server` config\n    // except for the port to enable having both the dev and preview servers running\n    // at the same time without extra configuration\n    return {\n        port: preview?.port,\n        strictPort: preview?.strictPort ?? server.strictPort,\n        host: preview?.host ?? server.host,\n        https: preview?.https ?? server.https,\n        open: preview?.open ?? server.open,\n        proxy: preview?.proxy ?? server.proxy,\n        cors: preview?.cors ?? server.cors,\n        headers: preview?.headers ?? server.headers,\n    };\n}\n/**\n * Starts the Vite server in preview mode, to simulate a production deployment\n */\nasync function preview(inlineConfig = {}) {\n    const config = await resolveConfig(inlineConfig, 'serve', 'production', 'production');\n    const distDir = path$o.resolve(config.root, config.build.outDir);\n    if (!fs$l.existsSync(distDir) &&\n        // error if no plugins implement `configurePreviewServer`\n        config.plugins.every((plugin) => !plugin.configurePreviewServer) &&\n        // error if called in CLI only. programmatic usage could access `httpServer`\n        // and affect file serving\n        process.argv[1]?.endsWith(path$o.normalize('bin/vite.js')) &&\n        process.argv[2] === 'preview') {\n        throw new Error(`The directory \"${config.build.outDir}\" does not exist. Did you build your project?`);\n    }\n    const app = connect();\n    const httpServer = await resolveHttpServer(config.preview, app, await resolveHttpsConfig(config.preview?.https));\n    setClientErrorHandler(httpServer, config.logger);\n    // apply server hooks from plugins\n    const postHooks = [];\n    for (const hook of config.getSortedPluginHooks('configurePreviewServer')) {\n        postHooks.push(await hook({ middlewares: app, httpServer }));\n    }\n    // cors\n    const { cors } = config.preview;\n    if (cors !== false) {\n        app.use(libExports$1(typeof cors === 'boolean' ? {} : cors));\n    }\n    // proxy\n    const { proxy } = config.preview;\n    if (proxy) {\n        app.use(proxyMiddleware(httpServer, proxy, config));\n    }\n    app.use(compression());\n    const previewBase = config.base === './' || config.base === '' ? '/' : config.base;\n    // static assets\n    const headers = config.preview.headers;\n    const assetServer = sirv(distDir, {\n        etag: true,\n        dev: true,\n        single: config.appType === 'spa',\n        setHeaders(res) {\n            if (headers) {\n                for (const name in headers) {\n                    res.setHeader(name, headers[name]);\n                }\n            }\n        },\n        shouldServe(filePath) {\n            return shouldServeFile(filePath, distDir);\n        },\n    });\n    app.use(previewBase, assetServer);\n    // apply post server hooks from plugins\n    postHooks.forEach((fn) => fn && fn());\n    const options = config.preview;\n    const hostname = await resolveHostname(options.host);\n    const port = options.port ?? DEFAULT_PREVIEW_PORT;\n    const protocol = options.https ? 'https' : 'http';\n    const logger = config.logger;\n    const serverPort = await httpServerStart(httpServer, {\n        port,\n        strictPort: options.strictPort,\n        host: hostname.host,\n        logger,\n    });\n    const resolvedUrls = await resolveServerUrls(httpServer, config.preview, config);\n    if (options.open) {\n        const path = typeof options.open === 'string' ? options.open : previewBase;\n        openBrowser(path.startsWith('http')\n            ? path\n            : new URL(path, `${protocol}://${hostname.name}:${serverPort}`).href, true, logger);\n    }\n    return {\n        config,\n        httpServer,\n        resolvedUrls,\n        printUrls() {\n            printServerUrls(resolvedUrls, options.host, logger.info);\n        },\n    };\n}\n\nvar preview$1 = {\n  __proto__: null,\n  preview: preview,\n  resolvePreviewOptions: resolvePreviewOptions\n};\n\nfunction resolveSSROptions(ssr, preserveSymlinks, buildSsrCjsExternalHeuristics) {\n    ssr ?? (ssr = {});\n    const optimizeDeps = ssr.optimizeDeps ?? {};\n    let format = 'esm';\n    let target = 'node';\n    if (buildSsrCjsExternalHeuristics) {\n        if (ssr) {\n            format = 'cjs';\n        }\n        else {\n            target = 'node';\n            format = 'cjs';\n        }\n    }\n    return {\n        format,\n        target,\n        ...ssr,\n        optimizeDeps: {\n            disabled: true,\n            ...optimizeDeps,\n            esbuildOptions: {\n                preserveSymlinks,\n                ...optimizeDeps.esbuildOptions,\n            },\n        },\n    };\n}\n\nconst debug = createDebugger('vite:config');\n/**\n * Type helper to make it easier to use vite.config.ts\n * accepts a direct {@link UserConfig} object, or a function that returns it.\n * The function receives a {@link ConfigEnv} object that exposes two properties:\n * `command` (either `'build'` or `'serve'`), and `mode`.\n */\nfunction defineConfig(config) {\n    return config;\n}\nasync function resolveConfig(inlineConfig, command, defaultMode = 'development', defaultNodeEnv = 'development') {\n    let config = inlineConfig;\n    let configFileDependencies = [];\n    let mode = inlineConfig.mode || defaultMode;\n    const isNodeEnvSet = !!process.env.NODE_ENV;\n    // some dependencies e.g. @vue/compiler-* relies on NODE_ENV for getting\n    // production-specific behavior, so set it early on\n    if (!isNodeEnvSet) {\n        process.env.NODE_ENV = defaultNodeEnv;\n    }\n    const configEnv = {\n        mode,\n        command,\n        ssrBuild: !!config.build?.ssr,\n    };\n    let { configFile } = config;\n    if (configFile !== false) {\n        const loadResult = await loadConfigFromFile(configEnv, configFile, config.root, config.logLevel);\n        if (loadResult) {\n            config = mergeConfig(loadResult.config, config);\n            configFile = loadResult.path;\n            configFileDependencies = loadResult.dependencies;\n        }\n    }\n    // user config may provide an alternative mode. But --mode has a higher priority\n    mode = inlineConfig.mode || config.mode || mode;\n    configEnv.mode = mode;\n    const filterPlugin = (p) => {\n        if (!p) {\n            return false;\n        }\n        else if (!p.apply) {\n            return true;\n        }\n        else if (typeof p.apply === 'function') {\n            return p.apply({ ...config, mode }, configEnv);\n        }\n        else {\n            return p.apply === command;\n        }\n    };\n    // Some plugins that aren't intended to work in the bundling of workers (doing post-processing at build time for example).\n    // And Plugins may also have cached that could be corrupted by being used in these extra rollup calls.\n    // So we need to separate the worker plugin from the plugin that vite needs to run.\n    const rawWorkerUserPlugins = (await asyncFlatten(config.worker?.plugins || [])).filter(filterPlugin);\n    // resolve plugins\n    const rawUserPlugins = (await asyncFlatten(config.plugins || [])).filter(filterPlugin);\n    const [prePlugins, normalPlugins, postPlugins] = sortUserPlugins(rawUserPlugins);\n    // run config hooks\n    const userPlugins = [...prePlugins, ...normalPlugins, ...postPlugins];\n    config = await runConfigHook(config, userPlugins, configEnv);\n    if (process.env.VITE_TEST_WITHOUT_PLUGIN_COMMONJS) {\n        config = mergeConfig(config, {\n            optimizeDeps: { disabled: false },\n            ssr: { optimizeDeps: { disabled: false } },\n        });\n        config.build ?? (config.build = {});\n        config.build.commonjsOptions = { include: [] };\n    }\n    // Define logger\n    const logger = createLogger(config.logLevel, {\n        allowClearScreen: config.clearScreen,\n        customLogger: config.customLogger,\n    });\n    // resolve root\n    const resolvedRoot = normalizePath$3(config.root ? path$o.resolve(config.root) : process.cwd());\n    const clientAlias = [\n        { find: /^\\/?@vite\\/env/, replacement: ENV_ENTRY },\n        { find: /^\\/?@vite\\/client/, replacement: CLIENT_ENTRY },\n    ];\n    // resolve alias with internal client alias\n    const resolvedAlias = normalizeAlias(mergeAlias(clientAlias, config.resolve?.alias || []));\n    const resolveOptions = {\n        mainFields: config.resolve?.mainFields ?? DEFAULT_MAIN_FIELDS,\n        browserField: config.resolve?.browserField ?? true,\n        conditions: config.resolve?.conditions ?? [],\n        extensions: config.resolve?.extensions ?? DEFAULT_EXTENSIONS$1,\n        dedupe: config.resolve?.dedupe ?? [],\n        preserveSymlinks: config.resolve?.preserveSymlinks ?? false,\n        alias: resolvedAlias,\n    };\n    // load .env files\n    const envDir = config.envDir\n        ? normalizePath$3(path$o.resolve(resolvedRoot, config.envDir))\n        : resolvedRoot;\n    const userEnv = inlineConfig.envFile !== false &&\n        loadEnv(mode, envDir, resolveEnvPrefix(config));\n    // Note it is possible for user to have a custom mode, e.g. `staging` where\n    // development-like behavior is expected. This is indicated by NODE_ENV=development\n    // loaded from `.staging.env` and set by us as VITE_USER_NODE_ENV\n    const userNodeEnv = process.env.VITE_USER_NODE_ENV;\n    if (!isNodeEnvSet && userNodeEnv) {\n        if (userNodeEnv === 'development') {\n            process.env.NODE_ENV = 'development';\n        }\n        else {\n            // NODE_ENV=production is not supported as it could break HMR in dev for frameworks like Vue\n            logger.warn(`NODE_ENV=${userNodeEnv} is not supported in the .env file. ` +\n                `Only NODE_ENV=development is supported to create a development build of your project. ` +\n                `If you need to set process.env.NODE_ENV, you can set it in the Vite config instead.`);\n        }\n    }\n    const isProduction = process.env.NODE_ENV === 'production';\n    // resolve public base url\n    const isBuild = command === 'build';\n    const relativeBaseShortcut = config.base === '' || config.base === './';\n    // During dev, we ignore relative base and fallback to '/'\n    // For the SSR build, relative base isn't possible by means\n    // of import.meta.url.\n    const resolvedBase = relativeBaseShortcut\n        ? !isBuild || config.build?.ssr\n            ? '/'\n            : './'\n        : resolveBaseUrl(config.base, isBuild, logger) ?? '/';\n    const resolvedBuildOptions = resolveBuildOptions(config.build, logger);\n    // resolve cache directory\n    const pkgPath = lookupFile(resolvedRoot, [`package.json`], { pathOnly: true });\n    const cacheDir = normalizePath$3(config.cacheDir\n        ? path$o.resolve(resolvedRoot, config.cacheDir)\n        : pkgPath\n            ? path$o.join(path$o.dirname(pkgPath), `node_modules/.vite`)\n            : path$o.join(resolvedRoot, `.vite`));\n    const assetsFilter = config.assetsInclude &&\n        (!Array.isArray(config.assetsInclude) || config.assetsInclude.length)\n        ? createFilter(config.assetsInclude)\n        : () => false;\n    // create an internal resolver to be used in special scenarios, e.g.\n    // optimizer & handling css @imports\n    const createResolver = (options) => {\n        let aliasContainer;\n        let resolverContainer;\n        return async (id, importer, aliasOnly, ssr) => {\n            let container;\n            if (aliasOnly) {\n                container =\n                    aliasContainer ||\n                        (aliasContainer = await createPluginContainer({\n                            ...resolved,\n                            plugins: [alias$1({ entries: resolved.resolve.alias })],\n                        }));\n            }\n            else {\n                container =\n                    resolverContainer ||\n                        (resolverContainer = await createPluginContainer({\n                            ...resolved,\n                            plugins: [\n                                alias$1({ entries: resolved.resolve.alias }),\n                                resolvePlugin({\n                                    ...resolved.resolve,\n                                    root: resolvedRoot,\n                                    isProduction,\n                                    isBuild: command === 'build',\n                                    ssrConfig: resolved.ssr,\n                                    asSrc: true,\n                                    preferRelative: false,\n                                    tryIndex: true,\n                                    ...options,\n                                }),\n                            ],\n                        }));\n            }\n            return (await container.resolveId(id, importer, {\n                ssr,\n                scan: options?.scan,\n            }))?.id;\n        };\n    };\n    const { publicDir } = config;\n    const resolvedPublicDir = publicDir !== false && publicDir !== ''\n        ? path$o.resolve(resolvedRoot, typeof publicDir === 'string' ? publicDir : 'public')\n        : '';\n    const server = resolveServerOptions(resolvedRoot, config.server, logger);\n    const ssr = resolveSSROptions(config.ssr, resolveOptions.preserveSymlinks, config.legacy?.buildSsrCjsExternalHeuristics);\n    const middlewareMode = config?.server?.middlewareMode;\n    const optimizeDeps = config.optimizeDeps || {};\n    const BASE_URL = resolvedBase;\n    // resolve worker\n    let workerConfig = mergeConfig({}, config);\n    const [workerPrePlugins, workerNormalPlugins, workerPostPlugins] = sortUserPlugins(rawWorkerUserPlugins);\n    // run config hooks\n    const workerUserPlugins = [\n        ...workerPrePlugins,\n        ...workerNormalPlugins,\n        ...workerPostPlugins,\n    ];\n    workerConfig = await runConfigHook(workerConfig, workerUserPlugins, configEnv);\n    const resolvedWorkerOptions = {\n        format: workerConfig.worker?.format || 'iife',\n        plugins: [],\n        rollupOptions: workerConfig.worker?.rollupOptions || {},\n        getSortedPlugins: undefined,\n        getSortedPluginHooks: undefined,\n    };\n    const resolvedConfig = {\n        configFile: configFile ? normalizePath$3(configFile) : undefined,\n        configFileDependencies: configFileDependencies.map((name) => normalizePath$3(path$o.resolve(name))),\n        inlineConfig,\n        root: resolvedRoot,\n        base: resolvedBase.endsWith('/') ? resolvedBase : resolvedBase + '/',\n        rawBase: resolvedBase,\n        resolve: resolveOptions,\n        publicDir: resolvedPublicDir,\n        cacheDir,\n        command,\n        mode,\n        ssr,\n        isWorker: false,\n        mainConfig: null,\n        isProduction,\n        plugins: userPlugins,\n        server,\n        build: resolvedBuildOptions,\n        preview: resolvePreviewOptions(config.preview, server),\n        env: {\n            ...userEnv,\n            BASE_URL,\n            MODE: mode,\n            DEV: !isProduction,\n            PROD: isProduction,\n        },\n        assetsInclude(file) {\n            return DEFAULT_ASSETS_RE.test(file) || assetsFilter(file);\n        },\n        logger,\n        packageCache: new Map(),\n        createResolver,\n        optimizeDeps: {\n            disabled: 'build',\n            ...optimizeDeps,\n            esbuildOptions: {\n                preserveSymlinks: resolveOptions.preserveSymlinks,\n                ...optimizeDeps.esbuildOptions,\n            },\n        },\n        worker: resolvedWorkerOptions,\n        appType: config.appType ?? (middlewareMode === 'ssr' ? 'custom' : 'spa'),\n        experimental: {\n            importGlobRestoreExtension: false,\n            hmrPartialAccept: false,\n            ...config.experimental,\n        },\n        getSortedPlugins: undefined,\n        getSortedPluginHooks: undefined,\n    };\n    const resolved = {\n        ...config,\n        ...resolvedConfig,\n    };\n    resolved.plugins = await resolvePlugins(resolved, prePlugins, normalPlugins, postPlugins);\n    Object.assign(resolved, createPluginHookUtils(resolved.plugins));\n    const workerResolved = {\n        ...workerConfig,\n        ...resolvedConfig,\n        isWorker: true,\n        mainConfig: resolved,\n    };\n    resolvedConfig.worker.plugins = await resolvePlugins(workerResolved, workerPrePlugins, workerNormalPlugins, workerPostPlugins);\n    Object.assign(resolvedConfig.worker, createPluginHookUtils(resolvedConfig.worker.plugins));\n    // call configResolved hooks\n    await Promise.all([\n        ...resolved\n            .getSortedPluginHooks('configResolved')\n            .map((hook) => hook(resolved)),\n        ...resolvedConfig.worker\n            .getSortedPluginHooks('configResolved')\n            .map((hook) => hook(workerResolved)),\n    ]);\n    // validate config\n    if (middlewareMode === 'ssr') {\n        logger.warn(picocolorsExports.yellow(`Setting server.middlewareMode to 'ssr' is deprecated, set server.middlewareMode to \\`true\\`${config.appType === 'custom' ? '' : ` and appType to 'custom'`} instead`));\n    }\n    if (middlewareMode === 'html') {\n        logger.warn(picocolorsExports.yellow(`Setting server.middlewareMode to 'html' is deprecated, set server.middlewareMode to \\`true\\` instead`));\n    }\n    if (config.server?.force &&\n        !isBuild &&\n        config.optimizeDeps?.force === undefined) {\n        resolved.optimizeDeps.force = true;\n        logger.warn(picocolorsExports.yellow(`server.force is deprecated, use optimizeDeps.force instead`));\n    }\n    if (process.env.DEBUG) {\n        debug(`using resolved config: %O`, {\n            ...resolved,\n            plugins: resolved.plugins.map((p) => p.name),\n            worker: {\n                ...resolved.worker,\n                plugins: resolved.worker.plugins.map((p) => p.name),\n            },\n        });\n    }\n    if (config.build?.terserOptions && config.build.minify !== 'terser') {\n        logger.warn(picocolorsExports.yellow(`build.terserOptions is specified but build.minify is not set to use Terser. ` +\n            `Note Vite now defaults to use esbuild for minification. If you still ` +\n            `prefer Terser, set build.minify to \"terser\".`));\n    }\n    // Check if all assetFileNames have the same reference.\n    // If not, display a warn for user.\n    const outputOption = config.build?.rollupOptions?.output ?? [];\n    // Use isArray to narrow its type to array\n    if (Array.isArray(outputOption)) {\n        const assetFileNamesList = outputOption.map((output) => output.assetFileNames);\n        if (assetFileNamesList.length > 1) {\n            const firstAssetFileNames = assetFileNamesList[0];\n            const hasDifferentReference = assetFileNamesList.some((assetFileNames) => assetFileNames !== firstAssetFileNames);\n            if (hasDifferentReference) {\n                resolved.logger.warn(picocolorsExports.yellow(`\nassetFileNames isn't equal for every build.rollupOptions.output. A single pattern across all outputs is supported by Vite.\n`));\n            }\n        }\n    }\n    return resolved;\n}\n/**\n * Resolve base url. Note that some users use Vite to build for non-web targets like\n * electron or expects to deploy\n */\nfunction resolveBaseUrl(base = '/', isBuild, logger) {\n    if (base.startsWith('.')) {\n        logger.warn(picocolorsExports.yellow(picocolorsExports.bold(`(!) invalid \"base\" option: ${base}. The value can only be an absolute ` +\n            `URL, ./, or an empty string.`)));\n        return '/';\n    }\n    // external URL flag\n    const isExternal = isExternalUrl(base);\n    // no leading slash warn\n    if (!isExternal && !base.startsWith('/')) {\n        logger.warn(picocolorsExports.yellow(picocolorsExports.bold(`(!) \"base\" option should start with a slash.`)));\n    }\n    // parse base when command is serve or base is not External URL\n    if (!isBuild || !isExternal) {\n        base = new URL(base, 'http://vitejs.dev').pathname;\n        // ensure leading slash\n        if (!base.startsWith('/')) {\n            base = '/' + base;\n        }\n    }\n    return base;\n}\nfunction sortUserPlugins(plugins) {\n    const prePlugins = [];\n    const postPlugins = [];\n    const normalPlugins = [];\n    if (plugins) {\n        plugins.flat().forEach((p) => {\n            if (p.enforce === 'pre')\n                prePlugins.push(p);\n            else if (p.enforce === 'post')\n                postPlugins.push(p);\n            else\n                normalPlugins.push(p);\n        });\n    }\n    return [prePlugins, normalPlugins, postPlugins];\n}\nasync function loadConfigFromFile(configEnv, configFile, configRoot = process.cwd(), logLevel) {\n    const start = performance.now();\n    const getTime = () => `${(performance.now() - start).toFixed(2)}ms`;\n    let resolvedPath;\n    if (configFile) {\n        // explicit config path is always resolved from cwd\n        resolvedPath = path$o.resolve(configFile);\n    }\n    else {\n        // implicit config file loaded from inline root (if present)\n        // otherwise from cwd\n        for (const filename of DEFAULT_CONFIG_FILES) {\n            const filePath = path$o.resolve(configRoot, filename);\n            if (!fs$l.existsSync(filePath))\n                continue;\n            resolvedPath = filePath;\n            break;\n        }\n    }\n    if (!resolvedPath) {\n        debug('no config file found.');\n        return null;\n    }\n    let isESM = false;\n    if (/\\.m[jt]s$/.test(resolvedPath)) {\n        isESM = true;\n    }\n    else if (/\\.c[jt]s$/.test(resolvedPath)) {\n        isESM = false;\n    }\n    else {\n        // check package.json for type: \"module\" and set `isESM` to true\n        try {\n            const pkg = lookupFile(configRoot, ['package.json']);\n            isESM = !!pkg && JSON.parse(pkg).type === 'module';\n        }\n        catch (e) { }\n    }\n    try {\n        const bundled = await bundleConfigFile(resolvedPath, isESM);\n        const userConfig = await loadConfigFromBundledFile(resolvedPath, bundled.code, isESM);\n        debug(`bundled config file loaded in ${getTime()}`);\n        const config = await (typeof userConfig === 'function'\n            ? userConfig(configEnv)\n            : userConfig);\n        if (!isObject$1(config)) {\n            throw new Error(`config must export or return an object.`);\n        }\n        return {\n            path: normalizePath$3(resolvedPath),\n            config,\n            dependencies: bundled.dependencies,\n        };\n    }\n    catch (e) {\n        createLogger(logLevel).error(picocolorsExports.red(`failed to load config from ${resolvedPath}`), { error: e });\n        throw e;\n    }\n}\nasync function bundleConfigFile(fileName, isESM) {\n    const dirnameVarName = '__vite_injected_original_dirname';\n    const filenameVarName = '__vite_injected_original_filename';\n    const importMetaUrlVarName = '__vite_injected_original_import_meta_url';\n    const result = await build$3({\n        absWorkingDir: process.cwd(),\n        entryPoints: [fileName],\n        outfile: 'out.js',\n        write: false,\n        target: ['node14.18', 'node16'],\n        platform: 'node',\n        bundle: true,\n        format: isESM ? 'esm' : 'cjs',\n        mainFields: ['main'],\n        sourcemap: 'inline',\n        metafile: true,\n        define: {\n            __dirname: dirnameVarName,\n            __filename: filenameVarName,\n            'import.meta.url': importMetaUrlVarName,\n        },\n        plugins: [\n            {\n                name: 'externalize-deps',\n                setup(build) {\n                    const options = {\n                        root: path$o.dirname(fileName),\n                        isBuild: true,\n                        isProduction: true,\n                        preferRelative: false,\n                        tryIndex: true,\n                        mainFields: [],\n                        browserField: false,\n                        conditions: [],\n                        overrideConditions: ['node'],\n                        dedupe: [],\n                        extensions: DEFAULT_EXTENSIONS$1,\n                        preserveSymlinks: false,\n                    };\n                    // externalize bare imports\n                    build.onResolve({ filter: /^[^.].*/ }, async ({ path: id, importer, kind }) => {\n                        if (kind === 'entry-point' ||\n                            path$o.isAbsolute(id) ||\n                            isBuiltin(id)) {\n                            return;\n                        }\n                        // partial deno support as `npm:` does not work with esbuild\n                        if (id.startsWith('npm:')) {\n                            return { external: true };\n                        }\n                        const isIdESM = isESM || kind === 'dynamic-import';\n                        let idFsPath = tryNodeResolve(id, importer, { ...options, isRequire: !isIdESM }, false)?.id;\n                        if (idFsPath && isIdESM) {\n                            idFsPath = pathToFileURL(idFsPath).href;\n                        }\n                        return {\n                            path: idFsPath,\n                            external: true,\n                        };\n                    });\n                },\n            },\n            {\n                name: 'inject-file-scope-variables',\n                setup(build) {\n                    build.onLoad({ filter: /\\.[cm]?[jt]s$/ }, async (args) => {\n                        const contents = await fs$l.promises.readFile(args.path, 'utf8');\n                        const injectValues = `const ${dirnameVarName} = ${JSON.stringify(path$o.dirname(args.path))};` +\n                            `const ${filenameVarName} = ${JSON.stringify(args.path)};` +\n                            `const ${importMetaUrlVarName} = ${JSON.stringify(pathToFileURL(args.path).href)};`;\n                        return {\n                            loader: args.path.endsWith('ts') ? 'ts' : 'js',\n                            contents: injectValues + contents,\n                        };\n                    });\n                },\n            },\n        ],\n    });\n    const { text } = result.outputFiles[0];\n    return {\n        code: text,\n        dependencies: result.metafile ? Object.keys(result.metafile.inputs) : [],\n    };\n}\nconst _require = createRequire$1(import.meta.url);\nasync function loadConfigFromBundledFile(fileName, bundledCode, isESM) {\n    // for esm, before we can register loaders without requiring users to run node\n    // with --experimental-loader themselves, we have to do a hack here:\n    // write it to disk, load it with native Node ESM, then delete the file.\n    if (isESM) {\n        const fileBase = `${fileName}.timestamp-${Date.now()}`;\n        const fileNameTmp = `${fileBase}.mjs`;\n        const fileUrl = `${pathToFileURL(fileBase)}.mjs`;\n        fs$l.writeFileSync(fileNameTmp, bundledCode);\n        try {\n            return (await dynamicImport(fileUrl)).default;\n        }\n        finally {\n            try {\n                fs$l.unlinkSync(fileNameTmp);\n            }\n            catch {\n                // already removed if this function is called twice simultaneously\n            }\n        }\n    }\n    // for cjs, we can register a custom loader via `_require.extensions`\n    else {\n        const extension = path$o.extname(fileName);\n        const realFileName = fs$l.realpathSync(fileName);\n        const loaderExt = extension in _require.extensions ? extension : '.js';\n        const defaultLoader = _require.extensions[loaderExt];\n        _require.extensions[loaderExt] = (module, filename) => {\n            if (filename === realFileName) {\n                module._compile(bundledCode, filename);\n            }\n            else {\n                defaultLoader(module, filename);\n            }\n        };\n        // clear cache in case of server restart\n        delete _require.cache[_require.resolve(fileName)];\n        const raw = _require(fileName);\n        _require.extensions[loaderExt] = defaultLoader;\n        return raw.__esModule ? raw.default : raw;\n    }\n}\nasync function runConfigHook(config, plugins, configEnv) {\n    let conf = config;\n    for (const p of getSortedPluginsByHook('config', plugins)) {\n        const hook = p.config;\n        const handler = hook && 'handler' in hook ? hook.handler : hook;\n        if (handler) {\n            const res = await handler(conf, configEnv);\n            if (res) {\n                conf = mergeConfig(conf, res);\n            }\n        }\n    }\n    return conf;\n}\nfunction getDepOptimizationConfig(config, ssr) {\n    return ssr ? config.ssr.optimizeDeps : config.optimizeDeps;\n}\nfunction isDepsOptimizerEnabled(config, ssr) {\n    const { command } = config;\n    const { disabled } = getDepOptimizationConfig(config, ssr);\n    return !(disabled === true ||\n        (command === 'build' && disabled === 'build') ||\n        (command === 'serve' && disabled === 'dev'));\n}\n\nexport { picocolorsExports as A, bindShortcuts as B, index$1 as C, build$1 as D, index as E, preview$1 as F, preprocessCSS as a, build as b, createServer as c, resolvePackageData as d, buildErrorMessage as e, formatPostcssSourceMap as f, defineConfig as g, resolveConfig as h, resolveBaseUrl as i, getDepOptimizationConfig as j, isDepsOptimizerEnabled as k, loadConfigFromFile as l, mergeConfig as m, normalizePath$3 as n, optimizeDeps as o, preview as p, mergeAlias as q, resolvePackageEntry as r, sortUserPlugins as s, transformWithEsbuild as t, createFilter as u, send$1 as v, createLogger as w, searchForWorkspaceRoot as x, loadEnv as y, resolveEnvPrefix as z };\n"}},"dep-f597f42f.js":{"file":{"contents":"import require$$0__default from 'fs';\nimport require$$0 from 'postcss';\nimport { c as commonjsGlobal } from './dep-ace95160.js';\nimport require$$0$1 from 'path';\nimport require$$5 from 'crypto';\nimport require$$0$2 from 'util';\nimport { l as lib } from './dep-c423598f.js';\n\nimport { fileURLToPath as __cjs_fileURLToPath } from 'node:url';\nimport { dirname as __cjs_dirname } from 'node:path';\nimport { createRequire as __cjs_createRequire } from 'node:module';\n\nconst __filename = __cjs_fileURLToPath(import.meta.url);\nconst __dirname = __cjs_dirname(__filename);\nconst require = __cjs_createRequire(import.meta.url);\nconst __require = require;\nfunction _mergeNamespaces(n, m) {\n  for (var i = 0; i < m.length; i++) {\n    var e = m[i];\n    if (typeof e !== 'string' && !Array.isArray(e)) { for (var k in e) {\n      if (k !== 'default' && !(k in n)) {\n        n[k] = e[k];\n      }\n    } }\n  }\n  return n;\n}\n\nvar buildExports = {};\nvar build = {\n  get exports(){ return buildExports; },\n  set exports(v){ buildExports = v; },\n};\n\nvar fs = {};\n\nObject.defineProperty(fs, \"__esModule\", {\n  value: true\n});\nfs.getFileSystem = getFileSystem;\nfs.setFileSystem = setFileSystem;\nlet fileSystem = {\n  readFile: () => {\n    throw Error(\"readFile not implemented\");\n  },\n  writeFile: () => {\n    throw Error(\"writeFile not implemented\");\n  }\n};\n\nfunction setFileSystem(fs) {\n  fileSystem.readFile = fs.readFile;\n  fileSystem.writeFile = fs.writeFile;\n}\n\nfunction getFileSystem() {\n  return fileSystem;\n}\n\nvar pluginFactory = {};\n\nvar unquote$1 = {};\n\nObject.defineProperty(unquote$1, \"__esModule\", {\n  value: true\n});\nunquote$1.default = unquote;\n// copied from https://github.com/lakenen/node-unquote\nconst reg = /['\"]/;\n\nfunction unquote(str) {\n  if (!str) {\n    return \"\";\n  }\n\n  if (reg.test(str.charAt(0))) {\n    str = str.substr(1);\n  }\n\n  if (reg.test(str.charAt(str.length - 1))) {\n    str = str.substr(0, str.length - 1);\n  }\n\n  return str;\n}\n\nvar Parser$1 = {};\n\nconst matchValueName = /[$]?[\\w-]+/g;\n\nconst replaceValueSymbols$2 = (value, replacements) => {\n  let matches;\n\n  while ((matches = matchValueName.exec(value))) {\n    const replacement = replacements[matches[0]];\n\n    if (replacement) {\n      value =\n        value.slice(0, matches.index) +\n        replacement +\n        value.slice(matchValueName.lastIndex);\n\n      matchValueName.lastIndex -= matches[0].length - replacement.length;\n    }\n  }\n\n  return value;\n};\n\nvar replaceValueSymbols_1 = replaceValueSymbols$2;\n\nconst replaceValueSymbols$1 = replaceValueSymbols_1;\n\nconst replaceSymbols$1 = (css, replacements) => {\n  css.walk((node) => {\n    if (node.type === \"decl\" && node.value) {\n      node.value = replaceValueSymbols$1(node.value.toString(), replacements);\n    } else if (node.type === \"rule\" && node.selector) {\n      node.selector = replaceValueSymbols$1(\n        node.selector.toString(),\n        replacements\n      );\n    } else if (node.type === \"atrule\" && node.params) {\n      node.params = replaceValueSymbols$1(node.params.toString(), replacements);\n    }\n  });\n};\n\nvar replaceSymbols_1 = replaceSymbols$1;\n\nconst importPattern = /^:import\\((\"[^\"]*\"|'[^']*'|[^\"']+)\\)$/;\nconst balancedQuotes = /^(\"[^\"]*\"|'[^']*'|[^\"']+)$/;\n\nconst getDeclsObject = (rule) => {\n  const object = {};\n\n  rule.walkDecls((decl) => {\n    const before = decl.raws.before ? decl.raws.before.trim() : \"\";\n\n    object[before + decl.prop] = decl.value;\n  });\n\n  return object;\n};\n/**\n *\n * @param {string} css\n * @param {boolean} removeRules\n * @param {'auto' | 'rule' | 'at-rule'} mode\n */\nconst extractICSS$2 = (css, removeRules = true, mode = \"auto\") => {\n  const icssImports = {};\n  const icssExports = {};\n\n  function addImports(node, path) {\n    const unquoted = path.replace(/'|\"/g, \"\");\n    icssImports[unquoted] = Object.assign(\n      icssImports[unquoted] || {},\n      getDeclsObject(node)\n    );\n\n    if (removeRules) {\n      node.remove();\n    }\n  }\n\n  function addExports(node) {\n    Object.assign(icssExports, getDeclsObject(node));\n    if (removeRules) {\n      node.remove();\n    }\n  }\n\n  css.each((node) => {\n    if (node.type === \"rule\" && mode !== \"at-rule\") {\n      if (node.selector.slice(0, 7) === \":import\") {\n        const matches = importPattern.exec(node.selector);\n\n        if (matches) {\n          addImports(node, matches[1]);\n        }\n      }\n\n      if (node.selector === \":export\") {\n        addExports(node);\n      }\n    }\n\n    if (node.type === \"atrule\" && mode !== \"rule\") {\n      if (node.name === \"icss-import\") {\n        const matches = balancedQuotes.exec(node.params);\n\n        if (matches) {\n          addImports(node, matches[1]);\n        }\n      }\n      if (node.name === \"icss-export\") {\n        addExports(node);\n      }\n    }\n  });\n\n  return { icssImports, icssExports };\n};\n\nvar extractICSS_1 = extractICSS$2;\n\nconst createImports = (imports, postcss, mode = \"rule\") => {\n  return Object.keys(imports).map((path) => {\n    const aliases = imports[path];\n    const declarations = Object.keys(aliases).map((key) =>\n      postcss.decl({\n        prop: key,\n        value: aliases[key],\n        raws: { before: \"\\n  \" },\n      })\n    );\n\n    const hasDeclarations = declarations.length > 0;\n\n    const rule =\n      mode === \"rule\"\n        ? postcss.rule({\n            selector: `:import('${path}')`,\n            raws: { after: hasDeclarations ? \"\\n\" : \"\" },\n          })\n        : postcss.atRule({\n            name: \"icss-import\",\n            params: `'${path}'`,\n            raws: { after: hasDeclarations ? \"\\n\" : \"\" },\n          });\n\n    if (hasDeclarations) {\n      rule.append(declarations);\n    }\n\n    return rule;\n  });\n};\n\nconst createExports = (exports, postcss, mode = \"rule\") => {\n  const declarations = Object.keys(exports).map((key) =>\n    postcss.decl({\n      prop: key,\n      value: exports[key],\n      raws: { before: \"\\n  \" },\n    })\n  );\n\n  if (declarations.length === 0) {\n    return [];\n  }\n  const rule =\n    mode === \"rule\"\n      ? postcss.rule({\n          selector: `:export`,\n          raws: { after: \"\\n\" },\n        })\n      : postcss.atRule({\n          name: \"icss-export\",\n          raws: { after: \"\\n\" },\n        });\n\n  rule.append(declarations);\n\n  return [rule];\n};\n\nconst createICSSRules$1 = (imports, exports, postcss, mode) => [\n  ...createImports(imports, postcss, mode),\n  ...createExports(exports, postcss, mode),\n];\n\nvar createICSSRules_1 = createICSSRules$1;\n\nconst replaceValueSymbols = replaceValueSymbols_1;\nconst replaceSymbols = replaceSymbols_1;\nconst extractICSS$1 = extractICSS_1;\nconst createICSSRules = createICSSRules_1;\n\nvar src$4 = {\n  replaceValueSymbols,\n  replaceSymbols,\n  extractICSS: extractICSS$1,\n  createICSSRules,\n};\n\nObject.defineProperty(Parser$1, \"__esModule\", {\n  value: true\n});\nParser$1.default = void 0;\n\nvar _icssUtils = src$4;\n\n// Initially copied from https://github.com/css-modules/css-modules-loader-core\nconst importRegexp = /^:import\\((.+)\\)$/;\n\nclass Parser {\n  constructor(pathFetcher, trace) {\n    this.pathFetcher = pathFetcher;\n    this.plugin = this.plugin.bind(this);\n    this.exportTokens = {};\n    this.translations = {};\n    this.trace = trace;\n  }\n\n  plugin() {\n    const parser = this;\n    return {\n      postcssPlugin: \"css-modules-parser\",\n\n      async OnceExit(css) {\n        await Promise.all(parser.fetchAllImports(css));\n        parser.linkImportedSymbols(css);\n        return parser.extractExports(css);\n      }\n\n    };\n  }\n\n  fetchAllImports(css) {\n    let imports = [];\n    css.each(node => {\n      if (node.type == \"rule\" && node.selector.match(importRegexp)) {\n        imports.push(this.fetchImport(node, css.source.input.from, imports.length));\n      }\n    });\n    return imports;\n  }\n\n  linkImportedSymbols(css) {\n    (0, _icssUtils.replaceSymbols)(css, this.translations);\n  }\n\n  extractExports(css) {\n    css.each(node => {\n      if (node.type == \"rule\" && node.selector == \":export\") this.handleExport(node);\n    });\n  }\n\n  handleExport(exportNode) {\n    exportNode.each(decl => {\n      if (decl.type == \"decl\") {\n        Object.keys(this.translations).forEach(translation => {\n          decl.value = decl.value.replace(translation, this.translations[translation]);\n        });\n        this.exportTokens[decl.prop] = decl.value;\n      }\n    });\n    exportNode.remove();\n  }\n\n  async fetchImport(importNode, relativeTo, depNr) {\n    const file = importNode.selector.match(importRegexp)[1];\n    const depTrace = this.trace + String.fromCharCode(depNr);\n    const exports = await this.pathFetcher(file, relativeTo, depTrace);\n\n    try {\n      importNode.each(decl => {\n        if (decl.type == \"decl\") {\n          this.translations[decl.prop] = exports[decl.value];\n        }\n      });\n      importNode.remove();\n    } catch (err) {\n      console.log(err);\n    }\n  }\n\n}\n\nParser$1.default = Parser;\n\nvar saveJSON$1 = {};\n\nObject.defineProperty(saveJSON$1, \"__esModule\", {\n  value: true\n});\nsaveJSON$1.default = saveJSON;\n\nvar _fs$2 = fs;\n\nfunction saveJSON(cssFile, json) {\n  return new Promise((resolve, reject) => {\n    const {\n      writeFile\n    } = (0, _fs$2.getFileSystem)();\n    writeFile(`${cssFile}.json`, JSON.stringify(json), e => e ? reject(e) : resolve(json));\n  });\n}\n\nvar localsConvention = {};\n\n/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/** `Object#toString` result references. */\nvar symbolTag = '[object Symbol]';\n\n/** Used to match words composed of alphanumeric characters. */\nvar reAsciiWord = /[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g;\n\n/** Used to match Latin Unicode letters (excluding mathematical operators). */\nvar reLatin = /[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g;\n\n/** Used to compose unicode character classes. */\nvar rsAstralRange = '\\\\ud800-\\\\udfff',\n    rsComboMarksRange = '\\\\u0300-\\\\u036f\\\\ufe20-\\\\ufe23',\n    rsComboSymbolsRange = '\\\\u20d0-\\\\u20f0',\n    rsDingbatRange = '\\\\u2700-\\\\u27bf',\n    rsLowerRange = 'a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff',\n    rsMathOpRange = '\\\\xac\\\\xb1\\\\xd7\\\\xf7',\n    rsNonCharRange = '\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf',\n    rsPunctuationRange = '\\\\u2000-\\\\u206f',\n    rsSpaceRange = ' \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000',\n    rsUpperRange = 'A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde',\n    rsVarRange = '\\\\ufe0e\\\\ufe0f',\n    rsBreakRange = rsMathOpRange + rsNonCharRange + rsPunctuationRange + rsSpaceRange;\n\n/** Used to compose unicode capture groups. */\nvar rsApos = \"['\\u2019]\",\n    rsAstral = '[' + rsAstralRange + ']',\n    rsBreak = '[' + rsBreakRange + ']',\n    rsCombo = '[' + rsComboMarksRange + rsComboSymbolsRange + ']',\n    rsDigits = '\\\\d+',\n    rsDingbat = '[' + rsDingbatRange + ']',\n    rsLower = '[' + rsLowerRange + ']',\n    rsMisc = '[^' + rsAstralRange + rsBreakRange + rsDigits + rsDingbatRange + rsLowerRange + rsUpperRange + ']',\n    rsFitz = '\\\\ud83c[\\\\udffb-\\\\udfff]',\n    rsModifier = '(?:' + rsCombo + '|' + rsFitz + ')',\n    rsNonAstral = '[^' + rsAstralRange + ']',\n    rsRegional = '(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}',\n    rsSurrPair = '[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]',\n    rsUpper = '[' + rsUpperRange + ']',\n    rsZWJ = '\\\\u200d';\n\n/** Used to compose unicode regexes. */\nvar rsLowerMisc = '(?:' + rsLower + '|' + rsMisc + ')',\n    rsUpperMisc = '(?:' + rsUpper + '|' + rsMisc + ')',\n    rsOptLowerContr = '(?:' + rsApos + '(?:d|ll|m|re|s|t|ve))?',\n    rsOptUpperContr = '(?:' + rsApos + '(?:D|LL|M|RE|S|T|VE))?',\n    reOptMod = rsModifier + '?',\n    rsOptVar = '[' + rsVarRange + ']?',\n    rsOptJoin = '(?:' + rsZWJ + '(?:' + [rsNonAstral, rsRegional, rsSurrPair].join('|') + ')' + rsOptVar + reOptMod + ')*',\n    rsSeq = rsOptVar + reOptMod + rsOptJoin,\n    rsEmoji = '(?:' + [rsDingbat, rsRegional, rsSurrPair].join('|') + ')' + rsSeq,\n    rsSymbol = '(?:' + [rsNonAstral + rsCombo + '?', rsCombo, rsRegional, rsSurrPair, rsAstral].join('|') + ')';\n\n/** Used to match apostrophes. */\nvar reApos = RegExp(rsApos, 'g');\n\n/**\n * Used to match [combining diacritical marks](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks) and\n * [combining diacritical marks for symbols](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks_for_Symbols).\n */\nvar reComboMark = RegExp(rsCombo, 'g');\n\n/** Used to match [string symbols](https://mathiasbynens.be/notes/javascript-unicode). */\nvar reUnicode = RegExp(rsFitz + '(?=' + rsFitz + ')|' + rsSymbol + rsSeq, 'g');\n\n/** Used to match complex or compound words. */\nvar reUnicodeWord = RegExp([\n  rsUpper + '?' + rsLower + '+' + rsOptLowerContr + '(?=' + [rsBreak, rsUpper, '$'].join('|') + ')',\n  rsUpperMisc + '+' + rsOptUpperContr + '(?=' + [rsBreak, rsUpper + rsLowerMisc, '$'].join('|') + ')',\n  rsUpper + '?' + rsLowerMisc + '+' + rsOptLowerContr,\n  rsUpper + '+' + rsOptUpperContr,\n  rsDigits,\n  rsEmoji\n].join('|'), 'g');\n\n/** Used to detect strings with [zero-width joiners or code points from the astral planes](http://eev.ee/blog/2015/09/12/dark-corners-of-unicode/). */\nvar reHasUnicode = RegExp('[' + rsZWJ + rsAstralRange  + rsComboMarksRange + rsComboSymbolsRange + rsVarRange + ']');\n\n/** Used to detect strings that need a more robust regexp to match words. */\nvar reHasUnicodeWord = /[a-z][A-Z]|[A-Z]{2,}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/;\n\n/** Used to map Latin Unicode letters to basic Latin letters. */\nvar deburredLetters = {\n  // Latin-1 Supplement block.\n  '\\xc0': 'A',  '\\xc1': 'A', '\\xc2': 'A', '\\xc3': 'A', '\\xc4': 'A', '\\xc5': 'A',\n  '\\xe0': 'a',  '\\xe1': 'a', '\\xe2': 'a', '\\xe3': 'a', '\\xe4': 'a', '\\xe5': 'a',\n  '\\xc7': 'C',  '\\xe7': 'c',\n  '\\xd0': 'D',  '\\xf0': 'd',\n  '\\xc8': 'E',  '\\xc9': 'E', '\\xca': 'E', '\\xcb': 'E',\n  '\\xe8': 'e',  '\\xe9': 'e', '\\xea': 'e', '\\xeb': 'e',\n  '\\xcc': 'I',  '\\xcd': 'I', '\\xce': 'I', '\\xcf': 'I',\n  '\\xec': 'i',  '\\xed': 'i', '\\xee': 'i', '\\xef': 'i',\n  '\\xd1': 'N',  '\\xf1': 'n',\n  '\\xd2': 'O',  '\\xd3': 'O', '\\xd4': 'O', '\\xd5': 'O', '\\xd6': 'O', '\\xd8': 'O',\n  '\\xf2': 'o',  '\\xf3': 'o', '\\xf4': 'o', '\\xf5': 'o', '\\xf6': 'o', '\\xf8': 'o',\n  '\\xd9': 'U',  '\\xda': 'U', '\\xdb': 'U', '\\xdc': 'U',\n  '\\xf9': 'u',  '\\xfa': 'u', '\\xfb': 'u', '\\xfc': 'u',\n  '\\xdd': 'Y',  '\\xfd': 'y', '\\xff': 'y',\n  '\\xc6': 'Ae', '\\xe6': 'ae',\n  '\\xde': 'Th', '\\xfe': 'th',\n  '\\xdf': 'ss',\n  // Latin Extended-A block.\n  '\\u0100': 'A',  '\\u0102': 'A', '\\u0104': 'A',\n  '\\u0101': 'a',  '\\u0103': 'a', '\\u0105': 'a',\n  '\\u0106': 'C',  '\\u0108': 'C', '\\u010a': 'C', '\\u010c': 'C',\n  '\\u0107': 'c',  '\\u0109': 'c', '\\u010b': 'c', '\\u010d': 'c',\n  '\\u010e': 'D',  '\\u0110': 'D', '\\u010f': 'd', '\\u0111': 'd',\n  '\\u0112': 'E',  '\\u0114': 'E', '\\u0116': 'E', '\\u0118': 'E', '\\u011a': 'E',\n  '\\u0113': 'e',  '\\u0115': 'e', '\\u0117': 'e', '\\u0119': 'e', '\\u011b': 'e',\n  '\\u011c': 'G',  '\\u011e': 'G', '\\u0120': 'G', '\\u0122': 'G',\n  '\\u011d': 'g',  '\\u011f': 'g', '\\u0121': 'g', '\\u0123': 'g',\n  '\\u0124': 'H',  '\\u0126': 'H', '\\u0125': 'h', '\\u0127': 'h',\n  '\\u0128': 'I',  '\\u012a': 'I', '\\u012c': 'I', '\\u012e': 'I', '\\u0130': 'I',\n  '\\u0129': 'i',  '\\u012b': 'i', '\\u012d': 'i', '\\u012f': 'i', '\\u0131': 'i',\n  '\\u0134': 'J',  '\\u0135': 'j',\n  '\\u0136': 'K',  '\\u0137': 'k', '\\u0138': 'k',\n  '\\u0139': 'L',  '\\u013b': 'L', '\\u013d': 'L', '\\u013f': 'L', '\\u0141': 'L',\n  '\\u013a': 'l',  '\\u013c': 'l', '\\u013e': 'l', '\\u0140': 'l', '\\u0142': 'l',\n  '\\u0143': 'N',  '\\u0145': 'N', '\\u0147': 'N', '\\u014a': 'N',\n  '\\u0144': 'n',  '\\u0146': 'n', '\\u0148': 'n', '\\u014b': 'n',\n  '\\u014c': 'O',  '\\u014e': 'O', '\\u0150': 'O',\n  '\\u014d': 'o',  '\\u014f': 'o', '\\u0151': 'o',\n  '\\u0154': 'R',  '\\u0156': 'R', '\\u0158': 'R',\n  '\\u0155': 'r',  '\\u0157': 'r', '\\u0159': 'r',\n  '\\u015a': 'S',  '\\u015c': 'S', '\\u015e': 'S', '\\u0160': 'S',\n  '\\u015b': 's',  '\\u015d': 's', '\\u015f': 's', '\\u0161': 's',\n  '\\u0162': 'T',  '\\u0164': 'T', '\\u0166': 'T',\n  '\\u0163': 't',  '\\u0165': 't', '\\u0167': 't',\n  '\\u0168': 'U',  '\\u016a': 'U', '\\u016c': 'U', '\\u016e': 'U', '\\u0170': 'U', '\\u0172': 'U',\n  '\\u0169': 'u',  '\\u016b': 'u', '\\u016d': 'u', '\\u016f': 'u', '\\u0171': 'u', '\\u0173': 'u',\n  '\\u0174': 'W',  '\\u0175': 'w',\n  '\\u0176': 'Y',  '\\u0177': 'y', '\\u0178': 'Y',\n  '\\u0179': 'Z',  '\\u017b': 'Z', '\\u017d': 'Z',\n  '\\u017a': 'z',  '\\u017c': 'z', '\\u017e': 'z',\n  '\\u0132': 'IJ', '\\u0133': 'ij',\n  '\\u0152': 'Oe', '\\u0153': 'oe',\n  '\\u0149': \"'n\", '\\u017f': 'ss'\n};\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof commonjsGlobal == 'object' && commonjsGlobal && commonjsGlobal.Object === Object && commonjsGlobal;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root$2 = freeGlobal || freeSelf || Function('return this')();\n\n/**\n * A specialized version of `_.reduce` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @param {boolean} [initAccum] Specify using the first element of `array` as\n *  the initial value.\n * @returns {*} Returns the accumulated value.\n */\nfunction arrayReduce(array, iteratee, accumulator, initAccum) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  if (initAccum && length) {\n    accumulator = array[++index];\n  }\n  while (++index < length) {\n    accumulator = iteratee(accumulator, array[index], index, array);\n  }\n  return accumulator;\n}\n\n/**\n * Converts an ASCII `string` to an array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the converted array.\n */\nfunction asciiToArray(string) {\n  return string.split('');\n}\n\n/**\n * Splits an ASCII `string` into an array of its words.\n *\n * @private\n * @param {string} The string to inspect.\n * @returns {Array} Returns the words of `string`.\n */\nfunction asciiWords(string) {\n  return string.match(reAsciiWord) || [];\n}\n\n/**\n * The base implementation of `_.propertyOf` without support for deep paths.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Function} Returns the new accessor function.\n */\nfunction basePropertyOf(object) {\n  return function(key) {\n    return object == null ? undefined : object[key];\n  };\n}\n\n/**\n * Used by `_.deburr` to convert Latin-1 Supplement and Latin Extended-A\n * letters to basic Latin letters.\n *\n * @private\n * @param {string} letter The matched letter to deburr.\n * @returns {string} Returns the deburred letter.\n */\nvar deburrLetter = basePropertyOf(deburredLetters);\n\n/**\n * Checks if `string` contains Unicode symbols.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {boolean} Returns `true` if a symbol is found, else `false`.\n */\nfunction hasUnicode(string) {\n  return reHasUnicode.test(string);\n}\n\n/**\n * Checks if `string` contains a word composed of Unicode symbols.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {boolean} Returns `true` if a word is found, else `false`.\n */\nfunction hasUnicodeWord(string) {\n  return reHasUnicodeWord.test(string);\n}\n\n/**\n * Converts `string` to an array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the converted array.\n */\nfunction stringToArray(string) {\n  return hasUnicode(string)\n    ? unicodeToArray(string)\n    : asciiToArray(string);\n}\n\n/**\n * Converts a Unicode `string` to an array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the converted array.\n */\nfunction unicodeToArray(string) {\n  return string.match(reUnicode) || [];\n}\n\n/**\n * Splits a Unicode `string` into an array of its words.\n *\n * @private\n * @param {string} The string to inspect.\n * @returns {Array} Returns the words of `string`.\n */\nfunction unicodeWords(string) {\n  return string.match(reUnicodeWord) || [];\n}\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar Symbol$1 = root$2.Symbol;\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol$1 ? Symbol$1.prototype : undefined,\n    symbolToString = symbolProto ? symbolProto.toString : undefined;\n\n/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.toString` which doesn't convert nullish\n * values to empty strings.\n *\n * @private\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n */\nfunction baseToString(value) {\n  // Exit early for strings to avoid a performance hit in some environments.\n  if (typeof value == 'string') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return symbolToString ? symbolToString.call(value) : '';\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\n/**\n * Casts `array` to a slice if it's needed.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {number} start The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the cast slice.\n */\nfunction castSlice(array, start, end) {\n  var length = array.length;\n  end = end === undefined ? length : end;\n  return (!start && end >= length) ? array : baseSlice(array, start, end);\n}\n\n/**\n * Creates a function like `_.lowerFirst`.\n *\n * @private\n * @param {string} methodName The name of the `String` case method to use.\n * @returns {Function} Returns the new case function.\n */\nfunction createCaseFirst(methodName) {\n  return function(string) {\n    string = toString(string);\n\n    var strSymbols = hasUnicode(string)\n      ? stringToArray(string)\n      : undefined;\n\n    var chr = strSymbols\n      ? strSymbols[0]\n      : string.charAt(0);\n\n    var trailing = strSymbols\n      ? castSlice(strSymbols, 1).join('')\n      : string.slice(1);\n\n    return chr[methodName]() + trailing;\n  };\n}\n\n/**\n * Creates a function like `_.camelCase`.\n *\n * @private\n * @param {Function} callback The function to combine each word.\n * @returns {Function} Returns the new compounder function.\n */\nfunction createCompounder(callback) {\n  return function(string) {\n    return arrayReduce(words(deburr(string).replace(reApos, '')), callback, '');\n  };\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * Checks if `value` is classified as a `Symbol` primitive or object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.\n * @example\n *\n * _.isSymbol(Symbol.iterator);\n * // => true\n *\n * _.isSymbol('abc');\n * // => false\n */\nfunction isSymbol(value) {\n  return typeof value == 'symbol' ||\n    (isObjectLike(value) && objectToString.call(value) == symbolTag);\n}\n\n/**\n * Converts `value` to a string. An empty string is returned for `null`\n * and `undefined` values. The sign of `-0` is preserved.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n * @example\n *\n * _.toString(null);\n * // => ''\n *\n * _.toString(-0);\n * // => '-0'\n *\n * _.toString([1, 2, 3]);\n * // => '1,2,3'\n */\nfunction toString(value) {\n  return value == null ? '' : baseToString(value);\n}\n\n/**\n * Converts `string` to [camel case](https://en.wikipedia.org/wiki/CamelCase).\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to convert.\n * @returns {string} Returns the camel cased string.\n * @example\n *\n * _.camelCase('Foo Bar');\n * // => 'fooBar'\n *\n * _.camelCase('--foo-bar--');\n * // => 'fooBar'\n *\n * _.camelCase('__FOO_BAR__');\n * // => 'fooBar'\n */\nvar camelCase = createCompounder(function(result, word, index) {\n  word = word.toLowerCase();\n  return result + (index ? capitalize(word) : word);\n});\n\n/**\n * Converts the first character of `string` to upper case and the remaining\n * to lower case.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to capitalize.\n * @returns {string} Returns the capitalized string.\n * @example\n *\n * _.capitalize('FRED');\n * // => 'Fred'\n */\nfunction capitalize(string) {\n  return upperFirst(toString(string).toLowerCase());\n}\n\n/**\n * Deburrs `string` by converting\n * [Latin-1 Supplement](https://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block)#Character_table)\n * and [Latin Extended-A](https://en.wikipedia.org/wiki/Latin_Extended-A)\n * letters to basic Latin letters and removing\n * [combining diacritical marks](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks).\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to deburr.\n * @returns {string} Returns the deburred string.\n * @example\n *\n * _.deburr('déjà vu');\n * // => 'deja vu'\n */\nfunction deburr(string) {\n  string = toString(string);\n  return string && string.replace(reLatin, deburrLetter).replace(reComboMark, '');\n}\n\n/**\n * Converts the first character of `string` to upper case.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category String\n * @param {string} [string=''] The string to convert.\n * @returns {string} Returns the converted string.\n * @example\n *\n * _.upperFirst('fred');\n * // => 'Fred'\n *\n * _.upperFirst('FRED');\n * // => 'FRED'\n */\nvar upperFirst = createCaseFirst('toUpperCase');\n\n/**\n * Splits `string` into an array of its words.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to inspect.\n * @param {RegExp|string} [pattern] The pattern to match words.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the words of `string`.\n * @example\n *\n * _.words('fred, barney, & pebbles');\n * // => ['fred', 'barney', 'pebbles']\n *\n * _.words('fred, barney, & pebbles', /[^, ]+/g);\n * // => ['fred', 'barney', '&', 'pebbles']\n */\nfunction words(string, pattern, guard) {\n  string = toString(string);\n  pattern = guard ? undefined : pattern;\n\n  if (pattern === undefined) {\n    return hasUnicodeWord(string) ? unicodeWords(string) : asciiWords(string);\n  }\n  return string.match(pattern) || [];\n}\n\nvar lodash_camelcase = camelCase;\n\nObject.defineProperty(localsConvention, \"__esModule\", {\n  value: true\n});\nlocalsConvention.makeLocalsConventionReducer = makeLocalsConventionReducer;\n\nvar _lodash = _interopRequireDefault$5(lodash_camelcase);\n\nfunction _interopRequireDefault$5(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction dashesCamelCase(string) {\n  return string.replace(/-+(\\w)/g, (_, firstLetter) => firstLetter.toUpperCase());\n}\n\nfunction makeLocalsConventionReducer(localsConvention, inputFile) {\n  const isFunc = typeof localsConvention === \"function\";\n  return (tokens, [className, value]) => {\n    if (isFunc) {\n      const convention = localsConvention(className, value, inputFile);\n      tokens[convention] = value;\n      return tokens;\n    }\n\n    switch (localsConvention) {\n      case \"camelCase\":\n        tokens[className] = value;\n        tokens[(0, _lodash.default)(className)] = value;\n        break;\n\n      case \"camelCaseOnly\":\n        tokens[(0, _lodash.default)(className)] = value;\n        break;\n\n      case \"dashes\":\n        tokens[className] = value;\n        tokens[dashesCamelCase(className)] = value;\n        break;\n\n      case \"dashesOnly\":\n        tokens[dashesCamelCase(className)] = value;\n        break;\n    }\n\n    return tokens;\n  };\n}\n\nvar FileSystemLoader$1 = {};\n\nObject.defineProperty(FileSystemLoader$1, \"__esModule\", {\n  value: true\n});\nFileSystemLoader$1.default = void 0;\n\nvar _postcss$1 = _interopRequireDefault$4(require$$0);\n\nvar _path = _interopRequireDefault$4(require$$0$1);\n\nvar _Parser$1 = _interopRequireDefault$4(Parser$1);\n\nvar _fs$1 = fs;\n\nfunction _interopRequireDefault$4(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// Initially copied from https://github.com/css-modules/css-modules-loader-core\nclass Core {\n  constructor(plugins) {\n    this.plugins = plugins || Core.defaultPlugins;\n  }\n\n  async load(sourceString, sourcePath, trace, pathFetcher) {\n    const parser = new _Parser$1.default(pathFetcher, trace);\n    const plugins = this.plugins.concat([parser.plugin()]);\n    const result = await (0, _postcss$1.default)(plugins).process(sourceString, {\n      from: sourcePath\n    });\n    return {\n      injectableSource: result.css,\n      exportTokens: parser.exportTokens\n    };\n  }\n\n} // Sorts dependencies in the following way:\n// AAA comes before AA and A\n// AB comes after AA and before A\n// All Bs come after all As\n// This ensures that the files are always returned in the following order:\n// - In the order they were required, except\n// - After all their dependencies\n\n\nconst traceKeySorter = (a, b) => {\n  if (a.length < b.length) {\n    return a < b.substring(0, a.length) ? -1 : 1;\n  }\n\n  if (a.length > b.length) {\n    return a.substring(0, b.length) <= b ? -1 : 1;\n  }\n\n  return a < b ? -1 : 1;\n};\n\nclass FileSystemLoader {\n  constructor(root, plugins, fileResolve) {\n    if (root === \"/\" && process.platform === \"win32\") {\n      const cwdDrive = process.cwd().slice(0, 3);\n\n      if (!/^[A-Za-z]:\\\\$/.test(cwdDrive)) {\n        throw new Error(`Failed to obtain root from \"${process.cwd()}\".`);\n      }\n\n      root = cwdDrive;\n    }\n\n    this.root = root;\n    this.fileResolve = fileResolve;\n    this.sources = {};\n    this.traces = {};\n    this.importNr = 0;\n    this.core = new Core(plugins);\n    this.tokensByFile = {};\n    this.fs = (0, _fs$1.getFileSystem)();\n  }\n\n  async fetch(_newPath, relativeTo, _trace) {\n    const newPath = _newPath.replace(/^[\"']|[\"']$/g, \"\");\n\n    const trace = _trace || String.fromCharCode(this.importNr++);\n\n    const useFileResolve = typeof this.fileResolve === \"function\";\n    const fileResolvedPath = useFileResolve ? await this.fileResolve(newPath, relativeTo) : await Promise.resolve();\n\n    if (fileResolvedPath && !_path.default.isAbsolute(fileResolvedPath)) {\n      throw new Error('The returned path from the \"fileResolve\" option must be absolute.');\n    }\n\n    const relativeDir = _path.default.dirname(relativeTo);\n\n    const rootRelativePath = fileResolvedPath || _path.default.resolve(relativeDir, newPath);\n\n    let fileRelativePath = fileResolvedPath || _path.default.resolve(_path.default.resolve(this.root, relativeDir), newPath); // if the path is not relative or absolute, try to resolve it in node_modules\n\n\n    if (!useFileResolve && newPath[0] !== \".\" && !_path.default.isAbsolute(newPath)) {\n      try {\n        fileRelativePath = require.resolve(newPath);\n      } catch (e) {// noop\n      }\n    }\n\n    const tokens = this.tokensByFile[fileRelativePath];\n    if (tokens) return tokens;\n    return new Promise((resolve, reject) => {\n      this.fs.readFile(fileRelativePath, \"utf-8\", async (err, source) => {\n        if (err) reject(err);\n        const {\n          injectableSource,\n          exportTokens\n        } = await this.core.load(source, rootRelativePath, trace, this.fetch.bind(this));\n        this.sources[fileRelativePath] = injectableSource;\n        this.traces[trace] = fileRelativePath;\n        this.tokensByFile[fileRelativePath] = exportTokens;\n        resolve(exportTokens);\n      });\n    });\n  }\n\n  get finalSource() {\n    const traces = this.traces;\n    const sources = this.sources;\n    let written = new Set();\n    return Object.keys(traces).sort(traceKeySorter).map(key => {\n      const filename = traces[key];\n\n      if (written.has(filename)) {\n        return null;\n      }\n\n      written.add(filename);\n      return sources[filename];\n    }).join(\"\");\n  }\n\n}\n\nFileSystemLoader$1.default = FileSystemLoader;\n\nvar scoping = {};\n\nvar srcExports$2 = {};\nvar src$3 = {\n  get exports(){ return srcExports$2; },\n  set exports(v){ srcExports$2 = v; },\n};\n\nconst PERMANENT_MARKER = 2;\nconst TEMPORARY_MARKER = 1;\n\nfunction createError(node, graph) {\n  const er = new Error(\"Nondeterministic import's order\");\n\n  const related = graph[node];\n  const relatedNode = related.find(\n    (relatedNode) => graph[relatedNode].indexOf(node) > -1\n  );\n\n  er.nodes = [node, relatedNode];\n\n  return er;\n}\n\nfunction walkGraph(node, graph, state, result, strict) {\n  if (state[node] === PERMANENT_MARKER) {\n    return;\n  }\n\n  if (state[node] === TEMPORARY_MARKER) {\n    if (strict) {\n      return createError(node, graph);\n    }\n\n    return;\n  }\n\n  state[node] = TEMPORARY_MARKER;\n\n  const children = graph[node];\n  const length = children.length;\n\n  for (let i = 0; i < length; ++i) {\n    const error = walkGraph(children[i], graph, state, result, strict);\n\n    if (error instanceof Error) {\n      return error;\n    }\n  }\n\n  state[node] = PERMANENT_MARKER;\n\n  result.push(node);\n}\n\nfunction topologicalSort$1(graph, strict) {\n  const result = [];\n  const state = {};\n\n  const nodes = Object.keys(graph);\n  const length = nodes.length;\n\n  for (let i = 0; i < length; ++i) {\n    const er = walkGraph(nodes[i], graph, state, result, strict);\n\n    if (er instanceof Error) {\n      return er;\n    }\n  }\n\n  return result;\n}\n\nvar topologicalSort_1 = topologicalSort$1;\n\nconst topologicalSort = topologicalSort_1;\n\nconst matchImports$1 = /^(.+?)\\s+from\\s+(?:\"([^\"]+)\"|'([^']+)'|(global))$/;\nconst icssImport = /^:import\\((?:\"([^\"]+)\"|'([^']+)')\\)/;\n\nconst VISITED_MARKER = 1;\n\n/**\n * :import('G') {}\n *\n * Rule\n *   composes: ... from 'A'\n *   composes: ... from 'B'\n\n * Rule\n *   composes: ... from 'A'\n *   composes: ... from 'A'\n *   composes: ... from 'C'\n *\n * Results in:\n *\n * graph: {\n *   G: [],\n *   A: [],\n *   B: ['A'],\n *   C: ['A'],\n * }\n */\nfunction addImportToGraph(importId, parentId, graph, visited) {\n  const siblingsId = parentId + \"_\" + \"siblings\";\n  const visitedId = parentId + \"_\" + importId;\n\n  if (visited[visitedId] !== VISITED_MARKER) {\n    if (!Array.isArray(visited[siblingsId])) {\n      visited[siblingsId] = [];\n    }\n\n    const siblings = visited[siblingsId];\n\n    if (Array.isArray(graph[importId])) {\n      graph[importId] = graph[importId].concat(siblings);\n    } else {\n      graph[importId] = siblings.slice();\n    }\n\n    visited[visitedId] = VISITED_MARKER;\n\n    siblings.push(importId);\n  }\n}\n\nsrc$3.exports = (options = {}) => {\n  let importIndex = 0;\n  const createImportedName =\n    typeof options.createImportedName !== \"function\"\n      ? (importName /*, path*/) =>\n          `i__imported_${importName.replace(/\\W/g, \"_\")}_${importIndex++}`\n      : options.createImportedName;\n  const failOnWrongOrder = options.failOnWrongOrder;\n\n  return {\n    postcssPlugin: \"postcss-modules-extract-imports\",\n    prepare() {\n      const graph = {};\n      const visited = {};\n      const existingImports = {};\n      const importDecls = {};\n      const imports = {};\n\n      return {\n        Once(root, postcss) {\n          // Check the existing imports order and save refs\n          root.walkRules((rule) => {\n            const matches = icssImport.exec(rule.selector);\n\n            if (matches) {\n              const [, /*match*/ doubleQuotePath, singleQuotePath] = matches;\n              const importPath = doubleQuotePath || singleQuotePath;\n\n              addImportToGraph(importPath, \"root\", graph, visited);\n\n              existingImports[importPath] = rule;\n            }\n          });\n\n          root.walkDecls(/^composes$/, (declaration) => {\n            const matches = declaration.value.match(matchImports$1);\n\n            if (!matches) {\n              return;\n            }\n\n            let tmpSymbols;\n            let [\n              ,\n              /*match*/ symbols,\n              doubleQuotePath,\n              singleQuotePath,\n              global,\n            ] = matches;\n\n            if (global) {\n              // Composing globals simply means changing these classes to wrap them in global(name)\n              tmpSymbols = symbols.split(/\\s+/).map((s) => `global(${s})`);\n            } else {\n              const importPath = doubleQuotePath || singleQuotePath;\n\n              let parent = declaration.parent;\n              let parentIndexes = \"\";\n\n              while (parent.type !== \"root\") {\n                parentIndexes =\n                  parent.parent.index(parent) + \"_\" + parentIndexes;\n                parent = parent.parent;\n              }\n\n              const { selector } = declaration.parent;\n              const parentRule = `_${parentIndexes}${selector}`;\n\n              addImportToGraph(importPath, parentRule, graph, visited);\n\n              importDecls[importPath] = declaration;\n              imports[importPath] = imports[importPath] || {};\n\n              tmpSymbols = symbols.split(/\\s+/).map((s) => {\n                if (!imports[importPath][s]) {\n                  imports[importPath][s] = createImportedName(s, importPath);\n                }\n\n                return imports[importPath][s];\n              });\n            }\n\n            declaration.value = tmpSymbols.join(\" \");\n          });\n\n          const importsOrder = topologicalSort(graph, failOnWrongOrder);\n\n          if (importsOrder instanceof Error) {\n            const importPath = importsOrder.nodes.find((importPath) =>\n              // eslint-disable-next-line no-prototype-builtins\n              importDecls.hasOwnProperty(importPath)\n            );\n            const decl = importDecls[importPath];\n\n            throw decl.error(\n              \"Failed to resolve order of composed modules \" +\n                importsOrder.nodes\n                  .map((importPath) => \"`\" + importPath + \"`\")\n                  .join(\", \") +\n                \".\",\n              {\n                plugin: \"postcss-modules-extract-imports\",\n                word: \"composes\",\n              }\n            );\n          }\n\n          let lastImportRule;\n\n          importsOrder.forEach((path) => {\n            const importedSymbols = imports[path];\n            let rule = existingImports[path];\n\n            if (!rule && importedSymbols) {\n              rule = postcss.rule({\n                selector: `:import(\"${path}\")`,\n                raws: { after: \"\\n\" },\n              });\n\n              if (lastImportRule) {\n                root.insertAfter(lastImportRule, rule);\n              } else {\n                root.prepend(rule);\n              }\n            }\n\n            lastImportRule = rule;\n\n            if (!importedSymbols) {\n              return;\n            }\n\n            Object.keys(importedSymbols).forEach((importedSymbol) => {\n              rule.append(\n                postcss.decl({\n                  value: importedSymbol,\n                  prop: importedSymbols[importedSymbol],\n                  raws: { before: \"\\n  \" },\n                })\n              );\n            });\n          });\n        },\n      };\n    },\n  };\n};\n\nsrcExports$2.postcss = true;\n\nvar wasmHashExports = {};\nvar wasmHash = {\n  get exports(){ return wasmHashExports; },\n  set exports(v){ wasmHashExports = v; },\n};\n\n/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\nvar hasRequiredWasmHash;\n\nfunction requireWasmHash () {\n\tif (hasRequiredWasmHash) return wasmHashExports;\n\thasRequiredWasmHash = 1;\n\n\t// 65536 is the size of a wasm memory page\n\t// 64 is the maximum chunk size for every possible wasm hash implementation\n\t// 4 is the maximum number of bytes per char for string encoding (max is utf-8)\n\t// ~3 makes sure that it's always a block of 4 chars, so avoid partially encoded bytes for base64\n\tconst MAX_SHORT_STRING = Math.floor((65536 - 64) / 4) & ~3;\n\n\tclass WasmHash {\n\t  /**\n\t   * @param {WebAssembly.Instance} instance wasm instance\n\t   * @param {WebAssembly.Instance[]} instancesPool pool of instances\n\t   * @param {number} chunkSize size of data chunks passed to wasm\n\t   * @param {number} digestSize size of digest returned by wasm\n\t   */\n\t  constructor(instance, instancesPool, chunkSize, digestSize) {\n\t    const exports = /** @type {any} */ (instance.exports);\n\n\t    exports.init();\n\n\t    this.exports = exports;\n\t    this.mem = Buffer.from(exports.memory.buffer, 0, 65536);\n\t    this.buffered = 0;\n\t    this.instancesPool = instancesPool;\n\t    this.chunkSize = chunkSize;\n\t    this.digestSize = digestSize;\n\t  }\n\n\t  reset() {\n\t    this.buffered = 0;\n\t    this.exports.init();\n\t  }\n\n\t  /**\n\t   * @param {Buffer | string} data data\n\t   * @param {BufferEncoding=} encoding encoding\n\t   * @returns {this} itself\n\t   */\n\t  update(data, encoding) {\n\t    if (typeof data === \"string\") {\n\t      while (data.length > MAX_SHORT_STRING) {\n\t        this._updateWithShortString(data.slice(0, MAX_SHORT_STRING), encoding);\n\t        data = data.slice(MAX_SHORT_STRING);\n\t      }\n\n\t      this._updateWithShortString(data, encoding);\n\n\t      return this;\n\t    }\n\n\t    this._updateWithBuffer(data);\n\n\t    return this;\n\t  }\n\n\t  /**\n\t   * @param {string} data data\n\t   * @param {BufferEncoding=} encoding encoding\n\t   * @returns {void}\n\t   */\n\t  _updateWithShortString(data, encoding) {\n\t    const { exports, buffered, mem, chunkSize } = this;\n\n\t    let endPos;\n\n\t    if (data.length < 70) {\n\t      if (!encoding || encoding === \"utf-8\" || encoding === \"utf8\") {\n\t        endPos = buffered;\n\t        for (let i = 0; i < data.length; i++) {\n\t          const cc = data.charCodeAt(i);\n\n\t          if (cc < 0x80) {\n\t            mem[endPos++] = cc;\n\t          } else if (cc < 0x800) {\n\t            mem[endPos] = (cc >> 6) | 0xc0;\n\t            mem[endPos + 1] = (cc & 0x3f) | 0x80;\n\t            endPos += 2;\n\t          } else {\n\t            // bail-out for weird chars\n\t            endPos += mem.write(data.slice(i), endPos, encoding);\n\t            break;\n\t          }\n\t        }\n\t      } else if (encoding === \"latin1\") {\n\t        endPos = buffered;\n\n\t        for (let i = 0; i < data.length; i++) {\n\t          const cc = data.charCodeAt(i);\n\n\t          mem[endPos++] = cc;\n\t        }\n\t      } else {\n\t        endPos = buffered + mem.write(data, buffered, encoding);\n\t      }\n\t    } else {\n\t      endPos = buffered + mem.write(data, buffered, encoding);\n\t    }\n\n\t    if (endPos < chunkSize) {\n\t      this.buffered = endPos;\n\t    } else {\n\t      const l = endPos & ~(this.chunkSize - 1);\n\n\t      exports.update(l);\n\n\t      const newBuffered = endPos - l;\n\n\t      this.buffered = newBuffered;\n\n\t      if (newBuffered > 0) {\n\t        mem.copyWithin(0, l, endPos);\n\t      }\n\t    }\n\t  }\n\n\t  /**\n\t   * @param {Buffer} data data\n\t   * @returns {void}\n\t   */\n\t  _updateWithBuffer(data) {\n\t    const { exports, buffered, mem } = this;\n\t    const length = data.length;\n\n\t    if (buffered + length < this.chunkSize) {\n\t      data.copy(mem, buffered, 0, length);\n\n\t      this.buffered += length;\n\t    } else {\n\t      const l = (buffered + length) & ~(this.chunkSize - 1);\n\n\t      if (l > 65536) {\n\t        let i = 65536 - buffered;\n\n\t        data.copy(mem, buffered, 0, i);\n\t        exports.update(65536);\n\n\t        const stop = l - buffered - 65536;\n\n\t        while (i < stop) {\n\t          data.copy(mem, 0, i, i + 65536);\n\t          exports.update(65536);\n\t          i += 65536;\n\t        }\n\n\t        data.copy(mem, 0, i, l - buffered);\n\n\t        exports.update(l - buffered - i);\n\t      } else {\n\t        data.copy(mem, buffered, 0, l - buffered);\n\n\t        exports.update(l);\n\t      }\n\n\t      const newBuffered = length + buffered - l;\n\n\t      this.buffered = newBuffered;\n\n\t      if (newBuffered > 0) {\n\t        data.copy(mem, 0, length - newBuffered, length);\n\t      }\n\t    }\n\t  }\n\n\t  digest(type) {\n\t    const { exports, buffered, mem, digestSize } = this;\n\n\t    exports.final(buffered);\n\n\t    this.instancesPool.push(this);\n\n\t    const hex = mem.toString(\"latin1\", 0, digestSize);\n\n\t    if (type === \"hex\") {\n\t      return hex;\n\t    }\n\n\t    if (type === \"binary\" || !type) {\n\t      return Buffer.from(hex, \"hex\");\n\t    }\n\n\t    return Buffer.from(hex, \"hex\").toString(type);\n\t  }\n\t}\n\n\tconst create = (wasmModule, instancesPool, chunkSize, digestSize) => {\n\t  if (instancesPool.length > 0) {\n\t    const old = instancesPool.pop();\n\n\t    old.reset();\n\n\t    return old;\n\t  } else {\n\t    return new WasmHash(\n\t      new WebAssembly.Instance(wasmModule),\n\t      instancesPool,\n\t      chunkSize,\n\t      digestSize\n\t    );\n\t  }\n\t};\n\n\twasmHash.exports = create;\n\twasmHashExports.MAX_SHORT_STRING = MAX_SHORT_STRING;\n\treturn wasmHashExports;\n}\n\n/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\nvar xxhash64_1;\nvar hasRequiredXxhash64;\n\nfunction requireXxhash64 () {\n\tif (hasRequiredXxhash64) return xxhash64_1;\n\thasRequiredXxhash64 = 1;\n\n\tconst create = requireWasmHash();\n\n\t//#region wasm code: xxhash64 (../../../assembly/hash/xxhash64.asm.ts) --initialMemory 1\n\tconst xxhash64 = new WebAssembly.Module(\n\t  Buffer.from(\n\t    // 1173 bytes\n\t    \"AGFzbQEAAAABCAJgAX8AYAAAAwQDAQAABQMBAAEGGgV+AUIAC34BQgALfgFCAAt+AUIAC34BQgALByIEBGluaXQAAAZ1cGRhdGUAAQVmaW5hbAACBm1lbW9yeQIACrUIAzAAQtbrgu7q/Yn14AAkAELP1tO+0ser2UIkAUIAJAJC+erQ0OfJoeThACQDQgAkBAvUAQIBfwR+IABFBEAPCyMEIACtfCQEIwAhAiMBIQMjAiEEIwMhBQNAIAIgASkDAELP1tO+0ser2UJ+fEIfiUKHla+vmLbem55/fiECIAMgASkDCELP1tO+0ser2UJ+fEIfiUKHla+vmLbem55/fiEDIAQgASkDEELP1tO+0ser2UJ+fEIfiUKHla+vmLbem55/fiEEIAUgASkDGELP1tO+0ser2UJ+fEIfiUKHla+vmLbem55/fiEFIAAgAUEgaiIBSw0ACyACJAAgAyQBIAQkAiAFJAMLqwYCAX8EfiMEQgBSBH4jACICQgGJIwEiA0IHiXwjAiIEQgyJfCMDIgVCEol8IAJCz9bTvtLHq9lCfkIfiUKHla+vmLbem55/foVCh5Wvr5i23puef35CnaO16oOxjYr6AH0gA0LP1tO+0ser2UJ+Qh+JQoeVr6+Ytt6bnn9+hUKHla+vmLbem55/fkKdo7Xqg7GNivoAfSAEQs/W077Sx6vZQn5CH4lCh5Wvr5i23puef36FQoeVr6+Ytt6bnn9+Qp2jteqDsY2K+gB9IAVCz9bTvtLHq9lCfkIfiUKHla+vmLbem55/foVCh5Wvr5i23puef35CnaO16oOxjYr6AH0FQsXP2bLx5brqJwsjBCAArXx8IQIDQCABQQhqIABNBEAgAiABKQMAQs/W077Sx6vZQn5CH4lCh5Wvr5i23puef36FQhuJQoeVr6+Ytt6bnn9+Qp2jteqDsY2K+gB9IQIgAUEIaiEBDAELCyABQQRqIABNBEACfyACIAE1AgBCh5Wvr5i23puef36FQheJQs/W077Sx6vZQn5C+fPd8Zn2masWfCECIAFBBGoLIQELA0AgACABRwRAIAIgATEAAELFz9my8eW66id+hUILiUKHla+vmLbem55/fiECIAFBAWohAQwBCwtBACACIAJCIYiFQs/W077Sx6vZQn4iAiACQh2IhUL5893xmfaZqxZ+IgIgAkIgiIUiAkIgiCIDQv//A4NCIIYgA0KAgPz/D4NCEIiEIgNC/4GAgPAfg0IQhiADQoD+g4CA4D+DQgiIhCIDQo+AvIDwgcAHg0IIhiADQvCBwIeAnoD4AINCBIiEIgNChoyYsODAgYMGfEIEiEKBgoSIkKDAgAGDQid+IANCsODAgYOGjJgwhHw3AwBBCCACQv////8PgyICQv//A4NCIIYgAkKAgPz/D4NCEIiEIgJC/4GAgPAfg0IQhiACQoD+g4CA4D+DQgiIhCICQo+AvIDwgcAHg0IIhiACQvCBwIeAnoD4AINCBIiEIgJChoyYsODAgYMGfEIEiEKBgoSIkKDAgAGDQid+IAJCsODAgYOGjJgwhHw3AwAL\",\n\t    \"base64\"\n\t  )\n\t);\n\t//#endregion\n\n\txxhash64_1 = create.bind(null, xxhash64, [], 32, 16);\n\treturn xxhash64_1;\n}\n\nvar BatchedHash_1;\nvar hasRequiredBatchedHash;\n\nfunction requireBatchedHash () {\n\tif (hasRequiredBatchedHash) return BatchedHash_1;\n\thasRequiredBatchedHash = 1;\n\tconst MAX_SHORT_STRING = requireWasmHash().MAX_SHORT_STRING;\n\n\tclass BatchedHash {\n\t  constructor(hash) {\n\t    this.string = undefined;\n\t    this.encoding = undefined;\n\t    this.hash = hash;\n\t  }\n\n\t  /**\n\t   * Update hash {@link https://nodejs.org/api/crypto.html#crypto_hash_update_data_inputencoding}\n\t   * @param {string|Buffer} data data\n\t   * @param {string=} inputEncoding data encoding\n\t   * @returns {this} updated hash\n\t   */\n\t  update(data, inputEncoding) {\n\t    if (this.string !== undefined) {\n\t      if (\n\t        typeof data === \"string\" &&\n\t        inputEncoding === this.encoding &&\n\t        this.string.length + data.length < MAX_SHORT_STRING\n\t      ) {\n\t        this.string += data;\n\n\t        return this;\n\t      }\n\n\t      this.hash.update(this.string, this.encoding);\n\t      this.string = undefined;\n\t    }\n\n\t    if (typeof data === \"string\") {\n\t      if (\n\t        data.length < MAX_SHORT_STRING &&\n\t        // base64 encoding is not valid since it may contain padding chars\n\t        (!inputEncoding || !inputEncoding.startsWith(\"ba\"))\n\t      ) {\n\t        this.string = data;\n\t        this.encoding = inputEncoding;\n\t      } else {\n\t        this.hash.update(data, inputEncoding);\n\t      }\n\t    } else {\n\t      this.hash.update(data);\n\t    }\n\n\t    return this;\n\t  }\n\n\t  /**\n\t   * Calculates the digest {@link https://nodejs.org/api/crypto.html#crypto_hash_digest_encoding}\n\t   * @param {string=} encoding encoding of the return value\n\t   * @returns {string|Buffer} digest\n\t   */\n\t  digest(encoding) {\n\t    if (this.string !== undefined) {\n\t      this.hash.update(this.string, this.encoding);\n\t    }\n\n\t    return this.hash.digest(encoding);\n\t  }\n\t}\n\n\tBatchedHash_1 = BatchedHash;\n\treturn BatchedHash_1;\n}\n\n/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\nvar md4_1;\nvar hasRequiredMd4;\n\nfunction requireMd4 () {\n\tif (hasRequiredMd4) return md4_1;\n\thasRequiredMd4 = 1;\n\n\tconst create = requireWasmHash();\n\n\t//#region wasm code: md4 (../../../assembly/hash/md4.asm.ts) --initialMemory 1\n\tconst md4 = new WebAssembly.Module(\n\t  Buffer.from(\n\t    // 2150 bytes\n\t    \"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\",\n\t    \"base64\"\n\t  )\n\t);\n\t//#endregion\n\n\tmd4_1 = create.bind(null, md4, [], 64, 32);\n\treturn md4_1;\n}\n\nvar BulkUpdateDecorator_1;\nvar hasRequiredBulkUpdateDecorator;\n\nfunction requireBulkUpdateDecorator () {\n\tif (hasRequiredBulkUpdateDecorator) return BulkUpdateDecorator_1;\n\thasRequiredBulkUpdateDecorator = 1;\n\tconst BULK_SIZE = 2000;\n\n\t// We are using an object instead of a Map as this will stay static during the runtime\n\t// so access to it can be optimized by v8\n\tconst digestCaches = {};\n\n\tclass BulkUpdateDecorator {\n\t  /**\n\t   * @param {Hash | function(): Hash} hashOrFactory function to create a hash\n\t   * @param {string=} hashKey key for caching\n\t   */\n\t  constructor(hashOrFactory, hashKey) {\n\t    this.hashKey = hashKey;\n\n\t    if (typeof hashOrFactory === \"function\") {\n\t      this.hashFactory = hashOrFactory;\n\t      this.hash = undefined;\n\t    } else {\n\t      this.hashFactory = undefined;\n\t      this.hash = hashOrFactory;\n\t    }\n\n\t    this.buffer = \"\";\n\t  }\n\n\t  /**\n\t   * Update hash {@link https://nodejs.org/api/crypto.html#crypto_hash_update_data_inputencoding}\n\t   * @param {string|Buffer} data data\n\t   * @param {string=} inputEncoding data encoding\n\t   * @returns {this} updated hash\n\t   */\n\t  update(data, inputEncoding) {\n\t    if (\n\t      inputEncoding !== undefined ||\n\t      typeof data !== \"string\" ||\n\t      data.length > BULK_SIZE\n\t    ) {\n\t      if (this.hash === undefined) {\n\t        this.hash = this.hashFactory();\n\t      }\n\n\t      if (this.buffer.length > 0) {\n\t        this.hash.update(this.buffer);\n\t        this.buffer = \"\";\n\t      }\n\n\t      this.hash.update(data, inputEncoding);\n\t    } else {\n\t      this.buffer += data;\n\n\t      if (this.buffer.length > BULK_SIZE) {\n\t        if (this.hash === undefined) {\n\t          this.hash = this.hashFactory();\n\t        }\n\n\t        this.hash.update(this.buffer);\n\t        this.buffer = \"\";\n\t      }\n\t    }\n\n\t    return this;\n\t  }\n\n\t  /**\n\t   * Calculates the digest {@link https://nodejs.org/api/crypto.html#crypto_hash_digest_encoding}\n\t   * @param {string=} encoding encoding of the return value\n\t   * @returns {string|Buffer} digest\n\t   */\n\t  digest(encoding) {\n\t    let digestCache;\n\n\t    const buffer = this.buffer;\n\n\t    if (this.hash === undefined) {\n\t      // short data for hash, we can use caching\n\t      const cacheKey = `${this.hashKey}-${encoding}`;\n\n\t      digestCache = digestCaches[cacheKey];\n\n\t      if (digestCache === undefined) {\n\t        digestCache = digestCaches[cacheKey] = new Map();\n\t      }\n\n\t      const cacheEntry = digestCache.get(buffer);\n\n\t      if (cacheEntry !== undefined) {\n\t        return cacheEntry;\n\t      }\n\n\t      this.hash = this.hashFactory();\n\t    }\n\n\t    if (buffer.length > 0) {\n\t      this.hash.update(buffer);\n\t    }\n\n\t    const digestResult = this.hash.digest(encoding);\n\n\t    if (digestCache !== undefined) {\n\t      digestCache.set(buffer, digestResult);\n\t    }\n\n\t    return digestResult;\n\t  }\n\t}\n\n\tBulkUpdateDecorator_1 = BulkUpdateDecorator;\n\treturn BulkUpdateDecorator_1;\n}\n\nconst baseEncodeTables = {\n  26: \"abcdefghijklmnopqrstuvwxyz\",\n  32: \"123456789abcdefghjkmnpqrstuvwxyz\", // no 0lio\n  36: \"0123456789abcdefghijklmnopqrstuvwxyz\",\n  49: \"abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ\", // no lIO\n  52: \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\",\n  58: \"123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ\", // no 0lIO\n  62: \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\",\n  64: \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-_\",\n};\n\n/**\n * @param {Uint32Array} uint32Array Treated as a long base-0x100000000 number, little endian\n * @param {number} divisor The divisor\n * @return {number} Modulo (remainder) of the division\n */\nfunction divmod32(uint32Array, divisor) {\n  let carry = 0;\n  for (let i = uint32Array.length - 1; i >= 0; i--) {\n    const value = carry * 0x100000000 + uint32Array[i];\n    carry = value % divisor;\n    uint32Array[i] = Math.floor(value / divisor);\n  }\n  return carry;\n}\n\nfunction encodeBufferToBase(buffer, base, length) {\n  const encodeTable = baseEncodeTables[base];\n\n  if (!encodeTable) {\n    throw new Error(\"Unknown encoding base\" + base);\n  }\n\n  // Input bits are only enough to generate this many characters\n  const limit = Math.ceil((buffer.length * 8) / Math.log2(base));\n  length = Math.min(length, limit);\n\n  // Most of the crypto digests (if not all) has length a multiple of 4 bytes.\n  // Fewer numbers in the array means faster math.\n  const uint32Array = new Uint32Array(Math.ceil(buffer.length / 4));\n\n  // Make sure the input buffer data is copied and is not mutated by reference.\n  // divmod32() would corrupt the BulkUpdateDecorator cache otherwise.\n  buffer.copy(Buffer.from(uint32Array.buffer));\n\n  let output = \"\";\n\n  for (let i = 0; i < length; i++) {\n    output = encodeTable[divmod32(uint32Array, base)] + output;\n  }\n\n  return output;\n}\n\nlet crypto = undefined;\nlet createXXHash64 = undefined;\nlet createMd4 = undefined;\nlet BatchedHash = undefined;\nlet BulkUpdateDecorator = undefined;\n\nfunction getHashDigest$1(buffer, algorithm, digestType, maxLength) {\n  algorithm = algorithm || \"xxhash64\";\n  maxLength = maxLength || 9999;\n\n  let hash;\n\n  if (algorithm === \"xxhash64\") {\n    if (createXXHash64 === undefined) {\n      createXXHash64 = requireXxhash64();\n\n      if (BatchedHash === undefined) {\n        BatchedHash = requireBatchedHash();\n      }\n    }\n\n    hash = new BatchedHash(createXXHash64());\n  } else if (algorithm === \"md4\") {\n    if (createMd4 === undefined) {\n      createMd4 = requireMd4();\n\n      if (BatchedHash === undefined) {\n        BatchedHash = requireBatchedHash();\n      }\n    }\n\n    hash = new BatchedHash(createMd4());\n  } else if (algorithm === \"native-md4\") {\n    if (typeof crypto === \"undefined\") {\n      crypto = require$$5;\n\n      if (BulkUpdateDecorator === undefined) {\n        BulkUpdateDecorator = requireBulkUpdateDecorator();\n      }\n    }\n\n    hash = new BulkUpdateDecorator(() => crypto.createHash(\"md4\"), \"md4\");\n  } else {\n    if (typeof crypto === \"undefined\") {\n      crypto = require$$5;\n\n      if (BulkUpdateDecorator === undefined) {\n        BulkUpdateDecorator = requireBulkUpdateDecorator();\n      }\n    }\n\n    hash = new BulkUpdateDecorator(\n      () => crypto.createHash(algorithm),\n      algorithm\n    );\n  }\n\n  hash.update(buffer);\n\n  if (\n    digestType === \"base26\" ||\n    digestType === \"base32\" ||\n    digestType === \"base36\" ||\n    digestType === \"base49\" ||\n    digestType === \"base52\" ||\n    digestType === \"base58\" ||\n    digestType === \"base62\"\n  ) {\n    return encodeBufferToBase(hash.digest(), digestType.substr(4), maxLength);\n  } else {\n    return hash.digest(digestType || \"hex\").substr(0, maxLength);\n  }\n}\n\nvar getHashDigest_1 = getHashDigest$1;\n\nconst path$1 = require$$0$1;\nconst getHashDigest = getHashDigest_1;\n\nfunction interpolateName$1(loaderContext, name, options = {}) {\n  let filename;\n\n  const hasQuery =\n    loaderContext.resourceQuery && loaderContext.resourceQuery.length > 1;\n\n  if (typeof name === \"function\") {\n    filename = name(\n      loaderContext.resourcePath,\n      hasQuery ? loaderContext.resourceQuery : undefined\n    );\n  } else {\n    filename = name || \"[hash].[ext]\";\n  }\n\n  const context = options.context;\n  const content = options.content;\n  const regExp = options.regExp;\n\n  let ext = \"bin\";\n  let basename = \"file\";\n  let directory = \"\";\n  let folder = \"\";\n  let query = \"\";\n\n  if (loaderContext.resourcePath) {\n    const parsed = path$1.parse(loaderContext.resourcePath);\n    let resourcePath = loaderContext.resourcePath;\n\n    if (parsed.ext) {\n      ext = parsed.ext.substr(1);\n    }\n\n    if (parsed.dir) {\n      basename = parsed.name;\n      resourcePath = parsed.dir + path$1.sep;\n    }\n\n    if (typeof context !== \"undefined\") {\n      directory = path$1\n        .relative(context, resourcePath + \"_\")\n        .replace(/\\\\/g, \"/\")\n        .replace(/\\.\\.(\\/)?/g, \"_$1\");\n      directory = directory.substr(0, directory.length - 1);\n    } else {\n      directory = resourcePath.replace(/\\\\/g, \"/\").replace(/\\.\\.(\\/)?/g, \"_$1\");\n    }\n\n    if (directory.length === 1) {\n      directory = \"\";\n    } else if (directory.length > 1) {\n      folder = path$1.basename(directory);\n    }\n  }\n\n  if (loaderContext.resourceQuery && loaderContext.resourceQuery.length > 1) {\n    query = loaderContext.resourceQuery;\n\n    const hashIdx = query.indexOf(\"#\");\n\n    if (hashIdx >= 0) {\n      query = query.substr(0, hashIdx);\n    }\n  }\n\n  let url = filename;\n\n  if (content) {\n    // Match hash template\n    url = url\n      // `hash` and `contenthash` are same in `loader-utils` context\n      // let's keep `hash` for backward compatibility\n      .replace(\n        /\\[(?:([^:\\]]+):)?(?:hash|contenthash)(?::([a-z]+\\d*))?(?::(\\d+))?\\]/gi,\n        (all, hashType, digestType, maxLength) =>\n          getHashDigest(content, hashType, digestType, parseInt(maxLength, 10))\n      );\n  }\n\n  url = url\n    .replace(/\\[ext\\]/gi, () => ext)\n    .replace(/\\[name\\]/gi, () => basename)\n    .replace(/\\[path\\]/gi, () => directory)\n    .replace(/\\[folder\\]/gi, () => folder)\n    .replace(/\\[query\\]/gi, () => query);\n\n  if (regExp && loaderContext.resourcePath) {\n    const match = loaderContext.resourcePath.match(new RegExp(regExp));\n\n    match &&\n      match.forEach((matched, i) => {\n        url = url.replace(new RegExp(\"\\\\[\" + i + \"\\\\]\", \"ig\"), matched);\n      });\n  }\n\n  if (\n    typeof loaderContext.options === \"object\" &&\n    typeof loaderContext.options.customInterpolateName === \"function\"\n  ) {\n    url = loaderContext.options.customInterpolateName.call(\n      loaderContext,\n      url,\n      name,\n      options\n    );\n  }\n\n  return url;\n}\n\nvar interpolateName_1 = interpolateName$1;\n\nvar interpolateName = interpolateName_1;\nvar path = require$$0$1;\n\n/**\n * @param  {string} pattern\n * @param  {object} options\n * @param  {string} options.context\n * @param  {string} options.hashPrefix\n * @return {function}\n */\nvar genericNames = function createGenerator(pattern, options) {\n  options = options || {};\n  var context =\n    options && typeof options.context === \"string\"\n      ? options.context\n      : process.cwd();\n  var hashPrefix =\n    options && typeof options.hashPrefix === \"string\" ? options.hashPrefix : \"\";\n\n  /**\n   * @param  {string} localName Usually a class name\n   * @param  {string} filepath  Absolute path\n   * @return {string}\n   */\n  return function generate(localName, filepath) {\n    var name = pattern.replace(/\\[local\\]/gi, localName);\n    var loaderContext = {\n      resourcePath: filepath,\n    };\n\n    var loaderOptions = {\n      content:\n        hashPrefix +\n        path.relative(context, filepath).replace(/\\\\/g, \"/\") +\n        \"\\x00\" +\n        localName,\n      context: context,\n    };\n\n    var genericName = interpolateName(loaderContext, name, loaderOptions);\n    return genericName\n      .replace(new RegExp(\"[^a-zA-Z0-9\\\\-_\\u00A0-\\uFFFF]\", \"g\"), \"-\")\n      .replace(/^((-?[0-9])|--)/, \"_$1\");\n  };\n};\n\nvar srcExports$1 = {};\nvar src$2 = {\n  get exports(){ return srcExports$1; },\n  set exports(v){ srcExports$1 = v; },\n};\n\nvar distExports = {};\nvar dist = {\n  get exports(){ return distExports; },\n  set exports(v){ distExports = v; },\n};\n\nvar processorExports = {};\nvar processor = {\n  get exports(){ return processorExports; },\n  set exports(v){ processorExports = v; },\n};\n\nvar parserExports = {};\nvar parser = {\n  get exports(){ return parserExports; },\n  set exports(v){ parserExports = v; },\n};\n\nvar rootExports = {};\nvar root$1 = {\n  get exports(){ return rootExports; },\n  set exports(v){ rootExports = v; },\n};\n\nvar containerExports = {};\nvar container = {\n  get exports(){ return containerExports; },\n  set exports(v){ containerExports = v; },\n};\n\nvar nodeExports = {};\nvar node$1 = {\n  get exports(){ return nodeExports; },\n  set exports(v){ nodeExports = v; },\n};\n\nvar util = {};\n\nvar unescExports = {};\nvar unesc = {\n  get exports(){ return unescExports; },\n  set exports(v){ unescExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = unesc;\n\n\t// Many thanks for this post which made this migration much easier.\n\t// https://mathiasbynens.be/notes/css-escapes\n\n\t/**\n\t * \n\t * @param {string} str \n\t * @returns {[string, number]|undefined}\n\t */\n\tfunction gobbleHex(str) {\n\t  var lower = str.toLowerCase();\n\t  var hex = '';\n\t  var spaceTerminated = false;\n\n\t  for (var i = 0; i < 6 && lower[i] !== undefined; i++) {\n\t    var code = lower.charCodeAt(i); // check to see if we are dealing with a valid hex char [a-f|0-9]\n\n\t    var valid = code >= 97 && code <= 102 || code >= 48 && code <= 57; // https://drafts.csswg.org/css-syntax/#consume-escaped-code-point\n\n\t    spaceTerminated = code === 32;\n\n\t    if (!valid) {\n\t      break;\n\t    }\n\n\t    hex += lower[i];\n\t  }\n\n\t  if (hex.length === 0) {\n\t    return undefined;\n\t  }\n\n\t  var codePoint = parseInt(hex, 16);\n\t  var isSurrogate = codePoint >= 0xD800 && codePoint <= 0xDFFF; // Add special case for\n\t  // \"If this number is zero, or is for a surrogate, or is greater than the maximum allowed code point\"\n\t  // https://drafts.csswg.org/css-syntax/#maximum-allowed-code-point\n\n\t  if (isSurrogate || codePoint === 0x0000 || codePoint > 0x10FFFF) {\n\t    return [\"\\uFFFD\", hex.length + (spaceTerminated ? 1 : 0)];\n\t  }\n\n\t  return [String.fromCodePoint(codePoint), hex.length + (spaceTerminated ? 1 : 0)];\n\t}\n\n\tvar CONTAINS_ESCAPE = /\\\\/;\n\n\tfunction unesc(str) {\n\t  var needToProcess = CONTAINS_ESCAPE.test(str);\n\n\t  if (!needToProcess) {\n\t    return str;\n\t  }\n\n\t  var ret = \"\";\n\n\t  for (var i = 0; i < str.length; i++) {\n\t    if (str[i] === \"\\\\\") {\n\t      var gobbled = gobbleHex(str.slice(i + 1, i + 7));\n\n\t      if (gobbled !== undefined) {\n\t        ret += gobbled[0];\n\t        i += gobbled[1];\n\t        continue;\n\t      } // Retain a pair of \\\\ if double escaped `\\\\\\\\`\n\t      // https://github.com/postcss/postcss-selector-parser/commit/268c9a7656fb53f543dc620aa5b73a30ec3ff20e\n\n\n\t      if (str[i + 1] === \"\\\\\") {\n\t        ret += \"\\\\\";\n\t        i++;\n\t        continue;\n\t      } // if \\\\ is at the end of the string retain it\n\t      // https://github.com/postcss/postcss-selector-parser/commit/01a6b346e3612ce1ab20219acc26abdc259ccefb\n\n\n\t      if (str.length === i + 1) {\n\t        ret += str[i];\n\t      }\n\n\t      continue;\n\t    }\n\n\t    ret += str[i];\n\t  }\n\n\t  return ret;\n\t}\n\n\tmodule.exports = exports.default;\n} (unesc, unescExports));\n\nvar getPropExports = {};\nvar getProp = {\n  get exports(){ return getPropExports; },\n  set exports(v){ getPropExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = getProp;\n\n\tfunction getProp(obj) {\n\t  for (var _len = arguments.length, props = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n\t    props[_key - 1] = arguments[_key];\n\t  }\n\n\t  while (props.length > 0) {\n\t    var prop = props.shift();\n\n\t    if (!obj[prop]) {\n\t      return undefined;\n\t    }\n\n\t    obj = obj[prop];\n\t  }\n\n\t  return obj;\n\t}\n\n\tmodule.exports = exports.default;\n} (getProp, getPropExports));\n\nvar ensureObjectExports = {};\nvar ensureObject = {\n  get exports(){ return ensureObjectExports; },\n  set exports(v){ ensureObjectExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = ensureObject;\n\n\tfunction ensureObject(obj) {\n\t  for (var _len = arguments.length, props = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n\t    props[_key - 1] = arguments[_key];\n\t  }\n\n\t  while (props.length > 0) {\n\t    var prop = props.shift();\n\n\t    if (!obj[prop]) {\n\t      obj[prop] = {};\n\t    }\n\n\t    obj = obj[prop];\n\t  }\n\t}\n\n\tmodule.exports = exports.default;\n} (ensureObject, ensureObjectExports));\n\nvar stripCommentsExports = {};\nvar stripComments = {\n  get exports(){ return stripCommentsExports; },\n  set exports(v){ stripCommentsExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = stripComments;\n\n\tfunction stripComments(str) {\n\t  var s = \"\";\n\t  var commentStart = str.indexOf(\"/*\");\n\t  var lastEnd = 0;\n\n\t  while (commentStart >= 0) {\n\t    s = s + str.slice(lastEnd, commentStart);\n\t    var commentEnd = str.indexOf(\"*/\", commentStart + 2);\n\n\t    if (commentEnd < 0) {\n\t      return s;\n\t    }\n\n\t    lastEnd = commentEnd + 2;\n\t    commentStart = str.indexOf(\"/*\", lastEnd);\n\t  }\n\n\t  s = s + str.slice(lastEnd);\n\t  return s;\n\t}\n\n\tmodule.exports = exports.default;\n} (stripComments, stripCommentsExports));\n\nutil.__esModule = true;\nutil.stripComments = util.ensureObject = util.getProp = util.unesc = void 0;\n\nvar _unesc = _interopRequireDefault$3(unescExports);\n\nutil.unesc = _unesc[\"default\"];\n\nvar _getProp = _interopRequireDefault$3(getPropExports);\n\nutil.getProp = _getProp[\"default\"];\n\nvar _ensureObject = _interopRequireDefault$3(ensureObjectExports);\n\nutil.ensureObject = _ensureObject[\"default\"];\n\nvar _stripComments = _interopRequireDefault$3(stripCommentsExports);\n\nutil.stripComments = _stripComments[\"default\"];\n\nfunction _interopRequireDefault$3(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _util = util;\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tvar cloneNode = function cloneNode(obj, parent) {\n\t  if (typeof obj !== 'object' || obj === null) {\n\t    return obj;\n\t  }\n\n\t  var cloned = new obj.constructor();\n\n\t  for (var i in obj) {\n\t    if (!obj.hasOwnProperty(i)) {\n\t      continue;\n\t    }\n\n\t    var value = obj[i];\n\t    var type = typeof value;\n\n\t    if (i === 'parent' && type === 'object') {\n\t      if (parent) {\n\t        cloned[i] = parent;\n\t      }\n\t    } else if (value instanceof Array) {\n\t      cloned[i] = value.map(function (j) {\n\t        return cloneNode(j, cloned);\n\t      });\n\t    } else {\n\t      cloned[i] = cloneNode(value, cloned);\n\t    }\n\t  }\n\n\t  return cloned;\n\t};\n\n\tvar Node = /*#__PURE__*/function () {\n\t  function Node(opts) {\n\t    if (opts === void 0) {\n\t      opts = {};\n\t    }\n\n\t    Object.assign(this, opts);\n\t    this.spaces = this.spaces || {};\n\t    this.spaces.before = this.spaces.before || '';\n\t    this.spaces.after = this.spaces.after || '';\n\t  }\n\n\t  var _proto = Node.prototype;\n\n\t  _proto.remove = function remove() {\n\t    if (this.parent) {\n\t      this.parent.removeChild(this);\n\t    }\n\n\t    this.parent = undefined;\n\t    return this;\n\t  };\n\n\t  _proto.replaceWith = function replaceWith() {\n\t    if (this.parent) {\n\t      for (var index in arguments) {\n\t        this.parent.insertBefore(this, arguments[index]);\n\t      }\n\n\t      this.remove();\n\t    }\n\n\t    return this;\n\t  };\n\n\t  _proto.next = function next() {\n\t    return this.parent.at(this.parent.index(this) + 1);\n\t  };\n\n\t  _proto.prev = function prev() {\n\t    return this.parent.at(this.parent.index(this) - 1);\n\t  };\n\n\t  _proto.clone = function clone(overrides) {\n\t    if (overrides === void 0) {\n\t      overrides = {};\n\t    }\n\n\t    var cloned = cloneNode(this);\n\n\t    for (var name in overrides) {\n\t      cloned[name] = overrides[name];\n\t    }\n\n\t    return cloned;\n\t  }\n\t  /**\n\t   * Some non-standard syntax doesn't follow normal escaping rules for css.\n\t   * This allows non standard syntax to be appended to an existing property\n\t   * by specifying the escaped value. By specifying the escaped value,\n\t   * illegal characters are allowed to be directly inserted into css output.\n\t   * @param {string} name the property to set\n\t   * @param {any} value the unescaped value of the property\n\t   * @param {string} valueEscaped optional. the escaped value of the property.\n\t   */\n\t  ;\n\n\t  _proto.appendToPropertyAndEscape = function appendToPropertyAndEscape(name, value, valueEscaped) {\n\t    if (!this.raws) {\n\t      this.raws = {};\n\t    }\n\n\t    var originalValue = this[name];\n\t    var originalEscaped = this.raws[name];\n\t    this[name] = originalValue + value; // this may trigger a setter that updates raws, so it has to be set first.\n\n\t    if (originalEscaped || valueEscaped !== value) {\n\t      this.raws[name] = (originalEscaped || originalValue) + valueEscaped;\n\t    } else {\n\t      delete this.raws[name]; // delete any escaped value that was created by the setter.\n\t    }\n\t  }\n\t  /**\n\t   * Some non-standard syntax doesn't follow normal escaping rules for css.\n\t   * This allows the escaped value to be specified directly, allowing illegal\n\t   * characters to be directly inserted into css output.\n\t   * @param {string} name the property to set\n\t   * @param {any} value the unescaped value of the property\n\t   * @param {string} valueEscaped the escaped value of the property.\n\t   */\n\t  ;\n\n\t  _proto.setPropertyAndEscape = function setPropertyAndEscape(name, value, valueEscaped) {\n\t    if (!this.raws) {\n\t      this.raws = {};\n\t    }\n\n\t    this[name] = value; // this may trigger a setter that updates raws, so it has to be set first.\n\n\t    this.raws[name] = valueEscaped;\n\t  }\n\t  /**\n\t   * When you want a value to passed through to CSS directly. This method\n\t   * deletes the corresponding raw value causing the stringifier to fallback\n\t   * to the unescaped value.\n\t   * @param {string} name the property to set.\n\t   * @param {any} value The value that is both escaped and unescaped.\n\t   */\n\t  ;\n\n\t  _proto.setPropertyWithoutEscape = function setPropertyWithoutEscape(name, value) {\n\t    this[name] = value; // this may trigger a setter that updates raws, so it has to be set first.\n\n\t    if (this.raws) {\n\t      delete this.raws[name];\n\t    }\n\t  }\n\t  /**\n\t   *\n\t   * @param {number} line The number (starting with 1)\n\t   * @param {number} column The column number (starting with 1)\n\t   */\n\t  ;\n\n\t  _proto.isAtPosition = function isAtPosition(line, column) {\n\t    if (this.source && this.source.start && this.source.end) {\n\t      if (this.source.start.line > line) {\n\t        return false;\n\t      }\n\n\t      if (this.source.end.line < line) {\n\t        return false;\n\t      }\n\n\t      if (this.source.start.line === line && this.source.start.column > column) {\n\t        return false;\n\t      }\n\n\t      if (this.source.end.line === line && this.source.end.column < column) {\n\t        return false;\n\t      }\n\n\t      return true;\n\t    }\n\n\t    return undefined;\n\t  };\n\n\t  _proto.stringifyProperty = function stringifyProperty(name) {\n\t    return this.raws && this.raws[name] || this[name];\n\t  };\n\n\t  _proto.valueToString = function valueToString() {\n\t    return String(this.stringifyProperty(\"value\"));\n\t  };\n\n\t  _proto.toString = function toString() {\n\t    return [this.rawSpaceBefore, this.valueToString(), this.rawSpaceAfter].join('');\n\t  };\n\n\t  _createClass(Node, [{\n\t    key: \"rawSpaceBefore\",\n\t    get: function get() {\n\t      var rawSpace = this.raws && this.raws.spaces && this.raws.spaces.before;\n\n\t      if (rawSpace === undefined) {\n\t        rawSpace = this.spaces && this.spaces.before;\n\t      }\n\n\t      return rawSpace || \"\";\n\t    },\n\t    set: function set(raw) {\n\t      (0, _util.ensureObject)(this, \"raws\", \"spaces\");\n\t      this.raws.spaces.before = raw;\n\t    }\n\t  }, {\n\t    key: \"rawSpaceAfter\",\n\t    get: function get() {\n\t      var rawSpace = this.raws && this.raws.spaces && this.raws.spaces.after;\n\n\t      if (rawSpace === undefined) {\n\t        rawSpace = this.spaces.after;\n\t      }\n\n\t      return rawSpace || \"\";\n\t    },\n\t    set: function set(raw) {\n\t      (0, _util.ensureObject)(this, \"raws\", \"spaces\");\n\t      this.raws.spaces.after = raw;\n\t    }\n\t  }]);\n\n\t  return Node;\n\t}();\n\n\texports[\"default\"] = Node;\n\tmodule.exports = exports.default;\n} (node$1, nodeExports));\n\nvar types = {};\n\ntypes.__esModule = true;\ntypes.UNIVERSAL = types.ATTRIBUTE = types.CLASS = types.COMBINATOR = types.COMMENT = types.ID = types.NESTING = types.PSEUDO = types.ROOT = types.SELECTOR = types.STRING = types.TAG = void 0;\nvar TAG = 'tag';\ntypes.TAG = TAG;\nvar STRING = 'string';\ntypes.STRING = STRING;\nvar SELECTOR = 'selector';\ntypes.SELECTOR = SELECTOR;\nvar ROOT = 'root';\ntypes.ROOT = ROOT;\nvar PSEUDO = 'pseudo';\ntypes.PSEUDO = PSEUDO;\nvar NESTING = 'nesting';\ntypes.NESTING = NESTING;\nvar ID = 'id';\ntypes.ID = ID;\nvar COMMENT = 'comment';\ntypes.COMMENT = COMMENT;\nvar COMBINATOR = 'combinator';\ntypes.COMBINATOR = COMBINATOR;\nvar CLASS = 'class';\ntypes.CLASS = CLASS;\nvar ATTRIBUTE = 'attribute';\ntypes.ATTRIBUTE = ATTRIBUTE;\nvar UNIVERSAL = 'universal';\ntypes.UNIVERSAL = UNIVERSAL;\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar types$1 = _interopRequireWildcard(types);\n\n\tfunction _getRequireWildcardCache() { if (typeof WeakMap !== \"function\") return null; var cache = new WeakMap(); _getRequireWildcardCache = function _getRequireWildcardCache() { return cache; }; return cache; }\n\n\tfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== \"object\" && typeof obj !== \"function\") { return { \"default\": obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj[\"default\"] = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it; if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } it = o[Symbol.iterator](); return it.next.bind(it); }\n\n\tfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\n\tfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Container = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(Container, _Node);\n\n\t  function Container(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\n\t    if (!_this.nodes) {\n\t      _this.nodes = [];\n\t    }\n\n\t    return _this;\n\t  }\n\n\t  var _proto = Container.prototype;\n\n\t  _proto.append = function append(selector) {\n\t    selector.parent = this;\n\t    this.nodes.push(selector);\n\t    return this;\n\t  };\n\n\t  _proto.prepend = function prepend(selector) {\n\t    selector.parent = this;\n\t    this.nodes.unshift(selector);\n\t    return this;\n\t  };\n\n\t  _proto.at = function at(index) {\n\t    return this.nodes[index];\n\t  };\n\n\t  _proto.index = function index(child) {\n\t    if (typeof child === 'number') {\n\t      return child;\n\t    }\n\n\t    return this.nodes.indexOf(child);\n\t  };\n\n\t  _proto.removeChild = function removeChild(child) {\n\t    child = this.index(child);\n\t    this.at(child).parent = undefined;\n\t    this.nodes.splice(child, 1);\n\t    var index;\n\n\t    for (var id in this.indexes) {\n\t      index = this.indexes[id];\n\n\t      if (index >= child) {\n\t        this.indexes[id] = index - 1;\n\t      }\n\t    }\n\n\t    return this;\n\t  };\n\n\t  _proto.removeAll = function removeAll() {\n\t    for (var _iterator = _createForOfIteratorHelperLoose(this.nodes), _step; !(_step = _iterator()).done;) {\n\t      var node = _step.value;\n\t      node.parent = undefined;\n\t    }\n\n\t    this.nodes = [];\n\t    return this;\n\t  };\n\n\t  _proto.empty = function empty() {\n\t    return this.removeAll();\n\t  };\n\n\t  _proto.insertAfter = function insertAfter(oldNode, newNode) {\n\t    newNode.parent = this;\n\t    var oldIndex = this.index(oldNode);\n\t    this.nodes.splice(oldIndex + 1, 0, newNode);\n\t    newNode.parent = this;\n\t    var index;\n\n\t    for (var id in this.indexes) {\n\t      index = this.indexes[id];\n\n\t      if (oldIndex <= index) {\n\t        this.indexes[id] = index + 1;\n\t      }\n\t    }\n\n\t    return this;\n\t  };\n\n\t  _proto.insertBefore = function insertBefore(oldNode, newNode) {\n\t    newNode.parent = this;\n\t    var oldIndex = this.index(oldNode);\n\t    this.nodes.splice(oldIndex, 0, newNode);\n\t    newNode.parent = this;\n\t    var index;\n\n\t    for (var id in this.indexes) {\n\t      index = this.indexes[id];\n\n\t      if (index <= oldIndex) {\n\t        this.indexes[id] = index + 1;\n\t      }\n\t    }\n\n\t    return this;\n\t  };\n\n\t  _proto._findChildAtPosition = function _findChildAtPosition(line, col) {\n\t    var found = undefined;\n\t    this.each(function (node) {\n\t      if (node.atPosition) {\n\t        var foundChild = node.atPosition(line, col);\n\n\t        if (foundChild) {\n\t          found = foundChild;\n\t          return false;\n\t        }\n\t      } else if (node.isAtPosition(line, col)) {\n\t        found = node;\n\t        return false;\n\t      }\n\t    });\n\t    return found;\n\t  }\n\t  /**\n\t   * Return the most specific node at the line and column number given.\n\t   * The source location is based on the original parsed location, locations aren't\n\t   * updated as selector nodes are mutated.\n\t   * \n\t   * Note that this location is relative to the location of the first character\n\t   * of the selector, and not the location of the selector in the overall document\n\t   * when used in conjunction with postcss.\n\t   *\n\t   * If not found, returns undefined.\n\t   * @param {number} line The line number of the node to find. (1-based index)\n\t   * @param {number} col  The column number of the node to find. (1-based index)\n\t   */\n\t  ;\n\n\t  _proto.atPosition = function atPosition(line, col) {\n\t    if (this.isAtPosition(line, col)) {\n\t      return this._findChildAtPosition(line, col) || this;\n\t    } else {\n\t      return undefined;\n\t    }\n\t  };\n\n\t  _proto._inferEndPosition = function _inferEndPosition() {\n\t    if (this.last && this.last.source && this.last.source.end) {\n\t      this.source = this.source || {};\n\t      this.source.end = this.source.end || {};\n\t      Object.assign(this.source.end, this.last.source.end);\n\t    }\n\t  };\n\n\t  _proto.each = function each(callback) {\n\t    if (!this.lastEach) {\n\t      this.lastEach = 0;\n\t    }\n\n\t    if (!this.indexes) {\n\t      this.indexes = {};\n\t    }\n\n\t    this.lastEach++;\n\t    var id = this.lastEach;\n\t    this.indexes[id] = 0;\n\n\t    if (!this.length) {\n\t      return undefined;\n\t    }\n\n\t    var index, result;\n\n\t    while (this.indexes[id] < this.length) {\n\t      index = this.indexes[id];\n\t      result = callback(this.at(index), index);\n\n\t      if (result === false) {\n\t        break;\n\t      }\n\n\t      this.indexes[id] += 1;\n\t    }\n\n\t    delete this.indexes[id];\n\n\t    if (result === false) {\n\t      return false;\n\t    }\n\t  };\n\n\t  _proto.walk = function walk(callback) {\n\t    return this.each(function (node, i) {\n\t      var result = callback(node, i);\n\n\t      if (result !== false && node.length) {\n\t        result = node.walk(callback);\n\t      }\n\n\t      if (result === false) {\n\t        return false;\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkAttributes = function walkAttributes(callback) {\n\t    var _this2 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.ATTRIBUTE) {\n\t        return callback.call(_this2, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkClasses = function walkClasses(callback) {\n\t    var _this3 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.CLASS) {\n\t        return callback.call(_this3, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkCombinators = function walkCombinators(callback) {\n\t    var _this4 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.COMBINATOR) {\n\t        return callback.call(_this4, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkComments = function walkComments(callback) {\n\t    var _this5 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.COMMENT) {\n\t        return callback.call(_this5, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkIds = function walkIds(callback) {\n\t    var _this6 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.ID) {\n\t        return callback.call(_this6, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkNesting = function walkNesting(callback) {\n\t    var _this7 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.NESTING) {\n\t        return callback.call(_this7, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkPseudos = function walkPseudos(callback) {\n\t    var _this8 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.PSEUDO) {\n\t        return callback.call(_this8, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkTags = function walkTags(callback) {\n\t    var _this9 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.TAG) {\n\t        return callback.call(_this9, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.walkUniversals = function walkUniversals(callback) {\n\t    var _this10 = this;\n\n\t    return this.walk(function (selector) {\n\t      if (selector.type === types$1.UNIVERSAL) {\n\t        return callback.call(_this10, selector);\n\t      }\n\t    });\n\t  };\n\n\t  _proto.split = function split(callback) {\n\t    var _this11 = this;\n\n\t    var current = [];\n\t    return this.reduce(function (memo, node, index) {\n\t      var split = callback.call(_this11, node);\n\t      current.push(node);\n\n\t      if (split) {\n\t        memo.push(current);\n\t        current = [];\n\t      } else if (index === _this11.length - 1) {\n\t        memo.push(current);\n\t      }\n\n\t      return memo;\n\t    }, []);\n\t  };\n\n\t  _proto.map = function map(callback) {\n\t    return this.nodes.map(callback);\n\t  };\n\n\t  _proto.reduce = function reduce(callback, memo) {\n\t    return this.nodes.reduce(callback, memo);\n\t  };\n\n\t  _proto.every = function every(callback) {\n\t    return this.nodes.every(callback);\n\t  };\n\n\t  _proto.some = function some(callback) {\n\t    return this.nodes.some(callback);\n\t  };\n\n\t  _proto.filter = function filter(callback) {\n\t    return this.nodes.filter(callback);\n\t  };\n\n\t  _proto.sort = function sort(callback) {\n\t    return this.nodes.sort(callback);\n\t  };\n\n\t  _proto.toString = function toString() {\n\t    return this.map(String).join('');\n\t  };\n\n\t  _createClass(Container, [{\n\t    key: \"first\",\n\t    get: function get() {\n\t      return this.at(0);\n\t    }\n\t  }, {\n\t    key: \"last\",\n\t    get: function get() {\n\t      return this.at(this.length - 1);\n\t    }\n\t  }, {\n\t    key: \"length\",\n\t    get: function get() {\n\t      return this.nodes.length;\n\t    }\n\t  }]);\n\n\t  return Container;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = Container;\n\tmodule.exports = exports.default;\n} (container, containerExports));\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _container = _interopRequireDefault(containerExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Root = /*#__PURE__*/function (_Container) {\n\t  _inheritsLoose(Root, _Container);\n\n\t  function Root(opts) {\n\t    var _this;\n\n\t    _this = _Container.call(this, opts) || this;\n\t    _this.type = _types.ROOT;\n\t    return _this;\n\t  }\n\n\t  var _proto = Root.prototype;\n\n\t  _proto.toString = function toString() {\n\t    var str = this.reduce(function (memo, selector) {\n\t      memo.push(String(selector));\n\t      return memo;\n\t    }, []).join(',');\n\t    return this.trailingComma ? str + ',' : str;\n\t  };\n\n\t  _proto.error = function error(message, options) {\n\t    if (this._error) {\n\t      return this._error(message, options);\n\t    } else {\n\t      return new Error(message);\n\t    }\n\t  };\n\n\t  _createClass(Root, [{\n\t    key: \"errorGenerator\",\n\t    set: function set(handler) {\n\t      this._error = handler;\n\t    }\n\t  }]);\n\n\t  return Root;\n\t}(_container[\"default\"]);\n\n\texports[\"default\"] = Root;\n\tmodule.exports = exports.default;\n} (root$1, rootExports));\n\nvar selectorExports = {};\nvar selector$1 = {\n  get exports(){ return selectorExports; },\n  set exports(v){ selectorExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _container = _interopRequireDefault(containerExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Selector = /*#__PURE__*/function (_Container) {\n\t  _inheritsLoose(Selector, _Container);\n\n\t  function Selector(opts) {\n\t    var _this;\n\n\t    _this = _Container.call(this, opts) || this;\n\t    _this.type = _types.SELECTOR;\n\t    return _this;\n\t  }\n\n\t  return Selector;\n\t}(_container[\"default\"]);\n\n\texports[\"default\"] = Selector;\n\tmodule.exports = exports.default;\n} (selector$1, selectorExports));\n\nvar classNameExports = {};\nvar className$1 = {\n  get exports(){ return classNameExports; },\n  set exports(v){ classNameExports = v; },\n};\n\n/*! https://mths.be/cssesc v3.0.0 by @mathias */\n\nvar object = {};\nvar hasOwnProperty$1 = object.hasOwnProperty;\nvar merge = function merge(options, defaults) {\n\tif (!options) {\n\t\treturn defaults;\n\t}\n\tvar result = {};\n\tfor (var key in defaults) {\n\t\t// `if (defaults.hasOwnProperty(key) { … }` is not needed here, since\n\t\t// only recognized option names are used.\n\t\tresult[key] = hasOwnProperty$1.call(options, key) ? options[key] : defaults[key];\n\t}\n\treturn result;\n};\n\nvar regexAnySingleEscape = /[ -,\\.\\/:-@\\[-\\^`\\{-~]/;\nvar regexSingleEscape = /[ -,\\.\\/:-@\\[\\]\\^`\\{-~]/;\nvar regexExcessiveSpaces = /(^|\\\\+)?(\\\\[A-F0-9]{1,6})\\x20(?![a-fA-F0-9\\x20])/g;\n\n// https://mathiasbynens.be/notes/css-escapes#css\nvar cssesc = function cssesc(string, options) {\n\toptions = merge(options, cssesc.options);\n\tif (options.quotes != 'single' && options.quotes != 'double') {\n\t\toptions.quotes = 'single';\n\t}\n\tvar quote = options.quotes == 'double' ? '\"' : '\\'';\n\tvar isIdentifier = options.isIdentifier;\n\n\tvar firstChar = string.charAt(0);\n\tvar output = '';\n\tvar counter = 0;\n\tvar length = string.length;\n\twhile (counter < length) {\n\t\tvar character = string.charAt(counter++);\n\t\tvar codePoint = character.charCodeAt();\n\t\tvar value = void 0;\n\t\t// If it’s not a printable ASCII character…\n\t\tif (codePoint < 0x20 || codePoint > 0x7E) {\n\t\t\tif (codePoint >= 0xD800 && codePoint <= 0xDBFF && counter < length) {\n\t\t\t\t// It’s a high surrogate, and there is a next character.\n\t\t\t\tvar extra = string.charCodeAt(counter++);\n\t\t\t\tif ((extra & 0xFC00) == 0xDC00) {\n\t\t\t\t\t// next character is low surrogate\n\t\t\t\t\tcodePoint = ((codePoint & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000;\n\t\t\t\t} else {\n\t\t\t\t\t// It’s an unmatched surrogate; only append this code unit, in case\n\t\t\t\t\t// the next code unit is the high surrogate of a surrogate pair.\n\t\t\t\t\tcounter--;\n\t\t\t\t}\n\t\t\t}\n\t\t\tvalue = '\\\\' + codePoint.toString(16).toUpperCase() + ' ';\n\t\t} else {\n\t\t\tif (options.escapeEverything) {\n\t\t\t\tif (regexAnySingleEscape.test(character)) {\n\t\t\t\t\tvalue = '\\\\' + character;\n\t\t\t\t} else {\n\t\t\t\t\tvalue = '\\\\' + codePoint.toString(16).toUpperCase() + ' ';\n\t\t\t\t}\n\t\t\t} else if (/[\\t\\n\\f\\r\\x0B]/.test(character)) {\n\t\t\t\tvalue = '\\\\' + codePoint.toString(16).toUpperCase() + ' ';\n\t\t\t} else if (character == '\\\\' || !isIdentifier && (character == '\"' && quote == character || character == '\\'' && quote == character) || isIdentifier && regexSingleEscape.test(character)) {\n\t\t\t\tvalue = '\\\\' + character;\n\t\t\t} else {\n\t\t\t\tvalue = character;\n\t\t\t}\n\t\t}\n\t\toutput += value;\n\t}\n\n\tif (isIdentifier) {\n\t\tif (/^-[-\\d]/.test(output)) {\n\t\t\toutput = '\\\\-' + output.slice(1);\n\t\t} else if (/\\d/.test(firstChar)) {\n\t\t\toutput = '\\\\3' + firstChar + ' ' + output.slice(1);\n\t\t}\n\t}\n\n\t// Remove spaces after `\\HEX` escapes that are not followed by a hex digit,\n\t// since they’re redundant. Note that this is only possible if the escape\n\t// sequence isn’t preceded by an odd number of backslashes.\n\toutput = output.replace(regexExcessiveSpaces, function ($0, $1, $2) {\n\t\tif ($1 && $1.length % 2) {\n\t\t\t// It’s not safe to remove the space, so don’t.\n\t\t\treturn $0;\n\t\t}\n\t\t// Strip the space.\n\t\treturn ($1 || '') + $2;\n\t});\n\n\tif (!isIdentifier && options.wrap) {\n\t\treturn quote + output + quote;\n\t}\n\treturn output;\n};\n\n// Expose default options (so they can be overridden globally).\ncssesc.options = {\n\t'escapeEverything': false,\n\t'isIdentifier': false,\n\t'quotes': 'single',\n\t'wrap': false\n};\n\ncssesc.version = '3.0.0';\n\nvar cssesc_1 = cssesc;\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _cssesc = _interopRequireDefault(cssesc_1);\n\n\tvar _util = util;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar ClassName = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(ClassName, _Node);\n\n\t  function ClassName(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\t    _this.type = _types.CLASS;\n\t    _this._constructed = true;\n\t    return _this;\n\t  }\n\n\t  var _proto = ClassName.prototype;\n\n\t  _proto.valueToString = function valueToString() {\n\t    return '.' + _Node.prototype.valueToString.call(this);\n\t  };\n\n\t  _createClass(ClassName, [{\n\t    key: \"value\",\n\t    get: function get() {\n\t      return this._value;\n\t    },\n\t    set: function set(v) {\n\t      if (this._constructed) {\n\t        var escaped = (0, _cssesc[\"default\"])(v, {\n\t          isIdentifier: true\n\t        });\n\n\t        if (escaped !== v) {\n\t          (0, _util.ensureObject)(this, \"raws\");\n\t          this.raws.value = escaped;\n\t        } else if (this.raws) {\n\t          delete this.raws.value;\n\t        }\n\t      }\n\n\t      this._value = v;\n\t    }\n\t  }]);\n\n\t  return ClassName;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = ClassName;\n\tmodule.exports = exports.default;\n} (className$1, classNameExports));\n\nvar commentExports = {};\nvar comment$2 = {\n  get exports(){ return commentExports; },\n  set exports(v){ commentExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Comment = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(Comment, _Node);\n\n\t  function Comment(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\t    _this.type = _types.COMMENT;\n\t    return _this;\n\t  }\n\n\t  return Comment;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = Comment;\n\tmodule.exports = exports.default;\n} (comment$2, commentExports));\n\nvar idExports = {};\nvar id$1 = {\n  get exports(){ return idExports; },\n  set exports(v){ idExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar ID = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(ID, _Node);\n\n\t  function ID(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\t    _this.type = _types.ID;\n\t    return _this;\n\t  }\n\n\t  var _proto = ID.prototype;\n\n\t  _proto.valueToString = function valueToString() {\n\t    return '#' + _Node.prototype.valueToString.call(this);\n\t  };\n\n\t  return ID;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = ID;\n\tmodule.exports = exports.default;\n} (id$1, idExports));\n\nvar tagExports = {};\nvar tag$1 = {\n  get exports(){ return tagExports; },\n  set exports(v){ tagExports = v; },\n};\n\nvar namespaceExports = {};\nvar namespace = {\n  get exports(){ return namespaceExports; },\n  set exports(v){ namespaceExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _cssesc = _interopRequireDefault(cssesc_1);\n\n\tvar _util = util;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Namespace = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(Namespace, _Node);\n\n\t  function Namespace() {\n\t    return _Node.apply(this, arguments) || this;\n\t  }\n\n\t  var _proto = Namespace.prototype;\n\n\t  _proto.qualifiedName = function qualifiedName(value) {\n\t    if (this.namespace) {\n\t      return this.namespaceString + \"|\" + value;\n\t    } else {\n\t      return value;\n\t    }\n\t  };\n\n\t  _proto.valueToString = function valueToString() {\n\t    return this.qualifiedName(_Node.prototype.valueToString.call(this));\n\t  };\n\n\t  _createClass(Namespace, [{\n\t    key: \"namespace\",\n\t    get: function get() {\n\t      return this._namespace;\n\t    },\n\t    set: function set(namespace) {\n\t      if (namespace === true || namespace === \"*\" || namespace === \"&\") {\n\t        this._namespace = namespace;\n\n\t        if (this.raws) {\n\t          delete this.raws.namespace;\n\t        }\n\n\t        return;\n\t      }\n\n\t      var escaped = (0, _cssesc[\"default\"])(namespace, {\n\t        isIdentifier: true\n\t      });\n\t      this._namespace = namespace;\n\n\t      if (escaped !== namespace) {\n\t        (0, _util.ensureObject)(this, \"raws\");\n\t        this.raws.namespace = escaped;\n\t      } else if (this.raws) {\n\t        delete this.raws.namespace;\n\t      }\n\t    }\n\t  }, {\n\t    key: \"ns\",\n\t    get: function get() {\n\t      return this._namespace;\n\t    },\n\t    set: function set(namespace) {\n\t      this.namespace = namespace;\n\t    }\n\t  }, {\n\t    key: \"namespaceString\",\n\t    get: function get() {\n\t      if (this.namespace) {\n\t        var ns = this.stringifyProperty(\"namespace\");\n\n\t        if (ns === true) {\n\t          return '';\n\t        } else {\n\t          return ns;\n\t        }\n\t      } else {\n\t        return '';\n\t      }\n\t    }\n\t  }]);\n\n\t  return Namespace;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = Namespace;\n\tmodule.exports = exports.default;\n} (namespace, namespaceExports));\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _namespace = _interopRequireDefault(namespaceExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Tag = /*#__PURE__*/function (_Namespace) {\n\t  _inheritsLoose(Tag, _Namespace);\n\n\t  function Tag(opts) {\n\t    var _this;\n\n\t    _this = _Namespace.call(this, opts) || this;\n\t    _this.type = _types.TAG;\n\t    return _this;\n\t  }\n\n\t  return Tag;\n\t}(_namespace[\"default\"]);\n\n\texports[\"default\"] = Tag;\n\tmodule.exports = exports.default;\n} (tag$1, tagExports));\n\nvar stringExports = {};\nvar string$1 = {\n  get exports(){ return stringExports; },\n  set exports(v){ stringExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar String = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(String, _Node);\n\n\t  function String(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\t    _this.type = _types.STRING;\n\t    return _this;\n\t  }\n\n\t  return String;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = String;\n\tmodule.exports = exports.default;\n} (string$1, stringExports));\n\nvar pseudoExports = {};\nvar pseudo$1 = {\n  get exports(){ return pseudoExports; },\n  set exports(v){ pseudoExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _container = _interopRequireDefault(containerExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Pseudo = /*#__PURE__*/function (_Container) {\n\t  _inheritsLoose(Pseudo, _Container);\n\n\t  function Pseudo(opts) {\n\t    var _this;\n\n\t    _this = _Container.call(this, opts) || this;\n\t    _this.type = _types.PSEUDO;\n\t    return _this;\n\t  }\n\n\t  var _proto = Pseudo.prototype;\n\n\t  _proto.toString = function toString() {\n\t    var params = this.length ? '(' + this.map(String).join(',') + ')' : '';\n\t    return [this.rawSpaceBefore, this.stringifyProperty(\"value\"), params, this.rawSpaceAfter].join('');\n\t  };\n\n\t  return Pseudo;\n\t}(_container[\"default\"]);\n\n\texports[\"default\"] = Pseudo;\n\tmodule.exports = exports.default;\n} (pseudo$1, pseudoExports));\n\nvar attribute$1 = {};\n\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nvar node = require$$0$2.deprecate;\n\n(function (exports) {\n\n\texports.__esModule = true;\n\texports.unescapeValue = unescapeValue;\n\texports[\"default\"] = void 0;\n\n\tvar _cssesc = _interopRequireDefault(cssesc_1);\n\n\tvar _unesc = _interopRequireDefault(unescExports);\n\n\tvar _namespace = _interopRequireDefault(namespaceExports);\n\n\tvar _types = types;\n\n\tvar _CSSESC_QUOTE_OPTIONS;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar deprecate = node;\n\n\tvar WRAPPED_IN_QUOTES = /^('|\")([^]*)\\1$/;\n\tvar warnOfDeprecatedValueAssignment = deprecate(function () {}, \"Assigning an attribute a value containing characters that might need to be escaped is deprecated. \" + \"Call attribute.setValue() instead.\");\n\tvar warnOfDeprecatedQuotedAssignment = deprecate(function () {}, \"Assigning attr.quoted is deprecated and has no effect. Assign to attr.quoteMark instead.\");\n\tvar warnOfDeprecatedConstructor = deprecate(function () {}, \"Constructing an Attribute selector with a value without specifying quoteMark is deprecated. Note: The value should be unescaped now.\");\n\n\tfunction unescapeValue(value) {\n\t  var deprecatedUsage = false;\n\t  var quoteMark = null;\n\t  var unescaped = value;\n\t  var m = unescaped.match(WRAPPED_IN_QUOTES);\n\n\t  if (m) {\n\t    quoteMark = m[1];\n\t    unescaped = m[2];\n\t  }\n\n\t  unescaped = (0, _unesc[\"default\"])(unescaped);\n\n\t  if (unescaped !== value) {\n\t    deprecatedUsage = true;\n\t  }\n\n\t  return {\n\t    deprecatedUsage: deprecatedUsage,\n\t    unescaped: unescaped,\n\t    quoteMark: quoteMark\n\t  };\n\t}\n\n\tfunction handleDeprecatedContructorOpts(opts) {\n\t  if (opts.quoteMark !== undefined) {\n\t    return opts;\n\t  }\n\n\t  if (opts.value === undefined) {\n\t    return opts;\n\t  }\n\n\t  warnOfDeprecatedConstructor();\n\n\t  var _unescapeValue = unescapeValue(opts.value),\n\t      quoteMark = _unescapeValue.quoteMark,\n\t      unescaped = _unescapeValue.unescaped;\n\n\t  if (!opts.raws) {\n\t    opts.raws = {};\n\t  }\n\n\t  if (opts.raws.value === undefined) {\n\t    opts.raws.value = opts.value;\n\t  }\n\n\t  opts.value = unescaped;\n\t  opts.quoteMark = quoteMark;\n\t  return opts;\n\t}\n\n\tvar Attribute = /*#__PURE__*/function (_Namespace) {\n\t  _inheritsLoose(Attribute, _Namespace);\n\n\t  function Attribute(opts) {\n\t    var _this;\n\n\t    if (opts === void 0) {\n\t      opts = {};\n\t    }\n\n\t    _this = _Namespace.call(this, handleDeprecatedContructorOpts(opts)) || this;\n\t    _this.type = _types.ATTRIBUTE;\n\t    _this.raws = _this.raws || {};\n\t    Object.defineProperty(_this.raws, 'unquoted', {\n\t      get: deprecate(function () {\n\t        return _this.value;\n\t      }, \"attr.raws.unquoted is deprecated. Call attr.value instead.\"),\n\t      set: deprecate(function () {\n\t        return _this.value;\n\t      }, \"Setting attr.raws.unquoted is deprecated and has no effect. attr.value is unescaped by default now.\")\n\t    });\n\t    _this._constructed = true;\n\t    return _this;\n\t  }\n\t  /**\n\t   * Returns the Attribute's value quoted such that it would be legal to use\n\t   * in the value of a css file. The original value's quotation setting\n\t   * used for stringification is left unchanged. See `setValue(value, options)`\n\t   * if you want to control the quote settings of a new value for the attribute.\n\t   *\n\t   * You can also change the quotation used for the current value by setting quoteMark.\n\t   *\n\t   * Options:\n\t   *   * quoteMark {'\"' | \"'\" | null} - Use this value to quote the value. If this\n\t   *     option is not set, the original value for quoteMark will be used. If\n\t   *     indeterminate, a double quote is used. The legal values are:\n\t   *     * `null` - the value will be unquoted and characters will be escaped as necessary.\n\t   *     * `'` - the value will be quoted with a single quote and single quotes are escaped.\n\t   *     * `\"` - the value will be quoted with a double quote and double quotes are escaped.\n\t   *   * preferCurrentQuoteMark {boolean} - if true, prefer the source quote mark\n\t   *     over the quoteMark option value.\n\t   *   * smart {boolean} - if true, will select a quote mark based on the value\n\t   *     and the other options specified here. See the `smartQuoteMark()`\n\t   *     method.\n\t   **/\n\n\n\t  var _proto = Attribute.prototype;\n\n\t  _proto.getQuotedValue = function getQuotedValue(options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    var quoteMark = this._determineQuoteMark(options);\n\n\t    var cssescopts = CSSESC_QUOTE_OPTIONS[quoteMark];\n\t    var escaped = (0, _cssesc[\"default\"])(this._value, cssescopts);\n\t    return escaped;\n\t  };\n\n\t  _proto._determineQuoteMark = function _determineQuoteMark(options) {\n\t    return options.smart ? this.smartQuoteMark(options) : this.preferredQuoteMark(options);\n\t  }\n\t  /**\n\t   * Set the unescaped value with the specified quotation options. The value\n\t   * provided must not include any wrapping quote marks -- those quotes will\n\t   * be interpreted as part of the value and escaped accordingly.\n\t   */\n\t  ;\n\n\t  _proto.setValue = function setValue(value, options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    this._value = value;\n\t    this._quoteMark = this._determineQuoteMark(options);\n\n\t    this._syncRawValue();\n\t  }\n\t  /**\n\t   * Intelligently select a quoteMark value based on the value's contents. If\n\t   * the value is a legal CSS ident, it will not be quoted. Otherwise a quote\n\t   * mark will be picked that minimizes the number of escapes.\n\t   *\n\t   * If there's no clear winner, the quote mark from these options is used,\n\t   * then the source quote mark (this is inverted if `preferCurrentQuoteMark` is\n\t   * true). If the quoteMark is unspecified, a double quote is used.\n\t   *\n\t   * @param options This takes the quoteMark and preferCurrentQuoteMark options\n\t   * from the quoteValue method.\n\t   */\n\t  ;\n\n\t  _proto.smartQuoteMark = function smartQuoteMark(options) {\n\t    var v = this.value;\n\t    var numSingleQuotes = v.replace(/[^']/g, '').length;\n\t    var numDoubleQuotes = v.replace(/[^\"]/g, '').length;\n\n\t    if (numSingleQuotes + numDoubleQuotes === 0) {\n\t      var escaped = (0, _cssesc[\"default\"])(v, {\n\t        isIdentifier: true\n\t      });\n\n\t      if (escaped === v) {\n\t        return Attribute.NO_QUOTE;\n\t      } else {\n\t        var pref = this.preferredQuoteMark(options);\n\n\t        if (pref === Attribute.NO_QUOTE) {\n\t          // pick a quote mark that isn't none and see if it's smaller\n\t          var quote = this.quoteMark || options.quoteMark || Attribute.DOUBLE_QUOTE;\n\t          var opts = CSSESC_QUOTE_OPTIONS[quote];\n\t          var quoteValue = (0, _cssesc[\"default\"])(v, opts);\n\n\t          if (quoteValue.length < escaped.length) {\n\t            return quote;\n\t          }\n\t        }\n\n\t        return pref;\n\t      }\n\t    } else if (numDoubleQuotes === numSingleQuotes) {\n\t      return this.preferredQuoteMark(options);\n\t    } else if (numDoubleQuotes < numSingleQuotes) {\n\t      return Attribute.DOUBLE_QUOTE;\n\t    } else {\n\t      return Attribute.SINGLE_QUOTE;\n\t    }\n\t  }\n\t  /**\n\t   * Selects the preferred quote mark based on the options and the current quote mark value.\n\t   * If you want the quote mark to depend on the attribute value, call `smartQuoteMark(opts)`\n\t   * instead.\n\t   */\n\t  ;\n\n\t  _proto.preferredQuoteMark = function preferredQuoteMark(options) {\n\t    var quoteMark = options.preferCurrentQuoteMark ? this.quoteMark : options.quoteMark;\n\n\t    if (quoteMark === undefined) {\n\t      quoteMark = options.preferCurrentQuoteMark ? options.quoteMark : this.quoteMark;\n\t    }\n\n\t    if (quoteMark === undefined) {\n\t      quoteMark = Attribute.DOUBLE_QUOTE;\n\t    }\n\n\t    return quoteMark;\n\t  };\n\n\t  _proto._syncRawValue = function _syncRawValue() {\n\t    var rawValue = (0, _cssesc[\"default\"])(this._value, CSSESC_QUOTE_OPTIONS[this.quoteMark]);\n\n\t    if (rawValue === this._value) {\n\t      if (this.raws) {\n\t        delete this.raws.value;\n\t      }\n\t    } else {\n\t      this.raws.value = rawValue;\n\t    }\n\t  };\n\n\t  _proto._handleEscapes = function _handleEscapes(prop, value) {\n\t    if (this._constructed) {\n\t      var escaped = (0, _cssesc[\"default\"])(value, {\n\t        isIdentifier: true\n\t      });\n\n\t      if (escaped !== value) {\n\t        this.raws[prop] = escaped;\n\t      } else {\n\t        delete this.raws[prop];\n\t      }\n\t    }\n\t  };\n\n\t  _proto._spacesFor = function _spacesFor(name) {\n\t    var attrSpaces = {\n\t      before: '',\n\t      after: ''\n\t    };\n\t    var spaces = this.spaces[name] || {};\n\t    var rawSpaces = this.raws.spaces && this.raws.spaces[name] || {};\n\t    return Object.assign(attrSpaces, spaces, rawSpaces);\n\t  };\n\n\t  _proto._stringFor = function _stringFor(name, spaceName, concat) {\n\t    if (spaceName === void 0) {\n\t      spaceName = name;\n\t    }\n\n\t    if (concat === void 0) {\n\t      concat = defaultAttrConcat;\n\t    }\n\n\t    var attrSpaces = this._spacesFor(spaceName);\n\n\t    return concat(this.stringifyProperty(name), attrSpaces);\n\t  }\n\t  /**\n\t   * returns the offset of the attribute part specified relative to the\n\t   * start of the node of the output string.\n\t   *\n\t   * * \"ns\" - alias for \"namespace\"\n\t   * * \"namespace\" - the namespace if it exists.\n\t   * * \"attribute\" - the attribute name\n\t   * * \"attributeNS\" - the start of the attribute or its namespace\n\t   * * \"operator\" - the match operator of the attribute\n\t   * * \"value\" - The value (string or identifier)\n\t   * * \"insensitive\" - the case insensitivity flag;\n\t   * @param part One of the possible values inside an attribute.\n\t   * @returns -1 if the name is invalid or the value doesn't exist in this attribute.\n\t   */\n\t  ;\n\n\t  _proto.offsetOf = function offsetOf(name) {\n\t    var count = 1;\n\n\t    var attributeSpaces = this._spacesFor(\"attribute\");\n\n\t    count += attributeSpaces.before.length;\n\n\t    if (name === \"namespace\" || name === \"ns\") {\n\t      return this.namespace ? count : -1;\n\t    }\n\n\t    if (name === \"attributeNS\") {\n\t      return count;\n\t    }\n\n\t    count += this.namespaceString.length;\n\n\t    if (this.namespace) {\n\t      count += 1;\n\t    }\n\n\t    if (name === \"attribute\") {\n\t      return count;\n\t    }\n\n\t    count += this.stringifyProperty(\"attribute\").length;\n\t    count += attributeSpaces.after.length;\n\n\t    var operatorSpaces = this._spacesFor(\"operator\");\n\n\t    count += operatorSpaces.before.length;\n\t    var operator = this.stringifyProperty(\"operator\");\n\n\t    if (name === \"operator\") {\n\t      return operator ? count : -1;\n\t    }\n\n\t    count += operator.length;\n\t    count += operatorSpaces.after.length;\n\n\t    var valueSpaces = this._spacesFor(\"value\");\n\n\t    count += valueSpaces.before.length;\n\t    var value = this.stringifyProperty(\"value\");\n\n\t    if (name === \"value\") {\n\t      return value ? count : -1;\n\t    }\n\n\t    count += value.length;\n\t    count += valueSpaces.after.length;\n\n\t    var insensitiveSpaces = this._spacesFor(\"insensitive\");\n\n\t    count += insensitiveSpaces.before.length;\n\n\t    if (name === \"insensitive\") {\n\t      return this.insensitive ? count : -1;\n\t    }\n\n\t    return -1;\n\t  };\n\n\t  _proto.toString = function toString() {\n\t    var _this2 = this;\n\n\t    var selector = [this.rawSpaceBefore, '['];\n\t    selector.push(this._stringFor('qualifiedAttribute', 'attribute'));\n\n\t    if (this.operator && (this.value || this.value === '')) {\n\t      selector.push(this._stringFor('operator'));\n\t      selector.push(this._stringFor('value'));\n\t      selector.push(this._stringFor('insensitiveFlag', 'insensitive', function (attrValue, attrSpaces) {\n\t        if (attrValue.length > 0 && !_this2.quoted && attrSpaces.before.length === 0 && !(_this2.spaces.value && _this2.spaces.value.after)) {\n\t          attrSpaces.before = \" \";\n\t        }\n\n\t        return defaultAttrConcat(attrValue, attrSpaces);\n\t      }));\n\t    }\n\n\t    selector.push(']');\n\t    selector.push(this.rawSpaceAfter);\n\t    return selector.join('');\n\t  };\n\n\t  _createClass(Attribute, [{\n\t    key: \"quoted\",\n\t    get: function get() {\n\t      var qm = this.quoteMark;\n\t      return qm === \"'\" || qm === '\"';\n\t    },\n\t    set: function set(value) {\n\t      warnOfDeprecatedQuotedAssignment();\n\t    }\n\t    /**\n\t     * returns a single (`'`) or double (`\"`) quote character if the value is quoted.\n\t     * returns `null` if the value is not quoted.\n\t     * returns `undefined` if the quotation state is unknown (this can happen when\n\t     * the attribute is constructed without specifying a quote mark.)\n\t     */\n\n\t  }, {\n\t    key: \"quoteMark\",\n\t    get: function get() {\n\t      return this._quoteMark;\n\t    }\n\t    /**\n\t     * Set the quote mark to be used by this attribute's value.\n\t     * If the quote mark changes, the raw (escaped) value at `attr.raws.value` of the attribute\n\t     * value is updated accordingly.\n\t     *\n\t     * @param {\"'\" | '\"' | null} quoteMark The quote mark or `null` if the value should be unquoted.\n\t     */\n\t    ,\n\t    set: function set(quoteMark) {\n\t      if (!this._constructed) {\n\t        this._quoteMark = quoteMark;\n\t        return;\n\t      }\n\n\t      if (this._quoteMark !== quoteMark) {\n\t        this._quoteMark = quoteMark;\n\n\t        this._syncRawValue();\n\t      }\n\t    }\n\t  }, {\n\t    key: \"qualifiedAttribute\",\n\t    get: function get() {\n\t      return this.qualifiedName(this.raws.attribute || this.attribute);\n\t    }\n\t  }, {\n\t    key: \"insensitiveFlag\",\n\t    get: function get() {\n\t      return this.insensitive ? 'i' : '';\n\t    }\n\t  }, {\n\t    key: \"value\",\n\t    get: function get() {\n\t      return this._value;\n\t    }\n\t    /**\n\t     * Before 3.0, the value had to be set to an escaped value including any wrapped\n\t     * quote marks. In 3.0, the semantics of `Attribute.value` changed so that the value\n\t     * is unescaped during parsing and any quote marks are removed.\n\t     *\n\t     * Because the ambiguity of this semantic change, if you set `attr.value = newValue`,\n\t     * a deprecation warning is raised when the new value contains any characters that would\n\t     * require escaping (including if it contains wrapped quotes).\n\t     *\n\t     * Instead, you should call `attr.setValue(newValue, opts)` and pass options that describe\n\t     * how the new value is quoted.\n\t     */\n\t    ,\n\t    set: function set(v) {\n\t      if (this._constructed) {\n\t        var _unescapeValue2 = unescapeValue(v),\n\t            deprecatedUsage = _unescapeValue2.deprecatedUsage,\n\t            unescaped = _unescapeValue2.unescaped,\n\t            quoteMark = _unescapeValue2.quoteMark;\n\n\t        if (deprecatedUsage) {\n\t          warnOfDeprecatedValueAssignment();\n\t        }\n\n\t        if (unescaped === this._value && quoteMark === this._quoteMark) {\n\t          return;\n\t        }\n\n\t        this._value = unescaped;\n\t        this._quoteMark = quoteMark;\n\n\t        this._syncRawValue();\n\t      } else {\n\t        this._value = v;\n\t      }\n\t    }\n\t  }, {\n\t    key: \"attribute\",\n\t    get: function get() {\n\t      return this._attribute;\n\t    },\n\t    set: function set(name) {\n\t      this._handleEscapes(\"attribute\", name);\n\n\t      this._attribute = name;\n\t    }\n\t  }]);\n\n\t  return Attribute;\n\t}(_namespace[\"default\"]);\n\n\texports[\"default\"] = Attribute;\n\tAttribute.NO_QUOTE = null;\n\tAttribute.SINGLE_QUOTE = \"'\";\n\tAttribute.DOUBLE_QUOTE = '\"';\n\tvar CSSESC_QUOTE_OPTIONS = (_CSSESC_QUOTE_OPTIONS = {\n\t  \"'\": {\n\t    quotes: 'single',\n\t    wrap: true\n\t  },\n\t  '\"': {\n\t    quotes: 'double',\n\t    wrap: true\n\t  }\n\t}, _CSSESC_QUOTE_OPTIONS[null] = {\n\t  isIdentifier: true\n\t}, _CSSESC_QUOTE_OPTIONS);\n\n\tfunction defaultAttrConcat(attrValue, attrSpaces) {\n\t  return \"\" + attrSpaces.before + attrValue + attrSpaces.after;\n\t}\n} (attribute$1));\n\nvar universalExports = {};\nvar universal$1 = {\n  get exports(){ return universalExports; },\n  set exports(v){ universalExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _namespace = _interopRequireDefault(namespaceExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Universal = /*#__PURE__*/function (_Namespace) {\n\t  _inheritsLoose(Universal, _Namespace);\n\n\t  function Universal(opts) {\n\t    var _this;\n\n\t    _this = _Namespace.call(this, opts) || this;\n\t    _this.type = _types.UNIVERSAL;\n\t    _this.value = '*';\n\t    return _this;\n\t  }\n\n\t  return Universal;\n\t}(_namespace[\"default\"]);\n\n\texports[\"default\"] = Universal;\n\tmodule.exports = exports.default;\n} (universal$1, universalExports));\n\nvar combinatorExports = {};\nvar combinator$2 = {\n  get exports(){ return combinatorExports; },\n  set exports(v){ combinatorExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Combinator = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(Combinator, _Node);\n\n\t  function Combinator(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\t    _this.type = _types.COMBINATOR;\n\t    return _this;\n\t  }\n\n\t  return Combinator;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = Combinator;\n\tmodule.exports = exports.default;\n} (combinator$2, combinatorExports));\n\nvar nestingExports = {};\nvar nesting$1 = {\n  get exports(){ return nestingExports; },\n  set exports(v){ nestingExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _node = _interopRequireDefault(nodeExports);\n\n\tvar _types = types;\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }\n\n\tfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\n\tvar Nesting = /*#__PURE__*/function (_Node) {\n\t  _inheritsLoose(Nesting, _Node);\n\n\t  function Nesting(opts) {\n\t    var _this;\n\n\t    _this = _Node.call(this, opts) || this;\n\t    _this.type = _types.NESTING;\n\t    _this.value = '&';\n\t    return _this;\n\t  }\n\n\t  return Nesting;\n\t}(_node[\"default\"]);\n\n\texports[\"default\"] = Nesting;\n\tmodule.exports = exports.default;\n} (nesting$1, nestingExports));\n\nvar sortAscendingExports = {};\nvar sortAscending = {\n  get exports(){ return sortAscendingExports; },\n  set exports(v){ sortAscendingExports = v; },\n};\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = sortAscending;\n\n\tfunction sortAscending(list) {\n\t  return list.sort(function (a, b) {\n\t    return a - b;\n\t  });\n\t}\n\tmodule.exports = exports.default;\n} (sortAscending, sortAscendingExports));\n\nvar tokenize = {};\n\nvar tokenTypes = {};\n\ntokenTypes.__esModule = true;\ntokenTypes.combinator = tokenTypes.word = tokenTypes.comment = tokenTypes.str = tokenTypes.tab = tokenTypes.newline = tokenTypes.feed = tokenTypes.cr = tokenTypes.backslash = tokenTypes.bang = tokenTypes.slash = tokenTypes.doubleQuote = tokenTypes.singleQuote = tokenTypes.space = tokenTypes.greaterThan = tokenTypes.pipe = tokenTypes.equals = tokenTypes.plus = tokenTypes.caret = tokenTypes.tilde = tokenTypes.dollar = tokenTypes.closeSquare = tokenTypes.openSquare = tokenTypes.closeParenthesis = tokenTypes.openParenthesis = tokenTypes.semicolon = tokenTypes.colon = tokenTypes.comma = tokenTypes.at = tokenTypes.asterisk = tokenTypes.ampersand = void 0;\nvar ampersand = 38; // `&`.charCodeAt(0);\n\ntokenTypes.ampersand = ampersand;\nvar asterisk = 42; // `*`.charCodeAt(0);\n\ntokenTypes.asterisk = asterisk;\nvar at = 64; // `@`.charCodeAt(0);\n\ntokenTypes.at = at;\nvar comma = 44; // `,`.charCodeAt(0);\n\ntokenTypes.comma = comma;\nvar colon = 58; // `:`.charCodeAt(0);\n\ntokenTypes.colon = colon;\nvar semicolon = 59; // `;`.charCodeAt(0);\n\ntokenTypes.semicolon = semicolon;\nvar openParenthesis = 40; // `(`.charCodeAt(0);\n\ntokenTypes.openParenthesis = openParenthesis;\nvar closeParenthesis = 41; // `)`.charCodeAt(0);\n\ntokenTypes.closeParenthesis = closeParenthesis;\nvar openSquare = 91; // `[`.charCodeAt(0);\n\ntokenTypes.openSquare = openSquare;\nvar closeSquare = 93; // `]`.charCodeAt(0);\n\ntokenTypes.closeSquare = closeSquare;\nvar dollar = 36; // `$`.charCodeAt(0);\n\ntokenTypes.dollar = dollar;\nvar tilde = 126; // `~`.charCodeAt(0);\n\ntokenTypes.tilde = tilde;\nvar caret = 94; // `^`.charCodeAt(0);\n\ntokenTypes.caret = caret;\nvar plus = 43; // `+`.charCodeAt(0);\n\ntokenTypes.plus = plus;\nvar equals = 61; // `=`.charCodeAt(0);\n\ntokenTypes.equals = equals;\nvar pipe = 124; // `|`.charCodeAt(0);\n\ntokenTypes.pipe = pipe;\nvar greaterThan = 62; // `>`.charCodeAt(0);\n\ntokenTypes.greaterThan = greaterThan;\nvar space = 32; // ` `.charCodeAt(0);\n\ntokenTypes.space = space;\nvar singleQuote = 39; // `'`.charCodeAt(0);\n\ntokenTypes.singleQuote = singleQuote;\nvar doubleQuote = 34; // `\"`.charCodeAt(0);\n\ntokenTypes.doubleQuote = doubleQuote;\nvar slash = 47; // `/`.charCodeAt(0);\n\ntokenTypes.slash = slash;\nvar bang = 33; // `!`.charCodeAt(0);\n\ntokenTypes.bang = bang;\nvar backslash = 92; // '\\\\'.charCodeAt(0);\n\ntokenTypes.backslash = backslash;\nvar cr = 13; // '\\r'.charCodeAt(0);\n\ntokenTypes.cr = cr;\nvar feed = 12; // '\\f'.charCodeAt(0);\n\ntokenTypes.feed = feed;\nvar newline = 10; // '\\n'.charCodeAt(0);\n\ntokenTypes.newline = newline;\nvar tab = 9; // '\\t'.charCodeAt(0);\n// Expose aliases primarily for readability.\n\ntokenTypes.tab = tab;\nvar str = singleQuote; // No good single character representation!\n\ntokenTypes.str = str;\nvar comment$1 = -1;\ntokenTypes.comment = comment$1;\nvar word = -2;\ntokenTypes.word = word;\nvar combinator$1 = -3;\ntokenTypes.combinator = combinator$1;\n\n(function (exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = tokenize;\n\texports.FIELDS = void 0;\n\n\tvar t = _interopRequireWildcard(tokenTypes);\n\n\tvar _unescapable, _wordDelimiters;\n\n\tfunction _getRequireWildcardCache() { if (typeof WeakMap !== \"function\") return null; var cache = new WeakMap(); _getRequireWildcardCache = function _getRequireWildcardCache() { return cache; }; return cache; }\n\n\tfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== \"object\" && typeof obj !== \"function\") { return { \"default\": obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj[\"default\"] = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\n\tvar unescapable = (_unescapable = {}, _unescapable[t.tab] = true, _unescapable[t.newline] = true, _unescapable[t.cr] = true, _unescapable[t.feed] = true, _unescapable);\n\tvar wordDelimiters = (_wordDelimiters = {}, _wordDelimiters[t.space] = true, _wordDelimiters[t.tab] = true, _wordDelimiters[t.newline] = true, _wordDelimiters[t.cr] = true, _wordDelimiters[t.feed] = true, _wordDelimiters[t.ampersand] = true, _wordDelimiters[t.asterisk] = true, _wordDelimiters[t.bang] = true, _wordDelimiters[t.comma] = true, _wordDelimiters[t.colon] = true, _wordDelimiters[t.semicolon] = true, _wordDelimiters[t.openParenthesis] = true, _wordDelimiters[t.closeParenthesis] = true, _wordDelimiters[t.openSquare] = true, _wordDelimiters[t.closeSquare] = true, _wordDelimiters[t.singleQuote] = true, _wordDelimiters[t.doubleQuote] = true, _wordDelimiters[t.plus] = true, _wordDelimiters[t.pipe] = true, _wordDelimiters[t.tilde] = true, _wordDelimiters[t.greaterThan] = true, _wordDelimiters[t.equals] = true, _wordDelimiters[t.dollar] = true, _wordDelimiters[t.caret] = true, _wordDelimiters[t.slash] = true, _wordDelimiters);\n\tvar hex = {};\n\tvar hexChars = \"0123456789abcdefABCDEF\";\n\n\tfor (var i = 0; i < hexChars.length; i++) {\n\t  hex[hexChars.charCodeAt(i)] = true;\n\t}\n\t/**\n\t *  Returns the last index of the bar css word\n\t * @param {string} css The string in which the word begins\n\t * @param {number} start The index into the string where word's first letter occurs\n\t */\n\n\n\tfunction consumeWord(css, start) {\n\t  var next = start;\n\t  var code;\n\n\t  do {\n\t    code = css.charCodeAt(next);\n\n\t    if (wordDelimiters[code]) {\n\t      return next - 1;\n\t    } else if (code === t.backslash) {\n\t      next = consumeEscape(css, next) + 1;\n\t    } else {\n\t      // All other characters are part of the word\n\t      next++;\n\t    }\n\t  } while (next < css.length);\n\n\t  return next - 1;\n\t}\n\t/**\n\t *  Returns the last index of the escape sequence\n\t * @param {string} css The string in which the sequence begins\n\t * @param {number} start The index into the string where escape character (`\\`) occurs.\n\t */\n\n\n\tfunction consumeEscape(css, start) {\n\t  var next = start;\n\t  var code = css.charCodeAt(next + 1);\n\n\t  if (unescapable[code]) ; else if (hex[code]) {\n\t    var hexDigits = 0; // consume up to 6 hex chars\n\n\t    do {\n\t      next++;\n\t      hexDigits++;\n\t      code = css.charCodeAt(next + 1);\n\t    } while (hex[code] && hexDigits < 6); // if fewer than 6 hex chars, a trailing space ends the escape\n\n\n\t    if (hexDigits < 6 && code === t.space) {\n\t      next++;\n\t    }\n\t  } else {\n\t    // the next char is part of the current word\n\t    next++;\n\t  }\n\n\t  return next;\n\t}\n\n\tvar FIELDS = {\n\t  TYPE: 0,\n\t  START_LINE: 1,\n\t  START_COL: 2,\n\t  END_LINE: 3,\n\t  END_COL: 4,\n\t  START_POS: 5,\n\t  END_POS: 6\n\t};\n\texports.FIELDS = FIELDS;\n\n\tfunction tokenize(input) {\n\t  var tokens = [];\n\t  var css = input.css.valueOf();\n\t  var _css = css,\n\t      length = _css.length;\n\t  var offset = -1;\n\t  var line = 1;\n\t  var start = 0;\n\t  var end = 0;\n\t  var code, content, endColumn, endLine, escaped, escapePos, last, lines, next, nextLine, nextOffset, quote, tokenType;\n\n\t  function unclosed(what, fix) {\n\t    if (input.safe) {\n\t      // fyi: this is never set to true.\n\t      css += fix;\n\t      next = css.length - 1;\n\t    } else {\n\t      throw input.error('Unclosed ' + what, line, start - offset, start);\n\t    }\n\t  }\n\n\t  while (start < length) {\n\t    code = css.charCodeAt(start);\n\n\t    if (code === t.newline) {\n\t      offset = start;\n\t      line += 1;\n\t    }\n\n\t    switch (code) {\n\t      case t.space:\n\t      case t.tab:\n\t      case t.newline:\n\t      case t.cr:\n\t      case t.feed:\n\t        next = start;\n\n\t        do {\n\t          next += 1;\n\t          code = css.charCodeAt(next);\n\n\t          if (code === t.newline) {\n\t            offset = next;\n\t            line += 1;\n\t          }\n\t        } while (code === t.space || code === t.newline || code === t.tab || code === t.cr || code === t.feed);\n\n\t        tokenType = t.space;\n\t        endLine = line;\n\t        endColumn = next - offset - 1;\n\t        end = next;\n\t        break;\n\n\t      case t.plus:\n\t      case t.greaterThan:\n\t      case t.tilde:\n\t      case t.pipe:\n\t        next = start;\n\n\t        do {\n\t          next += 1;\n\t          code = css.charCodeAt(next);\n\t        } while (code === t.plus || code === t.greaterThan || code === t.tilde || code === t.pipe);\n\n\t        tokenType = t.combinator;\n\t        endLine = line;\n\t        endColumn = start - offset;\n\t        end = next;\n\t        break;\n\t      // Consume these characters as single tokens.\n\n\t      case t.asterisk:\n\t      case t.ampersand:\n\t      case t.bang:\n\t      case t.comma:\n\t      case t.equals:\n\t      case t.dollar:\n\t      case t.caret:\n\t      case t.openSquare:\n\t      case t.closeSquare:\n\t      case t.colon:\n\t      case t.semicolon:\n\t      case t.openParenthesis:\n\t      case t.closeParenthesis:\n\t        next = start;\n\t        tokenType = code;\n\t        endLine = line;\n\t        endColumn = start - offset;\n\t        end = next + 1;\n\t        break;\n\n\t      case t.singleQuote:\n\t      case t.doubleQuote:\n\t        quote = code === t.singleQuote ? \"'\" : '\"';\n\t        next = start;\n\n\t        do {\n\t          escaped = false;\n\t          next = css.indexOf(quote, next + 1);\n\n\t          if (next === -1) {\n\t            unclosed('quote', quote);\n\t          }\n\n\t          escapePos = next;\n\n\t          while (css.charCodeAt(escapePos - 1) === t.backslash) {\n\t            escapePos -= 1;\n\t            escaped = !escaped;\n\t          }\n\t        } while (escaped);\n\n\t        tokenType = t.str;\n\t        endLine = line;\n\t        endColumn = start - offset;\n\t        end = next + 1;\n\t        break;\n\n\t      default:\n\t        if (code === t.slash && css.charCodeAt(start + 1) === t.asterisk) {\n\t          next = css.indexOf('*/', start + 2) + 1;\n\n\t          if (next === 0) {\n\t            unclosed('comment', '*/');\n\t          }\n\n\t          content = css.slice(start, next + 1);\n\t          lines = content.split('\\n');\n\t          last = lines.length - 1;\n\n\t          if (last > 0) {\n\t            nextLine = line + last;\n\t            nextOffset = next - lines[last].length;\n\t          } else {\n\t            nextLine = line;\n\t            nextOffset = offset;\n\t          }\n\n\t          tokenType = t.comment;\n\t          line = nextLine;\n\t          endLine = nextLine;\n\t          endColumn = next - nextOffset;\n\t        } else if (code === t.slash) {\n\t          next = start;\n\t          tokenType = code;\n\t          endLine = line;\n\t          endColumn = start - offset;\n\t          end = next + 1;\n\t        } else {\n\t          next = consumeWord(css, start);\n\t          tokenType = t.word;\n\t          endLine = line;\n\t          endColumn = next - offset;\n\t        }\n\n\t        end = next + 1;\n\t        break;\n\t    } // Ensure that the token structure remains consistent\n\n\n\t    tokens.push([tokenType, // [0] Token type\n\t    line, // [1] Starting line\n\t    start - offset, // [2] Starting column\n\t    endLine, // [3] Ending line\n\t    endColumn, // [4] Ending column\n\t    start, // [5] Start position / Source index\n\t    end // [6] End position\n\t    ]); // Reset offset for the next token\n\n\t    if (nextOffset) {\n\t      offset = nextOffset;\n\t      nextOffset = null;\n\t    }\n\n\t    start = end;\n\t  }\n\n\t  return tokens;\n\t}\n} (tokenize));\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _root = _interopRequireDefault(rootExports);\n\n\tvar _selector = _interopRequireDefault(selectorExports);\n\n\tvar _className = _interopRequireDefault(classNameExports);\n\n\tvar _comment = _interopRequireDefault(commentExports);\n\n\tvar _id = _interopRequireDefault(idExports);\n\n\tvar _tag = _interopRequireDefault(tagExports);\n\n\tvar _string = _interopRequireDefault(stringExports);\n\n\tvar _pseudo = _interopRequireDefault(pseudoExports);\n\n\tvar _attribute = _interopRequireWildcard(attribute$1);\n\n\tvar _universal = _interopRequireDefault(universalExports);\n\n\tvar _combinator = _interopRequireDefault(combinatorExports);\n\n\tvar _nesting = _interopRequireDefault(nestingExports);\n\n\tvar _sortAscending = _interopRequireDefault(sortAscendingExports);\n\n\tvar _tokenize = _interopRequireWildcard(tokenize);\n\n\tvar tokens = _interopRequireWildcard(tokenTypes);\n\n\tvar types$1 = _interopRequireWildcard(types);\n\n\tvar _util = util;\n\n\tvar _WHITESPACE_TOKENS, _Object$assign;\n\n\tfunction _getRequireWildcardCache() { if (typeof WeakMap !== \"function\") return null; var cache = new WeakMap(); _getRequireWildcardCache = function _getRequireWildcardCache() { return cache; }; return cache; }\n\n\tfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== \"object\" && typeof obj !== \"function\") { return { \"default\": obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj[\"default\"] = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\n\tfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\tvar WHITESPACE_TOKENS = (_WHITESPACE_TOKENS = {}, _WHITESPACE_TOKENS[tokens.space] = true, _WHITESPACE_TOKENS[tokens.cr] = true, _WHITESPACE_TOKENS[tokens.feed] = true, _WHITESPACE_TOKENS[tokens.newline] = true, _WHITESPACE_TOKENS[tokens.tab] = true, _WHITESPACE_TOKENS);\n\tvar WHITESPACE_EQUIV_TOKENS = Object.assign({}, WHITESPACE_TOKENS, (_Object$assign = {}, _Object$assign[tokens.comment] = true, _Object$assign));\n\n\tfunction tokenStart(token) {\n\t  return {\n\t    line: token[_tokenize.FIELDS.START_LINE],\n\t    column: token[_tokenize.FIELDS.START_COL]\n\t  };\n\t}\n\n\tfunction tokenEnd(token) {\n\t  return {\n\t    line: token[_tokenize.FIELDS.END_LINE],\n\t    column: token[_tokenize.FIELDS.END_COL]\n\t  };\n\t}\n\n\tfunction getSource(startLine, startColumn, endLine, endColumn) {\n\t  return {\n\t    start: {\n\t      line: startLine,\n\t      column: startColumn\n\t    },\n\t    end: {\n\t      line: endLine,\n\t      column: endColumn\n\t    }\n\t  };\n\t}\n\n\tfunction getTokenSource(token) {\n\t  return getSource(token[_tokenize.FIELDS.START_LINE], token[_tokenize.FIELDS.START_COL], token[_tokenize.FIELDS.END_LINE], token[_tokenize.FIELDS.END_COL]);\n\t}\n\n\tfunction getTokenSourceSpan(startToken, endToken) {\n\t  if (!startToken) {\n\t    return undefined;\n\t  }\n\n\t  return getSource(startToken[_tokenize.FIELDS.START_LINE], startToken[_tokenize.FIELDS.START_COL], endToken[_tokenize.FIELDS.END_LINE], endToken[_tokenize.FIELDS.END_COL]);\n\t}\n\n\tfunction unescapeProp(node, prop) {\n\t  var value = node[prop];\n\n\t  if (typeof value !== \"string\") {\n\t    return;\n\t  }\n\n\t  if (value.indexOf(\"\\\\\") !== -1) {\n\t    (0, _util.ensureObject)(node, 'raws');\n\t    node[prop] = (0, _util.unesc)(value);\n\n\t    if (node.raws[prop] === undefined) {\n\t      node.raws[prop] = value;\n\t    }\n\t  }\n\n\t  return node;\n\t}\n\n\tfunction indexesOf(array, item) {\n\t  var i = -1;\n\t  var indexes = [];\n\n\t  while ((i = array.indexOf(item, i + 1)) !== -1) {\n\t    indexes.push(i);\n\t  }\n\n\t  return indexes;\n\t}\n\n\tfunction uniqs() {\n\t  var list = Array.prototype.concat.apply([], arguments);\n\t  return list.filter(function (item, i) {\n\t    return i === list.indexOf(item);\n\t  });\n\t}\n\n\tvar Parser = /*#__PURE__*/function () {\n\t  function Parser(rule, options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    this.rule = rule;\n\t    this.options = Object.assign({\n\t      lossy: false,\n\t      safe: false\n\t    }, options);\n\t    this.position = 0;\n\t    this.css = typeof this.rule === 'string' ? this.rule : this.rule.selector;\n\t    this.tokens = (0, _tokenize[\"default\"])({\n\t      css: this.css,\n\t      error: this._errorGenerator(),\n\t      safe: this.options.safe\n\t    });\n\t    var rootSource = getTokenSourceSpan(this.tokens[0], this.tokens[this.tokens.length - 1]);\n\t    this.root = new _root[\"default\"]({\n\t      source: rootSource\n\t    });\n\t    this.root.errorGenerator = this._errorGenerator();\n\t    var selector = new _selector[\"default\"]({\n\t      source: {\n\t        start: {\n\t          line: 1,\n\t          column: 1\n\t        }\n\t      }\n\t    });\n\t    this.root.append(selector);\n\t    this.current = selector;\n\t    this.loop();\n\t  }\n\n\t  var _proto = Parser.prototype;\n\n\t  _proto._errorGenerator = function _errorGenerator() {\n\t    var _this = this;\n\n\t    return function (message, errorOptions) {\n\t      if (typeof _this.rule === 'string') {\n\t        return new Error(message);\n\t      }\n\n\t      return _this.rule.error(message, errorOptions);\n\t    };\n\t  };\n\n\t  _proto.attribute = function attribute() {\n\t    var attr = [];\n\t    var startingToken = this.currToken;\n\t    this.position++;\n\n\t    while (this.position < this.tokens.length && this.currToken[_tokenize.FIELDS.TYPE] !== tokens.closeSquare) {\n\t      attr.push(this.currToken);\n\t      this.position++;\n\t    }\n\n\t    if (this.currToken[_tokenize.FIELDS.TYPE] !== tokens.closeSquare) {\n\t      return this.expected('closing square bracket', this.currToken[_tokenize.FIELDS.START_POS]);\n\t    }\n\n\t    var len = attr.length;\n\t    var node = {\n\t      source: getSource(startingToken[1], startingToken[2], this.currToken[3], this.currToken[4]),\n\t      sourceIndex: startingToken[_tokenize.FIELDS.START_POS]\n\t    };\n\n\t    if (len === 1 && !~[tokens.word].indexOf(attr[0][_tokenize.FIELDS.TYPE])) {\n\t      return this.expected('attribute', attr[0][_tokenize.FIELDS.START_POS]);\n\t    }\n\n\t    var pos = 0;\n\t    var spaceBefore = '';\n\t    var commentBefore = '';\n\t    var lastAdded = null;\n\t    var spaceAfterMeaningfulToken = false;\n\n\t    while (pos < len) {\n\t      var token = attr[pos];\n\t      var content = this.content(token);\n\t      var next = attr[pos + 1];\n\n\t      switch (token[_tokenize.FIELDS.TYPE]) {\n\t        case tokens.space:\n\t          // if (\n\t          //     len === 1 ||\n\t          //     pos === 0 && this.content(next) === '|'\n\t          // ) {\n\t          //     return this.expected('attribute', token[TOKEN.START_POS], content);\n\t          // }\n\t          spaceAfterMeaningfulToken = true;\n\n\t          if (this.options.lossy) {\n\t            break;\n\t          }\n\n\t          if (lastAdded) {\n\t            (0, _util.ensureObject)(node, 'spaces', lastAdded);\n\t            var prevContent = node.spaces[lastAdded].after || '';\n\t            node.spaces[lastAdded].after = prevContent + content;\n\t            var existingComment = (0, _util.getProp)(node, 'raws', 'spaces', lastAdded, 'after') || null;\n\n\t            if (existingComment) {\n\t              node.raws.spaces[lastAdded].after = existingComment + content;\n\t            }\n\t          } else {\n\t            spaceBefore = spaceBefore + content;\n\t            commentBefore = commentBefore + content;\n\t          }\n\n\t          break;\n\n\t        case tokens.asterisk:\n\t          if (next[_tokenize.FIELDS.TYPE] === tokens.equals) {\n\t            node.operator = content;\n\t            lastAdded = 'operator';\n\t          } else if ((!node.namespace || lastAdded === \"namespace\" && !spaceAfterMeaningfulToken) && next) {\n\t            if (spaceBefore) {\n\t              (0, _util.ensureObject)(node, 'spaces', 'attribute');\n\t              node.spaces.attribute.before = spaceBefore;\n\t              spaceBefore = '';\n\t            }\n\n\t            if (commentBefore) {\n\t              (0, _util.ensureObject)(node, 'raws', 'spaces', 'attribute');\n\t              node.raws.spaces.attribute.before = spaceBefore;\n\t              commentBefore = '';\n\t            }\n\n\t            node.namespace = (node.namespace || \"\") + content;\n\t            var rawValue = (0, _util.getProp)(node, 'raws', 'namespace') || null;\n\n\t            if (rawValue) {\n\t              node.raws.namespace += content;\n\t            }\n\n\t            lastAdded = 'namespace';\n\t          }\n\n\t          spaceAfterMeaningfulToken = false;\n\t          break;\n\n\t        case tokens.dollar:\n\t          if (lastAdded === \"value\") {\n\t            var oldRawValue = (0, _util.getProp)(node, 'raws', 'value');\n\t            node.value += \"$\";\n\n\t            if (oldRawValue) {\n\t              node.raws.value = oldRawValue + \"$\";\n\t            }\n\n\t            break;\n\t          }\n\n\t        // Falls through\n\n\t        case tokens.caret:\n\t          if (next[_tokenize.FIELDS.TYPE] === tokens.equals) {\n\t            node.operator = content;\n\t            lastAdded = 'operator';\n\t          }\n\n\t          spaceAfterMeaningfulToken = false;\n\t          break;\n\n\t        case tokens.combinator:\n\t          if (content === '~' && next[_tokenize.FIELDS.TYPE] === tokens.equals) {\n\t            node.operator = content;\n\t            lastAdded = 'operator';\n\t          }\n\n\t          if (content !== '|') {\n\t            spaceAfterMeaningfulToken = false;\n\t            break;\n\t          }\n\n\t          if (next[_tokenize.FIELDS.TYPE] === tokens.equals) {\n\t            node.operator = content;\n\t            lastAdded = 'operator';\n\t          } else if (!node.namespace && !node.attribute) {\n\t            node.namespace = true;\n\t          }\n\n\t          spaceAfterMeaningfulToken = false;\n\t          break;\n\n\t        case tokens.word:\n\t          if (next && this.content(next) === '|' && attr[pos + 2] && attr[pos + 2][_tokenize.FIELDS.TYPE] !== tokens.equals && // this look-ahead probably fails with comment nodes involved.\n\t          !node.operator && !node.namespace) {\n\t            node.namespace = content;\n\t            lastAdded = 'namespace';\n\t          } else if (!node.attribute || lastAdded === \"attribute\" && !spaceAfterMeaningfulToken) {\n\t            if (spaceBefore) {\n\t              (0, _util.ensureObject)(node, 'spaces', 'attribute');\n\t              node.spaces.attribute.before = spaceBefore;\n\t              spaceBefore = '';\n\t            }\n\n\t            if (commentBefore) {\n\t              (0, _util.ensureObject)(node, 'raws', 'spaces', 'attribute');\n\t              node.raws.spaces.attribute.before = commentBefore;\n\t              commentBefore = '';\n\t            }\n\n\t            node.attribute = (node.attribute || \"\") + content;\n\n\t            var _rawValue = (0, _util.getProp)(node, 'raws', 'attribute') || null;\n\n\t            if (_rawValue) {\n\t              node.raws.attribute += content;\n\t            }\n\n\t            lastAdded = 'attribute';\n\t          } else if (!node.value && node.value !== \"\" || lastAdded === \"value\" && !spaceAfterMeaningfulToken) {\n\t            var _unescaped = (0, _util.unesc)(content);\n\n\t            var _oldRawValue = (0, _util.getProp)(node, 'raws', 'value') || '';\n\n\t            var oldValue = node.value || '';\n\t            node.value = oldValue + _unescaped;\n\t            node.quoteMark = null;\n\n\t            if (_unescaped !== content || _oldRawValue) {\n\t              (0, _util.ensureObject)(node, 'raws');\n\t              node.raws.value = (_oldRawValue || oldValue) + content;\n\t            }\n\n\t            lastAdded = 'value';\n\t          } else {\n\t            var insensitive = content === 'i' || content === \"I\";\n\n\t            if ((node.value || node.value === '') && (node.quoteMark || spaceAfterMeaningfulToken)) {\n\t              node.insensitive = insensitive;\n\n\t              if (!insensitive || content === \"I\") {\n\t                (0, _util.ensureObject)(node, 'raws');\n\t                node.raws.insensitiveFlag = content;\n\t              }\n\n\t              lastAdded = 'insensitive';\n\n\t              if (spaceBefore) {\n\t                (0, _util.ensureObject)(node, 'spaces', 'insensitive');\n\t                node.spaces.insensitive.before = spaceBefore;\n\t                spaceBefore = '';\n\t              }\n\n\t              if (commentBefore) {\n\t                (0, _util.ensureObject)(node, 'raws', 'spaces', 'insensitive');\n\t                node.raws.spaces.insensitive.before = commentBefore;\n\t                commentBefore = '';\n\t              }\n\t            } else if (node.value || node.value === '') {\n\t              lastAdded = 'value';\n\t              node.value += content;\n\n\t              if (node.raws.value) {\n\t                node.raws.value += content;\n\t              }\n\t            }\n\t          }\n\n\t          spaceAfterMeaningfulToken = false;\n\t          break;\n\n\t        case tokens.str:\n\t          if (!node.attribute || !node.operator) {\n\t            return this.error(\"Expected an attribute followed by an operator preceding the string.\", {\n\t              index: token[_tokenize.FIELDS.START_POS]\n\t            });\n\t          }\n\n\t          var _unescapeValue = (0, _attribute.unescapeValue)(content),\n\t              unescaped = _unescapeValue.unescaped,\n\t              quoteMark = _unescapeValue.quoteMark;\n\n\t          node.value = unescaped;\n\t          node.quoteMark = quoteMark;\n\t          lastAdded = 'value';\n\t          (0, _util.ensureObject)(node, 'raws');\n\t          node.raws.value = content;\n\t          spaceAfterMeaningfulToken = false;\n\t          break;\n\n\t        case tokens.equals:\n\t          if (!node.attribute) {\n\t            return this.expected('attribute', token[_tokenize.FIELDS.START_POS], content);\n\t          }\n\n\t          if (node.value) {\n\t            return this.error('Unexpected \"=\" found; an operator was already defined.', {\n\t              index: token[_tokenize.FIELDS.START_POS]\n\t            });\n\t          }\n\n\t          node.operator = node.operator ? node.operator + content : content;\n\t          lastAdded = 'operator';\n\t          spaceAfterMeaningfulToken = false;\n\t          break;\n\n\t        case tokens.comment:\n\t          if (lastAdded) {\n\t            if (spaceAfterMeaningfulToken || next && next[_tokenize.FIELDS.TYPE] === tokens.space || lastAdded === 'insensitive') {\n\t              var lastComment = (0, _util.getProp)(node, 'spaces', lastAdded, 'after') || '';\n\t              var rawLastComment = (0, _util.getProp)(node, 'raws', 'spaces', lastAdded, 'after') || lastComment;\n\t              (0, _util.ensureObject)(node, 'raws', 'spaces', lastAdded);\n\t              node.raws.spaces[lastAdded].after = rawLastComment + content;\n\t            } else {\n\t              var lastValue = node[lastAdded] || '';\n\t              var rawLastValue = (0, _util.getProp)(node, 'raws', lastAdded) || lastValue;\n\t              (0, _util.ensureObject)(node, 'raws');\n\t              node.raws[lastAdded] = rawLastValue + content;\n\t            }\n\t          } else {\n\t            commentBefore = commentBefore + content;\n\t          }\n\n\t          break;\n\n\t        default:\n\t          return this.error(\"Unexpected \\\"\" + content + \"\\\" found.\", {\n\t            index: token[_tokenize.FIELDS.START_POS]\n\t          });\n\t      }\n\n\t      pos++;\n\t    }\n\n\t    unescapeProp(node, \"attribute\");\n\t    unescapeProp(node, \"namespace\");\n\t    this.newNode(new _attribute[\"default\"](node));\n\t    this.position++;\n\t  }\n\t  /**\n\t   * return a node containing meaningless garbage up to (but not including) the specified token position.\n\t   * if the token position is negative, all remaining tokens are consumed.\n\t   *\n\t   * This returns an array containing a single string node if all whitespace,\n\t   * otherwise an array of comment nodes with space before and after.\n\t   *\n\t   * These tokens are not added to the current selector, the caller can add them or use them to amend\n\t   * a previous node's space metadata.\n\t   *\n\t   * In lossy mode, this returns only comments.\n\t   */\n\t  ;\n\n\t  _proto.parseWhitespaceEquivalentTokens = function parseWhitespaceEquivalentTokens(stopPosition) {\n\t    if (stopPosition < 0) {\n\t      stopPosition = this.tokens.length;\n\t    }\n\n\t    var startPosition = this.position;\n\t    var nodes = [];\n\t    var space = \"\";\n\t    var lastComment = undefined;\n\n\t    do {\n\t      if (WHITESPACE_TOKENS[this.currToken[_tokenize.FIELDS.TYPE]]) {\n\t        if (!this.options.lossy) {\n\t          space += this.content();\n\t        }\n\t      } else if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.comment) {\n\t        var spaces = {};\n\n\t        if (space) {\n\t          spaces.before = space;\n\t          space = \"\";\n\t        }\n\n\t        lastComment = new _comment[\"default\"]({\n\t          value: this.content(),\n\t          source: getTokenSource(this.currToken),\n\t          sourceIndex: this.currToken[_tokenize.FIELDS.START_POS],\n\t          spaces: spaces\n\t        });\n\t        nodes.push(lastComment);\n\t      }\n\t    } while (++this.position < stopPosition);\n\n\t    if (space) {\n\t      if (lastComment) {\n\t        lastComment.spaces.after = space;\n\t      } else if (!this.options.lossy) {\n\t        var firstToken = this.tokens[startPosition];\n\t        var lastToken = this.tokens[this.position - 1];\n\t        nodes.push(new _string[\"default\"]({\n\t          value: '',\n\t          source: getSource(firstToken[_tokenize.FIELDS.START_LINE], firstToken[_tokenize.FIELDS.START_COL], lastToken[_tokenize.FIELDS.END_LINE], lastToken[_tokenize.FIELDS.END_COL]),\n\t          sourceIndex: firstToken[_tokenize.FIELDS.START_POS],\n\t          spaces: {\n\t            before: space,\n\t            after: ''\n\t          }\n\t        }));\n\t      }\n\t    }\n\n\t    return nodes;\n\t  }\n\t  /**\n\t   * \n\t   * @param {*} nodes \n\t   */\n\t  ;\n\n\t  _proto.convertWhitespaceNodesToSpace = function convertWhitespaceNodesToSpace(nodes, requiredSpace) {\n\t    var _this2 = this;\n\n\t    if (requiredSpace === void 0) {\n\t      requiredSpace = false;\n\t    }\n\n\t    var space = \"\";\n\t    var rawSpace = \"\";\n\t    nodes.forEach(function (n) {\n\t      var spaceBefore = _this2.lossySpace(n.spaces.before, requiredSpace);\n\n\t      var rawSpaceBefore = _this2.lossySpace(n.rawSpaceBefore, requiredSpace);\n\n\t      space += spaceBefore + _this2.lossySpace(n.spaces.after, requiredSpace && spaceBefore.length === 0);\n\t      rawSpace += spaceBefore + n.value + _this2.lossySpace(n.rawSpaceAfter, requiredSpace && rawSpaceBefore.length === 0);\n\t    });\n\n\t    if (rawSpace === space) {\n\t      rawSpace = undefined;\n\t    }\n\n\t    var result = {\n\t      space: space,\n\t      rawSpace: rawSpace\n\t    };\n\t    return result;\n\t  };\n\n\t  _proto.isNamedCombinator = function isNamedCombinator(position) {\n\t    if (position === void 0) {\n\t      position = this.position;\n\t    }\n\n\t    return this.tokens[position + 0] && this.tokens[position + 0][_tokenize.FIELDS.TYPE] === tokens.slash && this.tokens[position + 1] && this.tokens[position + 1][_tokenize.FIELDS.TYPE] === tokens.word && this.tokens[position + 2] && this.tokens[position + 2][_tokenize.FIELDS.TYPE] === tokens.slash;\n\t  };\n\n\t  _proto.namedCombinator = function namedCombinator() {\n\t    if (this.isNamedCombinator()) {\n\t      var nameRaw = this.content(this.tokens[this.position + 1]);\n\t      var name = (0, _util.unesc)(nameRaw).toLowerCase();\n\t      var raws = {};\n\n\t      if (name !== nameRaw) {\n\t        raws.value = \"/\" + nameRaw + \"/\";\n\t      }\n\n\t      var node = new _combinator[\"default\"]({\n\t        value: \"/\" + name + \"/\",\n\t        source: getSource(this.currToken[_tokenize.FIELDS.START_LINE], this.currToken[_tokenize.FIELDS.START_COL], this.tokens[this.position + 2][_tokenize.FIELDS.END_LINE], this.tokens[this.position + 2][_tokenize.FIELDS.END_COL]),\n\t        sourceIndex: this.currToken[_tokenize.FIELDS.START_POS],\n\t        raws: raws\n\t      });\n\t      this.position = this.position + 3;\n\t      return node;\n\t    } else {\n\t      this.unexpected();\n\t    }\n\t  };\n\n\t  _proto.combinator = function combinator() {\n\t    var _this3 = this;\n\n\t    if (this.content() === '|') {\n\t      return this.namespace();\n\t    } // We need to decide between a space that's a descendant combinator and meaningless whitespace at the end of a selector.\n\n\n\t    var nextSigTokenPos = this.locateNextMeaningfulToken(this.position);\n\n\t    if (nextSigTokenPos < 0 || this.tokens[nextSigTokenPos][_tokenize.FIELDS.TYPE] === tokens.comma) {\n\t      var nodes = this.parseWhitespaceEquivalentTokens(nextSigTokenPos);\n\n\t      if (nodes.length > 0) {\n\t        var last = this.current.last;\n\n\t        if (last) {\n\t          var _this$convertWhitespa = this.convertWhitespaceNodesToSpace(nodes),\n\t              space = _this$convertWhitespa.space,\n\t              rawSpace = _this$convertWhitespa.rawSpace;\n\n\t          if (rawSpace !== undefined) {\n\t            last.rawSpaceAfter += rawSpace;\n\t          }\n\n\t          last.spaces.after += space;\n\t        } else {\n\t          nodes.forEach(function (n) {\n\t            return _this3.newNode(n);\n\t          });\n\t        }\n\t      }\n\n\t      return;\n\t    }\n\n\t    var firstToken = this.currToken;\n\t    var spaceOrDescendantSelectorNodes = undefined;\n\n\t    if (nextSigTokenPos > this.position) {\n\t      spaceOrDescendantSelectorNodes = this.parseWhitespaceEquivalentTokens(nextSigTokenPos);\n\t    }\n\n\t    var node;\n\n\t    if (this.isNamedCombinator()) {\n\t      node = this.namedCombinator();\n\t    } else if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.combinator) {\n\t      node = new _combinator[\"default\"]({\n\t        value: this.content(),\n\t        source: getTokenSource(this.currToken),\n\t        sourceIndex: this.currToken[_tokenize.FIELDS.START_POS]\n\t      });\n\t      this.position++;\n\t    } else if (WHITESPACE_TOKENS[this.currToken[_tokenize.FIELDS.TYPE]]) ; else if (!spaceOrDescendantSelectorNodes) {\n\t      this.unexpected();\n\t    }\n\n\t    if (node) {\n\t      if (spaceOrDescendantSelectorNodes) {\n\t        var _this$convertWhitespa2 = this.convertWhitespaceNodesToSpace(spaceOrDescendantSelectorNodes),\n\t            _space = _this$convertWhitespa2.space,\n\t            _rawSpace = _this$convertWhitespa2.rawSpace;\n\n\t        node.spaces.before = _space;\n\t        node.rawSpaceBefore = _rawSpace;\n\t      }\n\t    } else {\n\t      // descendant combinator\n\t      var _this$convertWhitespa3 = this.convertWhitespaceNodesToSpace(spaceOrDescendantSelectorNodes, true),\n\t          _space2 = _this$convertWhitespa3.space,\n\t          _rawSpace2 = _this$convertWhitespa3.rawSpace;\n\n\t      if (!_rawSpace2) {\n\t        _rawSpace2 = _space2;\n\t      }\n\n\t      var spaces = {};\n\t      var raws = {\n\t        spaces: {}\n\t      };\n\n\t      if (_space2.endsWith(' ') && _rawSpace2.endsWith(' ')) {\n\t        spaces.before = _space2.slice(0, _space2.length - 1);\n\t        raws.spaces.before = _rawSpace2.slice(0, _rawSpace2.length - 1);\n\t      } else if (_space2.startsWith(' ') && _rawSpace2.startsWith(' ')) {\n\t        spaces.after = _space2.slice(1);\n\t        raws.spaces.after = _rawSpace2.slice(1);\n\t      } else {\n\t        raws.value = _rawSpace2;\n\t      }\n\n\t      node = new _combinator[\"default\"]({\n\t        value: ' ',\n\t        source: getTokenSourceSpan(firstToken, this.tokens[this.position - 1]),\n\t        sourceIndex: firstToken[_tokenize.FIELDS.START_POS],\n\t        spaces: spaces,\n\t        raws: raws\n\t      });\n\t    }\n\n\t    if (this.currToken && this.currToken[_tokenize.FIELDS.TYPE] === tokens.space) {\n\t      node.spaces.after = this.optionalSpace(this.content());\n\t      this.position++;\n\t    }\n\n\t    return this.newNode(node);\n\t  };\n\n\t  _proto.comma = function comma() {\n\t    if (this.position === this.tokens.length - 1) {\n\t      this.root.trailingComma = true;\n\t      this.position++;\n\t      return;\n\t    }\n\n\t    this.current._inferEndPosition();\n\n\t    var selector = new _selector[\"default\"]({\n\t      source: {\n\t        start: tokenStart(this.tokens[this.position + 1])\n\t      }\n\t    });\n\t    this.current.parent.append(selector);\n\t    this.current = selector;\n\t    this.position++;\n\t  };\n\n\t  _proto.comment = function comment() {\n\t    var current = this.currToken;\n\t    this.newNode(new _comment[\"default\"]({\n\t      value: this.content(),\n\t      source: getTokenSource(current),\n\t      sourceIndex: current[_tokenize.FIELDS.START_POS]\n\t    }));\n\t    this.position++;\n\t  };\n\n\t  _proto.error = function error(message, opts) {\n\t    throw this.root.error(message, opts);\n\t  };\n\n\t  _proto.missingBackslash = function missingBackslash() {\n\t    return this.error('Expected a backslash preceding the semicolon.', {\n\t      index: this.currToken[_tokenize.FIELDS.START_POS]\n\t    });\n\t  };\n\n\t  _proto.missingParenthesis = function missingParenthesis() {\n\t    return this.expected('opening parenthesis', this.currToken[_tokenize.FIELDS.START_POS]);\n\t  };\n\n\t  _proto.missingSquareBracket = function missingSquareBracket() {\n\t    return this.expected('opening square bracket', this.currToken[_tokenize.FIELDS.START_POS]);\n\t  };\n\n\t  _proto.unexpected = function unexpected() {\n\t    return this.error(\"Unexpected '\" + this.content() + \"'. Escaping special characters with \\\\ may help.\", this.currToken[_tokenize.FIELDS.START_POS]);\n\t  };\n\n\t  _proto.namespace = function namespace() {\n\t    var before = this.prevToken && this.content(this.prevToken) || true;\n\n\t    if (this.nextToken[_tokenize.FIELDS.TYPE] === tokens.word) {\n\t      this.position++;\n\t      return this.word(before);\n\t    } else if (this.nextToken[_tokenize.FIELDS.TYPE] === tokens.asterisk) {\n\t      this.position++;\n\t      return this.universal(before);\n\t    }\n\t  };\n\n\t  _proto.nesting = function nesting() {\n\t    if (this.nextToken) {\n\t      var nextContent = this.content(this.nextToken);\n\n\t      if (nextContent === \"|\") {\n\t        this.position++;\n\t        return;\n\t      }\n\t    }\n\n\t    var current = this.currToken;\n\t    this.newNode(new _nesting[\"default\"]({\n\t      value: this.content(),\n\t      source: getTokenSource(current),\n\t      sourceIndex: current[_tokenize.FIELDS.START_POS]\n\t    }));\n\t    this.position++;\n\t  };\n\n\t  _proto.parentheses = function parentheses() {\n\t    var last = this.current.last;\n\t    var unbalanced = 1;\n\t    this.position++;\n\n\t    if (last && last.type === types$1.PSEUDO) {\n\t      var selector = new _selector[\"default\"]({\n\t        source: {\n\t          start: tokenStart(this.tokens[this.position - 1])\n\t        }\n\t      });\n\t      var cache = this.current;\n\t      last.append(selector);\n\t      this.current = selector;\n\n\t      while (this.position < this.tokens.length && unbalanced) {\n\t        if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.openParenthesis) {\n\t          unbalanced++;\n\t        }\n\n\t        if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.closeParenthesis) {\n\t          unbalanced--;\n\t        }\n\n\t        if (unbalanced) {\n\t          this.parse();\n\t        } else {\n\t          this.current.source.end = tokenEnd(this.currToken);\n\t          this.current.parent.source.end = tokenEnd(this.currToken);\n\t          this.position++;\n\t        }\n\t      }\n\n\t      this.current = cache;\n\t    } else {\n\t      // I think this case should be an error. It's used to implement a basic parse of media queries\n\t      // but I don't think it's a good idea.\n\t      var parenStart = this.currToken;\n\t      var parenValue = \"(\";\n\t      var parenEnd;\n\n\t      while (this.position < this.tokens.length && unbalanced) {\n\t        if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.openParenthesis) {\n\t          unbalanced++;\n\t        }\n\n\t        if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.closeParenthesis) {\n\t          unbalanced--;\n\t        }\n\n\t        parenEnd = this.currToken;\n\t        parenValue += this.parseParenthesisToken(this.currToken);\n\t        this.position++;\n\t      }\n\n\t      if (last) {\n\t        last.appendToPropertyAndEscape(\"value\", parenValue, parenValue);\n\t      } else {\n\t        this.newNode(new _string[\"default\"]({\n\t          value: parenValue,\n\t          source: getSource(parenStart[_tokenize.FIELDS.START_LINE], parenStart[_tokenize.FIELDS.START_COL], parenEnd[_tokenize.FIELDS.END_LINE], parenEnd[_tokenize.FIELDS.END_COL]),\n\t          sourceIndex: parenStart[_tokenize.FIELDS.START_POS]\n\t        }));\n\t      }\n\t    }\n\n\t    if (unbalanced) {\n\t      return this.expected('closing parenthesis', this.currToken[_tokenize.FIELDS.START_POS]);\n\t    }\n\t  };\n\n\t  _proto.pseudo = function pseudo() {\n\t    var _this4 = this;\n\n\t    var pseudoStr = '';\n\t    var startingToken = this.currToken;\n\n\t    while (this.currToken && this.currToken[_tokenize.FIELDS.TYPE] === tokens.colon) {\n\t      pseudoStr += this.content();\n\t      this.position++;\n\t    }\n\n\t    if (!this.currToken) {\n\t      return this.expected(['pseudo-class', 'pseudo-element'], this.position - 1);\n\t    }\n\n\t    if (this.currToken[_tokenize.FIELDS.TYPE] === tokens.word) {\n\t      this.splitWord(false, function (first, length) {\n\t        pseudoStr += first;\n\n\t        _this4.newNode(new _pseudo[\"default\"]({\n\t          value: pseudoStr,\n\t          source: getTokenSourceSpan(startingToken, _this4.currToken),\n\t          sourceIndex: startingToken[_tokenize.FIELDS.START_POS]\n\t        }));\n\n\t        if (length > 1 && _this4.nextToken && _this4.nextToken[_tokenize.FIELDS.TYPE] === tokens.openParenthesis) {\n\t          _this4.error('Misplaced parenthesis.', {\n\t            index: _this4.nextToken[_tokenize.FIELDS.START_POS]\n\t          });\n\t        }\n\t      });\n\t    } else {\n\t      return this.expected(['pseudo-class', 'pseudo-element'], this.currToken[_tokenize.FIELDS.START_POS]);\n\t    }\n\t  };\n\n\t  _proto.space = function space() {\n\t    var content = this.content(); // Handle space before and after the selector\n\n\t    if (this.position === 0 || this.prevToken[_tokenize.FIELDS.TYPE] === tokens.comma || this.prevToken[_tokenize.FIELDS.TYPE] === tokens.openParenthesis || this.current.nodes.every(function (node) {\n\t      return node.type === 'comment';\n\t    })) {\n\t      this.spaces = this.optionalSpace(content);\n\t      this.position++;\n\t    } else if (this.position === this.tokens.length - 1 || this.nextToken[_tokenize.FIELDS.TYPE] === tokens.comma || this.nextToken[_tokenize.FIELDS.TYPE] === tokens.closeParenthesis) {\n\t      this.current.last.spaces.after = this.optionalSpace(content);\n\t      this.position++;\n\t    } else {\n\t      this.combinator();\n\t    }\n\t  };\n\n\t  _proto.string = function string() {\n\t    var current = this.currToken;\n\t    this.newNode(new _string[\"default\"]({\n\t      value: this.content(),\n\t      source: getTokenSource(current),\n\t      sourceIndex: current[_tokenize.FIELDS.START_POS]\n\t    }));\n\t    this.position++;\n\t  };\n\n\t  _proto.universal = function universal(namespace) {\n\t    var nextToken = this.nextToken;\n\n\t    if (nextToken && this.content(nextToken) === '|') {\n\t      this.position++;\n\t      return this.namespace();\n\t    }\n\n\t    var current = this.currToken;\n\t    this.newNode(new _universal[\"default\"]({\n\t      value: this.content(),\n\t      source: getTokenSource(current),\n\t      sourceIndex: current[_tokenize.FIELDS.START_POS]\n\t    }), namespace);\n\t    this.position++;\n\t  };\n\n\t  _proto.splitWord = function splitWord(namespace, firstCallback) {\n\t    var _this5 = this;\n\n\t    var nextToken = this.nextToken;\n\t    var word = this.content();\n\n\t    while (nextToken && ~[tokens.dollar, tokens.caret, tokens.equals, tokens.word].indexOf(nextToken[_tokenize.FIELDS.TYPE])) {\n\t      this.position++;\n\t      var current = this.content();\n\t      word += current;\n\n\t      if (current.lastIndexOf('\\\\') === current.length - 1) {\n\t        var next = this.nextToken;\n\n\t        if (next && next[_tokenize.FIELDS.TYPE] === tokens.space) {\n\t          word += this.requiredSpace(this.content(next));\n\t          this.position++;\n\t        }\n\t      }\n\n\t      nextToken = this.nextToken;\n\t    }\n\n\t    var hasClass = indexesOf(word, '.').filter(function (i) {\n\t      // Allow escaped dot within class name\n\t      var escapedDot = word[i - 1] === '\\\\'; // Allow decimal numbers percent in @keyframes\n\n\t      var isKeyframesPercent = /^\\d+\\.\\d+%$/.test(word);\n\t      return !escapedDot && !isKeyframesPercent;\n\t    });\n\t    var hasId = indexesOf(word, '#').filter(function (i) {\n\t      return word[i - 1] !== '\\\\';\n\t    }); // Eliminate Sass interpolations from the list of id indexes\n\n\t    var interpolations = indexesOf(word, '#{');\n\n\t    if (interpolations.length) {\n\t      hasId = hasId.filter(function (hashIndex) {\n\t        return !~interpolations.indexOf(hashIndex);\n\t      });\n\t    }\n\n\t    var indices = (0, _sortAscending[\"default\"])(uniqs([0].concat(hasClass, hasId)));\n\t    indices.forEach(function (ind, i) {\n\t      var index = indices[i + 1] || word.length;\n\t      var value = word.slice(ind, index);\n\n\t      if (i === 0 && firstCallback) {\n\t        return firstCallback.call(_this5, value, indices.length);\n\t      }\n\n\t      var node;\n\t      var current = _this5.currToken;\n\t      var sourceIndex = current[_tokenize.FIELDS.START_POS] + indices[i];\n\t      var source = getSource(current[1], current[2] + ind, current[3], current[2] + (index - 1));\n\n\t      if (~hasClass.indexOf(ind)) {\n\t        var classNameOpts = {\n\t          value: value.slice(1),\n\t          source: source,\n\t          sourceIndex: sourceIndex\n\t        };\n\t        node = new _className[\"default\"](unescapeProp(classNameOpts, \"value\"));\n\t      } else if (~hasId.indexOf(ind)) {\n\t        var idOpts = {\n\t          value: value.slice(1),\n\t          source: source,\n\t          sourceIndex: sourceIndex\n\t        };\n\t        node = new _id[\"default\"](unescapeProp(idOpts, \"value\"));\n\t      } else {\n\t        var tagOpts = {\n\t          value: value,\n\t          source: source,\n\t          sourceIndex: sourceIndex\n\t        };\n\t        unescapeProp(tagOpts, \"value\");\n\t        node = new _tag[\"default\"](tagOpts);\n\t      }\n\n\t      _this5.newNode(node, namespace); // Ensure that the namespace is used only once\n\n\n\t      namespace = null;\n\t    });\n\t    this.position++;\n\t  };\n\n\t  _proto.word = function word(namespace) {\n\t    var nextToken = this.nextToken;\n\n\t    if (nextToken && this.content(nextToken) === '|') {\n\t      this.position++;\n\t      return this.namespace();\n\t    }\n\n\t    return this.splitWord(namespace);\n\t  };\n\n\t  _proto.loop = function loop() {\n\t    while (this.position < this.tokens.length) {\n\t      this.parse(true);\n\t    }\n\n\t    this.current._inferEndPosition();\n\n\t    return this.root;\n\t  };\n\n\t  _proto.parse = function parse(throwOnParenthesis) {\n\t    switch (this.currToken[_tokenize.FIELDS.TYPE]) {\n\t      case tokens.space:\n\t        this.space();\n\t        break;\n\n\t      case tokens.comment:\n\t        this.comment();\n\t        break;\n\n\t      case tokens.openParenthesis:\n\t        this.parentheses();\n\t        break;\n\n\t      case tokens.closeParenthesis:\n\t        if (throwOnParenthesis) {\n\t          this.missingParenthesis();\n\t        }\n\n\t        break;\n\n\t      case tokens.openSquare:\n\t        this.attribute();\n\t        break;\n\n\t      case tokens.dollar:\n\t      case tokens.caret:\n\t      case tokens.equals:\n\t      case tokens.word:\n\t        this.word();\n\t        break;\n\n\t      case tokens.colon:\n\t        this.pseudo();\n\t        break;\n\n\t      case tokens.comma:\n\t        this.comma();\n\t        break;\n\n\t      case tokens.asterisk:\n\t        this.universal();\n\t        break;\n\n\t      case tokens.ampersand:\n\t        this.nesting();\n\t        break;\n\n\t      case tokens.slash:\n\t      case tokens.combinator:\n\t        this.combinator();\n\t        break;\n\n\t      case tokens.str:\n\t        this.string();\n\t        break;\n\t      // These cases throw; no break needed.\n\n\t      case tokens.closeSquare:\n\t        this.missingSquareBracket();\n\n\t      case tokens.semicolon:\n\t        this.missingBackslash();\n\n\t      default:\n\t        this.unexpected();\n\t    }\n\t  }\n\t  /**\n\t   * Helpers\n\t   */\n\t  ;\n\n\t  _proto.expected = function expected(description, index, found) {\n\t    if (Array.isArray(description)) {\n\t      var last = description.pop();\n\t      description = description.join(', ') + \" or \" + last;\n\t    }\n\n\t    var an = /^[aeiou]/.test(description[0]) ? 'an' : 'a';\n\n\t    if (!found) {\n\t      return this.error(\"Expected \" + an + \" \" + description + \".\", {\n\t        index: index\n\t      });\n\t    }\n\n\t    return this.error(\"Expected \" + an + \" \" + description + \", found \\\"\" + found + \"\\\" instead.\", {\n\t      index: index\n\t    });\n\t  };\n\n\t  _proto.requiredSpace = function requiredSpace(space) {\n\t    return this.options.lossy ? ' ' : space;\n\t  };\n\n\t  _proto.optionalSpace = function optionalSpace(space) {\n\t    return this.options.lossy ? '' : space;\n\t  };\n\n\t  _proto.lossySpace = function lossySpace(space, required) {\n\t    if (this.options.lossy) {\n\t      return required ? ' ' : '';\n\t    } else {\n\t      return space;\n\t    }\n\t  };\n\n\t  _proto.parseParenthesisToken = function parseParenthesisToken(token) {\n\t    var content = this.content(token);\n\n\t    if (token[_tokenize.FIELDS.TYPE] === tokens.space) {\n\t      return this.requiredSpace(content);\n\t    } else {\n\t      return content;\n\t    }\n\t  };\n\n\t  _proto.newNode = function newNode(node, namespace) {\n\t    if (namespace) {\n\t      if (/^ +$/.test(namespace)) {\n\t        if (!this.options.lossy) {\n\t          this.spaces = (this.spaces || '') + namespace;\n\t        }\n\n\t        namespace = true;\n\t      }\n\n\t      node.namespace = namespace;\n\t      unescapeProp(node, \"namespace\");\n\t    }\n\n\t    if (this.spaces) {\n\t      node.spaces.before = this.spaces;\n\t      this.spaces = '';\n\t    }\n\n\t    return this.current.append(node);\n\t  };\n\n\t  _proto.content = function content(token) {\n\t    if (token === void 0) {\n\t      token = this.currToken;\n\t    }\n\n\t    return this.css.slice(token[_tokenize.FIELDS.START_POS], token[_tokenize.FIELDS.END_POS]);\n\t  };\n\n\t  /**\n\t   * returns the index of the next non-whitespace, non-comment token.\n\t   * returns -1 if no meaningful token is found.\n\t   */\n\t  _proto.locateNextMeaningfulToken = function locateNextMeaningfulToken(startPosition) {\n\t    if (startPosition === void 0) {\n\t      startPosition = this.position + 1;\n\t    }\n\n\t    var searchPosition = startPosition;\n\n\t    while (searchPosition < this.tokens.length) {\n\t      if (WHITESPACE_EQUIV_TOKENS[this.tokens[searchPosition][_tokenize.FIELDS.TYPE]]) {\n\t        searchPosition++;\n\t        continue;\n\t      } else {\n\t        return searchPosition;\n\t      }\n\t    }\n\n\t    return -1;\n\t  };\n\n\t  _createClass(Parser, [{\n\t    key: \"currToken\",\n\t    get: function get() {\n\t      return this.tokens[this.position];\n\t    }\n\t  }, {\n\t    key: \"nextToken\",\n\t    get: function get() {\n\t      return this.tokens[this.position + 1];\n\t    }\n\t  }, {\n\t    key: \"prevToken\",\n\t    get: function get() {\n\t      return this.tokens[this.position - 1];\n\t    }\n\t  }]);\n\n\t  return Parser;\n\t}();\n\n\texports[\"default\"] = Parser;\n\tmodule.exports = exports.default;\n} (parser, parserExports));\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _parser = _interopRequireDefault(parserExports);\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tvar Processor = /*#__PURE__*/function () {\n\t  function Processor(func, options) {\n\t    this.func = func || function noop() {};\n\n\t    this.funcRes = null;\n\t    this.options = options;\n\t  }\n\n\t  var _proto = Processor.prototype;\n\n\t  _proto._shouldUpdateSelector = function _shouldUpdateSelector(rule, options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    var merged = Object.assign({}, this.options, options);\n\n\t    if (merged.updateSelector === false) {\n\t      return false;\n\t    } else {\n\t      return typeof rule !== \"string\";\n\t    }\n\t  };\n\n\t  _proto._isLossy = function _isLossy(options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    var merged = Object.assign({}, this.options, options);\n\n\t    if (merged.lossless === false) {\n\t      return true;\n\t    } else {\n\t      return false;\n\t    }\n\t  };\n\n\t  _proto._root = function _root(rule, options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    var parser = new _parser[\"default\"](rule, this._parseOptions(options));\n\t    return parser.root;\n\t  };\n\n\t  _proto._parseOptions = function _parseOptions(options) {\n\t    return {\n\t      lossy: this._isLossy(options)\n\t    };\n\t  };\n\n\t  _proto._run = function _run(rule, options) {\n\t    var _this = this;\n\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    return new Promise(function (resolve, reject) {\n\t      try {\n\t        var root = _this._root(rule, options);\n\n\t        Promise.resolve(_this.func(root)).then(function (transform) {\n\t          var string = undefined;\n\n\t          if (_this._shouldUpdateSelector(rule, options)) {\n\t            string = root.toString();\n\t            rule.selector = string;\n\t          }\n\n\t          return {\n\t            transform: transform,\n\t            root: root,\n\t            string: string\n\t          };\n\t        }).then(resolve, reject);\n\t      } catch (e) {\n\t        reject(e);\n\t        return;\n\t      }\n\t    });\n\t  };\n\n\t  _proto._runSync = function _runSync(rule, options) {\n\t    if (options === void 0) {\n\t      options = {};\n\t    }\n\n\t    var root = this._root(rule, options);\n\n\t    var transform = this.func(root);\n\n\t    if (transform && typeof transform.then === \"function\") {\n\t      throw new Error(\"Selector processor returned a promise to a synchronous call.\");\n\t    }\n\n\t    var string = undefined;\n\n\t    if (options.updateSelector && typeof rule !== \"string\") {\n\t      string = root.toString();\n\t      rule.selector = string;\n\t    }\n\n\t    return {\n\t      transform: transform,\n\t      root: root,\n\t      string: string\n\t    };\n\t  }\n\t  /**\n\t   * Process rule into a selector AST.\n\t   *\n\t   * @param rule {postcss.Rule | string} The css selector to be processed\n\t   * @param options The options for processing\n\t   * @returns {Promise<parser.Root>} The AST of the selector after processing it.\n\t   */\n\t  ;\n\n\t  _proto.ast = function ast(rule, options) {\n\t    return this._run(rule, options).then(function (result) {\n\t      return result.root;\n\t    });\n\t  }\n\t  /**\n\t   * Process rule into a selector AST synchronously.\n\t   *\n\t   * @param rule {postcss.Rule | string} The css selector to be processed\n\t   * @param options The options for processing\n\t   * @returns {parser.Root} The AST of the selector after processing it.\n\t   */\n\t  ;\n\n\t  _proto.astSync = function astSync(rule, options) {\n\t    return this._runSync(rule, options).root;\n\t  }\n\t  /**\n\t   * Process a selector into a transformed value asynchronously\n\t   *\n\t   * @param rule {postcss.Rule | string} The css selector to be processed\n\t   * @param options The options for processing\n\t   * @returns {Promise<any>} The value returned by the processor.\n\t   */\n\t  ;\n\n\t  _proto.transform = function transform(rule, options) {\n\t    return this._run(rule, options).then(function (result) {\n\t      return result.transform;\n\t    });\n\t  }\n\t  /**\n\t   * Process a selector into a transformed value synchronously.\n\t   *\n\t   * @param rule {postcss.Rule | string} The css selector to be processed\n\t   * @param options The options for processing\n\t   * @returns {any} The value returned by the processor.\n\t   */\n\t  ;\n\n\t  _proto.transformSync = function transformSync(rule, options) {\n\t    return this._runSync(rule, options).transform;\n\t  }\n\t  /**\n\t   * Process a selector into a new selector string asynchronously.\n\t   *\n\t   * @param rule {postcss.Rule | string} The css selector to be processed\n\t   * @param options The options for processing\n\t   * @returns {string} the selector after processing.\n\t   */\n\t  ;\n\n\t  _proto.process = function process(rule, options) {\n\t    return this._run(rule, options).then(function (result) {\n\t      return result.string || result.root.toString();\n\t    });\n\t  }\n\t  /**\n\t   * Process a selector into a new selector string synchronously.\n\t   *\n\t   * @param rule {postcss.Rule | string} The css selector to be processed\n\t   * @param options The options for processing\n\t   * @returns {string} the selector after processing.\n\t   */\n\t  ;\n\n\t  _proto.processSync = function processSync(rule, options) {\n\t    var result = this._runSync(rule, options);\n\n\t    return result.string || result.root.toString();\n\t  };\n\n\t  return Processor;\n\t}();\n\n\texports[\"default\"] = Processor;\n\tmodule.exports = exports.default;\n} (processor, processorExports));\n\nvar selectors = {};\n\nvar constructors = {};\n\nconstructors.__esModule = true;\nconstructors.universal = constructors.tag = constructors.string = constructors.selector = constructors.root = constructors.pseudo = constructors.nesting = constructors.id = constructors.comment = constructors.combinator = constructors.className = constructors.attribute = void 0;\n\nvar _attribute = _interopRequireDefault$2(attribute$1);\n\nvar _className = _interopRequireDefault$2(classNameExports);\n\nvar _combinator = _interopRequireDefault$2(combinatorExports);\n\nvar _comment = _interopRequireDefault$2(commentExports);\n\nvar _id = _interopRequireDefault$2(idExports);\n\nvar _nesting = _interopRequireDefault$2(nestingExports);\n\nvar _pseudo = _interopRequireDefault$2(pseudoExports);\n\nvar _root = _interopRequireDefault$2(rootExports);\n\nvar _selector = _interopRequireDefault$2(selectorExports);\n\nvar _string = _interopRequireDefault$2(stringExports);\n\nvar _tag = _interopRequireDefault$2(tagExports);\n\nvar _universal = _interopRequireDefault$2(universalExports);\n\nfunction _interopRequireDefault$2(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\nvar attribute = function attribute(opts) {\n  return new _attribute[\"default\"](opts);\n};\n\nconstructors.attribute = attribute;\n\nvar className = function className(opts) {\n  return new _className[\"default\"](opts);\n};\n\nconstructors.className = className;\n\nvar combinator = function combinator(opts) {\n  return new _combinator[\"default\"](opts);\n};\n\nconstructors.combinator = combinator;\n\nvar comment = function comment(opts) {\n  return new _comment[\"default\"](opts);\n};\n\nconstructors.comment = comment;\n\nvar id = function id(opts) {\n  return new _id[\"default\"](opts);\n};\n\nconstructors.id = id;\n\nvar nesting = function nesting(opts) {\n  return new _nesting[\"default\"](opts);\n};\n\nconstructors.nesting = nesting;\n\nvar pseudo = function pseudo(opts) {\n  return new _pseudo[\"default\"](opts);\n};\n\nconstructors.pseudo = pseudo;\n\nvar root = function root(opts) {\n  return new _root[\"default\"](opts);\n};\n\nconstructors.root = root;\n\nvar selector = function selector(opts) {\n  return new _selector[\"default\"](opts);\n};\n\nconstructors.selector = selector;\n\nvar string = function string(opts) {\n  return new _string[\"default\"](opts);\n};\n\nconstructors.string = string;\n\nvar tag = function tag(opts) {\n  return new _tag[\"default\"](opts);\n};\n\nconstructors.tag = tag;\n\nvar universal = function universal(opts) {\n  return new _universal[\"default\"](opts);\n};\n\nconstructors.universal = universal;\n\nvar guards = {};\n\nguards.__esModule = true;\nguards.isNode = isNode;\nguards.isPseudoElement = isPseudoElement;\nguards.isPseudoClass = isPseudoClass;\nguards.isContainer = isContainer;\nguards.isNamespace = isNamespace;\nguards.isUniversal = guards.isTag = guards.isString = guards.isSelector = guards.isRoot = guards.isPseudo = guards.isNesting = guards.isIdentifier = guards.isComment = guards.isCombinator = guards.isClassName = guards.isAttribute = void 0;\n\nvar _types = types;\n\nvar _IS_TYPE;\n\nvar IS_TYPE = (_IS_TYPE = {}, _IS_TYPE[_types.ATTRIBUTE] = true, _IS_TYPE[_types.CLASS] = true, _IS_TYPE[_types.COMBINATOR] = true, _IS_TYPE[_types.COMMENT] = true, _IS_TYPE[_types.ID] = true, _IS_TYPE[_types.NESTING] = true, _IS_TYPE[_types.PSEUDO] = true, _IS_TYPE[_types.ROOT] = true, _IS_TYPE[_types.SELECTOR] = true, _IS_TYPE[_types.STRING] = true, _IS_TYPE[_types.TAG] = true, _IS_TYPE[_types.UNIVERSAL] = true, _IS_TYPE);\n\nfunction isNode(node) {\n  return typeof node === \"object\" && IS_TYPE[node.type];\n}\n\nfunction isNodeType(type, node) {\n  return isNode(node) && node.type === type;\n}\n\nvar isAttribute = isNodeType.bind(null, _types.ATTRIBUTE);\nguards.isAttribute = isAttribute;\nvar isClassName = isNodeType.bind(null, _types.CLASS);\nguards.isClassName = isClassName;\nvar isCombinator = isNodeType.bind(null, _types.COMBINATOR);\nguards.isCombinator = isCombinator;\nvar isComment = isNodeType.bind(null, _types.COMMENT);\nguards.isComment = isComment;\nvar isIdentifier = isNodeType.bind(null, _types.ID);\nguards.isIdentifier = isIdentifier;\nvar isNesting = isNodeType.bind(null, _types.NESTING);\nguards.isNesting = isNesting;\nvar isPseudo = isNodeType.bind(null, _types.PSEUDO);\nguards.isPseudo = isPseudo;\nvar isRoot = isNodeType.bind(null, _types.ROOT);\nguards.isRoot = isRoot;\nvar isSelector = isNodeType.bind(null, _types.SELECTOR);\nguards.isSelector = isSelector;\nvar isString = isNodeType.bind(null, _types.STRING);\nguards.isString = isString;\nvar isTag = isNodeType.bind(null, _types.TAG);\nguards.isTag = isTag;\nvar isUniversal = isNodeType.bind(null, _types.UNIVERSAL);\nguards.isUniversal = isUniversal;\n\nfunction isPseudoElement(node) {\n  return isPseudo(node) && node.value && (node.value.startsWith(\"::\") || node.value.toLowerCase() === \":before\" || node.value.toLowerCase() === \":after\" || node.value.toLowerCase() === \":first-letter\" || node.value.toLowerCase() === \":first-line\");\n}\n\nfunction isPseudoClass(node) {\n  return isPseudo(node) && !isPseudoElement(node);\n}\n\nfunction isContainer(node) {\n  return !!(isNode(node) && node.walk);\n}\n\nfunction isNamespace(node) {\n  return isAttribute(node) || isTag(node);\n}\n\n(function (exports) {\n\n\texports.__esModule = true;\n\n\tvar _types = types;\n\n\tObject.keys(_types).forEach(function (key) {\n\t  if (key === \"default\" || key === \"__esModule\") return;\n\t  if (key in exports && exports[key] === _types[key]) return;\n\t  exports[key] = _types[key];\n\t});\n\n\tvar _constructors = constructors;\n\n\tObject.keys(_constructors).forEach(function (key) {\n\t  if (key === \"default\" || key === \"__esModule\") return;\n\t  if (key in exports && exports[key] === _constructors[key]) return;\n\t  exports[key] = _constructors[key];\n\t});\n\n\tvar _guards = guards;\n\n\tObject.keys(_guards).forEach(function (key) {\n\t  if (key === \"default\" || key === \"__esModule\") return;\n\t  if (key in exports && exports[key] === _guards[key]) return;\n\t  exports[key] = _guards[key];\n\t});\n} (selectors));\n\n(function (module, exports) {\n\n\texports.__esModule = true;\n\texports[\"default\"] = void 0;\n\n\tvar _processor = _interopRequireDefault(processorExports);\n\n\tvar selectors$1 = _interopRequireWildcard(selectors);\n\n\tfunction _getRequireWildcardCache() { if (typeof WeakMap !== \"function\") return null; var cache = new WeakMap(); _getRequireWildcardCache = function _getRequireWildcardCache() { return cache; }; return cache; }\n\n\tfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== \"object\" && typeof obj !== \"function\") { return { \"default\": obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj[\"default\"] = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\n\tvar parser = function parser(processor) {\n\t  return new _processor[\"default\"](processor);\n\t};\n\n\tObject.assign(parser, selectors$1);\n\tdelete parser.__esModule;\n\tvar _default = parser;\n\texports[\"default\"] = _default;\n\tmodule.exports = exports.default;\n} (dist, distExports));\n\nconst selectorParser$1 = distExports;\nconst valueParser = lib;\nconst { extractICSS } = src$4;\n\nconst isSpacing = (node) => node.type === \"combinator\" && node.value === \" \";\n\nfunction normalizeNodeArray(nodes) {\n  const array = [];\n\n  nodes.forEach((x) => {\n    if (Array.isArray(x)) {\n      normalizeNodeArray(x).forEach((item) => {\n        array.push(item);\n      });\n    } else if (x) {\n      array.push(x);\n    }\n  });\n\n  if (array.length > 0 && isSpacing(array[array.length - 1])) {\n    array.pop();\n  }\n  return array;\n}\n\nfunction localizeNode(rule, mode, localAliasMap) {\n  const transform = (node, context) => {\n    if (context.ignoreNextSpacing && !isSpacing(node)) {\n      throw new Error(\"Missing whitespace after \" + context.ignoreNextSpacing);\n    }\n\n    if (context.enforceNoSpacing && isSpacing(node)) {\n      throw new Error(\"Missing whitespace before \" + context.enforceNoSpacing);\n    }\n\n    let newNodes;\n\n    switch (node.type) {\n      case \"root\": {\n        let resultingGlobal;\n\n        context.hasPureGlobals = false;\n\n        newNodes = node.nodes.map((n) => {\n          const nContext = {\n            global: context.global,\n            lastWasSpacing: true,\n            hasLocals: false,\n            explicit: false,\n          };\n\n          n = transform(n, nContext);\n\n          if (typeof resultingGlobal === \"undefined\") {\n            resultingGlobal = nContext.global;\n          } else if (resultingGlobal !== nContext.global) {\n            throw new Error(\n              'Inconsistent rule global/local result in rule \"' +\n                node +\n                '\" (multiple selectors must result in the same mode for the rule)'\n            );\n          }\n\n          if (!nContext.hasLocals) {\n            context.hasPureGlobals = true;\n          }\n\n          return n;\n        });\n\n        context.global = resultingGlobal;\n\n        node.nodes = normalizeNodeArray(newNodes);\n        break;\n      }\n      case \"selector\": {\n        newNodes = node.map((childNode) => transform(childNode, context));\n\n        node = node.clone();\n        node.nodes = normalizeNodeArray(newNodes);\n        break;\n      }\n      case \"combinator\": {\n        if (isSpacing(node)) {\n          if (context.ignoreNextSpacing) {\n            context.ignoreNextSpacing = false;\n            context.lastWasSpacing = false;\n            context.enforceNoSpacing = false;\n            return null;\n          }\n          context.lastWasSpacing = true;\n          return node;\n        }\n        break;\n      }\n      case \"pseudo\": {\n        let childContext;\n        const isNested = !!node.length;\n        const isScoped = node.value === \":local\" || node.value === \":global\";\n        const isImportExport =\n          node.value === \":import\" || node.value === \":export\";\n\n        if (isImportExport) {\n          context.hasLocals = true;\n          // :local(.foo)\n        } else if (isNested) {\n          if (isScoped) {\n            if (node.nodes.length === 0) {\n              throw new Error(`${node.value}() can't be empty`);\n            }\n\n            if (context.inside) {\n              throw new Error(\n                `A ${node.value} is not allowed inside of a ${context.inside}(...)`\n              );\n            }\n\n            childContext = {\n              global: node.value === \":global\",\n              inside: node.value,\n              hasLocals: false,\n              explicit: true,\n            };\n\n            newNodes = node\n              .map((childNode) => transform(childNode, childContext))\n              .reduce((acc, next) => acc.concat(next.nodes), []);\n\n            if (newNodes.length) {\n              const { before, after } = node.spaces;\n\n              const first = newNodes[0];\n              const last = newNodes[newNodes.length - 1];\n\n              first.spaces = { before, after: first.spaces.after };\n              last.spaces = { before: last.spaces.before, after };\n            }\n\n            node = newNodes;\n\n            break;\n          } else {\n            childContext = {\n              global: context.global,\n              inside: context.inside,\n              lastWasSpacing: true,\n              hasLocals: false,\n              explicit: context.explicit,\n            };\n            newNodes = node.map((childNode) =>\n              transform(childNode, childContext)\n            );\n\n            node = node.clone();\n            node.nodes = normalizeNodeArray(newNodes);\n\n            if (childContext.hasLocals) {\n              context.hasLocals = true;\n            }\n          }\n          break;\n\n          //:local .foo .bar\n        } else if (isScoped) {\n          if (context.inside) {\n            throw new Error(\n              `A ${node.value} is not allowed inside of a ${context.inside}(...)`\n            );\n          }\n\n          const addBackSpacing = !!node.spaces.before;\n\n          context.ignoreNextSpacing = context.lastWasSpacing\n            ? node.value\n            : false;\n\n          context.enforceNoSpacing = context.lastWasSpacing\n            ? false\n            : node.value;\n\n          context.global = node.value === \":global\";\n          context.explicit = true;\n\n          // because this node has spacing that is lost when we remove it\n          // we make up for it by adding an extra combinator in since adding\n          // spacing on the parent selector doesn't work\n          return addBackSpacing\n            ? selectorParser$1.combinator({ value: \" \" })\n            : null;\n        }\n        break;\n      }\n      case \"id\":\n      case \"class\": {\n        if (!node.value) {\n          throw new Error(\"Invalid class or id selector syntax\");\n        }\n\n        if (context.global) {\n          break;\n        }\n\n        const isImportedValue = localAliasMap.has(node.value);\n        const isImportedWithExplicitScope = isImportedValue && context.explicit;\n\n        if (!isImportedValue || isImportedWithExplicitScope) {\n          const innerNode = node.clone();\n          innerNode.spaces = { before: \"\", after: \"\" };\n\n          node = selectorParser$1.pseudo({\n            value: \":local\",\n            nodes: [innerNode],\n            spaces: node.spaces,\n          });\n\n          context.hasLocals = true;\n        }\n\n        break;\n      }\n    }\n\n    context.lastWasSpacing = false;\n    context.ignoreNextSpacing = false;\n    context.enforceNoSpacing = false;\n\n    return node;\n  };\n\n  const rootContext = {\n    global: mode === \"global\",\n    hasPureGlobals: false,\n  };\n\n  rootContext.selector = selectorParser$1((root) => {\n    transform(root, rootContext);\n  }).processSync(rule, { updateSelector: false, lossless: true });\n\n  return rootContext;\n}\n\nfunction localizeDeclNode(node, context) {\n  switch (node.type) {\n    case \"word\":\n      if (context.localizeNextItem) {\n        if (!context.localAliasMap.has(node.value)) {\n          node.value = \":local(\" + node.value + \")\";\n          context.localizeNextItem = false;\n        }\n      }\n      break;\n\n    case \"function\":\n      if (\n        context.options &&\n        context.options.rewriteUrl &&\n        node.value.toLowerCase() === \"url\"\n      ) {\n        node.nodes.map((nestedNode) => {\n          if (nestedNode.type !== \"string\" && nestedNode.type !== \"word\") {\n            return;\n          }\n\n          let newUrl = context.options.rewriteUrl(\n            context.global,\n            nestedNode.value\n          );\n\n          switch (nestedNode.type) {\n            case \"string\":\n              if (nestedNode.quote === \"'\") {\n                newUrl = newUrl.replace(/(\\\\)/g, \"\\\\$1\").replace(/'/g, \"\\\\'\");\n              }\n\n              if (nestedNode.quote === '\"') {\n                newUrl = newUrl.replace(/(\\\\)/g, \"\\\\$1\").replace(/\"/g, '\\\\\"');\n              }\n\n              break;\n            case \"word\":\n              newUrl = newUrl.replace(/(\"|'|\\)|\\\\)/g, \"\\\\$1\");\n              break;\n          }\n\n          nestedNode.value = newUrl;\n        });\n      }\n      break;\n  }\n  return node;\n}\n\nfunction isWordAFunctionArgument(wordNode, functionNode) {\n  return functionNode\n    ? functionNode.nodes.some(\n        (functionNodeChild) =>\n          functionNodeChild.sourceIndex === wordNode.sourceIndex\n      )\n    : false;\n}\n\nfunction localizeDeclarationValues(localize, declaration, context) {\n  const valueNodes = valueParser(declaration.value);\n\n  valueNodes.walk((node, index, nodes) => {\n    const subContext = {\n      options: context.options,\n      global: context.global,\n      localizeNextItem: localize && !context.global,\n      localAliasMap: context.localAliasMap,\n    };\n    nodes[index] = localizeDeclNode(node, subContext);\n  });\n\n  declaration.value = valueNodes.toString();\n}\n\nfunction localizeDeclaration(declaration, context) {\n  const isAnimation = /animation$/i.test(declaration.prop);\n\n  if (isAnimation) {\n    const validIdent = /^-?[_a-z][_a-z0-9-]*$/i;\n\n    /*\n    The spec defines some keywords that you can use to describe properties such as the timing\n    function. These are still valid animation names, so as long as there is a property that accepts\n    a keyword, it is given priority. Only when all the properties that can take a keyword are\n    exhausted can the animation name be set to the keyword. I.e.\n  \n    animation: infinite infinite;\n  \n    The animation will repeat an infinite number of times from the first argument, and will have an\n    animation name of infinite from the second.\n    */\n    const animationKeywords = {\n      $alternate: 1,\n      \"$alternate-reverse\": 1,\n      $backwards: 1,\n      $both: 1,\n      $ease: 1,\n      \"$ease-in\": 1,\n      \"$ease-in-out\": 1,\n      \"$ease-out\": 1,\n      $forwards: 1,\n      $infinite: 1,\n      $linear: 1,\n      $none: Infinity, // No matter how many times you write none, it will never be an animation name\n      $normal: 1,\n      $paused: 1,\n      $reverse: 1,\n      $running: 1,\n      \"$step-end\": 1,\n      \"$step-start\": 1,\n      $initial: Infinity,\n      $inherit: Infinity,\n      $unset: Infinity,\n    };\n    let parsedAnimationKeywords = {};\n    let stepsFunctionNode = null;\n    const valueNodes = valueParser(declaration.value).walk((node) => {\n      /* If div-token appeared (represents as comma ','), a possibility of an animation-keywords should be reflesh. */\n      if (node.type === \"div\") {\n        parsedAnimationKeywords = {};\n      }\n      if (node.type === \"function\" && node.value.toLowerCase() === \"steps\") {\n        stepsFunctionNode = node;\n      }\n      const value =\n        node.type === \"word\" &&\n        !isWordAFunctionArgument(node, stepsFunctionNode)\n          ? node.value.toLowerCase()\n          : null;\n\n      let shouldParseAnimationName = false;\n\n      if (value && validIdent.test(value)) {\n        if (\"$\" + value in animationKeywords) {\n          parsedAnimationKeywords[\"$\" + value] =\n            \"$\" + value in parsedAnimationKeywords\n              ? parsedAnimationKeywords[\"$\" + value] + 1\n              : 0;\n\n          shouldParseAnimationName =\n            parsedAnimationKeywords[\"$\" + value] >=\n            animationKeywords[\"$\" + value];\n        } else {\n          shouldParseAnimationName = true;\n        }\n      }\n\n      const subContext = {\n        options: context.options,\n        global: context.global,\n        localizeNextItem: shouldParseAnimationName && !context.global,\n        localAliasMap: context.localAliasMap,\n      };\n      return localizeDeclNode(node, subContext);\n    });\n\n    declaration.value = valueNodes.toString();\n\n    return;\n  }\n\n  const isAnimationName = /animation(-name)?$/i.test(declaration.prop);\n\n  if (isAnimationName) {\n    return localizeDeclarationValues(true, declaration, context);\n  }\n\n  const hasUrl = /url\\(/i.test(declaration.value);\n\n  if (hasUrl) {\n    return localizeDeclarationValues(false, declaration, context);\n  }\n}\n\nsrc$2.exports = (options = {}) => {\n  if (\n    options &&\n    options.mode &&\n    options.mode !== \"global\" &&\n    options.mode !== \"local\" &&\n    options.mode !== \"pure\"\n  ) {\n    throw new Error(\n      'options.mode must be either \"global\", \"local\" or \"pure\" (default \"local\")'\n    );\n  }\n\n  const pureMode = options && options.mode === \"pure\";\n  const globalMode = options && options.mode === \"global\";\n\n  return {\n    postcssPlugin: \"postcss-modules-local-by-default\",\n    prepare() {\n      const localAliasMap = new Map();\n\n      return {\n        Once(root) {\n          const { icssImports } = extractICSS(root, false);\n\n          Object.keys(icssImports).forEach((key) => {\n            Object.keys(icssImports[key]).forEach((prop) => {\n              localAliasMap.set(prop, icssImports[key][prop]);\n            });\n          });\n\n          root.walkAtRules((atRule) => {\n            if (/keyframes$/i.test(atRule.name)) {\n              const globalMatch = /^\\s*:global\\s*\\((.+)\\)\\s*$/.exec(\n                atRule.params\n              );\n              const localMatch = /^\\s*:local\\s*\\((.+)\\)\\s*$/.exec(\n                atRule.params\n              );\n\n              let globalKeyframes = globalMode;\n\n              if (globalMatch) {\n                if (pureMode) {\n                  throw atRule.error(\n                    \"@keyframes :global(...) is not allowed in pure mode\"\n                  );\n                }\n                atRule.params = globalMatch[1];\n                globalKeyframes = true;\n              } else if (localMatch) {\n                atRule.params = localMatch[0];\n                globalKeyframes = false;\n              } else if (!globalMode) {\n                if (atRule.params && !localAliasMap.has(atRule.params)) {\n                  atRule.params = \":local(\" + atRule.params + \")\";\n                }\n              }\n\n              atRule.walkDecls((declaration) => {\n                localizeDeclaration(declaration, {\n                  localAliasMap,\n                  options: options,\n                  global: globalKeyframes,\n                });\n              });\n            } else if (atRule.nodes) {\n              atRule.nodes.forEach((declaration) => {\n                if (declaration.type === \"decl\") {\n                  localizeDeclaration(declaration, {\n                    localAliasMap,\n                    options: options,\n                    global: globalMode,\n                  });\n                }\n              });\n            }\n          });\n\n          root.walkRules((rule) => {\n            if (\n              rule.parent &&\n              rule.parent.type === \"atrule\" &&\n              /keyframes$/i.test(rule.parent.name)\n            ) {\n              // ignore keyframe rules\n              return;\n            }\n\n            const context = localizeNode(rule, options.mode, localAliasMap);\n\n            context.options = options;\n            context.localAliasMap = localAliasMap;\n\n            if (pureMode && context.hasPureGlobals) {\n              throw rule.error(\n                'Selector \"' +\n                  rule.selector +\n                  '\" is not pure ' +\n                  \"(pure selectors must contain at least one local class or id)\"\n              );\n            }\n\n            rule.selector = context.selector;\n\n            // Less-syntax mixins parse as rules with no nodes\n            if (rule.nodes) {\n              rule.nodes.forEach((declaration) =>\n                localizeDeclaration(declaration, context)\n              );\n            }\n          });\n        },\n      };\n    },\n  };\n};\nsrcExports$1.postcss = true;\n\nconst selectorParser = distExports;\n\nconst hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction getSingleLocalNamesForComposes(root) {\n  return root.nodes.map((node) => {\n    if (node.type !== \"selector\" || node.nodes.length !== 1) {\n      throw new Error(\n        `composition is only allowed when selector is single :local class name not in \"${root}\"`\n      );\n    }\n\n    node = node.nodes[0];\n\n    if (\n      node.type !== \"pseudo\" ||\n      node.value !== \":local\" ||\n      node.nodes.length !== 1\n    ) {\n      throw new Error(\n        'composition is only allowed when selector is single :local class name not in \"' +\n          root +\n          '\", \"' +\n          node +\n          '\" is weird'\n      );\n    }\n\n    node = node.first;\n\n    if (node.type !== \"selector\" || node.length !== 1) {\n      throw new Error(\n        'composition is only allowed when selector is single :local class name not in \"' +\n          root +\n          '\", \"' +\n          node +\n          '\" is weird'\n      );\n    }\n\n    node = node.first;\n\n    if (node.type !== \"class\") {\n      // 'id' is not possible, because you can't compose ids\n      throw new Error(\n        'composition is only allowed when selector is single :local class name not in \"' +\n          root +\n          '\", \"' +\n          node +\n          '\" is weird'\n      );\n    }\n\n    return node.value;\n  });\n}\n\nconst whitespace = \"[\\\\x20\\\\t\\\\r\\\\n\\\\f]\";\nconst unescapeRegExp = new RegExp(\n  \"\\\\\\\\([\\\\da-f]{1,6}\" + whitespace + \"?|(\" + whitespace + \")|.)\",\n  \"ig\"\n);\n\nfunction unescape(str) {\n  return str.replace(unescapeRegExp, (_, escaped, escapedWhitespace) => {\n    const high = \"0x\" + escaped - 0x10000;\n\n    // NaN means non-codepoint\n    // Workaround erroneous numeric interpretation of +\"0x\"\n    return high !== high || escapedWhitespace\n      ? escaped\n      : high < 0\n      ? // BMP codepoint\n        String.fromCharCode(high + 0x10000)\n      : // Supplemental Plane codepoint (surrogate pair)\n        String.fromCharCode((high >> 10) | 0xd800, (high & 0x3ff) | 0xdc00);\n  });\n}\n\nconst plugin = (options = {}) => {\n  const generateScopedName =\n    (options && options.generateScopedName) || plugin.generateScopedName;\n  const generateExportEntry =\n    (options && options.generateExportEntry) || plugin.generateExportEntry;\n  const exportGlobals = options && options.exportGlobals;\n\n  return {\n    postcssPlugin: \"postcss-modules-scope\",\n    Once(root, { rule }) {\n      const exports = Object.create(null);\n\n      function exportScopedName(name, rawName) {\n        const scopedName = generateScopedName(\n          rawName ? rawName : name,\n          root.source.input.from,\n          root.source.input.css\n        );\n        const exportEntry = generateExportEntry(\n          rawName ? rawName : name,\n          scopedName,\n          root.source.input.from,\n          root.source.input.css\n        );\n        const { key, value } = exportEntry;\n\n        exports[key] = exports[key] || [];\n\n        if (exports[key].indexOf(value) < 0) {\n          exports[key].push(value);\n        }\n\n        return scopedName;\n      }\n\n      function localizeNode(node) {\n        switch (node.type) {\n          case \"selector\":\n            node.nodes = node.map(localizeNode);\n            return node;\n          case \"class\":\n            return selectorParser.className({\n              value: exportScopedName(\n                node.value,\n                node.raws && node.raws.value ? node.raws.value : null\n              ),\n            });\n          case \"id\": {\n            return selectorParser.id({\n              value: exportScopedName(\n                node.value,\n                node.raws && node.raws.value ? node.raws.value : null\n              ),\n            });\n          }\n        }\n\n        throw new Error(\n          `${node.type} (\"${node}\") is not allowed in a :local block`\n        );\n      }\n\n      function traverseNode(node) {\n        switch (node.type) {\n          case \"pseudo\":\n            if (node.value === \":local\") {\n              if (node.nodes.length !== 1) {\n                throw new Error('Unexpected comma (\",\") in :local block');\n              }\n\n              const selector = localizeNode(node.first);\n              // move the spaces that were around the psuedo selector to the first\n              // non-container node\n              selector.first.spaces = node.spaces;\n\n              const nextNode = node.next();\n\n              if (\n                nextNode &&\n                nextNode.type === \"combinator\" &&\n                nextNode.value === \" \" &&\n                /\\\\[A-F0-9]{1,6}$/.test(selector.last.value)\n              ) {\n                selector.last.spaces.after = \" \";\n              }\n\n              node.replaceWith(selector);\n\n              return;\n            }\n          /* falls through */\n          case \"root\":\n          case \"selector\": {\n            node.each(traverseNode);\n            break;\n          }\n          case \"id\":\n          case \"class\":\n            if (exportGlobals) {\n              exports[node.value] = [node.value];\n            }\n            break;\n        }\n        return node;\n      }\n\n      // Find any :import and remember imported names\n      const importedNames = {};\n\n      root.walkRules(/^:import\\(.+\\)$/, (rule) => {\n        rule.walkDecls((decl) => {\n          importedNames[decl.prop] = true;\n        });\n      });\n\n      // Find any :local selectors\n      root.walkRules((rule) => {\n        let parsedSelector = selectorParser().astSync(rule);\n\n        rule.selector = traverseNode(parsedSelector.clone()).toString();\n\n        rule.walkDecls(/composes|compose-with/i, (decl) => {\n          const localNames = getSingleLocalNamesForComposes(parsedSelector);\n          const classes = decl.value.split(/\\s+/);\n\n          classes.forEach((className) => {\n            const global = /^global\\(([^)]+)\\)$/.exec(className);\n\n            if (global) {\n              localNames.forEach((exportedName) => {\n                exports[exportedName].push(global[1]);\n              });\n            } else if (hasOwnProperty.call(importedNames, className)) {\n              localNames.forEach((exportedName) => {\n                exports[exportedName].push(className);\n              });\n            } else if (hasOwnProperty.call(exports, className)) {\n              localNames.forEach((exportedName) => {\n                exports[className].forEach((item) => {\n                  exports[exportedName].push(item);\n                });\n              });\n            } else {\n              throw decl.error(\n                `referenced class name \"${className}\" in ${decl.prop} not found`\n              );\n            }\n          });\n\n          decl.remove();\n        });\n\n        // Find any :local values\n        rule.walkDecls((decl) => {\n          if (!/:local\\s*\\((.+?)\\)/.test(decl.value)) {\n            return;\n          }\n\n          let tokens = decl.value.split(/(,|'[^']*'|\"[^\"]*\")/);\n\n          tokens = tokens.map((token, idx) => {\n            if (idx === 0 || tokens[idx - 1] === \",\") {\n              let result = token;\n\n              const localMatch = /:local\\s*\\((.+?)\\)/.exec(token);\n\n              if (localMatch) {\n                const input = localMatch.input;\n                const matchPattern = localMatch[0];\n                const matchVal = localMatch[1];\n                const newVal = exportScopedName(matchVal);\n\n                result = input.replace(matchPattern, newVal);\n              } else {\n                return token;\n              }\n\n              return result;\n            } else {\n              return token;\n            }\n          });\n\n          decl.value = tokens.join(\"\");\n        });\n      });\n\n      // Find any :local keyframes\n      root.walkAtRules(/keyframes$/i, (atRule) => {\n        const localMatch = /^\\s*:local\\s*\\((.+?)\\)\\s*$/.exec(atRule.params);\n\n        if (!localMatch) {\n          return;\n        }\n\n        atRule.params = exportScopedName(localMatch[1]);\n      });\n\n      // If we found any :locals, insert an :export rule\n      const exportedNames = Object.keys(exports);\n\n      if (exportedNames.length > 0) {\n        const exportRule = rule({ selector: \":export\" });\n\n        exportedNames.forEach((exportedName) =>\n          exportRule.append({\n            prop: exportedName,\n            value: exports[exportedName].join(\" \"),\n            raws: { before: \"\\n  \" },\n          })\n        );\n\n        root.append(exportRule);\n      }\n    },\n  };\n};\n\nplugin.postcss = true;\n\nplugin.generateScopedName = function (name, path) {\n  const sanitisedPath = path\n    .replace(/\\.[^./\\\\]+$/, \"\")\n    .replace(/[\\W_]+/g, \"_\")\n    .replace(/^_|_$/g, \"\");\n\n  return `_${sanitisedPath}__${name}`.trim();\n};\n\nplugin.generateExportEntry = function (name, scopedName) {\n  return {\n    key: unescape(name),\n    value: unescape(scopedName),\n  };\n};\n\nvar src$1 = plugin;\n\nfunction hash(str) {\n  var hash = 5381,\n      i    = str.length;\n\n  while(i) {\n    hash = (hash * 33) ^ str.charCodeAt(--i);\n  }\n\n  /* JavaScript does bitwise operations (like XOR, above) on 32-bit signed\n   * integers. Since we want the results to be always positive, convert the\n   * signed int to an unsigned by doing an unsigned bitshift. */\n  return hash >>> 0;\n}\n\nvar stringHash = hash;\n\nvar srcExports = {};\nvar src = {\n  get exports(){ return srcExports; },\n  set exports(v){ srcExports = v; },\n};\n\nconst ICSSUtils = src$4;\n\nconst matchImports = /^(.+?|\\([\\s\\S]+?\\))\\s+from\\s+(\"[^\"]*\"|'[^']*'|[\\w-]+)$/;\nconst matchValueDefinition = /(?:\\s+|^)([\\w-]+):?(.*?)$/;\nconst matchImport = /^([\\w-]+)(?:\\s+as\\s+([\\w-]+))?/;\n\nsrc.exports = (options) => {\n  let importIndex = 0;\n  const createImportedName =\n    (options && options.createImportedName) ||\n    ((importName /*, path*/) =>\n      `i__const_${importName.replace(/\\W/g, \"_\")}_${importIndex++}`);\n\n  return {\n    postcssPlugin: \"postcss-modules-values\",\n    prepare(result) {\n      const importAliases = [];\n      const definitions = {};\n\n      return {\n        Once(root, postcss) {\n          root.walkAtRules(/value/i, (atRule) => {\n            const matches = atRule.params.match(matchImports);\n\n            if (matches) {\n              let [, /*match*/ aliases, path] = matches;\n\n              // We can use constants for path names\n              if (definitions[path]) {\n                path = definitions[path];\n              }\n\n              const imports = aliases\n                .replace(/^\\(\\s*([\\s\\S]+)\\s*\\)$/, \"$1\")\n                .split(/\\s*,\\s*/)\n                .map((alias) => {\n                  const tokens = matchImport.exec(alias);\n\n                  if (tokens) {\n                    const [, /*match*/ theirName, myName = theirName] = tokens;\n                    const importedName = createImportedName(myName);\n                    definitions[myName] = importedName;\n                    return { theirName, importedName };\n                  } else {\n                    throw new Error(`@import statement \"${alias}\" is invalid!`);\n                  }\n                });\n\n              importAliases.push({ path, imports });\n\n              atRule.remove();\n\n              return;\n            }\n\n            if (atRule.params.indexOf(\"@value\") !== -1) {\n              result.warn(\"Invalid value definition: \" + atRule.params);\n            }\n\n            let [, key, value] = `${atRule.params}${atRule.raws.between}`.match(\n              matchValueDefinition\n            );\n\n            const normalizedValue = value.replace(/\\/\\*((?!\\*\\/).*?)\\*\\//g, \"\");\n\n            if (normalizedValue.length === 0) {\n              result.warn(\"Invalid value definition: \" + atRule.params);\n              atRule.remove();\n\n              return;\n            }\n\n            let isOnlySpace = /^\\s+$/.test(normalizedValue);\n\n            if (!isOnlySpace) {\n              value = value.trim();\n            }\n\n            // Add to the definitions, knowing that values can refer to each other\n            definitions[key] = ICSSUtils.replaceValueSymbols(\n              value,\n              definitions\n            );\n\n            atRule.remove();\n          });\n\n          /* If we have no definitions, don't continue */\n          if (!Object.keys(definitions).length) {\n            return;\n          }\n\n          /* Perform replacements */\n          ICSSUtils.replaceSymbols(root, definitions);\n\n          /* We want to export anything defined by now, but don't add it to the CSS yet or it well get picked up by the replacement stuff */\n          const exportDeclarations = Object.keys(definitions).map((key) =>\n            postcss.decl({\n              value: definitions[key],\n              prop: key,\n              raws: { before: \"\\n  \" },\n            })\n          );\n\n          /* Add export rules if any */\n          if (exportDeclarations.length > 0) {\n            const exportRule = postcss.rule({\n              selector: \":export\",\n              raws: { after: \"\\n\" },\n            });\n\n            exportRule.append(exportDeclarations);\n\n            root.prepend(exportRule);\n          }\n\n          /* Add import rules */\n          importAliases.reverse().forEach(({ path, imports }) => {\n            const importRule = postcss.rule({\n              selector: `:import(${path})`,\n              raws: { after: \"\\n\" },\n            });\n\n            imports.forEach(({ theirName, importedName }) => {\n              importRule.append({\n                value: theirName,\n                prop: importedName,\n                raws: { before: \"\\n  \" },\n              });\n            });\n\n            root.prepend(importRule);\n          });\n        },\n      };\n    },\n  };\n};\n\nsrcExports.postcss = true;\n\nObject.defineProperty(scoping, \"__esModule\", {\n  value: true\n});\nscoping.behaviours = void 0;\nscoping.getDefaultPlugins = getDefaultPlugins;\nscoping.getDefaultScopeBehaviour = getDefaultScopeBehaviour;\nscoping.getScopedNameGenerator = getScopedNameGenerator;\n\nvar _postcssModulesExtractImports = _interopRequireDefault$1(srcExports$2);\n\nvar _genericNames = _interopRequireDefault$1(genericNames);\n\nvar _postcssModulesLocalByDefault = _interopRequireDefault$1(srcExports$1);\n\nvar _postcssModulesScope = _interopRequireDefault$1(src$1);\n\nvar _stringHash = _interopRequireDefault$1(stringHash);\n\nvar _postcssModulesValues = _interopRequireDefault$1(srcExports);\n\nfunction _interopRequireDefault$1(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst behaviours = {\n  LOCAL: \"local\",\n  GLOBAL: \"global\"\n};\nscoping.behaviours = behaviours;\n\nfunction getDefaultPlugins({\n  behaviour,\n  generateScopedName,\n  exportGlobals\n}) {\n  const scope = (0, _postcssModulesScope.default)({\n    generateScopedName,\n    exportGlobals\n  });\n  const plugins = {\n    [behaviours.LOCAL]: [_postcssModulesValues.default, (0, _postcssModulesLocalByDefault.default)({\n      mode: \"local\"\n    }), _postcssModulesExtractImports.default, scope],\n    [behaviours.GLOBAL]: [_postcssModulesValues.default, (0, _postcssModulesLocalByDefault.default)({\n      mode: \"global\"\n    }), _postcssModulesExtractImports.default, scope]\n  };\n  return plugins[behaviour];\n}\n\nfunction isValidBehaviour(behaviour) {\n  return Object.keys(behaviours).map(key => behaviours[key]).indexOf(behaviour) > -1;\n}\n\nfunction getDefaultScopeBehaviour(scopeBehaviour) {\n  return scopeBehaviour && isValidBehaviour(scopeBehaviour) ? scopeBehaviour : behaviours.LOCAL;\n}\n\nfunction generateScopedNameDefault(name, filename, css) {\n  const i = css.indexOf(`.${name}`);\n  const lineNumber = css.substr(0, i).split(/[\\r\\n]/).length;\n  const hash = (0, _stringHash.default)(css).toString(36).substr(0, 5);\n  return `_${name}_${hash}_${lineNumber}`;\n}\n\nfunction getScopedNameGenerator(generateScopedName, hashPrefix) {\n  const scopedNameGenerator = generateScopedName || generateScopedNameDefault;\n\n  if (typeof scopedNameGenerator === \"function\") {\n    return scopedNameGenerator;\n  }\n\n  return (0, _genericNames.default)(scopedNameGenerator, {\n    context: process.cwd(),\n    hashPrefix: hashPrefix\n  });\n}\n\nObject.defineProperty(pluginFactory, \"__esModule\", {\n  value: true\n});\npluginFactory.makePlugin = makePlugin;\n\nvar _postcss = _interopRequireDefault(require$$0);\n\nvar _unquote = _interopRequireDefault(unquote$1);\n\nvar _Parser = _interopRequireDefault(Parser$1);\n\nvar _saveJSON = _interopRequireDefault(saveJSON$1);\n\nvar _localsConvention = localsConvention;\n\nvar _FileSystemLoader = _interopRequireDefault(FileSystemLoader$1);\n\nvar _scoping = scoping;\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst PLUGIN_NAME = \"postcss-modules\";\n\nfunction isGlobalModule(globalModules, inputFile) {\n  return globalModules.some(regex => inputFile.match(regex));\n}\n\nfunction getDefaultPluginsList(opts, inputFile) {\n  const globalModulesList = opts.globalModulePaths || null;\n  const exportGlobals = opts.exportGlobals || false;\n  const defaultBehaviour = (0, _scoping.getDefaultScopeBehaviour)(opts.scopeBehaviour);\n  const generateScopedName = (0, _scoping.getScopedNameGenerator)(opts.generateScopedName, opts.hashPrefix);\n\n  if (globalModulesList && isGlobalModule(globalModulesList, inputFile)) {\n    return (0, _scoping.getDefaultPlugins)({\n      behaviour: _scoping.behaviours.GLOBAL,\n      generateScopedName,\n      exportGlobals\n    });\n  }\n\n  return (0, _scoping.getDefaultPlugins)({\n    behaviour: defaultBehaviour,\n    generateScopedName,\n    exportGlobals\n  });\n}\n\nfunction getLoader(opts, plugins) {\n  const root = typeof opts.root === \"undefined\" ? \"/\" : opts.root;\n  return typeof opts.Loader === \"function\" ? new opts.Loader(root, plugins, opts.resolve) : new _FileSystemLoader.default(root, plugins, opts.resolve);\n}\n\nfunction isOurPlugin(plugin) {\n  return plugin.postcssPlugin === PLUGIN_NAME;\n}\n\nfunction makePlugin(opts) {\n  return {\n    postcssPlugin: PLUGIN_NAME,\n\n    async OnceExit(css, {\n      result\n    }) {\n      const getJSON = opts.getJSON || _saveJSON.default;\n      const inputFile = css.source.input.file;\n      const pluginList = getDefaultPluginsList(opts, inputFile);\n      const resultPluginIndex = result.processor.plugins.findIndex(plugin => isOurPlugin(plugin));\n\n      if (resultPluginIndex === -1) {\n        throw new Error(\"Plugin missing from options.\");\n      }\n\n      const earlierPlugins = result.processor.plugins.slice(0, resultPluginIndex);\n      const loaderPlugins = [...earlierPlugins, ...pluginList];\n      const loader = getLoader(opts, loaderPlugins);\n\n      const fetcher = async (file, relativeTo, depTrace) => {\n        const unquoteFile = (0, _unquote.default)(file);\n        return loader.fetch.call(loader, unquoteFile, relativeTo, depTrace);\n      };\n\n      const parser = new _Parser.default(fetcher);\n      await (0, _postcss.default)([...pluginList, parser.plugin()]).process(css, {\n        from: inputFile\n      });\n      const out = loader.finalSource;\n      if (out) css.prepend(out);\n\n      if (opts.localsConvention) {\n        const reducer = (0, _localsConvention.makeLocalsConventionReducer)(opts.localsConvention, inputFile);\n        parser.exportTokens = Object.entries(parser.exportTokens).reduce(reducer, {});\n      }\n\n      result.messages.push({\n        type: \"export\",\n        plugin: \"postcss-modules\",\n        exportTokens: parser.exportTokens\n      }); // getJSON may return a promise\n\n      return getJSON(css.source.input.file, parser.exportTokens, result.opts.to);\n    }\n\n  };\n}\n\nvar _fs = require$$0__default;\n\nvar _fs2 = fs;\n\nvar _pluginFactory = pluginFactory;\n\n(0, _fs2.setFileSystem)({\n  readFile: _fs.readFile,\n  writeFile: _fs.writeFile\n});\n\nbuild.exports = (opts = {}) => (0, _pluginFactory.makePlugin)(opts);\n\nvar postcss = buildExports.postcss = true;\n\nvar index = /*#__PURE__*/_mergeNamespaces({\n  __proto__: null,\n  get default () { return buildExports; },\n  postcss: postcss\n}, [buildExports]);\n\nexport { index as i };\n"}}}},"cli.js":{"file":{"contents":"import path from 'node:path';\nimport fs from 'node:fs';\nimport { performance } from 'node:perf_hooks';\nimport { EventEmitter } from 'events';\nimport { A as picocolorsExports, B as bindShortcuts, w as createLogger, h as resolveConfig } from './chunks/dep-ca21228b.js';\nimport { VERSION } from './constants.js';\nimport 'node:url';\nimport 'node:module';\nimport 'tty';\nimport 'esbuild';\nimport 'path';\nimport './chunks/dep-ace95160.js';\nimport 'fs';\nimport 'assert';\nimport 'util';\nimport 'net';\nimport 'url';\nimport 'http';\nimport 'stream';\nimport 'os';\nimport 'child_process';\nimport 'node:os';\nimport 'node:crypto';\nimport 'node:util';\nimport 'node:dns';\nimport 'resolve';\nimport 'crypto';\nimport 'node:buffer';\nimport 'module';\nimport 'node:assert';\nimport 'node:process';\nimport 'node:v8';\nimport 'worker_threads';\nimport 'zlib';\nimport 'buffer';\nimport 'https';\nimport 'tls';\nimport 'node:http';\nimport 'node:https';\nimport 'rollup';\nimport 'querystring';\nimport 'node:child_process';\nimport 'node:readline';\nimport 'node:zlib';\n\nfunction toArr(any) {\n\treturn any == null ? [] : Array.isArray(any) ? any : [any];\n}\n\nfunction toVal(out, key, val, opts) {\n\tvar x, old=out[key], nxt=(\n\t\t!!~opts.string.indexOf(key) ? (val == null || val === true ? '' : String(val))\n\t\t: typeof val === 'boolean' ? val\n\t\t: !!~opts.boolean.indexOf(key) ? (val === 'false' ? false : val === 'true' || (out._.push((x = +val,x * 0 === 0) ? x : val),!!val))\n\t\t: (x = +val,x * 0 === 0) ? x : val\n\t);\n\tout[key] = old == null ? nxt : (Array.isArray(old) ? old.concat(nxt) : [old, nxt]);\n}\n\nfunction mri2 (args, opts) {\n\targs = args || [];\n\topts = opts || {};\n\n\tvar k, arr, arg, name, val, out={ _:[] };\n\tvar i=0, j=0, idx=0, len=args.length;\n\n\tconst alibi = opts.alias !== void 0;\n\tconst strict = opts.unknown !== void 0;\n\tconst defaults = opts.default !== void 0;\n\n\topts.alias = opts.alias || {};\n\topts.string = toArr(opts.string);\n\topts.boolean = toArr(opts.boolean);\n\n\tif (alibi) {\n\t\tfor (k in opts.alias) {\n\t\t\tarr = opts.alias[k] = toArr(opts.alias[k]);\n\t\t\tfor (i=0; i < arr.length; i++) {\n\t\t\t\t(opts.alias[arr[i]] = arr.concat(k)).splice(i, 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i=opts.boolean.length; i-- > 0;) {\n\t\tarr = opts.alias[opts.boolean[i]] || [];\n\t\tfor (j=arr.length; j-- > 0;) opts.boolean.push(arr[j]);\n\t}\n\n\tfor (i=opts.string.length; i-- > 0;) {\n\t\tarr = opts.alias[opts.string[i]] || [];\n\t\tfor (j=arr.length; j-- > 0;) opts.string.push(arr[j]);\n\t}\n\n\tif (defaults) {\n\t\tfor (k in opts.default) {\n\t\t\tname = typeof opts.default[k];\n\t\t\tarr = opts.alias[k] = opts.alias[k] || [];\n\t\t\tif (opts[name] !== void 0) {\n\t\t\t\topts[name].push(k);\n\t\t\t\tfor (i=0; i < arr.length; i++) {\n\t\t\t\t\topts[name].push(arr[i]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tconst keys = strict ? Object.keys(opts.alias) : [];\n\n\tfor (i=0; i < len; i++) {\n\t\targ = args[i];\n\n\t\tif (arg === '--') {\n\t\t\tout._ = out._.concat(args.slice(++i));\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (j=0; j < arg.length; j++) {\n\t\t\tif (arg.charCodeAt(j) !== 45) break; // \"-\"\n\t\t}\n\n\t\tif (j === 0) {\n\t\t\tout._.push(arg);\n\t\t} else if (arg.substring(j, j + 3) === 'no-') {\n\t\t\tname = arg.substring(j + 3);\n\t\t\tif (strict && !~keys.indexOf(name)) {\n\t\t\t\treturn opts.unknown(arg);\n\t\t\t}\n\t\t\tout[name] = false;\n\t\t} else {\n\t\t\tfor (idx=j+1; idx < arg.length; idx++) {\n\t\t\t\tif (arg.charCodeAt(idx) === 61) break; // \"=\"\n\t\t\t}\n\n\t\t\tname = arg.substring(j, idx);\n\t\t\tval = arg.substring(++idx) || (i+1 === len || (''+args[i+1]).charCodeAt(0) === 45 || args[++i]);\n\t\t\tarr = (j === 2 ? [name] : name);\n\n\t\t\tfor (idx=0; idx < arr.length; idx++) {\n\t\t\t\tname = arr[idx];\n\t\t\t\tif (strict && !~keys.indexOf(name)) return opts.unknown('-'.repeat(j) + name);\n\t\t\t\ttoVal(out, name, (idx + 1 < arr.length) || val, opts);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (defaults) {\n\t\tfor (k in opts.default) {\n\t\t\tif (out[k] === void 0) {\n\t\t\t\tout[k] = opts.default[k];\n\t\t\t}\n\t\t}\n\t}\n\n\tif (alibi) {\n\t\tfor (k in out) {\n\t\t\tarr = opts.alias[k] || [];\n\t\t\twhile (arr.length > 0) {\n\t\t\t\tout[arr.shift()] = out[k];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn out;\n}\n\nconst removeBrackets = (v) => v.replace(/[<[].+/, \"\").trim();\nconst findAllBrackets = (v) => {\n  const ANGLED_BRACKET_RE_GLOBAL = /<([^>]+)>/g;\n  const SQUARE_BRACKET_RE_GLOBAL = /\\[([^\\]]+)\\]/g;\n  const res = [];\n  const parse = (match) => {\n    let variadic = false;\n    let value = match[1];\n    if (value.startsWith(\"...\")) {\n      value = value.slice(3);\n      variadic = true;\n    }\n    return {\n      required: match[0].startsWith(\"<\"),\n      value,\n      variadic\n    };\n  };\n  let angledMatch;\n  while (angledMatch = ANGLED_BRACKET_RE_GLOBAL.exec(v)) {\n    res.push(parse(angledMatch));\n  }\n  let squareMatch;\n  while (squareMatch = SQUARE_BRACKET_RE_GLOBAL.exec(v)) {\n    res.push(parse(squareMatch));\n  }\n  return res;\n};\nconst getMriOptions = (options) => {\n  const result = {alias: {}, boolean: []};\n  for (const [index, option] of options.entries()) {\n    if (option.names.length > 1) {\n      result.alias[option.names[0]] = option.names.slice(1);\n    }\n    if (option.isBoolean) {\n      if (option.negated) {\n        const hasStringTypeOption = options.some((o, i) => {\n          return i !== index && o.names.some((name) => option.names.includes(name)) && typeof o.required === \"boolean\";\n        });\n        if (!hasStringTypeOption) {\n          result.boolean.push(option.names[0]);\n        }\n      } else {\n        result.boolean.push(option.names[0]);\n      }\n    }\n  }\n  return result;\n};\nconst findLongest = (arr) => {\n  return arr.sort((a, b) => {\n    return a.length > b.length ? -1 : 1;\n  })[0];\n};\nconst padRight = (str, length) => {\n  return str.length >= length ? str : `${str}${\" \".repeat(length - str.length)}`;\n};\nconst camelcase = (input) => {\n  return input.replace(/([a-z])-([a-z])/g, (_, p1, p2) => {\n    return p1 + p2.toUpperCase();\n  });\n};\nconst setDotProp = (obj, keys, val) => {\n  let i = 0;\n  let length = keys.length;\n  let t = obj;\n  let x;\n  for (; i < length; ++i) {\n    x = t[keys[i]];\n    t = t[keys[i]] = i === length - 1 ? val : x != null ? x : !!~keys[i + 1].indexOf(\".\") || !(+keys[i + 1] > -1) ? {} : [];\n  }\n};\nconst setByType = (obj, transforms) => {\n  for (const key of Object.keys(transforms)) {\n    const transform = transforms[key];\n    if (transform.shouldTransform) {\n      obj[key] = Array.prototype.concat.call([], obj[key]);\n      if (typeof transform.transformFunction === \"function\") {\n        obj[key] = obj[key].map(transform.transformFunction);\n      }\n    }\n  }\n};\nconst getFileName = (input) => {\n  const m = /([^\\\\\\/]+)$/.exec(input);\n  return m ? m[1] : \"\";\n};\nconst camelcaseOptionName = (name) => {\n  return name.split(\".\").map((v, i) => {\n    return i === 0 ? camelcase(v) : v;\n  }).join(\".\");\n};\nclass CACError extends Error {\n  constructor(message) {\n    super(message);\n    this.name = this.constructor.name;\n    if (typeof Error.captureStackTrace === \"function\") {\n      Error.captureStackTrace(this, this.constructor);\n    } else {\n      this.stack = new Error(message).stack;\n    }\n  }\n}\n\nclass Option {\n  constructor(rawName, description, config) {\n    this.rawName = rawName;\n    this.description = description;\n    this.config = Object.assign({}, config);\n    rawName = rawName.replace(/\\.\\*/g, \"\");\n    this.negated = false;\n    this.names = removeBrackets(rawName).split(\",\").map((v) => {\n      let name = v.trim().replace(/^-{1,2}/, \"\");\n      if (name.startsWith(\"no-\")) {\n        this.negated = true;\n        name = name.replace(/^no-/, \"\");\n      }\n      return camelcaseOptionName(name);\n    }).sort((a, b) => a.length > b.length ? 1 : -1);\n    this.name = this.names[this.names.length - 1];\n    if (this.negated && this.config.default == null) {\n      this.config.default = true;\n    }\n    if (rawName.includes(\"<\")) {\n      this.required = true;\n    } else if (rawName.includes(\"[\")) {\n      this.required = false;\n    } else {\n      this.isBoolean = true;\n    }\n  }\n}\n\nconst processArgs = process.argv;\nconst platformInfo = `${process.platform}-${process.arch} node-${process.version}`;\n\nclass Command {\n  constructor(rawName, description, config = {}, cli) {\n    this.rawName = rawName;\n    this.description = description;\n    this.config = config;\n    this.cli = cli;\n    this.options = [];\n    this.aliasNames = [];\n    this.name = removeBrackets(rawName);\n    this.args = findAllBrackets(rawName);\n    this.examples = [];\n  }\n  usage(text) {\n    this.usageText = text;\n    return this;\n  }\n  allowUnknownOptions() {\n    this.config.allowUnknownOptions = true;\n    return this;\n  }\n  ignoreOptionDefaultValue() {\n    this.config.ignoreOptionDefaultValue = true;\n    return this;\n  }\n  version(version, customFlags = \"-v, --version\") {\n    this.versionNumber = version;\n    this.option(customFlags, \"Display version number\");\n    return this;\n  }\n  example(example) {\n    this.examples.push(example);\n    return this;\n  }\n  option(rawName, description, config) {\n    const option = new Option(rawName, description, config);\n    this.options.push(option);\n    return this;\n  }\n  alias(name) {\n    this.aliasNames.push(name);\n    return this;\n  }\n  action(callback) {\n    this.commandAction = callback;\n    return this;\n  }\n  isMatched(name) {\n    return this.name === name || this.aliasNames.includes(name);\n  }\n  get isDefaultCommand() {\n    return this.name === \"\" || this.aliasNames.includes(\"!\");\n  }\n  get isGlobalCommand() {\n    return this instanceof GlobalCommand;\n  }\n  hasOption(name) {\n    name = name.split(\".\")[0];\n    return this.options.find((option) => {\n      return option.names.includes(name);\n    });\n  }\n  outputHelp() {\n    const {name, commands} = this.cli;\n    const {\n      versionNumber,\n      options: globalOptions,\n      helpCallback\n    } = this.cli.globalCommand;\n    let sections = [\n      {\n        body: `${name}${versionNumber ? `/${versionNumber}` : \"\"}`\n      }\n    ];\n    sections.push({\n      title: \"Usage\",\n      body: `  $ ${name} ${this.usageText || this.rawName}`\n    });\n    const showCommands = (this.isGlobalCommand || this.isDefaultCommand) && commands.length > 0;\n    if (showCommands) {\n      const longestCommandName = findLongest(commands.map((command) => command.rawName));\n      sections.push({\n        title: \"Commands\",\n        body: commands.map((command) => {\n          return `  ${padRight(command.rawName, longestCommandName.length)}  ${command.description}`;\n        }).join(\"\\n\")\n      });\n      sections.push({\n        title: `For more info, run any command with the \\`--help\\` flag`,\n        body: commands.map((command) => `  $ ${name}${command.name === \"\" ? \"\" : ` ${command.name}`} --help`).join(\"\\n\")\n      });\n    }\n    let options = this.isGlobalCommand ? globalOptions : [...this.options, ...globalOptions || []];\n    if (!this.isGlobalCommand && !this.isDefaultCommand) {\n      options = options.filter((option) => option.name !== \"version\");\n    }\n    if (options.length > 0) {\n      const longestOptionName = findLongest(options.map((option) => option.rawName));\n      sections.push({\n        title: \"Options\",\n        body: options.map((option) => {\n          return `  ${padRight(option.rawName, longestOptionName.length)}  ${option.description} ${option.config.default === void 0 ? \"\" : `(default: ${option.config.default})`}`;\n        }).join(\"\\n\")\n      });\n    }\n    if (this.examples.length > 0) {\n      sections.push({\n        title: \"Examples\",\n        body: this.examples.map((example) => {\n          if (typeof example === \"function\") {\n            return example(name);\n          }\n          return example;\n        }).join(\"\\n\")\n      });\n    }\n    if (helpCallback) {\n      sections = helpCallback(sections) || sections;\n    }\n    console.log(sections.map((section) => {\n      return section.title ? `${section.title}:\n${section.body}` : section.body;\n    }).join(\"\\n\\n\"));\n  }\n  outputVersion() {\n    const {name} = this.cli;\n    const {versionNumber} = this.cli.globalCommand;\n    if (versionNumber) {\n      console.log(`${name}/${versionNumber} ${platformInfo}`);\n    }\n  }\n  checkRequiredArgs() {\n    const minimalArgsCount = this.args.filter((arg) => arg.required).length;\n    if (this.cli.args.length < minimalArgsCount) {\n      throw new CACError(`missing required args for command \\`${this.rawName}\\``);\n    }\n  }\n  checkUnknownOptions() {\n    const {options, globalCommand} = this.cli;\n    if (!this.config.allowUnknownOptions) {\n      for (const name of Object.keys(options)) {\n        if (name !== \"--\" && !this.hasOption(name) && !globalCommand.hasOption(name)) {\n          throw new CACError(`Unknown option \\`${name.length > 1 ? `--${name}` : `-${name}`}\\``);\n        }\n      }\n    }\n  }\n  checkOptionValue() {\n    const {options: parsedOptions, globalCommand} = this.cli;\n    const options = [...globalCommand.options, ...this.options];\n    for (const option of options) {\n      const value = parsedOptions[option.name.split(\".\")[0]];\n      if (option.required) {\n        const hasNegated = options.some((o) => o.negated && o.names.includes(option.name));\n        if (value === true || value === false && !hasNegated) {\n          throw new CACError(`option \\`${option.rawName}\\` value is missing`);\n        }\n      }\n    }\n  }\n}\nclass GlobalCommand extends Command {\n  constructor(cli) {\n    super(\"@@global@@\", \"\", {}, cli);\n  }\n}\n\nvar __assign = Object.assign;\nclass CAC extends EventEmitter {\n  constructor(name = \"\") {\n    super();\n    this.name = name;\n    this.commands = [];\n    this.rawArgs = [];\n    this.args = [];\n    this.options = {};\n    this.globalCommand = new GlobalCommand(this);\n    this.globalCommand.usage(\"<command> [options]\");\n  }\n  usage(text) {\n    this.globalCommand.usage(text);\n    return this;\n  }\n  command(rawName, description, config) {\n    const command = new Command(rawName, description || \"\", config, this);\n    command.globalCommand = this.globalCommand;\n    this.commands.push(command);\n    return command;\n  }\n  option(rawName, description, config) {\n    this.globalCommand.option(rawName, description, config);\n    return this;\n  }\n  help(callback) {\n    this.globalCommand.option(\"-h, --help\", \"Display this message\");\n    this.globalCommand.helpCallback = callback;\n    this.showHelpOnExit = true;\n    return this;\n  }\n  version(version, customFlags = \"-v, --version\") {\n    this.globalCommand.version(version, customFlags);\n    this.showVersionOnExit = true;\n    return this;\n  }\n  example(example) {\n    this.globalCommand.example(example);\n    return this;\n  }\n  outputHelp() {\n    if (this.matchedCommand) {\n      this.matchedCommand.outputHelp();\n    } else {\n      this.globalCommand.outputHelp();\n    }\n  }\n  outputVersion() {\n    this.globalCommand.outputVersion();\n  }\n  setParsedInfo({args, options}, matchedCommand, matchedCommandName) {\n    this.args = args;\n    this.options = options;\n    if (matchedCommand) {\n      this.matchedCommand = matchedCommand;\n    }\n    if (matchedCommandName) {\n      this.matchedCommandName = matchedCommandName;\n    }\n    return this;\n  }\n  unsetMatchedCommand() {\n    this.matchedCommand = void 0;\n    this.matchedCommandName = void 0;\n  }\n  parse(argv = processArgs, {\n    run = true\n  } = {}) {\n    this.rawArgs = argv;\n    if (!this.name) {\n      this.name = argv[1] ? getFileName(argv[1]) : \"cli\";\n    }\n    let shouldParse = true;\n    for (const command of this.commands) {\n      const parsed = this.mri(argv.slice(2), command);\n      const commandName = parsed.args[0];\n      if (command.isMatched(commandName)) {\n        shouldParse = false;\n        const parsedInfo = __assign(__assign({}, parsed), {\n          args: parsed.args.slice(1)\n        });\n        this.setParsedInfo(parsedInfo, command, commandName);\n        this.emit(`command:${commandName}`, command);\n      }\n    }\n    if (shouldParse) {\n      for (const command of this.commands) {\n        if (command.name === \"\") {\n          shouldParse = false;\n          const parsed = this.mri(argv.slice(2), command);\n          this.setParsedInfo(parsed, command);\n          this.emit(`command:!`, command);\n        }\n      }\n    }\n    if (shouldParse) {\n      const parsed = this.mri(argv.slice(2));\n      this.setParsedInfo(parsed);\n    }\n    if (this.options.help && this.showHelpOnExit) {\n      this.outputHelp();\n      run = false;\n      this.unsetMatchedCommand();\n    }\n    if (this.options.version && this.showVersionOnExit && this.matchedCommandName == null) {\n      this.outputVersion();\n      run = false;\n      this.unsetMatchedCommand();\n    }\n    const parsedArgv = {args: this.args, options: this.options};\n    if (run) {\n      this.runMatchedCommand();\n    }\n    if (!this.matchedCommand && this.args[0]) {\n      this.emit(\"command:*\");\n    }\n    return parsedArgv;\n  }\n  mri(argv, command) {\n    const cliOptions = [\n      ...this.globalCommand.options,\n      ...command ? command.options : []\n    ];\n    const mriOptions = getMriOptions(cliOptions);\n    let argsAfterDoubleDashes = [];\n    const doubleDashesIndex = argv.indexOf(\"--\");\n    if (doubleDashesIndex > -1) {\n      argsAfterDoubleDashes = argv.slice(doubleDashesIndex + 1);\n      argv = argv.slice(0, doubleDashesIndex);\n    }\n    let parsed = mri2(argv, mriOptions);\n    parsed = Object.keys(parsed).reduce((res, name) => {\n      return __assign(__assign({}, res), {\n        [camelcaseOptionName(name)]: parsed[name]\n      });\n    }, {_: []});\n    const args = parsed._;\n    const options = {\n      \"--\": argsAfterDoubleDashes\n    };\n    const ignoreDefault = command && command.config.ignoreOptionDefaultValue ? command.config.ignoreOptionDefaultValue : this.globalCommand.config.ignoreOptionDefaultValue;\n    let transforms = Object.create(null);\n    for (const cliOption of cliOptions) {\n      if (!ignoreDefault && cliOption.config.default !== void 0) {\n        for (const name of cliOption.names) {\n          options[name] = cliOption.config.default;\n        }\n      }\n      if (Array.isArray(cliOption.config.type)) {\n        if (transforms[cliOption.name] === void 0) {\n          transforms[cliOption.name] = Object.create(null);\n          transforms[cliOption.name][\"shouldTransform\"] = true;\n          transforms[cliOption.name][\"transformFunction\"] = cliOption.config.type[0];\n        }\n      }\n    }\n    for (const key of Object.keys(parsed)) {\n      if (key !== \"_\") {\n        const keys = key.split(\".\");\n        setDotProp(options, keys, parsed[key]);\n        setByType(options, transforms);\n      }\n    }\n    return {\n      args,\n      options\n    };\n  }\n  runMatchedCommand() {\n    const {args, options, matchedCommand: command} = this;\n    if (!command || !command.commandAction)\n      return;\n    command.checkUnknownOptions();\n    command.checkOptionValue();\n    command.checkRequiredArgs();\n    const actionArgs = [];\n    command.args.forEach((arg, index) => {\n      if (arg.variadic) {\n        actionArgs.push(args.slice(index));\n      } else {\n        actionArgs.push(args[index]);\n      }\n    });\n    actionArgs.push(options);\n    return command.commandAction.apply(this, actionArgs);\n  }\n}\n\nconst cac = (name = \"\") => new CAC(name);\n\nconst cli = cac('vite');\nlet profileSession = global.__vite_profile_session;\nlet profileCount = 0;\nconst stopProfiler = (log) => {\n    if (!profileSession)\n        return;\n    return new Promise((res, rej) => {\n        profileSession.post('Profiler.stop', (err, { profile }) => {\n            // Write profile to disk, upload, etc.\n            if (!err) {\n                const outPath = path.resolve(`./vite-profile-${profileCount++}.cpuprofile`);\n                fs.writeFileSync(outPath, JSON.stringify(profile));\n                log(picocolorsExports.yellow(`CPU profile written to ${picocolorsExports.white(picocolorsExports.dim(outPath))}`));\n                profileSession = undefined;\n                res();\n            }\n            else {\n                rej(err);\n            }\n        });\n    });\n};\nconst filterDuplicateOptions = (options) => {\n    for (const [key, value] of Object.entries(options)) {\n        if (Array.isArray(value)) {\n            options[key] = value[value.length - 1];\n        }\n    }\n};\n/**\n * removing global flags before passing as command specific sub-configs\n */\nfunction cleanOptions(options) {\n    const ret = { ...options };\n    delete ret['--'];\n    delete ret.c;\n    delete ret.config;\n    delete ret.base;\n    delete ret.l;\n    delete ret.logLevel;\n    delete ret.clearScreen;\n    delete ret.d;\n    delete ret.debug;\n    delete ret.f;\n    delete ret.filter;\n    delete ret.m;\n    delete ret.mode;\n    return ret;\n}\ncli\n    .option('-c, --config <file>', `[string] use specified config file`)\n    .option('--base <path>', `[string] public base path (default: /)`)\n    .option('-l, --logLevel <level>', `[string] info | warn | error | silent`)\n    .option('--clearScreen', `[boolean] allow/disable clear screen when logging`)\n    .option('-d, --debug [feat]', `[string | boolean] show debug logs`)\n    .option('-f, --filter <filter>', `[string] filter debug logs`)\n    .option('-m, --mode <mode>', `[string] set env mode`);\n// dev\ncli\n    .command('[root]', 'start dev server') // default command\n    .alias('serve') // the command is called 'serve' in Vite's API\n    .alias('dev') // alias to align with the script name\n    .option('--host [host]', `[string] specify hostname`)\n    .option('--port <port>', `[number] specify port`)\n    .option('--https', `[boolean] use TLS + HTTP/2`)\n    .option('--open [path]', `[boolean | string] open browser on startup`)\n    .option('--cors', `[boolean] enable CORS`)\n    .option('--strictPort', `[boolean] exit if specified port is already in use`)\n    .option('--force', `[boolean] force the optimizer to ignore the cache and re-bundle`)\n    .action(async (root, options) => {\n    filterDuplicateOptions(options);\n    // output structure is preserved even after bundling so require()\n    // is ok here\n    const { createServer } = await import('./chunks/dep-ca21228b.js').then(function (n) { return n.E; });\n    try {\n        const server = await createServer({\n            root,\n            base: options.base,\n            mode: options.mode,\n            configFile: options.config,\n            logLevel: options.logLevel,\n            clearScreen: options.clearScreen,\n            optimizeDeps: { force: options.force },\n            server: cleanOptions(options),\n        });\n        if (!server.httpServer) {\n            throw new Error('HTTP server not available');\n        }\n        await server.listen();\n        const info = server.config.logger.info;\n        const viteStartTime = global.__vite_start_time ?? false;\n        const startupDurationString = viteStartTime\n            ? picocolorsExports.dim(`ready in ${picocolorsExports.reset(picocolorsExports.bold(Math.ceil(performance.now() - viteStartTime)))} ms`)\n            : '';\n        info(`\\n  ${picocolorsExports.green(`${picocolorsExports.bold('VITE')} v${VERSION}`)}  ${startupDurationString}\\n`, { clear: !server.config.logger.hasWarned });\n        server.printUrls();\n        bindShortcuts(server, {\n            print: true,\n            customShortcuts: [\n                profileSession && {\n                    key: 'p',\n                    description: 'start/stop the profiler',\n                    async action(server) {\n                        if (profileSession) {\n                            await stopProfiler(server.config.logger.info);\n                        }\n                        else {\n                            const inspector = await import('node:inspector').then((r) => r.default);\n                            await new Promise((res) => {\n                                profileSession = new inspector.Session();\n                                profileSession.connect();\n                                profileSession.post('Profiler.enable', () => {\n                                    profileSession.post('Profiler.start', () => {\n                                        server.config.logger.info('Profiler started');\n                                        res();\n                                    });\n                                });\n                            });\n                        }\n                    },\n                },\n            ],\n        });\n    }\n    catch (e) {\n        const logger = createLogger(options.logLevel);\n        logger.error(picocolorsExports.red(`error when starting dev server:\\n${e.stack}`), {\n            error: e,\n        });\n        stopProfiler(logger.info);\n        process.exit(1);\n    }\n});\n// build\ncli\n    .command('build [root]', 'build for production')\n    .option('--target <target>', `[string] transpile target (default: 'modules')`)\n    .option('--outDir <dir>', `[string] output directory (default: dist)`)\n    .option('--assetsDir <dir>', `[string] directory under outDir to place assets in (default: assets)`)\n    .option('--assetsInlineLimit <number>', `[number] static asset base64 inline threshold in bytes (default: 4096)`)\n    .option('--ssr [entry]', `[string] build specified entry for server-side rendering`)\n    .option('--sourcemap', `[boolean] output source maps for build (default: false)`)\n    .option('--minify [minifier]', `[boolean | \"terser\" | \"esbuild\"] enable/disable minification, ` +\n    `or specify minifier to use (default: esbuild)`)\n    .option('--manifest [name]', `[boolean | string] emit build manifest json`)\n    .option('--ssrManifest [name]', `[boolean | string] emit ssr manifest json`)\n    .option('--force', `[boolean] force the optimizer to ignore the cache and re-bundle (experimental)`)\n    .option('--emptyOutDir', `[boolean] force empty outDir when it's outside of root`)\n    .option('-w, --watch', `[boolean] rebuilds when modules have changed on disk`)\n    .action(async (root, options) => {\n    filterDuplicateOptions(options);\n    const { build } = await import('./chunks/dep-ca21228b.js').then(function (n) { return n.D; });\n    const buildOptions = cleanOptions(options);\n    try {\n        await build({\n            root,\n            base: options.base,\n            mode: options.mode,\n            configFile: options.config,\n            logLevel: options.logLevel,\n            clearScreen: options.clearScreen,\n            optimizeDeps: { force: options.force },\n            build: buildOptions,\n        });\n    }\n    catch (e) {\n        createLogger(options.logLevel).error(picocolorsExports.red(`error during build:\\n${e.stack}`), { error: e });\n        process.exit(1);\n    }\n    finally {\n        stopProfiler((message) => createLogger(options.logLevel).info(message));\n    }\n});\n// optimize\ncli\n    .command('optimize [root]', 'pre-bundle dependencies')\n    .option('--force', `[boolean] force the optimizer to ignore the cache and re-bundle`)\n    .action(async (root, options) => {\n    filterDuplicateOptions(options);\n    const { optimizeDeps } = await import('./chunks/dep-ca21228b.js').then(function (n) { return n.C; });\n    try {\n        const config = await resolveConfig({\n            root,\n            base: options.base,\n            configFile: options.config,\n            logLevel: options.logLevel,\n        }, 'serve');\n        await optimizeDeps(config, options.force, true);\n    }\n    catch (e) {\n        createLogger(options.logLevel).error(picocolorsExports.red(`error when optimizing deps:\\n${e.stack}`), { error: e });\n        process.exit(1);\n    }\n});\ncli\n    .command('preview [root]', 'locally preview production build')\n    .option('--host [host]', `[string] specify hostname`)\n    .option('--port <port>', `[number] specify port`)\n    .option('--strictPort', `[boolean] exit if specified port is already in use`)\n    .option('--https', `[boolean] use TLS + HTTP/2`)\n    .option('--open [path]', `[boolean | string] open browser on startup`)\n    .option('--outDir <dir>', `[string] output directory (default: dist)`)\n    .action(async (root, options) => {\n    filterDuplicateOptions(options);\n    const { preview } = await import('./chunks/dep-ca21228b.js').then(function (n) { return n.F; });\n    try {\n        const server = await preview({\n            root,\n            base: options.base,\n            configFile: options.config,\n            logLevel: options.logLevel,\n            mode: options.mode,\n            build: {\n                outDir: options.outDir,\n            },\n            preview: {\n                port: options.port,\n                strictPort: options.strictPort,\n                host: options.host,\n                https: options.https,\n                open: options.open,\n            },\n        });\n        server.printUrls();\n    }\n    catch (e) {\n        createLogger(options.logLevel).error(picocolorsExports.red(`error when starting preview server:\\n${e.stack}`), { error: e });\n        process.exit(1);\n    }\n    finally {\n        stopProfiler((message) => createLogger(options.logLevel).info(message));\n    }\n});\ncli.help();\ncli.version(VERSION);\ncli.parse();\n\nexport { stopProfiler };\n"}},"constants.js":{"file":{"contents":"import path, { resolve } from 'node:path';\nimport { fileURLToPath } from 'node:url';\nimport { readFileSync } from 'node:fs';\n\nconst { version } = JSON.parse(readFileSync(new URL('../../package.json', import.meta.url)).toString());\nconst VERSION = version;\nconst DEFAULT_MAIN_FIELDS = [\n    'module',\n    'jsnext:main',\n    'jsnext',\n];\n// Baseline support browserslist\n// \"defaults and supports es6-module and supports es6-module-dynamic-import\"\n// Higher browser versions may be needed for extra features.\nconst ESBUILD_MODULES_TARGET = [\n    'es2020',\n    'edge88',\n    'firefox78',\n    'chrome87',\n    'safari14',\n];\nconst DEFAULT_EXTENSIONS = [\n    '.mjs',\n    '.js',\n    '.mts',\n    '.ts',\n    '.jsx',\n    '.tsx',\n    '.json',\n];\nconst DEFAULT_CONFIG_FILES = [\n    'vite.config.js',\n    'vite.config.mjs',\n    'vite.config.ts',\n    'vite.config.cjs',\n    'vite.config.mts',\n    'vite.config.cts',\n];\nconst JS_TYPES_RE = /\\.(?:j|t)sx?$|\\.mjs$/;\nconst CSS_LANGS_RE = /\\.(css|less|sass|scss|styl|stylus|pcss|postcss|sss)(?:$|\\?)/;\nconst OPTIMIZABLE_ENTRY_RE = /\\.[cm]?[jt]s$/;\nconst SPECIAL_QUERY_RE = /[?&](?:worker|sharedworker|raw|url)\\b/;\n/**\n * Prefix for resolved fs paths, since windows paths may not be valid as URLs.\n */\nconst FS_PREFIX = `/@fs/`;\n/**\n * Prefix for resolved Ids that are not valid browser import specifiers\n */\nconst VALID_ID_PREFIX = `/@id/`;\n/**\n * Plugins that use 'virtual modules' (e.g. for helper functions), prefix the\n * module ID with `\\0`, a convention from the rollup ecosystem.\n * This prevents other plugins from trying to process the id (like node resolution),\n * and core features like sourcemaps can use this info to differentiate between\n * virtual modules and regular files.\n * `\\0` is not a permitted char in import URLs so we have to replace them during\n * import analysis. The id will be decoded back before entering the plugins pipeline.\n * These encoded virtual ids are also prefixed by the VALID_ID_PREFIX, so virtual\n * modules in the browser end up encoded as `/@id/__x00__{id}`\n */\nconst NULL_BYTE_PLACEHOLDER = `__x00__`;\nconst CLIENT_PUBLIC_PATH = `/@vite/client`;\nconst ENV_PUBLIC_PATH = `/@vite/env`;\nconst VITE_PACKAGE_DIR = resolve(\n// import.meta.url is `dist/node/constants.js` after bundle\nfileURLToPath(import.meta.url), '../../..');\nconst CLIENT_ENTRY = resolve(VITE_PACKAGE_DIR, 'dist/client/client.mjs');\nconst ENV_ENTRY = resolve(VITE_PACKAGE_DIR, 'dist/client/env.mjs');\nconst CLIENT_DIR = path.dirname(CLIENT_ENTRY);\n// ** READ THIS ** before editing `KNOWN_ASSET_TYPES`.\n//   If you add an asset to `KNOWN_ASSET_TYPES`, make sure to also add it\n//   to the TypeScript declaration file `packages/vite/client.d.ts` and\n//   add a mime type to the `registerCustomMime` in\n//   `packages/vite/src/node/plugin/assets.ts` if mime type cannot be\n//   looked up by mrmime.\nconst KNOWN_ASSET_TYPES = [\n    // images\n    'png',\n    'jpe?g',\n    'jfif',\n    'pjpeg',\n    'pjp',\n    'gif',\n    'svg',\n    'ico',\n    'webp',\n    'avif',\n    // media\n    'mp4',\n    'webm',\n    'ogg',\n    'mp3',\n    'wav',\n    'flac',\n    'aac',\n    // fonts\n    'woff2?',\n    'eot',\n    'ttf',\n    'otf',\n    // other\n    'webmanifest',\n    'pdf',\n    'txt',\n];\nconst DEFAULT_ASSETS_RE = new RegExp(`\\\\.(` + KNOWN_ASSET_TYPES.join('|') + `)(\\\\?.*)?$`);\nconst DEP_VERSION_RE = /[?&](v=[\\w.-]+)\\b/;\nconst loopbackHosts = new Set([\n    'localhost',\n    '127.0.0.1',\n    '::1',\n    '0000:0000:0000:0000:0000:0000:0000:0001',\n]);\nconst wildcardHosts = new Set([\n    '0.0.0.0',\n    '::',\n    '0000:0000:0000:0000:0000:0000:0000:0000',\n]);\nconst DEFAULT_DEV_PORT = 5173;\nconst DEFAULT_PREVIEW_PORT = 4173;\n\nexport { CLIENT_DIR, CLIENT_ENTRY, CLIENT_PUBLIC_PATH, CSS_LANGS_RE, DEFAULT_ASSETS_RE, DEFAULT_CONFIG_FILES, DEFAULT_DEV_PORT, DEFAULT_EXTENSIONS, DEFAULT_MAIN_FIELDS, DEFAULT_PREVIEW_PORT, DEP_VERSION_RE, ENV_ENTRY, ENV_PUBLIC_PATH, ESBUILD_MODULES_TARGET, FS_PREFIX, JS_TYPES_RE, KNOWN_ASSET_TYPES, NULL_BYTE_PLACEHOLDER, OPTIMIZABLE_ENTRY_RE, SPECIAL_QUERY_RE, VALID_ID_PREFIX, VERSION, VITE_PACKAGE_DIR, loopbackHosts, wildcardHosts };\n"}},"index.d.ts":{"file":{"contents":"/// <reference types=\"node\" />\r\n\r\nimport type { Agent } from 'node:http';\r\nimport type { BuildOptions as BuildOptions_2 } from 'esbuild';\r\nimport { ChunkMetadata } from \"../../types/metadata\";\r\nimport type { ClientRequest } from 'node:http';\r\nimport type { ClientRequestArgs } from 'node:http';\r\nimport { ConnectedPayload } from \"../../types/hmrPayload\";\r\nimport { CustomEventMap } from \"../../types/customEvent\";\r\nimport { CustomPayload } from \"../../types/hmrPayload\";\r\nimport type { CustomPluginOptions } from 'rollup';\r\nimport type { Duplex } from 'node:stream';\r\nimport type { DuplexOptions } from 'node:stream';\r\nimport { ErrorPayload } from \"../../types/hmrPayload\";\r\nimport { TransformOptions as EsbuildTransformOptions } from 'esbuild';\r\nimport { version as esbuildVersion } from 'esbuild';\r\nimport { EventEmitter } from 'node:events';\r\nimport * as events from 'node:events';\r\nimport type { ExistingRawSourceMap } from 'rollup';\r\nimport type * as fs from 'node:fs';\r\nimport { FullReloadPayload } from \"../../types/hmrPayload\";\r\nimport { GeneralImportGlobOptions } from \"../../types/importGlob\";\r\nimport type { GetManualChunk } from 'rollup';\r\nimport { HMRPayload } from \"../../types/hmrPayload\";\r\nimport * as http from 'node:http';\r\nimport { ImportGlobEagerFunction } from \"../../types/importGlob\";\r\nimport { ImportGlobFunction } from \"../../types/importGlob\";\r\nimport { ImportGlobOptions } from \"../../types/importGlob\";\r\nimport type { IncomingMessage } from 'node:http';\r\nimport { InferCustomEventPayload } from \"../../types/customEvent\";\r\nimport type { InputOption } from 'rollup';\r\nimport type { InputOptions } from 'rollup';\r\nimport { InvalidatePayload } from \"../../types/customEvent\";\r\nimport { KnownAsTypeMap } from \"../../types/importGlob\";\r\nimport type { LoadResult } from 'rollup';\r\n\r\nimport type { ModuleFormat } from 'rollup';\r\nimport type { ModuleInfo } from 'rollup';\r\nimport type * as net from 'node:net';\r\nimport type { ObjectHook } from 'rollup';\r\nimport type { OutgoingHttpHeaders } from 'node:http';\r\nimport type { OutputBundle } from 'rollup';\r\nimport type { OutputChunk } from 'rollup';\r\nimport type { PartialResolvedId } from 'rollup';\r\nimport type { Plugin as Plugin_3 } from 'rollup';\r\nimport type { PluginContext } from 'rollup';\r\nimport type { PluginHooks } from 'rollup';\r\nimport type * as PostCSS from 'postcss';\r\nimport { PrunePayload } from \"../../types/hmrPayload\";\r\nimport type { ResolveIdResult } from 'rollup';\r\nimport type { RollupError } from 'rollup';\r\nimport type { RollupOptions } from 'rollup';\r\nimport type { RollupOutput } from 'rollup';\r\nimport { VERSION as rollupVersion } from 'rollup';\r\nimport type { RollupWatcher } from 'rollup';\r\nimport type { SecureContextOptions } from 'node:tls';\r\nimport type { Server } from 'node:http';\r\nimport type { Server as Server_2 } from 'node:https';\r\nimport type { ServerOptions as ServerOptions_2 } from 'node:https';\r\nimport type { ServerResponse } from 'node:http';\r\nimport type { SourceDescription } from 'rollup';\r\nimport type { SourceMap } from 'rollup';\r\nimport type { SourceMapInput } from 'rollup';\r\nimport type * as stream from 'node:stream';\r\nimport type { TransformPluginContext } from 'rollup';\r\nimport type { TransformResult as TransformResult_2 } from 'rollup';\r\nimport type { TransformResult as TransformResult_3 } from 'esbuild';\r\nimport { Update } from \"../../types/hmrPayload\";\r\nimport { UpdatePayload } from \"../../types/hmrPayload\";\r\nimport type * as url from 'node:url';\r\nimport type { URL as URL_2 } from 'node:url';\r\nimport type { WatcherOptions } from 'rollup';\r\nimport type { ZlibOptions } from 'node:zlib';\r\n\r\nexport declare interface Alias {\r\n    find: string | RegExp\r\n    replacement: string\r\n    /**\r\n     * Instructs the plugin to use an alternative resolving algorithm,\r\n     * rather than the Rollup's resolver.\r\n     * @default null\r\n     */\r\n    customResolver?: ResolverFunction | ResolverObject | null\r\n}\r\n\r\n/**\r\n * Specifies an `Object`, or an `Array` of `Object`,\r\n * which defines aliases used to replace values in `import` or `require` statements.\r\n * With either format, the order of the entries is important,\r\n * in that the first defined rules are applied first.\r\n *\r\n * This is passed to \\@rollup/plugin-alias as the \"entries\" field\r\n * https://github.com/rollup/plugins/tree/master/packages/alias#entries\r\n */\r\nexport declare type AliasOptions = readonly Alias[] | { [find: string]: string }\r\n\r\nexport declare type AnymatchFn = (testString: string) => boolean\r\n\r\nexport declare type AnymatchPattern = string | RegExp | AnymatchFn\r\n\r\n/**\r\n * spa: include SPA fallback middleware and configure sirv with `single: true` in preview\r\n *\r\n * mpa: only include non-SPA HTML middlewares\r\n *\r\n * custom: don't include HTML middlewares\r\n */\r\nexport declare type AppType = 'spa' | 'mpa' | 'custom';\r\n\r\nexport declare interface AwaitWriteFinishOptions {\r\n    /**\r\n     * Amount of time in milliseconds for a file size to remain constant before emitting its event.\r\n     */\r\n    stabilityThreshold?: number\r\n\r\n    /**\r\n     * File size polling interval.\r\n     */\r\n    pollInterval?: number\r\n}\r\n\r\n/**\r\n * Bundles the app for production.\r\n * Returns a Promise containing the build result.\r\n */\r\nexport declare function build(inlineConfig?: InlineConfig): Promise<RollupOutput | RollupOutput[] | RollupWatcher>;\r\n\r\nexport declare function buildErrorMessage(err: RollupError, args?: string[], includeStack?: boolean): string;\r\n\r\nexport declare interface BuildOptions {\r\n    /**\r\n     * Compatibility transform target. The transform is performed with esbuild\r\n     * and the lowest supported target is es2015/es6. Note this only handles\r\n     * syntax transformation and does not cover polyfills (except for dynamic\r\n     * import)\r\n     *\r\n     * Default: 'modules' - Similar to `@babel/preset-env`'s targets.esmodules,\r\n     * transpile targeting browsers that natively support dynamic es module imports.\r\n     * https://caniuse.com/es6-module-dynamic-import\r\n     *\r\n     * Another special value is 'esnext' - which only performs minimal transpiling\r\n     * (for minification compat) and assumes native dynamic imports support.\r\n     *\r\n     * For custom targets, see https://esbuild.github.io/api/#target and\r\n     * https://esbuild.github.io/content-types/#javascript for more details.\r\n     * @default 'modules'\r\n     */\r\n    target?: 'modules' | EsbuildTransformOptions['target'] | false;\r\n    /**\r\n     * whether to inject module preload polyfill.\r\n     * Note: does not apply to library mode.\r\n     * @default true\r\n     * @deprecated use `modulePreload.polyfill` instead\r\n     */\r\n    polyfillModulePreload?: boolean;\r\n    /**\r\n     * Configure module preload\r\n     * Note: does not apply to library mode.\r\n     * @default true\r\n     */\r\n    modulePreload?: boolean | ModulePreloadOptions;\r\n    /**\r\n     * Directory relative from `root` where build output will be placed. If the\r\n     * directory exists, it will be removed before the build.\r\n     * @default 'dist'\r\n     */\r\n    outDir?: string;\r\n    /**\r\n     * Directory relative from `outDir` where the built js/css/image assets will\r\n     * be placed.\r\n     * @default 'assets'\r\n     */\r\n    assetsDir?: string;\r\n    /**\r\n     * Static asset files smaller than this number (in bytes) will be inlined as\r\n     * base64 strings. Default limit is `4096` (4kb). Set to `0` to disable.\r\n     * @default 4096\r\n     */\r\n    assetsInlineLimit?: number;\r\n    /**\r\n     * Whether to code-split CSS. When enabled, CSS in async chunks will be\r\n     * inlined as strings in the chunk and inserted via dynamically created\r\n     * style tags when the chunk is loaded.\r\n     * @default true\r\n     */\r\n    cssCodeSplit?: boolean;\r\n    /**\r\n     * An optional separate target for CSS minification.\r\n     * As esbuild only supports configuring targets to mainstream\r\n     * browsers, users may need this option when they are targeting\r\n     * a niche browser that comes with most modern JavaScript features\r\n     * but has poor CSS support, e.g. Android WeChat WebView, which\r\n     * doesn't support the #RGBA syntax.\r\n     * @default target\r\n     */\r\n    cssTarget?: EsbuildTransformOptions['target'] | false;\r\n    /**\r\n     * If `true`, a separate sourcemap file will be created. If 'inline', the\r\n     * sourcemap will be appended to the resulting output file as data URI.\r\n     * 'hidden' works like `true` except that the corresponding sourcemap\r\n     * comments in the bundled files are suppressed.\r\n     * @default false\r\n     */\r\n    sourcemap?: boolean | 'inline' | 'hidden';\r\n    /**\r\n     * Set to `false` to disable minification, or specify the minifier to use.\r\n     * Available options are 'terser' or 'esbuild'.\r\n     * @default 'esbuild'\r\n     */\r\n    minify?: boolean | 'terser' | 'esbuild';\r\n    /**\r\n     * Options for terser\r\n     * https://terser.org/docs/api-reference#minify-options\r\n     */\r\n    terserOptions?: Terser.MinifyOptions;\r\n    /**\r\n     * Will be merged with internal rollup options.\r\n     * https://rollupjs.org/configuration-options/\r\n     */\r\n    rollupOptions?: RollupOptions;\r\n    /**\r\n     * Options to pass on to `@rollup/plugin-commonjs`\r\n     */\r\n    commonjsOptions?: RollupCommonJSOptions;\r\n    /**\r\n     * Options to pass on to `@rollup/plugin-dynamic-import-vars`\r\n     */\r\n    dynamicImportVarsOptions?: RollupDynamicImportVarsOptions;\r\n    /**\r\n     * Whether to write bundle to disk\r\n     * @default true\r\n     */\r\n    write?: boolean;\r\n    /**\r\n     * Empty outDir on write.\r\n     * @default true when outDir is a sub directory of project root\r\n     */\r\n    emptyOutDir?: boolean | null;\r\n    /**\r\n     * Copy the public directory to outDir on write.\r\n     * @default true\r\n     * @experimental\r\n     */\r\n    copyPublicDir?: boolean;\r\n    /**\r\n     * Whether to emit a manifest.json under assets dir to map hash-less filenames\r\n     * to their hashed versions. Useful when you want to generate your own HTML\r\n     * instead of using the one generated by Vite.\r\n     *\r\n     * Example:\r\n     *\r\n     * ```json\r\n     * {\r\n     *   \"main.js\": {\r\n     *     \"file\": \"main.68fe3fad.js\",\r\n     *     \"css\": \"main.e6b63442.css\",\r\n     *     \"imports\": [...],\r\n     *     \"dynamicImports\": [...]\r\n     *   }\r\n     * }\r\n     * ```\r\n     * @default false\r\n     */\r\n    manifest?: boolean | string;\r\n    /**\r\n     * Build in library mode. The value should be the global name of the lib in\r\n     * UMD mode. This will produce esm + cjs + umd bundle formats with default\r\n     * configurations that are suitable for distributing libraries.\r\n     * @default false\r\n     */\r\n    lib?: LibraryOptions | false;\r\n    /**\r\n     * Produce SSR oriented build. Note this requires specifying SSR entry via\r\n     * `rollupOptions.input`.\r\n     * @default false\r\n     */\r\n    ssr?: boolean | string;\r\n    /**\r\n     * Generate SSR manifest for determining style links and asset preload\r\n     * directives in production.\r\n     * @default false\r\n     */\r\n    ssrManifest?: boolean | string;\r\n    /**\r\n     * Emit assets during SSR.\r\n     * @experimental\r\n     * @default false\r\n     */\r\n    ssrEmitAssets?: boolean;\r\n    /**\r\n     * Set to false to disable reporting compressed chunk sizes.\r\n     * Can slightly improve build speed.\r\n     * @default true\r\n     */\r\n    reportCompressedSize?: boolean;\r\n    /**\r\n     * Adjust chunk size warning limit (in kbs).\r\n     * @default 500\r\n     */\r\n    chunkSizeWarningLimit?: number;\r\n    /**\r\n     * Rollup watch options\r\n     * https://rollupjs.org/configuration-options/#watch\r\n     * @default null\r\n     */\r\n    watch?: WatcherOptions | null;\r\n}\r\n\r\nexport { ChunkMetadata }\r\n\r\nexport declare interface CommonServerOptions {\r\n    /**\r\n     * Specify server port. Note if the port is already being used, Vite will\r\n     * automatically try the next available port so this may not be the actual\r\n     * port the server ends up listening on.\r\n     */\r\n    port?: number;\r\n    /**\r\n     * If enabled, vite will exit if specified port is already in use\r\n     */\r\n    strictPort?: boolean;\r\n    /**\r\n     * Specify which IP addresses the server should listen on.\r\n     * Set to 0.0.0.0 to listen on all addresses, including LAN and public addresses.\r\n     */\r\n    host?: string | boolean;\r\n    /**\r\n     * Enable TLS + HTTP/2.\r\n     * Note: this downgrades to TLS only when the proxy option is also used.\r\n     */\r\n    https?: boolean | ServerOptions_2;\r\n    /**\r\n     * Open browser window on startup\r\n     */\r\n    open?: boolean | string;\r\n    /**\r\n     * Configure custom proxy rules for the dev server. Expects an object\r\n     * of `{ key: options }` pairs.\r\n     * Uses [`http-proxy`](https://github.com/http-party/node-http-proxy).\r\n     * Full options [here](https://github.com/http-party/node-http-proxy#options).\r\n     *\r\n     * Example `vite.config.js`:\r\n     * ``` js\r\n     * module.exports = {\r\n     *   proxy: {\r\n     *     // string shorthand\r\n     *     '/foo': 'http://localhost:4567/foo',\r\n     *     // with options\r\n     *     '/api': {\r\n     *       target: 'http://jsonplaceholder.typicode.com',\r\n     *       changeOrigin: true,\r\n     *       rewrite: path => path.replace(/^\\/api/, '')\r\n     *     }\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    proxy?: Record<string, string | ProxyOptions>;\r\n    /**\r\n     * Configure CORS for the dev server.\r\n     * Uses https://github.com/expressjs/cors.\r\n     * Set to `true` to allow all methods from any origin, or configure separately\r\n     * using an object.\r\n     */\r\n    cors?: CorsOptions | boolean;\r\n    /**\r\n     * Specify server response headers.\r\n     */\r\n    headers?: OutgoingHttpHeaders;\r\n}\r\n\r\nexport declare interface ConfigEnv {\r\n    command: 'build' | 'serve';\r\n    mode: string;\r\n    /**\r\n     * @experimental\r\n     */\r\n    ssrBuild?: boolean;\r\n}\r\n\r\nexport declare namespace Connect {\r\n    export type ServerHandle = HandleFunction | http.Server\r\n\r\n    export class IncomingMessage extends http.IncomingMessage {\r\n        originalUrl?: http.IncomingMessage['url'] | undefined\r\n    }\r\n\r\n    export type NextFunction = (err?: any) => void\r\n\r\n    export type SimpleHandleFunction = (\r\n    req: IncomingMessage,\r\n    res: http.ServerResponse,\r\n    ) => void\r\n    export type NextHandleFunction = (\r\n    req: IncomingMessage,\r\n    res: http.ServerResponse,\r\n    next: NextFunction,\r\n    ) => void\r\n    export type ErrorHandleFunction = (\r\n    err: any,\r\n    req: IncomingMessage,\r\n    res: http.ServerResponse,\r\n    next: NextFunction,\r\n    ) => void\r\n    export type HandleFunction =\r\n    | SimpleHandleFunction\r\n    | NextHandleFunction\r\n    | ErrorHandleFunction\r\n\r\n    export interface ServerStackItem {\r\n        route: string\r\n        handle: ServerHandle\r\n    }\r\n\r\n    export interface Server extends NodeJS.EventEmitter {\r\n        (req: http.IncomingMessage, res: http.ServerResponse, next?: Function): void\r\n\r\n        route: string\r\n        stack: ServerStackItem[]\r\n\r\n        /**\r\n         * Utilize the given middleware `handle` to the given `route`,\r\n         * defaulting to _/_. This \"route\" is the mount-point for the\r\n         * middleware, when given a value other than _/_ the middleware\r\n         * is only effective when that segment is present in the request's\r\n         * pathname.\r\n         *\r\n         * For example if we were to mount a function at _/admin_, it would\r\n         * be invoked on _/admin_, and _/admin/settings_, however it would\r\n         * not be invoked for _/_, or _/posts_.\r\n         */\r\n        use(fn: NextHandleFunction): Server\r\n        use(fn: HandleFunction): Server\r\n        use(route: string, fn: NextHandleFunction): Server\r\n        use(route: string, fn: HandleFunction): Server\r\n\r\n        /**\r\n         * Handle server requests, punting them down\r\n         * the middleware stack.\r\n         */\r\n        handle(\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        next: Function,\r\n        ): void\r\n\r\n        /**\r\n         * Listen for connections.\r\n         *\r\n         * This method takes the same arguments\r\n         * as node's `http.Server#listen()`.\r\n         *\r\n         * HTTP and HTTPS:\r\n         *\r\n         * If you run your application both as HTTP\r\n         * and HTTPS you may wrap them individually,\r\n         * since your Connect \"server\" is really just\r\n         * a JavaScript `Function`.\r\n         *\r\n         *      var connect = require('connect')\r\n         *        , http = require('http')\r\n         *        , https = require('https');\r\n         *\r\n         *      var app = connect();\r\n         *\r\n         *      http.createServer(app).listen(80);\r\n         *      https.createServer(options, app).listen(443);\r\n         */\r\n        listen(\r\n        port: number,\r\n        hostname?: string,\r\n        backlog?: number,\r\n        callback?: Function,\r\n        ): http.Server\r\n        listen(port: number, hostname?: string, callback?: Function): http.Server\r\n        listen(path: string, callback?: Function): http.Server\r\n        listen(handle: any, listeningListener?: Function): http.Server\r\n    }\r\n}\r\n\r\nexport { ConnectedPayload }\r\n\r\n/**\r\n * https://github.com/expressjs/cors#configuration-options\r\n */\r\nexport declare interface CorsOptions {\r\n    origin?: CorsOrigin | ((origin: string, cb: (err: Error, origins: CorsOrigin) => void) => void);\r\n    methods?: string | string[];\r\n    allowedHeaders?: string | string[];\r\n    exposedHeaders?: string | string[];\r\n    credentials?: boolean;\r\n    maxAge?: number;\r\n    preflightContinue?: boolean;\r\n    optionsSuccessStatus?: number;\r\n}\r\n\r\nexport declare type CorsOrigin = boolean | string | RegExp | (string | RegExp)[];\r\n\r\nexport declare const createFilter: (include?: FilterPattern, exclude?: FilterPattern, options?: {\r\n    resolve?: string | false | null;\r\n}) => (id: string | unknown) => boolean;\r\n\r\nexport declare function createLogger(level?: LogLevel, options?: LoggerOptions): Logger;\r\n\r\nexport declare function createServer(inlineConfig?: InlineConfig): Promise<ViteDevServer>;\r\n\r\nexport declare interface CSSModulesOptions {\r\n    getJSON?: (cssFileName: string, json: Record<string, string>, outputFileName: string) => void;\r\n    scopeBehaviour?: 'global' | 'local';\r\n    globalModulePaths?: RegExp[];\r\n    generateScopedName?: string | ((name: string, filename: string, css: string) => string);\r\n    hashPrefix?: string;\r\n    /**\r\n     * default: undefined\r\n     */\r\n    localsConvention?: 'camelCase' | 'camelCaseOnly' | 'dashes' | 'dashesOnly' | ((originalClassName: string, generatedClassName: string, inputFile: string) => string);\r\n}\r\n\r\nexport declare interface CSSOptions {\r\n    /**\r\n     * https://github.com/css-modules/postcss-modules\r\n     */\r\n    modules?: CSSModulesOptions | false;\r\n    preprocessorOptions?: Record<string, any>;\r\n    postcss?: string | (PostCSS.ProcessOptions & {\r\n        plugins?: PostCSS.AcceptedPlugin[];\r\n    });\r\n    /**\r\n     * Enables css sourcemaps during dev\r\n     * @default false\r\n     * @experimental\r\n     */\r\n    devSourcemap?: boolean;\r\n}\r\n\r\nexport { CustomEventMap }\r\n\r\nexport { CustomPayload }\r\n\r\n/**\r\n * Type helper to make it easier to use vite.config.ts\r\n * accepts a direct {@link UserConfig} object, or a function that returns it.\r\n * The function receives a {@link ConfigEnv} object that exposes two properties:\r\n * `command` (either `'build'` or `'serve'`), and `mode`.\r\n */\r\nexport declare function defineConfig(config: UserConfigExport): UserConfigExport;\r\n\r\nexport declare interface DepOptimizationConfig {\r\n    /**\r\n     * Force optimize listed dependencies (must be resolvable import paths,\r\n     * cannot be globs).\r\n     */\r\n    include?: string[];\r\n    /**\r\n     * Do not optimize these dependencies (must be resolvable import paths,\r\n     * cannot be globs).\r\n     */\r\n    exclude?: string[];\r\n    /**\r\n     * Force ESM interop when importing for these dependencies. Some legacy\r\n     * packages advertise themselves as ESM but use `require` internally\r\n     * @experimental\r\n     */\r\n    needsInterop?: string[];\r\n    /**\r\n     * Options to pass to esbuild during the dep scanning and optimization\r\n     *\r\n     * Certain options are omitted since changing them would not be compatible\r\n     * with Vite's dep optimization.\r\n     *\r\n     * - `external` is also omitted, use Vite's `optimizeDeps.exclude` option\r\n     * - `plugins` are merged with Vite's dep plugin\r\n     *\r\n     * https://esbuild.github.io/api\r\n     */\r\n    esbuildOptions?: Omit<BuildOptions_2, 'bundle' | 'entryPoints' | 'external' | 'write' | 'watch' | 'outdir' | 'outfile' | 'outbase' | 'outExtension' | 'metafile'>;\r\n    /**\r\n     * List of file extensions that can be optimized. A corresponding esbuild\r\n     * plugin must exist to handle the specific extension.\r\n     *\r\n     * By default, Vite can optimize `.mjs`, `.js`, `.ts`, and `.mts` files. This option\r\n     * allows specifying additional extensions.\r\n     *\r\n     * @experimental\r\n     */\r\n    extensions?: string[];\r\n    /**\r\n     * Disables dependencies optimizations, true disables the optimizer during\r\n     * build and dev. Pass 'build' or 'dev' to only disable the optimizer in\r\n     * one of the modes. Deps optimization is enabled by default in dev only.\r\n     * @default 'build'\r\n     * @experimental\r\n     */\r\n    disabled?: boolean | 'build' | 'dev';\r\n}\r\n\r\nexport declare interface DepOptimizationMetadata {\r\n    /**\r\n     * The main hash is determined by user config and dependency lockfiles.\r\n     * This is checked on server startup to avoid unnecessary re-bundles.\r\n     */\r\n    hash: string;\r\n    /**\r\n     * The browser hash is determined by the main hash plus additional dependencies\r\n     * discovered at runtime. This is used to invalidate browser requests to\r\n     * optimized deps.\r\n     */\r\n    browserHash: string;\r\n    /**\r\n     * Metadata for each already optimized dependency\r\n     */\r\n    optimized: Record<string, OptimizedDepInfo>;\r\n    /**\r\n     * Metadata for non-entry optimized chunks and dynamic imports\r\n     */\r\n    chunks: Record<string, OptimizedDepInfo>;\r\n    /**\r\n     * Metadata for each newly discovered dependency after processing\r\n     */\r\n    discovered: Record<string, OptimizedDepInfo>;\r\n    /**\r\n     * OptimizedDepInfo list\r\n     */\r\n    depInfoList: OptimizedDepInfo[];\r\n}\r\n\r\nexport declare type DepOptimizationOptions = DepOptimizationConfig & {\r\n    /**\r\n     * By default, Vite will crawl your `index.html` to detect dependencies that\r\n     * need to be pre-bundled. If `build.rollupOptions.input` is specified, Vite\r\n     * will crawl those entry points instead.\r\n     *\r\n     * If neither of these fit your needs, you can specify custom entries using\r\n     * this option - the value should be a fast-glob pattern or array of patterns\r\n     * (https://github.com/mrmlnc/fast-glob#basic-syntax) that are relative from\r\n     * vite project root. This will overwrite default entries inference.\r\n     */\r\n    entries?: string | string[];\r\n    /**\r\n     * Force dep pre-optimization regardless of whether deps have changed.\r\n     * @experimental\r\n     */\r\n    force?: boolean;\r\n};\r\n\r\nexport declare interface DepOptimizationProcessing {\r\n    promise: Promise<void>;\r\n    resolve: () => void;\r\n}\r\n\r\nexport declare interface DepOptimizationResult {\r\n    metadata: DepOptimizationMetadata;\r\n    /**\r\n     * When doing a re-run, if there are newly discovered dependencies\r\n     * the page reload will be delayed until the next rerun so we need\r\n     * to be able to discard the result\r\n     */\r\n    commit: () => Promise<void>;\r\n    cancel: () => void;\r\n}\r\n\r\nexport declare interface DepsOptimizer {\r\n    metadata: DepOptimizationMetadata;\r\n    scanProcessing?: Promise<void>;\r\n    registerMissingImport: (id: string, resolved: string) => OptimizedDepInfo;\r\n    run: () => void;\r\n    isOptimizedDepFile: (id: string) => boolean;\r\n    isOptimizedDepUrl: (url: string) => boolean;\r\n    getOptimizedDepId: (depInfo: OptimizedDepInfo) => string;\r\n    delayDepsOptimizerUntil: (id: string, done: () => Promise<any>) => void;\r\n    registerWorkersSource: (id: string) => void;\r\n    resetRegisteredIds: () => void;\r\n    ensureFirstRun: () => void;\r\n    close: () => Promise<void>;\r\n    options: DepOptimizationOptions;\r\n}\r\n\r\nexport { ErrorPayload }\r\n\r\nexport declare interface ESBuildOptions extends EsbuildTransformOptions {\r\n    include?: string | RegExp | string[] | RegExp[];\r\n    exclude?: string | RegExp | string[] | RegExp[];\r\n    jsxInject?: string;\r\n    /**\r\n     * This option is not respected. Use `build.minify` instead.\r\n     */\r\n    minify?: never;\r\n}\r\n\r\nexport { EsbuildTransformOptions }\r\n\r\nexport declare type ESBuildTransformResult = Omit<TransformResult_3, 'map'> & {\r\n    map: SourceMap;\r\n};\r\n\r\nexport { esbuildVersion }\r\n\r\nexport declare interface ExperimentalOptions {\r\n    /**\r\n     * Append fake `&lang.(ext)` when queries are specified, to preserve the file extension for following plugins to process.\r\n     *\r\n     * @experimental\r\n     * @default false\r\n     */\r\n    importGlobRestoreExtension?: boolean;\r\n    /**\r\n     * Allow finegrain control over assets and public files paths\r\n     *\r\n     * @experimental\r\n     */\r\n    renderBuiltUrl?: RenderBuiltAssetUrl;\r\n    /**\r\n     * Enables support of HMR partial accept via `import.meta.hot.acceptExports`.\r\n     *\r\n     * @experimental\r\n     * @default false\r\n     */\r\n    hmrPartialAccept?: boolean;\r\n    /**\r\n     * Skips SSR transform to make it easier to use Vite with Node ESM loaders.\r\n     * @warning Enabling this will break normal operation of Vite's SSR in development mode.\r\n     *\r\n     * @experimental\r\n     * @default false\r\n     */\r\n    skipSsrTransform?: boolean;\r\n}\r\n\r\nexport declare type ExportsData = {\r\n    hasImports: boolean;\r\n    exports: readonly string[];\r\n    facade: boolean;\r\n    hasReExports?: boolean;\r\n    jsxLoader?: boolean;\r\n};\r\n\r\nexport declare interface FileSystemServeOptions {\r\n    /**\r\n     * Strictly restrict file accessing outside of allowing paths.\r\n     *\r\n     * Set to `false` to disable the warning\r\n     *\r\n     * @default true\r\n     */\r\n    strict?: boolean;\r\n    /**\r\n     * Restrict accessing files outside the allowed directories.\r\n     *\r\n     * Accepts absolute path or a path relative to project root.\r\n     * Will try to search up for workspace root by default.\r\n     */\r\n    allow?: string[];\r\n    /**\r\n     * Restrict accessing files that matches the patterns.\r\n     *\r\n     * This will have higher priority than `allow`.\r\n     * picomatch patterns are supported.\r\n     *\r\n     * @default ['.env', '.env.*', '*.crt', '*.pem']\r\n     */\r\n    deny?: string[];\r\n}\r\n\r\n/**\r\n * Inlined to keep `@rollup/pluginutils` in devDependencies\r\n */\r\nexport declare type FilterPattern = ReadonlyArray<string | RegExp> | string | RegExp | null;\r\n\r\nexport declare function formatPostcssSourceMap(rawMap: ExistingRawSourceMap, file: string): Promise<ExistingRawSourceMap>;\r\n\r\nexport declare class FSWatcher extends EventEmitter implements fs.FSWatcher {\r\n    options: WatchOptions\r\n\r\n    /**\r\n     * Constructs a new FSWatcher instance with optional WatchOptions parameter.\r\n     */\r\n    constructor(options?: WatchOptions)\r\n\r\n    /**\r\n     * Add files, directories, or glob patterns for tracking. Takes an array of strings or just one\r\n     * string.\r\n     */\r\n    add(paths: string | ReadonlyArray<string>): this\r\n\r\n    /**\r\n     * Stop watching files, directories, or glob patterns. Takes an array of strings or just one\r\n     * string.\r\n     */\r\n    unwatch(paths: string | ReadonlyArray<string>): this\r\n\r\n    /**\r\n     * Returns an object representing all the paths on the file system being watched by this\r\n     * `FSWatcher` instance. The object's keys are all the directories (using absolute paths unless\r\n     * the `cwd` option was used), and the values are arrays of the names of the items contained in\r\n     * each directory.\r\n     */\r\n    getWatched(): {\r\n        [directory: string]: string[]\r\n    }\r\n\r\n    /**\r\n     * Removes all listeners from watched files.\r\n     */\r\n    close(): Promise<void>\r\n\r\n    on(\r\n    event: 'add' | 'addDir' | 'change',\r\n    listener: (path: string, stats?: fs.Stats) => void,\r\n    ): this\r\n\r\n    on(\r\n    event: 'all',\r\n    listener: (\r\n    eventName: 'add' | 'addDir' | 'change' | 'unlink' | 'unlinkDir',\r\n    path: string,\r\n    stats?: fs.Stats,\r\n    ) => void,\r\n    ): this\r\n\r\n    /**\r\n     * Error occurred\r\n     */\r\n    on(event: 'error', listener: (error: Error) => void): this\r\n\r\n    /**\r\n     * Exposes the native Node `fs.FSWatcher events`\r\n     */\r\n    on(\r\n    event: 'raw',\r\n    listener: (eventName: string, path: string, details: any) => void,\r\n    ): this\r\n\r\n    /**\r\n     * Fires when the initial scan is complete\r\n     */\r\n    on(event: 'ready', listener: () => void): this\r\n\r\n    on(event: 'unlink' | 'unlinkDir', listener: (path: string) => void): this\r\n\r\n    on(event: string, listener: (...args: any[]) => void): this\r\n}\r\n\r\nexport { FullReloadPayload }\r\n\r\nexport { GeneralImportGlobOptions }\r\n\r\nexport declare function getDepOptimizationConfig(config: ResolvedConfig, ssr: boolean): DepOptimizationConfig;\r\n\r\nexport declare interface HmrContext {\r\n    file: string;\r\n    timestamp: number;\r\n    modules: Array<ModuleNode>;\r\n    read: () => string | Promise<string>;\r\n    server: ViteDevServer;\r\n}\r\n\r\nexport declare interface HmrOptions {\r\n    protocol?: string;\r\n    host?: string;\r\n    port?: number;\r\n    clientPort?: number;\r\n    path?: string;\r\n    timeout?: number;\r\n    overlay?: boolean;\r\n    server?: Server;\r\n}\r\n\r\nexport { HMRPayload }\r\n\r\nexport declare type HookHandler<T> = T extends ObjectHook<infer H> ? H : T;\r\n\r\nexport declare interface HtmlTagDescriptor {\r\n    tag: string;\r\n    attrs?: Record<string, string | boolean | undefined>;\r\n    children?: string | HtmlTagDescriptor[];\r\n    /**\r\n     * default: 'head-prepend'\r\n     */\r\n    injectTo?: 'head' | 'body' | 'head-prepend' | 'body-prepend';\r\n}\r\n\r\nexport declare namespace HttpProxy {\r\n    export type ProxyTarget = ProxyTargetUrl | ProxyTargetDetailed\r\n\r\n    export type ProxyTargetUrl = string | Partial<url.Url>\r\n\r\n    export interface ProxyTargetDetailed {\r\n        host: string\r\n        port: number\r\n        protocol?: string | undefined\r\n        hostname?: string | undefined\r\n        socketPath?: string | undefined\r\n        key?: string | undefined\r\n        passphrase?: string | undefined\r\n        pfx?: Buffer | string | undefined\r\n        cert?: string | undefined\r\n        ca?: string | undefined\r\n        ciphers?: string | undefined\r\n        secureProtocol?: string | undefined\r\n    }\r\n\r\n    export type ErrorCallback = (\r\n    err: Error,\r\n    req: http.IncomingMessage,\r\n    res: http.ServerResponse,\r\n    target?: ProxyTargetUrl,\r\n    ) => void\r\n\r\n    export class Server extends events.EventEmitter {\r\n        /**\r\n         * Creates the proxy server with specified options.\r\n         * @param options - Config object passed to the proxy\r\n         */\r\n        constructor(options?: ServerOptions)\r\n\r\n        /**\r\n         * Used for proxying regular HTTP(S) requests\r\n         * @param req - Client request.\r\n         * @param res - Client response.\r\n         * @param options - Additional options.\r\n         */\r\n        web(\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        options?: ServerOptions,\r\n        callback?: ErrorCallback,\r\n        ): void\r\n\r\n        /**\r\n         * Used for proxying regular HTTP(S) requests\r\n         * @param req - Client request.\r\n         * @param socket - Client socket.\r\n         * @param head - Client head.\r\n         * @param options - Additional options.\r\n         */\r\n        ws(\r\n        req: http.IncomingMessage,\r\n        socket: unknown,\r\n        head: unknown,\r\n        options?: ServerOptions,\r\n        callback?: ErrorCallback,\r\n        ): void\r\n\r\n        /**\r\n         * A function that wraps the object in a webserver, for your convenience\r\n         * @param port - Port to listen on\r\n         */\r\n        listen(port: number): Server\r\n\r\n        /**\r\n         * A function that closes the inner webserver and stops listening on given port\r\n         */\r\n        close(callback?: () => void): void\r\n\r\n        /**\r\n         * Creates the proxy server with specified options.\r\n         * @param options - Config object passed to the proxy\r\n         * @returns Proxy object with handlers for `ws` and `web` requests\r\n         */\r\n        static createProxyServer(options?: ServerOptions): Server\r\n\r\n        /**\r\n         * Creates the proxy server with specified options.\r\n         * @param options - Config object passed to the proxy\r\n         * @returns Proxy object with handlers for `ws` and `web` requests\r\n         */\r\n        static createServer(options?: ServerOptions): Server\r\n\r\n        /**\r\n         * Creates the proxy server with specified options.\r\n         * @param options - Config object passed to the proxy\r\n         * @returns Proxy object with handlers for `ws` and `web` requests\r\n         */\r\n        static createProxy(options?: ServerOptions): Server\r\n\r\n        addListener(event: string, listener: () => void): this\r\n        on(event: string, listener: () => void): this\r\n        on(event: 'error', listener: ErrorCallback): this\r\n        on(\r\n        event: 'start',\r\n        listener: (\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        target: ProxyTargetUrl,\r\n        ) => void,\r\n        ): this\r\n        on(\r\n        event: 'proxyReq',\r\n        listener: (\r\n        proxyReq: http.ClientRequest,\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        options: ServerOptions,\r\n        ) => void,\r\n        ): this\r\n        on(\r\n        event: 'proxyRes',\r\n        listener: (\r\n        proxyRes: http.IncomingMessage,\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        ) => void,\r\n        ): this\r\n        on(\r\n        event: 'proxyReqWs',\r\n        listener: (\r\n        proxyReq: http.ClientRequest,\r\n        req: http.IncomingMessage,\r\n        socket: net.Socket,\r\n        options: ServerOptions,\r\n        head: any,\r\n        ) => void,\r\n        ): this\r\n        on(\r\n        event: 'econnreset',\r\n        listener: (\r\n        err: Error,\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        target: ProxyTargetUrl,\r\n        ) => void,\r\n        ): this\r\n        on(\r\n        event: 'end',\r\n        listener: (\r\n        req: http.IncomingMessage,\r\n        res: http.ServerResponse,\r\n        proxyRes: http.IncomingMessage,\r\n        ) => void,\r\n        ): this\r\n        on(\r\n        event: 'close',\r\n        listener: (\r\n        proxyRes: http.IncomingMessage,\r\n        proxySocket: net.Socket,\r\n        proxyHead: any,\r\n        ) => void,\r\n        ): this\r\n\r\n        once(event: string, listener: () => void): this\r\n        removeListener(event: string, listener: () => void): this\r\n        removeAllListeners(event?: string): this\r\n        getMaxListeners(): number\r\n        setMaxListeners(n: number): this\r\n        listeners(event: string): Array<() => void>\r\n        emit(event: string, ...args: any[]): boolean\r\n        listenerCount(type: string): number\r\n    }\r\n\r\n    export interface ServerOptions {\r\n        /** URL string to be parsed with the url module. */\r\n        target?: ProxyTarget | undefined\r\n        /** URL string to be parsed with the url module. */\r\n        forward?: ProxyTargetUrl | undefined\r\n        /** Object to be passed to http(s).request. */\r\n        agent?: any\r\n        /** Object to be passed to https.createServer(). */\r\n        ssl?: any\r\n        /** If you want to proxy websockets. */\r\n        ws?: boolean | undefined\r\n        /** Adds x- forward headers. */\r\n        xfwd?: boolean | undefined\r\n        /** Verify SSL certificate. */\r\n        secure?: boolean | undefined\r\n        /** Explicitly specify if we are proxying to another proxy. */\r\n        toProxy?: boolean | undefined\r\n        /** Specify whether you want to prepend the target's path to the proxy path. */\r\n        prependPath?: boolean | undefined\r\n        /** Specify whether you want to ignore the proxy path of the incoming request. */\r\n        ignorePath?: boolean | undefined\r\n        /** Local interface string to bind for outgoing connections. */\r\n        localAddress?: string | undefined\r\n        /** Changes the origin of the host header to the target URL. */\r\n        changeOrigin?: boolean | undefined\r\n        /** specify whether you want to keep letter case of response header key */\r\n        preserveHeaderKeyCase?: boolean | undefined\r\n        /** Basic authentication i.e. 'user:password' to compute an Authorization header. */\r\n        auth?: string | undefined\r\n        /** Rewrites the location hostname on (301 / 302 / 307 / 308) redirects, Default: null. */\r\n        hostRewrite?: string | undefined\r\n        /** Rewrites the location host/ port on (301 / 302 / 307 / 308) redirects based on requested host/ port.Default: false. */\r\n        autoRewrite?: boolean | undefined\r\n        /** Rewrites the location protocol on (301 / 302 / 307 / 308) redirects to 'http' or 'https'.Default: null. */\r\n        protocolRewrite?: string | undefined\r\n        /** rewrites domain of set-cookie headers. */\r\n        cookieDomainRewrite?:\r\n        | false\r\n        | string\r\n        | { [oldDomain: string]: string }\r\n        | undefined\r\n        /** rewrites path of set-cookie headers. Default: false */\r\n        cookiePathRewrite?:\r\n        | false\r\n        | string\r\n        | { [oldPath: string]: string }\r\n        | undefined\r\n        /** object with extra headers to be added to target requests. */\r\n        headers?: { [header: string]: string } | undefined\r\n        /** Timeout (in milliseconds) when proxy receives no response from target. Default: 120000 (2 minutes) */\r\n        proxyTimeout?: number | undefined\r\n        /** Timeout (in milliseconds) for incoming requests */\r\n        timeout?: number | undefined\r\n        /** Specify whether you want to follow redirects. Default: false */\r\n        followRedirects?: boolean | undefined\r\n        /** If set to true, none of the webOutgoing passes are called and it's your responsibility to appropriately return the response by listening and acting on the proxyRes event */\r\n        selfHandleResponse?: boolean | undefined\r\n        /** Buffer */\r\n        buffer?: stream.Stream | undefined\r\n    }\r\n}\r\n\r\nexport { ImportGlobEagerFunction }\r\n\r\nexport { ImportGlobFunction }\r\n\r\nexport { ImportGlobOptions }\r\n\r\nexport declare type IndexHtmlTransform = IndexHtmlTransformHook | {\r\n    order?: 'pre' | 'post' | null;\r\n    /**\r\n     * @deprecated renamed to `order`\r\n     */\r\n    enforce?: 'pre' | 'post';\r\n    /**\r\n     * @deprecated renamed to `handler`\r\n     */\r\n    transform: IndexHtmlTransformHook;\r\n} | {\r\n    order?: 'pre' | 'post' | null;\r\n    /**\r\n     * @deprecated renamed to `order`\r\n     */\r\n    enforce?: 'pre' | 'post';\r\n    handler: IndexHtmlTransformHook;\r\n};\r\n\r\nexport declare interface IndexHtmlTransformContext {\r\n    /**\r\n     * public path when served\r\n     */\r\n    path: string;\r\n    /**\r\n     * filename on disk\r\n     */\r\n    filename: string;\r\n    server?: ViteDevServer;\r\n    bundle?: OutputBundle;\r\n    chunk?: OutputChunk;\r\n    originalUrl?: string;\r\n}\r\n\r\nexport declare type IndexHtmlTransformHook = (this: void, html: string, ctx: IndexHtmlTransformContext) => IndexHtmlTransformResult | void | Promise<IndexHtmlTransformResult | void>;\r\n\r\nexport declare type IndexHtmlTransformResult = string | HtmlTagDescriptor[] | {\r\n    html: string;\r\n    tags: HtmlTagDescriptor[];\r\n};\r\n\r\nexport { InferCustomEventPayload }\r\n\r\nexport declare interface InlineConfig extends UserConfig {\r\n    configFile?: string | false;\r\n    envFile?: false;\r\n}\r\n\r\nexport declare interface InternalResolveOptions extends Required<ResolveOptions> {\r\n    root: string;\r\n    isBuild: boolean;\r\n    isProduction: boolean;\r\n    ssrConfig?: SSROptions;\r\n    packageCache?: PackageCache;\r\n    /**\r\n     * src code mode also attempts the following:\r\n     * - resolving /xxx as URLs\r\n     * - resolving bare imports from optimized deps\r\n     */\r\n    asSrc?: boolean;\r\n    tryIndex?: boolean;\r\n    tryPrefix?: string;\r\n    skipPackageJson?: boolean;\r\n    preferRelative?: boolean;\r\n    isRequire?: boolean;\r\n    isFromTsImporter?: boolean;\r\n    tryEsmOnly?: boolean;\r\n    scan?: boolean;\r\n    ssrOptimizeCheck?: boolean;\r\n    getDepsOptimizer?: (ssr: boolean) => DepsOptimizer | undefined;\r\n    shouldExternalize?: (id: string) => boolean | undefined;\r\n}\r\n\r\nexport { InvalidatePayload }\r\n\r\nexport declare const isCSSRequest: (request: string) => boolean;\r\n\r\nexport declare function isDepsOptimizerEnabled(config: ResolvedConfig, ssr: boolean): boolean;\r\n\r\nexport declare interface JsonOptions {\r\n    /**\r\n     * Generate a named export for every property of the JSON object\r\n     * @default true\r\n     */\r\n    namedExports?: boolean;\r\n    /**\r\n     * Generate performant output as JSON.parse(\"stringified\").\r\n     * Enabling this will disable namedExports.\r\n     * @default false\r\n     */\r\n    stringify?: boolean;\r\n}\r\n\r\nexport { KnownAsTypeMap }\r\n\r\nexport declare interface LegacyOptions {\r\n    /**\r\n     * Revert vite build --ssr to the v2.9 strategy. Use CJS SSR build and v2.9 externalization heuristics\r\n     *\r\n     * @experimental\r\n     * @deprecated\r\n     * @default false\r\n     */\r\n    buildSsrCjsExternalHeuristics?: boolean;\r\n}\r\n\r\nexport declare type LibraryFormats = 'es' | 'cjs' | 'umd' | 'iife';\r\n\r\nexport declare interface LibraryOptions {\r\n    /**\r\n     * Path of library entry\r\n     */\r\n    entry: InputOption;\r\n    /**\r\n     * The name of the exposed global variable. Required when the `formats` option includes\r\n     * `umd` or `iife`\r\n     */\r\n    name?: string;\r\n    /**\r\n     * Output bundle formats\r\n     * @default ['es', 'umd']\r\n     */\r\n    formats?: LibraryFormats[];\r\n    /**\r\n     * The name of the package file output. The default file name is the name option\r\n     * of the project package.json. It can also be defined as a function taking the\r\n     * format as an argument.\r\n     */\r\n    fileName?: string | ((format: ModuleFormat, entryName: string) => string);\r\n}\r\n\r\nexport declare function loadConfigFromFile(configEnv: ConfigEnv, configFile?: string, configRoot?: string, logLevel?: LogLevel): Promise<{\r\n    path: string;\r\n    config: UserConfig;\r\n    dependencies: string[];\r\n} | null>;\r\n\r\nexport declare function loadEnv(mode: string, envDir: string, prefixes?: string | string[]): Record<string, string>;\r\n\r\nexport declare interface LogErrorOptions extends LogOptions {\r\n    error?: Error | RollupError | null;\r\n}\r\n\r\nexport declare interface Logger {\r\n    info(msg: string, options?: LogOptions): void;\r\n    warn(msg: string, options?: LogOptions): void;\r\n    warnOnce(msg: string, options?: LogOptions): void;\r\n    error(msg: string, options?: LogErrorOptions): void;\r\n    clearScreen(type: LogType): void;\r\n    hasErrorLogged(error: Error | RollupError): boolean;\r\n    hasWarned: boolean;\r\n}\r\n\r\nexport declare interface LoggerOptions {\r\n    prefix?: string;\r\n    allowClearScreen?: boolean;\r\n    customLogger?: Logger;\r\n}\r\n\r\nexport declare type LogLevel = LogType | 'silent';\r\n\r\nexport declare interface LogOptions {\r\n    clear?: boolean;\r\n    timestamp?: boolean;\r\n}\r\n\r\nexport declare type LogType = 'error' | 'warn' | 'info';\r\n\r\nexport declare type Manifest = Record<string, ManifestChunk>;\r\n\r\nexport declare interface ManifestChunk {\r\n    src?: string;\r\n    file: string;\r\n    css?: string[];\r\n    assets?: string[];\r\n    isEntry?: boolean;\r\n    isDynamicEntry?: boolean;\r\n    imports?: string[];\r\n    dynamicImports?: string[];\r\n}\r\n\r\nexport declare type MapToFunction<T> = T extends Function ? T : never\r\n\r\nexport declare type Matcher = AnymatchPattern | AnymatchPattern[]\r\n\r\nexport declare function mergeAlias(a?: AliasOptions, b?: AliasOptions): AliasOptions | undefined;\r\n\r\nexport declare function mergeConfig(defaults: Record<string, any>, overrides: Record<string, any>, isRoot?: boolean): Record<string, any>;\r\n\r\nexport declare class ModuleGraph {\r\n    private resolveId;\r\n    urlToModuleMap: Map<string, ModuleNode>;\r\n    idToModuleMap: Map<string, ModuleNode>;\r\n    fileToModulesMap: Map<string, Set<ModuleNode>>;\r\n    safeModulesPath: Set<string>;\r\n    constructor(resolveId: (url: string, ssr: boolean) => Promise<PartialResolvedId | null>);\r\n    getModuleByUrl(rawUrl: string, ssr?: boolean): Promise<ModuleNode | undefined>;\r\n    getModuleById(id: string): ModuleNode | undefined;\r\n    getModulesByFile(file: string): Set<ModuleNode> | undefined;\r\n    onFileChange(file: string): void;\r\n    invalidateModule(mod: ModuleNode, seen?: Set<ModuleNode>, timestamp?: number, isHmr?: boolean): void;\r\n    invalidateAll(): void;\r\n    /**\r\n     * Update the module graph based on a module's updated imports information\r\n     * If there are dependencies that no longer have any importers, they are\r\n     * returned as a Set.\r\n     */\r\n    updateModuleInfo(mod: ModuleNode, importedModules: Set<string | ModuleNode>, importedBindings: Map<string, Set<string>> | null, acceptedModules: Set<string | ModuleNode>, acceptedExports: Set<string> | null, isSelfAccepting: boolean, ssr?: boolean): Promise<Set<ModuleNode> | undefined>;\r\n    ensureEntryFromUrl(rawUrl: string, ssr?: boolean, setIsSelfAccepting?: boolean): Promise<ModuleNode>;\r\n    createFileOnlyEntry(file: string): ModuleNode;\r\n    resolveUrl(url: string, ssr?: boolean): Promise<ResolvedUrl>;\r\n}\r\n\r\nexport declare class ModuleNode {\r\n    /**\r\n     * Public served url path, starts with /\r\n     */\r\n    url: string;\r\n    /**\r\n     * Resolved file system path + query\r\n     */\r\n    id: string | null;\r\n    file: string | null;\r\n    type: 'js' | 'css';\r\n    info?: ModuleInfo;\r\n    meta?: Record<string, any>;\r\n    importers: Set<ModuleNode>;\r\n    importedModules: Set<ModuleNode>;\r\n    acceptedHmrDeps: Set<ModuleNode>;\r\n    acceptedHmrExports: Set<string> | null;\r\n    importedBindings: Map<string, Set<string>> | null;\r\n    isSelfAccepting?: boolean;\r\n    transformResult: TransformResult | null;\r\n    ssrTransformResult: TransformResult | null;\r\n    ssrModule: Record<string, any> | null;\r\n    ssrError: Error | null;\r\n    lastHMRTimestamp: number;\r\n    lastInvalidationTimestamp: number;\r\n    /**\r\n     * @param setIsSelfAccepting - set `false` to set `isSelfAccepting` later. e.g. #7870\r\n     */\r\n    constructor(url: string, setIsSelfAccepting?: boolean);\r\n}\r\n\r\nexport declare interface ModulePreloadOptions {\r\n    /**\r\n     * Whether to inject a module preload polyfill.\r\n     * Note: does not apply to library mode.\r\n     * @default true\r\n     */\r\n    polyfill?: boolean;\r\n    /**\r\n     * Resolve the list of dependencies to preload for a given dynamic import\r\n     * @experimental\r\n     */\r\n    resolveDependencies?: ResolveModulePreloadDependenciesFn;\r\n}\r\n\r\nexport declare function normalizePath(id: string): string;\r\n\r\nexport declare interface OptimizedDepInfo {\r\n    id: string;\r\n    file: string;\r\n    src?: string;\r\n    needsInterop?: boolean;\r\n    browserHash?: string;\r\n    fileHash?: string;\r\n    /**\r\n     * During optimization, ids can still be resolved to their final location\r\n     * but the bundles may not yet be saved to disk\r\n     */\r\n    processing?: Promise<void>;\r\n    /**\r\n     * ExportData cache, discovered deps will parse the src entry to get exports\r\n     * data used both to define if interop is needed and when pre-bundling\r\n     */\r\n    exportsData?: Promise<ExportsData>;\r\n}\r\n\r\n/**\r\n * Scan and optimize dependencies within a project.\r\n * Used by Vite CLI when running `vite optimize`.\r\n */\r\nexport declare function optimizeDeps(config: ResolvedConfig, force?: boolean | undefined, asCommand?: boolean): Promise<DepOptimizationMetadata>;\r\n\r\n/** Cache for package.json resolution and package.json contents */\r\nexport declare type PackageCache = Map<string, PackageData>;\r\n\r\nexport declare interface PackageData {\r\n    dir: string;\r\n    hasSideEffects: (id: string) => boolean | 'no-treeshake';\r\n    webResolvedImports: Record<string, string | undefined>;\r\n    nodeResolvedImports: Record<string, string | undefined>;\r\n    setResolvedCache: (key: string, entry: string, targetWeb: boolean) => void;\r\n    getResolvedCache: (key: string, targetWeb: boolean) => string | undefined;\r\n    data: {\r\n        [field: string]: any;\r\n        name: string;\r\n        type: string;\r\n        version: string;\r\n        main: string;\r\n        module: string;\r\n        browser: string | Record<string, string | false>;\r\n        exports: string | Record<string, any> | string[];\r\n        dependencies: Record<string, string>;\r\n    };\r\n}\r\n\r\n/**\r\n * Vite plugins extends the Rollup plugin interface with a few extra\r\n * vite-specific options. A valid vite plugin is also a valid Rollup plugin.\r\n * On the contrary, a Rollup plugin may or may NOT be a valid vite universal\r\n * plugin, since some Rollup features do not make sense in an unbundled\r\n * dev server context. That said, as long as a rollup plugin doesn't have strong\r\n * coupling between its bundle phase and output phase hooks then it should\r\n * just work (that means, most of them).\r\n *\r\n * By default, the plugins are run during both serve and build. When a plugin\r\n * is applied during serve, it will only run **non output plugin hooks** (see\r\n * rollup type definition of {@link rollup#PluginHooks}). You can think of the\r\n * dev server as only running `const bundle = rollup.rollup()` but never calling\r\n * `bundle.generate()`.\r\n *\r\n * A plugin that expects to have different behavior depending on serve/build can\r\n * export a factory function that receives the command being run via options.\r\n *\r\n * If a plugin should be applied only for server or build, a function format\r\n * config file can be used to conditional determine the plugins to use.\r\n */\r\ndeclare interface Plugin_2 extends Plugin_3 {\r\n    /**\r\n     * Enforce plugin invocation tier similar to webpack loaders.\r\n     *\r\n     * Plugin invocation order:\r\n     * - alias resolution\r\n     * - `enforce: 'pre'` plugins\r\n     * - vite core plugins\r\n     * - normal plugins\r\n     * - vite build plugins\r\n     * - `enforce: 'post'` plugins\r\n     * - vite build post plugins\r\n     */\r\n    enforce?: 'pre' | 'post';\r\n    /**\r\n     * Apply the plugin only for serve or build, or on certain conditions.\r\n     */\r\n    apply?: 'serve' | 'build' | ((this: void, config: UserConfig, env: ConfigEnv) => boolean);\r\n    /**\r\n     * Modify vite config before it's resolved. The hook can either mutate the\r\n     * passed-in config directly, or return a partial config object that will be\r\n     * deeply merged into existing config.\r\n     *\r\n     * Note: User plugins are resolved before running this hook so injecting other\r\n     * plugins inside  the `config` hook will have no effect.\r\n     */\r\n    config?: ObjectHook<(this: void, config: UserConfig, env: ConfigEnv) => UserConfig | null | void | Promise<UserConfig | null | void>>;\r\n    /**\r\n     * Use this hook to read and store the final resolved vite config.\r\n     */\r\n    configResolved?: ObjectHook<(this: void, config: ResolvedConfig) => void | Promise<void>>;\r\n    /**\r\n     * Configure the vite server. The hook receives the {@link ViteDevServer}\r\n     * instance. This can also be used to store a reference to the server\r\n     * for use in other hooks.\r\n     *\r\n     * The hooks will be called before internal middlewares are applied. A hook\r\n     * can return a post hook that will be called after internal middlewares\r\n     * are applied. Hook can be async functions and will be called in series.\r\n     */\r\n    configureServer?: ObjectHook<ServerHook>;\r\n    /**\r\n     * Configure the preview server. The hook receives the connect server and\r\n     * its underlying http server.\r\n     *\r\n     * The hooks are called before other middlewares are applied. A hook can\r\n     * return a post hook that will be called after other middlewares are\r\n     * applied. Hooks can be async functions and will be called in series.\r\n     */\r\n    configurePreviewServer?: ObjectHook<PreviewServerHook>;\r\n    /**\r\n     * Transform index.html.\r\n     * The hook receives the following arguments:\r\n     *\r\n     * - html: string\r\n     * - ctx?: vite.ServerContext (only present during serve)\r\n     * - bundle?: rollup.OutputBundle (only present during build)\r\n     *\r\n     * It can either return a transformed string, or a list of html tag\r\n     * descriptors that will be injected into the `<head>` or `<body>`.\r\n     *\r\n     * By default the transform is applied **after** vite's internal html\r\n     * transform. If you need to apply the transform before vite, use an object:\r\n     * `{ order: 'pre', handler: hook }`\r\n     */\r\n    transformIndexHtml?: IndexHtmlTransform;\r\n    /**\r\n     * Perform custom handling of HMR updates.\r\n     * The handler receives a context containing changed filename, timestamp, a\r\n     * list of modules affected by the file change, and the dev server instance.\r\n     *\r\n     * - The hook can return a filtered list of modules to narrow down the update.\r\n     *   e.g. for a Vue SFC, we can narrow down the part to update by comparing\r\n     *   the descriptors.\r\n     *\r\n     * - The hook can also return an empty array and then perform custom updates\r\n     *   by sending a custom hmr payload via server.ws.send().\r\n     *\r\n     * - If the hook doesn't return a value, the hmr update will be performed as\r\n     *   normal.\r\n     */\r\n    handleHotUpdate?: ObjectHook<(this: void, ctx: HmrContext) => Array<ModuleNode> | void | Promise<Array<ModuleNode> | void>>;\r\n    /**\r\n     * extend hooks with ssr flag\r\n     */\r\n    resolveId?: ObjectHook<(this: PluginContext, source: string, importer: string | undefined, options: {\r\n        assertions: Record<string, string>;\r\n        custom?: CustomPluginOptions;\r\n        ssr?: boolean;\r\n        /* Excluded from this release type: scan */\r\n        isEntry: boolean;\r\n    }) => Promise<ResolveIdResult> | ResolveIdResult>;\r\n    load?: ObjectHook<(this: PluginContext, id: string, options?: {\r\n        ssr?: boolean;\r\n    }) => Promise<LoadResult> | LoadResult>;\r\n    transform?: ObjectHook<(this: TransformPluginContext, code: string, id: string, options?: {\r\n        ssr?: boolean;\r\n    }) => Promise<TransformResult_2> | TransformResult_2>;\r\n}\r\nexport { Plugin_2 as Plugin }\r\n\r\nexport declare interface PluginContainer {\r\n    options: InputOptions;\r\n    getModuleInfo(id: string): ModuleInfo | null;\r\n    buildStart(options: InputOptions): Promise<void>;\r\n    resolveId(id: string, importer?: string, options?: {\r\n        assertions?: Record<string, string>;\r\n        custom?: CustomPluginOptions;\r\n        skip?: Set<Plugin_2>;\r\n        ssr?: boolean;\r\n        /* Excluded from this release type: scan */\r\n        isEntry?: boolean;\r\n    }): Promise<PartialResolvedId | null>;\r\n    transform(code: string, id: string, options?: {\r\n        inMap?: SourceDescription['map'];\r\n        ssr?: boolean;\r\n    }): Promise<SourceDescription | null>;\r\n    load(id: string, options?: {\r\n        ssr?: boolean;\r\n    }): Promise<LoadResult | null>;\r\n    close(): Promise<void>;\r\n}\r\n\r\nexport declare interface PluginHookUtils {\r\n    getSortedPlugins: (hookName: keyof Plugin_2) => Plugin_2[];\r\n    getSortedPluginHooks: <K extends keyof Plugin_2>(hookName: K) => NonNullable<HookHandler<Plugin_2[K]>>[];\r\n}\r\n\r\nexport declare type PluginOption = Plugin_2 | false | null | undefined | PluginOption[] | Promise<Plugin_2 | false | null | undefined | PluginOption[]>;\r\n\r\n/**\r\n * @experimental\r\n */\r\nexport declare function preprocessCSS(code: string, filename: string, config: ResolvedConfig): Promise<PreprocessCSSResult>;\r\n\r\nexport declare interface PreprocessCSSResult {\r\n    code: string;\r\n    map?: SourceMapInput;\r\n    modules?: Record<string, string>;\r\n    deps?: Set<string>;\r\n}\r\n\r\n/**\r\n * Starts the Vite server in preview mode, to simulate a production deployment\r\n */\r\nexport declare function preview(inlineConfig?: InlineConfig): Promise<PreviewServer>;\r\n\r\nexport declare interface PreviewOptions extends CommonServerOptions {\r\n}\r\n\r\nexport declare interface PreviewServer {\r\n    /**\r\n     * The resolved vite config object\r\n     */\r\n    config: ResolvedConfig;\r\n    /**\r\n     * native Node http server instance\r\n     */\r\n    httpServer: http.Server;\r\n    /**\r\n     * The resolved urls Vite prints on the CLI\r\n     */\r\n    resolvedUrls: ResolvedServerUrls;\r\n    /**\r\n     * Print server urls\r\n     */\r\n    printUrls(): void;\r\n}\r\n\r\nexport declare type PreviewServerHook = (this: void, server: {\r\n    middlewares: Connect.Server;\r\n    httpServer: http.Server;\r\n}) => (() => void) | void | Promise<(() => void) | void>;\r\n\r\nexport declare interface ProxyOptions extends HttpProxy.ServerOptions {\r\n    /**\r\n     * rewrite path\r\n     */\r\n    rewrite?: (path: string) => string;\r\n    /**\r\n     * configure the proxy server (e.g. listen to events)\r\n     */\r\n    configure?: (proxy: HttpProxy.Server, options: ProxyOptions) => void;\r\n    /**\r\n     * webpack-dev-server style bypass function\r\n     */\r\n    bypass?: (req: http.IncomingMessage, res: http.ServerResponse, options: ProxyOptions) => void | null | undefined | false | string;\r\n}\r\n\r\nexport { PrunePayload }\r\n\r\nexport declare type RenderBuiltAssetUrl = (filename: string, type: {\r\n    type: 'asset' | 'public';\r\n    hostId: string;\r\n    hostType: 'js' | 'css' | 'html';\r\n    ssr: boolean;\r\n}) => string | {\r\n    relative?: boolean;\r\n    runtime?: string;\r\n} | undefined;\r\n\r\n/**\r\n * Resolve base url. Note that some users use Vite to build for non-web targets like\r\n * electron or expects to deploy\r\n */\r\nexport declare function resolveBaseUrl(base: string | undefined, isBuild: boolean, logger: Logger): string;\r\n\r\nexport declare function resolveConfig(inlineConfig: InlineConfig, command: 'build' | 'serve', defaultMode?: string, defaultNodeEnv?: string): Promise<ResolvedConfig>;\r\n\r\nexport declare interface ResolvedBuildOptions extends Required<Omit<BuildOptions, 'polyfillModulePreload'>> {\r\n    modulePreload: false | ResolvedModulePreloadOptions;\r\n}\r\n\r\nexport declare type ResolvedConfig = Readonly<Omit<UserConfig, 'plugins' | 'assetsInclude' | 'optimizeDeps' | 'worker'> & {\r\n    configFile: string | undefined;\r\n    configFileDependencies: string[];\r\n    inlineConfig: InlineConfig;\r\n    root: string;\r\n    base: string;\r\n    /* Excluded from this release type: rawBase */\r\n    publicDir: string;\r\n    cacheDir: string;\r\n    command: 'build' | 'serve';\r\n    mode: string;\r\n    isWorker: boolean;\r\n    /* Excluded from this release type: mainConfig */\r\n    isProduction: boolean;\r\n    env: Record<string, any>;\r\n    resolve: Required<ResolveOptions> & {\r\n        alias: Alias[];\r\n    };\r\n    plugins: readonly Plugin_2[];\r\n    server: ResolvedServerOptions;\r\n    build: ResolvedBuildOptions;\r\n    preview: ResolvedPreviewOptions;\r\n    ssr: ResolvedSSROptions;\r\n    assetsInclude: (file: string) => boolean;\r\n    logger: Logger;\r\n    createResolver: (options?: Partial<InternalResolveOptions>) => ResolveFn;\r\n    optimizeDeps: DepOptimizationOptions;\r\n    /* Excluded from this release type: packageCache */\r\n    worker: ResolveWorkerOptions;\r\n    appType: AppType;\r\n    experimental: ExperimentalOptions;\r\n} & PluginHookUtils>;\r\n\r\nexport declare interface ResolvedModulePreloadOptions {\r\n    polyfill: boolean;\r\n    resolveDependencies?: ResolveModulePreloadDependenciesFn;\r\n}\r\n\r\nexport declare interface ResolvedPreviewOptions extends PreviewOptions {\r\n}\r\n\r\nexport declare interface ResolvedServerOptions extends ServerOptions {\r\n    fs: Required<FileSystemServeOptions>;\r\n    middlewareMode: boolean;\r\n}\r\n\r\nexport declare interface ResolvedServerUrls {\r\n    local: string[];\r\n    network: string[];\r\n}\r\n\r\nexport declare interface ResolvedSSROptions extends SSROptions {\r\n    target: SSRTarget;\r\n    format: SSRFormat;\r\n    optimizeDeps: SsrDepOptimizationOptions;\r\n}\r\n\r\nexport declare type ResolvedUrl = [\r\nurl: string,\r\nresolvedId: string,\r\nmeta: object | null | undefined\r\n];\r\n\r\nexport declare function resolveEnvPrefix({ envPrefix, }: UserConfig): string[];\r\n\r\nexport declare type ResolveFn = (id: string, importer?: string, aliasOnly?: boolean, ssr?: boolean) => Promise<string | undefined>;\r\n\r\nexport declare type ResolveModulePreloadDependenciesFn = (filename: string, deps: string[], context: {\r\n    hostId: string;\r\n    hostType: 'html' | 'js';\r\n}) => string[];\r\n\r\nexport declare interface ResolveOptions {\r\n    /**\r\n     * @default ['module', 'jsnext:main', 'jsnext']\r\n     */\r\n    mainFields?: string[];\r\n    /**\r\n     * @deprecated In future, `mainFields` should be used instead.\r\n     * @default true\r\n     */\r\n    browserField?: boolean;\r\n    conditions?: string[];\r\n    /**\r\n     * @default ['.mjs', '.js', '.mts', '.ts', '.jsx', '.tsx', '.json']\r\n     */\r\n    extensions?: string[];\r\n    dedupe?: string[];\r\n    /**\r\n     * @default false\r\n     */\r\n    preserveSymlinks?: boolean;\r\n}\r\n\r\nexport declare function resolvePackageData(id: string, basedir: string, preserveSymlinks?: boolean, packageCache?: PackageCache): PackageData | null;\r\n\r\nexport declare function resolvePackageEntry(id: string, { dir, data, setResolvedCache, getResolvedCache }: PackageData, targetWeb: boolean, options: InternalResolveOptions): string | undefined;\r\n\r\nexport declare type ResolverFunction = MapToFunction<PluginHooks['resolveId']>\r\n\r\nexport declare interface ResolverObject {\r\n    buildStart?: PluginHooks['buildStart']\r\n    resolveId: ResolverFunction\r\n}\r\n\r\nexport declare interface ResolveWorkerOptions extends PluginHookUtils {\r\n    format: 'es' | 'iife';\r\n    plugins: Plugin_2[];\r\n    rollupOptions: RollupOptions;\r\n}\r\n\r\n/**\r\n * https://github.com/rollup/plugins/blob/master/packages/commonjs/types/index.d.ts\r\n *\r\n * This source code is licensed under the MIT license found in the\r\n * LICENSE file at\r\n * https://github.com/rollup/plugins/blob/master/LICENSE\r\n */\r\nexport declare interface RollupCommonJSOptions {\r\n    /**\r\n     * A minimatch pattern, or array of patterns, which specifies the files in\r\n     * the build the plugin should operate on. By default, all files with\r\n     * extension `\".cjs\"` or those in `extensions` are included, but you can\r\n     * narrow this list by only including specific files. These files will be\r\n     * analyzed and transpiled if either the analysis does not find ES module\r\n     * specific statements or `transformMixedEsModules` is `true`.\r\n     * @default undefined\r\n     */\r\n    include?: string | RegExp | readonly (string | RegExp)[]\r\n    /**\r\n     * A minimatch pattern, or array of patterns, which specifies the files in\r\n     * the build the plugin should _ignore_. By default, all files with\r\n     * extensions other than those in `extensions` or `\".cjs\"` are ignored, but you\r\n     * can exclude additional files. See also the `include` option.\r\n     * @default undefined\r\n     */\r\n    exclude?: string | RegExp | readonly (string | RegExp)[]\r\n    /**\r\n     * For extensionless imports, search for extensions other than .js in the\r\n     * order specified. Note that you need to make sure that non-JavaScript files\r\n     * are transpiled by another plugin first.\r\n     * @default [ '.js' ]\r\n     */\r\n    extensions?: ReadonlyArray<string>\r\n    /**\r\n     * If true then uses of `global` won't be dealt with by this plugin\r\n     * @default false\r\n     */\r\n    ignoreGlobal?: boolean\r\n    /**\r\n     * If false, skips source map generation for CommonJS modules. This will\r\n     * improve performance.\r\n     * @default true\r\n     */\r\n    sourceMap?: boolean\r\n    /**\r\n     * Some `require` calls cannot be resolved statically to be translated to\r\n     * imports.\r\n     * When this option is set to `false`, the generated code will either\r\n     * directly throw an error when such a call is encountered or, when\r\n     * `dynamicRequireTargets` is used, when such a call cannot be resolved with a\r\n     * configured dynamic require target.\r\n     * Setting this option to `true` will instead leave the `require` call in the\r\n     * code or use it as a fallback for `dynamicRequireTargets`.\r\n     * @default false\r\n     */\r\n    ignoreDynamicRequires?: boolean\r\n    /**\r\n     * Instructs the plugin whether to enable mixed module transformations. This\r\n     * is useful in scenarios with modules that contain a mix of ES `import`\r\n     * statements and CommonJS `require` expressions. Set to `true` if `require`\r\n     * calls should be transformed to imports in mixed modules, or `false` if the\r\n     * `require` expressions should survive the transformation. The latter can be\r\n     * important if the code contains environment detection, or you are coding\r\n     * for an environment with special treatment for `require` calls such as\r\n     * ElectronJS. See also the `ignore` option.\r\n     * @default false\r\n     */\r\n    transformMixedEsModules?: boolean\r\n    /**\r\n     * By default, this plugin will try to hoist `require` statements as imports\r\n     * to the top of each file. While this works well for many code bases and\r\n     * allows for very efficient ESM output, it does not perfectly capture\r\n     * CommonJS semantics as the order of side effects like log statements may\r\n     * change. But it is especially problematic when there are circular `require`\r\n     * calls between CommonJS modules as those often rely on the lazy execution of\r\n     * nested `require` calls.\r\n     *\r\n     * Setting this option to `true` will wrap all CommonJS files in functions\r\n     * which are executed when they are required for the first time, preserving\r\n     * NodeJS semantics. Note that this can have an impact on the size and\r\n     * performance of the generated code.\r\n     *\r\n     * The default value of `\"auto\"` will only wrap CommonJS files when they are\r\n     * part of a CommonJS dependency cycle, e.g. an index file that is required by\r\n     * many of its dependencies. All other CommonJS files are hoisted. This is the\r\n     * recommended setting for most code bases.\r\n     *\r\n     * `false` will entirely prevent wrapping and hoist all files. This may still\r\n     * work depending on the nature of cyclic dependencies but will often cause\r\n     * problems.\r\n     *\r\n     * You can also provide a minimatch pattern, or array of patterns, to only\r\n     * specify a subset of files which should be wrapped in functions for proper\r\n     * `require` semantics.\r\n     *\r\n     * `\"debug\"` works like `\"auto\"` but after bundling, it will display a warning\r\n     * containing a list of ids that have been wrapped which can be used as\r\n     * minimatch pattern for fine-tuning.\r\n     * @default \"auto\"\r\n     */\r\n    strictRequires?: boolean | string | RegExp | readonly (string | RegExp)[]\r\n    /**\r\n     * Sometimes you have to leave require statements unconverted. Pass an array\r\n     * containing the IDs or a `id => boolean` function.\r\n     * @default []\r\n     */\r\n    ignore?: ReadonlyArray<string> | ((id: string) => boolean)\r\n    /**\r\n     * In most cases, where `require` calls are inside a `try-catch` clause,\r\n     * they should be left unconverted as it requires an optional dependency\r\n     * that may or may not be installed beside the rolled up package.\r\n     * Due to the conversion of `require` to a static `import` - the call is\r\n     * hoisted to the top of the file, outside the `try-catch` clause.\r\n     *\r\n     * - `true`: Default. All `require` calls inside a `try` will be left unconverted.\r\n     * - `false`: All `require` calls inside a `try` will be converted as if the\r\n     *   `try-catch` clause is not there.\r\n     * - `remove`: Remove all `require` calls from inside any `try` block.\r\n     * - `string[]`: Pass an array containing the IDs to left unconverted.\r\n     * - `((id: string) => boolean|'remove')`: Pass a function that controls\r\n     *   individual IDs.\r\n     *\r\n     * @default true\r\n     */\r\n    ignoreTryCatch?:\r\n    | boolean\r\n    | 'remove'\r\n    | ReadonlyArray<string>\r\n    | ((id: string) => boolean | 'remove')\r\n    /**\r\n     * Controls how to render imports from external dependencies. By default,\r\n     * this plugin assumes that all external dependencies are CommonJS. This\r\n     * means they are rendered as default imports to be compatible with e.g.\r\n     * NodeJS where ES modules can only import a default export from a CommonJS\r\n     * dependency.\r\n     *\r\n     * If you set `esmExternals` to `true`, this plugin assumes that all\r\n     * external dependencies are ES modules and respect the\r\n     * `requireReturnsDefault` option. If that option is not set, they will be\r\n     * rendered as namespace imports.\r\n     *\r\n     * You can also supply an array of ids to be treated as ES modules, or a\r\n     * function that will be passed each external id to determine whether it is\r\n     * an ES module.\r\n     * @default false\r\n     */\r\n    esmExternals?: boolean | ReadonlyArray<string> | ((id: string) => boolean)\r\n    /**\r\n     * Controls what is returned when requiring an ES module from a CommonJS file.\r\n     * When using the `esmExternals` option, this will also apply to external\r\n     * modules. By default, this plugin will render those imports as namespace\r\n     * imports i.e.\r\n     *\r\n     * ```js\r\n     * // input\r\n     * const foo = require('foo');\r\n     *\r\n     * // output\r\n     * import * as foo from 'foo';\r\n     * ```\r\n     *\r\n     * However, there are some situations where this may not be desired.\r\n     * For these situations, you can change Rollup's behaviour either globally or\r\n     * per module. To change it globally, set the `requireReturnsDefault` option\r\n     * to one of the following values:\r\n     *\r\n     * - `false`: This is the default, requiring an ES module returns its\r\n     *   namespace. This is the only option that will also add a marker\r\n     *   `__esModule: true` to the namespace to support interop patterns in\r\n     *   CommonJS modules that are transpiled ES modules.\r\n     * - `\"namespace\"`: Like `false`, requiring an ES module returns its\r\n     *   namespace, but the plugin does not add the `__esModule` marker and thus\r\n     *   creates more efficient code. For external dependencies when using\r\n     *   `esmExternals: true`, no additional interop code is generated.\r\n     * - `\"auto\"`: This is complementary to how `output.exports: \"auto\"` works in\r\n     *   Rollup: If a module has a default export and no named exports, requiring\r\n     *   that module returns the default export. In all other cases, the namespace\r\n     *   is returned. For external dependencies when using `esmExternals: true`, a\r\n     *   corresponding interop helper is added.\r\n     * - `\"preferred\"`: If a module has a default export, requiring that module\r\n     *   always returns the default export, no matter whether additional named\r\n     *   exports exist. This is similar to how previous versions of this plugin\r\n     *   worked. Again for external dependencies when using `esmExternals: true`,\r\n     *   an interop helper is added.\r\n     * - `true`: This will always try to return the default export on require\r\n     *   without checking if it actually exists. This can throw at build time if\r\n     *   there is no default export. This is how external dependencies are handled\r\n     *   when `esmExternals` is not used. The advantage over the other options is\r\n     *   that, like `false`, this does not add an interop helper for external\r\n     *   dependencies, keeping the code lean.\r\n     *\r\n     * To change this for individual modules, you can supply a function for\r\n     * `requireReturnsDefault` instead. This function will then be called once for\r\n     * each required ES module or external dependency with the corresponding id\r\n     * and allows you to return different values for different modules.\r\n     * @default false\r\n     */\r\n    requireReturnsDefault?:\r\n    | boolean\r\n    | 'auto'\r\n    | 'preferred'\r\n    | 'namespace'\r\n    | ((id: string) => boolean | 'auto' | 'preferred' | 'namespace')\r\n\r\n    /**\r\n     * @default \"auto\"\r\n     */\r\n    defaultIsModuleExports?: boolean | 'auto' | ((id: string) => boolean | 'auto')\r\n    /**\r\n     * Some modules contain dynamic `require` calls, or require modules that\r\n     * contain circular dependencies, which are not handled well by static\r\n     * imports. Including those modules as `dynamicRequireTargets` will simulate a\r\n     * CommonJS (NodeJS-like) environment for them with support for dynamic\r\n     * dependencies. It also enables `strictRequires` for those modules.\r\n     *\r\n     * Note: In extreme cases, this feature may result in some paths being\r\n     * rendered as absolute in the final bundle. The plugin tries to avoid\r\n     * exposing paths from the local machine, but if you are `dynamicRequirePaths`\r\n     * with paths that are far away from your project's folder, that may require\r\n     * replacing strings like `\"/Users/John/Desktop/foo-project/\"` -\\> `\"/\"`.\r\n     */\r\n    dynamicRequireTargets?: string | ReadonlyArray<string>\r\n    /**\r\n     * To avoid long paths when using the `dynamicRequireTargets` option, you can use this option to specify a directory\r\n     * that is a common parent for all files that use dynamic require statements. Using a directory higher up such as `/`\r\n     * may lead to unnecessarily long paths in the generated code and may expose directory names on your machine like your\r\n     * home directory name. By default, it uses the current working directory.\r\n     */\r\n    dynamicRequireRoot?: string\r\n}\r\n\r\nexport declare interface RollupDynamicImportVarsOptions {\r\n    /**\r\n     * Files to include in this plugin (default all).\r\n     * @default []\r\n     */\r\n    include?: string | RegExp | (string | RegExp)[]\r\n    /**\r\n     * Files to exclude in this plugin (default none).\r\n     * @default []\r\n     */\r\n    exclude?: string | RegExp | (string | RegExp)[]\r\n    /**\r\n     * By default, the plugin quits the build process when it encounters an error. If you set this option to true, it will throw a warning instead and leave the code untouched.\r\n     * @default false\r\n     */\r\n    warnOnError?: boolean\r\n}\r\n\r\nexport { rollupVersion }\r\n\r\n/**\r\n * Search up for the nearest workspace root\r\n */\r\nexport declare function searchForWorkspaceRoot(current: string, root?: string): string;\r\n\r\nexport declare function send(req: IncomingMessage, res: ServerResponse, content: string | Buffer, type: string, options: SendOptions): void;\r\n\r\nexport declare interface SendOptions {\r\n    etag?: string;\r\n    cacheControl?: string;\r\n    headers?: OutgoingHttpHeaders;\r\n    map?: SourceMap | null;\r\n}\r\n\r\nexport declare type ServerHook = (this: void, server: ViteDevServer) => (() => void) | void | Promise<(() => void) | void>;\r\n\r\nexport declare interface ServerOptions extends CommonServerOptions {\r\n    /**\r\n     * Configure HMR-specific options (port, host, path & protocol)\r\n     */\r\n    hmr?: HmrOptions | boolean;\r\n    /**\r\n     * chokidar watch options\r\n     * https://github.com/paulmillr/chokidar#api\r\n     */\r\n    watch?: WatchOptions;\r\n    /**\r\n     * Create Vite dev server to be used as a middleware in an existing server\r\n     * @default false\r\n     */\r\n    middlewareMode?: boolean | 'html' | 'ssr';\r\n    /**\r\n     * Prepend this folder to http requests, for use when proxying vite as a subfolder\r\n     * Should start and end with the `/` character\r\n     */\r\n    base?: string;\r\n    /**\r\n     * Options for files served via '/\\@fs/'.\r\n     */\r\n    fs?: FileSystemServeOptions;\r\n    /**\r\n     * Origin for the generated asset URLs.\r\n     *\r\n     * @example `http://127.0.0.1:8080`\r\n     */\r\n    origin?: string;\r\n    /**\r\n     * Pre-transform known direct imports\r\n     * @default true\r\n     */\r\n    preTransformRequests?: boolean;\r\n    /**\r\n     * Force dep pre-optimization regardless of whether deps have changed.\r\n     *\r\n     * @deprecated Use optimizeDeps.force instead, this option may be removed\r\n     * in a future minor version without following semver\r\n     */\r\n    force?: boolean;\r\n}\r\n\r\nexport declare function sortUserPlugins(plugins: (Plugin_2 | Plugin_2[])[] | undefined): [Plugin_2[], Plugin_2[], Plugin_2[]];\r\n\r\nexport declare function splitVendorChunk(options?: {\r\n    cache?: SplitVendorChunkCache;\r\n}): GetManualChunk;\r\n\r\nexport declare class SplitVendorChunkCache {\r\n    cache: Map<string, boolean>;\r\n    constructor();\r\n    reset(): void;\r\n}\r\n\r\nexport declare function splitVendorChunkPlugin(): Plugin_2;\r\n\r\nexport declare type SsrDepOptimizationOptions = DepOptimizationConfig;\r\n\r\nexport declare type SSRFormat = 'esm' | 'cjs';\r\n\r\nexport declare interface SSROptions {\r\n    noExternal?: string | RegExp | (string | RegExp)[] | true;\r\n    external?: string[];\r\n    /**\r\n     * Define the target for the ssr build. The browser field in package.json\r\n     * is ignored for node but used if webworker is the target\r\n     * @default 'node'\r\n     */\r\n    target?: SSRTarget;\r\n    /**\r\n     * Define the format for the ssr build. Since Vite v3 the SSR build generates ESM by default.\r\n     * `'cjs'` can be selected to generate a CJS build, but it isn't recommended. This option is\r\n     * left marked as experimental to give users more time to update to ESM. CJS builds requires\r\n     * complex externalization heuristics that aren't present in the ESM format.\r\n     * @experimental\r\n     * @default 'esm'\r\n     */\r\n    format?: SSRFormat;\r\n    /**\r\n     * Control over which dependencies are optimized during SSR and esbuild options\r\n     * During build:\r\n     *   no external CJS dependencies are optimized by default\r\n     * During dev:\r\n     *   explicit no external CJS dependencies are optimized by default\r\n     * @experimental\r\n     */\r\n    optimizeDeps?: SsrDepOptimizationOptions;\r\n}\r\n\r\nexport declare type SSRTarget = 'node' | 'webworker';\r\n\r\nexport declare namespace Terser {\r\n    export type ECMA = 5 | 2015 | 2016 | 2017 | 2018 | 2019 | 2020\r\n\r\n    export interface ParseOptions {\r\n        bare_returns?: boolean\r\n        /** @deprecated legacy option. Currently, all supported EcmaScript is valid to parse. */\r\n        ecma?: ECMA\r\n        html5_comments?: boolean\r\n        shebang?: boolean\r\n    }\r\n\r\n    export interface CompressOptions {\r\n        arguments?: boolean\r\n        arrows?: boolean\r\n        booleans_as_integers?: boolean\r\n        booleans?: boolean\r\n        collapse_vars?: boolean\r\n        comparisons?: boolean\r\n        computed_props?: boolean\r\n        conditionals?: boolean\r\n        dead_code?: boolean\r\n        defaults?: boolean\r\n        directives?: boolean\r\n        drop_console?: boolean\r\n        drop_debugger?: boolean\r\n        ecma?: ECMA\r\n        evaluate?: boolean\r\n        expression?: boolean\r\n        global_defs?: object\r\n        hoist_funs?: boolean\r\n        hoist_props?: boolean\r\n        hoist_vars?: boolean\r\n        ie8?: boolean\r\n        if_return?: boolean\r\n        inline?: boolean | InlineFunctions\r\n        join_vars?: boolean\r\n        keep_classnames?: boolean | RegExp\r\n        keep_fargs?: boolean\r\n        keep_fnames?: boolean | RegExp\r\n        keep_infinity?: boolean\r\n        loops?: boolean\r\n        module?: boolean\r\n        negate_iife?: boolean\r\n        passes?: number\r\n        properties?: boolean\r\n        pure_funcs?: string[]\r\n        pure_getters?: boolean | 'strict'\r\n        reduce_funcs?: boolean\r\n        reduce_vars?: boolean\r\n        sequences?: boolean | number\r\n        side_effects?: boolean\r\n        switches?: boolean\r\n        toplevel?: boolean\r\n        top_retain?: null | string | string[] | RegExp\r\n        typeofs?: boolean\r\n        unsafe_arrows?: boolean\r\n        unsafe?: boolean\r\n        unsafe_comps?: boolean\r\n        unsafe_Function?: boolean\r\n        unsafe_math?: boolean\r\n        unsafe_symbols?: boolean\r\n        unsafe_methods?: boolean\r\n        unsafe_proto?: boolean\r\n        unsafe_regexp?: boolean\r\n        unsafe_undefined?: boolean\r\n        unused?: boolean\r\n    }\r\n\r\n    export enum InlineFunctions {\r\n        Disabled = 0,\r\n        SimpleFunctions = 1,\r\n        WithArguments = 2,\r\n        WithArgumentsAndVariables = 3,\r\n    }\r\n\r\n    export interface MangleOptions {\r\n        eval?: boolean\r\n        keep_classnames?: boolean | RegExp\r\n        keep_fnames?: boolean | RegExp\r\n        module?: boolean\r\n        nth_identifier?: SimpleIdentifierMangler | WeightedIdentifierMangler\r\n        properties?: boolean | ManglePropertiesOptions\r\n        reserved?: string[]\r\n        safari10?: boolean\r\n        toplevel?: boolean\r\n    }\r\n\r\n    /**\r\n     * An identifier mangler for which the output is invariant with respect to the source code.\r\n     */\r\n    export interface SimpleIdentifierMangler {\r\n        /**\r\n         * Obtains the nth most favored (usually shortest) identifier to rename a variable to.\r\n         * The mangler will increment n and retry until the return value is not in use in scope, and is not a reserved word.\r\n         * This function is expected to be stable; Evaluating get(n) === get(n) should always return true.\r\n         * @param n - The ordinal of the identifier.\r\n         */\r\n        get(n: number): string\r\n    }\r\n\r\n    /**\r\n     * An identifier mangler that leverages character frequency analysis to determine identifier precedence.\r\n     */\r\n    export interface WeightedIdentifierMangler extends SimpleIdentifierMangler {\r\n        /**\r\n         * Modifies the internal weighting of the input characters by the specified delta.\r\n         * Will be invoked on the entire printed AST, and then deduct mangleable identifiers.\r\n         * @param chars - The characters to modify the weighting of.\r\n         * @param delta - The numeric weight to add to the characters.\r\n         */\r\n        consider(chars: string, delta: number): number\r\n        /**\r\n         * Resets character weights.\r\n         */\r\n        reset(): void\r\n        /**\r\n         * Sorts identifiers by character frequency, in preparation for calls to get(n).\r\n         */\r\n        sort(): void\r\n    }\r\n\r\n    export interface ManglePropertiesOptions {\r\n        builtins?: boolean\r\n        debug?: boolean\r\n        keep_quoted?: boolean | 'strict'\r\n        nth_identifier?: SimpleIdentifierMangler | WeightedIdentifierMangler\r\n        regex?: RegExp | string\r\n        reserved?: string[]\r\n    }\r\n\r\n    export interface FormatOptions {\r\n        ascii_only?: boolean\r\n        /** @deprecated Not implemented anymore */\r\n        beautify?: boolean\r\n        braces?: boolean\r\n        comments?:\r\n        | boolean\r\n        | 'all'\r\n        | 'some'\r\n        | RegExp\r\n        | ((\r\n        node: any,\r\n        comment: {\r\n            value: string\r\n            type: 'comment1' | 'comment2' | 'comment3' | 'comment4'\r\n            pos: number\r\n            line: number\r\n            col: number\r\n        },\r\n        ) => boolean)\r\n        ecma?: ECMA\r\n        ie8?: boolean\r\n        keep_numbers?: boolean\r\n        indent_level?: number\r\n        indent_start?: number\r\n        inline_script?: boolean\r\n        keep_quoted_props?: boolean\r\n        max_line_len?: number | false\r\n        preamble?: string\r\n        preserve_annotations?: boolean\r\n        quote_keys?: boolean\r\n        quote_style?: OutputQuoteStyle\r\n        safari10?: boolean\r\n        semicolons?: boolean\r\n        shebang?: boolean\r\n        shorthand?: boolean\r\n        source_map?: SourceMapOptions\r\n        webkit?: boolean\r\n        width?: number\r\n        wrap_iife?: boolean\r\n        wrap_func_args?: boolean\r\n    }\r\n\r\n    export enum OutputQuoteStyle {\r\n        PreferDouble = 0,\r\n        AlwaysSingle = 1,\r\n        AlwaysDouble = 2,\r\n        AlwaysOriginal = 3,\r\n    }\r\n\r\n    export interface MinifyOptions {\r\n        compress?: boolean | CompressOptions\r\n        ecma?: ECMA\r\n        enclose?: boolean | string\r\n        ie8?: boolean\r\n        keep_classnames?: boolean | RegExp\r\n        keep_fnames?: boolean | RegExp\r\n        mangle?: boolean | MangleOptions\r\n        module?: boolean\r\n        nameCache?: object\r\n        format?: FormatOptions\r\n        /** @deprecated deprecated */\r\n        output?: FormatOptions\r\n        parse?: ParseOptions\r\n        safari10?: boolean\r\n        sourceMap?: boolean | SourceMapOptions\r\n        toplevel?: boolean\r\n    }\r\n\r\n    export interface MinifyOutput {\r\n        code?: string\r\n        map?: object | string\r\n        decoded_map?: object | null\r\n    }\r\n\r\n    export interface SourceMapOptions {\r\n        /** Source map object, 'inline' or source map file content */\r\n        content?: object | string\r\n        includeSources?: boolean\r\n        filename?: string\r\n        root?: string\r\n        url?: string | 'inline'\r\n    }\r\n}\r\n\r\nexport declare interface TransformOptions {\r\n    ssr?: boolean;\r\n    html?: boolean;\r\n}\r\n\r\nexport declare interface TransformResult {\r\n    code: string;\r\n    map: SourceMap | null;\r\n    etag?: string;\r\n    deps?: string[];\r\n    dynamicDeps?: string[];\r\n}\r\n\r\nexport declare function transformWithEsbuild(code: string, filename: string, options?: EsbuildTransformOptions, inMap?: object): Promise<ESBuildTransformResult>;\r\n\r\nexport { Update }\r\n\r\nexport { UpdatePayload }\r\n\r\nexport declare interface UserConfig {\r\n    /**\r\n     * Project root directory. Can be an absolute path, or a path relative from\r\n     * the location of the config file itself.\r\n     * @default process.cwd()\r\n     */\r\n    root?: string;\r\n    /**\r\n     * Base public path when served in development or production.\r\n     * @default '/'\r\n     */\r\n    base?: string;\r\n    /**\r\n     * Directory to serve as plain static assets. Files in this directory are\r\n     * served and copied to build dist dir as-is without transform. The value\r\n     * can be either an absolute file system path or a path relative to project root.\r\n     *\r\n     * Set to `false` or an empty string to disable copied static assets to build dist dir.\r\n     * @default 'public'\r\n     */\r\n    publicDir?: string | false;\r\n    /**\r\n     * Directory to save cache files. Files in this directory are pre-bundled\r\n     * deps or some other cache files that generated by vite, which can improve\r\n     * the performance. You can use `--force` flag or manually delete the directory\r\n     * to regenerate the cache files. The value can be either an absolute file\r\n     * system path or a path relative to project root.\r\n     * Default to `.vite` when no `package.json` is detected.\r\n     * @default 'node_modules/.vite'\r\n     */\r\n    cacheDir?: string;\r\n    /**\r\n     * Explicitly set a mode to run in. This will override the default mode for\r\n     * each command, and can be overridden by the command line --mode option.\r\n     */\r\n    mode?: string;\r\n    /**\r\n     * Define global variable replacements.\r\n     * Entries will be defined on `window` during dev and replaced during build.\r\n     */\r\n    define?: Record<string, any>;\r\n    /**\r\n     * Array of vite plugins to use.\r\n     */\r\n    plugins?: PluginOption[];\r\n    /**\r\n     * Configure resolver\r\n     */\r\n    resolve?: ResolveOptions & {\r\n        alias?: AliasOptions;\r\n    };\r\n    /**\r\n     * CSS related options (preprocessors and CSS modules)\r\n     */\r\n    css?: CSSOptions;\r\n    /**\r\n     * JSON loading options\r\n     */\r\n    json?: JsonOptions;\r\n    /**\r\n     * Transform options to pass to esbuild.\r\n     * Or set to `false` to disable esbuild.\r\n     */\r\n    esbuild?: ESBuildOptions | false;\r\n    /**\r\n     * Specify additional picomatch patterns to be treated as static assets.\r\n     */\r\n    assetsInclude?: string | RegExp | (string | RegExp)[];\r\n    /**\r\n     * Server specific options, e.g. host, port, https...\r\n     */\r\n    server?: ServerOptions;\r\n    /**\r\n     * Build specific options\r\n     */\r\n    build?: BuildOptions;\r\n    /**\r\n     * Preview specific options, e.g. host, port, https...\r\n     */\r\n    preview?: PreviewOptions;\r\n    /**\r\n     * Dep optimization options\r\n     */\r\n    optimizeDeps?: DepOptimizationOptions;\r\n    /**\r\n     * SSR specific options\r\n     */\r\n    ssr?: SSROptions;\r\n    /**\r\n     * Experimental features\r\n     *\r\n     * Features under this field could change in the future and might NOT follow semver.\r\n     * Please be careful and always pin Vite's version when using them.\r\n     * @experimental\r\n     */\r\n    experimental?: ExperimentalOptions;\r\n    /**\r\n     * Legacy options\r\n     *\r\n     * Features under this field only follow semver for patches, they could be removed in a\r\n     * future minor version. Please always pin Vite's version to a minor when using them.\r\n     */\r\n    legacy?: LegacyOptions;\r\n    /**\r\n     * Log level.\r\n     * @default 'info'\r\n     */\r\n    logLevel?: LogLevel;\r\n    /**\r\n     * Custom logger.\r\n     */\r\n    customLogger?: Logger;\r\n    /**\r\n     * @default true\r\n     */\r\n    clearScreen?: boolean;\r\n    /**\r\n     * Environment files directory. Can be an absolute path, or a path relative from\r\n     * the location of the config file itself.\r\n     * @default root\r\n     */\r\n    envDir?: string;\r\n    /**\r\n     * Env variables starts with `envPrefix` will be exposed to your client source code via import.meta.env.\r\n     * @default 'VITE_'\r\n     */\r\n    envPrefix?: string | string[];\r\n    /**\r\n     * Worker bundle options\r\n     */\r\n    worker?: {\r\n        /**\r\n         * Output format for worker bundle\r\n         * @default 'iife'\r\n         */\r\n        format?: 'es' | 'iife';\r\n        /**\r\n         * Vite plugins that apply to worker bundle\r\n         */\r\n        plugins?: PluginOption[];\r\n        /**\r\n         * Rollup options to build worker bundle\r\n         */\r\n        rollupOptions?: Omit<RollupOptions, 'plugins' | 'input' | 'onwarn' | 'preserveEntrySignatures'>;\r\n    };\r\n    /**\r\n     * Whether your application is a Single Page Application (SPA),\r\n     * a Multi-Page Application (MPA), or Custom Application (SSR\r\n     * and frameworks with custom HTML handling)\r\n     * @default 'spa'\r\n     */\r\n    appType?: AppType;\r\n}\r\n\r\nexport declare type UserConfigExport = UserConfig | Promise<UserConfig> | UserConfigFn;\r\n\r\nexport declare type UserConfigFn = (env: ConfigEnv) => UserConfig | Promise<UserConfig>;\r\n\r\nexport declare const version: string;\r\n\r\nexport declare interface ViteDevServer {\r\n    /**\r\n     * The resolved vite config object\r\n     */\r\n    config: ResolvedConfig;\r\n    /**\r\n     * A connect app instance.\r\n     * - Can be used to attach custom middlewares to the dev server.\r\n     * - Can also be used as the handler function of a custom http server\r\n     *   or as a middleware in any connect-style Node.js frameworks\r\n     *\r\n     * https://github.com/senchalabs/connect#use-middleware\r\n     */\r\n    middlewares: Connect.Server;\r\n    /**\r\n     * native Node http server instance\r\n     * will be null in middleware mode\r\n     */\r\n    httpServer: http.Server | null;\r\n    /**\r\n     * chokidar watcher instance\r\n     * https://github.com/paulmillr/chokidar#api\r\n     */\r\n    watcher: FSWatcher;\r\n    /**\r\n     * web socket server with `send(payload)` method\r\n     */\r\n    ws: WebSocketServer;\r\n    /**\r\n     * Rollup plugin container that can run plugin hooks on a given file\r\n     */\r\n    pluginContainer: PluginContainer;\r\n    /**\r\n     * Module graph that tracks the import relationships, url to file mapping\r\n     * and hmr state.\r\n     */\r\n    moduleGraph: ModuleGraph;\r\n    /**\r\n     * The resolved urls Vite prints on the CLI. null in middleware mode or\r\n     * before `server.listen` is called.\r\n     */\r\n    resolvedUrls: ResolvedServerUrls | null;\r\n    /**\r\n     * Programmatically resolve, load and transform a URL and get the result\r\n     * without going through the http request pipeline.\r\n     */\r\n    transformRequest(url: string, options?: TransformOptions): Promise<TransformResult | null>;\r\n    /**\r\n     * Apply vite built-in HTML transforms and any plugin HTML transforms.\r\n     */\r\n    transformIndexHtml(url: string, html: string, originalUrl?: string): Promise<string>;\r\n    /**\r\n     * Transform module code into SSR format.\r\n     */\r\n    ssrTransform(code: string, inMap: SourceMap | null, url: string, originalCode?: string): Promise<TransformResult | null>;\r\n    /**\r\n     * Load a given URL as an instantiated module for SSR.\r\n     */\r\n    ssrLoadModule(url: string, opts?: {\r\n        fixStacktrace?: boolean;\r\n    }): Promise<Record<string, any>>;\r\n    /**\r\n     * Returns a fixed version of the given stack\r\n     */\r\n    ssrRewriteStacktrace(stack: string): string;\r\n    /**\r\n     * Mutates the given SSR error by rewriting the stacktrace\r\n     */\r\n    ssrFixStacktrace(e: Error): void;\r\n    /**\r\n     * Triggers HMR for a module in the module graph. You can use the `server.moduleGraph`\r\n     * API to retrieve the module to be reloaded. If `hmr` is false, this is a no-op.\r\n     */\r\n    reloadModule(module: ModuleNode): Promise<void>;\r\n    /**\r\n     * Start the server.\r\n     */\r\n    listen(port?: number, isRestart?: boolean): Promise<ViteDevServer>;\r\n    /**\r\n     * Stop the server.\r\n     */\r\n    close(): Promise<void>;\r\n    /**\r\n     * Print server urls\r\n     */\r\n    printUrls(): void;\r\n    /**\r\n     * Restart the server.\r\n     *\r\n     * @param forceOptimize - force the optimizer to re-bundle, same as --force cli flag\r\n     */\r\n    restart(forceOptimize?: boolean): Promise<void>;\r\n    /* Excluded from this release type: _importGlobMap */\r\n    /* Excluded from this release type: _ssrExternals */\r\n    /* Excluded from this release type: _restartPromise */\r\n    /* Excluded from this release type: _forceOptimizeOnRestart */\r\n    /* Excluded from this release type: _pendingRequests */\r\n    /* Excluded from this release type: _fsDenyGlob */\r\n    /* Excluded from this release type: _shortcutsOptions */\r\n}\r\n\r\nexport declare interface WatchOptions {\r\n    /**\r\n     * Indicates whether the process should continue to run as long as files are being watched. If\r\n     * set to `false` when using `fsevents` to watch, no more events will be emitted after `ready`,\r\n     * even if the process continues to run.\r\n     */\r\n    persistent?: boolean\r\n\r\n    /**\r\n     * ([anymatch](https://github.com/micromatch/anymatch)-compatible definition) Defines files/paths to\r\n     * be ignored. The whole relative or absolute path is tested, not just filename. If a function\r\n     * with two arguments is provided, it gets called twice per path - once with a single argument\r\n     * (the path), second time with two arguments (the path and the\r\n     * [`fs.Stats`](https://nodejs.org/api/fs.html#fs_class_fs_stats) object of that path).\r\n     */\r\n    ignored?: Matcher\r\n\r\n    /**\r\n     * If set to `false` then `add`/`addDir` events are also emitted for matching paths while\r\n     * instantiating the watching as chokidar discovers these file paths (before the `ready` event).\r\n     */\r\n    ignoreInitial?: boolean\r\n\r\n    /**\r\n     * When `false`, only the symlinks themselves will be watched for changes instead of following\r\n     * the link references and bubbling events through the link's path.\r\n     */\r\n    followSymlinks?: boolean\r\n\r\n    /**\r\n     * The base directory from which watch `paths` are to be derived. Paths emitted with events will\r\n     * be relative to this.\r\n     */\r\n    cwd?: string\r\n\r\n    /**\r\n     * If set to true then the strings passed to .watch() and .add() are treated as literal path\r\n     * names, even if they look like globs.\r\n     *\r\n     * @default false\r\n     */\r\n    disableGlobbing?: boolean\r\n\r\n    /**\r\n     * Whether to use fs.watchFile (backed by polling), or fs.watch. If polling leads to high CPU\r\n     * utilization, consider setting this to `false`. It is typically necessary to **set this to\r\n     * `true` to successfully watch files over a network**, and it may be necessary to successfully\r\n     * watch files in other non-standard situations. Setting to `true` explicitly on OS X overrides\r\n     * the `useFsEvents` default.\r\n     */\r\n    usePolling?: boolean\r\n\r\n    /**\r\n     * Whether to use the `fsevents` watching interface if available. When set to `true` explicitly\r\n     * and `fsevents` is available this supersedes the `usePolling` setting. When set to `false` on\r\n     * OS X, `usePolling: true` becomes the default.\r\n     */\r\n    useFsEvents?: boolean\r\n\r\n    /**\r\n     * If relying upon the [`fs.Stats`](https://nodejs.org/api/fs.html#fs_class_fs_stats) object that\r\n     * may get passed with `add`, `addDir`, and `change` events, set this to `true` to ensure it is\r\n     * provided even in cases where it wasn't already available from the underlying watch events.\r\n     */\r\n    alwaysStat?: boolean\r\n\r\n    /**\r\n     * If set, limits how many levels of subdirectories will be traversed.\r\n     */\r\n    depth?: number\r\n\r\n    /**\r\n     * Interval of file system polling.\r\n     */\r\n    interval?: number\r\n\r\n    /**\r\n     * Interval of file system polling for binary files. ([see list of binary extensions](https://gi\r\n     * thub.com/sindresorhus/binary-extensions/blob/master/binary-extensions.json))\r\n     */\r\n    binaryInterval?: number\r\n\r\n    /**\r\n     *  Indicates whether to watch files that don't have read permissions if possible. If watching\r\n     *  fails due to `EPERM` or `EACCES` with this set to `true`, the errors will be suppressed\r\n     *  silently.\r\n     */\r\n    ignorePermissionErrors?: boolean\r\n\r\n    /**\r\n     * `true` if `useFsEvents` and `usePolling` are `false`. Automatically filters out artifacts\r\n     * that occur when using editors that use \"atomic writes\" instead of writing directly to the\r\n     * source file. If a file is re-added within 100 ms of being deleted, Chokidar emits a `change`\r\n     * event rather than `unlink` then `add`. If the default of 100 ms does not work well for you,\r\n     * you can override it by setting `atomic` to a custom value, in milliseconds.\r\n     */\r\n    atomic?: boolean | number\r\n\r\n    /**\r\n     * can be set to an object in order to adjust timing params:\r\n     */\r\n    awaitWriteFinish?: AwaitWriteFinishOptions | boolean\r\n}\r\n\r\ndeclare class WebSocket_2 extends EventEmitter {\r\n    /** The connection is not yet open. */\r\n    static readonly CONNECTING: 0\r\n    /** The connection is open and ready to communicate. */\r\n    static readonly OPEN: 1\r\n    /** The connection is in the process of closing. */\r\n    static readonly CLOSING: 2\r\n    /** The connection is closed. */\r\n    static readonly CLOSED: 3\r\n\r\n    binaryType: 'nodebuffer' | 'arraybuffer' | 'fragments'\r\n    readonly bufferedAmount: number\r\n    readonly extensions: string\r\n    /** Indicates whether the websocket is paused */\r\n    readonly isPaused: boolean\r\n    readonly protocol: string\r\n    /** The current state of the connection */\r\n    readonly readyState:\r\n    | typeof WebSocket_2.CONNECTING\r\n    | typeof WebSocket_2.OPEN\r\n    | typeof WebSocket_2.CLOSING\r\n    | typeof WebSocket_2.CLOSED\r\n    readonly url: string\r\n\r\n    /** The connection is not yet open. */\r\n    readonly CONNECTING: 0\r\n    /** The connection is open and ready to communicate. */\r\n    readonly OPEN: 1\r\n    /** The connection is in the process of closing. */\r\n    readonly CLOSING: 2\r\n    /** The connection is closed. */\r\n    readonly CLOSED: 3\r\n\r\n    onopen: ((event: WebSocket_2.Event) => void) | null\r\n    onerror: ((event: WebSocket_2.ErrorEvent) => void) | null\r\n    onclose: ((event: WebSocket_2.CloseEvent) => void) | null\r\n    onmessage: ((event: WebSocket_2.MessageEvent) => void) | null\r\n\r\n    constructor(address: null)\r\n    constructor(\r\n    address: string | URL_2,\r\n    options?: WebSocket_2.ClientOptions | ClientRequestArgs,\r\n    )\r\n    constructor(\r\n    address: string | URL_2,\r\n    protocols?: string | string[],\r\n    options?: WebSocket_2.ClientOptions | ClientRequestArgs,\r\n    )\r\n\r\n    close(code?: number, data?: string | Buffer): void\r\n    ping(data?: any, mask?: boolean, cb?: (err: Error) => void): void\r\n    pong(data?: any, mask?: boolean, cb?: (err: Error) => void): void\r\n    send(data: any, cb?: (err?: Error) => void): void\r\n    send(\r\n    data: any,\r\n    options: {\r\n        mask?: boolean | undefined\r\n        binary?: boolean | undefined\r\n        compress?: boolean | undefined\r\n        fin?: boolean | undefined\r\n    },\r\n    cb?: (err?: Error) => void,\r\n    ): void\r\n    terminate(): void\r\n\r\n    /**\r\n     * Pause the websocket causing it to stop emitting events. Some events can still be\r\n     * emitted after this is called, until all buffered data is consumed. This method\r\n     * is a noop if the ready state is `CONNECTING` or `CLOSED`.\r\n     */\r\n    pause(): void\r\n    /**\r\n     * Make a paused socket resume emitting events. This method is a noop if the ready\r\n     * state is `CONNECTING` or `CLOSED`.\r\n     */\r\n    resume(): void\r\n\r\n    // HTML5 WebSocket events\r\n    addEventListener(\r\n    method: 'message',\r\n    cb: (event: WebSocket_2.MessageEvent) => void,\r\n    options?: WebSocket_2.EventListenerOptions,\r\n    ): void\r\n    addEventListener(\r\n    method: 'close',\r\n    cb: (event: WebSocket_2.CloseEvent) => void,\r\n    options?: WebSocket_2.EventListenerOptions,\r\n    ): void\r\n    addEventListener(\r\n    method: 'error',\r\n    cb: (event: WebSocket_2.ErrorEvent) => void,\r\n    options?: WebSocket_2.EventListenerOptions,\r\n    ): void\r\n    addEventListener(\r\n    method: 'open',\r\n    cb: (event: WebSocket_2.Event) => void,\r\n    options?: WebSocket_2.EventListenerOptions,\r\n    ): void\r\n\r\n    removeEventListener(\r\n    method: 'message',\r\n    cb: (event: WebSocket_2.MessageEvent) => void,\r\n    ): void\r\n    removeEventListener(\r\n    method: 'close',\r\n    cb: (event: WebSocket_2.CloseEvent) => void,\r\n    ): void\r\n    removeEventListener(\r\n    method: 'error',\r\n    cb: (event: WebSocket_2.ErrorEvent) => void,\r\n    ): void\r\n    removeEventListener(\r\n    method: 'open',\r\n    cb: (event: WebSocket_2.Event) => void,\r\n    ): void\r\n\r\n    // Events\r\n    on(\r\n    event: 'close',\r\n    listener: (this: WebSocket_2, code: number, reason: Buffer) => void,\r\n    ): this\r\n    on(event: 'error', listener: (this: WebSocket_2, err: Error) => void): this\r\n    on(\r\n    event: 'upgrade',\r\n    listener: (this: WebSocket_2, request: IncomingMessage) => void,\r\n    ): this\r\n    on(\r\n    event: 'message',\r\n    listener: (\r\n    this: WebSocket_2,\r\n    data: WebSocket_2.RawData,\r\n    isBinary: boolean,\r\n    ) => void,\r\n    ): this\r\n    on(event: 'open', listener: (this: WebSocket_2) => void): this\r\n    on(\r\n    event: 'ping' | 'pong',\r\n    listener: (this: WebSocket_2, data: Buffer) => void,\r\n    ): this\r\n    on(\r\n    event: 'unexpected-response',\r\n    listener: (\r\n    this: WebSocket_2,\r\n    request: ClientRequest,\r\n    response: IncomingMessage,\r\n    ) => void,\r\n    ): this\r\n    on(\r\n    event: string | symbol,\r\n    listener: (this: WebSocket_2, ...args: any[]) => void,\r\n    ): this\r\n\r\n    once(\r\n    event: 'close',\r\n    listener: (this: WebSocket_2, code: number, reason: Buffer) => void,\r\n    ): this\r\n    once(event: 'error', listener: (this: WebSocket_2, err: Error) => void): this\r\n    once(\r\n    event: 'upgrade',\r\n    listener: (this: WebSocket_2, request: IncomingMessage) => void,\r\n    ): this\r\n    once(\r\n    event: 'message',\r\n    listener: (\r\n    this: WebSocket_2,\r\n    data: WebSocket_2.RawData,\r\n    isBinary: boolean,\r\n    ) => void,\r\n    ): this\r\n    once(event: 'open', listener: (this: WebSocket_2) => void): this\r\n    once(\r\n    event: 'ping' | 'pong',\r\n    listener: (this: WebSocket_2, data: Buffer) => void,\r\n    ): this\r\n    once(\r\n    event: 'unexpected-response',\r\n    listener: (\r\n    this: WebSocket_2,\r\n    request: ClientRequest,\r\n    response: IncomingMessage,\r\n    ) => void,\r\n    ): this\r\n    once(\r\n    event: string | symbol,\r\n    listener: (this: WebSocket_2, ...args: any[]) => void,\r\n    ): this\r\n\r\n    off(\r\n    event: 'close',\r\n    listener: (this: WebSocket_2, code: number, reason: Buffer) => void,\r\n    ): this\r\n    off(event: 'error', listener: (this: WebSocket_2, err: Error) => void): this\r\n    off(\r\n    event: 'upgrade',\r\n    listener: (this: WebSocket_2, request: IncomingMessage) => void,\r\n    ): this\r\n    off(\r\n    event: 'message',\r\n    listener: (\r\n    this: WebSocket_2,\r\n    data: WebSocket_2.RawData,\r\n    isBinary: boolean,\r\n    ) => void,\r\n    ): this\r\n    off(event: 'open', listener: (this: WebSocket_2) => void): this\r\n    off(\r\n    event: 'ping' | 'pong',\r\n    listener: (this: WebSocket_2, data: Buffer) => void,\r\n    ): this\r\n    off(\r\n    event: 'unexpected-response',\r\n    listener: (\r\n    this: WebSocket_2,\r\n    request: ClientRequest,\r\n    response: IncomingMessage,\r\n    ) => void,\r\n    ): this\r\n    off(\r\n    event: string | symbol,\r\n    listener: (this: WebSocket_2, ...args: any[]) => void,\r\n    ): this\r\n\r\n    addListener(\r\n    event: 'close',\r\n    listener: (code: number, reason: Buffer) => void,\r\n    ): this\r\n    addListener(event: 'error', listener: (err: Error) => void): this\r\n    addListener(\r\n    event: 'upgrade',\r\n    listener: (request: IncomingMessage) => void,\r\n    ): this\r\n    addListener(\r\n    event: 'message',\r\n    listener: (data: WebSocket_2.RawData, isBinary: boolean) => void,\r\n    ): this\r\n    addListener(event: 'open', listener: () => void): this\r\n    addListener(event: 'ping' | 'pong', listener: (data: Buffer) => void): this\r\n    addListener(\r\n    event: 'unexpected-response',\r\n    listener: (request: ClientRequest, response: IncomingMessage) => void,\r\n    ): this\r\n    addListener(event: string | symbol, listener: (...args: any[]) => void): this\r\n\r\n    removeListener(\r\n    event: 'close',\r\n    listener: (code: number, reason: Buffer) => void,\r\n    ): this\r\n    removeListener(event: 'error', listener: (err: Error) => void): this\r\n    removeListener(\r\n    event: 'upgrade',\r\n    listener: (request: IncomingMessage) => void,\r\n    ): this\r\n    removeListener(\r\n    event: 'message',\r\n    listener: (data: WebSocket_2.RawData, isBinary: boolean) => void,\r\n    ): this\r\n    removeListener(event: 'open', listener: () => void): this\r\n    removeListener(event: 'ping' | 'pong', listener: (data: Buffer) => void): this\r\n    removeListener(\r\n    event: 'unexpected-response',\r\n    listener: (request: ClientRequest, response: IncomingMessage) => void,\r\n    ): this\r\n    removeListener(\r\n    event: string | symbol,\r\n    listener: (...args: any[]) => void,\r\n    ): this\r\n}\r\n\r\ndeclare namespace WebSocket_2 {\r\n    /**\r\n     * Data represents the raw message payload received over the WebSocket.\r\n     */\r\n    type RawData = Buffer | ArrayBuffer | Buffer[]\r\n\r\n    /**\r\n     * Data represents the message payload received over the WebSocket.\r\n     */\r\n    type Data = string | Buffer | ArrayBuffer | Buffer[]\r\n\r\n    /**\r\n     * CertMeta represents the accepted types for certificate & key data.\r\n     */\r\n    type CertMeta = string | string[] | Buffer | Buffer[]\r\n\r\n    /**\r\n     * VerifyClientCallbackSync is a synchronous callback used to inspect the\r\n     * incoming message. The return value (boolean) of the function determines\r\n     * whether or not to accept the handshake.\r\n     */\r\n    type VerifyClientCallbackSync = (info: {\r\n        origin: string\r\n        secure: boolean\r\n        req: IncomingMessage\r\n    }) => boolean\r\n\r\n    /**\r\n     * VerifyClientCallbackAsync is an asynchronous callback used to inspect the\r\n     * incoming message. The return value (boolean) of the function determines\r\n     * whether or not to accept the handshake.\r\n     */\r\n    type VerifyClientCallbackAsync = (\r\n    info: { origin: string; secure: boolean; req: IncomingMessage },\r\n    callback: (\r\n    res: boolean,\r\n    code?: number,\r\n    message?: string,\r\n    headers?: OutgoingHttpHeaders,\r\n    ) => void,\r\n    ) => void\r\n\r\n    interface ClientOptions extends SecureContextOptions {\r\n        protocol?: string | undefined\r\n        followRedirects?: boolean | undefined\r\n        generateMask?(mask: Buffer): void\r\n        handshakeTimeout?: number | undefined\r\n        maxRedirects?: number | undefined\r\n        perMessageDeflate?: boolean | PerMessageDeflateOptions | undefined\r\n        localAddress?: string | undefined\r\n        protocolVersion?: number | undefined\r\n        headers?: { [key: string]: string } | undefined\r\n        origin?: string | undefined\r\n        agent?: Agent | undefined\r\n        host?: string | undefined\r\n        family?: number | undefined\r\n        checkServerIdentity?(servername: string, cert: CertMeta): boolean\r\n        rejectUnauthorized?: boolean | undefined\r\n        maxPayload?: number | undefined\r\n        skipUTF8Validation?: boolean | undefined\r\n    }\r\n\r\n    interface PerMessageDeflateOptions {\r\n        serverNoContextTakeover?: boolean | undefined\r\n        clientNoContextTakeover?: boolean | undefined\r\n        serverMaxWindowBits?: number | undefined\r\n        clientMaxWindowBits?: number | undefined\r\n        zlibDeflateOptions?:\r\n        | {\r\n            flush?: number | undefined\r\n            finishFlush?: number | undefined\r\n            chunkSize?: number | undefined\r\n            windowBits?: number | undefined\r\n            level?: number | undefined\r\n            memLevel?: number | undefined\r\n            strategy?: number | undefined\r\n            dictionary?: Buffer | Buffer[] | DataView | undefined\r\n            info?: boolean | undefined\r\n        }\r\n        | undefined\r\n        zlibInflateOptions?: ZlibOptions | undefined\r\n        threshold?: number | undefined\r\n        concurrencyLimit?: number | undefined\r\n    }\r\n\r\n    interface Event {\r\n        type: string\r\n        target: WebSocket\r\n    }\r\n\r\n    interface ErrorEvent {\r\n        error: any\r\n        message: string\r\n        type: string\r\n        target: WebSocket\r\n    }\r\n\r\n    interface CloseEvent {\r\n        wasClean: boolean\r\n        code: number\r\n        reason: string\r\n        type: string\r\n        target: WebSocket\r\n    }\r\n\r\n    interface MessageEvent {\r\n        data: Data\r\n        type: string\r\n        target: WebSocket\r\n    }\r\n\r\n    interface EventListenerOptions {\r\n        once?: boolean | undefined\r\n    }\r\n\r\n    interface ServerOptions {\r\n        host?: string | undefined\r\n        port?: number | undefined\r\n        backlog?: number | undefined\r\n        server?: Server | Server_2 | undefined\r\n        verifyClient?:\r\n        | VerifyClientCallbackAsync\r\n        | VerifyClientCallbackSync\r\n        | undefined\r\n        handleProtocols?: (\r\n        protocols: Set<string>,\r\n        request: IncomingMessage,\r\n        ) => string | false\r\n        path?: string | undefined\r\n        noServer?: boolean | undefined\r\n        clientTracking?: boolean | undefined\r\n        perMessageDeflate?: boolean | PerMessageDeflateOptions | undefined\r\n        maxPayload?: number | undefined\r\n        skipUTF8Validation?: boolean | undefined\r\n        WebSocket?: typeof WebSocket.WebSocket | undefined\r\n    }\r\n\r\n    interface AddressInfo {\r\n        address: string\r\n        family: string\r\n        port: number\r\n    }\r\n\r\n    // WebSocket Server\r\n    class Server<T extends WebSocket = WebSocket> extends EventEmitter {\r\n        options: ServerOptions\r\n        path: string\r\n        clients: Set<T>\r\n\r\n        constructor(options?: ServerOptions, callback?: () => void)\r\n\r\n        address(): AddressInfo | string\r\n        close(cb?: (err?: Error) => void): void\r\n        handleUpgrade(\r\n        request: IncomingMessage,\r\n        socket: Duplex,\r\n        upgradeHead: Buffer,\r\n        callback: (client: T, request: IncomingMessage) => void,\r\n        ): void\r\n        shouldHandle(request: IncomingMessage): boolean | Promise<boolean>\r\n\r\n        // Events\r\n        on(\r\n        event: 'connection',\r\n        cb: (this: Server<T>, socket: T, request: IncomingMessage) => void,\r\n        ): this\r\n        on(event: 'error', cb: (this: Server<T>, error: Error) => void): this\r\n        on(\r\n        event: 'headers',\r\n        cb: (\r\n        this: Server<T>,\r\n        headers: string[],\r\n        request: IncomingMessage,\r\n        ) => void,\r\n        ): this\r\n        on(event: 'close' | 'listening', cb: (this: Server<T>) => void): this\r\n        on(\r\n        event: string | symbol,\r\n        listener: (this: Server<T>, ...args: any[]) => void,\r\n        ): this\r\n\r\n        once(\r\n        event: 'connection',\r\n        cb: (this: Server<T>, socket: T, request: IncomingMessage) => void,\r\n        ): this\r\n        once(event: 'error', cb: (this: Server<T>, error: Error) => void): this\r\n        once(\r\n        event: 'headers',\r\n        cb: (\r\n        this: Server<T>,\r\n        headers: string[],\r\n        request: IncomingMessage,\r\n        ) => void,\r\n        ): this\r\n        once(event: 'close' | 'listening', cb: (this: Server<T>) => void): this\r\n        once(\r\n        event: string | symbol,\r\n        listener: (this: Server<T>, ...args: any[]) => void,\r\n        ): this\r\n\r\n        off(\r\n        event: 'connection',\r\n        cb: (this: Server<T>, socket: T, request: IncomingMessage) => void,\r\n        ): this\r\n        off(event: 'error', cb: (this: Server<T>, error: Error) => void): this\r\n        off(\r\n        event: 'headers',\r\n        cb: (\r\n        this: Server<T>,\r\n        headers: string[],\r\n        request: IncomingMessage,\r\n        ) => void,\r\n        ): this\r\n        off(event: 'close' | 'listening', cb: (this: Server<T>) => void): this\r\n        off(\r\n        event: string | symbol,\r\n        listener: (this: Server<T>, ...args: any[]) => void,\r\n        ): this\r\n\r\n        addListener(\r\n        event: 'connection',\r\n        cb: (client: T, request: IncomingMessage) => void,\r\n        ): this\r\n        addListener(event: 'error', cb: (err: Error) => void): this\r\n        addListener(\r\n        event: 'headers',\r\n        cb: (headers: string[], request: IncomingMessage) => void,\r\n        ): this\r\n        addListener(event: 'close' | 'listening', cb: () => void): this\r\n        addListener(\r\n        event: string | symbol,\r\n        listener: (...args: any[]) => void,\r\n        ): this\r\n\r\n        removeListener(event: 'connection', cb: (client: T) => void): this\r\n        removeListener(event: 'error', cb: (err: Error) => void): this\r\n        removeListener(\r\n        event: 'headers',\r\n        cb: (headers: string[], request: IncomingMessage) => void,\r\n        ): this\r\n        removeListener(event: 'close' | 'listening', cb: () => void): this\r\n        removeListener(\r\n        event: string | symbol,\r\n        listener: (...args: any[]) => void,\r\n        ): this\r\n    }\r\n\r\n    const WebSocketServer: typeof Server\r\n    interface WebSocketServer extends Server {} // tslint:disable-line no-empty-interface\r\n    const WebSocket: typeof WebSocketAlias\r\n    interface WebSocket extends WebSocketAlias {} // tslint:disable-line no-empty-interface\r\n\r\n    // WebSocket stream\r\n    function createWebSocketStream(\r\n    websocket: WebSocket,\r\n    options?: DuplexOptions,\r\n    ): Duplex\r\n}\r\nexport { WebSocket_2 as WebSocket }\r\n\r\nexport declare const WebSocketAlias: typeof WebSocket_2;\r\n\r\nexport declare interface WebSocketAlias extends WebSocket_2 {}\r\n\r\nexport declare interface WebSocketClient {\r\n    /**\r\n     * Send event to the client\r\n     */\r\n    send(payload: HMRPayload): void;\r\n    /**\r\n     * Send custom event\r\n     */\r\n    send(event: string, payload?: CustomPayload['data']): void;\r\n    /**\r\n     * The raw WebSocket instance\r\n     * @advanced\r\n     */\r\n    socket: WebSocket_2;\r\n}\r\n\r\nexport declare type WebSocketCustomListener<T> = (data: T, client: WebSocketClient) => void;\r\n\r\nexport declare interface WebSocketServer {\r\n    /**\r\n     * Get all connected clients.\r\n     */\r\n    clients: Set<WebSocketClient>;\r\n    /**\r\n     * Broadcast events to all clients\r\n     */\r\n    send(payload: HMRPayload): void;\r\n    /**\r\n     * Send custom event\r\n     */\r\n    send<T extends string>(event: T, payload?: InferCustomEventPayload<T>): void;\r\n    /**\r\n     * Disconnect all clients and terminate the server.\r\n     */\r\n    close(): Promise<void>;\r\n    /**\r\n     * Handle custom event emitted by `import.meta.hot.send`\r\n     */\r\n    on: WebSocket_2.Server['on'] & {\r\n        <T extends string>(event: T, listener: WebSocketCustomListener<InferCustomEventPayload<T>>): void;\r\n    };\r\n    /**\r\n     * Unregister event listener.\r\n     */\r\n    off: WebSocket_2.Server['off'] & {\r\n        (event: string, listener: Function): void;\r\n    };\r\n}\r\n\r\nexport { }\r\n"}},"index.js":{"file":{"contents":"export { b as build, e as buildErrorMessage, u as createFilter, w as createLogger, c as createServer, g as defineConfig, f as formatPostcssSourceMap, j as getDepOptimizationConfig, k as isDepsOptimizerEnabled, l as loadConfigFromFile, y as loadEnv, q as mergeAlias, m as mergeConfig, n as normalizePath, o as optimizeDeps, a as preprocessCSS, p as preview, i as resolveBaseUrl, h as resolveConfig, z as resolveEnvPrefix, d as resolvePackageData, r as resolvePackageEntry, x as searchForWorkspaceRoot, v as send, s as sortUserPlugins, t as transformWithEsbuild } from './chunks/dep-ca21228b.js';\nexport { VERSION as version } from './constants.js';\nexport { version as esbuildVersion } from 'esbuild';\nexport { VERSION as rollupVersion } from 'rollup';\nimport 'node:fs';\nimport 'node:path';\nimport 'node:url';\nimport 'node:perf_hooks';\nimport 'node:module';\nimport 'tty';\nimport 'path';\nimport './chunks/dep-ace95160.js';\nimport 'fs';\nimport 'events';\nimport 'assert';\nimport 'util';\nimport 'net';\nimport 'url';\nimport 'http';\nimport 'stream';\nimport 'os';\nimport 'child_process';\nimport 'node:os';\nimport 'node:crypto';\nimport 'node:util';\nimport 'node:dns';\nimport 'resolve';\nimport 'crypto';\nimport 'node:buffer';\nimport 'module';\nimport 'node:assert';\nimport 'node:process';\nimport 'node:v8';\nimport 'worker_threads';\nimport 'zlib';\nimport 'buffer';\nimport 'https';\nimport 'tls';\nimport 'node:http';\nimport 'node:https';\nimport 'querystring';\nimport 'node:child_process';\nimport 'node:readline';\nimport 'node:zlib';\n\n// This file will be built for both ESM and CJS. Avoid relying on other modules as possible.\n// copy from constants.ts\nconst CSS_LANGS_RE = \n// eslint-disable-next-line regexp/no-unused-capturing-group\n/\\.(css|less|sass|scss|styl|stylus|pcss|postcss|sss)(?:$|\\?)/;\nconst isCSSRequest = (request) => CSS_LANGS_RE.test(request);\n// Use splitVendorChunkPlugin() to get the same manualChunks strategy as Vite 2.7\n// We don't recommend using this strategy as a general solution moving forward\n// splitVendorChunk is a simple index/vendor strategy that was used in Vite\n// until v2.8. It is exposed to let people continue to use it in case it was\n// working well for their setups.\n// The cache needs to be reset on buildStart for watch mode to work correctly\n// Don't use this manualChunks strategy for ssr, lib mode, and 'umd' or 'iife'\nclass SplitVendorChunkCache {\n    constructor() {\n        this.cache = new Map();\n    }\n    reset() {\n        this.cache = new Map();\n    }\n}\nfunction splitVendorChunk(options = {}) {\n    const cache = options.cache ?? new SplitVendorChunkCache();\n    return (id, { getModuleInfo }) => {\n        if (id.includes('node_modules') &&\n            !isCSSRequest(id) &&\n            staticImportedByEntry(id, getModuleInfo, cache.cache)) {\n            return 'vendor';\n        }\n    };\n}\nfunction staticImportedByEntry(id, getModuleInfo, cache, importStack = []) {\n    if (cache.has(id)) {\n        return cache.get(id);\n    }\n    if (importStack.includes(id)) {\n        // circular deps!\n        cache.set(id, false);\n        return false;\n    }\n    const mod = getModuleInfo(id);\n    if (!mod) {\n        cache.set(id, false);\n        return false;\n    }\n    if (mod.isEntry) {\n        cache.set(id, true);\n        return true;\n    }\n    const someImporterIs = mod.importers.some((importer) => staticImportedByEntry(importer, getModuleInfo, cache, importStack.concat(id)));\n    cache.set(id, someImporterIs);\n    return someImporterIs;\n}\nfunction splitVendorChunkPlugin() {\n    const caches = [];\n    function createSplitVendorChunk(output, config) {\n        const cache = new SplitVendorChunkCache();\n        caches.push(cache);\n        const build = config.build ?? {};\n        const format = output?.format;\n        if (!build.ssr && !build.lib && format !== 'umd' && format !== 'iife') {\n            return splitVendorChunk({ cache });\n        }\n    }\n    return {\n        name: 'vite:split-vendor-chunk',\n        config(config) {\n            let outputs = config?.build?.rollupOptions?.output;\n            if (outputs) {\n                outputs = Array.isArray(outputs) ? outputs : [outputs];\n                for (const output of outputs) {\n                    const viteManualChunks = createSplitVendorChunk(output, config);\n                    if (viteManualChunks) {\n                        if (output.manualChunks) {\n                            if (typeof output.manualChunks === 'function') {\n                                const userManualChunks = output.manualChunks;\n                                output.manualChunks = (id, api) => {\n                                    return userManualChunks(id, api) ?? viteManualChunks(id, api);\n                                };\n                            }\n                            // else, leave the object form of manualChunks untouched, as\n                            // we can't safely replicate rollup handling.\n                        }\n                        else {\n                            output.manualChunks = viteManualChunks;\n                        }\n                    }\n                }\n            }\n            else {\n                return {\n                    build: {\n                        rollupOptions: {\n                            output: {\n                                manualChunks: createSplitVendorChunk({}, config),\n                            },\n                        },\n                    },\n                };\n            }\n        },\n        buildStart() {\n            caches.forEach((cache) => cache.reset());\n        },\n    };\n}\n\nexport { isCSSRequest, splitVendorChunk, splitVendorChunkPlugin };\n"}}}},"node-cjs":{"directory":{"publicUtils.cjs":{"file":{"contents":"'use strict';\n\nvar path$3 = require('node:path');\nvar node_url = require('node:url');\nvar fs$1 = require('node:fs');\nvar esbuild = require('esbuild');\nvar rollup = require('rollup');\nvar os$1 = require('node:os');\nvar node_util = require('node:util');\nvar node_module = require('node:module');\nvar require$$0 = require('tty');\nvar require$$1 = require('util');\nvar require$$0$1 = require('path');\nvar require$$0$2 = require('crypto');\nvar require$$1$1 = require('fs');\nvar readline = require('node:readline');\nvar require$$2 = require('os');\n\nconst { version: version$2 } = JSON.parse(fs$1.readFileSync(new URL('../../package.json', (typeof document === 'undefined' ? new (require('u' + 'rl').URL)('file:' + __filename).href : (document.currentScript && document.currentScript.src || new URL('node-cjs/publicUtils.cjs', document.baseURI).href)))).toString());\nconst VERSION = version$2;\nconst VITE_PACKAGE_DIR = path$3.resolve(\n// import.meta.url is `dist/node/constants.js` after bundle\nnode_url.fileURLToPath((typeof document === 'undefined' ? new (require('u' + 'rl').URL)('file:' + __filename).href : (document.currentScript && document.currentScript.src || new URL('node-cjs/publicUtils.cjs', document.baseURI).href))), '../../..');\nconst CLIENT_ENTRY = path$3.resolve(VITE_PACKAGE_DIR, 'dist/client/client.mjs');\npath$3.resolve(VITE_PACKAGE_DIR, 'dist/client/env.mjs');\npath$3.dirname(CLIENT_ENTRY);\n\n// This file will be built for both ESM and CJS. Avoid relying on other modules as possible.\n// copy from constants.ts\nconst CSS_LANGS_RE = \n// eslint-disable-next-line regexp/no-unused-capturing-group\n/\\.(css|less|sass|scss|styl|stylus|pcss|postcss|sss)(?:$|\\?)/;\nconst isCSSRequest = (request) => CSS_LANGS_RE.test(request);\n// Use splitVendorChunkPlugin() to get the same manualChunks strategy as Vite 2.7\n// We don't recommend using this strategy as a general solution moving forward\n// splitVendorChunk is a simple index/vendor strategy that was used in Vite\n// until v2.8. It is exposed to let people continue to use it in case it was\n// working well for their setups.\n// The cache needs to be reset on buildStart for watch mode to work correctly\n// Don't use this manualChunks strategy for ssr, lib mode, and 'umd' or 'iife'\nclass SplitVendorChunkCache {\n    constructor() {\n        this.cache = new Map();\n    }\n    reset() {\n        this.cache = new Map();\n    }\n}\nfunction splitVendorChunk(options = {}) {\n    const cache = options.cache ?? new SplitVendorChunkCache();\n    return (id, { getModuleInfo }) => {\n        if (id.includes('node_modules') &&\n            !isCSSRequest(id) &&\n            staticImportedByEntry(id, getModuleInfo, cache.cache)) {\n            return 'vendor';\n        }\n    };\n}\nfunction staticImportedByEntry(id, getModuleInfo, cache, importStack = []) {\n    if (cache.has(id)) {\n        return cache.get(id);\n    }\n    if (importStack.includes(id)) {\n        // circular deps!\n        cache.set(id, false);\n        return false;\n    }\n    const mod = getModuleInfo(id);\n    if (!mod) {\n        cache.set(id, false);\n        return false;\n    }\n    if (mod.isEntry) {\n        cache.set(id, true);\n        return true;\n    }\n    const someImporterIs = mod.importers.some((importer) => staticImportedByEntry(importer, getModuleInfo, cache, importStack.concat(id)));\n    cache.set(id, someImporterIs);\n    return someImporterIs;\n}\nfunction splitVendorChunkPlugin() {\n    const caches = [];\n    function createSplitVendorChunk(output, config) {\n        const cache = new SplitVendorChunkCache();\n        caches.push(cache);\n        const build = config.build ?? {};\n        const format = output?.format;\n        if (!build.ssr && !build.lib && format !== 'umd' && format !== 'iife') {\n            return splitVendorChunk({ cache });\n        }\n    }\n    return {\n        name: 'vite:split-vendor-chunk',\n        config(config) {\n            let outputs = config?.build?.rollupOptions?.output;\n            if (outputs) {\n                outputs = Array.isArray(outputs) ? outputs : [outputs];\n                for (const output of outputs) {\n                    const viteManualChunks = createSplitVendorChunk(output, config);\n                    if (viteManualChunks) {\n                        if (output.manualChunks) {\n                            if (typeof output.manualChunks === 'function') {\n                                const userManualChunks = output.manualChunks;\n                                output.manualChunks = (id, api) => {\n                                    return userManualChunks(id, api) ?? viteManualChunks(id, api);\n                                };\n                            }\n                            // else, leave the object form of manualChunks untouched, as\n                            // we can't safely replicate rollup handling.\n                        }\n                        else {\n                            output.manualChunks = viteManualChunks;\n                        }\n                    }\n                }\n            }\n            else {\n                return {\n                    build: {\n                        rollupOptions: {\n                            output: {\n                                manualChunks: createSplitVendorChunk({}, config),\n                            },\n                        },\n                    },\n                };\n            }\n        },\n        buildStart() {\n            caches.forEach((cache) => cache.reset());\n        },\n    };\n}\n\nconst chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';\nconst intToChar = new Uint8Array(64); // 64 possible chars.\nconst charToInt = new Uint8Array(128); // z is 122 in ASCII\nfor (let i = 0; i < chars.length; i++) {\n    const c = chars.charCodeAt(i);\n    intToChar[i] = c;\n    charToInt[c] = i;\n}\n\n// Matches the scheme of a URL, eg \"http://\"\nvar UrlType;\n(function (UrlType) {\n    UrlType[UrlType[\"Empty\"] = 1] = \"Empty\";\n    UrlType[UrlType[\"Hash\"] = 2] = \"Hash\";\n    UrlType[UrlType[\"Query\"] = 3] = \"Query\";\n    UrlType[UrlType[\"RelativePath\"] = 4] = \"RelativePath\";\n    UrlType[UrlType[\"AbsolutePath\"] = 5] = \"AbsolutePath\";\n    UrlType[UrlType[\"SchemeRelative\"] = 6] = \"SchemeRelative\";\n    UrlType[UrlType[\"Absolute\"] = 7] = \"Absolute\";\n})(UrlType || (UrlType = {}));\n\nfunction getDefaultExportFromCjs (x) {\n\treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n}\n\nvar picocolorsExports = {};\nvar picocolors = {\n  get exports(){ return picocolorsExports; },\n  set exports(v){ picocolorsExports = v; },\n};\n\nlet tty = require$$0;\n\nlet isColorSupported =\n\t!(\"NO_COLOR\" in process.env || process.argv.includes(\"--no-color\")) &&\n\t(\"FORCE_COLOR\" in process.env ||\n\t\tprocess.argv.includes(\"--color\") ||\n\t\tprocess.platform === \"win32\" ||\n\t\t(tty.isatty(1) && process.env.TERM !== \"dumb\") ||\n\t\t\"CI\" in process.env);\n\nlet formatter =\n\t(open, close, replace = open) =>\n\tinput => {\n\t\tlet string = \"\" + input;\n\t\tlet index = string.indexOf(close, open.length);\n\t\treturn ~index\n\t\t\t? open + replaceClose(string, close, replace, index) + close\n\t\t\t: open + string + close\n\t};\n\nlet replaceClose = (string, close, replace, index) => {\n\tlet start = string.substring(0, index) + replace;\n\tlet end = string.substring(index + close.length);\n\tlet nextIndex = end.indexOf(close);\n\treturn ~nextIndex ? start + replaceClose(end, close, replace, nextIndex) : start + end\n};\n\nlet createColors = (enabled = isColorSupported) => ({\n\tisColorSupported: enabled,\n\treset: enabled ? s => `\\x1b[0m${s}\\x1b[0m` : String,\n\tbold: enabled ? formatter(\"\\x1b[1m\", \"\\x1b[22m\", \"\\x1b[22m\\x1b[1m\") : String,\n\tdim: enabled ? formatter(\"\\x1b[2m\", \"\\x1b[22m\", \"\\x1b[22m\\x1b[2m\") : String,\n\titalic: enabled ? formatter(\"\\x1b[3m\", \"\\x1b[23m\") : String,\n\tunderline: enabled ? formatter(\"\\x1b[4m\", \"\\x1b[24m\") : String,\n\tinverse: enabled ? formatter(\"\\x1b[7m\", \"\\x1b[27m\") : String,\n\thidden: enabled ? formatter(\"\\x1b[8m\", \"\\x1b[28m\") : String,\n\tstrikethrough: enabled ? formatter(\"\\x1b[9m\", \"\\x1b[29m\") : String,\n\tblack: enabled ? formatter(\"\\x1b[30m\", \"\\x1b[39m\") : String,\n\tred: enabled ? formatter(\"\\x1b[31m\", \"\\x1b[39m\") : String,\n\tgreen: enabled ? formatter(\"\\x1b[32m\", \"\\x1b[39m\") : String,\n\tyellow: enabled ? formatter(\"\\x1b[33m\", \"\\x1b[39m\") : String,\n\tblue: enabled ? formatter(\"\\x1b[34m\", \"\\x1b[39m\") : String,\n\tmagenta: enabled ? formatter(\"\\x1b[35m\", \"\\x1b[39m\") : String,\n\tcyan: enabled ? formatter(\"\\x1b[36m\", \"\\x1b[39m\") : String,\n\twhite: enabled ? formatter(\"\\x1b[37m\", \"\\x1b[39m\") : String,\n\tgray: enabled ? formatter(\"\\x1b[90m\", \"\\x1b[39m\") : String,\n\tbgBlack: enabled ? formatter(\"\\x1b[40m\", \"\\x1b[49m\") : String,\n\tbgRed: enabled ? formatter(\"\\x1b[41m\", \"\\x1b[49m\") : String,\n\tbgGreen: enabled ? formatter(\"\\x1b[42m\", \"\\x1b[49m\") : String,\n\tbgYellow: enabled ? formatter(\"\\x1b[43m\", \"\\x1b[49m\") : String,\n\tbgBlue: enabled ? formatter(\"\\x1b[44m\", \"\\x1b[49m\") : String,\n\tbgMagenta: enabled ? formatter(\"\\x1b[45m\", \"\\x1b[49m\") : String,\n\tbgCyan: enabled ? formatter(\"\\x1b[46m\", \"\\x1b[49m\") : String,\n\tbgWhite: enabled ? formatter(\"\\x1b[47m\", \"\\x1b[49m\") : String,\n});\n\npicocolors.exports = createColors();\npicocolorsExports.createColors = createColors;\n\nvar srcExports = {};\nvar src = {\n  get exports(){ return srcExports; },\n  set exports(v){ srcExports = v; },\n};\n\nvar browserExports = {};\nvar browser = {\n  get exports(){ return browserExports; },\n  set exports(v){ browserExports = v; },\n};\n\n/**\n * Helpers.\n */\n\nvar ms;\nvar hasRequiredMs;\n\nfunction requireMs () {\n\tif (hasRequiredMs) return ms;\n\thasRequiredMs = 1;\n\tvar s = 1000;\n\tvar m = s * 60;\n\tvar h = m * 60;\n\tvar d = h * 24;\n\tvar w = d * 7;\n\tvar y = d * 365.25;\n\n\t/**\n\t * Parse or format the given `val`.\n\t *\n\t * Options:\n\t *\n\t *  - `long` verbose formatting [false]\n\t *\n\t * @param {String|Number} val\n\t * @param {Object} [options]\n\t * @throws {Error} throw an error if val is not a non-empty string or a number\n\t * @return {String|Number}\n\t * @api public\n\t */\n\n\tms = function(val, options) {\n\t  options = options || {};\n\t  var type = typeof val;\n\t  if (type === 'string' && val.length > 0) {\n\t    return parse(val);\n\t  } else if (type === 'number' && isFinite(val)) {\n\t    return options.long ? fmtLong(val) : fmtShort(val);\n\t  }\n\t  throw new Error(\n\t    'val is not a non-empty string or a valid number. val=' +\n\t      JSON.stringify(val)\n\t  );\n\t};\n\n\t/**\n\t * Parse the given `str` and return milliseconds.\n\t *\n\t * @param {String} str\n\t * @return {Number}\n\t * @api private\n\t */\n\n\tfunction parse(str) {\n\t  str = String(str);\n\t  if (str.length > 100) {\n\t    return;\n\t  }\n\t  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n\t    str\n\t  );\n\t  if (!match) {\n\t    return;\n\t  }\n\t  var n = parseFloat(match[1]);\n\t  var type = (match[2] || 'ms').toLowerCase();\n\t  switch (type) {\n\t    case 'years':\n\t    case 'year':\n\t    case 'yrs':\n\t    case 'yr':\n\t    case 'y':\n\t      return n * y;\n\t    case 'weeks':\n\t    case 'week':\n\t    case 'w':\n\t      return n * w;\n\t    case 'days':\n\t    case 'day':\n\t    case 'd':\n\t      return n * d;\n\t    case 'hours':\n\t    case 'hour':\n\t    case 'hrs':\n\t    case 'hr':\n\t    case 'h':\n\t      return n * h;\n\t    case 'minutes':\n\t    case 'minute':\n\t    case 'mins':\n\t    case 'min':\n\t    case 'm':\n\t      return n * m;\n\t    case 'seconds':\n\t    case 'second':\n\t    case 'secs':\n\t    case 'sec':\n\t    case 's':\n\t      return n * s;\n\t    case 'milliseconds':\n\t    case 'millisecond':\n\t    case 'msecs':\n\t    case 'msec':\n\t    case 'ms':\n\t      return n;\n\t    default:\n\t      return undefined;\n\t  }\n\t}\n\n\t/**\n\t * Short format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\n\tfunction fmtShort(ms) {\n\t  var msAbs = Math.abs(ms);\n\t  if (msAbs >= d) {\n\t    return Math.round(ms / d) + 'd';\n\t  }\n\t  if (msAbs >= h) {\n\t    return Math.round(ms / h) + 'h';\n\t  }\n\t  if (msAbs >= m) {\n\t    return Math.round(ms / m) + 'm';\n\t  }\n\t  if (msAbs >= s) {\n\t    return Math.round(ms / s) + 's';\n\t  }\n\t  return ms + 'ms';\n\t}\n\n\t/**\n\t * Long format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\n\tfunction fmtLong(ms) {\n\t  var msAbs = Math.abs(ms);\n\t  if (msAbs >= d) {\n\t    return plural(ms, msAbs, d, 'day');\n\t  }\n\t  if (msAbs >= h) {\n\t    return plural(ms, msAbs, h, 'hour');\n\t  }\n\t  if (msAbs >= m) {\n\t    return plural(ms, msAbs, m, 'minute');\n\t  }\n\t  if (msAbs >= s) {\n\t    return plural(ms, msAbs, s, 'second');\n\t  }\n\t  return ms + ' ms';\n\t}\n\n\t/**\n\t * Pluralization helper.\n\t */\n\n\tfunction plural(ms, msAbs, n, name) {\n\t  var isPlural = msAbs >= n * 1.5;\n\t  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n\t}\n\treturn ms;\n}\n\nvar common;\nvar hasRequiredCommon;\n\nfunction requireCommon () {\n\tif (hasRequiredCommon) return common;\n\thasRequiredCommon = 1;\n\t/**\n\t * This is the common logic for both the Node.js and web browser\n\t * implementations of `debug()`.\n\t */\n\n\tfunction setup(env) {\n\t\tcreateDebug.debug = createDebug;\n\t\tcreateDebug.default = createDebug;\n\t\tcreateDebug.coerce = coerce;\n\t\tcreateDebug.disable = disable;\n\t\tcreateDebug.enable = enable;\n\t\tcreateDebug.enabled = enabled;\n\t\tcreateDebug.humanize = requireMs();\n\t\tcreateDebug.destroy = destroy;\n\n\t\tObject.keys(env).forEach(key => {\n\t\t\tcreateDebug[key] = env[key];\n\t\t});\n\n\t\t/**\n\t\t* The currently active debug mode names, and names to skip.\n\t\t*/\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\t/**\n\t\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t\t*\n\t\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t\t*/\n\t\tcreateDebug.formatters = {};\n\n\t\t/**\n\t\t* Selects a color for a debug namespace\n\t\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t\t* @return {Number|String} An ANSI color code for the given namespace\n\t\t* @api private\n\t\t*/\n\t\tfunction selectColor(namespace) {\n\t\t\tlet hash = 0;\n\n\t\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\t\thash |= 0; // Convert to 32bit integer\n\t\t\t}\n\n\t\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t\t}\n\t\tcreateDebug.selectColor = selectColor;\n\n\t\t/**\n\t\t* Create a debugger with the given `namespace`.\n\t\t*\n\t\t* @param {String} namespace\n\t\t* @return {Function}\n\t\t* @api public\n\t\t*/\n\t\tfunction createDebug(namespace) {\n\t\t\tlet prevTime;\n\t\t\tlet enableOverride = null;\n\t\t\tlet namespacesCache;\n\t\t\tlet enabledCache;\n\n\t\t\tfunction debug(...args) {\n\t\t\t\t// Disabled?\n\t\t\t\tif (!debug.enabled) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tconst self = debug;\n\n\t\t\t\t// Set `diff` timestamp\n\t\t\t\tconst curr = Number(new Date());\n\t\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\t\tself.diff = ms;\n\t\t\t\tself.prev = prevTime;\n\t\t\t\tself.curr = curr;\n\t\t\t\tprevTime = curr;\n\n\t\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\t\targs.unshift('%O');\n\t\t\t\t}\n\n\t\t\t\t// Apply any `formatters` transformations\n\t\t\t\tlet index = 0;\n\t\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\t\tif (match === '%%') {\n\t\t\t\t\t\treturn '%';\n\t\t\t\t\t}\n\t\t\t\t\tindex++;\n\t\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\t\tconst val = args[index];\n\t\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\t\tindex--;\n\t\t\t\t\t}\n\t\t\t\t\treturn match;\n\t\t\t\t});\n\n\t\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\t\tlogFn.apply(self, args);\n\t\t\t}\n\n\t\t\tdebug.namespace = namespace;\n\t\t\tdebug.useColors = createDebug.useColors();\n\t\t\tdebug.color = createDebug.selectColor(namespace);\n\t\t\tdebug.extend = extend;\n\t\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\t\tenumerable: true,\n\t\t\t\tconfigurable: false,\n\t\t\t\tget: () => {\n\t\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\t\treturn enableOverride;\n\t\t\t\t\t}\n\t\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t\t}\n\n\t\t\t\t\treturn enabledCache;\n\t\t\t\t},\n\t\t\t\tset: v => {\n\t\t\t\t\tenableOverride = v;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\t// Env-specific initialization logic for debug instances\n\t\t\tif (typeof createDebug.init === 'function') {\n\t\t\t\tcreateDebug.init(debug);\n\t\t\t}\n\n\t\t\treturn debug;\n\t\t}\n\n\t\tfunction extend(namespace, delimiter) {\n\t\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\t\tnewDebug.log = this.log;\n\t\t\treturn newDebug;\n\t\t}\n\n\t\t/**\n\t\t* Enables a debug mode by namespaces. This can include modes\n\t\t* separated by a colon and wildcards.\n\t\t*\n\t\t* @param {String} namespaces\n\t\t* @api public\n\t\t*/\n\t\tfunction enable(namespaces) {\n\t\t\tcreateDebug.save(namespaces);\n\t\t\tcreateDebug.namespaces = namespaces;\n\n\t\t\tcreateDebug.names = [];\n\t\t\tcreateDebug.skips = [];\n\n\t\t\tlet i;\n\t\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\t\tconst len = split.length;\n\n\t\t\tfor (i = 0; i < len; i++) {\n\t\t\t\tif (!split[i]) {\n\t\t\t\t\t// ignore empty strings\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\t\tif (namespaces[0] === '-') {\n\t\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t\t} else {\n\t\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t* Disable debug output.\n\t\t*\n\t\t* @return {String} namespaces\n\t\t* @api public\n\t\t*/\n\t\tfunction disable() {\n\t\t\tconst namespaces = [\n\t\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t\t].join(',');\n\t\t\tcreateDebug.enable('');\n\t\t\treturn namespaces;\n\t\t}\n\n\t\t/**\n\t\t* Returns true if the given mode name is enabled, false otherwise.\n\t\t*\n\t\t* @param {String} name\n\t\t* @return {Boolean}\n\t\t* @api public\n\t\t*/\n\t\tfunction enabled(name) {\n\t\t\tif (name[name.length - 1] === '*') {\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\tlet i;\n\t\t\tlet len;\n\n\t\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn false;\n\t\t}\n\n\t\t/**\n\t\t* Convert regexp to namespace\n\t\t*\n\t\t* @param {RegExp} regxep\n\t\t* @return {String} namespace\n\t\t* @api private\n\t\t*/\n\t\tfunction toNamespace(regexp) {\n\t\t\treturn regexp.toString()\n\t\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t\t}\n\n\t\t/**\n\t\t* Coerce `val`.\n\t\t*\n\t\t* @param {Mixed} val\n\t\t* @return {Mixed}\n\t\t* @api private\n\t\t*/\n\t\tfunction coerce(val) {\n\t\t\tif (val instanceof Error) {\n\t\t\t\treturn val.stack || val.message;\n\t\t\t}\n\t\t\treturn val;\n\t\t}\n\n\t\t/**\n\t\t* XXX DO NOT USE. This is a temporary stub function.\n\t\t* XXX It WILL be removed in the next major release.\n\t\t*/\n\t\tfunction destroy() {\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\n\t\tcreateDebug.enable(createDebug.load());\n\n\t\treturn createDebug;\n\t}\n\n\tcommon = setup;\n\treturn common;\n}\n\n/* eslint-env browser */\n\nvar hasRequiredBrowser;\n\nfunction requireBrowser () {\n\tif (hasRequiredBrowser) return browserExports;\n\thasRequiredBrowser = 1;\n\t(function (module, exports) {\n\t\t/**\n\t\t * This is the web browser implementation of `debug()`.\n\t\t */\n\n\t\texports.formatArgs = formatArgs;\n\t\texports.save = save;\n\t\texports.load = load;\n\t\texports.useColors = useColors;\n\t\texports.storage = localstorage();\n\t\texports.destroy = (() => {\n\t\t\tlet warned = false;\n\n\t\t\treturn () => {\n\t\t\t\tif (!warned) {\n\t\t\t\t\twarned = true;\n\t\t\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t\t\t}\n\t\t\t};\n\t\t})();\n\n\t\t/**\n\t\t * Colors.\n\t\t */\n\n\t\texports.colors = [\n\t\t\t'#0000CC',\n\t\t\t'#0000FF',\n\t\t\t'#0033CC',\n\t\t\t'#0033FF',\n\t\t\t'#0066CC',\n\t\t\t'#0066FF',\n\t\t\t'#0099CC',\n\t\t\t'#0099FF',\n\t\t\t'#00CC00',\n\t\t\t'#00CC33',\n\t\t\t'#00CC66',\n\t\t\t'#00CC99',\n\t\t\t'#00CCCC',\n\t\t\t'#00CCFF',\n\t\t\t'#3300CC',\n\t\t\t'#3300FF',\n\t\t\t'#3333CC',\n\t\t\t'#3333FF',\n\t\t\t'#3366CC',\n\t\t\t'#3366FF',\n\t\t\t'#3399CC',\n\t\t\t'#3399FF',\n\t\t\t'#33CC00',\n\t\t\t'#33CC33',\n\t\t\t'#33CC66',\n\t\t\t'#33CC99',\n\t\t\t'#33CCCC',\n\t\t\t'#33CCFF',\n\t\t\t'#6600CC',\n\t\t\t'#6600FF',\n\t\t\t'#6633CC',\n\t\t\t'#6633FF',\n\t\t\t'#66CC00',\n\t\t\t'#66CC33',\n\t\t\t'#9900CC',\n\t\t\t'#9900FF',\n\t\t\t'#9933CC',\n\t\t\t'#9933FF',\n\t\t\t'#99CC00',\n\t\t\t'#99CC33',\n\t\t\t'#CC0000',\n\t\t\t'#CC0033',\n\t\t\t'#CC0066',\n\t\t\t'#CC0099',\n\t\t\t'#CC00CC',\n\t\t\t'#CC00FF',\n\t\t\t'#CC3300',\n\t\t\t'#CC3333',\n\t\t\t'#CC3366',\n\t\t\t'#CC3399',\n\t\t\t'#CC33CC',\n\t\t\t'#CC33FF',\n\t\t\t'#CC6600',\n\t\t\t'#CC6633',\n\t\t\t'#CC9900',\n\t\t\t'#CC9933',\n\t\t\t'#CCCC00',\n\t\t\t'#CCCC33',\n\t\t\t'#FF0000',\n\t\t\t'#FF0033',\n\t\t\t'#FF0066',\n\t\t\t'#FF0099',\n\t\t\t'#FF00CC',\n\t\t\t'#FF00FF',\n\t\t\t'#FF3300',\n\t\t\t'#FF3333',\n\t\t\t'#FF3366',\n\t\t\t'#FF3399',\n\t\t\t'#FF33CC',\n\t\t\t'#FF33FF',\n\t\t\t'#FF6600',\n\t\t\t'#FF6633',\n\t\t\t'#FF9900',\n\t\t\t'#FF9933',\n\t\t\t'#FFCC00',\n\t\t\t'#FFCC33'\n\t\t];\n\n\t\t/**\n\t\t * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n\t\t * and the Firebug extension (any Firefox version) are known\n\t\t * to support \"%c\" CSS customizations.\n\t\t *\n\t\t * TODO: add a `localStorage` variable to explicitly enable/disable colors\n\t\t */\n\n\t\t// eslint-disable-next-line complexity\n\t\tfunction useColors() {\n\t\t\t// NB: In an Electron preload script, document will be defined but not fully\n\t\t\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t\t\t// explicitly\n\t\t\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\t// Internet Explorer and Edge do not support colors.\n\t\t\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t\t\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\t\t\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t\t\t// Is firefox >= v31?\n\t\t\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n\t\t}\n\n\t\t/**\n\t\t * Colorize log arguments if enabled.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction formatArgs(args) {\n\t\t\targs[0] = (this.useColors ? '%c' : '') +\n\t\t\t\tthis.namespace +\n\t\t\t\t(this.useColors ? ' %c' : ' ') +\n\t\t\t\targs[0] +\n\t\t\t\t(this.useColors ? '%c ' : ' ') +\n\t\t\t\t'+' + module.exports.humanize(this.diff);\n\n\t\t\tif (!this.useColors) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst c = 'color: ' + this.color;\n\t\t\targs.splice(1, 0, c, 'color: inherit');\n\n\t\t\t// The final \"%c\" is somewhat tricky, because there could be other\n\t\t\t// arguments passed either before or after the %c, so we need to\n\t\t\t// figure out the correct index to insert the CSS into\n\t\t\tlet index = 0;\n\t\t\tlet lastC = 0;\n\t\t\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tif (match === '%c') {\n\t\t\t\t\t// We only are interested in the *last* %c\n\t\t\t\t\t// (the user may have provided their own)\n\t\t\t\t\tlastC = index;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\targs.splice(lastC, 0, c);\n\t\t}\n\n\t\t/**\n\t\t * Invokes `console.debug()` when available.\n\t\t * No-op when `console.debug` is not a \"function\".\n\t\t * If `console.debug` is not available, falls back\n\t\t * to `console.log`.\n\t\t *\n\t\t * @api public\n\t\t */\n\t\texports.log = console.debug || console.log || (() => {});\n\n\t\t/**\n\t\t * Save `namespaces`.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api private\n\t\t */\n\t\tfunction save(namespaces) {\n\t\t\ttry {\n\t\t\t\tif (namespaces) {\n\t\t\t\t\texports.storage.setItem('debug', namespaces);\n\t\t\t\t} else {\n\t\t\t\t\texports.storage.removeItem('debug');\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\t// Swallow\n\t\t\t\t// XXX (@Qix-) should we be logging these?\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Load `namespaces`.\n\t\t *\n\t\t * @return {String} returns the previously persisted debug modes\n\t\t * @api private\n\t\t */\n\t\tfunction load() {\n\t\t\tlet r;\n\t\t\ttry {\n\t\t\t\tr = exports.storage.getItem('debug');\n\t\t\t} catch (error) {\n\t\t\t\t// Swallow\n\t\t\t\t// XXX (@Qix-) should we be logging these?\n\t\t\t}\n\n\t\t\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\t\t\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\t\t\tr = process.env.DEBUG;\n\t\t\t}\n\n\t\t\treturn r;\n\t\t}\n\n\t\t/**\n\t\t * Localstorage attempts to return the localstorage.\n\t\t *\n\t\t * This is necessary because safari throws\n\t\t * when a user disables cookies/localstorage\n\t\t * and you attempt to access it.\n\t\t *\n\t\t * @return {LocalStorage}\n\t\t * @api private\n\t\t */\n\n\t\tfunction localstorage() {\n\t\t\ttry {\n\t\t\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t\t\t// The Browser also has localStorage in the global context.\n\t\t\t\treturn localStorage;\n\t\t\t} catch (error) {\n\t\t\t\t// Swallow\n\t\t\t\t// XXX (@Qix-) should we be logging these?\n\t\t\t}\n\t\t}\n\n\t\tmodule.exports = requireCommon()(exports);\n\n\t\tconst {formatters} = module.exports;\n\n\t\t/**\n\t\t * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n\t\t */\n\n\t\tformatters.j = function (v) {\n\t\t\ttry {\n\t\t\t\treturn JSON.stringify(v);\n\t\t\t} catch (error) {\n\t\t\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t\t\t}\n\t\t};\n} (browser, browserExports));\n\treturn browserExports;\n}\n\nvar nodeExports = {};\nvar node = {\n  get exports(){ return nodeExports; },\n  set exports(v){ nodeExports = v; },\n};\n\n/**\n * Module dependencies.\n */\n\nvar hasRequiredNode;\n\nfunction requireNode () {\n\tif (hasRequiredNode) return nodeExports;\n\thasRequiredNode = 1;\n\t(function (module, exports) {\n\t\tconst tty = require$$0;\n\t\tconst util = require$$1;\n\n\t\t/**\n\t\t * This is the Node.js implementation of `debug()`.\n\t\t */\n\n\t\texports.init = init;\n\t\texports.log = log;\n\t\texports.formatArgs = formatArgs;\n\t\texports.save = save;\n\t\texports.load = load;\n\t\texports.useColors = useColors;\n\t\texports.destroy = util.deprecate(\n\t\t\t() => {},\n\t\t\t'Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.'\n\t\t);\n\n\t\t/**\n\t\t * Colors.\n\t\t */\n\n\t\texports.colors = [6, 2, 3, 4, 5, 1];\n\n\t\ttry {\n\t\t\t// Optional dependency (as in, doesn't need to be installed, NOT like optionalDependencies in package.json)\n\t\t\t// eslint-disable-next-line import/no-extraneous-dependencies\n\t\t\tconst supportsColor = require('supports-color');\n\n\t\t\tif (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {\n\t\t\t\texports.colors = [\n\t\t\t\t\t20,\n\t\t\t\t\t21,\n\t\t\t\t\t26,\n\t\t\t\t\t27,\n\t\t\t\t\t32,\n\t\t\t\t\t33,\n\t\t\t\t\t38,\n\t\t\t\t\t39,\n\t\t\t\t\t40,\n\t\t\t\t\t41,\n\t\t\t\t\t42,\n\t\t\t\t\t43,\n\t\t\t\t\t44,\n\t\t\t\t\t45,\n\t\t\t\t\t56,\n\t\t\t\t\t57,\n\t\t\t\t\t62,\n\t\t\t\t\t63,\n\t\t\t\t\t68,\n\t\t\t\t\t69,\n\t\t\t\t\t74,\n\t\t\t\t\t75,\n\t\t\t\t\t76,\n\t\t\t\t\t77,\n\t\t\t\t\t78,\n\t\t\t\t\t79,\n\t\t\t\t\t80,\n\t\t\t\t\t81,\n\t\t\t\t\t92,\n\t\t\t\t\t93,\n\t\t\t\t\t98,\n\t\t\t\t\t99,\n\t\t\t\t\t112,\n\t\t\t\t\t113,\n\t\t\t\t\t128,\n\t\t\t\t\t129,\n\t\t\t\t\t134,\n\t\t\t\t\t135,\n\t\t\t\t\t148,\n\t\t\t\t\t149,\n\t\t\t\t\t160,\n\t\t\t\t\t161,\n\t\t\t\t\t162,\n\t\t\t\t\t163,\n\t\t\t\t\t164,\n\t\t\t\t\t165,\n\t\t\t\t\t166,\n\t\t\t\t\t167,\n\t\t\t\t\t168,\n\t\t\t\t\t169,\n\t\t\t\t\t170,\n\t\t\t\t\t171,\n\t\t\t\t\t172,\n\t\t\t\t\t173,\n\t\t\t\t\t178,\n\t\t\t\t\t179,\n\t\t\t\t\t184,\n\t\t\t\t\t185,\n\t\t\t\t\t196,\n\t\t\t\t\t197,\n\t\t\t\t\t198,\n\t\t\t\t\t199,\n\t\t\t\t\t200,\n\t\t\t\t\t201,\n\t\t\t\t\t202,\n\t\t\t\t\t203,\n\t\t\t\t\t204,\n\t\t\t\t\t205,\n\t\t\t\t\t206,\n\t\t\t\t\t207,\n\t\t\t\t\t208,\n\t\t\t\t\t209,\n\t\t\t\t\t214,\n\t\t\t\t\t215,\n\t\t\t\t\t220,\n\t\t\t\t\t221\n\t\t\t\t];\n\t\t\t}\n\t\t} catch (error) {\n\t\t\t// Swallow - we only care if `supports-color` is available; it doesn't have to be.\n\t\t}\n\n\t\t/**\n\t\t * Build up the default `inspectOpts` object from the environment variables.\n\t\t *\n\t\t *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n\t\t */\n\n\t\texports.inspectOpts = Object.keys(process.env).filter(key => {\n\t\t\treturn /^debug_/i.test(key);\n\t\t}).reduce((obj, key) => {\n\t\t\t// Camel-case\n\t\t\tconst prop = key\n\t\t\t\t.substring(6)\n\t\t\t\t.toLowerCase()\n\t\t\t\t.replace(/_([a-z])/g, (_, k) => {\n\t\t\t\t\treturn k.toUpperCase();\n\t\t\t\t});\n\n\t\t\t// Coerce string value into JS value\n\t\t\tlet val = process.env[key];\n\t\t\tif (/^(yes|on|true|enabled)$/i.test(val)) {\n\t\t\t\tval = true;\n\t\t\t} else if (/^(no|off|false|disabled)$/i.test(val)) {\n\t\t\t\tval = false;\n\t\t\t} else if (val === 'null') {\n\t\t\t\tval = null;\n\t\t\t} else {\n\t\t\t\tval = Number(val);\n\t\t\t}\n\n\t\t\tobj[prop] = val;\n\t\t\treturn obj;\n\t\t}, {});\n\n\t\t/**\n\t\t * Is stdout a TTY? Colored output is enabled when `true`.\n\t\t */\n\n\t\tfunction useColors() {\n\t\t\treturn 'colors' in exports.inspectOpts ?\n\t\t\t\tBoolean(exports.inspectOpts.colors) :\n\t\t\t\ttty.isatty(process.stderr.fd);\n\t\t}\n\n\t\t/**\n\t\t * Adds ANSI color escape codes if enabled.\n\t\t *\n\t\t * @api public\n\t\t */\n\n\t\tfunction formatArgs(args) {\n\t\t\tconst {namespace: name, useColors} = this;\n\n\t\t\tif (useColors) {\n\t\t\t\tconst c = this.color;\n\t\t\t\tconst colorCode = '\\u001B[3' + (c < 8 ? c : '8;5;' + c);\n\t\t\t\tconst prefix = `  ${colorCode};1m${name} \\u001B[0m`;\n\n\t\t\t\targs[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n\t\t\t\targs.push(colorCode + 'm+' + module.exports.humanize(this.diff) + '\\u001B[0m');\n\t\t\t} else {\n\t\t\t\targs[0] = getDate() + name + ' ' + args[0];\n\t\t\t}\n\t\t}\n\n\t\tfunction getDate() {\n\t\t\tif (exports.inspectOpts.hideDate) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\treturn new Date().toISOString() + ' ';\n\t\t}\n\n\t\t/**\n\t\t * Invokes `util.format()` with the specified arguments and writes to stderr.\n\t\t */\n\n\t\tfunction log(...args) {\n\t\t\treturn process.stderr.write(util.format(...args) + '\\n');\n\t\t}\n\n\t\t/**\n\t\t * Save `namespaces`.\n\t\t *\n\t\t * @param {String} namespaces\n\t\t * @api private\n\t\t */\n\t\tfunction save(namespaces) {\n\t\t\tif (namespaces) {\n\t\t\t\tprocess.env.DEBUG = namespaces;\n\t\t\t} else {\n\t\t\t\t// If you set a process.env field to null or undefined, it gets cast to the\n\t\t\t\t// string 'null' or 'undefined'. Just delete instead.\n\t\t\t\tdelete process.env.DEBUG;\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Load `namespaces`.\n\t\t *\n\t\t * @return {String} returns the previously persisted debug modes\n\t\t * @api private\n\t\t */\n\n\t\tfunction load() {\n\t\t\treturn process.env.DEBUG;\n\t\t}\n\n\t\t/**\n\t\t * Init logic for `debug` instances.\n\t\t *\n\t\t * Create a new `inspectOpts` object in case `useColors` is set\n\t\t * differently for a particular `debug` instance.\n\t\t */\n\n\t\tfunction init(debug) {\n\t\t\tdebug.inspectOpts = {};\n\n\t\t\tconst keys = Object.keys(exports.inspectOpts);\n\t\t\tfor (let i = 0; i < keys.length; i++) {\n\t\t\t\tdebug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];\n\t\t\t}\n\t\t}\n\n\t\tmodule.exports = requireCommon()(exports);\n\n\t\tconst {formatters} = module.exports;\n\n\t\t/**\n\t\t * Map %o to `util.inspect()`, all on a single line.\n\t\t */\n\n\t\tformatters.o = function (v) {\n\t\t\tthis.inspectOpts.colors = this.useColors;\n\t\t\treturn util.inspect(v, this.inspectOpts)\n\t\t\t\t.split('\\n')\n\t\t\t\t.map(str => str.trim())\n\t\t\t\t.join(' ');\n\t\t};\n\n\t\t/**\n\t\t * Map %O to `util.inspect()`, allowing multiple lines if needed.\n\t\t */\n\n\t\tformatters.O = function (v) {\n\t\t\tthis.inspectOpts.colors = this.useColors;\n\t\t\treturn util.inspect(v, this.inspectOpts);\n\t\t};\n} (node, nodeExports));\n\treturn nodeExports;\n}\n\n/**\n * Detect Electron renderer / nwjs process, which is node, but we should\n * treat as a browser.\n */\n\n(function (module) {\n\tif (typeof process === 'undefined' || process.type === 'renderer' || process.browser === true || process.__nwjs) {\n\t\tmodule.exports = requireBrowser();\n\t} else {\n\t\tmodule.exports = requireNode();\n\t}\n} (src));\n\nvar debug = /*@__PURE__*/getDefaultExportFromCjs(srcExports);\n\nvar picomatchExports = {};\nvar picomatch$1 = {\n  get exports(){ return picomatchExports; },\n  set exports(v){ picomatchExports = v; },\n};\n\nvar utils$3 = {};\n\nconst path$2 = require$$0$1;\nconst WIN_SLASH = '\\\\\\\\/';\nconst WIN_NO_SLASH = `[^${WIN_SLASH}]`;\n\n/**\n * Posix glob regex\n */\n\nconst DOT_LITERAL = '\\\\.';\nconst PLUS_LITERAL = '\\\\+';\nconst QMARK_LITERAL = '\\\\?';\nconst SLASH_LITERAL = '\\\\/';\nconst ONE_CHAR = '(?=.)';\nconst QMARK = '[^/]';\nconst END_ANCHOR = `(?:${SLASH_LITERAL}|$)`;\nconst START_ANCHOR = `(?:^|${SLASH_LITERAL})`;\nconst DOTS_SLASH = `${DOT_LITERAL}{1,2}${END_ANCHOR}`;\nconst NO_DOT = `(?!${DOT_LITERAL})`;\nconst NO_DOTS = `(?!${START_ANCHOR}${DOTS_SLASH})`;\nconst NO_DOT_SLASH = `(?!${DOT_LITERAL}{0,1}${END_ANCHOR})`;\nconst NO_DOTS_SLASH = `(?!${DOTS_SLASH})`;\nconst QMARK_NO_DOT = `[^.${SLASH_LITERAL}]`;\nconst STAR = `${QMARK}*?`;\n\nconst POSIX_CHARS = {\n  DOT_LITERAL,\n  PLUS_LITERAL,\n  QMARK_LITERAL,\n  SLASH_LITERAL,\n  ONE_CHAR,\n  QMARK,\n  END_ANCHOR,\n  DOTS_SLASH,\n  NO_DOT,\n  NO_DOTS,\n  NO_DOT_SLASH,\n  NO_DOTS_SLASH,\n  QMARK_NO_DOT,\n  STAR,\n  START_ANCHOR\n};\n\n/**\n * Windows glob regex\n */\n\nconst WINDOWS_CHARS = {\n  ...POSIX_CHARS,\n\n  SLASH_LITERAL: `[${WIN_SLASH}]`,\n  QMARK: WIN_NO_SLASH,\n  STAR: `${WIN_NO_SLASH}*?`,\n  DOTS_SLASH: `${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$)`,\n  NO_DOT: `(?!${DOT_LITERAL})`,\n  NO_DOTS: `(?!(?:^|[${WIN_SLASH}])${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,\n  NO_DOT_SLASH: `(?!${DOT_LITERAL}{0,1}(?:[${WIN_SLASH}]|$))`,\n  NO_DOTS_SLASH: `(?!${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,\n  QMARK_NO_DOT: `[^.${WIN_SLASH}]`,\n  START_ANCHOR: `(?:^|[${WIN_SLASH}])`,\n  END_ANCHOR: `(?:[${WIN_SLASH}]|$)`\n};\n\n/**\n * POSIX Bracket Regex\n */\n\nconst POSIX_REGEX_SOURCE$1 = {\n  alnum: 'a-zA-Z0-9',\n  alpha: 'a-zA-Z',\n  ascii: '\\\\x00-\\\\x7F',\n  blank: ' \\\\t',\n  cntrl: '\\\\x00-\\\\x1F\\\\x7F',\n  digit: '0-9',\n  graph: '\\\\x21-\\\\x7E',\n  lower: 'a-z',\n  print: '\\\\x20-\\\\x7E ',\n  punct: '\\\\-!\"#$%&\\'()\\\\*+,./:;<=>?@[\\\\]^_`{|}~',\n  space: ' \\\\t\\\\r\\\\n\\\\v\\\\f',\n  upper: 'A-Z',\n  word: 'A-Za-z0-9_',\n  xdigit: 'A-Fa-f0-9'\n};\n\nvar constants$2 = {\n  MAX_LENGTH: 1024 * 64,\n  POSIX_REGEX_SOURCE: POSIX_REGEX_SOURCE$1,\n\n  // regular expressions\n  REGEX_BACKSLASH: /\\\\(?![*+?^${}(|)[\\]])/g,\n  REGEX_NON_SPECIAL_CHARS: /^[^@![\\].,$*+?^{}()|\\\\/]+/,\n  REGEX_SPECIAL_CHARS: /[-*+?.^${}(|)[\\]]/,\n  REGEX_SPECIAL_CHARS_BACKREF: /(\\\\?)((\\W)(\\3*))/g,\n  REGEX_SPECIAL_CHARS_GLOBAL: /([-*+?.^${}(|)[\\]])/g,\n  REGEX_REMOVE_BACKSLASH: /(?:\\[.*?[^\\\\]\\]|\\\\(?=.))/g,\n\n  // Replace globs with equivalent patterns to reduce parsing time.\n  REPLACEMENTS: {\n    '***': '*',\n    '**/**': '**',\n    '**/**/**': '**'\n  },\n\n  // Digits\n  CHAR_0: 48, /* 0 */\n  CHAR_9: 57, /* 9 */\n\n  // Alphabet chars.\n  CHAR_UPPERCASE_A: 65, /* A */\n  CHAR_LOWERCASE_A: 97, /* a */\n  CHAR_UPPERCASE_Z: 90, /* Z */\n  CHAR_LOWERCASE_Z: 122, /* z */\n\n  CHAR_LEFT_PARENTHESES: 40, /* ( */\n  CHAR_RIGHT_PARENTHESES: 41, /* ) */\n\n  CHAR_ASTERISK: 42, /* * */\n\n  // Non-alphabetic chars.\n  CHAR_AMPERSAND: 38, /* & */\n  CHAR_AT: 64, /* @ */\n  CHAR_BACKWARD_SLASH: 92, /* \\ */\n  CHAR_CARRIAGE_RETURN: 13, /* \\r */\n  CHAR_CIRCUMFLEX_ACCENT: 94, /* ^ */\n  CHAR_COLON: 58, /* : */\n  CHAR_COMMA: 44, /* , */\n  CHAR_DOT: 46, /* . */\n  CHAR_DOUBLE_QUOTE: 34, /* \" */\n  CHAR_EQUAL: 61, /* = */\n  CHAR_EXCLAMATION_MARK: 33, /* ! */\n  CHAR_FORM_FEED: 12, /* \\f */\n  CHAR_FORWARD_SLASH: 47, /* / */\n  CHAR_GRAVE_ACCENT: 96, /* ` */\n  CHAR_HASH: 35, /* # */\n  CHAR_HYPHEN_MINUS: 45, /* - */\n  CHAR_LEFT_ANGLE_BRACKET: 60, /* < */\n  CHAR_LEFT_CURLY_BRACE: 123, /* { */\n  CHAR_LEFT_SQUARE_BRACKET: 91, /* [ */\n  CHAR_LINE_FEED: 10, /* \\n */\n  CHAR_NO_BREAK_SPACE: 160, /* \\u00A0 */\n  CHAR_PERCENT: 37, /* % */\n  CHAR_PLUS: 43, /* + */\n  CHAR_QUESTION_MARK: 63, /* ? */\n  CHAR_RIGHT_ANGLE_BRACKET: 62, /* > */\n  CHAR_RIGHT_CURLY_BRACE: 125, /* } */\n  CHAR_RIGHT_SQUARE_BRACKET: 93, /* ] */\n  CHAR_SEMICOLON: 59, /* ; */\n  CHAR_SINGLE_QUOTE: 39, /* ' */\n  CHAR_SPACE: 32, /*   */\n  CHAR_TAB: 9, /* \\t */\n  CHAR_UNDERSCORE: 95, /* _ */\n  CHAR_VERTICAL_LINE: 124, /* | */\n  CHAR_ZERO_WIDTH_NOBREAK_SPACE: 65279, /* \\uFEFF */\n\n  SEP: path$2.sep,\n\n  /**\n   * Create EXTGLOB_CHARS\n   */\n\n  extglobChars(chars) {\n    return {\n      '!': { type: 'negate', open: '(?:(?!(?:', close: `))${chars.STAR})` },\n      '?': { type: 'qmark', open: '(?:', close: ')?' },\n      '+': { type: 'plus', open: '(?:', close: ')+' },\n      '*': { type: 'star', open: '(?:', close: ')*' },\n      '@': { type: 'at', open: '(?:', close: ')' }\n    };\n  },\n\n  /**\n   * Create GLOB_CHARS\n   */\n\n  globChars(win32) {\n    return win32 === true ? WINDOWS_CHARS : POSIX_CHARS;\n  }\n};\n\n(function (exports) {\n\n\tconst path = require$$0$1;\n\tconst win32 = process.platform === 'win32';\n\tconst {\n\t  REGEX_BACKSLASH,\n\t  REGEX_REMOVE_BACKSLASH,\n\t  REGEX_SPECIAL_CHARS,\n\t  REGEX_SPECIAL_CHARS_GLOBAL\n\t} = constants$2;\n\n\texports.isObject = val => val !== null && typeof val === 'object' && !Array.isArray(val);\n\texports.hasRegexChars = str => REGEX_SPECIAL_CHARS.test(str);\n\texports.isRegexChar = str => str.length === 1 && exports.hasRegexChars(str);\n\texports.escapeRegex = str => str.replace(REGEX_SPECIAL_CHARS_GLOBAL, '\\\\$1');\n\texports.toPosixSlashes = str => str.replace(REGEX_BACKSLASH, '/');\n\n\texports.removeBackslashes = str => {\n\t  return str.replace(REGEX_REMOVE_BACKSLASH, match => {\n\t    return match === '\\\\' ? '' : match;\n\t  });\n\t};\n\n\texports.supportsLookbehinds = () => {\n\t  const segs = process.version.slice(1).split('.').map(Number);\n\t  if (segs.length === 3 && segs[0] >= 9 || (segs[0] === 8 && segs[1] >= 10)) {\n\t    return true;\n\t  }\n\t  return false;\n\t};\n\n\texports.isWindows = options => {\n\t  if (options && typeof options.windows === 'boolean') {\n\t    return options.windows;\n\t  }\n\t  return win32 === true || path.sep === '\\\\';\n\t};\n\n\texports.escapeLast = (input, char, lastIdx) => {\n\t  const idx = input.lastIndexOf(char, lastIdx);\n\t  if (idx === -1) return input;\n\t  if (input[idx - 1] === '\\\\') return exports.escapeLast(input, char, idx - 1);\n\t  return `${input.slice(0, idx)}\\\\${input.slice(idx)}`;\n\t};\n\n\texports.removePrefix = (input, state = {}) => {\n\t  let output = input;\n\t  if (output.startsWith('./')) {\n\t    output = output.slice(2);\n\t    state.prefix = './';\n\t  }\n\t  return output;\n\t};\n\n\texports.wrapOutput = (input, state = {}, options = {}) => {\n\t  const prepend = options.contains ? '' : '^';\n\t  const append = options.contains ? '' : '$';\n\n\t  let output = `${prepend}(?:${input})${append}`;\n\t  if (state.negated === true) {\n\t    output = `(?:^(?!${output}).*$)`;\n\t  }\n\t  return output;\n\t};\n} (utils$3));\n\nconst utils$2 = utils$3;\nconst {\n  CHAR_ASTERISK,             /* * */\n  CHAR_AT,                   /* @ */\n  CHAR_BACKWARD_SLASH,       /* \\ */\n  CHAR_COMMA,                /* , */\n  CHAR_DOT,                  /* . */\n  CHAR_EXCLAMATION_MARK,     /* ! */\n  CHAR_FORWARD_SLASH,        /* / */\n  CHAR_LEFT_CURLY_BRACE,     /* { */\n  CHAR_LEFT_PARENTHESES,     /* ( */\n  CHAR_LEFT_SQUARE_BRACKET,  /* [ */\n  CHAR_PLUS,                 /* + */\n  CHAR_QUESTION_MARK,        /* ? */\n  CHAR_RIGHT_CURLY_BRACE,    /* } */\n  CHAR_RIGHT_PARENTHESES,    /* ) */\n  CHAR_RIGHT_SQUARE_BRACKET  /* ] */\n} = constants$2;\n\nconst isPathSeparator = code => {\n  return code === CHAR_FORWARD_SLASH || code === CHAR_BACKWARD_SLASH;\n};\n\nconst depth = token => {\n  if (token.isPrefix !== true) {\n    token.depth = token.isGlobstar ? Infinity : 1;\n  }\n};\n\n/**\n * Quickly scans a glob pattern and returns an object with a handful of\n * useful properties, like `isGlob`, `path` (the leading non-glob, if it exists),\n * `glob` (the actual pattern), `negated` (true if the path starts with `!` but not\n * with `!(`) and `negatedExtglob` (true if the path starts with `!(`).\n *\n * ```js\n * const pm = require('picomatch');\n * console.log(pm.scan('foo/bar/*.js'));\n * { isGlob: true, input: 'foo/bar/*.js', base: 'foo/bar', glob: '*.js' }\n * ```\n * @param {String} `str`\n * @param {Object} `options`\n * @return {Object} Returns an object with tokens and regex source string.\n * @api public\n */\n\nconst scan$1 = (input, options) => {\n  const opts = options || {};\n\n  const length = input.length - 1;\n  const scanToEnd = opts.parts === true || opts.scanToEnd === true;\n  const slashes = [];\n  const tokens = [];\n  const parts = [];\n\n  let str = input;\n  let index = -1;\n  let start = 0;\n  let lastIndex = 0;\n  let isBrace = false;\n  let isBracket = false;\n  let isGlob = false;\n  let isExtglob = false;\n  let isGlobstar = false;\n  let braceEscaped = false;\n  let backslashes = false;\n  let negated = false;\n  let negatedExtglob = false;\n  let finished = false;\n  let braces = 0;\n  let prev;\n  let code;\n  let token = { value: '', depth: 0, isGlob: false };\n\n  const eos = () => index >= length;\n  const peek = () => str.charCodeAt(index + 1);\n  const advance = () => {\n    prev = code;\n    return str.charCodeAt(++index);\n  };\n\n  while (index < length) {\n    code = advance();\n    let next;\n\n    if (code === CHAR_BACKWARD_SLASH) {\n      backslashes = token.backslashes = true;\n      code = advance();\n\n      if (code === CHAR_LEFT_CURLY_BRACE) {\n        braceEscaped = true;\n      }\n      continue;\n    }\n\n    if (braceEscaped === true || code === CHAR_LEFT_CURLY_BRACE) {\n      braces++;\n\n      while (eos() !== true && (code = advance())) {\n        if (code === CHAR_BACKWARD_SLASH) {\n          backslashes = token.backslashes = true;\n          advance();\n          continue;\n        }\n\n        if (code === CHAR_LEFT_CURLY_BRACE) {\n          braces++;\n          continue;\n        }\n\n        if (braceEscaped !== true && code === CHAR_DOT && (code = advance()) === CHAR_DOT) {\n          isBrace = token.isBrace = true;\n          isGlob = token.isGlob = true;\n          finished = true;\n\n          if (scanToEnd === true) {\n            continue;\n          }\n\n          break;\n        }\n\n        if (braceEscaped !== true && code === CHAR_COMMA) {\n          isBrace = token.isBrace = true;\n          isGlob = token.isGlob = true;\n          finished = true;\n\n          if (scanToEnd === true) {\n            continue;\n          }\n\n          break;\n        }\n\n        if (code === CHAR_RIGHT_CURLY_BRACE) {\n          braces--;\n\n          if (braces === 0) {\n            braceEscaped = false;\n            isBrace = token.isBrace = true;\n            finished = true;\n            break;\n          }\n        }\n      }\n\n      if (scanToEnd === true) {\n        continue;\n      }\n\n      break;\n    }\n\n    if (code === CHAR_FORWARD_SLASH) {\n      slashes.push(index);\n      tokens.push(token);\n      token = { value: '', depth: 0, isGlob: false };\n\n      if (finished === true) continue;\n      if (prev === CHAR_DOT && index === (start + 1)) {\n        start += 2;\n        continue;\n      }\n\n      lastIndex = index + 1;\n      continue;\n    }\n\n    if (opts.noext !== true) {\n      const isExtglobChar = code === CHAR_PLUS\n        || code === CHAR_AT\n        || code === CHAR_ASTERISK\n        || code === CHAR_QUESTION_MARK\n        || code === CHAR_EXCLAMATION_MARK;\n\n      if (isExtglobChar === true && peek() === CHAR_LEFT_PARENTHESES) {\n        isGlob = token.isGlob = true;\n        isExtglob = token.isExtglob = true;\n        finished = true;\n        if (code === CHAR_EXCLAMATION_MARK && index === start) {\n          negatedExtglob = true;\n        }\n\n        if (scanToEnd === true) {\n          while (eos() !== true && (code = advance())) {\n            if (code === CHAR_BACKWARD_SLASH) {\n              backslashes = token.backslashes = true;\n              code = advance();\n              continue;\n            }\n\n            if (code === CHAR_RIGHT_PARENTHESES) {\n              isGlob = token.isGlob = true;\n              finished = true;\n              break;\n            }\n          }\n          continue;\n        }\n        break;\n      }\n    }\n\n    if (code === CHAR_ASTERISK) {\n      if (prev === CHAR_ASTERISK) isGlobstar = token.isGlobstar = true;\n      isGlob = token.isGlob = true;\n      finished = true;\n\n      if (scanToEnd === true) {\n        continue;\n      }\n      break;\n    }\n\n    if (code === CHAR_QUESTION_MARK) {\n      isGlob = token.isGlob = true;\n      finished = true;\n\n      if (scanToEnd === true) {\n        continue;\n      }\n      break;\n    }\n\n    if (code === CHAR_LEFT_SQUARE_BRACKET) {\n      while (eos() !== true && (next = advance())) {\n        if (next === CHAR_BACKWARD_SLASH) {\n          backslashes = token.backslashes = true;\n          advance();\n          continue;\n        }\n\n        if (next === CHAR_RIGHT_SQUARE_BRACKET) {\n          isBracket = token.isBracket = true;\n          isGlob = token.isGlob = true;\n          finished = true;\n          break;\n        }\n      }\n\n      if (scanToEnd === true) {\n        continue;\n      }\n\n      break;\n    }\n\n    if (opts.nonegate !== true && code === CHAR_EXCLAMATION_MARK && index === start) {\n      negated = token.negated = true;\n      start++;\n      continue;\n    }\n\n    if (opts.noparen !== true && code === CHAR_LEFT_PARENTHESES) {\n      isGlob = token.isGlob = true;\n\n      if (scanToEnd === true) {\n        while (eos() !== true && (code = advance())) {\n          if (code === CHAR_LEFT_PARENTHESES) {\n            backslashes = token.backslashes = true;\n            code = advance();\n            continue;\n          }\n\n          if (code === CHAR_RIGHT_PARENTHESES) {\n            finished = true;\n            break;\n          }\n        }\n        continue;\n      }\n      break;\n    }\n\n    if (isGlob === true) {\n      finished = true;\n\n      if (scanToEnd === true) {\n        continue;\n      }\n\n      break;\n    }\n  }\n\n  if (opts.noext === true) {\n    isExtglob = false;\n    isGlob = false;\n  }\n\n  let base = str;\n  let prefix = '';\n  let glob = '';\n\n  if (start > 0) {\n    prefix = str.slice(0, start);\n    str = str.slice(start);\n    lastIndex -= start;\n  }\n\n  if (base && isGlob === true && lastIndex > 0) {\n    base = str.slice(0, lastIndex);\n    glob = str.slice(lastIndex);\n  } else if (isGlob === true) {\n    base = '';\n    glob = str;\n  } else {\n    base = str;\n  }\n\n  if (base && base !== '' && base !== '/' && base !== str) {\n    if (isPathSeparator(base.charCodeAt(base.length - 1))) {\n      base = base.slice(0, -1);\n    }\n  }\n\n  if (opts.unescape === true) {\n    if (glob) glob = utils$2.removeBackslashes(glob);\n\n    if (base && backslashes === true) {\n      base = utils$2.removeBackslashes(base);\n    }\n  }\n\n  const state = {\n    prefix,\n    input,\n    start,\n    base,\n    glob,\n    isBrace,\n    isBracket,\n    isGlob,\n    isExtglob,\n    isGlobstar,\n    negated,\n    negatedExtglob\n  };\n\n  if (opts.tokens === true) {\n    state.maxDepth = 0;\n    if (!isPathSeparator(code)) {\n      tokens.push(token);\n    }\n    state.tokens = tokens;\n  }\n\n  if (opts.parts === true || opts.tokens === true) {\n    let prevIndex;\n\n    for (let idx = 0; idx < slashes.length; idx++) {\n      const n = prevIndex ? prevIndex + 1 : start;\n      const i = slashes[idx];\n      const value = input.slice(n, i);\n      if (opts.tokens) {\n        if (idx === 0 && start !== 0) {\n          tokens[idx].isPrefix = true;\n          tokens[idx].value = prefix;\n        } else {\n          tokens[idx].value = value;\n        }\n        depth(tokens[idx]);\n        state.maxDepth += tokens[idx].depth;\n      }\n      if (idx !== 0 || value !== '') {\n        parts.push(value);\n      }\n      prevIndex = i;\n    }\n\n    if (prevIndex && prevIndex + 1 < input.length) {\n      const value = input.slice(prevIndex + 1);\n      parts.push(value);\n\n      if (opts.tokens) {\n        tokens[tokens.length - 1].value = value;\n        depth(tokens[tokens.length - 1]);\n        state.maxDepth += tokens[tokens.length - 1].depth;\n      }\n    }\n\n    state.slashes = slashes;\n    state.parts = parts;\n  }\n\n  return state;\n};\n\nvar scan_1 = scan$1;\n\nconst constants$1 = constants$2;\nconst utils$1 = utils$3;\n\n/**\n * Constants\n */\n\nconst {\n  MAX_LENGTH,\n  POSIX_REGEX_SOURCE,\n  REGEX_NON_SPECIAL_CHARS,\n  REGEX_SPECIAL_CHARS_BACKREF,\n  REPLACEMENTS\n} = constants$1;\n\n/**\n * Helpers\n */\n\nconst expandRange = (args, options) => {\n  if (typeof options.expandRange === 'function') {\n    return options.expandRange(...args, options);\n  }\n\n  args.sort();\n  const value = `[${args.join('-')}]`;\n\n  return value;\n};\n\n/**\n * Create the message for a syntax error\n */\n\nconst syntaxError = (type, char) => {\n  return `Missing ${type}: \"${char}\" - use \"\\\\\\\\${char}\" to match literal characters`;\n};\n\n/**\n * Parse the given input string.\n * @param {String} input\n * @param {Object} options\n * @return {Object}\n */\n\nconst parse$2 = (input, options) => {\n  if (typeof input !== 'string') {\n    throw new TypeError('Expected a string');\n  }\n\n  input = REPLACEMENTS[input] || input;\n\n  const opts = { ...options };\n  const max = typeof opts.maxLength === 'number' ? Math.min(MAX_LENGTH, opts.maxLength) : MAX_LENGTH;\n\n  let len = input.length;\n  if (len > max) {\n    throw new SyntaxError(`Input length: ${len}, exceeds maximum allowed length: ${max}`);\n  }\n\n  const bos = { type: 'bos', value: '', output: opts.prepend || '' };\n  const tokens = [bos];\n\n  const capture = opts.capture ? '' : '?:';\n  const win32 = utils$1.isWindows(options);\n\n  // create constants based on platform, for windows or posix\n  const PLATFORM_CHARS = constants$1.globChars(win32);\n  const EXTGLOB_CHARS = constants$1.extglobChars(PLATFORM_CHARS);\n\n  const {\n    DOT_LITERAL,\n    PLUS_LITERAL,\n    SLASH_LITERAL,\n    ONE_CHAR,\n    DOTS_SLASH,\n    NO_DOT,\n    NO_DOT_SLASH,\n    NO_DOTS_SLASH,\n    QMARK,\n    QMARK_NO_DOT,\n    STAR,\n    START_ANCHOR\n  } = PLATFORM_CHARS;\n\n  const globstar = opts => {\n    return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`;\n  };\n\n  const nodot = opts.dot ? '' : NO_DOT;\n  const qmarkNoDot = opts.dot ? QMARK : QMARK_NO_DOT;\n  let star = opts.bash === true ? globstar(opts) : STAR;\n\n  if (opts.capture) {\n    star = `(${star})`;\n  }\n\n  // minimatch options support\n  if (typeof opts.noext === 'boolean') {\n    opts.noextglob = opts.noext;\n  }\n\n  const state = {\n    input,\n    index: -1,\n    start: 0,\n    dot: opts.dot === true,\n    consumed: '',\n    output: '',\n    prefix: '',\n    backtrack: false,\n    negated: false,\n    brackets: 0,\n    braces: 0,\n    parens: 0,\n    quotes: 0,\n    globstar: false,\n    tokens\n  };\n\n  input = utils$1.removePrefix(input, state);\n  len = input.length;\n\n  const extglobs = [];\n  const braces = [];\n  const stack = [];\n  let prev = bos;\n  let value;\n\n  /**\n   * Tokenizing helpers\n   */\n\n  const eos = () => state.index === len - 1;\n  const peek = state.peek = (n = 1) => input[state.index + n];\n  const advance = state.advance = () => input[++state.index] || '';\n  const remaining = () => input.slice(state.index + 1);\n  const consume = (value = '', num = 0) => {\n    state.consumed += value;\n    state.index += num;\n  };\n\n  const append = token => {\n    state.output += token.output != null ? token.output : token.value;\n    consume(token.value);\n  };\n\n  const negate = () => {\n    let count = 1;\n\n    while (peek() === '!' && (peek(2) !== '(' || peek(3) === '?')) {\n      advance();\n      state.start++;\n      count++;\n    }\n\n    if (count % 2 === 0) {\n      return false;\n    }\n\n    state.negated = true;\n    state.start++;\n    return true;\n  };\n\n  const increment = type => {\n    state[type]++;\n    stack.push(type);\n  };\n\n  const decrement = type => {\n    state[type]--;\n    stack.pop();\n  };\n\n  /**\n   * Push tokens onto the tokens array. This helper speeds up\n   * tokenizing by 1) helping us avoid backtracking as much as possible,\n   * and 2) helping us avoid creating extra tokens when consecutive\n   * characters are plain text. This improves performance and simplifies\n   * lookbehinds.\n   */\n\n  const push = tok => {\n    if (prev.type === 'globstar') {\n      const isBrace = state.braces > 0 && (tok.type === 'comma' || tok.type === 'brace');\n      const isExtglob = tok.extglob === true || (extglobs.length && (tok.type === 'pipe' || tok.type === 'paren'));\n\n      if (tok.type !== 'slash' && tok.type !== 'paren' && !isBrace && !isExtglob) {\n        state.output = state.output.slice(0, -prev.output.length);\n        prev.type = 'star';\n        prev.value = '*';\n        prev.output = star;\n        state.output += prev.output;\n      }\n    }\n\n    if (extglobs.length && tok.type !== 'paren') {\n      extglobs[extglobs.length - 1].inner += tok.value;\n    }\n\n    if (tok.value || tok.output) append(tok);\n    if (prev && prev.type === 'text' && tok.type === 'text') {\n      prev.value += tok.value;\n      prev.output = (prev.output || '') + tok.value;\n      return;\n    }\n\n    tok.prev = prev;\n    tokens.push(tok);\n    prev = tok;\n  };\n\n  const extglobOpen = (type, value) => {\n    const token = { ...EXTGLOB_CHARS[value], conditions: 1, inner: '' };\n\n    token.prev = prev;\n    token.parens = state.parens;\n    token.output = state.output;\n    const output = (opts.capture ? '(' : '') + token.open;\n\n    increment('parens');\n    push({ type, value, output: state.output ? '' : ONE_CHAR });\n    push({ type: 'paren', extglob: true, value: advance(), output });\n    extglobs.push(token);\n  };\n\n  const extglobClose = token => {\n    let output = token.close + (opts.capture ? ')' : '');\n    let rest;\n\n    if (token.type === 'negate') {\n      let extglobStar = star;\n\n      if (token.inner && token.inner.length > 1 && token.inner.includes('/')) {\n        extglobStar = globstar(opts);\n      }\n\n      if (extglobStar !== star || eos() || /^\\)+$/.test(remaining())) {\n        output = token.close = `)$))${extglobStar}`;\n      }\n\n      if (token.inner.includes('*') && (rest = remaining()) && /^\\.[^\\\\/.]+$/.test(rest)) {\n        // Any non-magical string (`.ts`) or even nested expression (`.{ts,tsx}`) can follow after the closing parenthesis.\n        // In this case, we need to parse the string and use it in the output of the original pattern.\n        // Suitable patterns: `/!(*.d).ts`, `/!(*.d).{ts,tsx}`, `**/!(*-dbg).@(js)`.\n        //\n        // Disabling the `fastpaths` option due to a problem with parsing strings as `.ts` in the pattern like `**/!(*.d).ts`.\n        const expression = parse$2(rest, { ...options, fastpaths: false }).output;\n\n        output = token.close = `)${expression})${extglobStar})`;\n      }\n\n      if (token.prev.type === 'bos') {\n        state.negatedExtglob = true;\n      }\n    }\n\n    push({ type: 'paren', extglob: true, value, output });\n    decrement('parens');\n  };\n\n  /**\n   * Fast paths\n   */\n\n  if (opts.fastpaths !== false && !/(^[*!]|[/()[\\]{}\"])/.test(input)) {\n    let backslashes = false;\n\n    let output = input.replace(REGEX_SPECIAL_CHARS_BACKREF, (m, esc, chars, first, rest, index) => {\n      if (first === '\\\\') {\n        backslashes = true;\n        return m;\n      }\n\n      if (first === '?') {\n        if (esc) {\n          return esc + first + (rest ? QMARK.repeat(rest.length) : '');\n        }\n        if (index === 0) {\n          return qmarkNoDot + (rest ? QMARK.repeat(rest.length) : '');\n        }\n        return QMARK.repeat(chars.length);\n      }\n\n      if (first === '.') {\n        return DOT_LITERAL.repeat(chars.length);\n      }\n\n      if (first === '*') {\n        if (esc) {\n          return esc + first + (rest ? star : '');\n        }\n        return star;\n      }\n      return esc ? m : `\\\\${m}`;\n    });\n\n    if (backslashes === true) {\n      if (opts.unescape === true) {\n        output = output.replace(/\\\\/g, '');\n      } else {\n        output = output.replace(/\\\\+/g, m => {\n          return m.length % 2 === 0 ? '\\\\\\\\' : (m ? '\\\\' : '');\n        });\n      }\n    }\n\n    if (output === input && opts.contains === true) {\n      state.output = input;\n      return state;\n    }\n\n    state.output = utils$1.wrapOutput(output, state, options);\n    return state;\n  }\n\n  /**\n   * Tokenize input until we reach end-of-string\n   */\n\n  while (!eos()) {\n    value = advance();\n\n    if (value === '\\u0000') {\n      continue;\n    }\n\n    /**\n     * Escaped characters\n     */\n\n    if (value === '\\\\') {\n      const next = peek();\n\n      if (next === '/' && opts.bash !== true) {\n        continue;\n      }\n\n      if (next === '.' || next === ';') {\n        continue;\n      }\n\n      if (!next) {\n        value += '\\\\';\n        push({ type: 'text', value });\n        continue;\n      }\n\n      // collapse slashes to reduce potential for exploits\n      const match = /^\\\\+/.exec(remaining());\n      let slashes = 0;\n\n      if (match && match[0].length > 2) {\n        slashes = match[0].length;\n        state.index += slashes;\n        if (slashes % 2 !== 0) {\n          value += '\\\\';\n        }\n      }\n\n      if (opts.unescape === true) {\n        value = advance();\n      } else {\n        value += advance();\n      }\n\n      if (state.brackets === 0) {\n        push({ type: 'text', value });\n        continue;\n      }\n    }\n\n    /**\n     * If we're inside a regex character class, continue\n     * until we reach the closing bracket.\n     */\n\n    if (state.brackets > 0 && (value !== ']' || prev.value === '[' || prev.value === '[^')) {\n      if (opts.posix !== false && value === ':') {\n        const inner = prev.value.slice(1);\n        if (inner.includes('[')) {\n          prev.posix = true;\n\n          if (inner.includes(':')) {\n            const idx = prev.value.lastIndexOf('[');\n            const pre = prev.value.slice(0, idx);\n            const rest = prev.value.slice(idx + 2);\n            const posix = POSIX_REGEX_SOURCE[rest];\n            if (posix) {\n              prev.value = pre + posix;\n              state.backtrack = true;\n              advance();\n\n              if (!bos.output && tokens.indexOf(prev) === 1) {\n                bos.output = ONE_CHAR;\n              }\n              continue;\n            }\n          }\n        }\n      }\n\n      if ((value === '[' && peek() !== ':') || (value === '-' && peek() === ']')) {\n        value = `\\\\${value}`;\n      }\n\n      if (value === ']' && (prev.value === '[' || prev.value === '[^')) {\n        value = `\\\\${value}`;\n      }\n\n      if (opts.posix === true && value === '!' && prev.value === '[') {\n        value = '^';\n      }\n\n      prev.value += value;\n      append({ value });\n      continue;\n    }\n\n    /**\n     * If we're inside a quoted string, continue\n     * until we reach the closing double quote.\n     */\n\n    if (state.quotes === 1 && value !== '\"') {\n      value = utils$1.escapeRegex(value);\n      prev.value += value;\n      append({ value });\n      continue;\n    }\n\n    /**\n     * Double quotes\n     */\n\n    if (value === '\"') {\n      state.quotes = state.quotes === 1 ? 0 : 1;\n      if (opts.keepQuotes === true) {\n        push({ type: 'text', value });\n      }\n      continue;\n    }\n\n    /**\n     * Parentheses\n     */\n\n    if (value === '(') {\n      increment('parens');\n      push({ type: 'paren', value });\n      continue;\n    }\n\n    if (value === ')') {\n      if (state.parens === 0 && opts.strictBrackets === true) {\n        throw new SyntaxError(syntaxError('opening', '('));\n      }\n\n      const extglob = extglobs[extglobs.length - 1];\n      if (extglob && state.parens === extglob.parens + 1) {\n        extglobClose(extglobs.pop());\n        continue;\n      }\n\n      push({ type: 'paren', value, output: state.parens ? ')' : '\\\\)' });\n      decrement('parens');\n      continue;\n    }\n\n    /**\n     * Square brackets\n     */\n\n    if (value === '[') {\n      if (opts.nobracket === true || !remaining().includes(']')) {\n        if (opts.nobracket !== true && opts.strictBrackets === true) {\n          throw new SyntaxError(syntaxError('closing', ']'));\n        }\n\n        value = `\\\\${value}`;\n      } else {\n        increment('brackets');\n      }\n\n      push({ type: 'bracket', value });\n      continue;\n    }\n\n    if (value === ']') {\n      if (opts.nobracket === true || (prev && prev.type === 'bracket' && prev.value.length === 1)) {\n        push({ type: 'text', value, output: `\\\\${value}` });\n        continue;\n      }\n\n      if (state.brackets === 0) {\n        if (opts.strictBrackets === true) {\n          throw new SyntaxError(syntaxError('opening', '['));\n        }\n\n        push({ type: 'text', value, output: `\\\\${value}` });\n        continue;\n      }\n\n      decrement('brackets');\n\n      const prevValue = prev.value.slice(1);\n      if (prev.posix !== true && prevValue[0] === '^' && !prevValue.includes('/')) {\n        value = `/${value}`;\n      }\n\n      prev.value += value;\n      append({ value });\n\n      // when literal brackets are explicitly disabled\n      // assume we should match with a regex character class\n      if (opts.literalBrackets === false || utils$1.hasRegexChars(prevValue)) {\n        continue;\n      }\n\n      const escaped = utils$1.escapeRegex(prev.value);\n      state.output = state.output.slice(0, -prev.value.length);\n\n      // when literal brackets are explicitly enabled\n      // assume we should escape the brackets to match literal characters\n      if (opts.literalBrackets === true) {\n        state.output += escaped;\n        prev.value = escaped;\n        continue;\n      }\n\n      // when the user specifies nothing, try to match both\n      prev.value = `(${capture}${escaped}|${prev.value})`;\n      state.output += prev.value;\n      continue;\n    }\n\n    /**\n     * Braces\n     */\n\n    if (value === '{' && opts.nobrace !== true) {\n      increment('braces');\n\n      const open = {\n        type: 'brace',\n        value,\n        output: '(',\n        outputIndex: state.output.length,\n        tokensIndex: state.tokens.length\n      };\n\n      braces.push(open);\n      push(open);\n      continue;\n    }\n\n    if (value === '}') {\n      const brace = braces[braces.length - 1];\n\n      if (opts.nobrace === true || !brace) {\n        push({ type: 'text', value, output: value });\n        continue;\n      }\n\n      let output = ')';\n\n      if (brace.dots === true) {\n        const arr = tokens.slice();\n        const range = [];\n\n        for (let i = arr.length - 1; i >= 0; i--) {\n          tokens.pop();\n          if (arr[i].type === 'brace') {\n            break;\n          }\n          if (arr[i].type !== 'dots') {\n            range.unshift(arr[i].value);\n          }\n        }\n\n        output = expandRange(range, opts);\n        state.backtrack = true;\n      }\n\n      if (brace.comma !== true && brace.dots !== true) {\n        const out = state.output.slice(0, brace.outputIndex);\n        const toks = state.tokens.slice(brace.tokensIndex);\n        brace.value = brace.output = '\\\\{';\n        value = output = '\\\\}';\n        state.output = out;\n        for (const t of toks) {\n          state.output += (t.output || t.value);\n        }\n      }\n\n      push({ type: 'brace', value, output });\n      decrement('braces');\n      braces.pop();\n      continue;\n    }\n\n    /**\n     * Pipes\n     */\n\n    if (value === '|') {\n      if (extglobs.length > 0) {\n        extglobs[extglobs.length - 1].conditions++;\n      }\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Commas\n     */\n\n    if (value === ',') {\n      let output = value;\n\n      const brace = braces[braces.length - 1];\n      if (brace && stack[stack.length - 1] === 'braces') {\n        brace.comma = true;\n        output = '|';\n      }\n\n      push({ type: 'comma', value, output });\n      continue;\n    }\n\n    /**\n     * Slashes\n     */\n\n    if (value === '/') {\n      // if the beginning of the glob is \"./\", advance the start\n      // to the current index, and don't add the \"./\" characters\n      // to the state. This greatly simplifies lookbehinds when\n      // checking for BOS characters like \"!\" and \".\" (not \"./\")\n      if (prev.type === 'dot' && state.index === state.start + 1) {\n        state.start = state.index + 1;\n        state.consumed = '';\n        state.output = '';\n        tokens.pop();\n        prev = bos; // reset \"prev\" to the first token\n        continue;\n      }\n\n      push({ type: 'slash', value, output: SLASH_LITERAL });\n      continue;\n    }\n\n    /**\n     * Dots\n     */\n\n    if (value === '.') {\n      if (state.braces > 0 && prev.type === 'dot') {\n        if (prev.value === '.') prev.output = DOT_LITERAL;\n        const brace = braces[braces.length - 1];\n        prev.type = 'dots';\n        prev.output += value;\n        prev.value += value;\n        brace.dots = true;\n        continue;\n      }\n\n      if ((state.braces + state.parens) === 0 && prev.type !== 'bos' && prev.type !== 'slash') {\n        push({ type: 'text', value, output: DOT_LITERAL });\n        continue;\n      }\n\n      push({ type: 'dot', value, output: DOT_LITERAL });\n      continue;\n    }\n\n    /**\n     * Question marks\n     */\n\n    if (value === '?') {\n      const isGroup = prev && prev.value === '(';\n      if (!isGroup && opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {\n        extglobOpen('qmark', value);\n        continue;\n      }\n\n      if (prev && prev.type === 'paren') {\n        const next = peek();\n        let output = value;\n\n        if (next === '<' && !utils$1.supportsLookbehinds()) {\n          throw new Error('Node.js v10 or higher is required for regex lookbehinds');\n        }\n\n        if ((prev.value === '(' && !/[!=<:]/.test(next)) || (next === '<' && !/<([!=]|\\w+>)/.test(remaining()))) {\n          output = `\\\\${value}`;\n        }\n\n        push({ type: 'text', value, output });\n        continue;\n      }\n\n      if (opts.dot !== true && (prev.type === 'slash' || prev.type === 'bos')) {\n        push({ type: 'qmark', value, output: QMARK_NO_DOT });\n        continue;\n      }\n\n      push({ type: 'qmark', value, output: QMARK });\n      continue;\n    }\n\n    /**\n     * Exclamation\n     */\n\n    if (value === '!') {\n      if (opts.noextglob !== true && peek() === '(') {\n        if (peek(2) !== '?' || !/[!=<:]/.test(peek(3))) {\n          extglobOpen('negate', value);\n          continue;\n        }\n      }\n\n      if (opts.nonegate !== true && state.index === 0) {\n        negate();\n        continue;\n      }\n    }\n\n    /**\n     * Plus\n     */\n\n    if (value === '+') {\n      if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {\n        extglobOpen('plus', value);\n        continue;\n      }\n\n      if ((prev && prev.value === '(') || opts.regex === false) {\n        push({ type: 'plus', value, output: PLUS_LITERAL });\n        continue;\n      }\n\n      if ((prev && (prev.type === 'bracket' || prev.type === 'paren' || prev.type === 'brace')) || state.parens > 0) {\n        push({ type: 'plus', value });\n        continue;\n      }\n\n      push({ type: 'plus', value: PLUS_LITERAL });\n      continue;\n    }\n\n    /**\n     * Plain text\n     */\n\n    if (value === '@') {\n      if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {\n        push({ type: 'at', extglob: true, value, output: '' });\n        continue;\n      }\n\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Plain text\n     */\n\n    if (value !== '*') {\n      if (value === '$' || value === '^') {\n        value = `\\\\${value}`;\n      }\n\n      const match = REGEX_NON_SPECIAL_CHARS.exec(remaining());\n      if (match) {\n        value += match[0];\n        state.index += match[0].length;\n      }\n\n      push({ type: 'text', value });\n      continue;\n    }\n\n    /**\n     * Stars\n     */\n\n    if (prev && (prev.type === 'globstar' || prev.star === true)) {\n      prev.type = 'star';\n      prev.star = true;\n      prev.value += value;\n      prev.output = star;\n      state.backtrack = true;\n      state.globstar = true;\n      consume(value);\n      continue;\n    }\n\n    let rest = remaining();\n    if (opts.noextglob !== true && /^\\([^?]/.test(rest)) {\n      extglobOpen('star', value);\n      continue;\n    }\n\n    if (prev.type === 'star') {\n      if (opts.noglobstar === true) {\n        consume(value);\n        continue;\n      }\n\n      const prior = prev.prev;\n      const before = prior.prev;\n      const isStart = prior.type === 'slash' || prior.type === 'bos';\n      const afterStar = before && (before.type === 'star' || before.type === 'globstar');\n\n      if (opts.bash === true && (!isStart || (rest[0] && rest[0] !== '/'))) {\n        push({ type: 'star', value, output: '' });\n        continue;\n      }\n\n      const isBrace = state.braces > 0 && (prior.type === 'comma' || prior.type === 'brace');\n      const isExtglob = extglobs.length && (prior.type === 'pipe' || prior.type === 'paren');\n      if (!isStart && prior.type !== 'paren' && !isBrace && !isExtglob) {\n        push({ type: 'star', value, output: '' });\n        continue;\n      }\n\n      // strip consecutive `/**/`\n      while (rest.slice(0, 3) === '/**') {\n        const after = input[state.index + 4];\n        if (after && after !== '/') {\n          break;\n        }\n        rest = rest.slice(3);\n        consume('/**', 3);\n      }\n\n      if (prior.type === 'bos' && eos()) {\n        prev.type = 'globstar';\n        prev.value += value;\n        prev.output = globstar(opts);\n        state.output = prev.output;\n        state.globstar = true;\n        consume(value);\n        continue;\n      }\n\n      if (prior.type === 'slash' && prior.prev.type !== 'bos' && !afterStar && eos()) {\n        state.output = state.output.slice(0, -(prior.output + prev.output).length);\n        prior.output = `(?:${prior.output}`;\n\n        prev.type = 'globstar';\n        prev.output = globstar(opts) + (opts.strictSlashes ? ')' : '|$)');\n        prev.value += value;\n        state.globstar = true;\n        state.output += prior.output + prev.output;\n        consume(value);\n        continue;\n      }\n\n      if (prior.type === 'slash' && prior.prev.type !== 'bos' && rest[0] === '/') {\n        const end = rest[1] !== void 0 ? '|$' : '';\n\n        state.output = state.output.slice(0, -(prior.output + prev.output).length);\n        prior.output = `(?:${prior.output}`;\n\n        prev.type = 'globstar';\n        prev.output = `${globstar(opts)}${SLASH_LITERAL}|${SLASH_LITERAL}${end})`;\n        prev.value += value;\n\n        state.output += prior.output + prev.output;\n        state.globstar = true;\n\n        consume(value + advance());\n\n        push({ type: 'slash', value: '/', output: '' });\n        continue;\n      }\n\n      if (prior.type === 'bos' && rest[0] === '/') {\n        prev.type = 'globstar';\n        prev.value += value;\n        prev.output = `(?:^|${SLASH_LITERAL}|${globstar(opts)}${SLASH_LITERAL})`;\n        state.output = prev.output;\n        state.globstar = true;\n        consume(value + advance());\n        push({ type: 'slash', value: '/', output: '' });\n        continue;\n      }\n\n      // remove single star from output\n      state.output = state.output.slice(0, -prev.output.length);\n\n      // reset previous token to globstar\n      prev.type = 'globstar';\n      prev.output = globstar(opts);\n      prev.value += value;\n\n      // reset output with globstar\n      state.output += prev.output;\n      state.globstar = true;\n      consume(value);\n      continue;\n    }\n\n    const token = { type: 'star', value, output: star };\n\n    if (opts.bash === true) {\n      token.output = '.*?';\n      if (prev.type === 'bos' || prev.type === 'slash') {\n        token.output = nodot + token.output;\n      }\n      push(token);\n      continue;\n    }\n\n    if (prev && (prev.type === 'bracket' || prev.type === 'paren') && opts.regex === true) {\n      token.output = value;\n      push(token);\n      continue;\n    }\n\n    if (state.index === state.start || prev.type === 'slash' || prev.type === 'dot') {\n      if (prev.type === 'dot') {\n        state.output += NO_DOT_SLASH;\n        prev.output += NO_DOT_SLASH;\n\n      } else if (opts.dot === true) {\n        state.output += NO_DOTS_SLASH;\n        prev.output += NO_DOTS_SLASH;\n\n      } else {\n        state.output += nodot;\n        prev.output += nodot;\n      }\n\n      if (peek() !== '*') {\n        state.output += ONE_CHAR;\n        prev.output += ONE_CHAR;\n      }\n    }\n\n    push(token);\n  }\n\n  while (state.brackets > 0) {\n    if (opts.strictBrackets === true) throw new SyntaxError(syntaxError('closing', ']'));\n    state.output = utils$1.escapeLast(state.output, '[');\n    decrement('brackets');\n  }\n\n  while (state.parens > 0) {\n    if (opts.strictBrackets === true) throw new SyntaxError(syntaxError('closing', ')'));\n    state.output = utils$1.escapeLast(state.output, '(');\n    decrement('parens');\n  }\n\n  while (state.braces > 0) {\n    if (opts.strictBrackets === true) throw new SyntaxError(syntaxError('closing', '}'));\n    state.output = utils$1.escapeLast(state.output, '{');\n    decrement('braces');\n  }\n\n  if (opts.strictSlashes !== true && (prev.type === 'star' || prev.type === 'bracket')) {\n    push({ type: 'maybe_slash', value: '', output: `${SLASH_LITERAL}?` });\n  }\n\n  // rebuild the output if we had to backtrack at any point\n  if (state.backtrack === true) {\n    state.output = '';\n\n    for (const token of state.tokens) {\n      state.output += token.output != null ? token.output : token.value;\n\n      if (token.suffix) {\n        state.output += token.suffix;\n      }\n    }\n  }\n\n  return state;\n};\n\n/**\n * Fast paths for creating regular expressions for common glob patterns.\n * This can significantly speed up processing and has very little downside\n * impact when none of the fast paths match.\n */\n\nparse$2.fastpaths = (input, options) => {\n  const opts = { ...options };\n  const max = typeof opts.maxLength === 'number' ? Math.min(MAX_LENGTH, opts.maxLength) : MAX_LENGTH;\n  const len = input.length;\n  if (len > max) {\n    throw new SyntaxError(`Input length: ${len}, exceeds maximum allowed length: ${max}`);\n  }\n\n  input = REPLACEMENTS[input] || input;\n  const win32 = utils$1.isWindows(options);\n\n  // create constants based on platform, for windows or posix\n  const {\n    DOT_LITERAL,\n    SLASH_LITERAL,\n    ONE_CHAR,\n    DOTS_SLASH,\n    NO_DOT,\n    NO_DOTS,\n    NO_DOTS_SLASH,\n    STAR,\n    START_ANCHOR\n  } = constants$1.globChars(win32);\n\n  const nodot = opts.dot ? NO_DOTS : NO_DOT;\n  const slashDot = opts.dot ? NO_DOTS_SLASH : NO_DOT;\n  const capture = opts.capture ? '' : '?:';\n  const state = { negated: false, prefix: '' };\n  let star = opts.bash === true ? '.*?' : STAR;\n\n  if (opts.capture) {\n    star = `(${star})`;\n  }\n\n  const globstar = opts => {\n    if (opts.noglobstar === true) return star;\n    return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`;\n  };\n\n  const create = str => {\n    switch (str) {\n      case '*':\n        return `${nodot}${ONE_CHAR}${star}`;\n\n      case '.*':\n        return `${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      case '*.*':\n        return `${nodot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      case '*/*':\n        return `${nodot}${star}${SLASH_LITERAL}${ONE_CHAR}${slashDot}${star}`;\n\n      case '**':\n        return nodot + globstar(opts);\n\n      case '**/*':\n        return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${ONE_CHAR}${star}`;\n\n      case '**/*.*':\n        return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      case '**/.*':\n        return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${DOT_LITERAL}${ONE_CHAR}${star}`;\n\n      default: {\n        const match = /^(.*?)\\.(\\w+)$/.exec(str);\n        if (!match) return;\n\n        const source = create(match[1]);\n        if (!source) return;\n\n        return source + DOT_LITERAL + match[2];\n      }\n    }\n  };\n\n  const output = utils$1.removePrefix(input, state);\n  let source = create(output);\n\n  if (source && opts.strictSlashes !== true) {\n    source += `${SLASH_LITERAL}?`;\n  }\n\n  return source;\n};\n\nvar parse_1$1 = parse$2;\n\nconst path$1 = require$$0$1;\nconst scan = scan_1;\nconst parse$1 = parse_1$1;\nconst utils = utils$3;\nconst constants = constants$2;\nconst isObject$1 = val => val && typeof val === 'object' && !Array.isArray(val);\n\n/**\n * Creates a matcher function from one or more glob patterns. The\n * returned function takes a string to match as its first argument,\n * and returns true if the string is a match. The returned matcher\n * function also takes a boolean as the second argument that, when true,\n * returns an object with additional information.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch(glob[, options]);\n *\n * const isMatch = picomatch('*.!(*a)');\n * console.log(isMatch('a.a')); //=> false\n * console.log(isMatch('a.b')); //=> true\n * ```\n * @name picomatch\n * @param {String|Array} `globs` One or more glob patterns.\n * @param {Object=} `options`\n * @return {Function=} Returns a matcher function.\n * @api public\n */\n\nconst picomatch = (glob, options, returnState = false) => {\n  if (Array.isArray(glob)) {\n    const fns = glob.map(input => picomatch(input, options, returnState));\n    const arrayMatcher = str => {\n      for (const isMatch of fns) {\n        const state = isMatch(str);\n        if (state) return state;\n      }\n      return false;\n    };\n    return arrayMatcher;\n  }\n\n  const isState = isObject$1(glob) && glob.tokens && glob.input;\n\n  if (glob === '' || (typeof glob !== 'string' && !isState)) {\n    throw new TypeError('Expected pattern to be a non-empty string');\n  }\n\n  const opts = options || {};\n  const posix = utils.isWindows(options);\n  const regex = isState\n    ? picomatch.compileRe(glob, options)\n    : picomatch.makeRe(glob, options, false, true);\n\n  const state = regex.state;\n  delete regex.state;\n\n  let isIgnored = () => false;\n  if (opts.ignore) {\n    const ignoreOpts = { ...options, ignore: null, onMatch: null, onResult: null };\n    isIgnored = picomatch(opts.ignore, ignoreOpts, returnState);\n  }\n\n  const matcher = (input, returnObject = false) => {\n    const { isMatch, match, output } = picomatch.test(input, regex, options, { glob, posix });\n    const result = { glob, state, regex, posix, input, output, match, isMatch };\n\n    if (typeof opts.onResult === 'function') {\n      opts.onResult(result);\n    }\n\n    if (isMatch === false) {\n      result.isMatch = false;\n      return returnObject ? result : false;\n    }\n\n    if (isIgnored(input)) {\n      if (typeof opts.onIgnore === 'function') {\n        opts.onIgnore(result);\n      }\n      result.isMatch = false;\n      return returnObject ? result : false;\n    }\n\n    if (typeof opts.onMatch === 'function') {\n      opts.onMatch(result);\n    }\n    return returnObject ? result : true;\n  };\n\n  if (returnState) {\n    matcher.state = state;\n  }\n\n  return matcher;\n};\n\n/**\n * Test `input` with the given `regex`. This is used by the main\n * `picomatch()` function to test the input string.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.test(input, regex[, options]);\n *\n * console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\\/([^/]*?))$/));\n * // { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' }\n * ```\n * @param {String} `input` String to test.\n * @param {RegExp} `regex`\n * @return {Object} Returns an object with matching info.\n * @api public\n */\n\npicomatch.test = (input, regex, options, { glob, posix } = {}) => {\n  if (typeof input !== 'string') {\n    throw new TypeError('Expected input to be a string');\n  }\n\n  if (input === '') {\n    return { isMatch: false, output: '' };\n  }\n\n  const opts = options || {};\n  const format = opts.format || (posix ? utils.toPosixSlashes : null);\n  let match = input === glob;\n  let output = (match && format) ? format(input) : input;\n\n  if (match === false) {\n    output = format ? format(input) : input;\n    match = output === glob;\n  }\n\n  if (match === false || opts.capture === true) {\n    if (opts.matchBase === true || opts.basename === true) {\n      match = picomatch.matchBase(input, regex, options, posix);\n    } else {\n      match = regex.exec(output);\n    }\n  }\n\n  return { isMatch: Boolean(match), match, output };\n};\n\n/**\n * Match the basename of a filepath.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.matchBase(input, glob[, options]);\n * console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true\n * ```\n * @param {String} `input` String to test.\n * @param {RegExp|String} `glob` Glob pattern or regex created by [.makeRe](#makeRe).\n * @return {Boolean}\n * @api public\n */\n\npicomatch.matchBase = (input, glob, options, posix = utils.isWindows(options)) => {\n  const regex = glob instanceof RegExp ? glob : picomatch.makeRe(glob, options);\n  return regex.test(path$1.basename(input));\n};\n\n/**\n * Returns true if **any** of the given glob `patterns` match the specified `string`.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.isMatch(string, patterns[, options]);\n *\n * console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true\n * console.log(picomatch.isMatch('a.a', 'b.*')); //=> false\n * ```\n * @param {String|Array} str The string to test.\n * @param {String|Array} patterns One or more glob patterns to use for matching.\n * @param {Object} [options] See available [options](#options).\n * @return {Boolean} Returns true if any patterns match `str`\n * @api public\n */\n\npicomatch.isMatch = (str, patterns, options) => picomatch(patterns, options)(str);\n\n/**\n * Parse a glob pattern to create the source string for a regular\n * expression.\n *\n * ```js\n * const picomatch = require('picomatch');\n * const result = picomatch.parse(pattern[, options]);\n * ```\n * @param {String} `pattern`\n * @param {Object} `options`\n * @return {Object} Returns an object with useful properties and output to be used as a regex source string.\n * @api public\n */\n\npicomatch.parse = (pattern, options) => {\n  if (Array.isArray(pattern)) return pattern.map(p => picomatch.parse(p, options));\n  return parse$1(pattern, { ...options, fastpaths: false });\n};\n\n/**\n * Scan a glob pattern to separate the pattern into segments.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.scan(input[, options]);\n *\n * const result = picomatch.scan('!./foo/*.js');\n * console.log(result);\n * { prefix: '!./',\n *   input: '!./foo/*.js',\n *   start: 3,\n *   base: 'foo',\n *   glob: '*.js',\n *   isBrace: false,\n *   isBracket: false,\n *   isGlob: true,\n *   isExtglob: false,\n *   isGlobstar: false,\n *   negated: true }\n * ```\n * @param {String} `input` Glob pattern to scan.\n * @param {Object} `options`\n * @return {Object} Returns an object with\n * @api public\n */\n\npicomatch.scan = (input, options) => scan(input, options);\n\n/**\n * Compile a regular expression from the `state` object returned by the\n * [parse()](#parse) method.\n *\n * @param {Object} `state`\n * @param {Object} `options`\n * @param {Boolean} `returnOutput` Intended for implementors, this argument allows you to return the raw output from the parser.\n * @param {Boolean} `returnState` Adds the state to a `state` property on the returned regex. Useful for implementors and debugging.\n * @return {RegExp}\n * @api public\n */\n\npicomatch.compileRe = (state, options, returnOutput = false, returnState = false) => {\n  if (returnOutput === true) {\n    return state.output;\n  }\n\n  const opts = options || {};\n  const prepend = opts.contains ? '' : '^';\n  const append = opts.contains ? '' : '$';\n\n  let source = `${prepend}(?:${state.output})${append}`;\n  if (state && state.negated === true) {\n    source = `^(?!${source}).*$`;\n  }\n\n  const regex = picomatch.toRegex(source, options);\n  if (returnState === true) {\n    regex.state = state;\n  }\n\n  return regex;\n};\n\n/**\n * Create a regular expression from a parsed glob pattern.\n *\n * ```js\n * const picomatch = require('picomatch');\n * const state = picomatch.parse('*.js');\n * // picomatch.compileRe(state[, options]);\n *\n * console.log(picomatch.compileRe(state));\n * //=> /^(?:(?!\\.)(?=.)[^/]*?\\.js)$/\n * ```\n * @param {String} `state` The object returned from the `.parse` method.\n * @param {Object} `options`\n * @param {Boolean} `returnOutput` Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result.\n * @param {Boolean} `returnState` Implementors may use this argument to return the state from the parsed glob with the returned regular expression.\n * @return {RegExp} Returns a regex created from the given pattern.\n * @api public\n */\n\npicomatch.makeRe = (input, options = {}, returnOutput = false, returnState = false) => {\n  if (!input || typeof input !== 'string') {\n    throw new TypeError('Expected a non-empty string');\n  }\n\n  let parsed = { negated: false, fastpaths: true };\n\n  if (options.fastpaths !== false && (input[0] === '.' || input[0] === '*')) {\n    parsed.output = parse$1.fastpaths(input, options);\n  }\n\n  if (!parsed.output) {\n    parsed = parse$1(input, options);\n  }\n\n  return picomatch.compileRe(parsed, options, returnOutput, returnState);\n};\n\n/**\n * Create a regular expression from the given regex source string.\n *\n * ```js\n * const picomatch = require('picomatch');\n * // picomatch.toRegex(source[, options]);\n *\n * const { output } = picomatch.parse('*.js');\n * console.log(picomatch.toRegex(output));\n * //=> /^(?:(?!\\.)(?=.)[^/]*?\\.js)$/\n * ```\n * @param {String} `source` Regular expression source string.\n * @param {Object} `options`\n * @return {RegExp}\n * @api public\n */\n\npicomatch.toRegex = (source, options) => {\n  try {\n    const opts = options || {};\n    return new RegExp(source, opts.flags || (opts.nocase ? 'i' : ''));\n  } catch (err) {\n    if (options && options.debug === true) throw err;\n    return /$^/;\n  }\n};\n\n/**\n * Picomatch constants.\n * @return {Object}\n */\n\npicomatch.constants = constants;\n\n/**\n * Expose \"picomatch\"\n */\n\nvar picomatch_1 = picomatch;\n\n(function (module) {\n\n\tmodule.exports = picomatch_1;\n} (picomatch$1));\n\nvar pm = /*@__PURE__*/getDefaultExportFromCjs(picomatchExports);\n\n// Helper since Typescript can't detect readonly arrays with Array.isArray\nfunction isArray(arg) {\n    return Array.isArray(arg);\n}\nfunction ensureArray(thing) {\n    if (isArray(thing))\n        return thing;\n    if (thing == null)\n        return [];\n    return [thing];\n}\n\nconst normalizePath$1 = function normalizePath(filename) {\n    return filename.split(require$$0$1.win32.sep).join(require$$0$1.posix.sep);\n};\n\nfunction getMatcherString(id, resolutionBase) {\n    if (resolutionBase === false || require$$0$1.isAbsolute(id) || id.startsWith('*')) {\n        return normalizePath$1(id);\n    }\n    // resolve('') is valid and will default to process.cwd()\n    const basePath = normalizePath$1(require$$0$1.resolve(resolutionBase || ''))\n        // escape all possible (posix + win) path characters that might interfere with regex\n        .replace(/[-^$*+?.()|[\\]{}]/g, '\\\\$&');\n    // Note that we use posix.join because:\n    // 1. the basePath has been normalized to use /\n    // 2. the incoming glob (id) matcher, also uses /\n    // otherwise Node will force backslash (\\) on windows\n    return require$$0$1.posix.join(basePath, normalizePath$1(id));\n}\nconst createFilter$1 = function createFilter(include, exclude, options) {\n    const resolutionBase = options && options.resolve;\n    const getMatcher = (id) => id instanceof RegExp\n        ? id\n        : {\n            test: (what) => {\n                // this refactor is a tad overly verbose but makes for easy debugging\n                const pattern = getMatcherString(id, resolutionBase);\n                const fn = pm(pattern, { dot: true });\n                const result = fn(what);\n                return result;\n            }\n        };\n    const includeMatchers = ensureArray(include).map(getMatcher);\n    const excludeMatchers = ensureArray(exclude).map(getMatcher);\n    return function result(id) {\n        if (typeof id !== 'string')\n            return false;\n        if (/\\0/.test(id))\n            return false;\n        const pathId = normalizePath$1(id);\n        for (let i = 0; i < excludeMatchers.length; ++i) {\n            const matcher = excludeMatchers[i];\n            if (matcher.test(pathId))\n                return false;\n        }\n        for (let i = 0; i < includeMatchers.length; ++i) {\n            const matcher = includeMatchers[i];\n            if (matcher.test(pathId))\n                return true;\n        }\n        return !includeMatchers.length;\n    };\n};\n\nconst reservedWords = 'break case class catch const continue debugger default delete do else export extends finally for function if import in instanceof let new return super switch this throw try typeof var void while with yield enum await implements package protected static interface private public';\nconst builtins = 'arguments Infinity NaN undefined null true false eval uneval isFinite isNaN parseFloat parseInt decodeURI decodeURIComponent encodeURI encodeURIComponent escape unescape Object Function Boolean Symbol Error EvalError InternalError RangeError ReferenceError SyntaxError TypeError URIError Number Math Date String RegExp Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array Map Set WeakMap WeakSet SIMD ArrayBuffer DataView JSON Promise Generator GeneratorFunction Reflect Proxy Intl';\nconst forbiddenIdentifiers = new Set(`${reservedWords} ${builtins}`.split(' '));\nforbiddenIdentifiers.add('');\n\nconst createFilter = createFilter$1;\nfunction slash(p) {\n    return p.replace(/\\\\/g, '/');\n}\n// TODO: use import()\nconst _require = node_module.createRequire((typeof document === 'undefined' ? new (require('u' + 'rl').URL)('file:' + __filename).href : (document.currentScript && document.currentScript.src || new URL('node-cjs/publicUtils.cjs', document.baseURI).href)));\ntry {\n    Boolean(_require('pnpapi'));\n}\ncatch { }\n// set in bin/vite.js\nconst filter = process.env.VITE_DEBUG_FILTER;\nconst DEBUG = process.env.DEBUG;\nfunction createDebugger(namespace, options = {}) {\n    const log = debug(namespace);\n    const { onlyWhenFocused } = options;\n    const focus = typeof onlyWhenFocused === 'string' ? onlyWhenFocused : namespace;\n    return (msg, ...args) => {\n        if (filter && !msg.includes(filter)) {\n            return;\n        }\n        if (onlyWhenFocused && !DEBUG?.includes(focus)) {\n            return;\n        }\n        log(msg, ...args);\n    };\n}\nfunction testCaseInsensitiveFS() {\n    if (!CLIENT_ENTRY.endsWith('client.mjs')) {\n        throw new Error(`cannot test case insensitive FS, CLIENT_ENTRY const doesn't contain client.mjs`);\n    }\n    if (!fs$1.existsSync(CLIENT_ENTRY)) {\n        throw new Error('cannot test case insensitive FS, CLIENT_ENTRY does not point to an existing file: ' +\n            CLIENT_ENTRY);\n    }\n    return fs$1.existsSync(CLIENT_ENTRY.replace('client.mjs', 'cLiEnT.mjs'));\n}\ntestCaseInsensitiveFS();\nconst isWindows = os$1.platform() === 'win32';\nfunction normalizePath(id) {\n    return path$3.posix.normalize(isWindows ? slash(id) : id);\n}\nfunction isObject(value) {\n    return Object.prototype.toString.call(value) === '[object Object]';\n}\nfunction lookupFile(dir, formats, options) {\n    for (const format of formats) {\n        const fullPath = path$3.join(dir, format);\n        if (fs$1.existsSync(fullPath) && fs$1.statSync(fullPath).isFile()) {\n            const result = options?.pathOnly\n                ? fullPath\n                : fs$1.readFileSync(fullPath, 'utf-8');\n            if (!options?.predicate || options.predicate(result)) {\n                return result;\n            }\n        }\n    }\n    const parentDir = path$3.dirname(dir);\n    if (parentDir !== dir &&\n        (!options?.rootDir || parentDir.startsWith(options?.rootDir))) {\n        return lookupFile(parentDir, formats, options);\n    }\n}\nfunction isFileReadable(filename) {\n    try {\n        fs$1.accessSync(filename, fs$1.constants.R_OK);\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\nisWindows\n    ? node_util.promisify(gracefulRemoveDir)\n    : function removeDirSync(dir) {\n        // when removing `.vite/deps`, if it doesn't exist, nodejs may also remove\n        // other directories within `.vite/`, including `.vite/deps_temp` (bug).\n        // workaround by checking for directory existence before removing for now.\n        if (fs$1.existsSync(dir)) {\n            fs$1.rmSync(dir, { recursive: true, force: true });\n        }\n    };\nisWindows ? node_util.promisify(gracefulRename) : fs$1.renameSync;\nfunction arraify(target) {\n    return Array.isArray(target) ? target : [target];\n}\n// @ts-expect-error jest only exists when running Jest\nconst usingDynamicImport = typeof jest === 'undefined';\n/**\n * Dynamically import files. It will make sure it's not being compiled away by TS/Rollup.\n *\n * As a temporary workaround for Jest's lack of stable ESM support, we fallback to require\n * if we're in a Jest environment.\n * See https://github.com/vitejs/vite/pull/5197#issuecomment-938054077\n *\n * @param file File path to import.\n */\nusingDynamicImport\n    ? new Function('file', 'return import(file)')\n    : _require;\n// Based on node-graceful-fs\n// The ISC License\n// Copyright (c) 2011-2022 Isaac Z. Schlueter, Ben Noordhuis, and Contributors\n// https://github.com/isaacs/node-graceful-fs/blob/main/LICENSE\n// On Windows, A/V software can lock the directory, causing this\n// to fail with an EACCES or EPERM if the directory contains newly\n// created files. The original tried for up to 60 seconds, we only\n// wait for 5 seconds, as a longer time would be seen as an error\nconst GRACEFUL_RENAME_TIMEOUT = 5000;\nfunction gracefulRename(from, to, cb) {\n    const start = Date.now();\n    let backoff = 0;\n    fs$1.rename(from, to, function CB(er) {\n        if (er &&\n            (er.code === 'EACCES' || er.code === 'EPERM') &&\n            Date.now() - start < GRACEFUL_RENAME_TIMEOUT) {\n            setTimeout(function () {\n                fs$1.stat(to, function (stater, st) {\n                    if (stater && stater.code === 'ENOENT')\n                        fs$1.rename(from, to, CB);\n                    else\n                        CB(er);\n                });\n            }, backoff);\n            if (backoff < 100)\n                backoff += 10;\n            return;\n        }\n        if (cb)\n            cb(er);\n    });\n}\nconst GRACEFUL_REMOVE_DIR_TIMEOUT = 5000;\nfunction gracefulRemoveDir(dir, cb) {\n    const start = Date.now();\n    let backoff = 0;\n    fs$1.rm(dir, { recursive: true }, function CB(er) {\n        if (er) {\n            if ((er.code === 'ENOTEMPTY' ||\n                er.code === 'EACCES' ||\n                er.code === 'EPERM') &&\n                Date.now() - start < GRACEFUL_REMOVE_DIR_TIMEOUT) {\n                setTimeout(function () {\n                    fs$1.rm(dir, { recursive: true }, CB);\n                }, backoff);\n                if (backoff < 100)\n                    backoff += 10;\n                return;\n            }\n            if (er.code === 'ENOENT') {\n                er = null;\n            }\n        }\n        if (cb)\n            cb(er);\n    });\n}\nfunction mergeConfigRecursively(defaults, overrides, rootPath) {\n    const merged = { ...defaults };\n    for (const key in overrides) {\n        const value = overrides[key];\n        if (value == null) {\n            continue;\n        }\n        const existing = merged[key];\n        if (existing == null) {\n            merged[key] = value;\n            continue;\n        }\n        // fields that require special handling\n        if (key === 'alias' && (rootPath === 'resolve' || rootPath === '')) {\n            merged[key] = mergeAlias(existing, value);\n            continue;\n        }\n        else if (key === 'assetsInclude' && rootPath === '') {\n            merged[key] = [].concat(existing, value);\n            continue;\n        }\n        else if (key === 'noExternal' &&\n            rootPath === 'ssr' &&\n            (existing === true || value === true)) {\n            merged[key] = true;\n            continue;\n        }\n        if (Array.isArray(existing) || Array.isArray(value)) {\n            merged[key] = [...arraify(existing ?? []), ...arraify(value ?? [])];\n            continue;\n        }\n        if (isObject(existing) && isObject(value)) {\n            merged[key] = mergeConfigRecursively(existing, value, rootPath ? `${rootPath}.${key}` : key);\n            continue;\n        }\n        merged[key] = value;\n    }\n    return merged;\n}\nfunction mergeConfig(defaults, overrides, isRoot = true) {\n    return mergeConfigRecursively(defaults, overrides, isRoot ? '' : '.');\n}\nfunction mergeAlias(a, b) {\n    if (!a)\n        return b;\n    if (!b)\n        return a;\n    if (isObject(a) && isObject(b)) {\n        return { ...a, ...b };\n    }\n    // the order is flipped because the alias is resolved from top-down,\n    // where the later should have higher priority\n    return [...normalizeAlias(b), ...normalizeAlias(a)];\n}\nfunction normalizeAlias(o = []) {\n    return Array.isArray(o)\n        ? o.map(normalizeSingleAlias)\n        : Object.keys(o).map((find) => normalizeSingleAlias({\n            find,\n            replacement: o[find],\n        }));\n}\n// https://github.com/vitejs/vite/issues/1363\n// work around https://github.com/rollup/plugins/issues/759\nfunction normalizeSingleAlias({ find, replacement, customResolver, }) {\n    if (typeof find === 'string' &&\n        find.endsWith('/') &&\n        replacement.endsWith('/')) {\n        find = find.slice(0, find.length - 1);\n        replacement = replacement.slice(0, replacement.length - 1);\n    }\n    const alias = {\n        find,\n        replacement,\n    };\n    if (customResolver) {\n        alias.customResolver = customResolver;\n    }\n    return alias;\n}\n\n/*!\n * etag\n * Copyright(c) 2014-2016 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n/**\n * Module exports.\n * @public\n */\n\nvar etag_1 = etag;\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar crypto = require$$0$2;\nvar Stats = require$$1$1.Stats;\n\n/**\n * Module variables.\n * @private\n */\n\nvar toString = Object.prototype.toString;\n\n/**\n * Generate an entity tag.\n *\n * @param {Buffer|string} entity\n * @return {string}\n * @private\n */\n\nfunction entitytag (entity) {\n  if (entity.length === 0) {\n    // fast-path empty\n    return '\"0-2jmj7l5rSw0yVb/vlWAYkK/YBwk\"'\n  }\n\n  // compute hash of entity\n  var hash = crypto\n    .createHash('sha1')\n    .update(entity, 'utf8')\n    .digest('base64')\n    .substring(0, 27);\n\n  // compute length of entity\n  var len = typeof entity === 'string'\n    ? Buffer.byteLength(entity, 'utf8')\n    : entity.length;\n\n  return '\"' + len.toString(16) + '-' + hash + '\"'\n}\n\n/**\n * Create a simple ETag.\n *\n * @param {string|Buffer|Stats} entity\n * @param {object} [options]\n * @param {boolean} [options.weak]\n * @return {String}\n * @public\n */\n\nfunction etag (entity, options) {\n  if (entity == null) {\n    throw new TypeError('argument entity is required')\n  }\n\n  // support fs.Stats object\n  var isStats = isstats(entity);\n  var weak = options && typeof options.weak === 'boolean'\n    ? options.weak\n    : isStats;\n\n  // validate argument\n  if (!isStats && typeof entity !== 'string' && !Buffer.isBuffer(entity)) {\n    throw new TypeError('argument entity must be string, Buffer, or fs.Stats')\n  }\n\n  // generate entity tag\n  var tag = isStats\n    ? stattag(entity)\n    : entitytag(entity);\n\n  return weak\n    ? 'W/' + tag\n    : tag\n}\n\n/**\n * Determine if object is a Stats object.\n *\n * @param {object} obj\n * @return {boolean}\n * @api private\n */\n\nfunction isstats (obj) {\n  // genuine fs.Stats\n  if (typeof Stats === 'function' && obj instanceof Stats) {\n    return true\n  }\n\n  // quack quack\n  return obj && typeof obj === 'object' &&\n    'ctime' in obj && toString.call(obj.ctime) === '[object Date]' &&\n    'mtime' in obj && toString.call(obj.mtime) === '[object Date]' &&\n    'ino' in obj && typeof obj.ino === 'number' &&\n    'size' in obj && typeof obj.size === 'number'\n}\n\n/**\n * Generate a tag for a stat.\n *\n * @param {object} stat\n * @return {string}\n * @private\n */\n\nfunction stattag (stat) {\n  var mtime = stat.mtime.getTime().toString(16);\n  var size = stat.size.toString(16);\n\n  return '\"' + size + '-' + mtime + '\"'\n}\n\nconst isDebug = !!process.env.DEBUG;\ncreateDebugger('vite:sourcemap', {\n    onlyWhenFocused: true,\n});\nfunction genSourceMapUrl(map) {\n    if (typeof map !== 'string') {\n        map = JSON.stringify(map);\n    }\n    return `data:application/json;base64,${Buffer.from(map).toString('base64')}`;\n}\nfunction getCodeWithSourcemap(type, code, map) {\n    if (isDebug) {\n        code += `\\n/*${JSON.stringify(map, null, 2).replace(/\\*\\//g, '*\\\\/')}*/\\n`;\n    }\n    if (type === 'js') {\n        code += `\\n//# sourceMappingURL=${genSourceMapUrl(map)}`;\n    }\n    else if (type === 'css') {\n        code += `\\n/*# sourceMappingURL=${genSourceMapUrl(map)} */`;\n    }\n    return code;\n}\n\nconst alias = {\n    js: 'application/javascript',\n    css: 'text/css',\n    html: 'text/html',\n    json: 'application/json',\n};\nfunction send(req, res, content, type, options) {\n    const { etag = etag_1(content, { weak: true }), cacheControl = 'no-cache', headers, map, } = options;\n    if (res.writableEnded) {\n        return;\n    }\n    if (req.headers['if-none-match'] === etag) {\n        res.statusCode = 304;\n        res.end();\n        return;\n    }\n    res.setHeader('Content-Type', alias[type] || type);\n    res.setHeader('Cache-Control', cacheControl);\n    res.setHeader('Etag', etag);\n    if (headers) {\n        for (const name in headers) {\n            res.setHeader(name, headers[name]);\n        }\n    }\n    // inject source map reference\n    if (map && map.mappings) {\n        if (type === 'js' || type === 'css') {\n            content = getCodeWithSourcemap(type, content.toString(), map);\n        }\n    }\n    res.statusCode = 200;\n    res.end(content);\n    return;\n}\n\n/* eslint no-console: 0 */\nconst LogLevels = {\n    silent: 0,\n    error: 1,\n    warn: 2,\n    info: 3,\n};\nlet lastType;\nlet lastMsg;\nlet sameCount = 0;\nfunction clearScreen() {\n    const repeatCount = process.stdout.rows - 2;\n    const blank = repeatCount > 0 ? '\\n'.repeat(repeatCount) : '';\n    console.log(blank);\n    readline.cursorTo(process.stdout, 0, 0);\n    readline.clearScreenDown(process.stdout);\n}\nfunction createLogger(level = 'info', options = {}) {\n    if (options.customLogger) {\n        return options.customLogger;\n    }\n    const loggedErrors = new WeakSet();\n    const { prefix = '[vite]', allowClearScreen = true } = options;\n    const thresh = LogLevels[level];\n    const canClearScreen = allowClearScreen && process.stdout.isTTY && !process.env.CI;\n    const clear = canClearScreen ? clearScreen : () => { };\n    function output(type, msg, options = {}) {\n        if (thresh >= LogLevels[type]) {\n            const method = type === 'info' ? 'log' : type;\n            const format = () => {\n                if (options.timestamp) {\n                    const tag = type === 'info'\n                        ? picocolorsExports.cyan(picocolorsExports.bold(prefix))\n                        : type === 'warn'\n                            ? picocolorsExports.yellow(picocolorsExports.bold(prefix))\n                            : picocolorsExports.red(picocolorsExports.bold(prefix));\n                    return `${picocolorsExports.dim(new Date().toLocaleTimeString())} ${tag} ${msg}`;\n                }\n                else {\n                    return msg;\n                }\n            };\n            if (options.error) {\n                loggedErrors.add(options.error);\n            }\n            if (canClearScreen) {\n                if (type === lastType && msg === lastMsg) {\n                    sameCount++;\n                    clear();\n                    console[method](format(), picocolorsExports.yellow(`(x${sameCount + 1})`));\n                }\n                else {\n                    sameCount = 0;\n                    lastMsg = msg;\n                    lastType = type;\n                    if (options.clear) {\n                        clear();\n                    }\n                    console[method](format());\n                }\n            }\n            else {\n                console[method](format());\n            }\n        }\n    }\n    const warnedMessages = new Set();\n    const logger = {\n        hasWarned: false,\n        info(msg, opts) {\n            output('info', msg, opts);\n        },\n        warn(msg, opts) {\n            logger.hasWarned = true;\n            output('warn', msg, opts);\n        },\n        warnOnce(msg, opts) {\n            if (warnedMessages.has(msg))\n                return;\n            logger.hasWarned = true;\n            output('warn', msg, opts);\n            warnedMessages.add(msg);\n        },\n        error(msg, opts) {\n            logger.hasWarned = true;\n            output('error', msg, opts);\n        },\n        clearScreen(type) {\n            if (thresh >= LogLevels[type]) {\n                clear();\n            }\n        },\n        hasErrorLogged(error) {\n            return loggedErrors.has(error);\n        },\n    };\n    return logger;\n}\n\n// https://github.com/vitejs/vite/issues/2820#issuecomment-812495079\nconst ROOT_FILES = [\n    // '.git',\n    // https://pnpm.js.org/workspaces/\n    'pnpm-workspace.yaml',\n    // https://rushjs.io/pages/advanced/config_files/\n    // 'rush.json',\n    // https://nx.dev/latest/react/getting-started/nx-setup\n    // 'workspace.json',\n    // 'nx.json',\n    // https://github.com/lerna/lerna#lernajson\n    'lerna.json',\n];\n// npm: https://docs.npmjs.com/cli/v7/using-npm/workspaces#installing-workspaces\n// yarn: https://classic.yarnpkg.com/en/docs/workspaces/#toc-how-to-use-it\nfunction hasWorkspacePackageJSON(root) {\n    const path = path$3.join(root, 'package.json');\n    if (!isFileReadable(path)) {\n        return false;\n    }\n    const content = JSON.parse(fs$1.readFileSync(path, 'utf-8')) || {};\n    return !!content.workspaces;\n}\nfunction hasRootFile(root) {\n    return ROOT_FILES.some((file) => fs$1.existsSync(path$3.join(root, file)));\n}\nfunction hasPackageJSON(root) {\n    const path = path$3.join(root, 'package.json');\n    return fs$1.existsSync(path);\n}\n/**\n * Search up for the nearest `package.json`\n */\nfunction searchForPackageRoot(current, root = current) {\n    if (hasPackageJSON(current))\n        return current;\n    const dir = path$3.dirname(current);\n    // reach the fs root\n    if (!dir || dir === current)\n        return root;\n    return searchForPackageRoot(dir, root);\n}\n/**\n * Search up for the nearest workspace root\n */\nfunction searchForWorkspaceRoot(current, root = searchForPackageRoot(current)) {\n    if (hasRootFile(current))\n        return current;\n    if (hasWorkspacePackageJSON(current))\n        return current;\n    const dir = path$3.dirname(current);\n    // reach the fs root\n    if (!dir || dir === current)\n        return root;\n    return searchForWorkspaceRoot(dir, root);\n}\n\nvar mainExports = {};\nvar main$1 = {\n  get exports(){ return mainExports; },\n  set exports(v){ mainExports = v; },\n};\n\nvar name = \"dotenv\";\nvar version$1 = \"16.0.3\";\nvar description = \"Loads environment variables from .env file\";\nvar main = \"lib/main.js\";\nvar types = \"lib/main.d.ts\";\nvar exports$1 = {\n\t\".\": {\n\t\trequire: \"./lib/main.js\",\n\t\ttypes: \"./lib/main.d.ts\",\n\t\t\"default\": \"./lib/main.js\"\n\t},\n\t\"./config\": \"./config.js\",\n\t\"./config.js\": \"./config.js\",\n\t\"./lib/env-options\": \"./lib/env-options.js\",\n\t\"./lib/env-options.js\": \"./lib/env-options.js\",\n\t\"./lib/cli-options\": \"./lib/cli-options.js\",\n\t\"./lib/cli-options.js\": \"./lib/cli-options.js\",\n\t\"./package.json\": \"./package.json\"\n};\nvar scripts = {\n\t\"dts-check\": \"tsc --project tests/types/tsconfig.json\",\n\tlint: \"standard\",\n\t\"lint-readme\": \"standard-markdown\",\n\tpretest: \"npm run lint && npm run dts-check\",\n\ttest: \"tap tests/*.js --100 -Rspec\",\n\tprerelease: \"npm test\",\n\trelease: \"standard-version\"\n};\nvar repository = {\n\ttype: \"git\",\n\turl: \"git://github.com/motdotla/dotenv.git\"\n};\nvar keywords = [\n\t\"dotenv\",\n\t\"env\",\n\t\".env\",\n\t\"environment\",\n\t\"variables\",\n\t\"config\",\n\t\"settings\"\n];\nvar readmeFilename = \"README.md\";\nvar license = \"BSD-2-Clause\";\nvar devDependencies = {\n\t\"@types/node\": \"^17.0.9\",\n\tdecache: \"^4.6.1\",\n\tdtslint: \"^3.7.0\",\n\tsinon: \"^12.0.1\",\n\tstandard: \"^16.0.4\",\n\t\"standard-markdown\": \"^7.1.0\",\n\t\"standard-version\": \"^9.3.2\",\n\ttap: \"^15.1.6\",\n\ttar: \"^6.1.11\",\n\ttypescript: \"^4.5.4\"\n};\nvar engines = {\n\tnode: \">=12\"\n};\nvar require$$3 = {\n\tname: name,\n\tversion: version$1,\n\tdescription: description,\n\tmain: main,\n\ttypes: types,\n\texports: exports$1,\n\tscripts: scripts,\n\trepository: repository,\n\tkeywords: keywords,\n\treadmeFilename: readmeFilename,\n\tlicense: license,\n\tdevDependencies: devDependencies,\n\tengines: engines\n};\n\nconst fs = require$$1$1;\nconst path = require$$0$1;\nconst os = require$$2;\nconst packageJson = require$$3;\n\nconst version = packageJson.version;\n\nconst LINE = /(?:^|^)\\s*(?:export\\s+)?([\\w.-]+)(?:\\s*=\\s*?|:\\s+?)(\\s*'(?:\\\\'|[^'])*'|\\s*\"(?:\\\\\"|[^\"])*\"|\\s*`(?:\\\\`|[^`])*`|[^#\\r\\n]+)?\\s*(?:#.*)?(?:$|$)/mg;\n\n// Parser src into an Object\nfunction parse (src) {\n  const obj = {};\n\n  // Convert buffer to string\n  let lines = src.toString();\n\n  // Convert line breaks to same format\n  lines = lines.replace(/\\r\\n?/mg, '\\n');\n\n  let match;\n  while ((match = LINE.exec(lines)) != null) {\n    const key = match[1];\n\n    // Default undefined or null to empty string\n    let value = (match[2] || '');\n\n    // Remove whitespace\n    value = value.trim();\n\n    // Check if double quoted\n    const maybeQuote = value[0];\n\n    // Remove surrounding quotes\n    value = value.replace(/^(['\"`])([\\s\\S]*)\\1$/mg, '$2');\n\n    // Expand newlines if double quoted\n    if (maybeQuote === '\"') {\n      value = value.replace(/\\\\n/g, '\\n');\n      value = value.replace(/\\\\r/g, '\\r');\n    }\n\n    // Add to object\n    obj[key] = value;\n  }\n\n  return obj\n}\n\nfunction _log (message) {\n  console.log(`[dotenv@${version}][DEBUG] ${message}`);\n}\n\nfunction _resolveHome (envPath) {\n  return envPath[0] === '~' ? path.join(os.homedir(), envPath.slice(1)) : envPath\n}\n\n// Populates process.env from .env file\nfunction config (options) {\n  let dotenvPath = path.resolve(process.cwd(), '.env');\n  let encoding = 'utf8';\n  const debug = Boolean(options && options.debug);\n  const override = Boolean(options && options.override);\n\n  if (options) {\n    if (options.path != null) {\n      dotenvPath = _resolveHome(options.path);\n    }\n    if (options.encoding != null) {\n      encoding = options.encoding;\n    }\n  }\n\n  try {\n    // Specifying an encoding returns a string instead of a buffer\n    const parsed = DotenvModule.parse(fs.readFileSync(dotenvPath, { encoding }));\n\n    Object.keys(parsed).forEach(function (key) {\n      if (!Object.prototype.hasOwnProperty.call(process.env, key)) {\n        process.env[key] = parsed[key];\n      } else {\n        if (override === true) {\n          process.env[key] = parsed[key];\n        }\n\n        if (debug) {\n          if (override === true) {\n            _log(`\"${key}\" is already defined in \\`process.env\\` and WAS overwritten`);\n          } else {\n            _log(`\"${key}\" is already defined in \\`process.env\\` and was NOT overwritten`);\n          }\n        }\n      }\n    });\n\n    return { parsed }\n  } catch (e) {\n    if (debug) {\n      _log(`Failed to load ${dotenvPath} ${e.message}`);\n    }\n\n    return { error: e }\n  }\n}\n\nconst DotenvModule = {\n  config,\n  parse\n};\n\nmainExports.config = DotenvModule.config;\nvar parse_1 = mainExports.parse = DotenvModule.parse;\nmain$1.exports = DotenvModule;\n\nfunction _interpolate (envValue, environment, config) {\n  const matches = envValue.match(/(.?\\${*[\\w]*(?::-[\\w/]*)?}*)/g) || [];\n\n  return matches.reduce(function (newEnv, match, index) {\n    const parts = /(.?)\\${*([\\w]*(?::-[\\w/]*)?)?}*/g.exec(match);\n    if (!parts || parts.length === 0) {\n      return newEnv\n    }\n\n    const prefix = parts[1];\n\n    let value, replacePart;\n\n    if (prefix === '\\\\') {\n      replacePart = parts[0];\n      value = replacePart.replace('\\\\$', '$');\n    } else {\n      // PATCH: compatible with env variables ended with unescaped $\n      if(!parts[2]) {\n        return newEnv\n      }\n      const keyParts = parts[2].split(':-');\n      const key = keyParts[0];\n      replacePart = parts[0].substring(prefix.length);\n      // process.env value 'wins' over .env file's value\n      value = Object.prototype.hasOwnProperty.call(environment, key)\n        ? environment[key]\n        : (config.parsed[key] || keyParts[1] || '');\n\n      // If the value is found, remove nested expansions.\n      if (keyParts.length > 1 && value) {\n        const replaceNested = matches[index + 1];\n        matches[index + 1] = '';\n\n        newEnv = newEnv.replace(replaceNested, '');\n      }\n      // Resolve recursive interpolations\n      value = _interpolate(value, environment, config);\n    }\n\n    return newEnv.replace(replacePart, value)\n  }, envValue)\n}\n\nfunction expand (config) {\n  // if ignoring process.env, use a blank object\n  const environment = config.ignoreProcessEnv ? {} : process.env;\n\n  for (const configKey in config.parsed) {\n    const value = Object.prototype.hasOwnProperty.call(environment, configKey) ? environment[configKey] : config.parsed[configKey];\n\n    config.parsed[configKey] = _interpolate(value, environment, config);\n  }\n\n  // PATCH: don't write to process.env\n  // for (const processKey in config.parsed) {\n  //   environment[processKey] = config.parsed[processKey]\n  // }\n\n  return config\n}\n\nvar expand_1 = expand;\n\nfunction loadEnv(mode, envDir, prefixes = 'VITE_') {\n    if (mode === 'local') {\n        throw new Error(`\"local\" cannot be used as a mode name because it conflicts with ` +\n            `the .local postfix for .env files.`);\n    }\n    prefixes = arraify(prefixes);\n    const env = {};\n    const envFiles = [\n        /** default file */ `.env`,\n        /** local file */ `.env.local`,\n        /** mode file */ `.env.${mode}`,\n        /** mode local file */ `.env.${mode}.local`,\n    ];\n    const parsed = Object.fromEntries(envFiles.flatMap((file) => {\n        const path = lookupFile(envDir, [file], {\n            pathOnly: true,\n            rootDir: envDir,\n        });\n        if (!path)\n            return [];\n        return Object.entries(parse_1(fs$1.readFileSync(path)));\n    }));\n    // test NODE_ENV override before expand as otherwise process.env.NODE_ENV would override this\n    if (parsed.NODE_ENV && process.env.VITE_USER_NODE_ENV === undefined) {\n        process.env.VITE_USER_NODE_ENV = parsed.NODE_ENV;\n    }\n    // support BROWSER and BROWSER_ARGS env variables\n    if (parsed.BROWSER && process.env.BROWSER === undefined) {\n        process.env.BROWSER = parsed.BROWSER;\n    }\n    if (parsed.BROWSER_ARGS && process.env.BROWSER_ARGS === undefined) {\n        process.env.BROWSER_ARGS = parsed.BROWSER_ARGS;\n    }\n    // let environment variables use each other\n    // `expand` patched in patches/dotenv-expand@9.0.0.patch\n    expand_1({ parsed });\n    // only keys that start with prefix are exposed to client\n    for (const [key, value] of Object.entries(parsed)) {\n        if (prefixes.some((prefix) => key.startsWith(prefix))) {\n            env[key] = value;\n        }\n    }\n    // check if there are actual env variables starting with VITE_*\n    // these are typically provided inline and should be prioritized\n    for (const key in process.env) {\n        if (prefixes.some((prefix) => key.startsWith(prefix))) {\n            env[key] = process.env[key];\n        }\n    }\n    return env;\n}\nfunction resolveEnvPrefix({ envPrefix = 'VITE_', }) {\n    envPrefix = arraify(envPrefix);\n    if (envPrefix.some((prefix) => prefix === '')) {\n        throw new Error(`envPrefix option contains value '', which could lead unexpected exposure of sensitive information.`);\n    }\n    return envPrefix;\n}\n\nexports.esbuildVersion = esbuild.version;\nexports.rollupVersion = rollup.VERSION;\nexports.createFilter = createFilter;\nexports.createLogger = createLogger;\nexports.isCSSRequest = isCSSRequest;\nexports.loadEnv = loadEnv;\nexports.mergeAlias = mergeAlias;\nexports.mergeConfig = mergeConfig;\nexports.normalizePath = normalizePath;\nexports.resolveEnvPrefix = resolveEnvPrefix;\nexports.searchForWorkspaceRoot = searchForWorkspaceRoot;\nexports.send = send;\nexports.splitVendorChunk = splitVendorChunk;\nexports.splitVendorChunkPlugin = splitVendorChunkPlugin;\nexports.version = VERSION;\n"}}}}}},"index.cjs":{"file":{"contents":"/* eslint-disable no-restricted-globals */\n\n// type utils\nmodule.exports.defineConfig = (config) => config\n\n// proxy cjs utils (sync functions)\nObject.assign(module.exports, require('./dist/node-cjs/publicUtils.cjs'))\n\n// async functions, can be redirect from ESM build\nconst asyncFunctions = [\n  'build',\n  'createServer',\n  'preview',\n  'transformWithEsbuild',\n  'resolveConfig',\n  'optimizeDeps',\n  'formatPostcssSourceMap',\n  'loadConfigFromFile',\n  'preprocessCSS',\n]\nasyncFunctions.forEach((name) => {\n  module.exports[name] = (...args) =>\n    import('./dist/node/index.js').then((i) => i[name](...args))\n})\n\n// some sync functions are marked not supported due to their complexity and uncommon usage\nconst unsupportedCJS = ['resolvePackageEntry', 'resolvePackageData']\nunsupportedCJS.forEach((name) => {\n  module.exports[name] = () => {\n    throw new Error(\n      `\"${name}\" is not supported in CJS build of Vite 4.\\nPlease use ESM or dynamic imports \\`const { ${name} } = await import('vite')\\`.`,\n    )\n  }\n})\n"}},"LICENSE.md":{"file":{"contents":"# Vite core license\nVite is released under the MIT license:\n\nMIT License\n\nCopyright (c) 2019-present, Yuxi (Evan) You and Vite contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n# Licenses of bundled dependencies\nThe published Vite artifact additionally contains code with the following licenses:\nApache-2.0, BSD-2-Clause, CC0-1.0, ISC, MIT\n\n# Bundled dependencies:\n## @ampproject/remapping\nLicense: Apache-2.0\nBy: Justin Ridgewell\nRepository: git+https://github.com/ampproject/remapping.git\n\n> Apache License\n>                            Version 2.0, January 2004\n>                         http://www.apache.org/licenses/\n> \n>    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n> \n>    1. Definitions.\n> \n>       \"License\" shall mean the terms and conditions for use, reproduction,\n>       and distribution as defined by Sections 1 through 9 of this document.\n> \n>       \"Licensor\" shall mean the copyright owner or entity authorized by\n>       the copyright owner that is granting the License.\n> \n>       \"Legal Entity\" shall mean the union of the acting entity and all\n>       other entities that control, are controlled by, or are under common\n>       control with that entity. For the purposes of this definition,\n>       \"control\" means (i) the power, direct or indirect, to cause the\n>       direction or management of such entity, whether by contract or\n>       otherwise, or (ii) ownership of fifty percent (50%) or more of the\n>       outstanding shares, or (iii) beneficial ownership of such entity.\n> \n>       \"You\" (or \"Your\") shall mean an individual or Legal Entity\n>       exercising permissions granted by this License.\n> \n>       \"Source\" form shall mean the preferred form for making modifications,\n>       including but not limited to software source code, documentation\n>       source, and configuration files.\n> \n>       \"Object\" form shall mean any form resulting from mechanical\n>       transformation or translation of a Source form, including but\n>       not limited to compiled object code, generated documentation,\n>       and conversions to other media types.\n> \n>       \"Work\" shall mean the work of authorship, whether in Source or\n>       Object form, made available under the License, as indicated by a\n>       copyright notice that is included in or attached to the work\n>       (an example is provided in the Appendix below).\n> \n>       \"Derivative Works\" shall mean any work, whether in Source or Object\n>       form, that is based on (or derived from) the Work and for which the\n>       editorial revisions, annotations, elaborations, or other modifications\n>       represent, as a whole, an original work of authorship. For the purposes\n>       of this License, Derivative Works shall not include works that remain\n>       separable from, or merely link (or bind by name) to the interfaces of,\n>       the Work and Derivative Works thereof.\n> \n>       \"Contribution\" shall mean any work of authorship, including\n>       the original version of the Work and any modifications or additions\n>       to that Work or Derivative Works thereof, that is intentionally\n>       submitted to Licensor for inclusion in the Work by the copyright owner\n>       or by an individual or Legal Entity authorized to submit on behalf of\n>       the copyright owner. For the purposes of this definition, \"submitted\"\n>       means any form of electronic, verbal, or written communication sent\n>       to the Licensor or its representatives, including but not limited to\n>       communication on electronic mailing lists, source code control systems,\n>       and issue tracking systems that are managed by, or on behalf of, the\n>       Licensor for the purpose of discussing and improving the Work, but\n>       excluding communication that is conspicuously marked or otherwise\n>       designated in writing by the copyright owner as \"Not a Contribution.\"\n> \n>       \"Contributor\" shall mean Licensor and any individual or Legal Entity\n>       on behalf of whom a Contribution has been received by Licensor and\n>       subsequently incorporated within the Work.\n> \n>    2. Grant of Copyright License. Subject to the terms and conditions of\n>       this License, each Contributor hereby grants to You a perpetual,\n>       worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n>       copyright license to reproduce, prepare Derivative Works of,\n>       publicly display, publicly perform, sublicense, and distribute the\n>       Work and such Derivative Works in Source or Object form.\n> \n>    3. Grant of Patent License. Subject to the terms and conditions of\n>       this License, each Contributor hereby grants to You a perpetual,\n>       worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n>       (except as stated in this section) patent license to make, have made,\n>       use, offer to sell, sell, import, and otherwise transfer the Work,\n>       where such license applies only to those patent claims licensable\n>       by such Contributor that are necessarily infringed by their\n>       Contribution(s) alone or by combination of their Contribution(s)\n>       with the Work to which such Contribution(s) was submitted. If You\n>       institute patent litigation against any entity (including a\n>       cross-claim or counterclaim in a lawsuit) alleging that the Work\n>       or a Contribution incorporated within the Work constitutes direct\n>       or contributory patent infringement, then any patent licenses\n>       granted to You under this License for that Work shall terminate\n>       as of the date such litigation is filed.\n> \n>    4. Redistribution. You may reproduce and distribute copies of the\n>       Work or Derivative Works thereof in any medium, with or without\n>       modifications, and in Source or Object form, provided that You\n>       meet the following conditions:\n> \n>       (a) You must give any other recipients of the Work or\n>           Derivative Works a copy of this License; and\n> \n>       (b) You must cause any modified files to carry prominent notices\n>           stating that You changed the files; and\n> \n>       (c) You must retain, in the Source form of any Derivative Works\n>           that You distribute, all copyright, patent, trademark, and\n>           attribution notices from the Source form of the Work,\n>           excluding those notices that do not pertain to any part of\n>           the Derivative Works; and\n> \n>       (d) If the Work includes a \"NOTICE\" text file as part of its\n>           distribution, then any Derivative Works that You distribute must\n>           include a readable copy of the attribution notices contained\n>           within such NOTICE file, excluding those notices that do not\n>           pertain to any part of the Derivative Works, in at least one\n>           of the following places: within a NOTICE text file distributed\n>           as part of the Derivative Works; within the Source form or\n>           documentation, if provided along with the Derivative Works; or,\n>           within a display generated by the Derivative Works, if and\n>           wherever such third-party notices normally appear. The contents\n>           of the NOTICE file are for informational purposes only and\n>           do not modify the License. You may add Your own attribution\n>           notices within Derivative Works that You distribute, alongside\n>           or as an addendum to the NOTICE text from the Work, provided\n>           that such additional attribution notices cannot be construed\n>           as modifying the License.\n> \n>       You may add Your own copyright statement to Your modifications and\n>       may provide additional or different license terms and conditions\n>       for use, reproduction, or distribution of Your modifications, or\n>       for any such Derivative Works as a whole, provided Your use,\n>       reproduction, and distribution of the Work otherwise complies with\n>       the conditions stated in this License.\n> \n>    5. Submission of Contributions. Unless You explicitly state otherwise,\n>       any Contribution intentionally submitted for inclusion in the Work\n>       by You to the Licensor shall be under the terms and conditions of\n>       this License, without any additional terms or conditions.\n>       Notwithstanding the above, nothing herein shall supersede or modify\n>       the terms of any separate license agreement you may have executed\n>       with Licensor regarding such Contributions.\n> \n>    6. Trademarks. This License does not grant permission to use the trade\n>       names, trademarks, service marks, or product names of the Licensor,\n>       except as required for reasonable and customary use in describing the\n>       origin of the Work and reproducing the content of the NOTICE file.\n> \n>    7. Disclaimer of Warranty. Unless required by applicable law or\n>       agreed to in writing, Licensor provides the Work (and each\n>       Contributor provides its Contributions) on an \"AS IS\" BASIS,\n>       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n>       implied, including, without limitation, any warranties or conditions\n>       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n>       PARTICULAR PURPOSE. You are solely responsible for determining the\n>       appropriateness of using or redistributing the Work and assume any\n>       risks associated with Your exercise of permissions under this License.\n> \n>    8. Limitation of Liability. In no event and under no legal theory,\n>       whether in tort (including negligence), contract, or otherwise,\n>       unless required by applicable law (such as deliberate and grossly\n>       negligent acts) or agreed to in writing, shall any Contributor be\n>       liable to You for damages, including any direct, indirect, special,\n>       incidental, or consequential damages of any character arising as a\n>       result of this License or out of the use or inability to use the\n>       Work (including but not limited to damages for loss of goodwill,\n>       work stoppage, computer failure or malfunction, or any and all\n>       other commercial damages or losses), even if such Contributor\n>       has been advised of the possibility of such damages.\n> \n>    9. Accepting Warranty or Additional Liability. While redistributing\n>       the Work or Derivative Works thereof, You may choose to offer,\n>       and charge a fee for, acceptance of support, warranty, indemnity,\n>       or other liability obligations and/or rights consistent with this\n>       License. However, in accepting such obligations, You may act only\n>       on Your own behalf and on Your sole responsibility, not on behalf\n>       of any other Contributor, and only if You agree to indemnify,\n>       defend, and hold each Contributor harmless for any liability\n>       incurred by, or claims asserted against, such Contributor by reason\n>       of your accepting any such warranty or additional liability.\n> \n>    END OF TERMS AND CONDITIONS\n> \n>    APPENDIX: How to apply the Apache License to your work.\n> \n>       To apply the Apache License to your work, attach the following\n>       boilerplate notice, with the fields enclosed by brackets \"[]\"\n>       replaced with your own identifying information. (Don't include\n>       the brackets!)  The text should be enclosed in the appropriate\n>       comment syntax for the file format. We also recommend that a\n>       file or class name and description of purpose be included on the\n>       same \"printed page\" as the copyright notice for easier\n>       identification within third-party archives.\n> \n>    Copyright 2019 Google LLC\n> \n>    Licensed under the Apache License, Version 2.0 (the \"License\");\n>    you may not use this file except in compliance with the License.\n>    You may obtain a copy of the License at\n> \n>        http://www.apache.org/licenses/LICENSE-2.0\n> \n>    Unless required by applicable law or agreed to in writing, software\n>    distributed under the License is distributed on an \"AS IS\" BASIS,\n>    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n>    See the License for the specific language governing permissions and\n>    limitations under the License.\n\n---------------------------------------\n\n## @jridgewell/gen-mapping\nLicense: MIT\nBy: Justin Ridgewell\nRepository: https://github.com/jridgewell/gen-mapping\n\n> Copyright 2022 Justin Ridgewell <jridgewell@google.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @jridgewell/resolve-uri\nLicense: MIT\nBy: Justin Ridgewell\nRepository: https://github.com/jridgewell/resolve-uri\n\n> Copyright 2019 Justin Ridgewell <jridgewell@google.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @jridgewell/set-array\nLicense: MIT\nBy: Justin Ridgewell\nRepository: https://github.com/jridgewell/set-array\n\n> Copyright 2022 Justin Ridgewell <jridgewell@google.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @jridgewell/sourcemap-codec\nLicense: MIT\nBy: Rich Harris\nRepository: git+https://github.com/jridgewell/sourcemap-codec.git\n\n> The MIT License\n> \n> Copyright (c) 2015 Rich Harris\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## @jridgewell/trace-mapping\nLicense: MIT\nBy: Justin Ridgewell\nRepository: git+https://github.com/jridgewell/trace-mapping.git\n\n> Copyright 2022 Justin Ridgewell <justin@ridgewell.name>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @nodelib/fs.scandir\nLicense: MIT\nRepository: https://github.com/nodelib/nodelib/tree/master/packages/fs/fs.scandir\n\n> The MIT License (MIT)\n> \n> Copyright (c) Denis Malinochkin\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @nodelib/fs.stat\nLicense: MIT\nRepository: https://github.com/nodelib/nodelib/tree/master/packages/fs/fs.stat\n\n> The MIT License (MIT)\n> \n> Copyright (c) Denis Malinochkin\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @nodelib/fs.walk\nLicense: MIT\nRepository: https://github.com/nodelib/nodelib/tree/master/packages/fs/fs.walk\n\n> The MIT License (MIT)\n> \n> Copyright (c) Denis Malinochkin\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## @polka/url\nLicense: MIT\nBy: Luke Edwards\nRepository: lukeed/polka\n\n> The MIT License (MIT)\n> \n> Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (https://lukeed.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## @rollup/plugin-alias\nLicense: MIT\nBy: Johannes Stein\nRepository: rollup/plugins\n\n---------------------------------------\n\n## @rollup/plugin-commonjs\nLicense: MIT\nBy: Rich Harris\nRepository: rollup/plugins\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2019 RollupJS Plugin Contributors (https://github.com/rollup/plugins/graphs/contributors)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## @rollup/plugin-dynamic-import-vars\nLicense: MIT\nBy: LarsDenBakker\nRepository: rollup/plugins\n\n---------------------------------------\n\n## @rollup/pluginutils\nLicense: MIT\nBy: Rich Harris\nRepository: rollup/plugins\n\n---------------------------------------\n\n## acorn\nLicense: MIT\nBy: Marijn Haverbeke, Ingvar Stepanyan, Adrian Heine\nRepository: https://github.com/acornjs/acorn.git\n\n> MIT License\n> \n> Copyright (C) 2012-2022 by various contributors (see AUTHORS)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## acorn-walk\nLicense: MIT\nBy: Marijn Haverbeke, Ingvar Stepanyan, Adrian Heine\nRepository: https://github.com/acornjs/acorn.git\n\n> MIT License\n> \n> Copyright (C) 2012-2020 by various contributors (see AUTHORS)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## ansi-regex\nLicense: MIT\nBy: Sindre Sorhus\nRepository: chalk/ansi-regex\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## anymatch\nLicense: ISC\nBy: Elan Shanker\nRepository: https://github.com/micromatch/anymatch\n\n> The ISC License\n> \n> Copyright (c) 2019 Elan Shanker, Paul Miller (https://paulmillr.com)\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## balanced-match\nLicense: MIT\nBy: Julian Gruber\nRepository: git://github.com/juliangruber/balanced-match.git\n\n> (MIT)\n> \n> Copyright (c) 2013 Julian Gruber &lt;julian@juliangruber.com&gt;\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n> of the Software, and to permit persons to whom the Software is furnished to do\n> so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## binary-extensions\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/binary-extensions\n\n> MIT License\n> \n> Copyright (c) 2019 Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com), Paul Miller (https://paulmillr.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## brace-expansion\nLicense: MIT\nBy: Julian Gruber\nRepository: git://github.com/juliangruber/brace-expansion.git\n\n> MIT License\n> \n> Copyright (c) 2013 Julian Gruber <julian@juliangruber.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## braces\nLicense: MIT\nBy: Jon Schlinkert, Brian Woodward, Elan Shanker, Eugene Sharygin, hemanth.hm\nRepository: micromatch/braces\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-2018, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## cac\nLicense: MIT\nBy: egoist\nRepository: egoist/cac\n\n> The MIT License (MIT)\n> \n> Copyright (c) EGOIST <0x142857@gmail.com> (https://github.com/egoist)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## chokidar\nLicense: MIT\nBy: Paul Miller, Elan Shanker\nRepository: git+https://github.com/paulmillr/chokidar.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2012-2019 Paul Miller (https://paulmillr.com), Elan Shanker\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the “Software”), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## commondir\nLicense: MIT\nBy: James Halliday\nRepository: http://github.com/substack/node-commondir.git\n\n> The MIT License\n> \n> Copyright (c) 2013 James Halliday (mail@substack.net)\n> \n> Permission is hereby granted, free of charge, \n> to any person obtaining a copy of this software and \n> associated documentation files (the \"Software\"), to \n> deal in the Software without restriction, including \n> without limitation the rights to use, copy, modify, \n> merge, publish, distribute, sublicense, and/or sell \n> copies of the Software, and to permit persons to whom \n> the Software is furnished to do so, \n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice \n> shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, \n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES \n> OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. \n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR \n> ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, \n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE \n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## connect\nLicense: MIT\nBy: TJ Holowaychuk, Douglas Christopher Wilson, Jonathan Ong, Tim Caswell\nRepository: senchalabs/connect\n\n> (The MIT License)\n> \n> Copyright (c) 2010 Sencha Inc.\n> Copyright (c) 2011 LearnBoost\n> Copyright (c) 2011-2014 TJ Holowaychuk\n> Copyright (c) 2015 Douglas Christopher Wilson\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## connect-history-api-fallback\nLicense: MIT\nBy: Ben Ripkens, Craig Myles\nRepository: http://github.com/bripkens/connect-history-api-fallback.git\n\n> The MIT License\n> \n> Copyright (c) 2022 Ben Blackmore and contributors\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## convert-source-map\nLicense: MIT\nBy: Thorsten Lorenz\nRepository: git://github.com/thlorenz/convert-source-map.git\n\n> Copyright 2013 Thorsten Lorenz. \n> All rights reserved.\n> \n> Permission is hereby granted, free of charge, to any person\n> obtaining a copy of this software and associated documentation\n> files (the \"Software\"), to deal in the Software without\n> restriction, including without limitation the rights to use,\n> copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the\n> Software is furnished to do so, subject to the following\n> conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n> OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n> NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n> HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n> WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n> FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n> OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## cors\nLicense: MIT\nBy: Troy Goode\nRepository: expressjs/cors\n\n> (The MIT License)\n> \n> Copyright (c) 2013 Troy Goode <troygoode@gmail.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## cross-spawn\nLicense: MIT\nBy: André Cruz\nRepository: git@github.com:moxystudio/node-cross-spawn.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2018 Made With MOXY Lda <hello@moxy.studio>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## cssesc\nLicense: MIT\nBy: Mathias Bynens\nRepository: https://github.com/mathiasbynens/cssesc.git\n\n> Copyright Mathias Bynens <https://mathiasbynens.be/>\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> \"Software\"), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n> NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n> LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n> OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n> WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## debug\nLicense: MIT\nBy: Josh Junon, TJ Holowaychuk, Nathan Rajlich, Andrew Rhyne\nRepository: git://github.com/debug-js/debug.git\n\n> (The MIT License)\n> \n> Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca>\n> Copyright (c) 2018-2021 Josh Junon\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software\n> and associated documentation files (the 'Software'), to deal in the Software without restriction,\n> including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,\n> and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial\n> portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n> LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n> WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## define-lazy-prop\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/define-lazy-prop\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## dotenv\nLicense: BSD-2-Clause\nRepository: git://github.com/motdotla/dotenv.git\n\n> Copyright (c) 2015, Scott Motte\n> All rights reserved.\n> \n> Redistribution and use in source and binary forms, with or without\n> modification, are permitted provided that the following conditions are met:\n> \n> * Redistributions of source code must retain the above copyright notice, this\n>   list of conditions and the following disclaimer.\n> \n> * Redistributions in binary form must reproduce the above copyright notice,\n>   this list of conditions and the following disclaimer in the documentation\n>   and/or other materials provided with the distribution.\n> \n> THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n> AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n> IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n> DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n> FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n> DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n> SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n> CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n> OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n> OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n---------------------------------------\n\n## dotenv-expand\nLicense: BSD-2-Clause\nBy: motdotla\nRepository: https://github.com/motdotla/dotenv-expand\n\n> Copyright (c) 2016, Scott Motte\n> All rights reserved.\n> \n> Redistribution and use in source and binary forms, with or without\n> modification, are permitted provided that the following conditions are met:\n> \n> * Redistributions of source code must retain the above copyright notice, this\n>   list of conditions and the following disclaimer.\n> \n> * Redistributions in binary form must reproduce the above copyright notice,\n>   this list of conditions and the following disclaimer in the documentation\n>   and/or other materials provided with the distribution.\n> \n> THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n> AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n> IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n> DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n> FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n> DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n> SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n> CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n> OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n> OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n---------------------------------------\n\n## ee-first\nLicense: MIT\nBy: Jonathan Ong, Douglas Christopher Wilson\nRepository: jonathanong/ee-first\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014 Jonathan Ong me@jongleberry.com\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## encodeurl\nLicense: MIT\nBy: Douglas Christopher Wilson\nRepository: pillarjs/encodeurl\n\n> (The MIT License)\n> \n> Copyright (c) 2016 Douglas Christopher Wilson\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## entities\nLicense: BSD-2-Clause\nBy: Felix Boehm\nRepository: git://github.com/fb55/entities.git\n\n> Copyright (c) Felix Böhm\n> All rights reserved.\n> \n> Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n> \n> Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n> \n> Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n> \n> THIS IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS,\n> EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n---------------------------------------\n\n## es-module-lexer\nLicense: MIT\nBy: Guy Bedford\nRepository: git+https://github.com/guybedford/es-module-lexer.git\n\n> MIT License\n> -----------\n> \n> Copyright (C) 2018-2022 Guy Bedford\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## escape-html\nLicense: MIT\nRepository: component/escape-html\n\n> (The MIT License)\n> \n> Copyright (c) 2012-2013 TJ Holowaychuk\n> Copyright (c) 2015 Andreas Lubbe\n> Copyright (c) 2015 Tiancheng \"Timothy\" Gu\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## estree-walker\nLicense: MIT\nBy: Rich Harris\nRepository: https://github.com/Rich-Harris/estree-walker\n\n> Copyright (c) 2015-20 [these people](https://github.com/Rich-Harris/estree-walker/graphs/contributors)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## etag\nLicense: MIT\nBy: Douglas Christopher Wilson, David Björklund\nRepository: jshttp/etag\n\n> (The MIT License)\n> \n> Copyright (c) 2014-2016 Douglas Christopher Wilson\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## eventemitter3\nLicense: MIT\nBy: Arnout Kazemier\nRepository: git://github.com/primus/eventemitter3.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014 Arnout Kazemier\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## fast-glob\nLicense: MIT\nBy: Denis Malinochkin\nRepository: mrmlnc/fast-glob\n\n> The MIT License (MIT)\n> \n> Copyright (c) Denis Malinochkin\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## fastq\nLicense: ISC\nBy: Matteo Collina\nRepository: git+https://github.com/mcollina/fastq.git\n\n> Copyright (c) 2015-2020, Matteo Collina <matteo.collina@gmail.com>\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n> OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## fill-range\nLicense: MIT\nBy: Jon Schlinkert, Edo Rivai, Paul Miller, Rouven Weßling\nRepository: jonschlinkert/fill-range\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-present, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## finalhandler\nLicense: MIT\nBy: Douglas Christopher Wilson\nRepository: pillarjs/finalhandler\n\n> (The MIT License)\n> \n> Copyright (c) 2014-2017 Douglas Christopher Wilson <doug@somethingdoug.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## follow-redirects\nLicense: MIT\nBy: Ruben Verborgh, Olivier Lalonde, James Talmage\nRepository: git@github.com:follow-redirects/follow-redirects.git\n\n> Copyright 2014–present Olivier Lalonde <olalonde@gmail.com>, James Talmage <james@talmage.io>, Ruben Verborgh\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n> of the Software, and to permit persons to whom the Software is furnished to do\n> so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n> WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR\n> IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## fs.realpath\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: git+https://github.com/isaacs/fs.realpath.git\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n> \n> ----\n> \n> This library bundles a version of the `fs.realpath` and `fs.realpathSync`\n> methods from Node.js v0.10 under the terms of the Node.js MIT license.\n> \n> Node's license follows, also included at the header of `old.js` which contains\n> the licensed code:\n> \n>   Copyright Joyent, Inc. and other Node contributors.\n> \n>   Permission is hereby granted, free of charge, to any person obtaining a\n>   copy of this software and associated documentation files (the \"Software\"),\n>   to deal in the Software without restriction, including without limitation\n>   the rights to use, copy, modify, merge, publish, distribute, sublicense,\n>   and/or sell copies of the Software, and to permit persons to whom the\n>   Software is furnished to do so, subject to the following conditions:\n> \n>   The above copyright notice and this permission notice shall be included in\n>   all copies or substantial portions of the Software.\n> \n>   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n>   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n>   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n>   AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n>   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n>   FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n>   DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## generic-names\nLicense: MIT\nBy: Alexey Litvinov\nRepository: git+https://github.com/css-modules/generic-names.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2015 Alexey Litvinov\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## glob\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: git://github.com/isaacs/node-glob.git\n\n> The ISC License\n> \n> Copyright (c) 2009-2022 Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## glob-parent\nLicense: ISC\nBy: Gulp Team, Elan Shanker, Blaine Bublitz\nRepository: gulpjs/glob-parent\n\n> The ISC License\n> \n> Copyright (c) 2015, 2019 Elan Shanker\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## http-proxy\nLicense: MIT\nBy: Charlie Robbins, jcrugzz <jcrugzz@gmail.com>\nRepository: https://github.com/http-party/node-http-proxy.git\n\n> node-http-proxy\n> \n>   Copyright (c) 2010-2016 Charlie Robbins, Jarrett Cruger & the Contributors.\n> \n>   Permission is hereby granted, free of charge, to any person obtaining\n>   a copy of this software and associated documentation files (the\n>   \"Software\"), to deal in the Software without restriction, including\n>   without limitation the rights to use, copy, modify, merge, publish,\n>   distribute, sublicense, and/or sell copies of the Software, and to\n>   permit persons to whom the Software is furnished to do so, subject to\n>   the following conditions:\n> \n>   The above copyright notice and this permission notice shall be\n>   included in all copies or substantial portions of the Software.\n> \n>   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n>   EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n>   MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n>   NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n>   LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n>   OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n>   WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## icss-utils\nLicense: ISC\nBy: Glen Maddern\nRepository: git+https://github.com/css-modules/icss-utils.git\n\n> ISC License (ISC)\n> Copyright 2018 Glen Maddern\n> \n> Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## inflight\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: https://github.com/npm/inflight.git\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## inherits\nLicense: ISC\nRepository: git://github.com/isaacs/inherits\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n> REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n> FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n> INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\n> LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\n> OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n> PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## is-binary-path\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/is-binary-path\n\n> MIT License\n> \n> Copyright (c) 2019 Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com), Paul Miller (https://paulmillr.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## is-docker\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/is-docker\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## is-extglob\nLicense: MIT\nBy: Jon Schlinkert\nRepository: jonschlinkert/is-extglob\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-2016, Jon Schlinkert\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## is-glob\nLicense: MIT\nBy: Jon Schlinkert, Brian Woodward, Daniel Perez\nRepository: micromatch/is-glob\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-2017, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## is-number\nLicense: MIT\nBy: Jon Schlinkert, Olsten Larck, Rouven Weßling\nRepository: jonschlinkert/is-number\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-present, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## is-reference\nLicense: MIT\nBy: Rich Harris\nRepository: git+https://github.com/Rich-Harris/is-reference.git\n\n---------------------------------------\n\n## is-wsl\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/is-wsl\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## isexe\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: git+https://github.com/isaacs/isexe.git\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## json-stable-stringify\nLicense: MIT\nBy: James Halliday\nRepository: git://github.com/ljharb/json-stable-stringify.git\n\n> This software is released under the MIT license:\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## launch-editor\nLicense: MIT\nBy: Evan You\nRepository: git+https://github.com/yyx990803/launch-editor.git\n\n---------------------------------------\n\n## launch-editor-middleware\nLicense: MIT\nBy: Evan You\nRepository: git+https://github.com/yyx990803/launch-editor.git\n\n---------------------------------------\n\n## lilconfig\nLicense: MIT\nBy: antonk52\nRepository: https://github.com/antonk52/lilconfig\n\n---------------------------------------\n\n## loader-utils\nLicense: MIT\nBy: Tobias Koppers @sokra\nRepository: https://github.com/webpack/loader-utils.git\n\n> Copyright JS Foundation and other contributors\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## lodash.camelcase\nLicense: MIT\nBy: John-David Dalton, Blaine Bublitz, Mathias Bynens\nRepository: lodash/lodash\n\n> Copyright jQuery Foundation and other contributors <https://jquery.org/>\n> \n> Based on Underscore.js, copyright Jeremy Ashkenas,\n> DocumentCloud and Investigative Reporters & Editors <http://underscorejs.org/>\n> \n> This software consists of voluntary contributions made by many\n> individuals. For exact contribution history, see the revision history\n> available at https://github.com/lodash/lodash\n> \n> The following license applies to all parts of this software except as\n> documented below:\n> \n> ====\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> \"Software\"), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n> NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n> LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n> OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n> WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n> \n> ====\n> \n> Copyright and related rights for sample code are waived via CC0. Sample\n> code is defined as all source code displayed within the prose of the\n> documentation.\n> \n> CC0: http://creativecommons.org/publicdomain/zero/1.0/\n> \n> ====\n> \n> Files located in the node_modules and vendor directories are externally\n> maintained libraries used by this software which have their own\n> licenses; we recommend you read them, as their terms may differ from the\n> terms above.\n\n---------------------------------------\n\n## magic-string\nLicense: MIT\nBy: Rich Harris\nRepository: https://github.com/rich-harris/magic-string\n\n> Copyright 2018 Rich Harris\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## merge2\nLicense: MIT\nRepository: git@github.com:teambition/merge2.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-2020 Teambition\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## micromatch\nLicense: MIT\nBy: Jon Schlinkert, Amila Welihinda, Bogdan Chadkin, Brian Woodward, Devon Govett, Elan Shanker, Fabrício Matté, Martin Kolárik, Olsten Larck, Paul Miller, Tom Byrer, Tyler Akins, Peter Bright, Kuba Juszczyk\nRepository: micromatch/micromatch\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-present, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## minimatch\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: git://github.com/isaacs/minimatch.git\n\n> The ISC License\n> \n> Copyright (c) 2011-2022 Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## mlly\nLicense: MIT\nRepository: unjs/mlly\n\n> MIT License\n> \n> Copyright (c) Pooya Parsa <pooya@pi0.io>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## mrmime\nLicense: MIT\nBy: Luke Edwards\nRepository: lukeed/mrmime\n\n> The MIT License (MIT)\n> \n> Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (https://lukeed.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## ms\nLicense: MIT\nRepository: zeit/ms\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2016 Zeit, Inc.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## normalize-path\nLicense: MIT\nBy: Jon Schlinkert, Blaine Bublitz\nRepository: jonschlinkert/normalize-path\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014-2018, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## object-assign\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/object-assign\n\n> The MIT License (MIT)\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## okie\nLicense: MIT\nBy: Evan You\nRepository: git+https://github.com/yyx990803/okie.git\n\n> MIT License\n> \n> Copyright (c) 2020-present, Yuxi (Evan) You\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## on-finished\nLicense: MIT\nBy: Douglas Christopher Wilson, Jonathan Ong\nRepository: jshttp/on-finished\n\n> (The MIT License)\n> \n> Copyright (c) 2013 Jonathan Ong <me@jongleberry.com>\n> Copyright (c) 2014 Douglas Christopher Wilson <doug@somethingdoug.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## once\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: git://github.com/isaacs/once\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## open\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/open\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## parse5\nLicense: MIT\nBy: Ivan Nikulin, https://github.com/inikulin/parse5/graphs/contributors\nRepository: git://github.com/inikulin/parse5.git\n\n> Copyright (c) 2013-2019 Ivan Nikulin (ifaaan@gmail.com, https://github.com/inikulin)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## parseurl\nLicense: MIT\nBy: Douglas Christopher Wilson, Jonathan Ong\nRepository: pillarjs/parseurl\n\n> (The MIT License)\n> \n> Copyright (c) 2014 Jonathan Ong <me@jongleberry.com>\n> Copyright (c) 2014-2017 Douglas Christopher Wilson <doug@somethingdoug.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## path-key\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/path-key\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## periscopic\nLicense: MIT\nRepository: Rich-Harris/periscopic\n\n> Copyright (c) 2019 Rich Harris\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## picocolors\nLicense: ISC\nBy: Alexey Raspopov\nRepository: alexeyraspopov/picocolors\n\n> ISC License\n> \n> Copyright (c) 2021 Alexey Raspopov, Kostiantyn Denysov, Anton Verinov\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n> OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## picomatch\nLicense: MIT\nBy: Jon Schlinkert\nRepository: micromatch/picomatch\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2017-present, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## pify\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/pify\n\n> The MIT License (MIT)\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## postcss-import\nLicense: MIT\nBy: Maxime Thirouin\nRepository: https://github.com/postcss/postcss-import.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014 Maxime Thirouin, Jason Campbell & Kevin Mårtensson\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## postcss-load-config\nLicense: MIT\nBy: Michael Ciniawky, Ryan Dunckel, Mateusz Derks, Dalton Santos, Patrick Gilday, François Wouts\nRepository: postcss/postcss-load-config\n\n> The MIT License (MIT)\n> \n> Copyright Michael Ciniawsky <michael.ciniawsky@gmail.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## postcss-modules\nLicense: MIT\nBy: Alexander Madyankin\nRepository: https://github.com/css-modules/postcss-modules.git\n\n> The MIT License (MIT)\n> \n> Copyright 2015-present Alexander Madyankin <alexander@madyankin.name>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## postcss-modules-extract-imports\nLicense: ISC\nBy: Glen Maddern\nRepository: https://github.com/css-modules/postcss-modules-extract-imports.git\n\n> Copyright 2015 Glen Maddern\n> \n> Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## postcss-modules-local-by-default\nLicense: MIT\nBy: Mark Dalgleish\nRepository: https://github.com/css-modules/postcss-modules-local-by-default.git\n\n> The MIT License (MIT)\n> \n> Copyright 2015 Mark Dalgleish <mark.john.dalgleish@gmail.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## postcss-modules-scope\nLicense: ISC\nBy: Glen Maddern\nRepository: https://github.com/css-modules/postcss-modules-scope.git\n\n> ISC License (ISC)\n> \n> Copyright (c) 2015, Glen Maddern\n> \n> Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## postcss-modules-values\nLicense: ISC\nBy: Glen Maddern\nRepository: git+https://github.com/css-modules/postcss-modules-values.git\n\n> ISC License (ISC)\n> \n> Copyright (c) 2015, Glen Maddern\n> \n> Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## postcss-selector-parser\nLicense: MIT\nBy: Ben Briggs, Chris Eppstein\nRepository: postcss/postcss-selector-parser\n\n> Copyright (c) Ben Briggs <beneb.info@gmail.com> (http://beneb.info)\n> \n> Permission is hereby granted, free of charge, to any person\n> obtaining a copy of this software and associated documentation\n> files (the \"Software\"), to deal in the Software without\n> restriction, including without limitation the rights to use,\n> copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the\n> Software is furnished to do so, subject to the following\n> conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n> OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n> NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n> HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n> WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n> FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n> OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## postcss-value-parser\nLicense: MIT\nBy: Bogdan Chadkin\nRepository: https://github.com/TrySound/postcss-value-parser.git\n\n> Copyright (c) Bogdan Chadkin <trysound@yandex.ru>\n> \n> Permission is hereby granted, free of charge, to any person\n> obtaining a copy of this software and associated documentation\n> files (the \"Software\"), to deal in the Software without\n> restriction, including without limitation the rights to use,\n> copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the\n> Software is furnished to do so, subject to the following\n> conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n> OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n> NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n> HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n> WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n> FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n> OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## queue-microtask\nLicense: MIT\nBy: Feross Aboukhadijeh\nRepository: git://github.com/feross/queue-microtask.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) Feross Aboukhadijeh\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## read-cache\nLicense: MIT\nBy: Bogdan Chadkin\nRepository: git+https://github.com/TrySound/read-cache.git\n\n> The MIT License (MIT)\n> \n> Copyright 2016 Bogdan Chadkin <trysound@yandex.ru>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## readdirp\nLicense: MIT\nBy: Thorsten Lorenz, Paul Miller\nRepository: git://github.com/paulmillr/readdirp.git\n\n> MIT License\n> \n> Copyright (c) 2012-2019 Thorsten Lorenz, Paul Miller (https://paulmillr.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## requires-port\nLicense: MIT\nBy: Arnout Kazemier\nRepository: https://github.com/unshiftio/requires-port\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2015 Unshift.io, Arnout Kazemier,  the Contributors.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## resolve.exports\nLicense: MIT\nBy: Luke Edwards\nRepository: lukeed/resolve.exports\n\n> The MIT License (MIT)\n> \n> Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (lukeed.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## reusify\nLicense: MIT\nBy: Matteo Collina\nRepository: git+https://github.com/mcollina/reusify.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2015 Matteo Collina\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## run-parallel\nLicense: MIT\nBy: Feross Aboukhadijeh\nRepository: git://github.com/feross/run-parallel.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) Feross Aboukhadijeh\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## shebang-command\nLicense: MIT\nBy: Kevin Mårtensson\nRepository: kevva/shebang-command\n\n> MIT License\n> \n> Copyright (c) Kevin Mårtensson <kevinmartensson@gmail.com> (github.com/kevva)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## shebang-regex\nLicense: MIT\nBy: Sindre Sorhus\nRepository: sindresorhus/shebang-regex\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## shell-quote\nLicense: MIT\nBy: James Halliday\nRepository: http://github.com/substack/node-shell-quote.git\n\n> The MIT License\n> \n> Copyright (c) 2013 James Halliday (mail@substack.net)\n> \n> Permission is hereby granted, free of charge, \n> to any person obtaining a copy of this software and \n> associated documentation files (the \"Software\"), to \n> deal in the Software without restriction, including \n> without limitation the rights to use, copy, modify, \n> merge, publish, distribute, sublicense, and/or sell \n> copies of the Software, and to permit persons to whom \n> the Software is furnished to do so, \n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice \n> shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, \n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES \n> OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. \n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR \n> ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, \n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE \n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## sirv\nLicense: MIT\nBy: Luke Edwards\nRepository: lukeed/sirv\n\n---------------------------------------\n\n## statuses\nLicense: MIT\nBy: Douglas Christopher Wilson, Jonathan Ong\nRepository: jshttp/statuses\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2014 Jonathan Ong <me@jongleberry.com>\n> Copyright (c) 2016 Douglas Christopher Wilson <doug@somethingdoug.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## string-hash\nLicense: CC0-1.0\nBy: The Dark Sky Company\nRepository: git://github.com/darkskyapp/string-hash.git\n\n---------------------------------------\n\n## strip-ansi\nLicense: MIT\nBy: Sindre Sorhus\nRepository: chalk/strip-ansi\n\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## strip-literal\nLicense: MIT\nBy: Anthony Fu\nRepository: git+https://github.com/antfu/strip-literal.git\n\n> MIT License\n> \n> Copyright (c) 2022 Anthony Fu <https://github.com/antfu>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## to-regex-range\nLicense: MIT\nBy: Jon Schlinkert, Rouven Weßling\nRepository: micromatch/to-regex-range\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2015-present, Jon Schlinkert.\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## totalist\nLicense: MIT\nBy: Luke Edwards\nRepository: lukeed/totalist\n\n> The MIT License (MIT)\n> \n> Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (lukeed.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in\n> all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n> THE SOFTWARE.\n\n---------------------------------------\n\n## tsconfck\nLicense: MIT\nBy: dominikg\nRepository: git+https://github.com/dominikg/tsconfck.git\n\n> MIT License\n> \n> Copyright (c) 2021-present dominikg and [contributors](https://github.com/dominikg/tsconfck/graphs/contributors)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n> \n> -- Licenses for 3rd-party code included in tsconfck --\n> \n> # strip-bom and strip-json-comments\n> MIT License\n> \n> Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## ufo\nLicense: MIT\nRepository: unjs/ufo\n\n> MIT License\n> \n> Copyright (c) Pooya Parsa <pooya@pi0.io>\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy\n> of this software and associated documentation files (the \"Software\"), to deal\n> in the Software without restriction, including without limitation the rights\n> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the Software is\n> furnished to do so, subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n> SOFTWARE.\n\n---------------------------------------\n\n## unpipe\nLicense: MIT\nBy: Douglas Christopher Wilson\nRepository: stream-utils/unpipe\n\n> (The MIT License)\n> \n> Copyright (c) 2015 Douglas Christopher Wilson <doug@somethingdoug.com>\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## util-deprecate\nLicense: MIT\nBy: Nathan Rajlich\nRepository: git://github.com/TooTallNate/util-deprecate.git\n\n> (The MIT License)\n> \n> Copyright (c) 2014 Nathan Rajlich <nathan@tootallnate.net>\n> \n> Permission is hereby granted, free of charge, to any person\n> obtaining a copy of this software and associated documentation\n> files (the \"Software\"), to deal in the Software without\n> restriction, including without limitation the rights to use,\n> copy, modify, merge, publish, distribute, sublicense, and/or sell\n> copies of the Software, and to permit persons to whom the\n> Software is furnished to do so, subject to the following\n> conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n> OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n> NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n> HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n> WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n> FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n> OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## utils-merge\nLicense: MIT\nBy: Jared Hanson\nRepository: git://github.com/jaredhanson/utils-merge.git\n\n> The MIT License (MIT)\n> \n> Copyright (c) 2013-2017 Jared Hanson\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## vary\nLicense: MIT\nBy: Douglas Christopher Wilson\nRepository: jshttp/vary\n\n> (The MIT License)\n> \n> Copyright (c) 2014-2017 Douglas Christopher Wilson\n> \n> Permission is hereby granted, free of charge, to any person obtaining\n> a copy of this software and associated documentation files (the\n> 'Software'), to deal in the Software without restriction, including\n> without limitation the rights to use, copy, modify, merge, publish,\n> distribute, sublicense, and/or sell copies of the Software, and to\n> permit persons to whom the Software is furnished to do so, subject to\n> the following conditions:\n> \n> The above copyright notice and this permission notice shall be\n> included in all copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\n> EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n> MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n> IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n> CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n> TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n> SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## which\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: git://github.com/isaacs/node-which.git\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## wrappy\nLicense: ISC\nBy: Isaac Z. Schlueter\nRepository: https://github.com/npm/wrappy\n\n> The ISC License\n> \n> Copyright (c) Isaac Z. Schlueter and Contributors\n> \n> Permission to use, copy, modify, and/or distribute this software for any\n> purpose with or without fee is hereby granted, provided that the above\n> copyright notice and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n> WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n> MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n> ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n> WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n> ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n> IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n---------------------------------------\n\n## ws\nLicense: MIT\nBy: Einar Otto Stangvik\nRepository: websockets/ws\n\n> Copyright (c) 2011 Einar Otto Stangvik <einaros@gmail.com>\n> Copyright (c) 2013 Arnout Kazemier and contributors\n> Copyright (c) 2016 Luigi Pinca and contributors\n> \n> Permission is hereby granted, free of charge, to any person obtaining a copy of\n> this software and associated documentation files (the \"Software\"), to deal in\n> the Software without restriction, including without limitation the rights to\n> use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n> the Software, and to permit persons to whom the Software is furnished to do so,\n> subject to the following conditions:\n> \n> The above copyright notice and this permission notice shall be included in all\n> copies or substantial portions of the Software.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n> FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n> COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n> IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n> CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n---------------------------------------\n\n## yaml\nLicense: ISC\nBy: Eemeli Aro\nRepository: github:eemeli/yaml\n\n> Copyright Eemeli Aro <eemeli@gmail.com>\n> \n> Permission to use, copy, modify, and/or distribute this software for any purpose\n> with or without fee is hereby granted, provided that the above copyright notice\n> and this permission notice appear in all copies.\n> \n> THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n> REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n> FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n> INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS\n> OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER\n> TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF\n> THIS SOFTWARE.\n"}},"package.json":{"file":{"contents":"{\n  \"name\": \"vite\",\n  \"version\": \"4.1.4\",\n  \"type\": \"module\",\n  \"license\": \"MIT\",\n  \"author\": \"Evan You\",\n  \"description\": \"Native-ESM powered web dev build tool\",\n  \"bin\": {\n    \"vite\": \"bin/vite.js\"\n  },\n  \"keywords\": [\n    \"frontend\",\n    \"framework\",\n    \"hmr\",\n    \"dev-server\",\n    \"build-tool\",\n    \"vite\"\n  ],\n  \"main\": \"./dist/node/index.js\",\n  \"types\": \"./dist/node/index.d.ts\",\n  \"exports\": {\n    \".\": {\n      \"types\": \"./dist/node/index.d.ts\",\n      \"import\": \"./dist/node/index.js\",\n      \"require\": \"./index.cjs\"\n    },\n    \"./client\": {\n      \"types\": \"./client.d.ts\"\n    },\n    \"./dist/client/*\": \"./dist/client/*\",\n    \"./package.json\": \"./package.json\"\n  },\n  \"files\": [\n    \"bin\",\n    \"dist\",\n    \"client.d.ts\",\n    \"index.cjs\",\n    \"types\"\n  ],\n  \"engines\": {\n    \"node\": \"^14.18.0 || >=16.0.0\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/vitejs/vite.git\",\n    \"directory\": \"packages/vite\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/vitejs/vite/issues\"\n  },\n  \"homepage\": \"https://github.com/vitejs/vite/tree/main/#readme\",\n  \"scripts\": {\n    \"dev\": \"rimraf dist && pnpm run build-bundle -w\",\n    \"build\": \"rimraf dist && run-s build-bundle build-types\",\n    \"build-bundle\": \"rollup --config rollup.config.ts --configPlugin typescript\",\n    \"build-types\": \"run-s build-types-temp build-types-pre-patch build-types-roll build-types-post-patch build-types-check\",\n    \"build-types-temp\": \"tsc --emitDeclarationOnly --outDir temp/node -p src/node\",\n    \"build-types-pre-patch\": \"tsx scripts/prePatchTypes.ts\",\n    \"build-types-roll\": \"api-extractor run && rimraf temp\",\n    \"build-types-post-patch\": \"tsx scripts/postPatchTypes.ts\",\n    \"build-types-check\": \"tsx scripts/checkBuiltTypes.ts && tsc --project tsconfig.check.json\",\n    \"typecheck\": \"tsc --noEmit\",\n    \"lint\": \"eslint --cache --ext .ts src/**\",\n    \"format\": \"prettier --write --cache --parser typescript \\\"src/**/*.ts\\\"\",\n    \"prepublishOnly\": \"npm run build\"\n  },\n  \"//\": \"READ CONTRIBUTING.md to understand what to put under deps vs. devDeps!\",\n  \"dependencies\": {\n    \"esbuild\": \"^0.16.14\",\n    \"postcss\": \"^8.4.21\",\n    \"resolve\": \"^1.22.1\",\n    \"rollup\": \"^3.10.0\"\n  },\n  \"optionalDependencies\": {\n    \"fsevents\": \"~2.3.2\"\n  },\n  \"devDependencies\": {\n    \"@ampproject/remapping\": \"^2.2.0\",\n    \"@babel/parser\": \"^7.20.13\",\n    \"@babel/types\": \"^7.20.7\",\n    \"@jridgewell/trace-mapping\": \"^0.3.17\",\n    \"@rollup/plugin-alias\": \"^4.0.3\",\n    \"@rollup/plugin-commonjs\": \"^24.0.1\",\n    \"@rollup/plugin-dynamic-import-vars\": \"^2.0.3\",\n    \"@rollup/plugin-json\": \"^6.0.0\",\n    \"@rollup/plugin-node-resolve\": \"15.0.1\",\n    \"@rollup/plugin-typescript\": \"^11.0.0\",\n    \"@rollup/pluginutils\": \"^5.0.2\",\n    \"acorn\": \"^8.8.2\",\n    \"acorn-walk\": \"^8.2.0\",\n    \"cac\": \"^6.7.14\",\n    \"chokidar\": \"^3.5.3\",\n    \"connect\": \"^3.7.0\",\n    \"connect-history-api-fallback\": \"^2.0.0\",\n    \"convert-source-map\": \"^2.0.0\",\n    \"cors\": \"^2.8.5\",\n    \"cross-spawn\": \"^7.0.3\",\n    \"debug\": \"^4.3.4\",\n    \"dep-types\": \"link:./src/types\",\n    \"dotenv\": \"^16.0.3\",\n    \"dotenv-expand\": \"^9.0.0\",\n    \"es-module-lexer\": \"^1.1.0\",\n    \"estree-walker\": \"^3.0.3\",\n    \"etag\": \"^1.8.1\",\n    \"fast-glob\": \"^3.2.12\",\n    \"http-proxy\": \"^1.18.1\",\n    \"json-stable-stringify\": \"^1.0.2\",\n    \"launch-editor-middleware\": \"^2.6.0\",\n    \"magic-string\": \"^0.27.0\",\n    \"micromatch\": \"^4.0.5\",\n    \"mlly\": \"^1.1.0\",\n    \"mrmime\": \"^1.0.1\",\n    \"okie\": \"^1.0.1\",\n    \"open\": \"^8.4.0\",\n    \"parse5\": \"^7.1.2\",\n    \"periscopic\": \"^3.1.0\",\n    \"picocolors\": \"^1.0.0\",\n    \"picomatch\": \"^2.3.1\",\n    \"postcss-import\": \"^15.1.0\",\n    \"postcss-load-config\": \"^4.0.1\",\n    \"postcss-modules\": \"^6.0.0\",\n    \"resolve.exports\": \"^2.0.0\",\n    \"rollup-plugin-license\": \"^3.0.1\",\n    \"sirv\": \"^2.0.2\",\n    \"source-map-js\": \"^1.0.2\",\n    \"source-map-support\": \"^0.5.21\",\n    \"strip-ansi\": \"^7.0.1\",\n    \"strip-literal\": \"^1.0.1\",\n    \"tsconfck\": \"^2.0.2\",\n    \"tslib\": \"^2.5.0\",\n    \"types\": \"link:./types\",\n    \"ufo\": \"^1.0.1\",\n    \"ws\": \"^8.12.0\"\n  },\n  \"peerDependencies\": {\n    \"@types/node\": \">= 14\",\n    \"less\": \"*\",\n    \"sass\": \"*\",\n    \"stylus\": \"*\",\n    \"sugarss\": \"*\",\n    \"terser\": \"^5.4.0\"\n  },\n  \"peerDependenciesMeta\": {\n    \"@types/node\": {\n      \"optional\": true\n    },\n    \"sass\": {\n      \"optional\": true\n    },\n    \"stylus\": {\n      \"optional\": true\n    },\n    \"less\": {\n      \"optional\": true\n    },\n    \"sugarss\": {\n      \"optional\": true\n    },\n    \"terser\": {\n      \"optional\": true\n    }\n  }\n}\n"}},"README.md":{"file":{"contents":"# vite ⚡\n\n> Next Generation Frontend Tooling\n\n- 💡 Instant Server Start\n- ⚡️ Lightning Fast HMR\n- 🛠️ Rich Features\n- 📦 Optimized Build\n- 🔩 Universal Plugin Interface\n- 🔑 Fully Typed APIs\n\nVite (French word for \"fast\", pronounced `/vit/`) is a new breed of frontend build tool that significantly improves the frontend development experience. It consists of two major parts:\n\n- A dev server that serves your source files over [native ES modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules), with [rich built-in features](https://vitejs.dev/guide/features.html) and astonishingly fast [Hot Module Replacement (HMR)](https://vitejs.dev/guide/features.html#hot-module-replacement).\n\n- A [build command](https://vitejs.dev/guide/build.html) that bundles your code with [Rollup](https://rollupjs.org), pre-configured to output highly optimized static assets for production.\n\nIn addition, Vite is highly extensible via its [Plugin API](https://vitejs.dev/guide/api-plugin.html) and [JavaScript API](https://vitejs.dev/guide/api-javascript.html) with full typing support.\n\n[Read the Docs to Learn More](https://vitejs.dev).\n"}},"types":{"directory":{"customEvent.d.ts":{"file":{"contents":"import type {\n  ErrorPayload,\n  FullReloadPayload,\n  PrunePayload,\n  UpdatePayload,\n} from './hmrPayload'\n\nexport interface CustomEventMap {\n  'vite:beforeUpdate': UpdatePayload\n  'vite:afterUpdate': UpdatePayload\n  'vite:beforePrune': PrunePayload\n  'vite:beforeFullReload': FullReloadPayload\n  'vite:error': ErrorPayload\n  'vite:invalidate': InvalidatePayload\n}\n\nexport interface InvalidatePayload {\n  path: string\n  message: string | undefined\n}\n\nexport type InferCustomEventPayload<T extends string> =\n  T extends keyof CustomEventMap ? CustomEventMap[T] : any\n"}},"hmrPayload.d.ts":{"file":{"contents":"export type HMRPayload =\n  | ConnectedPayload\n  | UpdatePayload\n  | FullReloadPayload\n  | CustomPayload\n  | ErrorPayload\n  | PrunePayload\n\nexport interface ConnectedPayload {\n  type: 'connected'\n}\n\nexport interface UpdatePayload {\n  type: 'update'\n  updates: Update[]\n}\n\nexport interface Update {\n  type: 'js-update' | 'css-update'\n  path: string\n  acceptedPath: string\n  timestamp: number\n  /**\n   * @experimental internal\n   */\n  explicitImportRequired?: boolean | undefined\n}\n\nexport interface PrunePayload {\n  type: 'prune'\n  paths: string[]\n}\n\nexport interface FullReloadPayload {\n  type: 'full-reload'\n  path?: string\n}\n\nexport interface CustomPayload {\n  type: 'custom'\n  event: string\n  data?: any\n}\n\nexport interface ErrorPayload {\n  type: 'error'\n  err: {\n    [name: string]: any\n    message: string\n    stack: string\n    id?: string\n    frame?: string\n    plugin?: string\n    pluginCode?: string\n    loc?: {\n      file?: string\n      line: number\n      column: number\n    }\n  }\n}\n"}},"hot.d.ts":{"file":{"contents":"import type { InferCustomEventPayload } from './customEvent'\n\nexport type ModuleNamespace = Record<string, any> & {\n  [Symbol.toStringTag]: 'Module'\n}\n\nexport interface ViteHotContext {\n  readonly data: any\n\n  accept(): void\n  accept(cb: (mod: ModuleNamespace | undefined) => void): void\n  accept(dep: string, cb: (mod: ModuleNamespace | undefined) => void): void\n  accept(\n    deps: readonly string[],\n    cb: (mods: Array<ModuleNamespace | undefined>) => void,\n  ): void\n\n  acceptExports(\n    exportNames: string | readonly string[],\n    cb?: (mod: ModuleNamespace | undefined) => void,\n  ): void\n\n  dispose(cb: (data: any) => void): void\n  prune(cb: (data: any) => void): void\n  invalidate(message?: string): void\n\n  on<T extends string>(\n    event: T,\n    cb: (payload: InferCustomEventPayload<T>) => void,\n  ): void\n  send<T extends string>(event: T, data?: InferCustomEventPayload<T>): void\n}\n"}},"importGlob.d.ts":{"file":{"contents":"export interface ImportGlobOptions<\n  Eager extends boolean,\n  AsType extends string,\n> {\n  /**\n   * Import type for the import url.\n   */\n  as?: AsType\n  /**\n   * Import as static or dynamic\n   *\n   * @default false\n   */\n  eager?: Eager\n  /**\n   * Import only the specific named export. Set to `default` to import the default export.\n   */\n  import?: string\n  /**\n   * Custom queries\n   */\n  query?: string | Record<string, string | number | boolean>\n  /**\n   * Search files also inside `node_modules/` and hidden directories (e.g. `.git/`). This might have impact on performance.\n   *\n   * @default false\n   */\n  exhaustive?: boolean\n}\n\nexport type GeneralImportGlobOptions = ImportGlobOptions<boolean, string>\n\nexport interface KnownAsTypeMap {\n  raw: string\n  url: string\n  worker: Worker\n}\n\nexport interface ImportGlobFunction {\n  /**\n   * Import a list of files with a glob pattern.\n   *\n   * Overload 1: No generic provided, infer the type from `eager` and `as`\n   */\n  <\n    Eager extends boolean,\n    As extends string,\n    T = As extends keyof KnownAsTypeMap ? KnownAsTypeMap[As] : unknown,\n  >(\n    glob: string | string[],\n    options?: ImportGlobOptions<Eager, As>,\n  ): (Eager extends true ? true : false) extends true\n    ? Record<string, T>\n    : Record<string, () => Promise<T>>\n  /**\n   * Import a list of files with a glob pattern.\n   *\n   * Overload 2: Module generic provided, infer the type from `eager: false`\n   */\n  <M>(\n    glob: string | string[],\n    options?: ImportGlobOptions<false, string>,\n  ): Record<string, () => Promise<M>>\n  /**\n   * Import a list of files with a glob pattern.\n   *\n   * Overload 3: Module generic provided, infer the type from `eager: true`\n   */\n  <M>(\n    glob: string | string[],\n    options: ImportGlobOptions<true, string>,\n  ): Record<string, M>\n}\n\nexport interface ImportGlobEagerFunction {\n  /**\n   * Eagerly import a list of files with a glob pattern.\n   *\n   * Overload 1: No generic provided, infer the type from `as`\n   */\n  <\n    As extends string,\n    T = As extends keyof KnownAsTypeMap ? KnownAsTypeMap[As] : unknown,\n  >(\n    glob: string | string[],\n    options?: Omit<ImportGlobOptions<boolean, As>, 'eager'>,\n  ): Record<string, T>\n  /**\n   * Eagerly import a list of files with a glob pattern.\n   *\n   * Overload 2: Module generic provided\n   */\n  <M>(\n    glob: string | string[],\n    options?: Omit<ImportGlobOptions<boolean, string>, 'eager'>,\n  ): Record<string, M>\n}\n"}},"importMeta.d.ts":{"file":{"contents":"// This file is an augmentation to the built-in ImportMeta interface\n// Thus cannot contain any top-level imports\n// <https://www.typescriptlang.org/docs/handbook/declaration-merging.html#module-augmentation>\n\n/* eslint-disable @typescript-eslint/consistent-type-imports */\n\ninterface ImportMetaEnv {\n  [key: string]: any\n  BASE_URL: string\n  MODE: string\n  DEV: boolean\n  PROD: boolean\n  SSR: boolean\n}\n\ninterface ImportMeta {\n  url: string\n\n  readonly hot?: import('./hot').ViteHotContext\n\n  readonly env: ImportMetaEnv\n\n  glob: import('./importGlob').ImportGlobFunction\n  /**\n   * @deprecated Use `import.meta.glob('*', { eager: true })` instead\n   */\n  globEager: import('./importGlob').ImportGlobEagerFunction\n}\n"}},"metadata.d.ts":{"file":{"contents":"export interface ChunkMetadata {\n  importedAssets: Set<string>\n  importedCss: Set<string>\n}\n\ndeclare module 'rollup' {\n  export interface RenderedChunk {\n    viteMetadata?: ChunkMetadata\n  }\n}\n"}},"package.json":{"file":{"contents":"{\n  \"//\": \"this file is here to make typescript happy when moduleResolution=node16+\"\n}\n"}}}}}}